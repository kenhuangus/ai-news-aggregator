---
phase: 03-image-provider-support
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - generators/image_client.py
  - requirements.txt
autonomous: true

must_haves:
  truths:
    - "NativeGeminiClient can generate images using google-genai SDK"
    - "OpenAICompatibleClient can generate images using REST chat/completions format"
    - "ImageClient.from_config() returns appropriate implementation based on mode"
  artifacts:
    - path: "generators/image_client.py"
      provides: "Unified image client abstraction with factory method"
      exports: ["BaseImageClient", "NativeGeminiClient", "OpenAICompatibleClient", "ImageClient", "ImageResponse"]
    - path: "requirements.txt"
      provides: "google-genai SDK dependency"
      contains: "google-genai"
  key_links:
    - from: "generators/image_client.py:ImageClient.from_config"
      to: "agents/config/schema.py:ImageProviderConfig"
      via: "mode field determines client type"
      pattern: "config\\.mode"
---

<objective>
Create unified image client abstraction with NativeGeminiClient (google-genai SDK) and OpenAICompatibleClient (REST) implementations.

Purpose: Enable hero image generation via direct Google Gemini API or OpenAI-compatible proxies with a single unified interface. This follows the same factory pattern established for LLM client in Phase 2.

Output:
- `generators/image_client.py` with BaseImageClient ABC, NativeGeminiClient, OpenAICompatibleClient, and ImageClient factory
- Updated `requirements.txt` with google-genai SDK dependency
</objective>

<execution_context>
@/Users/ryand/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ryand/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-image-provider-support/03-RESEARCH.md
@agents/config/schema.py
@agents/llm_client.py
@generators/hero_generator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add google-genai SDK to requirements.txt</name>
  <files>requirements.txt</files>
  <action>
Add `google-genai>=1.0.0` to requirements.txt. This is the official Google SDK for Gemini, replacing the deprecated google-generativeai package.

Place it alphabetically or grouped with other API client libraries (near anthropic, httpx).
  </action>
  <verify>
Verify the line exists:
```bash
grep "google-genai" requirements.txt
```
  </verify>
  <done>requirements.txt contains google-genai>=1.0.0 dependency</done>
</task>

<task type="auto">
  <name>Task 2: Create image_client.py with unified abstraction</name>
  <files>generators/image_client.py</files>
  <action>
Create `generators/image_client.py` with:

1. **ImageResponse dataclass:**
   - `image_data: bytes` - Raw image bytes
   - `mime_type: str = "image/png"`

2. **BaseImageClient ABC:**
   - Abstract `async generate(prompt, reference_image, aspect_ratio, image_size) -> ImageResponse`
   - Default aspect_ratio="21:9", image_size="2K"

3. **NativeGeminiClient (native mode):**
   - Uses `google-genai` SDK (NOT google-generativeai)
   - Constructor: `api_key`, `model` (default "gemini-3-pro-image-preview"), `timeout` (default 180.0)
   - Initialize `genai.Client(api_key=api_key)` with explicit key (don't rely on env vars)
   - Use `HttpOptions(timeout=int(timeout * 1000))` - SDK uses milliseconds!
   - Use `HttpRetryOptions(attempts=3, initial_delay=1.0, max_delay=10.0)` for built-in retry
   - In generate():
     - Convert reference_image bytes to PIL Image using `Image.open(io.BytesIO(reference_image))`
     - Build contents list: [pil_image (if provided), prompt]
     - Call `await self.client.aio.models.generate_content()` with `types.GenerateContentConfig(image_config=types.ImageConfig(aspect_ratio, image_size))`
     - Extract image from `response.parts[].inline_data.data`
   - Handle `errors.APIError` with mode-specific troubleshooting message
   - Log initialization info at INFO level

4. **OpenAICompatibleClient (openai-compatible mode):**
   - Refactor from existing HeroGenerator code
   - Constructor: `api_key`, `endpoint`, `model`, `timeout` (default 180.0)
   - Auto-append /chat/completions if endpoint ends with /v1
   - In generate():
     - Build content list with image_url (base64) and text
     - POST to endpoint with Bearer auth, modalities=["image", "text"], image_config
     - Extract image from `choices[0].message.images[0].image_url.url`
     - Handle base64 data URL parsing
   - Handle httpx errors with mode-specific troubleshooting message
   - Log initialization info at INFO level

5. **ImageClient factory class:**
   - `from_config(config: ImageProviderConfig) -> BaseImageClient`
   - If mode == "native": return NativeGeminiClient
   - If mode == "openai-compatible": return OpenAICompatibleClient
   - Raise ValueError for unknown mode

Use TYPE_CHECKING import for ImageProviderConfig to avoid circular imports (same pattern as llm_client.py).

Import pattern from google-genai:
```python
from google import genai
from google.genai import types, errors
```
  </action>
  <verify>
Verify the file exists and has correct exports:
```bash
python3 -c "from generators.image_client import BaseImageClient, NativeGeminiClient, OpenAICompatibleClient, ImageClient, ImageResponse; print('Imports OK')"
```
  </verify>
  <done>generators/image_client.py exists with BaseImageClient, NativeGeminiClient, OpenAICompatibleClient, ImageClient factory, and ImageResponse dataclass</done>
</task>

<task type="auto">
  <name>Task 3: Verify factory pattern with mock config</name>
  <files>generators/image_client.py</files>
  <action>
Create a quick verification script to test the factory pattern works correctly:

```python
# In Python REPL or script
import sys
sys.path.insert(0, '.')

from agents.config.schema import ImageProviderConfig
from generators.image_client import ImageClient, NativeGeminiClient, OpenAICompatibleClient

# Test native mode (will fail on actual API call but factory should work)
native_config = ImageProviderConfig(
    mode="native",
    api_key="test-key-for-verification"
)
native_client = ImageClient.from_config(native_config)
assert isinstance(native_client, NativeGeminiClient), f"Expected NativeGeminiClient, got {type(native_client)}"
print(f"Native mode: {type(native_client).__name__}")

# Test openai-compatible mode
compat_config = ImageProviderConfig(
    mode="openai-compatible",
    api_key="test-key-for-verification",
    endpoint="https://api.example.com/v1"
)
compat_client = ImageClient.from_config(compat_config)
assert isinstance(compat_client, OpenAICompatibleClient), f"Expected OpenAICompatibleClient, got {type(compat_client)}"
print(f"OpenAI-compatible mode: {type(compat_client).__name__}")

print("Factory pattern verified!")
```

If there are any import errors or factory issues, fix them in image_client.py.
  </action>
  <verify>
Run the verification:
```bash
cd /Users/ryand/Code/AATF/ai-news-aggregator && python3 -c "
import sys
sys.path.insert(0, '.')
from agents.config.schema import ImageProviderConfig
from generators.image_client import ImageClient, NativeGeminiClient, OpenAICompatibleClient
native_config = ImageProviderConfig(mode='native', api_key='test-key')
native_client = ImageClient.from_config(native_config)
assert isinstance(native_client, NativeGeminiClient)
compat_config = ImageProviderConfig(mode='openai-compatible', api_key='test-key', endpoint='https://api.example.com/v1')
compat_client = ImageClient.from_config(compat_config)
assert isinstance(compat_client, OpenAICompatibleClient)
print('Factory pattern verified!')
"
```
  </verify>
  <done>ImageClient.from_config() returns NativeGeminiClient for native mode and OpenAICompatibleClient for openai-compatible mode</done>
</task>

</tasks>

<verification>
1. requirements.txt contains google-genai>=1.0.0
2. generators/image_client.py imports successfully
3. ImageClient.from_config() returns correct client type based on mode
4. No circular import errors
</verification>

<success_criteria>
- google-genai added to requirements.txt
- image_client.py created with full abstraction layer
- Factory pattern works correctly for both modes
- Code follows established patterns from llm_client.py
</success_criteria>

<output>
After completion, create `.planning/phases/03-image-provider-support/03-01-SUMMARY.md`
</output>
