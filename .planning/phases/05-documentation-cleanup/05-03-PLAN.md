---
phase: 05-documentation-cleanup
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - agents/config/schema.py
  - agents/config/loader.py
  - generators/feed_generator.py
  - config/providers.yaml
  - run_pipeline.py
autonomous: true

must_haves:
  truths:
    - "User can set base_url in providers.yaml under pipeline section"
    - "User can set lookback_hours in providers.yaml under pipeline section"
    - "FeedGenerator uses configured base_url instead of hardcoded value"
    - "Default base_url is localhost for local development"
    - "providers.yaml example has comprehensive comments"
  artifacts:
    - path: "agents/config/schema.py"
      provides: "PipelineConfig model with base_url and lookback_hours"
      contains: "PipelineConfig"
    - path: "generators/feed_generator.py"
      provides: "FeedGenerator accepting base_url parameter"
    - path: "config/providers.yaml"
      provides: "Configuration with pipeline section"
      contains: "pipeline:"
  key_links:
    - from: "generators/feed_generator.py"
      to: "agents/config/schema.py"
      via: "PipelineConfig type"
      pattern: "base_url"
    - from: "run_pipeline.py"
      to: "generators/feed_generator.py"
      via: "FeedGenerator constructor with base_url param"
      pattern: "base_url=pipeline_config\\.base_url"
---

<objective>
Add PipelineConfig to the configuration schema with base_url and lookback_hours settings, update FeedGenerator to use configured base_url, and enhance providers.yaml with comprehensive comments.

Purpose: Make the RSS feed base URL configurable so users can deploy to their own domains, and consolidate remaining env vars into YAML config.
Output: Extended config schema, updated FeedGenerator, enhanced providers.yaml with full documentation.
</objective>

<execution_context>
@/Users/ryand/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ryand/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-documentation-cleanup/05-CONTEXT.md

From context decisions:
- base_url: Required for RSS feeds to have correct absolute URLs
- lookback_hours: Currently env var LOOKBACK_HOURS, move to YAML
- Default base_url: "http://localhost:8080" for local dev
- providers.yaml.example should be heavily commented (self-documenting)

Current code references:
@agents/config/schema.py (ProviderConfig, LLMProviderConfig, ImageProviderConfig)
@generators/feed_generator.py (hardcoded SITE_URL = "https://news.aatf.ai")
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add PipelineConfig to schema</name>
  <files>agents/config/schema.py</files>
  <action>
    Add a new PipelineConfig model to agents/config/schema.py:

    ```python
    class PipelineConfig(BaseModel):
        """Configuration for pipeline settings.

        Attributes:
            base_url: Base URL for RSS feed links (e.g., https://your-domain.com)
            lookback_hours: Data collection window in hours (default: 24)
        """
        base_url: str = Field(
            default="http://localhost:8080",
            description="Base URL for RSS feed links. Set to your deployment domain."
        )
        lookback_hours: int = Field(
            default=24,
            ge=1,
            le=168,
            description="Data collection window in hours (1-168)"
        )

        @field_validator('base_url')
        @classmethod
        def validate_base_url(cls, v: str) -> str:
            """Validate and normalize base_url."""
            if not v:
                raise ValueError("base_url cannot be empty")
            # Remove trailing slash for consistency
            return v.rstrip('/')

        model_config = {"extra": "ignore"}
    ```

    Update ProviderConfig to include the pipeline config:

    ```python
    class ProviderConfig(BaseModel):
        llm: LLMProviderConfig
        image: Optional[ImageProviderConfig] = None
        pipeline: Optional[PipelineConfig] = None  # NEW: Optional pipeline settings

        model_config = {"extra": "ignore"}
    ```

    Add a helper method or property to get pipeline config with defaults:

    ```python
    def get_pipeline_config(self) -> PipelineConfig:
        """Get pipeline config, returning defaults if not specified."""
        return self.pipeline or PipelineConfig()
    ```
  </action>
  <verify>
    grep "PipelineConfig" agents/config/schema.py returns the class
    grep "base_url" agents/config/schema.py returns the field
    Python syntax is valid (python3 -m py_compile agents/config/schema.py)
    Config loading works with new optional field:
      python3 -c "from agents.config.loader import load_config; c=load_config('config/providers.yaml'); print(c.get_pipeline_config().base_url)"
  </verify>
  <done>PipelineConfig model added to schema with base_url and lookback_hours</done>
</task>

<task type="auto">
  <name>Task 2: Update FeedGenerator to use configured base_url</name>
  <files>generators/feed_generator.py</files>
  <action>
    Modify FeedGenerator to accept base_url as a constructor parameter:

    1. Change the class-level constant:
       - Remove: `SITE_URL = "https://news.aatf.ai"`
       - Keep as fallback default in __init__

    2. Update __init__ to accept base_url:
       ```python
       def __init__(self, output_dir: str, rolling_window_days: int = 7, base_url: str = None):
           """
           Initialize feed generator.

           Args:
               output_dir: Base output directory (typically web/)
               rolling_window_days: Number of days to include in feeds
               base_url: Base URL for feed links (defaults to http://localhost:8080)
           """
           self.output_dir = output_dir
           self.rolling_window_days = rolling_window_days
           self.base_url = (base_url or "http://localhost:8080").rstrip('/')
       ```

    3. Replace all uses of self.SITE_URL with self.base_url throughout the class

    4. Update make_urls_absolute() to use the instance base_url instead of hardcoded value

    Note: The FeedGenerator is instantiated in run_pipeline.py - that integration will need
    to pass the config value. For now, make the parameter optional with sensible default.
  </action>
  <verify>
    grep "SITE_URL = " generators/feed_generator.py returns no results (removed)
    grep "self.base_url" generators/feed_generator.py returns results
    grep "news.aatf.ai" generators/feed_generator.py returns no hardcoded references
    Python syntax is valid
  </verify>
  <done>FeedGenerator accepts and uses configurable base_url</done>
</task>

<task type="auto">
  <name>Task 3: Update providers.yaml with pipeline section and comprehensive comments</name>
  <files>config/providers.yaml</files>
  <action>
    Update config/providers.yaml to add the pipeline section and comprehensive comments.

    The file should be self-documenting with comments explaining every option.

    Structure:
    ```yaml
    # =============================================================================
    # AI News Aggregator - Provider Configuration
    # =============================================================================
    # This file configures API providers and pipeline settings.
    # Environment variables can be referenced using ${VAR_NAME} syntax.
    #
    # Quick Start:
    # 1. Copy this file to config/providers.yaml (if using example)
    # 2. Set your API keys (use ${ENV_VAR} to reference environment variables)
    # 3. Adjust settings as needed
    # =============================================================================

    # -----------------------------------------------------------------------------
    # LLM Provider Configuration (Required)
    # -----------------------------------------------------------------------------
    # Supports two modes:
    # - anthropic: Direct Anthropic API with x-api-key header (recommended)
    # - openai-compatible: OpenAI-compatible proxy (LiteLLM, vLLM, etc.)
    llm:
      # API mode: "anthropic" or "openai-compatible"
      mode: anthropic

      # API key - use ${ANTHROPIC_API_KEY} to reference environment variable
      api_key: ${ANTHROPIC_API_KEY}

      # API base URL (without /v1 suffix)
      # For direct Anthropic: https://api.anthropic.com
      # For proxy: your proxy URL (e.g., http://localhost:4000)
      base_url: https://api.anthropic.com

      # Model identifier
      # For direct Anthropic: claude-opus-4-5-20251101
      # For proxy: depends on your proxy configuration
      model: claude-opus-4-5-20251101

      # Request timeout in seconds (1-600)
      timeout: 300

    # -----------------------------------------------------------------------------
    # Image Provider Configuration (Optional)
    # -----------------------------------------------------------------------------
    # If not configured, hero image generation will be skipped.
    # Supports two modes:
    # - native: Google Gemini API via google-genai SDK (recommended)
    # - openai-compatible: OpenAI-compatible image endpoint
    image:
      # API mode: "native" or "openai-compatible"
      mode: native

      # API key for image generation
      api_key: ${GOOGLE_API_KEY}

      # Model name for image generation
      model: gemini-3-pro-image-preview

      # Endpoint URL (required only for openai-compatible mode)
      # endpoint: https://your-proxy.com/v1/images/generations

    # -----------------------------------------------------------------------------
    # Pipeline Settings (Optional)
    # -----------------------------------------------------------------------------
    # General pipeline configuration. All fields have sensible defaults.
    pipeline:
      # Base URL for RSS feed links
      # Set this to your deployment domain for production
      # Examples:
      #   - http://localhost:8080 (local development)
      #   - https://news.example.com (production)
      base_url: http://localhost:8080

      # Data collection window in hours (1-168)
      # How far back to look for news items
      lookback_hours: 24
    ```

    Preserve any existing api_key values (they may have real ${VAR} references).
  </action>
  <verify>
    grep "pipeline:" config/providers.yaml returns result
    grep "base_url:" config/providers.yaml returns result
    grep "lookback_hours:" config/providers.yaml returns result
    YAML is valid (python3 -c "import yaml; yaml.safe_load(open('config/providers.yaml'))")
  </verify>
  <done>providers.yaml has pipeline section and comprehensive documentation comments</done>
</task>

<task type="auto">
  <name>Task 4: Wire PipelineConfig to FeedGenerator in run_pipeline.py</name>
  <files>run_pipeline.py</files>
  <action>
    Update run_pipeline.py to pass base_url from config to FeedGenerator:

    1. Around line 128 where FeedGenerator is instantiated, change:
       ```python
       feed_generator = FeedGenerator(web_dir, rolling_window_days=7)
       ```

       To:
       ```python
       pipeline_config = config.get_pipeline_config()
       feed_generator = FeedGenerator(
           web_dir,
           rolling_window_days=7,
           base_url=pipeline_config.base_url
       )
       ```

    2. Ensure `config` is already available in scope (it should be from the initial config loading)

    This completes the wiring from YAML config -> PipelineConfig -> FeedGenerator.
  </action>
  <verify>
    grep "get_pipeline_config" run_pipeline.py returns result
    grep "base_url=pipeline_config" run_pipeline.py returns result
    Python syntax is valid (python3 -m py_compile run_pipeline.py)
  </verify>
  <done>FeedGenerator receives base_url from providers.yaml via PipelineConfig</done>
</task>

</tasks>

<verification>
After all tasks complete:

1. Validate Python syntax:
   ```bash
   python3 -m py_compile agents/config/schema.py
   python3 -m py_compile generators/feed_generator.py
   ```

2. Validate YAML:
   ```bash
   python3 -c "import yaml; yaml.safe_load(open('config/providers.yaml'))"
   ```

3. Verify no hardcoded URLs remain:
   ```bash
   grep -r "news.aatf.ai" generators/ && echo "FAIL" || echo "PASS"
   ```

4. Quick import test:
   ```bash
   python3 -c "from agents.config.schema import PipelineConfig; print('PipelineConfig imported')"
   ```
</verification>

<success_criteria>
- PipelineConfig model exists in schema with base_url and lookback_hours
- FeedGenerator accepts base_url parameter
- No hardcoded "news.aatf.ai" in feed generator
- providers.yaml has pipeline section with documented fields
- All Python files compile without errors
- YAML is valid
</success_criteria>

<output>
After completion, create `.planning/phases/05-documentation-cleanup/05-03-SUMMARY.md`
</output>
