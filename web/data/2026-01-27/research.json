{
  "category": "research",
  "date": "2026-01-27",
  "category_summary": "Today's research reveals critical vulnerabilities across the AI ecosystem, from scientific integrity to deployed systems. A [forensic audit](/?date=2026-01-27&category=research#item-06853cd665b6) quantifying **17% phantom citation rates** in AI-assisted survey papers exposes systematic epistemic decay in AI-augmented research workflows.\n\nSecurity and safety research dominates:\n- First formal [security analysis of **MCP**](/?date=2026-01-27&category=research#item-1a053f6e2fff) identifies fundamental vulnerabilities in capability attestation and tool poisoning\n- **MortalMATH** [benchmark shows](/?date=2026-01-27&category=research#item-9f820242e5b9) reasoning-optimized models exhibit dangerous tunnel vision, ignoring life-threatening emergencies embedded in math problems\n- **Physical Prompt Injection Attacks** [demonstrate black-box exploitation](/?date=2026-01-27&category=research#item-964a801cdcf8) of VLMs through malicious instructions in physical objects\n- **Hidden intentions taxonomy** [categorizes ten categories](/?date=2026-01-27&category=research#item-b7a9371615f9) of covert goal-directed behaviors in LLMs that evade current detection\n- Analysis of [**20,000 real mental health AI conversations**](/?date=2026-01-27&category=research#item-f8e79ae33540) reveals gaps between simulation-based safety testing and real-world performance\n\nArchitecture and efficiency advances include NVIDIA's **LatentMoE** [optimizing accuracy per FLOP](/?date=2026-01-27&category=research#item-a7099d08e107) through hardware-software co-design, and **AR-Omni** [achieving unified any-to-any](/?date=2026-01-27&category=research#item-9ba984802fd4) multimodal generation without expert decoders. Privacy research shows fine-tuned models [leak **input-only PII**](/?date=2026-01-27&category=research#item-457b819c1a26) through unexpected memorization channels.",
  "category_summary_html": "<p>Today's research reveals critical vulnerabilities across the AI ecosystem, from scientific integrity to deployed systems. A <a href=\"/?date=2026-01-27&amp;category=research#item-06853cd665b6\" class=\"internal-link\" rel=\"noopener noreferrer\">forensic audit</a> quantifying <strong>17% phantom citation rates</strong> in AI-assisted survey papers exposes systematic epistemic decay in AI-augmented research workflows.</p>\n<p>Security and safety research dominates:</p>\n<ul>\n<li>First formal <a href=\"/?date=2026-01-27&amp;category=research#item-1a053f6e2fff\" class=\"internal-link\" rel=\"noopener noreferrer\">security analysis of <strong>MCP</strong></a> identifies fundamental vulnerabilities in capability attestation and tool poisoning</li>\n<li><strong>MortalMATH</strong> <a href=\"/?date=2026-01-27&amp;category=research#item-9f820242e5b9\" class=\"internal-link\" rel=\"noopener noreferrer\">benchmark shows</a> reasoning-optimized models exhibit dangerous tunnel vision, ignoring life-threatening emergencies embedded in math problems</li>\n<li><strong>Physical Prompt Injection Attacks</strong> <a href=\"/?date=2026-01-27&amp;category=research#item-964a801cdcf8\" class=\"internal-link\" rel=\"noopener noreferrer\">demonstrate black-box exploitation</a> of VLMs through malicious instructions in physical objects</li>\n<li><strong>Hidden intentions taxonomy</strong> <a href=\"/?date=2026-01-27&amp;category=research#item-b7a9371615f9\" class=\"internal-link\" rel=\"noopener noreferrer\">categorizes ten categories</a> of covert goal-directed behaviors in LLMs that evade current detection</li>\n<li>Analysis of <a href=\"/?date=2026-01-27&amp;category=research#item-f8e79ae33540\" class=\"internal-link\" rel=\"noopener noreferrer\"><strong>20,000 real mental health AI conversations</strong></a> reveals gaps between simulation-based safety testing and real-world performance</li>\n</ul>\n<p>Architecture and efficiency advances include NVIDIA's <strong>LatentMoE</strong> <a href=\"/?date=2026-01-27&amp;category=research#item-a7099d08e107\" class=\"internal-link\" rel=\"noopener noreferrer\">optimizing accuracy per FLOP</a> through hardware-software co-design, and <strong>AR-Omni</strong> <a href=\"/?date=2026-01-27&amp;category=research#item-9ba984802fd4\" class=\"internal-link\" rel=\"noopener noreferrer\">achieving unified any-to-any</a> multimodal generation without expert decoders. Privacy research shows fine-tuned models <a href=\"/?date=2026-01-27&amp;category=research#item-457b819c1a26\" class=\"internal-link\" rel=\"noopener noreferrer\">leak <strong>input-only PII</strong></a> through unexpected memorization channels.</p>",
  "themes": [
    {
      "name": "AI Security & Privacy Attacks",
      "description": "Novel attacks on LLMs, VLMs, federated learning including prompt injection, membership inference, PII leakage, and protocol vulnerabilities",
      "item_count": 10,
      "example_items": [],
      "importance": 90
    },
    {
      "name": "AI Scientific Integrity",
      "description": "Meta-research on hallucinated citations and systematic degradation of scientific literature from AI assistance",
      "item_count": 2,
      "example_items": [],
      "importance": 88
    },
    {
      "name": "AI Safety & Alignment",
      "description": "Research on ensuring AI systems behave safely and as intended, including moral robustness, DPO dynamics, verifiable rewards, and process supervision",
      "item_count": 16,
      "example_items": [],
      "importance": 85
    },
    {
      "name": "Agentic Systems Architecture",
      "description": "Frameworks and protocols for reliable agent workflows including MCP analysis, parallel execution, and declarative layers",
      "item_count": 6,
      "example_items": [],
      "importance": 85
    },
    {
      "name": "AI Safety and Alignment",
      "description": "Research on value alignment, hidden intentions, sycophancy, and safety evaluation of LLMs in various deployment contexts",
      "item_count": 8,
      "example_items": [],
      "importance": 85
    },
    {
      "name": "AI Safety & Guardrails",
      "description": "Research on safety mechanisms for AI systems including agentic guardrails, vulnerability detection, execution control, and safety benchmarks for high-stakes domains",
      "item_count": 12,
      "example_items": [],
      "importance": 82
    },
    {
      "name": "Agentic AI Systems",
      "description": "Frameworks, architectures, and evaluations for autonomous AI agents including planning, tool use, self-improvement, and multi-agent coordination",
      "item_count": 22,
      "example_items": [],
      "importance": 78
    },
    {
      "name": "On-device & Efficient LLMs",
      "description": "Memory compression, adapter clustering, sparse attention, and inference optimization for resource-constrained deployment",
      "item_count": 8,
      "example_items": [],
      "importance": 78
    },
    {
      "name": "Reinforcement Learning for Hard Problems",
      "description": "Novel approaches to improve RL exploration and sample efficiency on difficult reasoning tasks where standard methods fail, including POPE, PrefixRL, and JitRL",
      "item_count": 8,
      "example_items": [],
      "importance": 78
    },
    {
      "name": "Reasoning and Interpretability",
      "description": "Studies of how LLMs represent and execute reasoning, including mechanistic analysis of reasoning structures and token-level signals",
      "item_count": 7,
      "example_items": [],
      "importance": 76
    }
  ],
  "total_items": 694,
  "items": [
    {
      "id": "06853cd665b6",
      "title": "The 17% Gap: Quantifying Epistemic Decay in AI-Assisted Survey Papers",
      "content": "arXiv:2601.17431v1 Announce Type: cross  Abstract: The adoption of Large Language Models (LLMs) in scientific writing promises efficiency but risks introducing informational entropy. While \"hallucinated papers\" are a known artifact, the systematic degradation of valid citation chains remains unquantified. We conducted a forensic audit of 50 recent survey papers in Artificial Intelligence (N=5,514 citations) published between September 2024 and January 2026. We utilized a hybrid verification pipeline combining DOI resolution, Crossref metadata analysis, Semantic Scholar queries, and fuzzy text matching to distinguish between formatting errors (\"Sloppiness\") and verifiable non-existence (\"Phantoms). We detect a persistent 17.0% Phantom Rate -- citations that cannot be resolved to any digital object despite aggressive forensic recovery. Diagnostic categorization reveals three distinct failure modes: pure hallucinations (5.1%), hallucinated identifiers with valid titles (16.4%), and parsing-induced matching failures (78.5%). Longitudinal analysis reveals a flat trend (+0.07 pp/month), suggesting that high-entropy citation practices have stabilized as an endemic feature of the field. The scientific citation graph in AI survey literature exhibits \"link rot\" at scale. This suggests a mechanism where AI tools act as \"lazy research assistants,\" retrieving correct titles but hallucinating metadata, thereby severing the digital chain of custody required for reproducible science.",
      "url": "http://arxiv.org/abs/2601.17431",
      "author": "H. Kemal \\.Ilter",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "A forensic audit of 50 AI survey papers (5,514 citations) reveals a consistent 17% 'phantom rate' - citations that cannot be resolved to any existing publication. This quantifies systematic epistemic degradation from AI-assisted scientific writing.",
      "importance_score": 92,
      "reasoning": "Critical meta-research quantifying AI's impact on scientific integrity. First rigorous measurement of hallucinated citations in real literature. High impact for science policy and AI governance.",
      "themes": [
        "AI Safety",
        "Scientific Integrity",
        "LLM Hallucination"
      ],
      "continuation": null,
      "summary_html": "<p>A forensic audit of 50 AI survey papers (5,514 citations) reveals a consistent 17% 'phantom rate' - citations that cannot be resolved to any existing publication. This quantifies systematic epistemic degradation from AI-assisted scientific writing.</p>",
      "content_html": "<p>arXiv:2601.17431v1 Announce Type: cross  Abstract: The adoption of Large Language Models (LLMs) in scientific writing promises efficiency but risks introducing informational entropy. While \"hallucinated papers\" are a known artifact, the systematic degradation of valid citation chains remains unquantified. We conducted a forensic audit of 50 recent survey papers in Artificial Intelligence (N=5,514 citations) published between September 2024 and January 2026. We utilized a hybrid verification pipeline combining DOI resolution, Crossref metadata analysis, Semantic Scholar queries, and fuzzy text matching to distinguish between formatting errors (\"Sloppiness\") and verifiable non-existence (\"Phantoms). We detect a persistent 17.0% Phantom Rate -- citations that cannot be resolved to any digital object despite aggressive forensic recovery. Diagnostic categorization reveals three distinct failure modes: pure hallucinations (5.1%), hallucinated identifiers with valid titles (16.4%), and parsing-induced matching failures (78.5%). Longitudinal analysis reveals a flat trend (+0.07 pp/month), suggesting that high-entropy citation practices have stabilized as an endemic feature of the field. The scientific citation graph in AI survey literature exhibits \"link rot\" at scale. This suggests a mechanism where AI tools act as \"lazy research assistants,\" retrieving correct titles but hallucinating metadata, thereby severing the digital chain of custody required for reproducible science.</p>"
    },
    {
      "id": "1a053f6e2fff",
      "title": "Breaking the Protocol: Security Analysis of the Model Context Protocol Specification and Prompt Injection Vulnerabilities in Tool-Integrated LLM Agents",
      "content": "arXiv:2601.17549v1 Announce Type: cross  Abstract: The Model Context Protocol (MCP) has emerged as a de facto standard for integrating Large Language Models with external tools, yet no formal security analysis of the protocol specification exists. We present the first rigorous security analysis of MCP's architectural design, identifying three fundamental protocol-level vulnerabilities: (1) absence of capability attestation allowing servers to claim arbitrary permissions, (2) bidirectional sampling without origin authentication enabling server-side prompt injection, and (3) implicit trust propagation in multi-server configurations. We implement \\textsc{MCPBench}, a novel framework bridging existing agent security benchmarks to MCP-compliant infrastructure, enabling direct measurement of protocol-specific attack surfaces. Through controlled experiments on 847 attack scenarios across five MCP server implementations, we demonstrate that MCP's architectural choices amplify attack success rates by 23--41\\% compared to equivalent non-MCP integrations. We propose \\textsc{MCPSec}, a backward-compatible protocol extension adding capability attestation and message authentication, reducing attack success rates from 52.8\\% to 12.4\\% with median latency overhead of 8.3ms per message. Our findings establish that MCP's security weaknesses are architectural rather than implementation-specific, requiring protocol-level remediation.",
      "url": "http://arxiv.org/abs/2601.17549",
      "author": "Narek Maloyan, Dmitry Namiot",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "First formal security analysis of the Model Context Protocol (MCP) specification, identifying three fundamental vulnerabilities: absent capability attestation, unauthenticated bidirectional sampling enabling prompt injection, and implicit trust propagation in multi-server setups.",
      "importance_score": 91,
      "reasoning": "MCP is becoming a de facto standard for LLM-tool integration. First rigorous security analysis with concrete vulnerabilities. MCPBench framework enables systematic testing. Critical for agentic systems safety.",
      "themes": [
        "AI Security",
        "Agentic Systems",
        "Prompt Injection",
        "MCP"
      ],
      "continuation": null,
      "summary_html": "<p>First formal security analysis of the Model Context Protocol (MCP) specification, identifying three fundamental vulnerabilities: absent capability attestation, unauthenticated bidirectional sampling enabling prompt injection, and implicit trust propagation in multi-server setups.</p>",
      "content_html": "<p>arXiv:2601.17549v1 Announce Type: cross  Abstract: The Model Context Protocol (MCP) has emerged as a de facto standard for integrating Large Language Models with external tools, yet no formal security analysis of the protocol specification exists. We present the first rigorous security analysis of MCP's architectural design, identifying three fundamental protocol-level vulnerabilities: (1) absence of capability attestation allowing servers to claim arbitrary permissions, (2) bidirectional sampling without origin authentication enabling server-side prompt injection, and (3) implicit trust propagation in multi-server configurations. We implement \\textsc{MCPBench}, a novel framework bridging existing agent security benchmarks to MCP-compliant infrastructure, enabling direct measurement of protocol-specific attack surfaces. Through controlled experiments on 847 attack scenarios across five MCP server implementations, we demonstrate that MCP's architectural choices amplify attack success rates by 23--41\\% compared to equivalent non-MCP integrations. We propose \\textsc{MCPSec}, a backward-compatible protocol extension adding capability attestation and message authentication, reducing attack success rates from 52.8\\% to 12.4\\% with median latency overhead of 8.3ms per message. Our findings establish that MCP's security weaknesses are architectural rather than implementation-specific, requiring protocol-level remediation.</p>"
    },
    {
      "id": "964a801cdcf8",
      "title": "Physical Prompt Injection Attacks on Large Vision-Language Models",
      "content": "arXiv:2601.17383v1 Announce Type: cross  Abstract: Large Vision-Language Models (LVLMs) are increasingly deployed in real-world intelligent systems for perception and reasoning in open physical environments. While LVLMs are known to be vulnerable to prompt injection attacks, existing methods either require access to input channels or depend on knowledge of user queries, assumptions that rarely hold in practical deployments. We propose the first Physical Prompt Injection Attack (PPIA), a black-box, query-agnostic attack that embeds malicious typographic instructions into physical objects perceivable by the LVLM. PPIA requires no access to the model, its inputs, or internal pipeline, and operates solely through visual observation. It combines offline selection of highly recognizable and semantically effective visual prompts with strategic environment-aware placement guided by spatiotemporal attention, ensuring that the injected prompts are both perceivable and influential on model behavior. We evaluate PPIA across 10 state-of-the-art LVLMs in both simulated and real-world settings on tasks including visual question answering, planning, and navigation, PPIA achieves attack success rates up to 98%, with strong robustness under varying physical conditions such as distance, viewpoint, and illumination. Our code is publicly available at https://github.com/2023cghacker/Physical-Prompt-Injection-Attack.",
      "url": "http://arxiv.org/abs/2601.17383",
      "author": "Chen Ling, Kai Hu, Hangcheng Liu, Xingshuo Han, Tianwei Zhang, Changhai Ou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces PPIA, the first physical prompt injection attack on vision-language models that embeds malicious instructions into physical objects. The attack is black-box, query-agnostic, and operates solely through visual observation without model access.",
      "importance_score": 88,
      "reasoning": "Novel attack vector for deployed VLMs in physical environments. Black-box and query-agnostic makes it practically threatening. Important for robotics and real-world AI systems security.",
      "themes": [
        "AI Security",
        "Vision-Language Models",
        "Adversarial Attacks",
        "Prompt Injection"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces PPIA, the first physical prompt injection attack on vision-language models that embeds malicious instructions into physical objects. The attack is black-box, query-agnostic, and operates solely through visual observation without model access.</p>",
      "content_html": "<p>arXiv:2601.17383v1 Announce Type: cross  Abstract: Large Vision-Language Models (LVLMs) are increasingly deployed in real-world intelligent systems for perception and reasoning in open physical environments. While LVLMs are known to be vulnerable to prompt injection attacks, existing methods either require access to input channels or depend on knowledge of user queries, assumptions that rarely hold in practical deployments. We propose the first Physical Prompt Injection Attack (PPIA), a black-box, query-agnostic attack that embeds malicious typographic instructions into physical objects perceivable by the LVLM. PPIA requires no access to the model, its inputs, or internal pipeline, and operates solely through visual observation. It combines offline selection of highly recognizable and semantically effective visual prompts with strategic environment-aware placement guided by spatiotemporal attention, ensuring that the injected prompts are both perceivable and influential on model behavior. We evaluate PPIA across 10 state-of-the-art LVLMs in both simulated and real-world settings on tasks including visual question answering, planning, and navigation, PPIA achieves attack success rates up to 98%, with strong robustness under varying physical conditions such as distance, viewpoint, and illumination. Our code is publicly available at https://github.com/2023cghacker/Physical-Prompt-Injection-Attack.</p>"
    },
    {
      "id": "9f820242e5b9",
      "title": "MortalMATH: Evaluating the Conflict Between Reasoning Objectives and Emergency Contexts",
      "content": "arXiv:2601.18790v1 Announce Type: new  Abstract: Large Language Models are increasingly optimized for deep reasoning, prioritizing the correct execution of complex tasks over general conversation. We investigate whether this focus on calculation creates a \"tunnel vision\" that ignores safety in critical situations. We introduce MortalMATH, a benchmark of 150 scenarios where users request algebra help while describing increasingly life-threatening emergencies (e.g., stroke symptoms, freefall). We find a sharp behavioral split: generalist models (like Llama-3.1) successfully refuse the math to address the danger. In contrast, specialized reasoning models (like Qwen-3-32b and GPT-5-nano) often ignore the emergency entirely, maintaining over 95 percent task completion rates while the user describes dying. Furthermore, the computational time required for reasoning introduces dangerous delays: up to 15 seconds before any potential help is offered. These results suggest that training models to relentlessly pursue correct answers may inadvertently unlearn the survival instincts required for safe deployment.",
      "url": "http://arxiv.org/abs/2601.18790",
      "author": "Etienne Lanzeray, Stephane Meilliez, Malo Ruelle, Damien Sileo",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces MortalMATH benchmark revealing that reasoning-optimized LLMs exhibit 'tunnel vision' - ignoring life-threatening emergencies (stroke symptoms, freefall) while maintaining 95%+ task completion on math problems. Generalist models like Llama-3.1 appropriately refuse tasks to address danger.",
      "importance_score": 88,
      "reasoning": "Critical safety finding showing specialized reasoning models have dangerous blind spots. High-impact benchmark revealing fundamental tension between task optimization and safety awareness.",
      "themes": [
        "AI Safety",
        "Benchmarks",
        "Reasoning",
        "Alignment"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces MortalMATH benchmark revealing that reasoning-optimized LLMs exhibit 'tunnel vision' - ignoring life-threatening emergencies (stroke symptoms, freefall) while maintaining 95%+ task completion on math problems. Generalist models like Llama-3.1 appropriately refuse tasks to address danger.</p>",
      "content_html": "<p>arXiv:2601.18790v1 Announce Type: new  Abstract: Large Language Models are increasingly optimized for deep reasoning, prioritizing the correct execution of complex tasks over general conversation. We investigate whether this focus on calculation creates a \"tunnel vision\" that ignores safety in critical situations. We introduce MortalMATH, a benchmark of 150 scenarios where users request algebra help while describing increasingly life-threatening emergencies (e.g., stroke symptoms, freefall). We find a sharp behavioral split: generalist models (like Llama-3.1) successfully refuse the math to address the danger. In contrast, specialized reasoning models (like Qwen-3-32b and GPT-5-nano) often ignore the emergency entirely, maintaining over 95 percent task completion rates while the user describes dying. Furthermore, the computational time required for reasoning introduces dangerous delays: up to 15 seconds before any potential help is offered. These results suggest that training models to relentlessly pursue correct answers may inadvertently unlearn the survival instincts required for safe deployment.</p>"
    },
    {
      "id": "457b819c1a26",
      "title": "Unintended Memorization of Sensitive Information in Fine-Tuned Language Models",
      "content": "arXiv:2601.17480v1 Announce Type: cross  Abstract: Fine-tuning Large Language Models (LLMs) on sensitive datasets carries a substantial risk of unintended memorization and leakage of Personally Identifiable Information (PII), which can violate privacy regulations and compromise individual safety. In this work, we systematically investigate a critical and underexplored vulnerability: the exposure of PII that appears only in model inputs, not in training targets. Using both synthetic and real-world datasets, we design controlled extraction probes to quantify unintended PII memorization and study how factors such as language, PII frequency, task type, and model size influence memorization behavior. We further benchmark four privacy-preserving approaches including differential privacy, machine unlearning, regularization, and preference alignment, evaluating their trade-offs between privacy and task performance. Our results show that post-training methods generally provide more consistent privacy-utility trade-offs, while differential privacy achieves strong reduction in leakage in specific settings, although it can introduce training instability. These findings highlight the persistent challenge of memorization in fine-tuned LLMs and emphasize the need for robust, scalable privacy-preserving techniques.",
      "url": "http://arxiv.org/abs/2601.17480",
      "author": "Marton Szep, Jorge Marin Ruiz, Georgios Kaissis, Paulina Seidl, R\\\"udiger von Eisenhart-Rothe, Florian Hinterwimmer, Daniel Rueckert",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Systematically investigates PII leakage from fine-tuned LLMs, finding that sensitive information appearing only in model inputs (not training targets) can still be extracted. Benchmarks four privacy-preserving approaches including differential privacy.",
      "importance_score": 86,
      "reasoning": "Critical privacy research showing unexpected leakage channel. Input-only PII exposure is underexplored. Practical implications for any organization fine-tuning LLMs on sensitive data.",
      "themes": [
        "AI Privacy",
        "Language Models",
        "Data Security",
        "Fine-tuning"
      ],
      "continuation": null,
      "summary_html": "<p>Systematically investigates PII leakage from fine-tuned LLMs, finding that sensitive information appearing only in model inputs (not training targets) can still be extracted. Benchmarks four privacy-preserving approaches including differential privacy.</p>",
      "content_html": "<p>arXiv:2601.17480v1 Announce Type: cross  Abstract: Fine-tuning Large Language Models (LLMs) on sensitive datasets carries a substantial risk of unintended memorization and leakage of Personally Identifiable Information (PII), which can violate privacy regulations and compromise individual safety. In this work, we systematically investigate a critical and underexplored vulnerability: the exposure of PII that appears only in model inputs, not in training targets. Using both synthetic and real-world datasets, we design controlled extraction probes to quantify unintended PII memorization and study how factors such as language, PII frequency, task type, and model size influence memorization behavior. We further benchmark four privacy-preserving approaches including differential privacy, machine unlearning, regularization, and preference alignment, evaluating their trade-offs between privacy and task performance. Our results show that post-training methods generally provide more consistent privacy-utility trade-offs, while differential privacy achieves strong reduction in leakage in specific settings, although it can introduce training instability. These findings highlight the persistent challenge of memorization in fine-tuned LLMs and emphasize the need for robust, scalable privacy-preserving techniques.</p>"
    },
    {
      "id": "7465509b2391",
      "title": "Reconstructing Training Data from Adapter-based Federated Large Language Models",
      "content": "arXiv:2601.17533v1 Announce Type: cross  Abstract: Adapter-based Federated Large Language Models (FedLLMs) are widely adopted to reduce the computational, storage, and communication overhead of full-parameter fine-tuning for web-scale applications while preserving user privacy. By freezing the backbone and training only compact low-rank adapters, these methods appear to limit gradient leakage and thwart existing Gradient Inversion Attacks (GIAs).   Contrary to this assumption, we show that low-rank adapters create new, exploitable leakage channels. We propose the Unordered-word-bag-based Text Reconstruction (UTR) attack, a novel GIA tailored to the unique structure of adapter-based FedLLMs. UTR overcomes three core challenges: low-dimensional gradients, frozen backbones, and combinatorially large reconstruction spaces by: (i) inferring token presence from attention patterns in frozen layers, (ii) performing sentence-level inversion within the low-rank subspace of adapter gradients, and (iii) enforcing semantic coherence through constrained greedy decoding guided by language priors. Extensive experiments across diverse models (GPT2-Large, BERT, Qwen2.5-7B) and datasets (CoLA, SST-2, Rotten Tomatoes) demonstrate that UTR achieves near-perfect reconstruction accuracy (ROUGE-1/2 > 99), even with large batch size settings where prior GIAs fail completely. Our results reveal a fundamental tension between parameter efficiency and privacy in FedLLMs, challenging the prevailing belief that lightweight adaptation inherently enhances security. Our code and data are available at https://github.com/shwksnshwowk-wq/GIA.",
      "url": "http://arxiv.org/abs/2601.17533",
      "author": "Silong Chen, Yuchuan Luo, Guilin Deng, Yi Liu, Min Xu, Shaojing Fu, Xiaohua Jia",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Demonstrates that adapter-based federated LLMs (using LoRA) create new exploitable leakage channels contrary to assumptions. Proposes UTR attack that reconstructs training data from low-rank adapter gradients.",
      "importance_score": 85,
      "reasoning": "Challenges safety assumptions about adapter-based FedLLMs. Shows LoRA creates new vulnerabilities rather than limiting them. Important for federated learning practitioners.",
      "themes": [
        "Federated Learning",
        "AI Security",
        "Privacy Attacks",
        "LoRA"
      ],
      "continuation": null,
      "summary_html": "<p>Demonstrates that adapter-based federated LLMs (using LoRA) create new exploitable leakage channels contrary to assumptions. Proposes UTR attack that reconstructs training data from low-rank adapter gradients.</p>",
      "content_html": "<p>arXiv:2601.17533v1 Announce Type: cross  Abstract: Adapter-based Federated Large Language Models (FedLLMs) are widely adopted to reduce the computational, storage, and communication overhead of full-parameter fine-tuning for web-scale applications while preserving user privacy. By freezing the backbone and training only compact low-rank adapters, these methods appear to limit gradient leakage and thwart existing Gradient Inversion Attacks (GIAs).   Contrary to this assumption, we show that low-rank adapters create new, exploitable leakage channels. We propose the Unordered-word-bag-based Text Reconstruction (UTR) attack, a novel GIA tailored to the unique structure of adapter-based FedLLMs. UTR overcomes three core challenges: low-dimensional gradients, frozen backbones, and combinatorially large reconstruction spaces by: (i) inferring token presence from attention patterns in frozen layers, (ii) performing sentence-level inversion within the low-rank subspace of adapter gradients, and (iii) enforcing semantic coherence through constrained greedy decoding guided by language priors. Extensive experiments across diverse models (GPT2-Large, BERT, Qwen2.5-7B) and datasets (CoLA, SST-2, Rotten Tomatoes) demonstrate that UTR achieves near-perfect reconstruction accuracy (ROUGE-1/2 &gt; 99), even with large batch size settings where prior GIAs fail completely. Our results reveal a fundamental tension between parameter efficiency and privacy in FedLLMs, challenging the prevailing belief that lightweight adaptation inherently enhances security. Our code and data are available at https://github.com/shwksnshwowk-wq/GIA.</p>"
    },
    {
      "id": "5346d9dbcb7f",
      "title": "The Shadow Self: Intrinsic Value Misalignment in Large Language Model Agents",
      "content": "arXiv:2601.17344v1 Announce Type: new  Abstract: Large language model (LLM) agents with extended autonomy unlock new capabilities, but also introduce heightened challenges for LLM safety. In particular, an LLM agent may pursue objectives that deviate from human values and ethical norms, a risk known as value misalignment. Existing evaluations primarily focus on responses to explicit harmful input or robustness against system failure, while value misalignment in realistic, fully benign, and agentic settings remains largely underexplored. To fill this gap, we first formalize the Loss-of-Control risk and identify the previously underexamined Intrinsic Value Misalignment (Intrinsic VM). We then introduce IMPRESS (Intrinsic Value Misalignment Probes in REalistic Scenario Set), a scenario-driven framework for systematically assessing this risk. Following our framework, we construct benchmarks composed of realistic, fully benign, and contextualized scenarios, using a multi-stage LLM generation pipeline with rigorous quality control. We evaluate Intrinsic VM on 21 state-of-the-art LLM agents and find that it is a common and broadly observed safety risk across models. Moreover, the misalignment rates vary by motives, risk types, model scales, and architectures. While decoding strategies and hyperparameters exhibit only marginal influence, contextualization and framing mechanisms significantly shape misalignment behaviors. Finally, we conduct human verification to validate our automated judgments and assess existing mitigation strategies, such as safety prompting and guardrails, which show instability or limited effectiveness. We further demonstrate key use cases of IMPRESS across the AI Ecosystem. Our code and benchmark will be publicly released upon acceptance.",
      "url": "http://arxiv.org/abs/2601.17344",
      "author": "Chen Chen, Kim Young Il, Yuan Yang, Wenhao Su, Yilin Zhang, Xueluan Gong, Qian Wang, Yongsen Zheng, Ziyao Liu, Kwok-Yan Lam",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Formalizes Loss-of-Control risk and Intrinsic Value Misalignment in LLM agents operating in benign settings. Introduces IMPRESS benchmark for probing value misalignment in realistic scenarios without explicit harmful inputs.",
      "importance_score": 85,
      "reasoning": "Critical AI safety contribution identifying under-examined risks in autonomous LLM agents. Novel formalization of intrinsic value misalignment distinct from robustness to harmful inputs.",
      "themes": [
        "AI Safety",
        "Alignment",
        "LLM Agents",
        "Value Alignment"
      ],
      "continuation": null,
      "summary_html": "<p>Formalizes Loss-of-Control risk and Intrinsic Value Misalignment in LLM agents operating in benign settings. Introduces IMPRESS benchmark for probing value misalignment in realistic scenarios without explicit harmful inputs.</p>",
      "content_html": "<p>arXiv:2601.17344v1 Announce Type: new  Abstract: Large language model (LLM) agents with extended autonomy unlock new capabilities, but also introduce heightened challenges for LLM safety. In particular, an LLM agent may pursue objectives that deviate from human values and ethical norms, a risk known as value misalignment. Existing evaluations primarily focus on responses to explicit harmful input or robustness against system failure, while value misalignment in realistic, fully benign, and agentic settings remains largely underexplored. To fill this gap, we first formalize the Loss-of-Control risk and identify the previously underexamined Intrinsic Value Misalignment (Intrinsic VM). We then introduce IMPRESS (Intrinsic Value Misalignment Probes in REalistic Scenario Set), a scenario-driven framework for systematically assessing this risk. Following our framework, we construct benchmarks composed of realistic, fully benign, and contextualized scenarios, using a multi-stage LLM generation pipeline with rigorous quality control. We evaluate Intrinsic VM on 21 state-of-the-art LLM agents and find that it is a common and broadly observed safety risk across models. Moreover, the misalignment rates vary by motives, risk types, model scales, and architectures. While decoding strategies and hyperparameters exhibit only marginal influence, contextualization and framing mechanisms significantly shape misalignment behaviors. Finally, we conduct human verification to validate our automated judgments and assess existing mitigation strategies, such as safety prompting and guardrails, which show instability or limited effectiveness. We further demonstrate key use cases of IMPRESS across the AI Ecosystem. Our code and benchmark will be publicly released upon acceptance.</p>"
    },
    {
      "id": "9ba984802fd4",
      "title": "AR-Omni: A Unified Autoregressive Model for Any-to-Any Generation",
      "content": "arXiv:2601.17761v1 Announce Type: cross  Abstract: Real-world perception and interaction are inherently multimodal, encompassing not only language but also vision and speech, which motivates the development of \"Omni\" MLLMs that support both multimodal inputs and multimodal outputs. While a sequence of omni MLLMs has emerged, most existing systems still rely on additional expert components to achieve multimodal generation, limiting the simplicity of unified training and inference. Autoregressive (AR) modeling, with a single token stream, a single next-token objective, and a single decoder, is an elegant and scalable foundation in the text domain. Motivated by this, we present AR-Omni, a unified any-to-any model in the autoregressive paradigm without any expert decoders. AR-Omni supports autoregressive text and image generation, as well as streaming speech generation, all under a single Transformer decoder. We further address three practical issues in unified AR modeling: modality imbalance via task-aware loss reweighting, visual fidelity via a lightweight token-level perceptual alignment loss for image tokens, and stability-creativity trade-offs via a finite-state decoding mechanism. Empirically, AR-Omni achieves strong quality across three modalities while remaining real-time, achieving a 0.88 real-time factor for speech generation.",
      "url": "http://arxiv.org/abs/2601.17761",
      "author": "Dongjie Cheng, Ruifeng Yuan, Yongqi Li, Runyang You, Wenjie Wang, Liqiang Nie, Lei Zhang, Wenjie Li",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "AR-Omni presents a unified autoregressive model for any-to-any multimodal generation (text, vision, speech) without requiring expert decoder modules, using a single token stream and next-token objective.",
      "importance_score": 84,
      "reasoning": "Elegant unified architecture for omni-modal generation. Removing expert decoders simplifies training and inference. Represents progress toward truly unified multimodal models.",
      "themes": [
        "Multimodal Models",
        "Autoregressive Models",
        "Unified Architecture"
      ],
      "continuation": null,
      "summary_html": "<p>AR-Omni presents a unified autoregressive model for any-to-any multimodal generation (text, vision, speech) without requiring expert decoder modules, using a single token stream and next-token objective.</p>",
      "content_html": "<p>arXiv:2601.17761v1 Announce Type: cross  Abstract: Real-world perception and interaction are inherently multimodal, encompassing not only language but also vision and speech, which motivates the development of \"Omni\" MLLMs that support both multimodal inputs and multimodal outputs. While a sequence of omni MLLMs has emerged, most existing systems still rely on additional expert components to achieve multimodal generation, limiting the simplicity of unified training and inference. Autoregressive (AR) modeling, with a single token stream, a single next-token objective, and a single decoder, is an elegant and scalable foundation in the text domain. Motivated by this, we present AR-Omni, a unified any-to-any model in the autoregressive paradigm without any expert decoders. AR-Omni supports autoregressive text and image generation, as well as streaming speech generation, all under a single Transformer decoder. We further address three practical issues in unified AR modeling: modality imbalance via task-aware loss reweighting, visual fidelity via a lightweight token-level perceptual alignment loss for image tokens, and stability-creativity trade-offs via a finite-state decoding mechanism. Empirically, AR-Omni achieves strong quality across three modalities while remaining real-time, achieving a 0.88 real-time factor for speech generation.</p>"
    },
    {
      "id": "e2eb514146a7",
      "title": "Self-Manager: Parallel Agent Loop for Long-form Deep Research",
      "content": "arXiv:2601.17879v1 Announce Type: cross  Abstract: Long-form deep research requires multi-faceted investigations over extended horizons to get a comprehensive report. When handling such complex tasks, existing agents manage context at the subtask level to overcome linear context accumulation and information loss. However, they still adhere to a single context window and sequential execution paradigm, which results in mutual interference and blocking behavior, restricting scalability and adaptability. To address this issue, this paper introduces Self-Manager, a parallel agent loop that enables asynchronous and concurrent execution. The main thread can create multiple subthreads, each with its own isolated context, and manage them iteratively through Thread Control Blocks, allowing for more focused and flexible parallel agent execution. To assess its effectiveness, we benchmark Self-Manager on DeepResearch Bench, where it consistently outperforms existing single-agent loop baselines across all metrics. Furthermore, we conduct extensive analytical experiments to demonstrate the necessity of Self-Manager's design choices, as well as its advantages in contextual capacity, efficiency, and generalization.",
      "url": "http://arxiv.org/abs/2601.17879",
      "author": "Yilong Xu, Zhi Zheng, Xiang Long, Yujun Cai, Yiwei Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Self-Manager introduces a parallel agent loop for complex research tasks, enabling asynchronous concurrent execution with isolated context windows per subthread, managed via Thread Control Blocks.",
      "importance_score": 83,
      "reasoning": "Addresses key limitations in agentic systems: sequential execution and context interference. Parallel isolated execution is important architectural direction for complex agent tasks.",
      "themes": [
        "Agentic Systems",
        "Agent Architecture",
        "Parallel Computing"
      ],
      "continuation": null,
      "summary_html": "<p>Self-Manager introduces a parallel agent loop for complex research tasks, enabling asynchronous concurrent execution with isolated context windows per subthread, managed via Thread Control Blocks.</p>",
      "content_html": "<p>arXiv:2601.17879v1 Announce Type: cross  Abstract: Long-form deep research requires multi-faceted investigations over extended horizons to get a comprehensive report. When handling such complex tasks, existing agents manage context at the subtask level to overcome linear context accumulation and information loss. However, they still adhere to a single context window and sequential execution paradigm, which results in mutual interference and blocking behavior, restricting scalability and adaptability. To address this issue, this paper introduces Self-Manager, a parallel agent loop that enables asynchronous and concurrent execution. The main thread can create multiple subthreads, each with its own isolated context, and manage them iteratively through Thread Control Blocks, allowing for more focused and flexible parallel agent execution. To assess its effectiveness, we benchmark Self-Manager on DeepResearch Bench, where it consistently outperforms existing single-agent loop baselines across all metrics. Furthermore, we conduct extensive analytical experiments to demonstrate the necessity of Self-Manager's design choices, as well as its advantages in contextual capacity, efficiency, and generalization.</p>"
    },
    {
      "id": "682f7ea37f2a",
      "title": "A Monosemantic Attribution Framework for Stable Interpretability in Clinical Neuroscience Large Language Models",
      "content": "arXiv:2601.17952v1 Announce Type: cross  Abstract: Interpretability remains a key challenge for deploying large language models (LLMs) in clinical settings such as Alzheimer's disease progression diagnosis, where early and trustworthy predictions are essential. Existing attribution methods exhibit high inter-method variability and unstable explanations due to the polysemantic nature of LLM representations, while mechanistic interpretability approaches lack direct alignment with model inputs and outputs and do not provide explicit importance scores. We introduce a unified interpretability framework that integrates attributional and mechanistic perspectives through monosemantic feature extraction. By constructing a monosemantic embedding space at the level of an LLM layer and optimizing the framework to explicitly reduce inter-method variability, our approach produces stable input-level importance scores and highlights salient features via a decompressed representation of the layer of interest, advancing the safe and trustworthy application of LLMs in cognitive health and neurodegenerative disease.",
      "url": "http://arxiv.org/abs/2601.17952",
      "author": "Michail Mamalakis, Tiago Azevedo, Cristian Cosentino, Chiara D'Ercoli, Subati Abulikemu, Zhongtian Sun, Richard Bethlehem, Pietro Lio",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes a unified interpretability framework for clinical LLMs combining attribution and mechanistic interpretability through monosemantic feature extraction. Addresses instability in existing attribution methods.",
      "importance_score": 82,
      "reasoning": "Novel integration of attribution and mechanistic interpretability. Clinical applications demand reliable interpretability. Monosemantic approach addresses polysemanticity problem.",
      "themes": [
        "Interpretability",
        "Clinical AI",
        "Mechanistic Interpretability",
        "LLM Safety"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes a unified interpretability framework for clinical LLMs combining attribution and mechanistic interpretability through monosemantic feature extraction. Addresses instability in existing attribution methods.</p>",
      "content_html": "<p>arXiv:2601.17952v1 Announce Type: cross  Abstract: Interpretability remains a key challenge for deploying large language models (LLMs) in clinical settings such as Alzheimer's disease progression diagnosis, where early and trustworthy predictions are essential. Existing attribution methods exhibit high inter-method variability and unstable explanations due to the polysemantic nature of LLM representations, while mechanistic interpretability approaches lack direct alignment with model inputs and outputs and do not provide explicit importance scores. We introduce a unified interpretability framework that integrates attributional and mechanistic perspectives through monosemantic feature extraction. By constructing a monosemantic embedding space at the level of an LLM layer and optimizing the framework to explicitly reduce inter-method variability, our approach produces stable input-level importance scores and highlights salient features via a decompressed representation of the layer of interest, advancing the safe and trustworthy application of LLMs in cognitive health and neurodegenerative disease.</p>"
    },
    {
      "id": "a7099d08e107",
      "title": "LatentMoE: Toward Optimal Accuracy per FLOP and Parameter in Mixture of Experts",
      "content": "arXiv:2601.18089v1 Announce Type: cross  Abstract: Mixture of Experts (MoEs) have become a central component of many state-of-the-art open-source and proprietary large language models. Despite their widespread adoption, it remains unclear how close existing MoE architectures are to optimal with respect to inference cost, as measured by accuracy per floating-point operation and per parameter. In this work, we revisit MoE design from a hardware-software co-design perspective, grounded in empirical and theoretical considerations. We characterize key performance bottlenecks across diverse deployment regimes, spanning offline high-throughput execution and online, latency-critical inference. Guided by these insights, we introduce LatentMoE, a new model architecture resulting from systematic design exploration and optimized for maximal accuracy per unit of compute. Empirical design space exploration at scales of up to 95B parameters and over a 1T-token training horizon, together with supporting theoretical analysis, shows that LatentMoE consistently outperforms standard MoE architectures in terms of accuracy per FLOP and per parameter. Given its strong performance, the LatentMoE architecture has been adopted by the flagship Nemotron-3 Super and Ultra models and scaled to substantially larger regimes, including longer token horizons and larger model sizes, as reported in Nvidia et al. (arXiv:2512.20856).",
      "url": "http://arxiv.org/abs/2601.18089",
      "author": "Venmugil Elango, Nidhi Bhatia, Roger Waleffe, Rasoul Shafipour, Tomer Asida, Abhinav Khattar, Nave Assaf, Maximilian Golub, Joey Guman, Tiyasa Mitra, Ritchie Zhao, Ritika Borkar, Ran Zilberstein, Mostofa Patwary, Mohammad Shoeybi, Bita Rouhani",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "NVIDIA researchers revisit Mixture of Experts design from hardware-software co-design perspective, introducing LatentMoE to optimize accuracy per FLOP and parameter. Characterizes performance bottlenecks across offline and online inference regimes.",
      "importance_score": 82,
      "reasoning": "Major contribution from NVIDIA on MoE efficiency - critical for LLM deployment. Hardware-software co-design approach addresses real deployment bottlenecks. Strong team including Mostofa Patwary and Mohammad Shoeybi.",
      "themes": [
        "Mixture of Experts",
        "Model Efficiency",
        "Hardware-Software Co-design",
        "Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>NVIDIA researchers revisit Mixture of Experts design from hardware-software co-design perspective, introducing LatentMoE to optimize accuracy per FLOP and parameter. Characterizes performance bottlenecks across offline and online inference regimes.</p>",
      "content_html": "<p>arXiv:2601.18089v1 Announce Type: cross  Abstract: Mixture of Experts (MoEs) have become a central component of many state-of-the-art open-source and proprietary large language models. Despite their widespread adoption, it remains unclear how close existing MoE architectures are to optimal with respect to inference cost, as measured by accuracy per floating-point operation and per parameter. In this work, we revisit MoE design from a hardware-software co-design perspective, grounded in empirical and theoretical considerations. We characterize key performance bottlenecks across diverse deployment regimes, spanning offline high-throughput execution and online, latency-critical inference. Guided by these insights, we introduce LatentMoE, a new model architecture resulting from systematic design exploration and optimized for maximal accuracy per unit of compute. Empirical design space exploration at scales of up to 95B parameters and over a 1T-token training horizon, together with supporting theoretical analysis, shows that LatentMoE consistently outperforms standard MoE architectures in terms of accuracy per FLOP and per parameter. Given its strong performance, the LatentMoE architecture has been adopted by the flagship Nemotron-3 Super and Ultra models and scaled to substantially larger regimes, including longer token horizons and larger model sizes, as reported in Nvidia et al. (arXiv:2512.20856).</p>"
    },
    {
      "id": "b7a9371615f9",
      "title": "Unknown Unknowns: Why Hidden Intentions in LLMs Evade Detection",
      "content": "arXiv:2601.18552v1 Announce Type: new  Abstract: LLMs are increasingly embedded in everyday decision-making, yet their outputs can encode subtle, unintended behaviours that shape user beliefs and actions. We refer to these covert, goal-directed behaviours as hidden intentions, which may arise from training and optimisation artefacts, or be deliberately induced by an adversarial developer, yet remain difficult to detect in practice. We introduce a taxonomy of ten categories of hidden intentions, grounded in social science research and organised by intent, mechanism, context, and impact, shifting attention from surface-level behaviours to design-level strategies of influence. We show how hidden intentions can be easily induced in controlled models, providing both testbeds for evaluation and demonstrations of potential misuse. We systematically assess detection methods, including reasoning and non-reasoning LLM judges, and find that detection collapses in realistic open-world settings, particularly under low-prevalence conditions, where false positives overwhelm precision and false negatives conceal true risks. Stress tests on precision-prevalence and precision-FNR trade-offs reveal why auditing fails without vanishingly small false positive rates or strong priors on manipulation types. Finally, a qualitative case study shows that all ten categories manifest in deployed, state-of-the-art LLMs, emphasising the urgent need for robust frameworks. Our work provides the first systematic analysis of detectability failures of hidden intentions in LLMs under open-world settings, offering a foundation for understanding, inducing, and stress-testing such behaviours, and establishing a flexible taxonomy for anticipating evolving threats and informing governance.",
      "url": "http://arxiv.org/abs/2601.18552",
      "author": "Devansh Srivastav, David Pape, Lea Sch\\\"onherr",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces taxonomy of ten categories of hidden intentions in LLMs (goal-directed covert behaviors arising from training or adversarial manipulation). Shows these can be easily induced but evade detection.",
      "importance_score": 82,
      "reasoning": "Critical AI safety work identifying underexplored risk category. Comprehensive taxonomy grounded in social science with demonstrated detection difficulty.",
      "themes": [
        "AI Safety",
        "Hidden Behaviors",
        "LLM Security",
        "Alignment"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces taxonomy of ten categories of hidden intentions in LLMs (goal-directed covert behaviors arising from training or adversarial manipulation). Shows these can be easily induced but evade detection.</p>",
      "content_html": "<p>arXiv:2601.18552v1 Announce Type: new  Abstract: LLMs are increasingly embedded in everyday decision-making, yet their outputs can encode subtle, unintended behaviours that shape user beliefs and actions. We refer to these covert, goal-directed behaviours as hidden intentions, which may arise from training and optimisation artefacts, or be deliberately induced by an adversarial developer, yet remain difficult to detect in practice. We introduce a taxonomy of ten categories of hidden intentions, grounded in social science research and organised by intent, mechanism, context, and impact, shifting attention from surface-level behaviours to design-level strategies of influence. We show how hidden intentions can be easily induced in controlled models, providing both testbeds for evaluation and demonstrations of potential misuse. We systematically assess detection methods, including reasoning and non-reasoning LLM judges, and find that detection collapses in realistic open-world settings, particularly under low-prevalence conditions, where false positives overwhelm precision and false negatives conceal true risks. Stress tests on precision-prevalence and precision-FNR trade-offs reveal why auditing fails without vanishingly small false positive rates or strong priors on manipulation types. Finally, a qualitative case study shows that all ten categories manifest in deployed, state-of-the-art LLMs, emphasising the urgent need for robust frameworks. Our work provides the first systematic analysis of detectability failures of hidden intentions in LLMs under open-world settings, offering a foundation for understanding, inducing, and stress-testing such behaviours, and establishing a flexible taxonomy for anticipating evolving threats and informing governance.</p>"
    },
    {
      "id": "f8e79ae33540",
      "title": "Beyond Simulations: What 20,000 Real Conversations Reveal About Mental Health AI Safety",
      "content": "arXiv:2601.17003v1 Announce Type: cross  Abstract: Large language models (LLMs) are increasingly used for mental health support, yet existing safety evaluations rely primarily on small, simulation-based test sets that have an unknown relationship to the linguistic distribution of real usage. In this study, we present replications of four published safety test sets targeting suicide risk assessment, harmful content generation, refusal robustness, and adversarial jailbreaks for a leading frontier generic AI model alongside an AI purpose built for mental health support. We then propose and conduct an ecological audit on over 20,000 real-world user conversations with the purpose-built AI designed with layered suicide and non-suicidal self-injury (NSSI) safeguards to compare test set performance to real world performance. While the purpose-built AI was significantly less likely than general-purpose LLMs to produce enabling or harmful content across suicide/NSSI (.4-11.27% vs 29.0-54.4%), eating disorder (8.4% vs 54.0%), and substance use (9.9% vs 45.0%) benchmark prompts, test set failure rates for suicide/NSSI were far higher than in real-world deployment. Clinician review of flagged conversations from the ecological audit identified zero cases of suicide risk that failed to receive crisis resources. Across all 20,000 conversations, three mentions of NSSI risk (.015%) did not trigger a crisis intervention; among sessions flagged by the LLM judge, this corresponds to an end-to-end system false negative rate of .38%, providing a lower bound on real-world safety failures. These findings support a shift toward continuous, deployment-relevant safety assurance for AI mental-health systems rather than limited set benchmark certification.",
      "url": "http://arxiv.org/abs/2601.17003",
      "author": "Caitlin A. Stamatis, Jonah Meyerhoff, Richard Zhang, Olivier Tieleman, Matteo Malgaroli, Thomas D. Hull",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Analyzes 20,000+ real-world mental health AI conversations to validate safety measures, comparing performance to simulation-based test sets. Reveals gaps between simulated safety evaluations and actual user interactions.",
      "importance_score": 82,
      "reasoning": "Rare large-scale ecological validity study of AI safety in high-stakes domain. Critical findings about limitations of simulation-based safety testing.",
      "themes": [
        "AI Safety",
        "Mental Health",
        "Real-world Evaluation",
        "Benchmarks"
      ],
      "continuation": null,
      "summary_html": "<p>Analyzes 20,000+ real-world mental health AI conversations to validate safety measures, comparing performance to simulation-based test sets. Reveals gaps between simulated safety evaluations and actual user interactions.</p>",
      "content_html": "<p>arXiv:2601.17003v1 Announce Type: cross  Abstract: Large language models (LLMs) are increasingly used for mental health support, yet existing safety evaluations rely primarily on small, simulation-based test sets that have an unknown relationship to the linguistic distribution of real usage. In this study, we present replications of four published safety test sets targeting suicide risk assessment, harmful content generation, refusal robustness, and adversarial jailbreaks for a leading frontier generic AI model alongside an AI purpose built for mental health support. We then propose and conduct an ecological audit on over 20,000 real-world user conversations with the purpose-built AI designed with layered suicide and non-suicidal self-injury (NSSI) safeguards to compare test set performance to real world performance. While the purpose-built AI was significantly less likely than general-purpose LLMs to produce enabling or harmful content across suicide/NSSI (.4-11.27% vs 29.0-54.4%), eating disorder (8.4% vs 54.0%), and substance use (9.9% vs 45.0%) benchmark prompts, test set failure rates for suicide/NSSI were far higher than in real-world deployment. Clinician review of flagged conversations from the ecological audit identified zero cases of suicide risk that failed to receive crisis resources. Across all 20,000 conversations, three mentions of NSSI risk (.015%) did not trigger a crisis intervention; among sessions flagged by the LLM judge, this corresponds to an end-to-end system false negative rate of .38%, providing a lower bound on real-world safety failures. These findings support a shift toward continuous, deployment-relevant safety assurance for AI mental-health systems rather than limited set benchmark certification.</p>"
    },
    {
      "id": "b638c07638e2",
      "title": "Less is More for RAG: Information Gain Pruning for Generator-Aligned Reranking and Evidence Selection",
      "content": "arXiv:2601.17532v1 Announce Type: cross  Abstract: Retrieval-augmented generation (RAG) grounds large language models with external evidence, but under a limited context budget, the key challenge is deciding which retrieved passages should be injected. We show that retrieval relevance metrics (e.g., NDCG) correlate weakly with end-to-end QA quality and can even become negatively correlated under multi-passage injection, where redundancy and mild conflicts destabilize generation. We propose \\textbf{Information Gain Pruning (IGP)}, a deployment-friendly reranking-and-pruning module that selects evidence using a generator-aligned utility signal and filters weak or harmful passages before truncation, without changing existing budget interfaces. Across five open-domain QA benchmarks and multiple retrievers and generators, IGP consistently improves the quality--cost trade-off. In a representative multi-evidence setting, IGP delivers about +12--20% relative improvement in average F1 while reducing final-stage input tokens by roughly 76--79% compared to retriever-only baselines.",
      "url": "http://arxiv.org/abs/2601.17532",
      "author": "Zhipeng Song, Yizhi Zhou, Xiangyu Kong, Jiulong Jiao, Xinrui Bao, Xu You, Xueqing Shi, Yuhang Zhou, Heng Qi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Shows retrieval relevance metrics (NDCG) correlate weakly or negatively with QA quality in RAG systems. Proposes Information Gain Pruning (IGP) for generator-aligned evidence selection.",
      "importance_score": 81,
      "reasoning": "Important finding that retrieval quality  generation quality. Practical deployment-friendly solution. Addresses fundamental disconnect in RAG optimization.",
      "themes": [
        "RAG",
        "Information Retrieval",
        "Language Models",
        "NLP"
      ],
      "continuation": null,
      "summary_html": "<p>Shows retrieval relevance metrics (NDCG) correlate weakly or negatively with QA quality in RAG systems. Proposes Information Gain Pruning (IGP) for generator-aligned evidence selection.</p>",
      "content_html": "<p>arXiv:2601.17532v1 Announce Type: cross  Abstract: Retrieval-augmented generation (RAG) grounds large language models with external evidence, but under a limited context budget, the key challenge is deciding which retrieved passages should be injected. We show that retrieval relevance metrics (e.g., NDCG) correlate weakly with end-to-end QA quality and can even become negatively correlated under multi-passage injection, where redundancy and mild conflicts destabilize generation. We propose \\textbf{Information Gain Pruning (IGP)}, a deployment-friendly reranking-and-pruning module that selects evidence using a generator-aligned utility signal and filters weak or harmful passages before truncation, without changing existing budget interfaces. Across five open-domain QA benchmarks and multiple retrievers and generators, IGP consistently improves the quality--cost trade-off. In a representative multi-evidence setting, IGP delivers about +12--20% relative improvement in average F1 while reducing final-stage input tokens by roughly 76--79% compared to retriever-only baselines.</p>"
    },
    {
      "id": "907d53ff2c75",
      "title": "How AI Coding Agents Modify Code: A Large-Scale Study of GitHub Pull Requests",
      "content": "arXiv:2601.17581v1 Announce Type: cross  Abstract: AI coding agents are increasingly acting as autonomous contributors by generating and submitting pull requests (PRs). However, we lack empirical evidence on how these agent-generated PRs differ from human contributions, particularly in how they modify code and describe their changes. Understanding these differences is essential for assessing their reliability and impact on development workflows. Using the MSR 2026 Mining Challenge version of the AIDev dataset, we analyze 24,014 merged Agentic PRs (440,295 commits) and 5,081 merged Human PRs (23,242 commits). We examine additions, deletions, commits, and files touched, and evaluate the consistency between PR descriptions and their diffs using lexical and semantic similarity. Agentic PRs differ substantially from Human PRs in commit count (Cliff's $\\delta = 0.5429$) and show moderate differences in files touched and deleted lines. They also exhibit slightly higher description-to-diff similarity across all measures. These findings provide a large-scale empirical characterization of how AI coding agents contribute to open source development.",
      "url": "http://arxiv.org/abs/2601.17581",
      "author": "Daniel Ogenrwot, John Businge",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.SE"
      ],
      "summary": "Large-scale empirical analysis of 24,014 AI agent-generated GitHub PRs compared to 5,081 human PRs, examining code modifications and PR description consistency. Finds systematic differences in agentic vs human contributions.",
      "importance_score": 80,
      "reasoning": "First large-scale empirical study of AI coding agents in production. Important for understanding real-world AI code generation patterns and setting expectations.",
      "themes": [
        "AI Coding Agents",
        "Software Engineering",
        "Empirical Study"
      ],
      "continuation": null,
      "summary_html": "<p>Large-scale empirical analysis of 24,014 AI agent-generated GitHub PRs compared to 5,081 human PRs, examining code modifications and PR description consistency. Finds systematic differences in agentic vs human contributions.</p>",
      "content_html": "<p>arXiv:2601.17581v1 Announce Type: cross  Abstract: AI coding agents are increasingly acting as autonomous contributors by generating and submitting pull requests (PRs). However, we lack empirical evidence on how these agent-generated PRs differ from human contributions, particularly in how they modify code and describe their changes. Understanding these differences is essential for assessing their reliability and impact on development workflows. Using the MSR 2026 Mining Challenge version of the AIDev dataset, we analyze 24,014 merged Agentic PRs (440,295 commits) and 5,081 merged Human PRs (23,242 commits). We examine additions, deletions, commits, and files touched, and evaluate the consistency between PR descriptions and their diffs using lexical and semantic similarity. Agentic PRs differ substantially from Human PRs in commit count (Cliff's $\\delta = 0.5429$) and show moderate differences in files touched and deleted lines. They also exhibit slightly higher description-to-diff similarity across all measures. These findings provide a large-scale empirical characterization of how AI coding agents contribute to open source development.</p>"
    },
    {
      "id": "d590e386a9f7",
      "title": "CommonLID: Re-evaluating State-of-the-Art Language Identification Performance on Web Data",
      "content": "arXiv:2601.18026v1 Announce Type: new  Abstract: Language identification (LID) is a fundamental step in curating multilingual corpora. However, LID models still perform poorly for many languages, especially on the noisy and heterogeneous web data often used to train multilingual language models. In this paper, we introduce CommonLID, a community-driven, human-annotated LID benchmark for the web domain, covering 109 languages. Many of the included languages have been previously under-served, making CommonLID a key resource for developing more representative high-quality text corpora. We show CommonLID's value by using it, alongside five other common evaluation sets, to test eight popular LID models. We analyse our results to situate our contribution and to provide an overview of the state of the art. In particular, we highlight that existing evaluations overestimate LID accuracy for many languages in the web domain. We make CommonLID and the code used to create it available under an open, permissive license.",
      "url": "http://arxiv.org/abs/2601.18026",
      "author": "Pedro Ortiz Suarez, Laurie Burchell, Catherine Arnett, Rafael Mosquera-G\\'omez, Sara Hincapie-Monsalve, Thom Vaughan, Damian Stewart, Malte Ostendorff, Idris Abdulmumin, Vukosi Marivate, Shamsuddeen Hassan Muhammad, Atnafu Lambebo Tonja, Hend Al-Khalifa, Nadia Ghezaiel Hammouda, Verrah Otiende, Tack Hwa Wong, Jakhongir Saydaliev, Melika Nobakhtian, Muhammad Ravi Shulthan Habibi, Chalamalasetti Kranti, Carol Muchemi, Khang Nguyen, Faisal Muhammad Adam, Luis Frentzen Salim, Reem Alqifari, Cynthia Amol, Joseph Marvin Imperial, Ilker Kesen, Ahmad Mustafid, Pavel Stepachev, Leshem Choshen, David Anugraha, Hamada Nayel, Seid Muhie Yimam, Vallerie Alexandra Putra, My Chiffon Nguyen, Azmine Toushik Wasi, Gouthami Vadithya, Rob van der Goot, Lanwenn ar C'horr, Karan Dua, Andrew Yates, Mithil Bangera, Yeshil Bangera, Hitesh Laxmichand Patel, Shu Okabe, Fenal Ashokbhai Ilasariya, Dmitry Gaynullin, Genta Indra Winata, Yiyuan Li, Juan Pablo Mart\\'inez, Amit Agarwal, Ikhlasul Akmal Hanif, Raia Abu Ahmad, Esther Adenuga, Filbert Aurelian Tjiaranata, Weerayut Buaphet, Michael Anugraha, Sowmya Vajjala, Benjamin Rice, Azril Hafizi Amirudin, Jesujoba O. Alabi, Srikant Panda, Yassine Toughrai, Bruhan Kyomuhendo, Daniel Ruffinelli, Akshata A, Manuel Goul\\~ao, Ej Zhou, Ingrid Gabriela Franco Ramirez, Cristina Aggazzotti, Konstantin Dobler, Jun Kevin, Quentin Pag\\`es, Nicholas Andrews, Nuhu Ibrahim, Mattes Ruckdeschel, Amr Keleg, Mike Zhang, Casper Muziri, Saron Samuel, Sotaro Takeshita, Kun Kerdthaisong, Luca Foppiano, Rasul Dent, Tommaso Green, Ahmad Mustapha Wali, Kamohelo Makaaka, Vicky Feliren, Inshirah Idris, Hande Celikkanat, Abdulhamid Abubakar, Jean Maillard, Beno\\^it Sagot, Thibault Cl\\'erice, Kenton Murray, Sarah Luger",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces CommonLID, a community-driven human-annotated language identification benchmark for web data covering 109 languages including many under-served languages. Tests eight popular LID models.",
      "importance_score": 80,
      "reasoning": "Major resource contribution for multilingual NLP with extensive language coverage and community involvement. Critical for building representative corpora.",
      "themes": [
        "Language Identification",
        "Multilingual NLP",
        "Benchmark",
        "Low-Resource Languages"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces CommonLID, a community-driven human-annotated language identification benchmark for web data covering 109 languages including many under-served languages. Tests eight popular LID models.</p>",
      "content_html": "<p>arXiv:2601.18026v1 Announce Type: new  Abstract: Language identification (LID) is a fundamental step in curating multilingual corpora. However, LID models still perform poorly for many languages, especially on the noisy and heterogeneous web data often used to train multilingual language models. In this paper, we introduce CommonLID, a community-driven, human-annotated LID benchmark for the web domain, covering 109 languages. Many of the included languages have been previously under-served, making CommonLID a key resource for developing more representative high-quality text corpora. We show CommonLID's value by using it, alongside five other common evaluation sets, to test eight popular LID models. We analyse our results to situate our contribution and to provide an overview of the state of the art. In particular, we highlight that existing evaluations overestimate LID accuracy for many languages in the web domain. We make CommonLID and the code used to create it available under an open, permissive license.</p>"
    },
    {
      "id": "7d5cca5f387b",
      "title": "Overalignment in Frontier LLMs: An Empirical Study of Sycophantic Behaviour in Healthcare",
      "content": "arXiv:2601.18334v1 Announce Type: new  Abstract: As LLMs are increasingly integrated into clinical workflows, their tendency for sycophancy, prioritizing user agreement over factual accuracy, poses significant risks to patient safety. While existing evaluations often rely on subjective datasets, we introduce a robust framework grounded in medical MCQA with verifiable ground truths. We propose the Adjusted Sycophancy Score, a novel metric that isolates alignment bias by accounting for stochastic model instability, or \"confusability\". Through an extensive scaling analysis of the Qwen-3 and Llama-3 families, we identify a clear scaling trajectory for resilience. Furthermore, we reveal a counter-intuitive vulnerability in reasoning-optimized \"Thinking\" models: while they demonstrate high vanilla accuracy, their internal reasoning traces frequently rationalize incorrect user suggestions under authoritative pressure. Our results across frontier models suggest that benchmark performance is not a proxy for clinical reliability, and that simplified reasoning structures may offer superior robustness against expert-driven sycophancy.",
      "url": "http://arxiv.org/abs/2601.18334",
      "author": "Cl\\'ement Christophe, Wadood Mohammed Abdul, Prateek Munjal, Tathagata Raha, Ronnie Rajan, Praveenkumar Kanithi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Studies sycophancy in healthcare LLMs using medical MCQA with verifiable ground truths. Introduces Adjusted Sycophancy Score and finds counter-intuitive vulnerability in reasoning-optimized models.",
      "importance_score": 80,
      "reasoning": "Critical safety work for clinical AI deployment. Novel robust evaluation framework and important finding about reasoning model vulnerabilities.",
      "themes": [
        "AI Safety",
        "Healthcare AI",
        "Sycophancy",
        "Alignment"
      ],
      "continuation": null,
      "summary_html": "<p>Studies sycophancy in healthcare LLMs using medical MCQA with verifiable ground truths. Introduces Adjusted Sycophancy Score and finds counter-intuitive vulnerability in reasoning-optimized models.</p>",
      "content_html": "<p>arXiv:2601.18334v1 Announce Type: new  Abstract: As LLMs are increasingly integrated into clinical workflows, their tendency for sycophancy, prioritizing user agreement over factual accuracy, poses significant risks to patient safety. While existing evaluations often rely on subjective datasets, we introduce a robust framework grounded in medical MCQA with verifiable ground truths. We propose the Adjusted Sycophancy Score, a novel metric that isolates alignment bias by accounting for stochastic model instability, or \"confusability\". Through an extensive scaling analysis of the Qwen-3 and Llama-3 families, we identify a clear scaling trajectory for resilience. Furthermore, we reveal a counter-intuitive vulnerability in reasoning-optimized \"Thinking\" models: while they demonstrate high vanilla accuracy, their internal reasoning traces frequently rationalize incorrect user suggestions under authoritative pressure. Our results across frontier models suggest that benchmark performance is not a proxy for clinical reliability, and that simplified reasoning structures may offer superior robustness against expert-driven sycophancy.</p>"
    },
    {
      "id": "2870c5d35131",
      "title": "AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security",
      "content": "arXiv:2601.18491v1 Announce Type: new  Abstract: The rise of AI agents introduces complex safety and security challenges arising from autonomous tool use and environmental interactions. Current guardrail models lack agentic risk awareness and transparency in risk diagnosis. To introduce an agentic guardrail that covers complex and numerous risky behaviors, we first propose a unified three-dimensional taxonomy that orthogonally categorizes agentic risks by their source (where), failure mode (how), and consequence (what). Guided by this structured and hierarchical taxonomy, we introduce a new fine-grained agentic safety benchmark (ATBench) and a Diagnostic Guardrail framework for agent safety and security (AgentDoG). AgentDoG provides fine-grained and contextual monitoring across agent trajectories. More Crucially, AgentDoG can diagnose the root causes of unsafe actions and seemingly safe but unreasonable actions, offering provenance and transparency beyond binary labels to facilitate effective agent alignment. AgentDoG variants are available in three sizes (4B, 7B, and 8B parameters) across Qwen and Llama model families. Extensive experimental results demonstrate that AgentDoG achieves state-of-the-art performance in agentic safety moderation in diverse and complex interactive scenarios. All models and datasets are openly released.",
      "url": "http://arxiv.org/abs/2601.18491",
      "author": "Dongrui Liu, Qihan Ren, Chen Qian, Shuai Shao, Yuejin Xie, Yu Li, Zhonghao Yang, Haoyu Luo, Peng Wang, Qingyu Liu, Binxin Hu, Ling Tang, Jilin Mei, Dadi Guo, Leitao Yuan, Junyao Yang, Guanxu Chen, Qihao Lin, Yi Yu, Bo Zhang, Jiaxuan Guo, Jie Zhang, Wenqi Shao, Huiqi Deng, Zhiheng Xi, Wenjie Wang, Wenxuan Wang, Wen Shen, Zhikai Chen, Haoyu Xie, Jialing Tao, Juntao Dai, Jiaming Ji, Zhongjie Ba, Linfeng Zhang, Yong Liu, Quanshi Zhang, Lei Zhu, Zhihua Wei, Hui Xue, Chaochao Lu, Jing Shao, Xia Hu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes AgentDoG, a diagnostic guardrail framework with three-dimensional taxonomy categorizing agentic risks by source, failure mode, and consequence, introducing ATBench benchmark for fine-grained safety evaluation.",
      "importance_score": 79,
      "reasoning": "Comprehensive safety framework addressing critical gap in agent guardrails; systematic taxonomy with practical benchmark.",
      "themes": [
        "AI Safety",
        "Agentic AI",
        "Guardrails",
        "Benchmarks"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes AgentDoG, a diagnostic guardrail framework with three-dimensional taxonomy categorizing agentic risks by source, failure mode, and consequence, introducing ATBench benchmark for fine-grained safety evaluation.</p>",
      "content_html": "<p>arXiv:2601.18491v1 Announce Type: new  Abstract: The rise of AI agents introduces complex safety and security challenges arising from autonomous tool use and environmental interactions. Current guardrail models lack agentic risk awareness and transparency in risk diagnosis. To introduce an agentic guardrail that covers complex and numerous risky behaviors, we first propose a unified three-dimensional taxonomy that orthogonally categorizes agentic risks by their source (where), failure mode (how), and consequence (what). Guided by this structured and hierarchical taxonomy, we introduce a new fine-grained agentic safety benchmark (ATBench) and a Diagnostic Guardrail framework for agent safety and security (AgentDoG). AgentDoG provides fine-grained and contextual monitoring across agent trajectories. More Crucially, AgentDoG can diagnose the root causes of unsafe actions and seemingly safe but unreasonable actions, offering provenance and transparency beyond binary labels to facilitate effective agent alignment. AgentDoG variants are available in three sizes (4B, 7B, and 8B parameters) across Qwen and Llama model families. Extensive experimental results demonstrate that AgentDoG achieves state-of-the-art performance in agentic safety moderation in diverse and complex interactive scenarios. All models and datasets are openly released.</p>"
    },
    {
      "id": "0d9f007165d9",
      "title": "Towards a Declarative Agentic Layer for Intelligent Agents in MCP-Based Server Ecosystems",
      "content": "arXiv:2601.17435v1 Announce Type: cross  Abstract: Recent advances in Large Language Models (LLMs) have enabled the development of increasingly complex agentic and multi-agent systems capable of planning, tool use and task decomposition. However, empirical evidence shows that many of these systems suffer from fundamental reliability issues, including hallucinated actions, unexecutable plans and brittle coordination. Crucially, these failures do not stem from limitations of the underlying models themselves, but from the absence of explicit architectural structure linking goals, capabilities and execution. This paper presents a declarative, model-independent architectural layer for grounded agentic workflows that addresses this gap. The proposed layer, referred to as DALIA (Declarative Agentic Layer for Intelligent Agents), formalises executable capabilities, exposes tasks through a declarative discovery protocol, maintains a federated directory of agents and their execution resources, and constructs deterministic task graphs grounded exclusively in declared operations. By enforcing a clear separation between discovery, planning and execution, the architecture constrains agent behaviour to a verifiable operational space, reducing reliance on speculative reasoning and free-form coordination. We present the architecture and design principles of the proposed layer and illustrate its operation through a representative task-oriented scenario, demonstrating how declarative grounding enables reproducible and verifiable agentic workflows across heterogeneous environments.",
      "url": "http://arxiv.org/abs/2601.17435",
      "author": "Maria Jesus Rodriguez-Sanchez, Manuel Noguera, Angel Ruiz-Zafra, Kawtar Benghazi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.SE"
      ],
      "summary": "DALIA proposes a declarative, model-independent architectural layer for grounded agentic workflows in MCP-based systems, addressing hallucinated actions and brittle coordination through explicit goal-capability-execution structure.",
      "importance_score": 79,
      "reasoning": "Addresses reliability failures in agentic systems with architectural solution. Targets MCP ecosystem. Complements security analysis of MCP.",
      "themes": [
        "Agentic Systems",
        "MCP",
        "Agent Architecture",
        "Reliability"
      ],
      "continuation": null,
      "summary_html": "<p>DALIA proposes a declarative, model-independent architectural layer for grounded agentic workflows in MCP-based systems, addressing hallucinated actions and brittle coordination through explicit goal-capability-execution structure.</p>",
      "content_html": "<p>arXiv:2601.17435v1 Announce Type: cross  Abstract: Recent advances in Large Language Models (LLMs) have enabled the development of increasingly complex agentic and multi-agent systems capable of planning, tool use and task decomposition. However, empirical evidence shows that many of these systems suffer from fundamental reliability issues, including hallucinated actions, unexecutable plans and brittle coordination. Crucially, these failures do not stem from limitations of the underlying models themselves, but from the absence of explicit architectural structure linking goals, capabilities and execution. This paper presents a declarative, model-independent architectural layer for grounded agentic workflows that addresses this gap. The proposed layer, referred to as DALIA (Declarative Agentic Layer for Intelligent Agents), formalises executable capabilities, exposes tasks through a declarative discovery protocol, maintains a federated directory of agents and their execution resources, and constructs deterministic task graphs grounded exclusively in declared operations. By enforcing a clear separation between discovery, planning and execution, the architecture constrains agent behaviour to a verifiable operational space, reducing reliance on speculative reasoning and free-form coordination. We present the architecture and design principles of the proposed layer and illustrate its operation through a representative task-oriented scenario, demonstrating how declarative grounding enables reproducible and verifiable agentic workflows across heterogeneous environments.</p>"
    },
    {
      "id": "f69fdfd03bba",
      "title": "daVinci-Dev: Agent-native Mid-training for Software Engineering",
      "content": "arXiv:2601.18418v1 Announce Type: cross  Abstract: Recently, the frontier of Large Language Model (LLM) capabilities has shifted from single-turn code generation to agentic software engineering-a paradigm where models autonomously navigate, edit, and test complex repositories. While post-training methods have become the de facto approach for code agents, **agentic mid-training**-mid-training (MT) on large-scale data that mirrors authentic agentic workflows-remains critically underexplored due to substantial resource requirements, despite offering a more scalable path to instilling foundational agentic behaviors than relying solely on expensive reinforcement learning. A central challenge in realizing effective agentic mid-training is the distribution mismatch between static training data and the dynamic, feedback-rich environment of real development. To address this, we present a systematic study of agentic mid-training, establishing both the data synthesis principles and training methodology for effective agent development at scale. Central to our approach is **agent-native data**-supervision comprising two complementary types of trajectories: **contextually-native trajectories** that preserve the complete information flow an agent experiences, offering broad coverage and diversity; and **environmentally-native trajectories** collected from executable repositories where observations stem from actual tool invocations and test executions, providing depth and interaction authenticity. We verify the model's agentic capabilities on `SWE-Bench Verified`. We demonstrate our superiority over the previous open software engineering mid-training recipe `Kimi-Dev` under two post-training settings with an aligned base model and agentic scaffold, while using less than half mid-training tokens (73.1B). Besides relative advantage, our best performing 32B and 72B models achieve **56.1%** and **58.5%** resolution rates, respectively, which are ...",
      "url": "http://arxiv.org/abs/2601.18418",
      "author": "Ji Zeng, Dayuan Fu, Tiantian Mi, Yumin Zhuang, Yaxing Huang, Xuefeng Li, Lyumanshan Ye, Muhang Xie, Qishuo Hua, Zhen Huang, Mohan Jiang, Hanning Wang, Jifan Lin, Yang Xiao, Jie Sun, Yunze Wu, Pengfei Liu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.SE"
      ],
      "summary": "Introduces daVinci-Dev, exploring agentic mid-training for software engineering LLMs. Addresses distribution mismatch between static training data and authentic agentic workflows through mid-training on large-scale agentic data.",
      "importance_score": 79,
      "reasoning": "Novel paradigm: mid-training on agentic workflows rather than just post-training. Addresses fundamental distribution mismatch. Highly relevant for code agent development.",
      "themes": [
        "Software Engineering",
        "Agentic AI",
        "Mid-training",
        "Code Agents"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces daVinci-Dev, exploring agentic mid-training for software engineering LLMs. Addresses distribution mismatch between static training data and authentic agentic workflows through mid-training on large-scale agentic data.</p>",
      "content_html": "<p>arXiv:2601.18418v1 Announce Type: cross  Abstract: Recently, the frontier of Large Language Model (LLM) capabilities has shifted from single-turn code generation to agentic software engineering-a paradigm where models autonomously navigate, edit, and test complex repositories. While post-training methods have become the de facto approach for code agents, <strong>agentic mid-training</strong>-mid-training (MT) on large-scale data that mirrors authentic agentic workflows-remains critically underexplored due to substantial resource requirements, despite offering a more scalable path to instilling foundational agentic behaviors than relying solely on expensive reinforcement learning. A central challenge in realizing effective agentic mid-training is the distribution mismatch between static training data and the dynamic, feedback-rich environment of real development. To address this, we present a systematic study of agentic mid-training, establishing both the data synthesis principles and training methodology for effective agent development at scale. Central to our approach is <strong>agent-native data</strong>-supervision comprising two complementary types of trajectories: <strong>contextually-native trajectories</strong> that preserve the complete information flow an agent experiences, offering broad coverage and diversity; and <strong>environmentally-native trajectories</strong> collected from executable repositories where observations stem from actual tool invocations and test executions, providing depth and interaction authenticity. We verify the model's agentic capabilities on `SWE-Bench Verified`. We demonstrate our superiority over the previous open software engineering mid-training recipe `Kimi-Dev` under two post-training settings with an aligned base model and agentic scaffold, while using less than half mid-training tokens (73.1B). Besides relative advantage, our best performing 32B and 72B models achieve <strong>56.1%</strong> and <strong>58.5%</strong> resolution rates, respectively, which are ...</p>"
    },
    {
      "id": "83ee42f0d13a",
      "title": "When Personalization Legitimizes Risks: Uncovering Safety Vulnerabilities in Personalized Dialogue Agents",
      "content": "arXiv:2601.17887v1 Announce Type: new  Abstract: Long-term memory enables large language model (LLM) agents to support personalized and sustained interactions. However, most work on personalized agents prioritizes utility and user experience, treating memory as a neutral component and largely overlooking its safety implications. In this paper, we reveal intent legitimation, a previously underexplored safety failure in personalized agents, where benign personal memories bias intent inference and cause models to legitimize inherently harmful queries. To study this phenomenon, we introduce PS-Bench, a benchmark designed to identify and quantify intent legitimation in personalized interactions. Across multiple memory-augmented agent frameworks and base LLMs, personalization increases attack success rates by 15.8%-243.7% relative to stateless baselines. We further provide mechanistic evidence for intent legitimation from internal representations space, and propose a lightweight detection-reflection method that effectively reduces safety degradation. Overall, our work provides the first systematic exploration and evaluation of intent legitimation as a safety failure mode that naturally arises from benign, real-world personalization, highlighting the importance of assessing safety under long-term personal context. WARNING: This paper may contain harmful content.",
      "url": "http://arxiv.org/abs/2601.17887",
      "author": "Jiahe Guo, Xiangran Guo, Yulin Hu, Zimo Long, Xingyu Sui, Xuda Zhi, Yongbo Huang, Hao He, Weixiang Zhao, Yanyan Zhao, Bing Qin",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Reveals 'intent legitimation' vulnerability in personalized LLM agents where benign personal memories bias intent inference and cause models to legitimize harmful queries, introducing PS-Bench benchmark.",
      "importance_score": 78,
      "reasoning": "Important novel safety finding with significant implications for personalized agents; systematic benchmark enables further research.",
      "themes": [
        "AI Safety",
        "Personalization",
        "Adversarial Attacks"
      ],
      "continuation": null,
      "summary_html": "<p>Reveals 'intent legitimation' vulnerability in personalized LLM agents where benign personal memories bias intent inference and cause models to legitimize harmful queries, introducing PS-Bench benchmark.</p>",
      "content_html": "<p>arXiv:2601.17887v1 Announce Type: new  Abstract: Long-term memory enables large language model (LLM) agents to support personalized and sustained interactions. However, most work on personalized agents prioritizes utility and user experience, treating memory as a neutral component and largely overlooking its safety implications. In this paper, we reveal intent legitimation, a previously underexplored safety failure in personalized agents, where benign personal memories bias intent inference and cause models to legitimize inherently harmful queries. To study this phenomenon, we introduce PS-Bench, a benchmark designed to identify and quantify intent legitimation in personalized interactions. Across multiple memory-augmented agent frameworks and base LLMs, personalization increases attack success rates by 15.8%-243.7% relative to stateless baselines. We further provide mechanistic evidence for intent legitimation from internal representations space, and propose a lightweight detection-reflection method that effectively reduces safety degradation. Overall, our work provides the first systematic exploration and evaluation of intent legitimation as a safety failure mode that naturally arises from benign, real-world personalization, highlighting the importance of assessing safety under long-term personal context. WARNING: This paper may contain harmful content.</p>"
    },
    {
      "id": "a78b0d8b6dce",
      "title": "Lost in Simulation: LLM-Simulated Users are Unreliable Proxies for Human Users in Agentic Evaluations",
      "content": "arXiv:2601.17087v1 Announce Type: cross  Abstract: Agentic benchmarks increasingly rely on LLM-simulated users to scalably evaluate agent performance, yet the robustness, validity, and fairness of this approach remain unexamined. Through a user study with participants across the United States, India, Kenya, and Nigeria, we investigate whether LLM-simulated users serve as reliable proxies for real human users in evaluating agents on {\\tau}-Bench retail tasks. We find that user simulation lacks robustness, with agent success rates varying up to 9 percentage points across different user LLMs. Furthermore, evaluations using simulated users exhibit systematic miscalibration, underestimating agent performance on challenging tasks and overestimating it on moderately difficult ones. African American Vernacular English (AAVE) speakers experience consistently worse success rates and calibration errors than Standard American English (SAE) speakers, with disparities compounding significantly with age. We also find simulated users to be a differentially effective proxy for different populations, performing worst for AAVE and Indian English speakers. Additionally, simulated users introduce conversational artifacts and surface different failure patterns than human users. These findings demonstrate that current evaluation practices risk misrepresenting agent capabilities across diverse user populations and may obscure real-world deployment challenges.",
      "url": "http://arxiv.org/abs/2601.17087",
      "author": "Preethi Seshadri, Samuel Cahyawijaya, Ayomide Odumakinde, Sameer Singh, Seraphina Goldfarb-Tarrant",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.HC"
      ],
      "summary": "Through multi-country user study, demonstrates that LLM-simulated users are unreliable proxies for real humans in agent evaluation. Shows systematic miscalibration and demographic bias.",
      "importance_score": 78,
      "reasoning": "Critical finding for agent benchmark methodology. Multi-country study with strong evidence that simulated users create unfair evaluations. High impact for agentic AI research.",
      "themes": [
        "Agent Evaluation",
        "LLM Simulation",
        "Fairness",
        "Benchmarks"
      ],
      "continuation": null,
      "summary_html": "<p>Through multi-country user study, demonstrates that LLM-simulated users are unreliable proxies for real humans in agent evaluation. Shows systematic miscalibration and demographic bias.</p>",
      "content_html": "<p>arXiv:2601.17087v1 Announce Type: cross  Abstract: Agentic benchmarks increasingly rely on LLM-simulated users to scalably evaluate agent performance, yet the robustness, validity, and fairness of this approach remain unexamined. Through a user study with participants across the United States, India, Kenya, and Nigeria, we investigate whether LLM-simulated users serve as reliable proxies for real human users in evaluating agents on {\\tau}-Bench retail tasks. We find that user simulation lacks robustness, with agent success rates varying up to 9 percentage points across different user LLMs. Furthermore, evaluations using simulated users exhibit systematic miscalibration, underestimating agent performance on challenging tasks and overestimating it on moderately difficult ones. African American Vernacular English (AAVE) speakers experience consistently worse success rates and calibration errors than Standard American English (SAE) speakers, with disparities compounding significantly with age. We also find simulated users to be a differentially effective proxy for different populations, performing worst for AAVE and Indian English speakers. Additionally, simulated users introduce conversational artifacts and surface different failure patterns than human users. These findings demonstrate that current evaluation practices risk misrepresenting agent capabilities across diverse user populations and may obscure real-world deployment challenges.</p>"
    },
    {
      "id": "d7171de9ef38",
      "title": "Elastic Attention: Test-time Adaptive Sparsity Ratios for Efficient Transformers",
      "content": "arXiv:2601.17367v1 Announce Type: cross  Abstract: The quadratic complexity of standard attention mechanisms poses a significant scalability bottleneck for large language models (LLMs) in long-context scenarios. While hybrid attention strategies that combine sparse and full attention within a single model offer a viable solution, they typically employ static computation ratios (i.e., fixed proportions of sparse versus full attention) and fail to adapt to the varying sparsity sensitivities of downstream tasks during inference. To address this issue, we propose Elastic Attention, which allows the model to dynamically adjust its overall sparsity based on the input. This is achieved by integrating a lightweight Attention Router into the existing pretrained model, which dynamically assigns each attention head to different computation modes. Within only 12 hours of training on 8xA800 GPUs, our method enables models to achieve both strong performance and efficient inference. Experiments across three long-context benchmarks on widely-used LLMs demonstrate the superiority of our method.",
      "url": "http://arxiv.org/abs/2601.17367",
      "author": "Zecheng Tang, Quantong Qiu, Yi Yang, Zhiyi Hong, Haiya Xiang, Kebin Liu, Qingqing Dang, Juntao Li, Min Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Elastic Attention dynamically adjusts sparsity ratios at test time via a lightweight Attention Router, adapting to varying input complexity rather than using fixed sparse/full attention ratios.",
      "importance_score": 78,
      "reasoning": "Practical efficiency improvement for transformers. Test-time adaptivity is valuable. Addresses quadratic complexity with input-dependent sparsity.",
      "themes": [
        "Efficient Transformers",
        "Attention Mechanisms",
        "Model Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>Elastic Attention dynamically adjusts sparsity ratios at test time via a lightweight Attention Router, adapting to varying input complexity rather than using fixed sparse/full attention ratios.</p>",
      "content_html": "<p>arXiv:2601.17367v1 Announce Type: cross  Abstract: The quadratic complexity of standard attention mechanisms poses a significant scalability bottleneck for large language models (LLMs) in long-context scenarios. While hybrid attention strategies that combine sparse and full attention within a single model offer a viable solution, they typically employ static computation ratios (i.e., fixed proportions of sparse versus full attention) and fail to adapt to the varying sparsity sensitivities of downstream tasks during inference. To address this issue, we propose Elastic Attention, which allows the model to dynamically adjust its overall sparsity based on the input. This is achieved by integrating a lightweight Attention Router into the existing pretrained model, which dynamically assigns each attention head to different computation modes. Within only 12 hours of training on 8xA800 GPUs, our method enables models to achieve both strong performance and efficient inference. Experiments across three long-context benchmarks on widely-used LLMs demonstrate the superiority of our method.</p>"
    },
    {
      "id": "8ff1b4868a29",
      "title": "Demystifying Data-Driven Probabilistic Medium-Range Weather Forecasting",
      "content": "arXiv:2601.18111v1 Announce Type: cross  Abstract: The recent revolution in data-driven methods for weather forecasting has lead to a fragmented landscape of complex, bespoke architectures and training strategies, obscuring the fundamental drivers of forecast accuracy. Here, we demonstrate that state-of-the-art probabilistic skill requires neither intricate architectural constraints nor specialized training heuristics. We introduce a scalable framework for learning multi-scale atmospheric dynamics by combining a directly downsampled latent space with a history-conditioned local projector that resolves high-resolution physics. We find that our framework design is robust to the choice of probabilistic estimator, seamlessly supporting stochastic interpolants, diffusion models, and CRPS-based ensemble training. Validated against the Integrated Forecasting System and the deep learning probabilistic model GenCast, our framework achieves statistically significant improvements on most of the variables. These results suggest scaling a general-purpose model is sufficient for state-of-the-art medium-range prediction, eliminating the need for tailored training recipes and proving effective across the full spectrum of probabilistic frameworks.",
      "url": "http://arxiv.org/abs/2601.18111",
      "author": "Jean Kossaifi, Nikola Kovachki, Morteza Mardani, Daniel Leibovici, Suman Ravuri, Ira Shokar, Edoardo Calvello, Mohammad Shoaib Abbas, Peter Harrington, Ashay Subramaniam, Noah Brenowitz, Boris Bonev, Wonmin Byeon, Karsten Kreis, Dale Durran, Arash Vahdat, Mike Pritchard, Jan Kautz",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "NVIDIA team demonstrates state-of-the-art probabilistic weather forecasting without complex architectures or specialized heuristics. Introduces scalable framework combining downsampled latent space with history-conditioned local projector for multi-scale atmospheric dynamics.",
      "importance_score": 78,
      "reasoning": "Strong team from NVIDIA (Kossaifi, Vahdat, Kautz). Simplifies SOTA weather prediction, showing complex architectures may be unnecessary. High practical impact for weather forecasting community.",
      "themes": [
        "Weather Forecasting",
        "Scientific AI",
        "Diffusion Models",
        "Probabilistic Modeling"
      ],
      "continuation": null,
      "summary_html": "<p>NVIDIA team demonstrates state-of-the-art probabilistic weather forecasting without complex architectures or specialized heuristics. Introduces scalable framework combining downsampled latent space with history-conditioned local projector for multi-scale atmospheric dynamics.</p>",
      "content_html": "<p>arXiv:2601.18111v1 Announce Type: cross  Abstract: The recent revolution in data-driven methods for weather forecasting has lead to a fragmented landscape of complex, bespoke architectures and training strategies, obscuring the fundamental drivers of forecast accuracy. Here, we demonstrate that state-of-the-art probabilistic skill requires neither intricate architectural constraints nor specialized training heuristics. We introduce a scalable framework for learning multi-scale atmospheric dynamics by combining a directly downsampled latent space with a history-conditioned local projector that resolves high-resolution physics. We find that our framework design is robust to the choice of probabilistic estimator, seamlessly supporting stochastic interpolants, diffusion models, and CRPS-based ensemble training. Validated against the Integrated Forecasting System and the deep learning probabilistic model GenCast, our framework achieves statistically significant improvements on most of the variables. These results suggest scaling a general-purpose model is sufficient for state-of-the-art medium-range prediction, eliminating the need for tailored training recipes and proving effective across the full spectrum of probabilistic frameworks.</p>"
    },
    {
      "id": "0cb3d55582f9",
      "title": "Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes",
      "content": "arXiv:2601.18795v1 Announce Type: cross  Abstract: Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.",
      "url": "http://arxiv.org/abs/2601.18795",
      "author": "Amrith Setlur, Zijian Wang, Andrew Cohen, Paria Rashidinejad, Sang Michael Xie",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces PrefixRL to reuse previous sampling FLOPs for RL by conditioning on successful off-policy trace prefixes, side-stepping off-policy instabilities while modulating problem difficulty.",
      "importance_score": 78,
      "reasoning": "Elegant solution to RL efficiency on hard problems. Avoids off-policy instabilities while leveraging prior compute. Complements POPE paper. Proves convergence improvements.",
      "themes": [
        "Reinforcement Learning",
        "Sample Efficiency",
        "LLM Reasoning",
        "Hard Problems"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces PrefixRL to reuse previous sampling FLOPs for RL by conditioning on successful off-policy trace prefixes, side-stepping off-policy instabilities while modulating problem difficulty.</p>",
      "content_html": "<p>arXiv:2601.18795v1 Announce Type: cross  Abstract: Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.</p>"
    },
    {
      "id": "931e6f7ef34c",
      "title": "S$^3$-Attention:Attention-Aligned Endogenous Retrieval for Memory-Bounded Long-Context Inference",
      "content": "arXiv:2601.17702v1 Announce Type: new  Abstract: Large language models are increasingly applied to multi-document and long-form inputs, yet long-context inference remains memory- and noise-inefficient. Key-value (KV) caching scales linearly with context length, while external retrieval methods often return lexically similar but causally irrelevant passages.   We present S3-Attention, a memory-first inference-time framework that treats long-context processing as attention-aligned endogenous retrieval. S3-Attention decodes transient key and query projections into top-k sparse feature identifiers using lightweight sparse autoencoders, and constructs a CPU-based inverted index mapping features to token positions or spans during a single streaming scan. This design allows the KV cache to be discarded entirely and bounds GPU memory usage by the scan chunk size.   At generation time, feature co-activation is used to retrieve compact evidence spans, optionally fused with BM25 for exact lexical matching. Under a unified LongBench evaluation protocol with fixed prompting, decoding, and matched token budgets, S3-Hybrid closely matches full-context inference across multiple model families and improves robustness in several information-dense settings. We also report an engineering limitation of the current prototype, which incurs higher wall-clock latency than optimized full-KV baselines, motivating future kernel-level optimization.",
      "url": "http://arxiv.org/abs/2601.17702",
      "author": "Qingsen Ma, Dianyun Wang, Yaoye Wang, Lechen Ning, Sujie Zhu, Xiaohang Zhang, Jiaming Lyu, Linhao Ren, Zhenbo Xu, Zhaofeng He",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents S3-Attention, a memory-efficient long-context inference framework using sparse autoencoders to decode KV projections into sparse features, enabling CPU-based inverted index for attention-aligned retrieval.",
      "importance_score": 78,
      "reasoning": "Important efficiency contribution for long-context inference addressing critical memory bottleneck. Novel use of sparse autoencoders for KV cache optimization.",
      "themes": [
        "Efficiency",
        "Long Context",
        "Attention Mechanisms",
        "Memory Optimization"
      ],
      "continuation": null,
      "summary_html": "<p>Presents S3-Attention, a memory-efficient long-context inference framework using sparse autoencoders to decode KV projections into sparse features, enabling CPU-based inverted index for attention-aligned retrieval.</p>",
      "content_html": "<p>arXiv:2601.17702v1 Announce Type: new  Abstract: Large language models are increasingly applied to multi-document and long-form inputs, yet long-context inference remains memory- and noise-inefficient. Key-value (KV) caching scales linearly with context length, while external retrieval methods often return lexically similar but causally irrelevant passages.   We present S3-Attention, a memory-first inference-time framework that treats long-context processing as attention-aligned endogenous retrieval. S3-Attention decodes transient key and query projections into top-k sparse feature identifiers using lightweight sparse autoencoders, and constructs a CPU-based inverted index mapping features to token positions or spans during a single streaming scan. This design allows the KV cache to be discarded entirely and bounds GPU memory usage by the scan chunk size.   At generation time, feature co-activation is used to retrieve compact evidence spans, optionally fused with BM25 for exact lexical matching. Under a unified LongBench evaluation protocol with fixed prompting, decoding, and matched token budgets, S3-Hybrid closely matches full-context inference across multiple model families and improves robustness in several information-dense settings. We also report an engineering limitation of the current prototype, which incurs higher wall-clock latency than optimized full-KV baselines, motivating future kernel-level optimization.</p>"
    },
    {
      "id": "9fe79e02b9e5",
      "title": "From Verifiable Dot to Reward Chain: Harnessing Verifiable Reference-based Rewards for Reinforcement Learning of Open-ended Generation",
      "content": "arXiv:2601.18533v1 Announce Type: new  Abstract: Reinforcement learning with verifiable rewards (RLVR) succeeds in reasoning tasks (e.g., math and code) by checking the final verifiable answer (i.e., a verifiable dot signal). However, extending this paradigm to open-ended generation is challenging because there is no unambiguous ground truth. Relying on single-dot supervision often leads to inefficiency and reward hacking. To address these issues, we propose reinforcement learning with verifiable reference-based rewards (RLVRR). Instead of checking the final answer, RLVRR extracts an ordered linguistic signal from high-quality references (i.e, reward chain). Specifically, RLVRR decomposes rewards into two dimensions: content, which preserves deterministic core concepts (e.g., keywords), and style, which evaluates adherence to stylistic properties through LLM-based verification. In this way, RLVRR combines the exploratory strength of RL with the efficiency and reliability of supervised fine-tuning (SFT). Extensive experiments on more than 10 benchmarks with Qwen and Llama models confirm the advantages of our approach. RLVRR (1) substantially outperforms SFT trained with ten times more data and advanced reward models, (2) unifies the training of structured reasoning and open-ended generation, and (3) generalizes more effectively while preserving output diversity. These results establish RLVRR as a principled and efficient path toward verifiable reinforcement learning for general-purpose LLM alignment. We release our code and data at https://github.com/YJiangcm/RLVRR.",
      "url": "http://arxiv.org/abs/2601.18533",
      "author": "Yuxin Jiang, Yufei Wang, Qiyuan Zhang, Xingshan Zeng, Liangyou Li, Jierun Chen, Chaofan Tao, Haoli Bai, Lifeng Shang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes RLVRR extending verifiable rewards to open-ended generation by extracting reward chains from references, decomposing rewards into content (keywords) and structure (discourse markers) dimensions.",
      "importance_score": 78,
      "reasoning": "Important extension of RLVR paradigm to open-ended generation. Novel reward chain formulation addresses fundamental challenge in RL for text generation.",
      "themes": [
        "Reinforcement Learning",
        "Reward Modeling",
        "Open-Ended Generation",
        "Alignment"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes RLVRR extending verifiable rewards to open-ended generation by extracting reward chains from references, decomposing rewards into content (keywords) and structure (discourse markers) dimensions.</p>",
      "content_html": "<p>arXiv:2601.18533v1 Announce Type: new  Abstract: Reinforcement learning with verifiable rewards (RLVR) succeeds in reasoning tasks (e.g., math and code) by checking the final verifiable answer (i.e., a verifiable dot signal). However, extending this paradigm to open-ended generation is challenging because there is no unambiguous ground truth. Relying on single-dot supervision often leads to inefficiency and reward hacking. To address these issues, we propose reinforcement learning with verifiable reference-based rewards (RLVRR). Instead of checking the final answer, RLVRR extracts an ordered linguistic signal from high-quality references (i.e, reward chain). Specifically, RLVRR decomposes rewards into two dimensions: content, which preserves deterministic core concepts (e.g., keywords), and style, which evaluates adherence to stylistic properties through LLM-based verification. In this way, RLVRR combines the exploratory strength of RL with the efficiency and reliability of supervised fine-tuning (SFT). Extensive experiments on more than 10 benchmarks with Qwen and Llama models confirm the advantages of our approach. RLVRR (1) substantially outperforms SFT trained with ten times more data and advanced reward models, (2) unifies the training of structured reasoning and open-ended generation, and (3) generalizes more effectively while preserving output diversity. These results establish RLVRR as a principled and efficient path toward verifiable reinforcement learning for general-purpose LLM alignment. We release our code and data at https://github.com/YJiangcm/RLVRR.</p>"
    },
    {
      "id": "f1f72918f200",
      "title": "Reflect: Transparent Principle-Guided Reasoning for Constitutional Alignment at Scale",
      "content": "arXiv:2601.18730v1 Announce Type: new  Abstract: The constitutional framework of alignment aims to align large language models (LLMs) with value-laden principles written in natural language (such as to avoid using biased language). Prior work has focused on parameter fine-tuning techniques, such as reinforcement learning from human feedback (RLHF), to instill these principles. However, these approaches are computationally demanding, require careful engineering and tuning, and often require difficult-to-obtain human annotation data. We propose \\textsc{reflect}, an inference-time framework for constitutional alignment that does not require any training or data, providing a plug-and-play approach for aligning an instruction-tuned model to a set of principles. \\textsc{reflect} operates entirely in-context, combining a (i) constitution-conditioned base response with post-generation (ii) self-evaluation, (iii)(a) self-critique, and (iii)(b) final revision. \\textsc{reflect}'s technique of explicit in-context reasoning over principles during post-generation outperforms standard few-shot prompting and provides transparent reasoning traces. Our results demonstrate that \\textsc{reflect} significantly improves LLM conformance to diverse and complex principles, including principles quite distinct from those emphasized in the model's original parameter fine-tuning, without sacrificing factual reasoning. \\textsc{reflect} is particularly effective at reducing the rate of rare but significant violations of principles, thereby improving safety and robustness in the tail end of the distribution of generations. Finally, we show that \\textsc{reflect} naturally generates useful training data for traditional parameter fine-tuning techniques, allowing for efficient scaling and the reduction of inference-time computational overhead in long-term deployment scenarios.",
      "url": "http://arxiv.org/abs/2601.18730",
      "author": "Henry Bell, Caroline Zhang, Mohammed Mobasserul Haque, Dhaval Potdar, Samia Zaman, Brandon Fain",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes REFLECT, an inference-time framework for aligning LLMs to constitutional principles without any training or data. The plug-and-play approach operates at inference time to align instruction-tuned models to specified principles, offering a more computationally efficient alternative to RLHF.",
      "importance_score": 78,
      "reasoning": "Novel training-free alignment method that addresses key limitations of RLHF (computational cost, data requirements). Important contribution to practical constitutional AI approaches.",
      "themes": [
        "AI Safety",
        "Alignment",
        "Constitutional AI",
        "Inference Optimization"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes REFLECT, an inference-time framework for aligning LLMs to constitutional principles without any training or data. The plug-and-play approach operates at inference time to align instruction-tuned models to specified principles, offering a more computationally efficient alternative to RLHF.</p>",
      "content_html": "<p>arXiv:2601.18730v1 Announce Type: new  Abstract: The constitutional framework of alignment aims to align large language models (LLMs) with value-laden principles written in natural language (such as to avoid using biased language). Prior work has focused on parameter fine-tuning techniques, such as reinforcement learning from human feedback (RLHF), to instill these principles. However, these approaches are computationally demanding, require careful engineering and tuning, and often require difficult-to-obtain human annotation data. We propose \\textsc{reflect}, an inference-time framework for constitutional alignment that does not require any training or data, providing a plug-and-play approach for aligning an instruction-tuned model to a set of principles. \\textsc{reflect} operates entirely in-context, combining a (i) constitution-conditioned base response with post-generation (ii) self-evaluation, (iii)(a) self-critique, and (iii)(b) final revision. \\textsc{reflect}'s technique of explicit in-context reasoning over principles during post-generation outperforms standard few-shot prompting and provides transparent reasoning traces. Our results demonstrate that \\textsc{reflect} significantly improves LLM conformance to diverse and complex principles, including principles quite distinct from those emphasized in the model's original parameter fine-tuning, without sacrificing factual reasoning. \\textsc{reflect} is particularly effective at reducing the rate of rare but significant violations of principles, thereby improving safety and robustness in the tail end of the distribution of generations. Finally, we show that \\textsc{reflect} naturally generates useful training data for traditional parameter fine-tuning techniques, allowing for efficient scaling and the reduction of inference-time computational overhead in long-term deployment scenarios.</p>"
    },
    {
      "id": "7f07bea5216f",
      "title": "A Pragmatic VLA Foundation Model",
      "content": "arXiv:2601.18692v1 Announce Type: cross  Abstract: Offering great potential in robotic manipulation, a capable Vision-Language-Action (VLA) foundation model is expected to faithfully generalize across tasks and platforms while ensuring cost efficiency (e.g., data and GPU hours required for adaptation). To this end, we develop LingBot-VLA with around 20,000 hours of real-world data from 9 popular dual-arm robot configurations. Through a systematic assessment on 3 robotic platforms, each completing 100 tasks with 130 post-training episodes per task, our model achieves clear superiority over competitors, showcasing its strong performance and broad generalizability. We have also built an efficient codebase, which delivers a throughput of 261 samples per second per GPU with an 8-GPU training setup, representing a 1.5~2.8$\\times$ (depending on the relied VLM base model) speedup over existing VLA-oriented codebases. The above features ensure that our model is well-suited for real-world deployment. To advance the field of robot learning, we provide open access to the code, base model, and benchmark data, with a focus on enabling more challenging tasks and promoting sound evaluation standards.",
      "url": "http://arxiv.org/abs/2601.18692",
      "author": "Wei Wu, Fan Lu, Yunnan Wang, Shuai Yang, Shi Liu, Fangjing Wang, Qian Zhu, He Sun, Yong Wang, Shuailei Ma, Yiyu Ren, Kejia Zhang, Hui Yu, Jingmei Zhao, Shuai Zhou, Zhenqi Qiu, Houlong Xiong, Ziyu Wang, Zechen Wang, Ran Cheng, Yong-Lu Li, Yongtao Huang, Xing Zhu, Yujun Shen, Kecheng Zheng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Introduces LingBot-VLA, a VLA foundation model trained on ~20,000 hours of real-world data from 9 dual-arm robot configurations, evaluated on 3 platforms with 100 tasks each.",
      "importance_score": 78,
      "reasoning": "Major VLA foundation model contribution with massive real-world dataset, systematic evaluation across multiple platforms, and efficient codebase. Significant for robotics foundation models.",
      "themes": [
        "Foundation Models",
        "Vision-Language-Action",
        "Robotics",
        "Robot Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces LingBot-VLA, a VLA foundation model trained on ~20,000 hours of real-world data from 9 dual-arm robot configurations, evaluated on 3 platforms with 100 tasks each.</p>",
      "content_html": "<p>arXiv:2601.18692v1 Announce Type: cross  Abstract: Offering great potential in robotic manipulation, a capable Vision-Language-Action (VLA) foundation model is expected to faithfully generalize across tasks and platforms while ensuring cost efficiency (e.g., data and GPU hours required for adaptation). To this end, we develop LingBot-VLA with around 20,000 hours of real-world data from 9 popular dual-arm robot configurations. Through a systematic assessment on 3 robotic platforms, each completing 100 tasks with 130 post-training episodes per task, our model achieves clear superiority over competitors, showcasing its strong performance and broad generalizability. We have also built an efficient codebase, which delivers a throughput of 261 samples per second per GPU with an 8-GPU training setup, representing a 1.5~2.8$\\times$ (depending on the relied VLM base model) speedup over existing VLA-oriented codebases. The above features ensure that our model is well-suited for real-world deployment. To advance the field of robot learning, we provide open access to the code, base model, and benchmark data, with a focus on enabling more challenging tasks and promoting sound evaluation standards.</p>"
    },
    {
      "id": "a8796827ef90",
      "title": "AlgZoo: uninterpreted models with fewer than 1,500 parameters",
      "content": "This post covers work done by several researchers at, visitors to and collaborators of ARC, including Zihao Chen, George Robinson, David Matolcsi, Jacob Stavrianos, Jiawei Li and Michael Sklar. Thanks to Aryan Bhatt, Gabriel Wu, Jiawei Li, Lee Sharkey, Victor Lecomte and Zihao Chen for comments. In the wake of recent debate about pragmatic versus ambitious visions for mechanistic interpretability, ARC is sharing some models we've been studying that, in spite of their tiny size, serve as challenging test cases for any ambitious interpretability vision. The models are RNNs and transformers trained to perform algorithmic tasks, and range in size from 8 to 1,408 parameters. The largest model that we believe we more-or-less fully understand has 32 parameters; the next largest model that we have put substantial effort into, but have failed to fully understand, has 432 parameters. The models are available here: [ AlgZoo GitHub repo ] We think that the \"ambitious\" side of the mechanistic interpretability community has historically underinvested in \"fully understanding slightly complex models\" compared to \"partially understanding incredibly complex models\". There has been some prior work aimed at full understanding, for instance on models trained to perform paren balancing, modular addition and more general group operations, but we still don't think the field is close to being able to fully understand our models (at least, not in the sense we discuss in this post). If we are going to one day fully understand multi-billion-parameter LLMs, we probably first need to reach the point where fully understanding models with a few hundred parameters is pretty easy; we hope that AlgZoo will spur research to either help us reach that point, or help us reckon with the magnitude of the challenge we face. One likely reason for this underinvestment is lingering philosophical confusion over the meaning of \"explanation\" and \"full understanding\". Our current perspective at ARC is that, given ...",
      "url": "https://www.lesswrong.com/posts/x8BbjZqooS4LFXS8Z/algzoo-uninterpreted-models-with-fewer-than-1-500-parameters",
      "author": "Jacob_Hilton",
      "published": "2026-01-26T12:30:15.501000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "ARC releases AlgZoo, a collection of tiny algorithmic models (8-1,408 parameters) as challenging benchmarks for mechanistic interpretability. Reveals that even 432-parameter models remain not fully understood despite substantial effort, while 32-parameter models are tractable.",
      "importance_score": 78,
      "reasoning": "Significant contribution to mechanistic interpretability research from credible organization. Provides concrete evidence about interpretability difficulty scaling and useful benchmarks. Supports 'ambitious interpretability' research agenda.",
      "themes": [
        "Mechanistic Interpretability",
        "AI Safety",
        "Benchmarks",
        "ARC Research"
      ],
      "continuation": null,
      "summary_html": "<p>ARC releases AlgZoo, a collection of tiny algorithmic models (8-1,408 parameters) as challenging benchmarks for mechanistic interpretability. Reveals that even 432-parameter models remain not fully understood despite substantial effort, while 32-parameter models are tractable.</p>",
      "content_html": "<p>This post covers work done by several researchers at, visitors to and collaborators of ARC, including Zihao Chen, George Robinson, David Matolcsi, Jacob Stavrianos, Jiawei Li and Michael Sklar. Thanks to Aryan Bhatt, Gabriel Wu, Jiawei Li, Lee Sharkey, Victor Lecomte and Zihao Chen for comments. In the wake of recent debate about pragmatic versus ambitious visions for mechanistic interpretability, ARC is sharing some models we've been studying that, in spite of their tiny size, serve as challenging test cases for any ambitious interpretability vision. The models are RNNs and transformers trained to perform algorithmic tasks, and range in size from 8 to 1,408 parameters. The largest model that we believe we more-or-less fully understand has 32 parameters; the next largest model that we have put substantial effort into, but have failed to fully understand, has 432 parameters. The models are available here: [ AlgZoo GitHub repo ] We think that the \"ambitious\" side of the mechanistic interpretability community has historically underinvested in \"fully understanding slightly complex models\" compared to \"partially understanding incredibly complex models\". There has been some prior work aimed at full understanding, for instance on models trained to perform paren balancing, modular addition and more general group operations, but we still don't think the field is close to being able to fully understand our models (at least, not in the sense we discuss in this post). If we are going to one day fully understand multi-billion-parameter LLMs, we probably first need to reach the point where fully understanding models with a few hundred parameters is pretty easy; we hope that AlgZoo will spur research to either help us reach that point, or help us reckon with the magnitude of the challenge we face. One likely reason for this underinvestment is lingering philosophical confusion over the meaning of \"explanation\" and \"full understanding\". Our current perspective at ARC is that, given ...</p>"
    },
    {
      "id": "05bb8c6730b2",
      "title": "Expert Evaluation and the Limits of Human Feedback in Mental Health AI Safety Testing",
      "content": "arXiv:2601.18061v1 Announce Type: new  Abstract: Learning from human feedback~(LHF) assumes that expert judgments, appropriately aggregated, yield valid ground truth for training and evaluating AI systems. We tested this assumption in mental health, where high safety stakes make expert consensus essential. Three certified psychiatrists independently evaluated LLM-generated responses using a calibrated rubric. Despite similar training and shared instructions, inter-rater reliability was consistently poor ($ICC$ $0.087$--$0.295$), falling below thresholds considered acceptable for consequential assessment. Disagreement was highest on the most safety-critical items. Suicide and self-harm responses produced greater divergence than any other category, and was systematic rather than random. One factor yielded negative reliability (Krippendorff's $\\alpha = -0.203$), indicating structured disagreement worse than chance. Qualitative interviews revealed that disagreement reflects coherent but incompatible individual clinical frameworks, safety-first, engagement-centered, and culturally-informed orientations, rather than measurement error. By demonstrating that experts rely on holistic risk heuristics rather than granular factor discrimination, these findings suggest that aggregated labels function as arithmetic compromises that effectively erase grounded professional philosophies. Our results characterize expert disagreement in safety-critical AI as a sociotechnical phenomenon where professional experience introduces sophisticated layers of principled divergence. We discuss implications for reward modeling, safety classification, and evaluation benchmarks, recommending that practitioners shift from consensus-based aggregation to alignment methods that preserve and learn from expert disagreement.",
      "url": "http://arxiv.org/abs/2601.18061",
      "author": "Kiana Jafari, Paul Ulrich Nikolaus Rust, Duncan Eddy, Robbie Fraser, Nina Vasan, Darja Djordjevic, Akanksha Dadlani, Max Lamparth, Eugenia Kim, Mykel Kochenderfer",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Finds that three certified psychiatrists showed poor inter-rater reliability (ICC 0.087-0.295) evaluating LLM mental health responses, with highest disagreement on suicide/self-harm content, challenging human feedback assumptions.",
      "importance_score": 77,
      "reasoning": "Critical finding challenging foundations of RLHF in high-stakes domains; has major implications for mental health AI safety evaluation.",
      "themes": [
        "AI Safety",
        "Healthcare AI",
        "Human Feedback",
        "Evaluation Methodology"
      ],
      "continuation": null,
      "summary_html": "<p>Finds that three certified psychiatrists showed poor inter-rater reliability (ICC 0.087-0.295) evaluating LLM mental health responses, with highest disagreement on suicide/self-harm content, challenging human feedback assumptions.</p>",
      "content_html": "<p>arXiv:2601.18061v1 Announce Type: new  Abstract: Learning from human feedback~(LHF) assumes that expert judgments, appropriately aggregated, yield valid ground truth for training and evaluating AI systems. We tested this assumption in mental health, where high safety stakes make expert consensus essential. Three certified psychiatrists independently evaluated LLM-generated responses using a calibrated rubric. Despite similar training and shared instructions, inter-rater reliability was consistently poor ($ICC$ $0.087$--$0.295$), falling below thresholds considered acceptable for consequential assessment. Disagreement was highest on the most safety-critical items. Suicide and self-harm responses produced greater divergence than any other category, and was systematic rather than random. One factor yielded negative reliability (Krippendorff's $\\alpha = -0.203$), indicating structured disagreement worse than chance. Qualitative interviews revealed that disagreement reflects coherent but incompatible individual clinical frameworks, safety-first, engagement-centered, and culturally-informed orientations, rather than measurement error. By demonstrating that experts rely on holistic risk heuristics rather than granular factor discrimination, these findings suggest that aggregated labels function as arithmetic compromises that effectively erase grounded professional philosophies. Our results characterize expert disagreement in safety-critical AI as a sociotechnical phenomenon where professional experience introduces sophisticated layers of principled divergence. We discuss implications for reward modeling, safety classification, and evaluation benchmarks, recommending that practitioners shift from consensus-based aggregation to alignment methods that preserve and learn from expert disagreement.</p>"
    },
    {
      "id": "1f7f2b92dc4e",
      "title": "A Systemic Evaluation of Multimodal RAG Privacy",
      "content": "arXiv:2601.17644v1 Announce Type: cross  Abstract: The growing adoption of multimodal Retrieval-Augmented Generation (mRAG) pipelines for vision-centric tasks (e.g. visual QA) introduces important privacy challenges. In particular, while mRAG provides a practical capability to connect private datasets to improve model performance, it risks the leakage of private information from these datasets during inference. In this paper, we perform an empirical study to analyze the privacy risks inherent in the mRAG pipeline observed through standard model prompting. Specifically, we implement a case study that attempts to infer the inclusion of a visual asset, e.g. image, in the mRAG, and if present leak the metadata, e.g. caption, related to it. Our findings highlight the need for privacy-preserving mechanisms and motivate future research on mRAG privacy.",
      "url": "http://arxiv.org/abs/2601.17644",
      "author": "Ali Al-Lawati, Suhang Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Empirical study of privacy risks in multimodal RAG pipelines, demonstrating ability to infer image inclusion and leak associated metadata through standard prompting.",
      "importance_score": 77,
      "reasoning": "First systematic privacy analysis of mRAG. As mRAG adoption grows, these risks become more relevant. Practical attack scenarios.",
      "themes": [
        "RAG Privacy",
        "Multimodal AI",
        "AI Security"
      ],
      "continuation": null,
      "summary_html": "<p>Empirical study of privacy risks in multimodal RAG pipelines, demonstrating ability to infer image inclusion and leak associated metadata through standard prompting.</p>",
      "content_html": "<p>arXiv:2601.17644v1 Announce Type: cross  Abstract: The growing adoption of multimodal Retrieval-Augmented Generation (mRAG) pipelines for vision-centric tasks (e.g. visual QA) introduces important privacy challenges. In particular, while mRAG provides a practical capability to connect private datasets to improve model performance, it risks the leakage of private information from these datasets during inference. In this paper, we perform an empirical study to analyze the privacy risks inherent in the mRAG pipeline observed through standard model prompting. Specifically, we implement a case study that attempts to infer the inclusion of a visual asset, e.g. image, in the mRAG, and if present leak the metadata, e.g. caption, related to it. Our findings highlight the need for privacy-preserving mechanisms and motivate future research on mRAG privacy.</p>"
    },
    {
      "id": "3f5adadbf258",
      "title": "POPE: Learning to Reason on Hard Problems via Privileged On-Policy Exploration",
      "content": "arXiv:2601.18779v1 Announce Type: cross  Abstract: Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without improving solvability. A natural alternative is to leverage transfer from easier problems. However, we show that mixing easy and hard problems during RL training is counterproductive due to ray interference, where optimization focuses on already-solvable problems in a way that actively inhibits progress on harder ones. To address this challenge, we introduce Privileged On-Policy Exploration (POPE), an approach that leverages human- or other oracle solutions as privileged information to guide exploration on hard problems, unlike methods that use oracle solutions as training targets (e.g., off-policy RL methods or warmstarting from SFT). POPE augments hard problems with prefixes of oracle solutions, enabling RL to obtain non-zero rewards during guided rollouts. Crucially, the resulting behaviors transfer back to the original, unguided problems through a synergy between instruction-following and reasoning. Empirically, POPE expands the set of solvable problems and substantially improves performance on challenging reasoning benchmarks.",
      "url": "http://arxiv.org/abs/2601.18779",
      "author": "Yuxiao Qu, Amrith Setlur, Virginia Smith, Ruslan Salakhutdinov, Aviral Kumar",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces POPE (Privileged On-Policy Exploration) for RL on hard problems where standard on-policy rarely finds correct solutions. Uses privileged policy with longer compute budget for exploration, then distills.",
      "importance_score": 77,
      "reasoning": "Addresses fundamental exploration problem in RL for reasoning. Shows natural solutions (entropy, clipping) fail. Privileged exploration is principled solution.",
      "themes": [
        "Reinforcement Learning",
        "Exploration",
        "LLM Reasoning",
        "Hard Problems"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces POPE (Privileged On-Policy Exploration) for RL on hard problems where standard on-policy rarely finds correct solutions. Uses privileged policy with longer compute budget for exploration, then distills.</p>",
      "content_html": "<p>arXiv:2601.18779v1 Announce Type: cross  Abstract: Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without improving solvability. A natural alternative is to leverage transfer from easier problems. However, we show that mixing easy and hard problems during RL training is counterproductive due to ray interference, where optimization focuses on already-solvable problems in a way that actively inhibits progress on harder ones. To address this challenge, we introduce Privileged On-Policy Exploration (POPE), an approach that leverages human- or other oracle solutions as privileged information to guide exploration on hard problems, unlike methods that use oracle solutions as training targets (e.g., off-policy RL methods or warmstarting from SFT). POPE augments hard problems with prefixes of oracle solutions, enabling RL to obtain non-zero rewards during guided rollouts. Crucially, the resulting behaviors transfer back to the original, unguided problems through a synergy between instruction-following and reasoning. Empirically, POPE expands the set of solvable problems and substantially improves performance on challenging reasoning benchmarks.</p>"
    },
    {
      "id": "9eb0a878d6f9",
      "title": "From Chains to DAGs: Probing the Graph Structure of Reasoning in LLMs",
      "content": "arXiv:2601.17593v1 Announce Type: new  Abstract: Recent progress in large language models has renewed interest in mechanistically characterizing how multi-step reasoning is represented and computed. While much prior work treats reasoning as a linear chain of steps, many reasoning problems are more naturally structured as directed acyclic graphs (DAGs), where intermediate conclusions may depend on multiple premises, branch into parallel sub-derivations, and later merge or be reused. Understanding whether such graph-structured reasoning is reflected in model internals remains an open question.   In this work, we introduce Reasoning DAG Probing, a framework that directly asks whether LLM hidden states encode the geometry of a reasoning DAG in a linearly accessible form, and where this structure emerges across layers. Within this framework, we associate each reasoning node with a textual realization and train lightweight probes to predict two graph-theoretic properties from hidden states: node depth and pairwise node distance. We use these probes to analyze the layerwise emergence of DAG structure and evaluate controls that disrupt reasoning-relevant structure while preserving superficial textual properties. Our results provide evidence that reasoning DAG geometry is meaningfully encoded in intermediate layers, with recoverability varying systematically by node depth and model scale, suggesting that LLM reasoning is not only sequential but exhibits measurable internal graph structure.",
      "url": "http://arxiv.org/abs/2601.17593",
      "author": "Tianjun Zhong, Linyang He, Nima Mesgarani",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces Reasoning DAG Probing framework to test whether LLM hidden states encode the geometry of directed acyclic graph reasoning structures in a linearly accessible form. Examines where this structure emerges across layers.",
      "importance_score": 77,
      "reasoning": "Novel mechanistic interpretability framework addressing fundamental question about reasoning representation. Important for understanding compositional reasoning.",
      "themes": [
        "Interpretability",
        "Reasoning",
        "Mechanistic Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Reasoning DAG Probing framework to test whether LLM hidden states encode the geometry of directed acyclic graph reasoning structures in a linearly accessible form. Examines where this structure emerges across layers.</p>",
      "content_html": "<p>arXiv:2601.17593v1 Announce Type: new  Abstract: Recent progress in large language models has renewed interest in mechanistically characterizing how multi-step reasoning is represented and computed. While much prior work treats reasoning as a linear chain of steps, many reasoning problems are more naturally structured as directed acyclic graphs (DAGs), where intermediate conclusions may depend on multiple premises, branch into parallel sub-derivations, and later merge or be reused. Understanding whether such graph-structured reasoning is reflected in model internals remains an open question.   In this work, we introduce Reasoning DAG Probing, a framework that directly asks whether LLM hidden states encode the geometry of a reasoning DAG in a linearly accessible form, and where this structure emerges across layers. Within this framework, we associate each reasoning node with a textual realization and train lightweight probes to predict two graph-theoretic properties from hidden states: node depth and pairwise node distance. We use these probes to analyze the layerwise emergence of DAG structure and evaluate controls that disrupt reasoning-relevant structure while preserving superficial textual properties. Our results provide evidence that reasoning DAG geometry is meaningfully encoded in intermediate layers, with recoverability varying systematically by node depth and model scale, suggesting that LLM reasoning is not only sequential but exhibits measurable internal graph structure.</p>"
    },
    {
      "id": "ee1df324f0af",
      "title": "Mechanistic Analysis of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning",
      "content": "arXiv:2601.18699v1 Announce Type: cross  Abstract: Large language models exhibit remarkable performance across diverse tasks through pre-training and fine-tuning paradigms. However, continual fine-tuning on sequential tasks induces catastrophic forgetting, where newly acquired knowledge interferes with previously learned capabilities. Despite widespread observations of this phenomenon, the mechanistic understanding remains limited. Here, we present a comprehensive mechanistic analysis of catastrophic forgetting in transformer-based LLMs during sequential fine-tuning. Through systematic experiments across multiple model scales (109B to 400B total parameters) and task sequences, we identify three primary mechanisms driving forgetting: gradient interference in attention weights, representational drift in intermediate layers, and loss landscape flattening. We demonstrate that forgetting severity correlates strongly with task similarity (Pearson r = 0.87) and gradient alignment metrics. Our analysis reveals that approximately 15 to 23 percent of attention heads undergo severe disruption during fine-tuning, with lower layers showing greater susceptibility. These findings establish mechanistic foundations for developing targeted mitigation strategies in continual learning systems.",
      "url": "http://arxiv.org/abs/2601.18699",
      "author": "Olaf Yunus Laitinen Imanov",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Presents comprehensive mechanistic analysis of catastrophic forgetting across model scales (109B-400B parameters), identifying three mechanisms: gradient interference in attention, representation drift in FFN layers, and attention pattern disruption.",
      "importance_score": 77,
      "reasoning": "Important interpretability research providing mechanistic understanding of catastrophic forgetting at scale. Valuable for developing mitigation strategies.",
      "themes": [
        "Interpretability",
        "Catastrophic Forgetting",
        "Mechanistic Analysis",
        "LLMs"
      ],
      "continuation": null,
      "summary_html": "<p>Presents comprehensive mechanistic analysis of catastrophic forgetting across model scales (109B-400B parameters), identifying three mechanisms: gradient interference in attention, representation drift in FFN layers, and attention pattern disruption.</p>",
      "content_html": "<p>arXiv:2601.18699v1 Announce Type: cross  Abstract: Large language models exhibit remarkable performance across diverse tasks through pre-training and fine-tuning paradigms. However, continual fine-tuning on sequential tasks induces catastrophic forgetting, where newly acquired knowledge interferes with previously learned capabilities. Despite widespread observations of this phenomenon, the mechanistic understanding remains limited. Here, we present a comprehensive mechanistic analysis of catastrophic forgetting in transformer-based LLMs during sequential fine-tuning. Through systematic experiments across multiple model scales (109B to 400B total parameters) and task sequences, we identify three primary mechanisms driving forgetting: gradient interference in attention weights, representational drift in intermediate layers, and loss landscape flattening. We demonstrate that forgetting severity correlates strongly with task similarity (Pearson r = 0.87) and gradient alignment metrics. Our analysis reveals that approximately 15 to 23 percent of attention heads undergo severe disruption during fine-tuning, with lower layers showing greater susceptibility. These findings establish mechanistic foundations for developing targeted mitigation strategies in continual learning systems.</p>"
    },
    {
      "id": "4093d0fe1b9b",
      "title": "Neuro-Symbolic Verification on Instruction Following of LLMs",
      "content": "arXiv:2601.17789v1 Announce Type: new  Abstract: A fundamental problem of applying Large Language Models (LLMs) to important applications is that LLMs do not always follow instructions, and violations are often hard to observe or check. In LLM-based agentic workflows, such violations can propagate and amplify along reasoning chains, causing task failures and system incidents. This paper presents NSVIF, a neuro-symbolic framework for verifying whether an LLM's output follows the instructions used to prompt the LLM. NSVIF is a universal, general-purpose verifier; it makes no assumption about the instruction or the LLM. NSVIF formulates instruction-following verification as a constraint-satisfaction problem by modeling user instructions as constraints. NSVIF models both logical and semantic constraints; constraint solving is done by a unified solver that orchestrates logical reasoning and semantic analysis. To evaluate NSVIF, we develop VIFBENCH, a new benchmark for instruction-following verifiers with fine-grained data labels. Experiments show that NSVIF significantly outperforms LLM-based approaches and provides interpretable feedback. We also show that feedback from NSVIF helps improve LLMs' instruction-following capability without post-training.",
      "url": "http://arxiv.org/abs/2601.17789",
      "author": "Yiming Su, Kunzhao Xu, Yanjie Gao, Fan Yang, Cheng Li, Mao Yang, Tianyin Xu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Presents NSVIF, a neuro-symbolic framework for verifying LLM instruction-following by modeling instructions as constraints and checking both logical and semantic constraint satisfaction.",
      "importance_score": 76,
      "reasoning": "Important practical contribution for LLM reliability; universal verifier approach addresses key deployment challenge in agentic workflows.",
      "themes": [
        "Instruction Following",
        "Verification",
        "Neuro-Symbolic AI",
        "AI Safety"
      ],
      "continuation": null,
      "summary_html": "<p>Presents NSVIF, a neuro-symbolic framework for verifying LLM instruction-following by modeling instructions as constraints and checking both logical and semantic constraint satisfaction.</p>",
      "content_html": "<p>arXiv:2601.17789v1 Announce Type: new  Abstract: A fundamental problem of applying Large Language Models (LLMs) to important applications is that LLMs do not always follow instructions, and violations are often hard to observe or check. In LLM-based agentic workflows, such violations can propagate and amplify along reasoning chains, causing task failures and system incidents. This paper presents NSVIF, a neuro-symbolic framework for verifying whether an LLM's output follows the instructions used to prompt the LLM. NSVIF is a universal, general-purpose verifier; it makes no assumption about the instruction or the LLM. NSVIF formulates instruction-following verification as a constraint-satisfaction problem by modeling user instructions as constraints. NSVIF models both logical and semantic constraints; constraint solving is done by a unified solver that orchestrates logical reasoning and semantic analysis. To evaluate NSVIF, we develop VIFBENCH, a new benchmark for instruction-following verifiers with fine-grained data labels. Experiments show that NSVIF significantly outperforms LLM-based approaches and provides interpretable feedback. We also show that feedback from NSVIF helps improve LLMs' instruction-following capability without post-training.</p>"
    },
    {
      "id": "1910b969c8fb",
      "title": "An Experimental Comparison of Cognitive Forcing Functions for Execution Plans in AI-Assisted Writing: Effects On Trust, Overreliance, and Perceived Critical Thinking",
      "content": "arXiv:2601.18033v1 Announce Type: cross  Abstract: Generative AI (GenAI) tools improve productivity in knowledge workflows such as writing, but also risk overreliance and reduced critical thinking. Cognitive forcing functions (CFFs) mitigate these risks by requiring active engagement with AI output. As GenAI workflows grow more complex, systems increasingly present execution plans for user review. However, these plans are themselves AI-generated and prone to overreliance, and the effectiveness of applying CFFs to AI plans remains underexplored. We conduct a controlled experiment in which participants completed AI-assisted writing tasks while reviewing AI-generated plans under four CFF conditions: Assumption (argument analysis), WhatIf (hypothesis testing), Both, and a no-CFF control. A follow-up think-aloud and interview study qualitatively compared these conditions. Results show that the Assumption CFF most effectively reduced overreliance without increasing cognitive load, while participants perceived the WhatIf CFF as most helpful. These findings highlight the value of plan-focused CFFs for supporting critical reflection in GenAI-assisted knowledge work.",
      "url": "http://arxiv.org/abs/2601.18033",
      "author": "Ahana Ghosh, Advait Sarkar, Si\\^an Lindley, Christian Poelitz",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.HC"
      ],
      "summary": "Controlled experiment testing cognitive forcing functions (CFFs) for AI-generated execution plans in writing tasks. Tests assumption analysis and hypothesis testing interventions against overreliance.",
      "importance_score": 76,
      "reasoning": "Important human-AI interaction research. CFFs for AI plans (not just outputs) is novel. Addresses overreliance problem systematically.",
      "themes": [
        "Human-AI Interaction",
        "Cognitive Science",
        "AI Overreliance"
      ],
      "continuation": null,
      "summary_html": "<p>Controlled experiment testing cognitive forcing functions (CFFs) for AI-generated execution plans in writing tasks. Tests assumption analysis and hypothesis testing interventions against overreliance.</p>",
      "content_html": "<p>arXiv:2601.18033v1 Announce Type: cross  Abstract: Generative AI (GenAI) tools improve productivity in knowledge workflows such as writing, but also risk overreliance and reduced critical thinking. Cognitive forcing functions (CFFs) mitigate these risks by requiring active engagement with AI output. As GenAI workflows grow more complex, systems increasingly present execution plans for user review. However, these plans are themselves AI-generated and prone to overreliance, and the effectiveness of applying CFFs to AI plans remains underexplored. We conduct a controlled experiment in which participants completed AI-assisted writing tasks while reviewing AI-generated plans under four CFF conditions: Assumption (argument analysis), WhatIf (hypothesis testing), Both, and a no-CFF control. A follow-up think-aloud and interview study qualitatively compared these conditions. Results show that the Assumption CFF most effectively reduced overreliance without increasing cognitive load, while participants perceived the WhatIf CFF as most helpful. These findings highlight the value of plan-focused CFFs for supporting critical reflection in GenAI-assisted knowledge work.</p>"
    },
    {
      "id": "204e04111d71",
      "title": "Code over Words: Overcoming Semantic Inertia via Code-Grounded Reasoning",
      "content": "arXiv:2601.18352v1 Announce Type: cross  Abstract: LLMs struggle with Semantic Inertia: the inability to inhibit pre-trained priors (e.g., \"Lava is Dangerous\") when dynamic, in-context rules contradict them. We probe this phenomenon using Baba Is You, where physical laws are mutable text rules, enabling precise evaluation of models' ability to override learned priors when rules change. We quantatively observe that larger models can exhibit inverse scaling: they perform worse than smaller models when natural language reasoning requires suppressing pre-trained associations (e.g., accepting \"Lava is Safe\"). Our analysis attributes this to natural language encoding, which entangles descriptive semantics and logical rules, leading to persistent hallucinations of familiar physics despite explicit contradictory rules. Here we show that representing dynamics as executable code, rather than descriptive text, reverses this trend and enables effective prior inhibition. We introduce Code-Grounded Vistas (LCV), which fine-tunes models on counterfactual pairs and identifies states with contradictory rules, thereby forcing attention to logical constraints rather than visual semantics. This training-time approach outperforms expensive inference-time search methods in both efficiency and accuracy. Our results demonstrate that representation fundamentally determines whether scaling improves or impairs contextual reasoning. This challenges the assumption that larger models are universally better, with implications for domains that require dynamic overriding of learned priors.",
      "url": "http://arxiv.org/abs/2601.18352",
      "author": "Manjie Xu, Isabella Yin, Xinyi Tu, Chi Zhang, Yixin Zhu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Discovers 'Semantic Inertia' - LLMs' inability to override pre-trained priors (e.g., 'Lava is Dangerous') when in-context rules contradict them. Using Baba Is You game, shows larger models exhibit inverse scaling on such tasks.",
      "importance_score": 76,
      "reasoning": "Important finding about fundamental LLM limitation. Inverse scaling is significant - larger models worse at suppressing priors. Code-grounded reasoning proposed as solution.",
      "themes": [
        "LLM Limitations",
        "In-Context Learning",
        "Inverse Scaling",
        "Reasoning"
      ],
      "continuation": null,
      "summary_html": "<p>Discovers 'Semantic Inertia' - LLMs' inability to override pre-trained priors (e.g., 'Lava is Dangerous') when in-context rules contradict them. Using Baba Is You game, shows larger models exhibit inverse scaling on such tasks.</p>",
      "content_html": "<p>arXiv:2601.18352v1 Announce Type: cross  Abstract: LLMs struggle with Semantic Inertia: the inability to inhibit pre-trained priors (e.g., \"Lava is Dangerous\") when dynamic, in-context rules contradict them. We probe this phenomenon using Baba Is You, where physical laws are mutable text rules, enabling precise evaluation of models' ability to override learned priors when rules change. We quantatively observe that larger models can exhibit inverse scaling: they perform worse than smaller models when natural language reasoning requires suppressing pre-trained associations (e.g., accepting \"Lava is Safe\"). Our analysis attributes this to natural language encoding, which entangles descriptive semantics and logical rules, leading to persistent hallucinations of familiar physics despite explicit contradictory rules. Here we show that representing dynamics as executable code, rather than descriptive text, reverses this trend and enables effective prior inhibition. We introduce Code-Grounded Vistas (LCV), which fine-tunes models on counterfactual pairs and identifies states with contradictory rules, thereby forcing attention to logical constraints rather than visual semantics. This training-time approach outperforms expensive inference-time search methods in both efficiency and accuracy. Our results demonstrate that representation fundamentally determines whether scaling improves or impairs contextual reasoning. This challenges the assumption that larger models are universally better, with implications for domains that require dynamic overriding of learned priors.</p>"
    },
    {
      "id": "e0db23dc2be4",
      "title": "Gained in Translation: Privileged Pairwise Judges Enhance Multilingual Reasoning",
      "content": "arXiv:2601.18722v1 Announce Type: new  Abstract: When asked a question in a language less seen in its training data, current reasoning large language models (RLMs) often exhibit dramatically lower performance than when asked the same question in English. In response, we introduce \\texttt{SP3F} (Self-Play with Privileged Pairwise Feedback), a two-stage framework for enhancing multilingual reasoning without \\textit{any} data in the target language(s). First, we supervise fine-tune (SFT) on translated versions of English question-answer pairs to raise base model correctness. Second, we perform RL with feedback from a pairwise judge in a self-play fashion, with the judge receiving the English reference response as \\textit{privileged information}. Thus, even when none of the model's responses are completely correct, the privileged pairwise judge can still tell which response is better. End-to-end, \\texttt{SP3F} greatly improves base model performance, even outperforming fully post-trained models on multiple math and non-math tasks with less than   of the training data across the single-language, multilingual, and generalization to unseen language settings.",
      "url": "http://arxiv.org/abs/2601.18722",
      "author": "Lintang Sutawika, Gokul Swamy, Zhiwei Steven Wu, Graham Neubig",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces SP3F framework for multilingual reasoning enhancement using self-play with privileged pairwise feedback from judges receiving English reference responses. Achieves improvements without target language data.",
      "importance_score": 76,
      "reasoning": "Important contribution to multilingual reasoning with novel privileged feedback mechanism. Practical zero-shot approach to language transfer.",
      "themes": [
        "Multilingual NLP",
        "Reasoning",
        "Reinforcement Learning",
        "Self-Play"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces SP3F framework for multilingual reasoning enhancement using self-play with privileged pairwise feedback from judges receiving English reference responses. Achieves improvements without target language data.</p>",
      "content_html": "<p>arXiv:2601.18722v1 Announce Type: new  Abstract: When asked a question in a language less seen in its training data, current reasoning large language models (RLMs) often exhibit dramatically lower performance than when asked the same question in English. In response, we introduce \\texttt{SP3F} (Self-Play with Privileged Pairwise Feedback), a two-stage framework for enhancing multilingual reasoning without \\textit{any} data in the target language(s). First, we supervise fine-tune (SFT) on translated versions of English question-answer pairs to raise base model correctness. Second, we perform RL with feedback from a pairwise judge in a self-play fashion, with the judge receiving the English reference response as \\textit{privileged information}. Thus, even when none of the model's responses are completely correct, the privileged pairwise judge can still tell which response is better. End-to-end, \\texttt{SP3F} greatly improves base model performance, even outperforming fully post-trained models on multiple math and non-math tasks with less than   of the training data across the single-language, multilingual, and generalization to unseen language settings.</p>"
    },
    {
      "id": "03e1daa9be9c",
      "title": "$\\infty$-MoE: Generalizing Mixture of Experts to Infinite Experts",
      "content": "arXiv:2601.17680v1 Announce Type: cross  Abstract: The Mixture of Experts (MoE) selects a few feed-forward networks (FFNs) per token, achieving an effective trade-off between computational cost and performance. In conventional MoE, each expert is treated as entirely independent, and experts are combined in a discrete space. As a result, when the number of experts increases, it becomes difficult to train each expert effectively. To stabilize training while increasing the number of experts, we propose $\\infty$-MoE that selects a portion of the parameters of large FFNs based on continuous values sampled for each token. By considering experts in a continuous space, this approach allows for an infinite number of experts while maintaining computational efficiency. Experiments show that a GPT-2 Small-based $\\infty$-MoE model, with 129M active and 186M total parameters, achieves comparable performance to a dense GPT-2 Medium with 350M parameters. Adjusting the number of sampled experts at inference time allows for a flexible trade-off between accuracy and speed, with an improvement of up to 2.5\\% in accuracy over conventional MoE.",
      "url": "http://arxiv.org/abs/2601.17680",
      "author": "Shota Takashiro, Takeshi Kojima, Shohei Taniguchi, Yusuke Iwasawa, Yutaka Matsuo",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes -MoE, generalizing Mixture of Experts to infinite experts by selecting parameters from large FFNs based on continuous values rather than discrete expert selection. Enables more effective training when scaling expert count.",
      "importance_score": 76,
      "reasoning": "Novel architectural contribution addressing fundamental MoE scaling limitations. Continuous expert space is innovative approach with efficiency implications.",
      "themes": [
        "Architecture",
        "Mixture of Experts",
        "Efficiency",
        "Scaling"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes -MoE, generalizing Mixture of Experts to infinite experts by selecting parameters from large FFNs based on continuous values rather than discrete expert selection. Enables more effective training when scaling expert count.</p>",
      "content_html": "<p>arXiv:2601.17680v1 Announce Type: cross  Abstract: The Mixture of Experts (MoE) selects a few feed-forward networks (FFNs) per token, achieving an effective trade-off between computational cost and performance. In conventional MoE, each expert is treated as entirely independent, and experts are combined in a discrete space. As a result, when the number of experts increases, it becomes difficult to train each expert effectively. To stabilize training while increasing the number of experts, we propose $\\infty$-MoE that selects a portion of the parameters of large FFNs based on continuous values sampled for each token. By considering experts in a continuous space, this approach allows for an infinite number of experts while maintaining computational efficiency. Experiments show that a GPT-2 Small-based $\\infty$-MoE model, with 129M active and 186M total parameters, achieves comparable performance to a dense GPT-2 Medium with 350M parameters. Adjusting the number of sampled experts at inference time allows for a flexible trade-off between accuracy and speed, with an improvement of up to 2.5\\% in accuracy over conventional MoE.</p>"
    },
    {
      "id": "057e4c501fa0",
      "title": "High-Fidelity Longitudinal Patient Simulation Using Real-World Data",
      "content": "arXiv:2601.17310v1 Announce Type: new  Abstract: Simulation is a powerful tool for exploring uncertainty. Its potential in clinical medicine is transformative and includes personalized treatment planning and virtual clinical trials. However, simulating patient trajectories is challenging because of complex biological and sociocultural influences. Here, we show that real-world clinical records can be leveraged to empirically model patient timelines. We developed a generative simulator model that takes a patient's history as input and synthesizes fine-grained, realistic future trajectories. The model was pretrained on more than 200 million clinical records. It produced high-fidelity future timelines, closely matching event occurrence rates, laboratory test results, and temporal dynamics in real patient future data. It also accurately estimated future event probabilities, with observed-to-expected ratios consistently near 1.0 across diverse outcomes and time horizons. Our results reveal the untapped value of real-world data in electronic health records and introduce a scalable framework for in silico modeling of clinical care.",
      "url": "http://arxiv.org/abs/2601.17310",
      "author": "Yu Akagi, Tomohisa Seki, Hiromasa Ito, Toru Takiguchi, Kazuhiko Ohe, Yoshimasa Kawazoe",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Develops a generative simulator pretrained on 200+ million clinical records that synthesizes realistic future patient trajectories, enabling personalized treatment planning and virtual clinical trials.",
      "importance_score": 75,
      "reasoning": "Large-scale healthcare AI with significant potential impact; strong methodology using real-world data at scale for clinically relevant applications.",
      "themes": [
        "Healthcare AI",
        "Generative Models",
        "Clinical Decision Support"
      ],
      "continuation": null,
      "summary_html": "<p>Develops a generative simulator pretrained on 200+ million clinical records that synthesizes realistic future patient trajectories, enabling personalized treatment planning and virtual clinical trials.</p>",
      "content_html": "<p>arXiv:2601.17310v1 Announce Type: new  Abstract: Simulation is a powerful tool for exploring uncertainty. Its potential in clinical medicine is transformative and includes personalized treatment planning and virtual clinical trials. However, simulating patient trajectories is challenging because of complex biological and sociocultural influences. Here, we show that real-world clinical records can be leveraged to empirically model patient timelines. We developed a generative simulator model that takes a patient's history as input and synthesizes fine-grained, realistic future trajectories. The model was pretrained on more than 200 million clinical records. It produced high-fidelity future timelines, closely matching event occurrence rates, laboratory test results, and temporal dynamics in real patient future data. It also accurately estimated future event probabilities, with observed-to-expected ratios consistently near 1.0 across diverse outcomes and time horizons. Our results reveal the untapped value of real-world data in electronic health records and introduce a scalable framework for in silico modeling of clinical care.</p>"
    },
    {
      "id": "d3f50ed9d1ec",
      "title": "The Viscosity of Logic: Phase Transitions and Hysteresis in DPO Alignment",
      "content": "arXiv:2601.17260v1 Announce Type: cross  Abstract: Direct Preference Optimization (DPO) is often tuned as if increasing alignment pressure (controlled by $\\beta$) yields progressively \"better\" behavior. We instead treat $\\beta$ as a control parameter and densely sweep it for three 7B open-weight families under a fixed DPO recipe. In Mistral, capability is sharply non-monotonic: aggregated logic-probe margins become positive only in a narrow band near $\\beta \\approx 10^{-2}$ and revert outside it, with boundary points that are seed-sensitive. Across architectures under the same sweep, we observe qualitatively different response modes: sharp reorganization in Mistral, selective changes in Llama, and smooth trade-offs in Qwen. Critically, the DPO preference margin can anticorrelate with reasoning capability (Pearson $r=-0.91$ for Llama logic), so margin-based selection can prefer capability-impaired models. Training path also matters: exposure to high $\\beta$ induces capability losses that persist even after $\\beta$ is reduced (hysteresis). These findings motivate capability-resolved evaluation across the $\\beta$ landscape rather than reliance on margins or aggregate benchmarks.",
      "url": "http://arxiv.org/abs/2601.17260",
      "author": "Marco Pollanen",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Studies DPO alignment by treating  as control parameter, discovering sharp non-monotonic capability changes including phase transitions and hysteresis effects across model families.",
      "importance_score": 75,
      "reasoning": "Important empirical finding revealing complex dynamics in DPO training. Has significant implications for alignment methodology and hyperparameter selection.",
      "themes": [
        "Alignment",
        "DPO",
        "Training Dynamics",
        "Phase Transitions"
      ],
      "continuation": null,
      "summary_html": "<p>Studies DPO alignment by treating  as control parameter, discovering sharp non-monotonic capability changes including phase transitions and hysteresis effects across model families.</p>",
      "content_html": "<p>arXiv:2601.17260v1 Announce Type: cross  Abstract: Direct Preference Optimization (DPO) is often tuned as if increasing alignment pressure (controlled by $\\beta$) yields progressively \"better\" behavior. We instead treat $\\beta$ as a control parameter and densely sweep it for three 7B open-weight families under a fixed DPO recipe. In Mistral, capability is sharply non-monotonic: aggregated logic-probe margins become positive only in a narrow band near $\\beta \\approx 10^{-2}$ and revert outside it, with boundary points that are seed-sensitive. Across architectures under the same sweep, we observe qualitatively different response modes: sharp reorganization in Mistral, selective changes in Llama, and smooth trade-offs in Qwen. Critically, the DPO preference margin can anticorrelate with reasoning capability (Pearson $r=-0.91$ for Llama logic), so margin-based selection can prefer capability-impaired models. Training path also matters: exposure to high $\\beta$ induces capability losses that persist even after $\\beta$ is reduced (hysteresis). These findings motivate capability-resolved evaluation across the $\\beta$ landscape rather than reliance on margins or aggregate benchmarks.</p>"
    },
    {
      "id": "988fa4bc57a2",
      "title": "treaming-dLLM: Accelerating Diffusion LLMs via Suffix Pruning and Dynamic Decoding",
      "content": "arXiv:2601.17917v1 Announce Type: cross  Abstract: Diffusion Large Language Models (dLLMs) offer a compelling paradigm for natural language generation, leveraging parallel decoding and bidirectional attention to achieve superior global coherence compared to autoregressive models. While recent works have accelerated inference via KV cache reuse or heuristic decoding, they overlook the intrinsic inefficiencies within the block-wise diffusion process. Specifically, they suffer from spatial redundancy by modeling informative-sparse suffix regions uniformly and temporal inefficiency by applying fixed denoising schedules across all the decoding process. To address this, we propose Streaming-dLLM, a training-free framework that streamlines inference across both spatial and temporal dimensions. Spatially, we introduce attenuation guided suffix modeling to approximate the full context by pruning redundant mask tokens. Temporally, we employ a dynamic confidence aware strategy with an early exit mechanism, allowing the model to skip unnecessary iterations for converged tokens. Extensive experiments show that Streaming-dLLM achieves up to 68.2X speedup while maintaining generation quality, highlighting its effectiveness in diffusion decoding. The code is available at https://github.com/xiaoshideta/Streaming-dLLM.",
      "url": "http://arxiv.org/abs/2601.17917",
      "author": "Zhongyu Xiao, Zhiwei Hao, Jianyuan Guo, Yong Luo, Jia Liu, Jie Xu, Han Hu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Streaming-dLLM accelerates diffusion language models through suffix pruning (spatial) and dynamic decoding schedules (temporal), achieving training-free efficiency improvements.",
      "importance_score": 75,
      "reasoning": "Diffusion LLMs gaining traction. Practical efficiency improvements without retraining. Addresses both spatial and temporal inefficiencies.",
      "themes": [
        "Diffusion Language Models",
        "Model Efficiency",
        "Inference Optimization"
      ],
      "continuation": null,
      "summary_html": "<p>Streaming-dLLM accelerates diffusion language models through suffix pruning (spatial) and dynamic decoding schedules (temporal), achieving training-free efficiency improvements.</p>",
      "content_html": "<p>arXiv:2601.17917v1 Announce Type: cross  Abstract: Diffusion Large Language Models (dLLMs) offer a compelling paradigm for natural language generation, leveraging parallel decoding and bidirectional attention to achieve superior global coherence compared to autoregressive models. While recent works have accelerated inference via KV cache reuse or heuristic decoding, they overlook the intrinsic inefficiencies within the block-wise diffusion process. Specifically, they suffer from spatial redundancy by modeling informative-sparse suffix regions uniformly and temporal inefficiency by applying fixed denoising schedules across all the decoding process. To address this, we propose Streaming-dLLM, a training-free framework that streamlines inference across both spatial and temporal dimensions. Spatially, we introduce attenuation guided suffix modeling to approximate the full context by pruning redundant mask tokens. Temporally, we employ a dynamic confidence aware strategy with an early exit mechanism, allowing the model to skip unnecessary iterations for converged tokens. Extensive experiments show that Streaming-dLLM achieves up to 68.2X speedup while maintaining generation quality, highlighting its effectiveness in diffusion decoding. The code is available at https://github.com/xiaoshideta/Streaming-dLLM.</p>"
    },
    {
      "id": "9d758eee209a",
      "title": "VIBEVOICE-ASR Technical Report",
      "content": "arXiv:2601.18184v1 Announce Type: cross  Abstract: This report presents VibeVoice-ASR, a general-purpose speech understanding framework built upon VibeVoice, designed to address the persistent challenges of context fragmentation and multi-speaker complexity in long-form audio (e.g., meetings, podcasts) that remain despite recent advancements in short-form speech recognition. Unlike traditional pipelined approaches that rely on audio chunking, VibeVoice-ASRsupports single-pass processing for up to 60 minutes of audio. It unifies Automatic Speech Recognition, Speaker Diarization, and Timestamping into a single end-to-end generation task. In addition, VibeVoice-ASR supports over 50 languages, requires no explicit language setting, and natively handles code-switching within and across utterances. Furthermore, we introduce a prompt-based context injection mechanism that allows users to supply customized conetxt, significantly improving accuracy on domain-specific terminology and polyphonic character disambiguation.",
      "url": "http://arxiv.org/abs/2601.18184",
      "author": "Zhiliang Peng, Jianwei Yu, Yaoyao Chang, Zilong Wang, Li Dong, Yingbo Hao, Yujie Tu, Chenyu Yang, Wenhui Wang, Songchen Xu, Yutao Sun, Hangbo Bao, Weijiang Xu, Yi Zhu, Zehua Wang, Ting Song, Yan Xia, Zewen Chi, Shaohan Huang, Liang Wang, Chuang Ding, Shuai Wang, Xie Chen, Furu Wei",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.SD"
      ],
      "summary": "Microsoft/Furu Wei team presents VibeVoice-ASR, end-to-end speech understanding framework supporting single-pass processing for up to 60 minutes of audio. Unifies ASR, speaker diarization, and timestamping across 50+ languages with code-switching support.",
      "importance_score": 75,
      "reasoning": "Strong Microsoft Research team. Significant practical advance: 60-minute single-pass processing eliminates chunking artifacts. 50+ language support with code-switching is substantial engineering achievement.",
      "themes": [
        "Speech Recognition",
        "Long-form Audio",
        "Multilingual AI",
        "Speaker Diarization"
      ],
      "continuation": null,
      "summary_html": "<p>Microsoft/Furu Wei team presents VibeVoice-ASR, end-to-end speech understanding framework supporting single-pass processing for up to 60 minutes of audio. Unifies ASR, speaker diarization, and timestamping across 50+ languages with code-switching support.</p>",
      "content_html": "<p>arXiv:2601.18184v1 Announce Type: cross  Abstract: This report presents VibeVoice-ASR, a general-purpose speech understanding framework built upon VibeVoice, designed to address the persistent challenges of context fragmentation and multi-speaker complexity in long-form audio (e.g., meetings, podcasts) that remain despite recent advancements in short-form speech recognition. Unlike traditional pipelined approaches that rely on audio chunking, VibeVoice-ASRsupports single-pass processing for up to 60 minutes of audio. It unifies Automatic Speech Recognition, Speaker Diarization, and Timestamping into a single end-to-end generation task. In addition, VibeVoice-ASR supports over 50 languages, requires no explicit language setting, and natively handles code-switching within and across utterances. Furthermore, we introduce a prompt-based context injection mechanism that allows users to supply customized conetxt, significantly improving accuracy on domain-specific terminology and polyphonic character disambiguation.</p>"
    },
    {
      "id": "6f45a624cef1",
      "title": "HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences",
      "content": "arXiv:2601.18724v1 Announce Type: cross  Abstract: Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as \"HalluCitation\" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility.",
      "url": "http://arxiv.org/abs/2601.18724",
      "author": "Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Systematic analysis finding nearly 300 papers in ACL/NAACL/EMNLP 2024-2025 contain hallucinated citations (HalluCitation) that don't correspond to existing works, with most appearing in 2025 publications.",
      "importance_score": 75,
      "reasoning": "Important meta-science finding about scientific integrity. ~300 papers with fake citations is alarming. Highly relevant given AI writing assistance proliferation.",
      "themes": [
        "Scientific Integrity",
        "Hallucinations",
        "Meta-Science",
        "AI Safety"
      ],
      "continuation": null,
      "summary_html": "<p>Systematic analysis finding nearly 300 papers in ACL/NAACL/EMNLP 2024-2025 contain hallucinated citations (HalluCitation) that don't correspond to existing works, with most appearing in 2025 publications.</p>",
      "content_html": "<p>arXiv:2601.18724v1 Announce Type: cross  Abstract: Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as \"HalluCitation\" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility.</p>"
    },
    {
      "id": "4924073d9dc9",
      "title": "Oops, Wait: Token-Level Signals as a Lens into LLM Reasoning",
      "content": "arXiv:2601.17421v1 Announce Type: new  Abstract: The emergence of discourse-like tokens such as \"wait\" and \"therefore\" in large language models (LLMs) has offered a unique window into their reasoning processes. However, systematic analyses of how such signals vary across training strategies and model scales remain lacking. In this paper, we analyze token-level signals through token probabilities across various models. We find that specific tokens strongly correlate with reasoning correctness, varying with training strategies while remaining stable across model scales. A closer look at the \"wait\" token in relation to answer probability demonstrates that models fine-tuned on small-scale datasets acquire reasoning ability through such signals but exploit them only partially. This work provides a systematic lens to observe and understand the dynamics of LLM reasoning.",
      "url": "http://arxiv.org/abs/2601.17421",
      "author": "Jaehui Hwang, Dongyoon Han, Sangdoo Yun, Byeongho Heo",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Analyzes token-level signals like 'wait' and 'therefore' in LLM reasoning, finding specific tokens strongly correlate with reasoning correctness. Shows reasoning models acquire but only partially exploit these signals.",
      "importance_score": 75,
      "reasoning": "Valuable mechanistic insight into reasoning models with practical implications. Identifies underutilized potential in fine-tuned models.",
      "themes": [
        "Interpretability",
        "Reasoning",
        "Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>Analyzes token-level signals like 'wait' and 'therefore' in LLM reasoning, finding specific tokens strongly correlate with reasoning correctness. Shows reasoning models acquire but only partially exploit these signals.</p>",
      "content_html": "<p>arXiv:2601.17421v1 Announce Type: new  Abstract: The emergence of discourse-like tokens such as \"wait\" and \"therefore\" in large language models (LLMs) has offered a unique window into their reasoning processes. However, systematic analyses of how such signals vary across training strategies and model scales remain lacking. In this paper, we analyze token-level signals through token probabilities across various models. We find that specific tokens strongly correlate with reasoning correctness, varying with training strategies while remaining stable across model scales. A closer look at the \"wait\" token in relation to answer probability demonstrates that models fine-tuned on small-scale datasets acquire reasoning ability through such signals but exploit them only partially. This work provides a systematic lens to observe and understand the dynamics of LLM reasoning.</p>"
    },
    {
      "id": "e56e73ddc9ae",
      "title": "Demographic Probing of Large Language Models Lacks Construct Validity",
      "content": "arXiv:2601.18486v1 Announce Type: new  Abstract: Demographic probing is widely used to study how large language models (LLMs) adapt their behavior to signaled demographic attributes. This approach typically uses a single demographic cue in isolation (e.g., a name or dialect) as a signal for group membership, implicitly assuming strong construct validity: that such cues are interchangeable operationalizations of the same underlying, demographically conditioned behavior. We test this assumption in realistic advice-seeking interactions, focusing on race and gender in a U.S. context. We find that cues intended to represent the same demographic group induce only partially overlapping changes in model behavior, while differentiation between groups within a given cue is weak and uneven. Consequently, estimated disparities are unstable, with both magnitude and direction varying across cues. We further show that these inconsistencies partly arise from variation in how strongly cues encode demographic attributes and from linguistic confounders that independently shape model behavior. Together, our findings suggest that demographic probing lacks construct validity: it does not yield a single, stable characterization of how LLMs condition on demographic information, which may reflect a misspecified or fragmented construct. We conclude by recommending the use of multiple, ecologically valid cues and explicit control of confounders to support more defensible claims about demographic effects in LLMs.",
      "url": "http://arxiv.org/abs/2601.18486",
      "author": "Manuel Tonneau, Neil K. R. Seghal, Niyati Malhotra, Victor Orozco-Olvera, Ana Mar\\'ia Mu\\~noz Boudet, Lakshmi Subramanian, Sharath Chandra Guntuku, Valentin Hofmann",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Demonstrates that demographic probing of LLMs lacks construct validity: different cues intended to represent the same demographic group induce only partially overlapping behavior changes.",
      "importance_score": 75,
      "reasoning": "Important methodological critique with significant implications for bias research. Shows fundamental limitations in common evaluation approaches.",
      "themes": [
        "Bias and Fairness",
        "LLM Evaluation",
        "Methodology"
      ],
      "continuation": null,
      "summary_html": "<p>Demonstrates that demographic probing of LLMs lacks construct validity: different cues intended to represent the same demographic group induce only partially overlapping behavior changes.</p>",
      "content_html": "<p>arXiv:2601.18486v1 Announce Type: new  Abstract: Demographic probing is widely used to study how large language models (LLMs) adapt their behavior to signaled demographic attributes. This approach typically uses a single demographic cue in isolation (e.g., a name or dialect) as a signal for group membership, implicitly assuming strong construct validity: that such cues are interchangeable operationalizations of the same underlying, demographically conditioned behavior. We test this assumption in realistic advice-seeking interactions, focusing on race and gender in a U.S. context. We find that cues intended to represent the same demographic group induce only partially overlapping changes in model behavior, while differentiation between groups within a given cue is weak and uneven. Consequently, estimated disparities are unstable, with both magnitude and direction varying across cues. We further show that these inconsistencies partly arise from variation in how strongly cues encode demographic attributes and from linguistic confounders that independently shape model behavior. Together, our findings suggest that demographic probing lacks construct validity: it does not yield a single, stable characterization of how LLMs condition on demographic information, which may reflect a misspecified or fragmented construct. We conclude by recommending the use of multiple, ecologically valid cues and explicit control of confounders to support more defensible claims about demographic effects in LLMs.</p>"
    },
    {
      "id": "e42b0d480abc",
      "title": "Agentic Search in the Wild: Intents and Trajectory Dynamics from 14M+ Real Search Requests",
      "content": "arXiv:2601.17617v1 Announce Type: cross  Abstract: LLM-powered search agents are increasingly being used for multi-step information seeking tasks, yet the IR community lacks empirical understanding of how agentic search sessions unfold and how retrieved evidence is used. This paper presents a large-scale log analysis of agentic search based on 14.44M search requests (3.97M sessions) collected from DeepResearchGym, i.e. an open-source search API accessed by external agentic clients. We sessionize the logs, assign session-level intents and step-wise query-reformulation labels using LLM-based annotation, and propose Context-driven Term Adoption Rate (CTAR) to quantify whether newly introduced query terms are traceable to previously retrieved evidence. Our analyses reveal distinctive behavioral patterns. First, over 90% of multi-turn sessions contain at most ten steps, and 89% of inter-step intervals fall under one minute. Second, behavior varies by intent. Fact-seeking sessions exhibit high repetition that increases over time, while sessions requiring reasoning sustain broader exploration. Third, agents reuse evidence across steps. On average, 54% of newly introduced query terms appear in the accumulated evidence context, with contributions from earlier steps beyond the most recent retrieval. The findings suggest that agentic search may benefit from repetition-aware early stopping, intent-adaptive retrieval budgets, and explicit cross-step context tracking. We plan to release the anonymized logs to support future research.",
      "url": "http://arxiv.org/abs/2601.17617",
      "author": "Jingjie Ning, Jo\\~ao Coelho, Yibo Kong, Yunfan Long, Bruno Martins, Jo\\~ao Magalh\\~aes, Jamie Callan, Chenyan Xiong",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.IR"
      ],
      "summary": "Large-scale analysis of 14.44M agentic search requests revealing distinctive behavioral patterns in LLM-powered search agents. Proposes Context-driven Term Adoption Rate (CTAR) to quantify query term origins from retrieved evidence.",
      "importance_score": 75,
      "reasoning": "Substantial empirical contribution to understanding agentic AI search behavior at unprecedented scale. Novel metrics and important behavioral insights.",
      "themes": [
        "Agentic AI",
        "Search",
        "Empirical Analysis",
        "LLM Agents"
      ],
      "continuation": null,
      "summary_html": "<p>Large-scale analysis of 14.44M agentic search requests revealing distinctive behavioral patterns in LLM-powered search agents. Proposes Context-driven Term Adoption Rate (CTAR) to quantify query term origins from retrieved evidence.</p>",
      "content_html": "<p>arXiv:2601.17617v1 Announce Type: cross  Abstract: LLM-powered search agents are increasingly being used for multi-step information seeking tasks, yet the IR community lacks empirical understanding of how agentic search sessions unfold and how retrieved evidence is used. This paper presents a large-scale log analysis of agentic search based on 14.44M search requests (3.97M sessions) collected from DeepResearchGym, i.e. an open-source search API accessed by external agentic clients. We sessionize the logs, assign session-level intents and step-wise query-reformulation labels using LLM-based annotation, and propose Context-driven Term Adoption Rate (CTAR) to quantify whether newly introduced query terms are traceable to previously retrieved evidence. Our analyses reveal distinctive behavioral patterns. First, over 90% of multi-turn sessions contain at most ten steps, and 89% of inter-step intervals fall under one minute. Second, behavior varies by intent. Fact-seeking sessions exhibit high repetition that increases over time, while sessions requiring reasoning sustain broader exploration. Third, agents reuse evidence across steps. On average, 54% of newly introduced query terms appear in the accumulated evidence context, with contributions from earlier steps beyond the most recent retrieval. The findings suggest that agentic search may benefit from repetition-aware early stopping, intent-adaptive retrieval budgets, and explicit cross-step context tracking. We plan to release the anonymized logs to support future research.</p>"
    },
    {
      "id": "7c2253fa9c7b",
      "title": "Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability",
      "content": "arXiv:2601.18778v1 Announce Type: cross  Abstract: Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data.",
      "url": "http://arxiv.org/abs/2601.18778",
      "author": "Shobhita Sundaram, John Quan, Ariel Kwiatkowski, Kartik Ahuja, Yann Ollivier, Julia Kempe",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces SOAR, a meta-RL framework where teacher model proposes synthetic problems for student copy, rewarded by student improvement on hard problems. Enables models to escape learning plateaus through self-generated curriculum.",
      "importance_score": 75,
      "reasoning": "Novel self-improvement framework addressing fundamental challenge of learning from low success rate problems. Important for reasoning model development.",
      "themes": [
        "Self-improvement",
        "Meta-learning",
        "Curriculum Learning",
        "Reasoning"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces SOAR, a meta-RL framework where teacher model proposes synthetic problems for student copy, rewarded by student improvement on hard problems. Enables models to escape learning plateaus through self-generated curriculum.</p>",
      "content_html": "<p>arXiv:2601.18778v1 Announce Type: cross  Abstract: Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data.</p>"
    },
    {
      "id": "bd058ed89297",
      "title": "Faramesh: A Protocol-Agnostic Execution Control Plane for Autonomous Agent Systems",
      "content": "arXiv:2601.17744v1 Announce Type: new  Abstract: Autonomous agent systems increasingly trigger real-world side effects: deploying infrastructure, modifying databases, moving money, and executing workflows. Yet most agent stacks provide no mandatory execution checkpoint where organizations can deterministically permit, deny, or defer an action before it changes reality. This paper introduces Faramesh, a protocol-agnostic execution control plane that enforces execution-time authorization for agent-driven actions via a non-bypassable Action Authorization Boundary (AAB). Faramesh canonicalizes agent intent into a Canonical Action Representation (CAR), evaluates actions deterministically against policy and state, and issues a decision artifact (PERMIT/DEFER/DENY) that executors must validate prior to execution. The system is designed to be framework- and model-agnostic, supports multi-agent and multi-tenant deployments, and remains independent of transport protocols (e.g., MCP). Faramesh further provides decision-centric, append-only provenance logging keyed by canonical action hashes, enabling auditability, verification, and deterministic replay without re-running agent reasoning. We show how these primitives yield enforceable, predictable governance for autonomous execution while avoiding hidden coupling to orchestration layers or observability-only approaches.",
      "url": "http://arxiv.org/abs/2601.17744",
      "author": "Amjad Fatmi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces Faramesh, a protocol-agnostic execution control plane enforcing mandatory authorization checkpoints for agent actions before they affect the real world through a non-bypassable boundary.",
      "importance_score": 74,
      "reasoning": "Critical infrastructure for safe agent deployment; addresses fundamental gap in current agent stacks for real-world safety.",
      "themes": [
        "AI Safety",
        "Agentic AI",
        "Systems Architecture"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Faramesh, a protocol-agnostic execution control plane enforcing mandatory authorization checkpoints for agent actions before they affect the real world through a non-bypassable boundary.</p>",
      "content_html": "<p>arXiv:2601.17744v1 Announce Type: new  Abstract: Autonomous agent systems increasingly trigger real-world side effects: deploying infrastructure, modifying databases, moving money, and executing workflows. Yet most agent stacks provide no mandatory execution checkpoint where organizations can deterministically permit, deny, or defer an action before it changes reality. This paper introduces Faramesh, a protocol-agnostic execution control plane that enforces execution-time authorization for agent-driven actions via a non-bypassable Action Authorization Boundary (AAB). Faramesh canonicalizes agent intent into a Canonical Action Representation (CAR), evaluates actions deterministically against policy and state, and issues a decision artifact (PERMIT/DEFER/DENY) that executors must validate prior to execution. The system is designed to be framework- and model-agnostic, supports multi-agent and multi-tenant deployments, and remains independent of transport protocols (e.g., MCP). Faramesh further provides decision-centric, append-only provenance logging keyed by canonical action hashes, enabling auditability, verification, and deterministic replay without re-running agent reasoning. We show how these primitives yield enforceable, predictable governance for autonomous execution while avoiding hidden coupling to orchestration layers or observability-only approaches.</p>"
    },
    {
      "id": "4354278a0132",
      "title": "Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success",
      "content": "arXiv:2601.18175v1 Announce Type: new  Abstract: A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $\\chi^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective.",
      "url": "http://arxiv.org/abs/2601.18175",
      "author": "Daniel Russo",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proves that success conditioning (rejection sampling with SFT) exactly solves a trust-region optimization problem, yielding an identity connecting policy improvement, change magnitude, and problem difficulty.",
      "importance_score": 74,
      "reasoning": "Important theoretical result clarifying what widely-used technique actually optimizes; bridges practice and theory in RL fine-tuning.",
      "themes": [
        "Reinforcement Learning",
        "Theoretical AI",
        "Policy Optimization"
      ],
      "continuation": null,
      "summary_html": "<p>Proves that success conditioning (rejection sampling with SFT) exactly solves a trust-region optimization problem, yielding an identity connecting policy improvement, change magnitude, and problem difficulty.</p>",
      "content_html": "<p>arXiv:2601.18175v1 Announce Type: new  Abstract: A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $\\chi^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective.</p>"
    },
    {
      "id": "b0044a9f973a",
      "title": "ReLE: A Scalable System and Structured Benchmark for Diagnosing Capability Anisotropy in Chinese LLMs",
      "content": "arXiv:2601.17399v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have achieved rapid progress in Chinese language understanding, yet accurately evaluating their capabilities remains challenged by benchmark saturation and prohibitive computational costs. While static leaderboards provide snapshot rankings, they often mask the structural trade-offs between capabilities. In this work, we present ReLE (Robust Efficient Live Evaluation), a scalable system designed to diagnose Capability Anisotropy, the non-uniformity of model performance across domains. Using ReLE, we evaluate 304 models (189 commercial, 115 open-source) across a Domain $\\times$ Capability orthogonal matrix comprising 207,843 samples. We introduce two methodological contributions to address current evaluation pitfalls: (1) A Symbolic-Grounded Hybrid Scoring Mechanism that eliminates embedding-based false positives in reasoning tasks; (2) A Dynamic Variance-Aware Scheduler based on Neyman allocation with noise correction, which reduces compute costs by 70\\% compared to full-pass evaluations while maintaining a ranking correlation of $\\rho=0.96$. Our analysis reveals that aggregate rankings are highly sensitive to weighting schemes: models exhibit a Rank Stability Amplitude (RSA) of 11.4 in ReLE versus $\\sim$5.0 in traditional benchmarks, confirming that modern models are highly specialized rather than generally superior. We position ReLE not as a replacement for comprehensive static benchmarks, but as a high-frequency diagnostic monitor for the evolving model landscape.",
      "url": "http://arxiv.org/abs/2601.17399",
      "author": "Rui Fang, Jian Li, Wei Chen, Bin Hu, Ying-Cong Chen, Xin Tang, Liang Diao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "ReLE benchmark evaluates 304 LLMs (189 commercial, 115 open-source) for Chinese language understanding across a domaincapability matrix with 207,843 samples, measuring 'capability anisotropy'.",
      "importance_score": 74,
      "reasoning": "Large-scale systematic evaluation. Novel capability anisotropy concept. Important for Chinese LLM development.",
      "themes": [
        "LLM Evaluation",
        "Benchmarks",
        "Chinese NLP"
      ],
      "continuation": null,
      "summary_html": "<p>ReLE benchmark evaluates 304 LLMs (189 commercial, 115 open-source) for Chinese language understanding across a domaincapability matrix with 207,843 samples, measuring 'capability anisotropy'.</p>",
      "content_html": "<p>arXiv:2601.17399v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have achieved rapid progress in Chinese language understanding, yet accurately evaluating their capabilities remains challenged by benchmark saturation and prohibitive computational costs. While static leaderboards provide snapshot rankings, they often mask the structural trade-offs between capabilities. In this work, we present ReLE (Robust Efficient Live Evaluation), a scalable system designed to diagnose Capability Anisotropy, the non-uniformity of model performance across domains. Using ReLE, we evaluate 304 models (189 commercial, 115 open-source) across a Domain $\\times$ Capability orthogonal matrix comprising 207,843 samples. We introduce two methodological contributions to address current evaluation pitfalls: (1) A Symbolic-Grounded Hybrid Scoring Mechanism that eliminates embedding-based false positives in reasoning tasks; (2) A Dynamic Variance-Aware Scheduler based on Neyman allocation with noise correction, which reduces compute costs by 70\\% compared to full-pass evaluations while maintaining a ranking correlation of $\\rho=0.96$. Our analysis reveals that aggregate rankings are highly sensitive to weighting schemes: models exhibit a Rank Stability Amplitude (RSA) of 11.4 in ReLE versus $\\sim$5.0 in traditional benchmarks, confirming that modern models are highly specialized rather than generally superior. We position ReLE not as a replacement for comprehensive static benchmarks, but as a high-frequency diagnostic monitor for the evolving model landscape.</p>"
    },
    {
      "id": "241c82cc4bd2",
      "title": "Just-In-Time Reinforcement Learning: Continual Learning in LLM Agents Without Gradient Updates",
      "content": "arXiv:2601.18510v1 Announce Type: cross  Abstract: While Large Language Model (LLM) agents excel at general tasks, they inherently struggle with continual adaptation due to the frozen weights after deployment. Conventional reinforcement learning (RL) offers a solution but incurs prohibitive computational costs and the risk of catastrophic forgetting. We introduce Just-In-Time Reinforcement Learning (JitRL), a training-free framework that enables test-time policy optimization without any gradient updates. JitRL maintains a dynamic, non-parametric memory of experiences and retrieves relevant trajectories to estimate action advantages on-the-fly. These estimates are then used to directly modulate the LLM's output logits. We theoretically prove that this additive update rule is the exact closed-form solution to the KL-constrained policy optimization objective. Extensive experiments on WebArena and Jericho demonstrate that JitRL establishes a new state-of-the-art among training-free methods. Crucially, JitRL outperforms the performance of computationally expensive fine-tuning methods (e.g., WebRL) while reducing monetary costs by over 30 times, offering a scalable path for continual learning agents. The code is available at https://github.com/liushiliushi/JitRL.",
      "url": "http://arxiv.org/abs/2601.18510",
      "author": "Yibo Li, Zijie Lin, Ailin Deng, Xuan Zhang, Yufei He, Shuo Ji, Tri Cao, Bryan Hooi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces JitRL, training-free framework enabling test-time policy optimization for LLM agents without gradient updates. Uses dynamic non-parametric memory and on-the-fly advantage estimation to modulate output logits.",
      "importance_score": 74,
      "reasoning": "Novel approach: RL at test-time without training. Addresses frozen weights limitation of deployed LLMs. Theoretical proof of optimality adds rigor.",
      "themes": [
        "Reinforcement Learning",
        "LLM Agents",
        "Test-time Adaptation"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces JitRL, training-free framework enabling test-time policy optimization for LLM agents without gradient updates. Uses dynamic non-parametric memory and on-the-fly advantage estimation to modulate output logits.</p>",
      "content_html": "<p>arXiv:2601.18510v1 Announce Type: cross  Abstract: While Large Language Model (LLM) agents excel at general tasks, they inherently struggle with continual adaptation due to the frozen weights after deployment. Conventional reinforcement learning (RL) offers a solution but incurs prohibitive computational costs and the risk of catastrophic forgetting. We introduce Just-In-Time Reinforcement Learning (JitRL), a training-free framework that enables test-time policy optimization without any gradient updates. JitRL maintains a dynamic, non-parametric memory of experiences and retrieves relevant trajectories to estimate action advantages on-the-fly. These estimates are then used to directly modulate the LLM's output logits. We theoretically prove that this additive update rule is the exact closed-form solution to the KL-constrained policy optimization objective. Extensive experiments on WebArena and Jericho demonstrate that JitRL establishes a new state-of-the-art among training-free methods. Crucially, JitRL outperforms the performance of computationally expensive fine-tuning methods (e.g., WebRL) while reducing monetary costs by over 30 times, offering a scalable path for continual learning agents. The code is available at https://github.com/liushiliushi/JitRL.</p>"
    },
    {
      "id": "f340cc0d6358",
      "title": "Beyond Preferences: Learning Alignment Principles Grounded in Human Reasons and Values",
      "content": "arXiv:2601.18760v1 Announce Type: cross  Abstract: A crucial consideration when developing and deploying Large Language Models (LLMs) is the human values to which these models are aligned. In the constitutional framework of alignment models are aligned to a set of principles (the constitution) specified in natural language. However, it is unclear how to fairly determine this constitution with widespread stakeholder input. In this work we propose Grounded Constitutional AI (GCAI), a unified framework for generating constitutions of principles that are representative of both users' general expectations toward AI (general principles) and their interaction-time preferences (contextual principles). We extend the Inverse Constitutional AI (ICAI) approach to generate contextual principles from human preference annotation data by leveraging human-provided \\textit{reasons} for their preferences. We supplement these contextual principles with general principles surfaced from user statements of \\textit{values} regarding AI. We show that a constitution generated by GCAI is preferred by humans over one generated through ICAI both personally, and for widespread use in governing AI behavior. Additionally participants consider the GCAI constitution to be more morally grounded, coherent, and pluralistic.",
      "url": "http://arxiv.org/abs/2601.18760",
      "author": "Henry Bell, Lara Neubauer da Costa Schertel, Bochu Ding, Brandon Fain",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes Grounded Constitutional AI (GCAI) for generating representative constitutions from both general user expectations and interaction-time preferences, extending Inverse Constitutional AI to derive contextual principles.",
      "importance_score": 74,
      "reasoning": "Important contribution to making constitutional AI more representative and grounded in stakeholder input. Advances participatory alignment.",
      "themes": [
        "Alignment",
        "Constitutional AI",
        "Human Values",
        "Participatory AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Grounded Constitutional AI (GCAI) for generating representative constitutions from both general user expectations and interaction-time preferences, extending Inverse Constitutional AI to derive contextual principles.</p>",
      "content_html": "<p>arXiv:2601.18760v1 Announce Type: cross  Abstract: A crucial consideration when developing and deploying Large Language Models (LLMs) is the human values to which these models are aligned. In the constitutional framework of alignment models are aligned to a set of principles (the constitution) specified in natural language. However, it is unclear how to fairly determine this constitution with widespread stakeholder input. In this work we propose Grounded Constitutional AI (GCAI), a unified framework for generating constitutions of principles that are representative of both users' general expectations toward AI (general principles) and their interaction-time preferences (contextual principles). We extend the Inverse Constitutional AI (ICAI) approach to generate contextual principles from human preference annotation data by leveraging human-provided \\textit{reasons} for their preferences. We supplement these contextual principles with general principles surfaced from user statements of \\textit{values} regarding AI. We show that a constitution generated by GCAI is preferred by humans over one generated through ICAI both personally, and for widespread use in governing AI behavior. Additionally participants consider the GCAI constitution to be more morally grounded, coherent, and pluralistic.</p>"
    },
    {
      "id": "70fac02b3784",
      "title": "Lattice: Generative Guardrails for Conversational Agents",
      "content": "arXiv:2601.17481v1 Announce Type: new  Abstract: Conversational AI systems require guardrails to prevent harmful outputs, yet existing approaches use static rules that cannot adapt to new threats or deployment contexts. We introduce Lattice, a framework for self-constructing and continuously improving guardrails. Lattice operates in two stages: construction builds initial guardrails from labeled examples through iterative simulation and optimization; continuous improvement autonomously adapts deployed guardrails through risk assessment, adversarial testing, and consolidation. Evaluated on the ProsocialDialog dataset, Lattice achieves 91% F1 on held-out data, outperforming keyword baselines by 43pp, LlamaGuard by 25pp, and NeMo by 4pp. The continuous improvement stage achieves 7pp F1 improvement on cross-domain data through closed-loop optimization. Our framework shows that effective guardrails can be self-constructed through iterative optimization.",
      "url": "http://arxiv.org/abs/2601.17481",
      "author": "Emily Broadhurst, Tawab Safi, Joseph Edell, Vashisht Ganesh, Karime Maamari",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces Lattice, a framework for self-constructing and continuously improving conversational AI guardrails through iterative simulation, optimization, and autonomous adversarial testing, achieving 91% F1.",
      "importance_score": 73,
      "reasoning": "Strong practical contribution to AI safety; adaptive guardrails address real deployment needs with demonstrated improvements over existing methods.",
      "themes": [
        "AI Safety",
        "Guardrails",
        "Conversational AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Lattice, a framework for self-constructing and continuously improving conversational AI guardrails through iterative simulation, optimization, and autonomous adversarial testing, achieving 91% F1.</p>",
      "content_html": "<p>arXiv:2601.17481v1 Announce Type: new  Abstract: Conversational AI systems require guardrails to prevent harmful outputs, yet existing approaches use static rules that cannot adapt to new threats or deployment contexts. We introduce Lattice, a framework for self-constructing and continuously improving guardrails. Lattice operates in two stages: construction builds initial guardrails from labeled examples through iterative simulation and optimization; continuous improvement autonomously adapts deployed guardrails through risk assessment, adversarial testing, and consolidation. Evaluated on the ProsocialDialog dataset, Lattice achieves 91% F1 on held-out data, outperforming keyword baselines by 43pp, LlamaGuard by 25pp, and NeMo by 4pp. The continuous improvement stage achieves 7pp F1 improvement on cross-domain data through closed-loop optimization. Our framework shows that effective guardrails can be self-constructed through iterative optimization.</p>"
    },
    {
      "id": "f24f4a373b94",
      "title": "Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents",
      "content": "arXiv:2601.18217v1 Announce Type: new  Abstract: Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.",
      "url": "http://arxiv.org/abs/2601.18217",
      "author": "Zhihan Liu, Lin Guan, Yixin Nie, Kai Zhang, Zhuoqun Hao, Lin Chen, Asli Celikyilmaz, Zhaoran Wang, Na Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Investigates cross-domain generalization of RL-trained LLM agents, identifying state information richness and planning complexity as key environment axes affecting out-of-domain performance.",
      "importance_score": 73,
      "reasoning": "Important findings for practical agent deployment; identifies actionable factors affecting generalization.",
      "themes": [
        "Agentic AI",
        "Generalization",
        "Reinforcement Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Investigates cross-domain generalization of RL-trained LLM agents, identifying state information richness and planning complexity as key environment axes affecting out-of-domain performance.</p>",
      "content_html": "<p>arXiv:2601.18217v1 Announce Type: new  Abstract: Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.</p>"
    },
    {
      "id": "2f27a7db3b37",
      "title": "Beyond Outcome Verification: Verifiable Process Reward Models for Structured Reasoning",
      "content": "arXiv:2601.17223v1 Announce Type: cross  Abstract: Recent work on reinforcement learning with verifiable rewards (RLVR) has shown that large language models (LLMs) can be substantially improved using outcome-level verification signals, such as unit tests for code or exact-match checks for mathematics. In parallel, process supervision has long been explored as a way to shape the intermediate reasoning behaviour of LLMs, but existing approaches rely on neural judges to score chain-of-thought steps, leaving them vulnerable to opacity, bias, and reward hacking. To address this gap, we introduce Verifiable Process Reward Models (VPRMs), a reinforcement-learning framework in which intermediate reasoning steps are checked by deterministic, rule-based verifiers. We apply VPRMs to risk-of-bias assessment for medical evidence synthesis, a domain where guideline-defined criteria and rule-based decision paths enable programmatic verification of reasoning traces. Across multiple datasets, we find that VPRMs generate reasoning that adheres closely to domain rules and achieve substantially higher coherence between step-level decisions and final labels. Results show that VPRMs achieve up to 20% higher F1 than state-of-the-art models and 6.5% higher than verifiable outcome rewards, with substantial gains in evidence grounding and logical coherence.",
      "url": "http://arxiv.org/abs/2601.17223",
      "author": "Massimiliano Pronesti, Anya Belz, Yufang Hou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces Verifiable Process Reward Models (VPRMs), using deterministic rule-based verifiers for intermediate reasoning steps in RLVR. Applies to risk-of-bias assessment task.",
      "importance_score": 73,
      "reasoning": "Important contribution to verifiable RL alignment. Addresses opacity and reward hacking in process supervision with principled approach.",
      "themes": [
        "Alignment",
        "Reinforcement Learning",
        "Verifiable Rewards",
        "Process Supervision"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Verifiable Process Reward Models (VPRMs), using deterministic rule-based verifiers for intermediate reasoning steps in RLVR. Applies to risk-of-bias assessment task.</p>",
      "content_html": "<p>arXiv:2601.17223v1 Announce Type: cross  Abstract: Recent work on reinforcement learning with verifiable rewards (RLVR) has shown that large language models (LLMs) can be substantially improved using outcome-level verification signals, such as unit tests for code or exact-match checks for mathematics. In parallel, process supervision has long been explored as a way to shape the intermediate reasoning behaviour of LLMs, but existing approaches rely on neural judges to score chain-of-thought steps, leaving them vulnerable to opacity, bias, and reward hacking. To address this gap, we introduce Verifiable Process Reward Models (VPRMs), a reinforcement-learning framework in which intermediate reasoning steps are checked by deterministic, rule-based verifiers. We apply VPRMs to risk-of-bias assessment for medical evidence synthesis, a domain where guideline-defined criteria and rule-based decision paths enable programmatic verification of reasoning traces. Across multiple datasets, we find that VPRMs generate reasoning that adheres closely to domain rules and achieve substantially higher coherence between step-level decisions and final labels. Results show that VPRMs achieve up to 20% higher F1 than state-of-the-art models and 6.5% higher than verifiable outcome rewards, with substantial gains in evidence grounding and logical coherence.</p>"
    },
    {
      "id": "5705e6fa11c0",
      "title": "Data-driven Clustering and Merging of Adapters for On-device Large Language Models",
      "content": "arXiv:2601.17441v1 Announce Type: cross  Abstract: On-device large language models commonly employ task-specific adapters (e.g., LoRAs) to deliver strong performance on downstream tasks. While storing all available adapters is impractical due to memory constraints, mobile devices typically have sufficient capacity to store a limited number of these parameters. This raises a critical challenge: how to select representative adapters that generalize well across multiple tasks - a problem that remains unexplored in existing literature. We propose a novel method D2C for adapter clustering that leverages minimal task-specific examples (e.g., 10 per task) and employs an iterative optimization process to refine cluster assignments. The adapters within each cluster are merged, creating multi-task adapters deployable on resource-constrained devices. Experimental results demonstrate that our method effectively boosts performance for considered storage budgets.",
      "url": "http://arxiv.org/abs/2601.17441",
      "author": "Ondrej Bohdal, Taha Ceritli, Mete Ozay, Jijoong Moon, Kyeng-Hun Lee, Hyeonmok Ko, Umberto Michieli",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "D2C addresses on-device LLM adapter selection by clustering adapters using minimal task examples and iteratively optimizing assignments, then merging within clusters for multi-task deployment.",
      "importance_score": 73,
      "reasoning": "Practical solution for memory-constrained deployment. Novel problem formulation for adapter selection. Relevant for edge AI.",
      "themes": [
        "On-device AI",
        "LoRA Adapters",
        "Model Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>D2C addresses on-device LLM adapter selection by clustering adapters using minimal task examples and iteratively optimizing assignments, then merging within clusters for multi-task deployment.</p>",
      "content_html": "<p>arXiv:2601.17441v1 Announce Type: cross  Abstract: On-device large language models commonly employ task-specific adapters (e.g., LoRAs) to deliver strong performance on downstream tasks. While storing all available adapters is impractical due to memory constraints, mobile devices typically have sufficient capacity to store a limited number of these parameters. This raises a critical challenge: how to select representative adapters that generalize well across multiple tasks - a problem that remains unexplored in existing literature. We propose a novel method D2C for adapter clustering that leverages minimal task-specific examples (e.g., 10 per task) and employs an iterative optimization process to refine cluster assignments. The adapters within each cluster are merged, creating multi-task adapters deployable on resource-constrained devices. Experimental results demonstrate that our method effectively boosts performance for considered storage budgets.</p>"
    },
    {
      "id": "e9f91fd1f640",
      "title": "The Limits of AI Data Transparency Policy: Three Disclosure Fallacies",
      "content": "arXiv:2601.18127v1 Announce Type: cross  Abstract: Data transparency has emerged as a rallying cry for addressing concerns about AI: data quality, privacy, and copyright chief among them. Yet while these calls are crucial for accountability, current transparency policies often fall short of their intended aims. Similar to nutrition facts for food, policies aimed at nutrition facts for AI currently suffer from a limited consideration of research on effective disclosures. We offer an institutional perspective and identify three common fallacies in policy implementations of data disclosures for AI. First, many data transparency proposals exhibit a specification gap between the stated goals of data transparency and the actual disclosures necessary to achieve such goals. Second, reform attempts exhibit an enforcement gap between required disclosures on paper and enforcement to ensure compliance in fact. Third, policy proposals manifest an impact gap between disclosed information and meaningful changes in developer practices and public understanding. Informed by the social science on transparency, our analysis identifies affirmative paths for transparency that are effective rather than merely symbolic.",
      "url": "http://arxiv.org/abs/2601.18127",
      "author": "Judy Hanwen Shen, Ken Liu, Angelina Wang, Sarah H. Cen, Andy K. Zhang, Caroline Meinhardt, Daniel Zhang, Kevin Klyman, Rishi Bommasani, Daniel E. Ho",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Stanford HAI researchers identify three fallacies in AI data transparency policies: specification gaps, reform attempts creating new problems, and limited consideration of effective disclosure research. Critiques 'nutrition facts for AI' approaches.",
      "importance_score": 73,
      "reasoning": "Strong team from Stanford HAI (Bommasani, Ho). Timely policy analysis with concrete framework for improving transparency policies. High relevance for AI governance.",
      "themes": [
        "AI Policy",
        "Data Transparency",
        "AI Governance",
        "Regulatory Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Stanford HAI researchers identify three fallacies in AI data transparency policies: specification gaps, reform attempts creating new problems, and limited consideration of effective disclosure research. Critiques 'nutrition facts for AI' approaches.</p>",
      "content_html": "<p>arXiv:2601.18127v1 Announce Type: cross  Abstract: Data transparency has emerged as a rallying cry for addressing concerns about AI: data quality, privacy, and copyright chief among them. Yet while these calls are crucial for accountability, current transparency policies often fall short of their intended aims. Similar to nutrition facts for food, policies aimed at nutrition facts for AI currently suffer from a limited consideration of research on effective disclosures. We offer an institutional perspective and identify three common fallacies in policy implementations of data disclosures for AI. First, many data transparency proposals exhibit a specification gap between the stated goals of data transparency and the actual disclosures necessary to achieve such goals. Second, reform attempts exhibit an enforcement gap between required disclosures on paper and enforcement to ensure compliance in fact. Third, policy proposals manifest an impact gap between disclosed information and meaningful changes in developer practices and public understanding. Informed by the social science on transparency, our analysis identifies affirmative paths for transparency that are effective rather than merely symbolic.</p>"
    },
    {
      "id": "61a4d714a852",
      "title": "Unsupervised Elicitation of Moral Values from Language Models",
      "content": "arXiv:2601.17728v1 Announce Type: new  Abstract: As AI systems become pervasive, grounding their behavior in human values is critical. Prior work suggests that language models (LMs) exhibit limited inherent moral reasoning, leading to calls for explicit moral teaching. However, constructing ground truth data for moral evaluation is difficult given plural frameworks and pervasive biases. We investigate unsupervised elicitation as an alternative, asking whether pretrained (base) LMs possess intrinsic moral reasoning capability that can be surfaced without human supervision. Using the Internal Coherence Maximization (ICM) algorithm across three benchmark datasets and four LMs, we test whether ICM can reliably label moral judgments, generalize across moral frameworks, and mitigate social bias. Results show that ICM outperforms all pre-trained and chatbot baselines on the Norm Bank and ETHICS benchmarks, while fine-tuning on ICM labels performs on par with or surpasses those of human labels. Across theoretically motivated moral frameworks, ICM yields its largest relative gains on Justice and Commonsense morality. Furthermore, although chatbot LMs exhibit social bias failure rates comparable to their pretrained ones, ICM reduces such errors by more than half, with the largest improvements in race, socioeconomic status, and politics. These findings suggest that pretrained LMs possess latent moral reasoning capacities that can be elicited through unsupervised methods like ICM, providing a scalable path for AI alignment.",
      "url": "http://arxiv.org/abs/2601.17728",
      "author": "Meysam Alizadeh, Fabrizio Gilardi, Zeynab Samei",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Investigates unsupervised elicitation of moral values from LLMs using Internal Coherence Maximization algorithm across benchmark datasets. Tests whether base models possess intrinsic moral reasoning without human supervision.",
      "importance_score": 73,
      "reasoning": "Important contribution to AI alignment and ethics. Novel unsupervised approach avoids biases in ground truth moral data.",
      "themes": [
        "AI Safety",
        "Alignment",
        "Moral Reasoning",
        "LLM Behavior"
      ],
      "continuation": null,
      "summary_html": "<p>Investigates unsupervised elicitation of moral values from LLMs using Internal Coherence Maximization algorithm across benchmark datasets. Tests whether base models possess intrinsic moral reasoning without human supervision.</p>",
      "content_html": "<p>arXiv:2601.17728v1 Announce Type: new  Abstract: As AI systems become pervasive, grounding their behavior in human values is critical. Prior work suggests that language models (LMs) exhibit limited inherent moral reasoning, leading to calls for explicit moral teaching. However, constructing ground truth data for moral evaluation is difficult given plural frameworks and pervasive biases. We investigate unsupervised elicitation as an alternative, asking whether pretrained (base) LMs possess intrinsic moral reasoning capability that can be surfaced without human supervision. Using the Internal Coherence Maximization (ICM) algorithm across three benchmark datasets and four LMs, we test whether ICM can reliably label moral judgments, generalize across moral frameworks, and mitigate social bias. Results show that ICM outperforms all pre-trained and chatbot baselines on the Norm Bank and ETHICS benchmarks, while fine-tuning on ICM labels performs on par with or surpasses those of human labels. Across theoretically motivated moral frameworks, ICM yields its largest relative gains on Justice and Commonsense morality. Furthermore, although chatbot LMs exhibit social bias failure rates comparable to their pretrained ones, ICM reduces such errors by more than half, with the largest improvements in race, socioeconomic status, and politics. These findings suggest that pretrained LMs possess latent moral reasoning capacities that can be elicited through unsupervised methods like ICM, providing a scalable path for AI alignment.</p>"
    },
    {
      "id": "d876166eb208",
      "title": "FP8-RL: A Practical and Stable Low-Precision Stack for LLM Reinforcement Learning",
      "content": "arXiv:2601.18150v1 Announce Type: cross  Abstract: Reinforcement learning (RL) for large language models (LLMs) is increasingly bottlenecked by rollout (generation), where long output sequence lengths make attention and KV-cache memory dominate end-to-end step time. FP8 offers an attractive lever for accelerating RL by reducing compute cost and memory traffic during rollout, but applying FP8 in RL introduces unique engineering and algorithmic challenges: policy weights change every step (requiring repeated quantization and weight synchronization into the inference engine) and low-precision rollouts can deviate from the higher-precision policy assumed by the trainer, causing train-inference mismatch and potential instability. This report presents a practical FP8 rollout stack for LLM RL, implemented in the veRL ecosystem with support for common training backends (e.g., FSDP/Megatron-LM) and inference engines (e.g., vLLM/SGLang). We (i) enable FP8 W8A8 linear-layer rollout using blockwise FP8 quantization, (ii) extend FP8 to KV-cache to remove long-context memory bottlenecks via per-step QKV scale recalibration, and (iii) mitigate mismatch using importance-sampling-based rollout correction (token-level TIS/MIS variants). Across dense and MoE models, these techniques deliver up to 44% rollout throughput gains while preserving learning behavior comparable to BF16 baselines.",
      "url": "http://arxiv.org/abs/2601.18150",
      "author": "Zhaopeng Qiu, Shuang Yu, Jingqi Zhang, Shuai Zhang, Xue Huang, Jingyi Yang, Junjie Lai",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Presents FP8 rollout stack for LLM reinforcement learning addressing unique challenges of policy weight changes every step and train-inference mismatch. Provides practical engineering solutions for low-precision RL.",
      "importance_score": 73,
      "reasoning": "Practical efficiency improvements for emerging LLM RL paradigm. Addresses real engineering challenges with reproducible solutions.",
      "themes": [
        "Efficiency",
        "Reinforcement Learning",
        "Quantization",
        "LLM Training"
      ],
      "continuation": null,
      "summary_html": "<p>Presents FP8 rollout stack for LLM reinforcement learning addressing unique challenges of policy weight changes every step and train-inference mismatch. Provides practical engineering solutions for low-precision RL.</p>",
      "content_html": "<p>arXiv:2601.18150v1 Announce Type: cross  Abstract: Reinforcement learning (RL) for large language models (LLMs) is increasingly bottlenecked by rollout (generation), where long output sequence lengths make attention and KV-cache memory dominate end-to-end step time. FP8 offers an attractive lever for accelerating RL by reducing compute cost and memory traffic during rollout, but applying FP8 in RL introduces unique engineering and algorithmic challenges: policy weights change every step (requiring repeated quantization and weight synchronization into the inference engine) and low-precision rollouts can deviate from the higher-precision policy assumed by the trainer, causing train-inference mismatch and potential instability. This report presents a practical FP8 rollout stack for LLM RL, implemented in the veRL ecosystem with support for common training backends (e.g., FSDP/Megatron-LM) and inference engines (e.g., vLLM/SGLang). We (i) enable FP8 W8A8 linear-layer rollout using blockwise FP8 quantization, (ii) extend FP8 to KV-cache to remove long-context memory bottlenecks via per-step QKV scale recalibration, and (iii) mitigate mismatch using importance-sampling-based rollout correction (token-level TIS/MIS variants). Across dense and MoE models, these techniques deliver up to 44% rollout throughput gains while preserving learning behavior comparable to BF16 baselines.</p>"
    },
    {
      "id": "fca58e79cf8b",
      "title": "Interpreting Agentic Systems: Beyond Model Explanations to System-Level Accountability",
      "content": "arXiv:2601.17168v1 Announce Type: new  Abstract: Agentic systems have transformed how Large Language Models (LLMs) can be leveraged to create autonomous systems with goal-directed behaviors, consisting of multi-step planning and the ability to interact with different environments. These systems differ fundamentally from traditional machine learning models, both in architecture and deployment, introducing unique AI safety challenges, including goal misalignment, compounding decision errors, and coordination risks among interacting agents, that necessitate embedding interpretability and explainability by design to ensure traceability and accountability across their autonomous behaviors. Current interpretability techniques, developed primarily for static models, show limitations when applied to agentic systems. The temporal dynamics, compounding decisions, and context-dependent behaviors of agentic systems demand new analytical approaches. This paper assesses the suitability and limitations of existing interpretability methods in the context of agentic systems, identifying gaps in their capacity to provide meaningful insight into agent decision-making. We propose future directions for developing interpretability techniques specifically designed for agentic systems, pinpointing where interpretability is required to embed oversight mechanisms across the agent lifecycle from goal formation, through environmental interaction, to outcome evaluation. These advances are essential to ensure the safe and accountable deployment of agentic AI systems.",
      "url": "http://arxiv.org/abs/2601.17168",
      "author": "Judy Zhu, Dhari Gandhi, Himanshu Joshi, Ahmad Rezaie Mianroodi, Sedef Akinli Kocak, Dhanesh Ramachandran",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Addresses interpretability challenges unique to agentic AI systems, arguing that traditional model-level explanations are insufficient and proposing system-level accountability frameworks for autonomous agents with multi-step planning.",
      "importance_score": 72,
      "reasoning": "Timely and important topic as agents become more prevalent; identifies key gaps in current interpretability approaches for agentic systems.",
      "themes": [
        "AI Safety",
        "Agentic AI",
        "Interpretability"
      ],
      "continuation": null,
      "summary_html": "<p>Addresses interpretability challenges unique to agentic AI systems, arguing that traditional model-level explanations are insufficient and proposing system-level accountability frameworks for autonomous agents with multi-step planning.</p>",
      "content_html": "<p>arXiv:2601.17168v1 Announce Type: new  Abstract: Agentic systems have transformed how Large Language Models (LLMs) can be leveraged to create autonomous systems with goal-directed behaviors, consisting of multi-step planning and the ability to interact with different environments. These systems differ fundamentally from traditional machine learning models, both in architecture and deployment, introducing unique AI safety challenges, including goal misalignment, compounding decision errors, and coordination risks among interacting agents, that necessitate embedding interpretability and explainability by design to ensure traceability and accountability across their autonomous behaviors. Current interpretability techniques, developed primarily for static models, show limitations when applied to agentic systems. The temporal dynamics, compounding decisions, and context-dependent behaviors of agentic systems demand new analytical approaches. This paper assesses the suitability and limitations of existing interpretability methods in the context of agentic systems, identifying gaps in their capacity to provide meaningful insight into agent decision-making. We propose future directions for developing interpretability techniques specifically designed for agentic systems, pinpointing where interpretability is required to embed oversight mechanisms across the agent lifecycle from goal formation, through environmental interaction, to outcome evaluation. These advances are essential to ensure the safe and accountable deployment of agentic AI systems.</p>"
    },
    {
      "id": "c06cfb4fb392",
      "title": "DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints",
      "content": "arXiv:2601.18137v1 Announce Type: new  Abstract: While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.",
      "url": "http://arxiv.org/abs/2601.18137",
      "author": "Yinger Zhang, Shutong Jiang, Renhao Li, Jianhong Tu, Yang Su, Lianghao Deng, Xudong Guo, Chenxu Lv, Junyang Lin",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces DeepPlanning benchmark for long-horizon agent planning featuring multi-day travel and shopping tasks requiring proactive information gathering and global constrained optimization.",
      "importance_score": 72,
      "reasoning": "Well-designed benchmark addressing gap in agent evaluation; tests genuine planning rather than local reasoning.",
      "themes": [
        "Agentic AI",
        "Planning",
        "Benchmarks"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces DeepPlanning benchmark for long-horizon agent planning featuring multi-day travel and shopping tasks requiring proactive information gathering and global constrained optimization.</p>",
      "content_html": "<p>arXiv:2601.18137v1 Announce Type: new  Abstract: While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.</p>"
    },
    {
      "id": "841da9eba576",
      "title": "Initial results of the Digital Consciousness Model",
      "content": "arXiv:2601.17060v1 Announce Type: cross  Abstract: Artificially intelligent systems have become remarkably sophisticated. They hold conversations, write essays, and seem to understand context in ways that surprise even their creators. This raises a crucial question: Are we creating systems that are conscious? The Digital Consciousness Model (DCM) is a first attempt to assess the evidence for consciousness in AI systems in a systematic, probabilistic way. It provides a shared framework for comparing different AIs and biological organisms, and for tracking how the evidence changes over time as AI develops. Instead of adopting a single theory of consciousness, it incorporates a range of leading theories and perspectives - acknowledging that experts disagree fundamentally about what consciousness is and what conditions are necessary for it. This report describes the structure and initial results of the Digital Consciousness Model. Overall, we find that the evidence is against 2024 LLMs being conscious, but the evidence against 2024 LLMs being conscious is not decisive. The evidence against LLM consciousness is much weaker than the evidence against consciousness in simpler AI systems.",
      "url": "http://arxiv.org/abs/2601.17060",
      "author": "Derek Shiller, Laura Duffy, Arvo Mu\\~noz Mor\\'an, Adri\\`a Moret, Chris Percy, Hayley Clatterbuck",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Introduces Digital Consciousness Model (DCM), a systematic probabilistic framework for assessing AI consciousness by incorporating multiple leading theories. First attempt at principled AI consciousness assessment.",
      "importance_score": 72,
      "reasoning": "Novel and important attempt to systematically address AI consciousness question. Multi-theory approach is methodologically sound. Highly relevant to AI safety discourse.",
      "themes": [
        "AI Consciousness",
        "AI Safety",
        "Philosophy of Mind"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Digital Consciousness Model (DCM), a systematic probabilistic framework for assessing AI consciousness by incorporating multiple leading theories. First attempt at principled AI consciousness assessment.</p>",
      "content_html": "<p>arXiv:2601.17060v1 Announce Type: cross  Abstract: Artificially intelligent systems have become remarkably sophisticated. They hold conversations, write essays, and seem to understand context in ways that surprise even their creators. This raises a crucial question: Are we creating systems that are conscious? The Digital Consciousness Model (DCM) is a first attempt to assess the evidence for consciousness in AI systems in a systematic, probabilistic way. It provides a shared framework for comparing different AIs and biological organisms, and for tracking how the evidence changes over time as AI develops. Instead of adopting a single theory of consciousness, it incorporates a range of leading theories and perspectives - acknowledging that experts disagree fundamentally about what consciousness is and what conditions are necessary for it. This report describes the structure and initial results of the Digital Consciousness Model. Overall, we find that the evidence is against 2024 LLMs being conscious, but the evidence against 2024 LLMs being conscious is not decisive. The evidence against LLM consciousness is much weaker than the evidence against consciousness in simpler AI systems.</p>"
    },
    {
      "id": "a05c7dd179b8",
      "title": "Causal Pre-training Under the Fairness Lens: An Empirical Study of TabPFN",
      "content": "arXiv:2601.17912v1 Announce Type: cross  Abstract: Foundation models for tabular data, such as the Tabular Prior-data Fitted Network (TabPFN), are pre-trained on a massive number of synthetic datasets generated by structural causal models (SCM). They leverage in-context learning to offer high predictive accuracy in real-world tasks. However, the fairness properties of these foundational models, which incorporate ideas from causal reasoning during pre-training, have not yet been explored in sufficient depth. In this work, we conduct a comprehensive empirical evaluation of TabPFN and its fine-tuned variants, assessing predictive performance, fairness, and robustness across varying dataset sizes and distributional shifts. Our results reveal that while TabPFN achieves stronger predictive accuracy compared to baselines and exhibits robustness to spurious correlations, improvements in fairness are moderate and inconsistent, particularly under missing-not-at-random (MNAR) covariate shifts. These findings suggest that the causal pre-training in TabPFN is helpful but insufficient for algorithmic fairness, highlighting implications for deploying such models in practice and the need for further fairness interventions.",
      "url": "http://arxiv.org/abs/2601.17912",
      "author": "Qinyi Liu, Mohammad Khalil, Naman Goel",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Comprehensive fairness evaluation of TabPFN (tabular foundation model pre-trained on synthetic causal data), finding it achieves stronger accuracy but worse fairness compared to traditional models, especially under distribution shift.",
      "importance_score": 72,
      "reasoning": "Important fairness analysis of emerging foundation model paradigm. Reveals tradeoffs in causally-pretrained models. Practical implications for deployment.",
      "themes": [
        "AI Fairness",
        "Foundation Models",
        "Tabular Data"
      ],
      "continuation": null,
      "summary_html": "<p>Comprehensive fairness evaluation of TabPFN (tabular foundation model pre-trained on synthetic causal data), finding it achieves stronger accuracy but worse fairness compared to traditional models, especially under distribution shift.</p>",
      "content_html": "<p>arXiv:2601.17912v1 Announce Type: cross  Abstract: Foundation models for tabular data, such as the Tabular Prior-data Fitted Network (TabPFN), are pre-trained on a massive number of synthetic datasets generated by structural causal models (SCM). They leverage in-context learning to offer high predictive accuracy in real-world tasks. However, the fairness properties of these foundational models, which incorporate ideas from causal reasoning during pre-training, have not yet been explored in sufficient depth. In this work, we conduct a comprehensive empirical evaluation of TabPFN and its fine-tuned variants, assessing predictive performance, fairness, and robustness across varying dataset sizes and distributional shifts. Our results reveal that while TabPFN achieves stronger predictive accuracy compared to baselines and exhibits robustness to spurious correlations, improvements in fairness are moderate and inconsistent, particularly under missing-not-at-random (MNAR) covariate shifts. These findings suggest that the causal pre-training in TabPFN is helpful but insufficient for algorithmic fairness, highlighting implications for deploying such models in practice and the need for further fairness interventions.</p>"
    },
    {
      "id": "ce3013554c4e",
      "title": "One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment",
      "content": "arXiv:2601.18731v1 Announce Type: cross  Abstract: Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users. We argue that addressing these constraints requires a paradigm shift from fitting data to learn user preferences to learn the process of preference adaptation. To realize this, we propose Meta Reward Modeling (MRM), which reformulates personalized reward modeling as a meta-learning problem. Specifically, we represent each user's reward model as a weighted combination of base reward functions, and optimize the initialization of these weights using a Model-Agnostic Meta-Learning (MAML)-style framework to support fast adaptation under limited feedback. To ensure robustness, we introduce the Robust Personalization Objective (RPO), which places greater emphasis on hard-to-learn users during meta optimization. Extensive experiments on personalized preference datasets validate that MRM enhances few-shot personalization, improves user robustness, and consistently outperforms baselines.",
      "url": "http://arxiv.org/abs/2601.18731",
      "author": "Hongru Cai, Yongqi Li, Tiezheng Yu, Fengbin Zhu, Wenjie Wang, Fuli Feng, Wenjie Li",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes Meta Reward Modeling (MRM) for personalized LLM alignment, reformulating personalized reward learning as meta-learning problem to efficiently adapt to unseen users with scarce individual feedback.",
      "importance_score": 72,
      "reasoning": "Novel paradigm shift from fitting data to learning adaptation process. Addresses critical personalization challenge. Practical for user-specific alignment.",
      "themes": [
        "Personalization",
        "Reward Modeling",
        "Meta-Learning",
        "Alignment"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Meta Reward Modeling (MRM) for personalized LLM alignment, reformulating personalized reward learning as meta-learning problem to efficiently adapt to unseen users with scarce individual feedback.</p>",
      "content_html": "<p>arXiv:2601.18731v1 Announce Type: cross  Abstract: Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users. We argue that addressing these constraints requires a paradigm shift from fitting data to learn user preferences to learn the process of preference adaptation. To realize this, we propose Meta Reward Modeling (MRM), which reformulates personalized reward modeling as a meta-learning problem. Specifically, we represent each user's reward model as a weighted combination of base reward functions, and optimize the initialization of these weights using a Model-Agnostic Meta-Learning (MAML)-style framework to support fast adaptation under limited feedback. To ensure robustness, we introduce the Robust Personalization Objective (RPO), which places greater emphasis on hard-to-learn users during meta optimization. Extensive experiments on personalized preference datasets validate that MRM enhances few-shot personalization, improves user robustness, and consistently outperforms baselines.</p>"
    },
    {
      "id": "dd7685955078",
      "title": "HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs",
      "content": "arXiv:2601.18753v1 Announce Type: cross  Abstract: The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations.",
      "url": "http://arxiv.org/abs/2601.18753",
      "author": "Xinyue Zeng, Junhong Lin, Yujun Yan, Feng Guo, Liang Shi, Jun Wu, Dawei Zhou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces Hallucination Risk Bound framework decomposing hallucination into data-driven and reasoning-driven components, providing principled foundation for unified detection across scenarios.",
      "importance_score": 72,
      "reasoning": "Theoretical framework unifying hallucination sources. Decomposition into data vs reasoning components provides actionable framework. Addresses major LLM reliability challenge.",
      "themes": [
        "Hallucination Detection",
        "LLM Reliability",
        "Theoretical Framework"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Hallucination Risk Bound framework decomposing hallucination into data-driven and reasoning-driven components, providing principled foundation for unified detection across scenarios.</p>",
      "content_html": "<p>arXiv:2601.18753v1 Announce Type: cross  Abstract: The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations.</p>"
    },
    {
      "id": "7e2bc8555928",
      "title": "LLM-Based Adversarial Persuasion Attacks on Fact-Checking Systems",
      "content": "arXiv:2601.16890v1 Announce Type: cross  Abstract: Automated fact-checking (AFC) systems are susceptible to adversarial attacks, enabling false claims to evade detection. Existing adversarial frameworks typically rely on injecting noise or altering semantics, yet no existing framework exploits the adversarial potential of persuasion techniques, which are widely used in disinformation campaigns to manipulate audiences. In this paper, we introduce a novel class of persuasive adversarial attacks on AFCs by employing a generative LLM to rephrase claims using persuasion techniques. Considering 15 techniques grouped into 6 categories, we study the effects of persuasion on both claim verification and evidence retrieval using a decoupled evaluation strategy. Experiments on the FEVER and FEVEROUS benchmarks show that persuasion attacks can substantially degrade both verification performance and evidence retrieval. Our analysis identifies persuasion techniques as a potent class of adversarial attacks, highlighting the need for more robust AFC systems.",
      "url": "http://arxiv.org/abs/2601.16890",
      "author": "Jo\\~ao A. Leite, Olesya Razuvayevskaya, Kalina Bontcheva, Carolina Scarton",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces adversarial persuasion attacks on automated fact-checking systems using LLMs to rephrase claims with persuasion techniques. Tests 15 persuasion techniques across 6 categories on FEVER and FEVEROUS benchmarks.",
      "importance_score": 72,
      "reasoning": "Important AI safety work revealing vulnerabilities in fact-checking systems to manipulation tactics common in disinformation. Directly relevant to misinformation defense.",
      "themes": [
        "AI Safety",
        "Fact-Checking",
        "Adversarial Attacks",
        "Misinformation"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces adversarial persuasion attacks on automated fact-checking systems using LLMs to rephrase claims with persuasion techniques. Tests 15 persuasion techniques across 6 categories on FEVER and FEVEROUS benchmarks.</p>",
      "content_html": "<p>arXiv:2601.16890v1 Announce Type: cross  Abstract: Automated fact-checking (AFC) systems are susceptible to adversarial attacks, enabling false claims to evade detection. Existing adversarial frameworks typically rely on injecting noise or altering semantics, yet no existing framework exploits the adversarial potential of persuasion techniques, which are widely used in disinformation campaigns to manipulate audiences. In this paper, we introduce a novel class of persuasive adversarial attacks on AFCs by employing a generative LLM to rephrase claims using persuasion techniques. Considering 15 techniques grouped into 6 categories, we study the effects of persuasion on both claim verification and evidence retrieval using a decoupled evaluation strategy. Experiments on the FEVER and FEVEROUS benchmarks show that persuasion attacks can substantially degrade both verification performance and evidence retrieval. Our analysis identifies persuasion techniques as a potent class of adversarial attacks, highlighting the need for more robust AFC systems.</p>"
    },
    {
      "id": "b28129c765dc",
      "title": "Sparks of Cooperative Reasoning: LLMs as Strategic Hanabi Agents",
      "content": "arXiv:2601.18077v1 Announce Type: new  Abstract: Cooperative reasoning under incomplete information remains challenging for both humans and multi-agent systems. The card game Hanabi embodies this challenge, requiring theory-of-mind reasoning and strategic communication. We benchmark 17 state-of-the-art LLM agents in 2-5 player games and study the impact of context engineering across model scales (4B to 600B+) to understand persistent coordination failures and robustness to scaffolding: from a minimal prompt with only explicit card details (Watson setting), to scaffolding with programmatic, Bayesian-motivated deductions (Sherlock setting), to multi-turn state tracking via working memory (Mycroft setting). We show that (1) agents can maintain an internal working memory for state tracking and (2) cross-play performance between different LLMs smoothly interpolates with model strength. In the Sherlock setting, the strongest reasoning models exceed 15 points on average across player counts, yet still trail experienced humans and specialist Hanabi agents, both consistently scoring above 20. We release the first public Hanabi datasets with annotated trajectories and move utilities: (1) HanabiLogs, containing 1,520 full game logs for instruction tuning, and (2) HanabiRewards, containing 560 games with dense move-level value annotations for all candidate moves. Supervised and RL finetuning of a 4B open-weight model (Qwen3-Instruct) on our datasets improves cooperative Hanabi play by 21% and 156% respectively, bringing performance to within ~3 points of a strong proprietary reasoning model (o4-mini) and surpassing the best non-reasoning model (GPT-4.1) by 52%. The HanabiRewards RL-finetuned model further generalizes beyond Hanabi, improving performance on a cooperative group-guessing benchmark by 11%, temporal reasoning on EventQA by 6.4%, instruction-following on IFBench-800K by 1.7 Pass@10, and matching AIME 2025 mathematical reasoning Pass@10.",
      "url": "http://arxiv.org/abs/2601.18077",
      "author": "Mahesh Ramesh, Kaousheik Jayakumar, Aswinkumar Ramkumar, Pavan Thodima, Aniket Rege",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Benchmarks 17 LLM agents on Hanabi cooperative game testing theory-of-mind and strategic communication across model scales (4B to 600B+). Studies impact of context engineering approaches.",
      "importance_score": 72,
      "reasoning": "Comprehensive evaluation of LLMs on challenging cooperative reasoning task. Novel multi-scale analysis with insights about coordination failures.",
      "themes": [
        "LLM Evaluation",
        "Cooperative AI",
        "Theory of Mind",
        "Multi-Agent"
      ],
      "continuation": null,
      "summary_html": "<p>Benchmarks 17 LLM agents on Hanabi cooperative game testing theory-of-mind and strategic communication across model scales (4B to 600B+). Studies impact of context engineering approaches.</p>",
      "content_html": "<p>arXiv:2601.18077v1 Announce Type: new  Abstract: Cooperative reasoning under incomplete information remains challenging for both humans and multi-agent systems. The card game Hanabi embodies this challenge, requiring theory-of-mind reasoning and strategic communication. We benchmark 17 state-of-the-art LLM agents in 2-5 player games and study the impact of context engineering across model scales (4B to 600B+) to understand persistent coordination failures and robustness to scaffolding: from a minimal prompt with only explicit card details (Watson setting), to scaffolding with programmatic, Bayesian-motivated deductions (Sherlock setting), to multi-turn state tracking via working memory (Mycroft setting). We show that (1) agents can maintain an internal working memory for state tracking and (2) cross-play performance between different LLMs smoothly interpolates with model strength. In the Sherlock setting, the strongest reasoning models exceed 15 points on average across player counts, yet still trail experienced humans and specialist Hanabi agents, both consistently scoring above 20. We release the first public Hanabi datasets with annotated trajectories and move utilities: (1) HanabiLogs, containing 1,520 full game logs for instruction tuning, and (2) HanabiRewards, containing 560 games with dense move-level value annotations for all candidate moves. Supervised and RL finetuning of a 4B open-weight model (Qwen3-Instruct) on our datasets improves cooperative Hanabi play by 21% and 156% respectively, bringing performance to within ~3 points of a strong proprietary reasoning model (o4-mini) and surpassing the best non-reasoning model (GPT-4.1) by 52%. The HanabiRewards RL-finetuned model further generalizes beyond Hanabi, improving performance on a cooperative group-guessing benchmark by 11%, temporal reasoning on EventQA by 6.4%, instruction-following on IFBench-800K by 1.7 Pass@10, and matching AIME 2025 mathematical reasoning Pass@10.</p>"
    },
    {
      "id": "1710f46e8c9e",
      "title": "Fast KVzip: Efficient and Accurate LLM Inference with Gated KV Eviction",
      "content": "arXiv:2601.17668v1 Announce Type: cross  Abstract: Efficient key-value (KV) cache management is crucial for the practical deployment of large language models (LLMs), yet existing compression techniques often incur a trade-off between performance degradation and computational overhead. We propose a novel gating-based KV cache eviction method for frozen-weight LLMs that achieves high compression ratios with negligible computational cost. Our approach introduces lightweight sink-attention gating modules to identify and retain critical KV pairs, and integrates seamlessly into both the prefill and decoding stages. The proposed gate training algorithm relies on forward passes of an LLM, avoiding expensive backpropagation, while achieving strong task generalization through a task-agnostic reconstruction objective. Extensive experiments across the Qwen2.5-1M, Qwen3, and Gemma3 families show that our method maintains near-lossless performance while evicting up to 70% of the KV cache. The results are consistent across a wide range of tasks, including long-context understanding, code comprehension, and mathematical reasoning, demonstrating the generality of our approach.",
      "url": "http://arxiv.org/abs/2601.17668",
      "author": "Jang-Hyun Kim, Dongyoon Han, Sangdoo Yun",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes gating-based KV cache eviction for frozen LLMs achieving high compression with negligible computational cost. Uses lightweight sink-attention gating modules for task-agnostic compression without expensive backpropagation.",
      "importance_score": 72,
      "reasoning": "Practical efficiency improvement for LLM inference. Task-agnostic approach and integration into both prefill/decoding stages shows broad applicability.",
      "themes": [
        "Efficiency",
        "Inference Optimization",
        "KV Cache",
        "Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes gating-based KV cache eviction for frozen LLMs achieving high compression with negligible computational cost. Uses lightweight sink-attention gating modules for task-agnostic compression without expensive backpropagation.</p>",
      "content_html": "<p>arXiv:2601.17668v1 Announce Type: cross  Abstract: Efficient key-value (KV) cache management is crucial for the practical deployment of large language models (LLMs), yet existing compression techniques often incur a trade-off between performance degradation and computational overhead. We propose a novel gating-based KV cache eviction method for frozen-weight LLMs that achieves high compression ratios with negligible computational cost. Our approach introduces lightweight sink-attention gating modules to identify and retain critical KV pairs, and integrates seamlessly into both the prefill and decoding stages. The proposed gate training algorithm relies on forward passes of an LLM, avoiding expensive backpropagation, while achieving strong task generalization through a task-agnostic reconstruction objective. Extensive experiments across the Qwen2.5-1M, Qwen3, and Gemma3 families show that our method maintains near-lossless performance while evicting up to 70% of the KV cache. The results are consistent across a wide range of tasks, including long-context understanding, code comprehension, and mathematical reasoning, demonstrating the generality of our approach.</p>"
    },
    {
      "id": "a97b6ef02142",
      "title": "Sponge Tool Attack: Stealthy Denial-of-Efficiency against Tool-Augmented Agentic Reasoning",
      "content": "arXiv:2601.17566v1 Announce Type: new  Abstract: Enabling large language models (LLMs) to solve complex reasoning tasks is a key step toward artificial general intelligence. Recent work augments LLMs with external tools to enable agentic reasoning, achieving high utility and efficiency in a plug-and-play manner. However, the inherent vulnerabilities of such methods to malicious manipulation of the tool-calling process remain largely unexplored. In this work, we identify a tool-specific attack surface and propose Sponge Tool Attack (STA), which disrupts agentic reasoning solely by rewriting the input prompt under a strict query-only access assumption. Without any modification on the underlying model or the external tools, STA converts originally concise and efficient reasoning trajectories into unnecessarily verbose and convoluted ones before arriving at the final answer. This results in substantial computational overhead while remaining stealthy by preserving the original task semantics and user intent. To achieve this, we design STA as an iterative, multi-agent collaborative framework with explicit rewritten policy control, and generates benign-looking prompt rewrites from the original one with high semantic fidelity. Extensive experiments across 6 models (including both open-source models and closed-source APIs), 12 tools, 4 agentic frameworks, and 13 datasets spanning 5 domains validate the effectiveness of STA.",
      "url": "http://arxiv.org/abs/2601.17566",
      "author": "Qi Li, Xinchao Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces Sponge Tool Attack (STA), a novel attack that disrupts tool-augmented LLM reasoning by rewriting input prompts without modifying the model or tools. This identifies a new attack surface for agentic AI systems under query-only access assumptions.",
      "importance_score": 72,
      "reasoning": "Important security research identifying vulnerabilities in increasingly popular tool-augmented LLM agents. Relevant to AI safety but limited technical detail in abstract.",
      "themes": [
        "AI Safety",
        "LLM Agents",
        "Adversarial Attacks"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Sponge Tool Attack (STA), a novel attack that disrupts tool-augmented LLM reasoning by rewriting input prompts without modifying the model or tools. This identifies a new attack surface for agentic AI systems under query-only access assumptions.</p>",
      "content_html": "<p>arXiv:2601.17566v1 Announce Type: new  Abstract: Enabling large language models (LLMs) to solve complex reasoning tasks is a key step toward artificial general intelligence. Recent work augments LLMs with external tools to enable agentic reasoning, achieving high utility and efficiency in a plug-and-play manner. However, the inherent vulnerabilities of such methods to malicious manipulation of the tool-calling process remain largely unexplored. In this work, we identify a tool-specific attack surface and propose Sponge Tool Attack (STA), which disrupts agentic reasoning solely by rewriting the input prompt under a strict query-only access assumption. Without any modification on the underlying model or the external tools, STA converts originally concise and efficient reasoning trajectories into unnecessarily verbose and convoluted ones before arriving at the final answer. This results in substantial computational overhead while remaining stealthy by preserving the original task semantics and user intent. To achieve this, we design STA as an iterative, multi-agent collaborative framework with explicit rewritten policy control, and generates benign-looking prompt rewrites from the original one with high semantic fidelity. Extensive experiments across 6 models (including both open-source models and closed-source APIs), 12 tools, 4 agentic frameworks, and 13 datasets spanning 5 domains validate the effectiveness of STA.</p>"
    },
    {
      "id": "523e55e3f455",
      "title": "GenAgent: Scaling Text-to-Image Generation via Agentic Multimodal Reasoning",
      "content": "arXiv:2601.18543v1 Announce Type: new  Abstract: We introduce GenAgent, unifying visual understanding and generation through an agentic multimodal model. Unlike unified models that face expensive training costs and understanding-generation trade-offs, GenAgent decouples these capabilities through an agentic framework: understanding is handled by the multimodal model itself, while generation is achieved by treating image generation models as invokable tools. Crucially, unlike existing modular systems constrained by static pipelines, this design enables autonomous multi-turn interactions where the agent generates multimodal chains-of-thought encompassing reasoning, tool invocation, judgment, and reflection to iteratively refine outputs. We employ a two-stage training strategy: first, cold-start with supervised fine-tuning on high-quality tool invocation and reflection data to bootstrap agent behaviors; second, end-to-end agentic reinforcement learning combining pointwise rewards (final image quality) and pairwise rewards (reflection accuracy), with trajectory resampling for enhanced multi-turn exploration. GenAgent significantly boosts base generator(FLUX.1-dev) performance on GenEval++ (+23.6\\%) and WISE (+14\\%). Beyond performance gains, our framework demonstrates three key properties: 1) cross-tool generalization to generators with varying capabilities, 2) test-time scaling with consistent improvements across interaction rounds, and 3) task-adaptive reasoning that automatically adjusts to different tasks. Our code will be available at \\href{https://github.com/deep-kaixun/GenAgent}{this url}.",
      "url": "http://arxiv.org/abs/2601.18543",
      "author": "Kaixun Jiang, Yuzheng Wang, Junjie Zhou, Pandeng Li, Zhihang Liu, Chen-Wei Xie, Zhaoyu Chen, Yun Zheng, Wenqiang Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "GenAgent unifies visual understanding and generation through an agentic multimodal model that treats image generators as tools, enabling autonomous multi-turn refinement with reasoning, judgment, and reflection.",
      "importance_score": 72,
      "reasoning": "Important direction for scaling text-to-image with agentic reasoning. Avoids expensive unified model training while enabling iterative refinement.",
      "themes": [
        "AI Agents",
        "Image Generation",
        "Multimodal Models",
        "Scaling"
      ],
      "continuation": null,
      "summary_html": "<p>GenAgent unifies visual understanding and generation through an agentic multimodal model that treats image generators as tools, enabling autonomous multi-turn refinement with reasoning, judgment, and reflection.</p>",
      "content_html": "<p>arXiv:2601.18543v1 Announce Type: new  Abstract: We introduce GenAgent, unifying visual understanding and generation through an agentic multimodal model. Unlike unified models that face expensive training costs and understanding-generation trade-offs, GenAgent decouples these capabilities through an agentic framework: understanding is handled by the multimodal model itself, while generation is achieved by treating image generation models as invokable tools. Crucially, unlike existing modular systems constrained by static pipelines, this design enables autonomous multi-turn interactions where the agent generates multimodal chains-of-thought encompassing reasoning, tool invocation, judgment, and reflection to iteratively refine outputs. We employ a two-stage training strategy: first, cold-start with supervised fine-tuning on high-quality tool invocation and reflection data to bootstrap agent behaviors; second, end-to-end agentic reinforcement learning combining pointwise rewards (final image quality) and pairwise rewards (reflection accuracy), with trajectory resampling for enhanced multi-turn exploration. GenAgent significantly boosts base generator(FLUX.1-dev) performance on GenEval++ (+23.6\\%) and WISE (+14\\%). Beyond performance gains, our framework demonstrates three key properties: 1) cross-tool generalization to generators with varying capabilities, 2) test-time scaling with consistent improvements across interaction rounds, and 3) task-adaptive reasoning that automatically adjusts to different tasks. Our code will be available at \\href{https://github.com/deep-kaixun/GenAgent}{this url}.</p>"
    },
    {
      "id": "f293aab96970",
      "title": "EEG Foundation Models: Progresses, Benchmarking, and Open Problems",
      "content": "arXiv:2601.17883v1 Announce Type: cross  Abstract: Electroencephalography (EEG) foundation models have recently emerged as a promising paradigm for brain-computer interfaces (BCIs), aiming to learn transferable neural representations from large-scale heterogeneous recordings. Despite rapid progresses, there lacks fair and comprehensive comparisons of existing EEG foundation models, due to inconsistent pre-training objectives, preprocessing choices, and downstream evaluation protocols. This paper fills this gap. We first review 50 representative models and organize their design choices into a unified taxonomic framework including data standardization, model architectures, and self-supervised pre-training strategies. We then evaluate 12 open-source foundation models and competitive specialist baselines across 13 EEG datasets spanning nine BCI paradigms. Emphasizing real-world deployments, we consider both cross-subject generalization under a leave-one-subject-out protocol and rapid calibration under a within-subject few-shot setting. We further compare full-parameter fine-tuning with linear probing to assess the transferability of pre-trained representations, and examine the relationship between model scale and downstream performance. Our results indicate that: 1) linear probing is frequently insufficient; 2) specialist models trained from scratch remain competitive across many tasks; and, 3) larger foundation models do not necessarily yield better generalization performance under current data regimes and training practices.",
      "url": "http://arxiv.org/abs/2601.17883",
      "author": "Dingkun Liu, Yuheng Chen, Zhu Chen, Zhenyao Cui, Yaozhi Wen, Jiayu An, Jingwei Luo, Dongrui Wu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Comprehensive review and benchmark of 50 EEG foundation models, organizing design choices into unified taxonomy and evaluating 12 open-source models with competitive baselines across multiple tasks.",
      "importance_score": 72,
      "reasoning": "Valuable survey and systematic benchmark paper filling important gap in EEG foundation model evaluation, useful for BCI research community.",
      "themes": [
        "Foundation Models",
        "EEG/BCI",
        "Benchmark Development",
        "Survey Paper"
      ],
      "continuation": null,
      "summary_html": "<p>Comprehensive review and benchmark of 50 EEG foundation models, organizing design choices into unified taxonomy and evaluating 12 open-source models with competitive baselines across multiple tasks.</p>",
      "content_html": "<p>arXiv:2601.17883v1 Announce Type: cross  Abstract: Electroencephalography (EEG) foundation models have recently emerged as a promising paradigm for brain-computer interfaces (BCIs), aiming to learn transferable neural representations from large-scale heterogeneous recordings. Despite rapid progresses, there lacks fair and comprehensive comparisons of existing EEG foundation models, due to inconsistent pre-training objectives, preprocessing choices, and downstream evaluation protocols. This paper fills this gap. We first review 50 representative models and organize their design choices into a unified taxonomic framework including data standardization, model architectures, and self-supervised pre-training strategies. We then evaluate 12 open-source foundation models and competitive specialist baselines across 13 EEG datasets spanning nine BCI paradigms. Emphasizing real-world deployments, we consider both cross-subject generalization under a leave-one-subject-out protocol and rapid calibration under a within-subject few-shot setting. We further compare full-parameter fine-tuning with linear probing to assess the transferability of pre-trained representations, and examine the relationship between model scale and downstream performance. Our results indicate that: 1) linear probing is frequently insufficient; 2) specialist models trained from scratch remain competitive across many tasks; and, 3) larger foundation models do not necessarily yield better generalization performance under current data regimes and training practices.</p>"
    },
    {
      "id": "b7de29539aef",
      "title": "Reasoning Long Jump: Why we shouldnt rely on CoT monitoring for interpretability",
      "content": "In Part One, we explore how models sometimes rationalise a pre-conceived answer to generate a chain of thought, rather than using the chain of thought to produce the answer. In Part Two, the implications of this finding for frontier models, and their reasoning efficiency, are discussed.TLDRReasoning models are doing more efficient reasoning whilst getting better at tasks such as coding. As models continue to improve, they will take bigger reasoning jumps which will make it very challenging to use the CoT as a method of interpretability. Further into the future, models may stop using CoT entirely and move towards reasoning directly in the latent space - never reasoning using language.Part 1: ExperimentationThe (simplified) argument for why we shouldnt rely on reading the chain of thought (CoT) as a method of interpretability is that models dont always truthfully say how they have reached their answer in the CoT. Instead, models sometimes use CoT to rationalise answers that they have already decided on. This is shown by Turpin et al where hints were added to questions posed to reasoning models and the impact of this on the CoT was observed: the hints were used by the model to arrive at its answer, but they were not always included in the CoT. This implies that, in its CoT, the model was just rationalising an answer that it had already settled on. We dont want a models rationalisation of an answer, we want to know how it arrived there!Recreating hint resultsThe DeepSeek R1-Distill Qwen-14B model (48 layers) is used. In this section we will focus on the visual hint example shown in Figure 1, but you can see the other prompts used in the Github repo. Both few shot visual hints (Figure 1) and few shot always option A hint prompts were used.In Figure 1 in the hinted prompt, a square was placed next to the correct multiple choice option.Figure 1: Control and hinted prompt - hinted prompt has a  next to the answerFigure 2: Prompt responses. Left: control CoT. Right: v...",
      "url": "https://www.lesswrong.com/posts/NE33XtSKmKskNaSxm/reasoning-long-jump-why-we-shouldn-t-rely-on-cot-monitoring",
      "author": "tobypullan",
      "published": "2026-01-26T05:10:36.175000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Argues against relying on Chain-of-Thought monitoring for interpretability, showing that models sometimes rationalize pre-conceived answers rather than reasoning through CoT. Suggests models are taking bigger 'reasoning jumps' and may eventually reason entirely in latent space.",
      "importance_score": 72,
      "reasoning": "Important point for AI safety interpretability methods. Builds on existing work (Turpin et al.) with relevant implications for frontier model oversight. Argues for fundamental limitations of CoT-based interpretability.",
      "themes": [
        "Interpretability",
        "Chain of Thought",
        "AI Safety",
        "Reasoning Models"
      ],
      "continuation": null,
      "summary_html": "<p>Argues against relying on Chain-of-Thought monitoring for interpretability, showing that models sometimes rationalize pre-conceived answers rather than reasoning through CoT. Suggests models are taking bigger 'reasoning jumps' and may eventually reason entirely in latent space.</p>",
      "content_html": "<p>In Part One, we explore how models sometimes rationalise a pre-conceived answer to generate a chain of thought, rather than using the chain of thought to produce the answer. In Part Two, the implications of this finding for frontier models, and their reasoning efficiency, are discussed.TLDRReasoning models are doing more efficient reasoning whilst getting better at tasks such as coding. As models continue to improve, they will take bigger reasoning jumps which will make it very challenging to use the CoT as a method of interpretability. Further into the future, models may stop using CoT entirely and move towards reasoning directly in the latent space - never reasoning using language.Part 1: ExperimentationThe (simplified) argument for why we shouldnt rely on reading the chain of thought (CoT) as a method of interpretability is that models dont always truthfully say how they have reached their answer in the CoT. Instead, models sometimes use CoT to rationalise answers that they have already decided on. This is shown by Turpin et al where hints were added to questions posed to reasoning models and the impact of this on the CoT was observed: the hints were used by the model to arrive at its answer, but they were not always included in the CoT. This implies that, in its CoT, the model was just rationalising an answer that it had already settled on. We dont want a models rationalisation of an answer, we want to know how it arrived there!Recreating hint resultsThe DeepSeek R1-Distill Qwen-14B model (48 layers) is used. In this section we will focus on the visual hint example shown in Figure 1, but you can see the other prompts used in the Github repo. Both few shot visual hints (Figure 1) and few shot always option A hint prompts were used.In Figure 1 in the hinted prompt, a square was placed next to the correct multiple choice option.Figure 1: Control and hinted prompt - hinted prompt has a  next to the answerFigure 2: Prompt responses. Left: control CoT. Right: v...</p>"
    },
    {
      "id": "537de70701b9",
      "title": "JaxARC: A High-Performance JAX-based Environment for Abstraction and Reasoning Research",
      "content": "arXiv:2601.17564v1 Announce Type: new  Abstract: The Abstraction and Reasoning Corpus (ARC) tests AI systems' ability to perform human-like inductive reasoning from a few demonstration pairs. Existing Gymnasium-based RL environments severely limit experimental scale due to computational bottlenecks. We present JaxARC, an open-source, high-performance RL environment for ARC implemented in JAX. Its functional, stateless architecture enables massive parallelism, achieving 38-5,439x speedup over Gymnasium at matched batch sizes, with peak throughput of 790M steps/second. JaxARC supports multiple ARC datasets, flexible action spaces, composable wrappers, and configuration-driven reproducibility, enabling large-scale RL research previously computationally infeasible. JaxARC is available at https://github.com/aadimator/JaxARC.",
      "url": "http://arxiv.org/abs/2601.17564",
      "author": "Aadam, Monu Verma, Mohamed Abdel-Mottaleb",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Presents JaxARC, a high-performance JAX-based RL environment for the Abstraction and Reasoning Corpus achieving 38-5,439x speedup over Gymnasium implementations with 790M steps/second throughput.",
      "importance_score": 71,
      "reasoning": "Significant infrastructure contribution enabling large-scale research on important reasoning benchmark; substantial performance improvements unlock new research possibilities.",
      "themes": [
        "Reasoning",
        "Reinforcement Learning",
        "Research Infrastructure"
      ],
      "continuation": null,
      "summary_html": "<p>Presents JaxARC, a high-performance JAX-based RL environment for the Abstraction and Reasoning Corpus achieving 38-5,439x speedup over Gymnasium implementations with 790M steps/second throughput.</p>",
      "content_html": "<p>arXiv:2601.17564v1 Announce Type: new  Abstract: The Abstraction and Reasoning Corpus (ARC) tests AI systems' ability to perform human-like inductive reasoning from a few demonstration pairs. Existing Gymnasium-based RL environments severely limit experimental scale due to computational bottlenecks. We present JaxARC, an open-source, high-performance RL environment for ARC implemented in JAX. Its functional, stateless architecture enables massive parallelism, achieving 38-5,439x speedup over Gymnasium at matched batch sizes, with peak throughput of 790M steps/second. JaxARC supports multiple ARC datasets, flexible action spaces, composable wrappers, and configuration-driven reproducibility, enabling large-scale RL research previously computationally infeasible. JaxARC is available at https://github.com/aadimator/JaxARC.</p>"
    },
    {
      "id": "7051f4e50d52",
      "title": "Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models",
      "content": "arXiv:2601.18383v1 Announce Type: new  Abstract: Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency.",
      "url": "http://arxiv.org/abs/2601.18383",
      "author": "Zhenyuan Guo, Tong Chen, Wenlong Meng, Chen Gong, Xin Yu, Chengkun Wei, Wenzhi Chen",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes DynTS using attention maps to identify decision-critical tokens in reasoning traces, retaining only their KV cache states to reduce memory while maintaining accuracy in Large Reasoning Models.",
      "importance_score": 71,
      "reasoning": "Practical efficiency improvement for reasoning models; principled approach to KV cache management with attention-based selection.",
      "themes": [
        "Reasoning",
        "Efficiency",
        "KV Cache"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes DynTS using attention maps to identify decision-critical tokens in reasoning traces, retaining only their KV cache states to reduce memory while maintaining accuracy in Large Reasoning Models.</p>",
      "content_html": "<p>arXiv:2601.18383v1 Announce Type: new  Abstract: Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency.</p>"
    },
    {
      "id": "99c28ad75a5e",
      "title": "DPI: Exploiting Parameter Heterogeneity for Interference-Free Fine-Tuning",
      "content": "arXiv:2601.17777v1 Announce Type: cross  Abstract: Supervised fine-tuning (SFT) is a crucial step for adapting large language models (LLMs) to downstream tasks. However, conflicting objectives across heterogeneous SFT tasks often induce the \"seesaw effect\": optimizing for one task may degrade performance on others, particularly when model parameters are updated indiscriminately. In this paper, we propose a principled approach to disentangle and isolate task-specific parameter regions, motivated by the hypothesis that parameter heterogeneity underlies cross-task interference. Specifically, we first independently fine-tune LLMs on diverse SFT tasks and identify each task's core parameter region as the subset of parameters exhibiting the largest updates. Tasks with highly overlapping core parameter regions are merged for joint training, while disjoint tasks are organized into different stages. During multi-stage SFT, core parameters acquired in prior tasks are frozen, thereby preventing overwriting by subsequent tasks. To verify the effectiveness of our method, we conducted intensive experiments on multiple public datasets. The results showed that our dynamic parameter isolation strategy consistently reduced data conflicts and achieved consistent performance improvements compared to multi-stage and multi-task tuning baselines.",
      "url": "http://arxiv.org/abs/2601.17777",
      "author": "Xiaoyu Liu, Xiaoyu Guan, Di Liang, Xianjie Wu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "DPI addresses 'seesaw effect' in multi-task SFT by identifying task-specific parameter regions (largest updates) and isolating fine-tuning to non-overlapping regions to prevent cross-task interference.",
      "importance_score": 71,
      "reasoning": "Addresses practical multi-task fine-tuning problem. Principled approach based on parameter heterogeneity hypothesis. Useful for practitioners.",
      "themes": [
        "Fine-tuning",
        "Multi-task Learning",
        "Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>DPI addresses 'seesaw effect' in multi-task SFT by identifying task-specific parameter regions (largest updates) and isolating fine-tuning to non-overlapping regions to prevent cross-task interference.</p>",
      "content_html": "<p>arXiv:2601.17777v1 Announce Type: cross  Abstract: Supervised fine-tuning (SFT) is a crucial step for adapting large language models (LLMs) to downstream tasks. However, conflicting objectives across heterogeneous SFT tasks often induce the \"seesaw effect\": optimizing for one task may degrade performance on others, particularly when model parameters are updated indiscriminately. In this paper, we propose a principled approach to disentangle and isolate task-specific parameter regions, motivated by the hypothesis that parameter heterogeneity underlies cross-task interference. Specifically, we first independently fine-tune LLMs on diverse SFT tasks and identify each task's core parameter region as the subset of parameters exhibiting the largest updates. Tasks with highly overlapping core parameter regions are merged for joint training, while disjoint tasks are organized into different stages. During multi-stage SFT, core parameters acquired in prior tasks are frozen, thereby preventing overwriting by subsequent tasks. To verify the effectiveness of our method, we conducted intensive experiments on multiple public datasets. The results showed that our dynamic parameter isolation strategy consistently reduced data conflicts and achieved consistent performance improvements compared to multi-stage and multi-task tuning baselines.</p>"
    },
    {
      "id": "80a03c8a8218",
      "title": "TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment",
      "content": "arXiv:2601.18292v1 Announce Type: cross  Abstract: In recent years, safety risks associated with large language models have become increasingly prominent, highlighting the urgent need to mitigate the generation of toxic and harmful content. The mainstream paradigm for LLM safety alignment typically adopts a collaborative framework involving three roles: an attacker for adversarial prompt generation, a defender for safety defense, and an evaluator for response assessment. In this paper, we propose a closed-loop reinforcement learning framework called TriPlay-RL that enables iterative and co-improving collaboration among three roles with near-zero manual annotation. Experimental results show that the attacker preserves high output diversity while achieving a 20%-50% improvement in adversarial effectiveness; the defender attains 10%-30% gains in safety performance without degrading general reasoning capability; and the evaluator continuously refines its fine-grained judgment ability through iterations, accurately distinguishing unsafe responses, simple refusals, and useful guidance. Overall, our framework establishes an efficient and scalable paradigm for LLM safety alignment, enabling continuous co-evolution within a unified learning loop.",
      "url": "http://arxiv.org/abs/2601.18292",
      "author": "Zhewen Tan, Wenhan Yu, Jianfeng Si, Tongxin Liu, Kaiqi Guan, Huiyan Jin, Jiawen Tao, Xiaokun Yuan, Duohe Ma, Xiangzheng Zhang, Tong Yang, Lin Sun",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes TriPlay-RL, closed-loop RL framework with three co-improving roles (attacker, defender, evaluator) for LLM safety alignment with near-zero manual annotation. Shows 20-50% improvement in adversarial success.",
      "importance_score": 71,
      "reasoning": "Novel self-play approach for safety alignment. Near-zero annotation requirement is significant. 20-50% improvement in red-teaming suggests meaningful capability.",
      "themes": [
        "AI Safety",
        "Alignment",
        "Reinforcement Learning",
        "Red-teaming"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes TriPlay-RL, closed-loop RL framework with three co-improving roles (attacker, defender, evaluator) for LLM safety alignment with near-zero manual annotation. Shows 20-50% improvement in adversarial success.</p>",
      "content_html": "<p>arXiv:2601.18292v1 Announce Type: cross  Abstract: In recent years, safety risks associated with large language models have become increasingly prominent, highlighting the urgent need to mitigate the generation of toxic and harmful content. The mainstream paradigm for LLM safety alignment typically adopts a collaborative framework involving three roles: an attacker for adversarial prompt generation, a defender for safety defense, and an evaluator for response assessment. In this paper, we propose a closed-loop reinforcement learning framework called TriPlay-RL that enables iterative and co-improving collaboration among three roles with near-zero manual annotation. Experimental results show that the attacker preserves high output diversity while achieving a 20%-50% improvement in adversarial effectiveness; the defender attains 10%-30% gains in safety performance without degrading general reasoning capability; and the evaluator continuously refines its fine-grained judgment ability through iterations, accurately distinguishing unsafe responses, simple refusals, and useful guidance. Overall, our framework establishes an efficient and scalable paradigm for LLM safety alignment, enabling continuous co-evolution within a unified learning loop.</p>"
    },
    {
      "id": "0e669703bb43",
      "title": "Frame-Guided Synthetic Claim Generation for Automatic Fact-Checking Using High-Volume Tabular Data",
      "content": "arXiv:2601.17232v1 Announce Type: new  Abstract: Automated fact-checking benchmarks have largely ignored the challenge of verifying claims against real-world, high-volume structured data, instead focusing on small, curated tables. We introduce a new large-scale, multilingual dataset to address this critical gap. It contains 78,503 synthetic claims grounded in 434 complex OECD tables, which average over 500K rows each. We propose a novel, frame-guided methodology where algorithms programmatically select significant data points based on six semantic frames to generate realistic claims in English, Chinese, Spanish, and Hindi. Crucially, we demonstrate through knowledge-probing experiments that LLMs have not memorized these facts, forcing systems to perform genuine retrieval and reasoning rather than relying on parameterized knowledge. We provide a baseline SQL-generation system and show that our benchmark is highly challenging. Our analysis identifies evidence retrieval as the primary bottleneck, with models struggling to find the correct data in massive tables. This dataset provides a critical new resource for advancing research on this unsolved, real-world problem.",
      "url": "http://arxiv.org/abs/2601.17232",
      "author": "Jacob Devasier, Akshith Putta, Qing Wang, Alankrit Moses, Chengkai Li",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Creates large-scale multilingual fact-checking dataset with 78,503 synthetic claims across English, Chinese, Spanish, and Hindi grounded in complex OECD tables averaging 500K+ rows. Demonstrates LLMs haven't memorized these facts.",
      "importance_score": 71,
      "reasoning": "Significant resource contribution for fact-checking against structured data. Novel frame-guided methodology and proof that genuine reasoning is required.",
      "themes": [
        "Fact-Checking",
        "Multilingual NLP",
        "Dataset",
        "Structured Data"
      ],
      "continuation": null,
      "summary_html": "<p>Creates large-scale multilingual fact-checking dataset with 78,503 synthetic claims across English, Chinese, Spanish, and Hindi grounded in complex OECD tables averaging 500K+ rows. Demonstrates LLMs haven't memorized these facts.</p>",
      "content_html": "<p>arXiv:2601.17232v1 Announce Type: new  Abstract: Automated fact-checking benchmarks have largely ignored the challenge of verifying claims against real-world, high-volume structured data, instead focusing on small, curated tables. We introduce a new large-scale, multilingual dataset to address this critical gap. It contains 78,503 synthetic claims grounded in 434 complex OECD tables, which average over 500K rows each. We propose a novel, frame-guided methodology where algorithms programmatically select significant data points based on six semantic frames to generate realistic claims in English, Chinese, Spanish, and Hindi. Crucially, we demonstrate through knowledge-probing experiments that LLMs have not memorized these facts, forcing systems to perform genuine retrieval and reasoning rather than relying on parameterized knowledge. We provide a baseline SQL-generation system and show that our benchmark is highly challenging. Our analysis identifies evidence retrieval as the primary bottleneck, with models struggling to find the correct data in massive tables. This dataset provides a critical new resource for advancing research on this unsolved, real-world problem.</p>"
    },
    {
      "id": "65cea2fa240c",
      "title": "A Universal Load Balancing Principle and Its Application to Large Language Model Serving",
      "content": "arXiv:2601.17855v1 Announce Type: cross  Abstract: Load balancing-the allocation of work across parallel resources to reduce delay, energy and cost-is a pervasive challenge in science and engineering, from large-scale simulation and data processing to cloud and manufacturing operations. Motivated by the emerging bottleneck in large language model (LLM) serving, we study a particularly stringent regime of load balancing that arises in barrier-synchronized, stateful systems: work cannot be freely migrated and progress is gated by the slowest participant at each step, so heterogeneity and temporal drift in workloads create persistent stragglers and substantial idle time. LLM serving under data-parallel decoding provides a prominent modern instance: in production traces, barrier-induced idle can exceed 40% of compute time per decode step. Here we develop a universal load-balancing principle, which admits a step-wise finite-horizon integer-optimization formulation and yields worst-case guarantees: across LLM decode models and a broader class of non-decreasing workload drift processes, it reduces long-run imbalance by a factor that grows with batch size and system scale. Extensive experiments corroborate the theory, showing substantial improvements in throughput and latency together with reductions in energy consumption. These results provide a general, theoretically grounded framework for load balancing, with immediate implications for sustainable LLM serving and broad relevance to other synchronization-gated resource-allocation problems.",
      "url": "http://arxiv.org/abs/2601.17855",
      "author": "Zixi Chen, Tianci Bu, Chendong Song, Xin Lu, Yinyu Ye, Zijie Zhou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "cs.DC"
      ],
      "summary": "Studies load balancing in barrier-synchronized stateful systems like LLM serving, proposing universal principle that achieves near-optimal idle time reduction.",
      "importance_score": 71,
      "reasoning": "Highly relevant to LLM infrastructure with theoretical foundation and practical validation on production traces. Addresses key bottleneck in LLM serving.",
      "themes": [
        "LLM Infrastructure",
        "Load Balancing",
        "Systems Optimization"
      ],
      "continuation": null,
      "summary_html": "<p>Studies load balancing in barrier-synchronized stateful systems like LLM serving, proposing universal principle that achieves near-optimal idle time reduction.</p>",
      "content_html": "<p>arXiv:2601.17855v1 Announce Type: cross  Abstract: Load balancing-the allocation of work across parallel resources to reduce delay, energy and cost-is a pervasive challenge in science and engineering, from large-scale simulation and data processing to cloud and manufacturing operations. Motivated by the emerging bottleneck in large language model (LLM) serving, we study a particularly stringent regime of load balancing that arises in barrier-synchronized, stateful systems: work cannot be freely migrated and progress is gated by the slowest participant at each step, so heterogeneity and temporal drift in workloads create persistent stragglers and substantial idle time. LLM serving under data-parallel decoding provides a prominent modern instance: in production traces, barrier-induced idle can exceed 40% of compute time per decode step. Here we develop a universal load-balancing principle, which admits a step-wise finite-horizon integer-optimization formulation and yields worst-case guarantees: across LLM decode models and a broader class of non-decreasing workload drift processes, it reduces long-run imbalance by a factor that grows with batch size and system scale. Extensive experiments corroborate the theory, showing substantial improvements in throughput and latency together with reductions in energy consumption. These results provide a general, theoretically grounded framework for load balancing, with immediate implications for sustainable LLM serving and broad relevance to other synchronization-gated resource-allocation problems.</p>"
    },
    {
      "id": "af53cd338ac5",
      "title": "Phase Transition for Budgeted Multi-Agent Synergy",
      "content": "arXiv:2601.17311v1 Announce Type: new  Abstract: Multi-agent systems can improve reliability, yet under a fixed inference budget they often help, saturate, or even collapse. We develop a minimal and calibratable theory that predicts these regimes from three binding constraints of modern agent stacks: finite context windows, lossy inter-agent communication, and shared failures among similar agents. Each leaf agent is summarized by a compute-performance scaling exponent $\\beta$; communication is captured by a message-length fidelity curve $\\gamma(m)$; dependence is captured by an effective shared-error correlation $\\rho$; and a context window $W$ imposes hard fan-in limits that make hierarchy necessary. For binary success/failure tasks with majority aggregation, we prove a sharp phase transition for deep $b$-ary trees with correlated inputs and lossy communication: a single scalar $\\alpha_\\rho$ (combining $\\gamma(m)$, $\\rho$, and fan-in $b$) determines whether weak signal is amplified to a nontrivial fixed point or washed out to chance. In the amplifying regime, we derive an organization exponent $s$ and show that budgeted synergy, i.e., outperforming the best single agent under the same total budget, occurs exactly when $s>\\beta$, yielding closed-form compute allocation rules and explicit budget thresholds. We further characterize saturation via a mixing depth and provide a conservative clipped predictor that remains accurate across growth and saturation. A continuous-performance warm-up gives closed-form risks for star, chain, and tree organizations, making correlation- and communication-induced floors explicit and exposing the core design trade-offs in a smooth setting. Finally, we validate the predicted phase boundaries in controlled synthetic simulations and show how the same mechanisms explain the dominant bottlenecks reported in recent large-scale matched-budget studies of LLM agent-system scaling.",
      "url": "http://arxiv.org/abs/2601.17311",
      "author": "Bang Liu, Linglong Kong, Jian Pei",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Develops a theoretical framework predicting when multi-agent systems help, saturate, or collapse under fixed inference budgets, identifying phase transitions based on context windows, communication fidelity, and error correlation.",
      "importance_score": 70,
      "reasoning": "Novel theoretical contribution providing calibratable predictions for multi-agent performance; addresses practical deployment questions with rigorous analysis.",
      "themes": [
        "Multi-Agent Systems",
        "Theoretical AI",
        "Scaling Laws"
      ],
      "continuation": null,
      "summary_html": "<p>Develops a theoretical framework predicting when multi-agent systems help, saturate, or collapse under fixed inference budgets, identifying phase transitions based on context windows, communication fidelity, and error correlation.</p>",
      "content_html": "<p>arXiv:2601.17311v1 Announce Type: new  Abstract: Multi-agent systems can improve reliability, yet under a fixed inference budget they often help, saturate, or even collapse. We develop a minimal and calibratable theory that predicts these regimes from three binding constraints of modern agent stacks: finite context windows, lossy inter-agent communication, and shared failures among similar agents. Each leaf agent is summarized by a compute-performance scaling exponent $\\beta$; communication is captured by a message-length fidelity curve $\\gamma(m)$; dependence is captured by an effective shared-error correlation $\\rho$; and a context window $W$ imposes hard fan-in limits that make hierarchy necessary. For binary success/failure tasks with majority aggregation, we prove a sharp phase transition for deep $b$-ary trees with correlated inputs and lossy communication: a single scalar $\\alpha_\\rho$ (combining $\\gamma(m)$, $\\rho$, and fan-in $b$) determines whether weak signal is amplified to a nontrivial fixed point or washed out to chance. In the amplifying regime, we derive an organization exponent $s$ and show that budgeted synergy, i.e., outperforming the best single agent under the same total budget, occurs exactly when $s&gt;\\beta$, yielding closed-form compute allocation rules and explicit budget thresholds. We further characterize saturation via a mixing depth and provide a conservative clipped predictor that remains accurate across growth and saturation. A continuous-performance warm-up gives closed-form risks for star, chain, and tree organizations, making correlation- and communication-induced floors explicit and exposing the core design trade-offs in a smooth setting. Finally, we validate the predicted phase boundaries in controlled synthetic simulations and show how the same mechanisms explain the dominant bottlenecks reported in recent large-scale matched-budget studies of LLM agent-system scaling.</p>"
    },
    {
      "id": "7e6f07d743e9",
      "title": "OffSeeker: Online Reinforcement Learning Is Not All You Need for Deep Research Agents",
      "content": "arXiv:2601.18467v1 Announce Type: new  Abstract: Deep research agents have shown remarkable potential in handling long-horizon tasks. However, state-of-the-art performance typically relies on online reinforcement learning (RL), which is financially expensive due to extensive API calls. While offline training offers a more efficient alternative, its progress is hindered by the scarcity of high-quality research trajectories. In this paper, we demonstrate that expensive online reinforcement learning is not all you need to build powerful research agents. To bridge this gap, we introduce a fully open-source suite designed for effective offline training. Our core contributions include DeepForge, a ready-to-use task synthesis framework that generates large-scale research queries without heavy preprocessing; and a curated collection of 66k QA pairs, 33k SFT trajectories, and 21k DPO pairs. Leveraging these resources, we train OffSeeker (8B), a model developed entirely offline. Extensive evaluations across six benchmarks show that OffSeeker not only leads among similar-sized agents but also remains competitive with 30B-parameter systems trained via heavy online RL.",
      "url": "http://arxiv.org/abs/2601.18467",
      "author": "Yuhang Zhou, Kai Zheng, Qiguang Chen, Mengkang Hu, Qingfeng Sun, Can Xu, Jingjing Chen",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces OffSeeker demonstrating expensive online RL is not necessary for research agents, providing open-source suite including DeepForge task synthesis framework for effective offline training.",
      "importance_score": 70,
      "reasoning": "Important practical finding reducing barrier to research agent training; fully open-source contribution.",
      "themes": [
        "Agentic AI",
        "Reinforcement Learning",
        "Deep Research"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces OffSeeker demonstrating expensive online RL is not necessary for research agents, providing open-source suite including DeepForge task synthesis framework for effective offline training.</p>",
      "content_html": "<p>arXiv:2601.18467v1 Announce Type: new  Abstract: Deep research agents have shown remarkable potential in handling long-horizon tasks. However, state-of-the-art performance typically relies on online reinforcement learning (RL), which is financially expensive due to extensive API calls. While offline training offers a more efficient alternative, its progress is hindered by the scarcity of high-quality research trajectories. In this paper, we demonstrate that expensive online reinforcement learning is not all you need to build powerful research agents. To bridge this gap, we introduce a fully open-source suite designed for effective offline training. Our core contributions include DeepForge, a ready-to-use task synthesis framework that generates large-scale research queries without heavy preprocessing; and a curated collection of 66k QA pairs, 33k SFT trajectories, and 21k DPO pairs. Leveraging these resources, we train OffSeeker (8B), a model developed entirely offline. Extensive evaluations across six benchmarks show that OffSeeker not only leads among similar-sized agents but also remains competitive with 30B-parameter systems trained via heavy online RL.</p>"
    },
    {
      "id": "f6461bed1f19",
      "title": "Do VLMs Have a Moral Backbone? A Study on the Fragile Morality of Vision-Language Models",
      "content": "arXiv:2601.17082v1 Announce Type: cross  Abstract: Despite substantial efforts toward improving the moral alignment of Vision-Language Models (VLMs), it remains unclear whether their ethical judgments are stable in realistic settings. This work studies moral robustness in VLMs, defined as the ability to preserve moral judgments under textual and visual perturbations that do not alter the underlying moral context. We systematically probe VLMs with a diverse set of model-agnostic multimodal perturbations and find that their moral stances are highly fragile, frequently flipping under simple manipulations. Our analysis reveals systematic vulnerabilities across perturbation types, moral domains, and model scales, including a sycophancy trade-off where stronger instruction-following models are more susceptible to persuasion. We further show that lightweight inference-time interventions can partially restore moral stability. These results demonstrate that moral alignment alone is insufficient and that moral robustness is a necessary criterion for the responsible deployment of VLMs.",
      "url": "http://arxiv.org/abs/2601.17082",
      "author": "Zhining Liu, Tianyi Wang, Xiao Lin, Penghao Ouyang, Gaotang Li, Ze Yang, Hui Liu, Sumit Keswani, Vishwa Pardeshi, Huijun Zhao, Wei Fan, Hanghang Tong",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Studies moral robustness in VLMs, finding ethical judgments are highly fragile under simple text and visual perturbations. Reveals sycophancy trade-off in instruction-following models.",
      "importance_score": 70,
      "reasoning": "Important finding for AI safety showing VLM moral judgments are unstable. Systematic evaluation with practical implications for deployment.",
      "themes": [
        "AI Safety",
        "VLM Evaluation",
        "Moral Reasoning",
        "Robustness"
      ],
      "continuation": null,
      "summary_html": "<p>Studies moral robustness in VLMs, finding ethical judgments are highly fragile under simple text and visual perturbations. Reveals sycophancy trade-off in instruction-following models.</p>",
      "content_html": "<p>arXiv:2601.17082v1 Announce Type: cross  Abstract: Despite substantial efforts toward improving the moral alignment of Vision-Language Models (VLMs), it remains unclear whether their ethical judgments are stable in realistic settings. This work studies moral robustness in VLMs, defined as the ability to preserve moral judgments under textual and visual perturbations that do not alter the underlying moral context. We systematically probe VLMs with a diverse set of model-agnostic multimodal perturbations and find that their moral stances are highly fragile, frequently flipping under simple manipulations. Our analysis reveals systematic vulnerabilities across perturbation types, moral domains, and model scales, including a sycophancy trade-off where stronger instruction-following models are more susceptible to persuasion. We further show that lightweight inference-time interventions can partially restore moral stability. These results demonstrate that moral alignment alone is insufficient and that moral robustness is a necessary criterion for the responsible deployment of VLMs.</p>"
    },
    {
      "id": "d46fc0564364",
      "title": "Conformal Feedback Alignment: Quantifying Answer-Level Reliability for Robust LLM Alignment",
      "content": "arXiv:2601.17329v1 Announce Type: cross  Abstract: Preference-based alignment like Reinforcement Learning from Human Feedback (RLHF) learns from pairwise preferences, yet the labels are often noisy and inconsistent. Existing uncertainty-aware approaches weight preferences, but ignore a more fundamental factor: the reliability of the \\emph{answers} being compared. To address the problem, we propose Conformal Feedback Alignment (CFA), a framework that grounds preference weighting in the statistical guarantees of Conformal Prediction (CP). CFA quantifies answer-level reliability by constructing conformal prediction sets with controllable coverage and aggregates these reliabilities into principled weights for both DPO- and PPO-style training. Experiments across different datasets show that CFA improves alignment robustness and data efficiency, highlighting that modeling \\emph{answer-side} uncertainty complements preference-level weighting and yields more robust, data-efficient alignment. Codes are provided here.",
      "url": "http://arxiv.org/abs/2601.17329",
      "author": "Tiejin Chen, Xiaoou Liu, Vishnu Nandam, Kuan-Ru Liou, Hua Wei",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes Conformal Feedback Alignment (CFA) using conformal prediction for answer-level reliability quantification in preference-based alignment. Grounds preference weighting in statistical guarantees.",
      "importance_score": 70,
      "reasoning": "Novel approach combining conformal prediction with alignment training. Principled framework for addressing label noise in RLHF.",
      "themes": [
        "Alignment",
        "Conformal Prediction",
        "RLHF",
        "Uncertainty"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Conformal Feedback Alignment (CFA) using conformal prediction for answer-level reliability quantification in preference-based alignment. Grounds preference weighting in statistical guarantees.</p>",
      "content_html": "<p>arXiv:2601.17329v1 Announce Type: cross  Abstract: Preference-based alignment like Reinforcement Learning from Human Feedback (RLHF) learns from pairwise preferences, yet the labels are often noisy and inconsistent. Existing uncertainty-aware approaches weight preferences, but ignore a more fundamental factor: the reliability of the \\emph{answers} being compared. To address the problem, we propose Conformal Feedback Alignment (CFA), a framework that grounds preference weighting in the statistical guarantees of Conformal Prediction (CP). CFA quantifies answer-level reliability by constructing conformal prediction sets with controllable coverage and aggregates these reliabilities into principled weights for both DPO- and PPO-style training. Experiments across different datasets show that CFA improves alignment robustness and data efficiency, highlighting that modeling \\emph{answer-side} uncertainty complements preference-level weighting and yields more robust, data-efficient alignment. Codes are provided here.</p>"
    },
    {
      "id": "557cedf813d2",
      "title": "Improving User Privacy in Personalized Generation: Client-Side Retrieval-Augmented Modification of Server-Side Generated Speculations",
      "content": "arXiv:2601.17569v1 Announce Type: cross  Abstract: Personalization is crucial for aligning Large Language Model (LLM) outputs with individual user preferences and background knowledge. State-of-the-art solutions are based on retrieval augmentation, where relevant context from a user profile is retrieved for LLM consumption. These methods deal with a trade-off between exposing retrieved private data to cloud providers and relying on less capable local models. We introduce $P^3$, an interactive framework for high-quality personalization without revealing private profiles to server-side LLMs. In $P^3$, a large server-side model generates a sequence of $k$ draft tokens based solely on the user query, while a small client-side model, with retrieval access to the user's private profile, evaluates and modifies these drafts to better reflect user preferences. This process repeats until an end token is generated. Experiments on LaMP-QA, a recent benchmark consisting of three personalized question answering datasets, show that $P^3$ consistently outperforms both non-personalized server-side and personalized client-side baselines, achieving statistically significant improvements of $7.4%$ to $9%$ on average. Importantly, $P^3$ recovers $90.3%$ to $95.7%$ of the utility of a ``leaky'' upper-bound scenario in which the full profile is exposed to the large server-side model. Privacy analyses, including linkability and attribute inference attacks, indicate that $P^3$ preserves the privacy of a non-personalized server-side model, introducing only marginal additional leakage ($1.5%$--$3.5%$) compared to submitting a query without any personal context. Additionally, the framework is efficient for edge deployment, with the client-side model generating only $9.2%$ of the total tokens. These results demonstrate that $P^3$ provides a practical, effective solution for personalized generation with improved privacy.",
      "url": "http://arxiv.org/abs/2601.17569",
      "author": "Alireza Salemi, Hamed Zamani",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "P framework enables personalization without revealing private profiles to cloud LLMs through client-side retrieval-augmented modification of server-generated draft tokens.",
      "importance_score": 70,
      "reasoning": "Novel privacy-preserving personalization architecture. Combines speculative decoding with privacy. Practical client-server design.",
      "themes": [
        "Privacy",
        "Personalization",
        "LLM Architecture"
      ],
      "continuation": null,
      "summary_html": "<p>P framework enables personalization without revealing private profiles to cloud LLMs through client-side retrieval-augmented modification of server-generated draft tokens.</p>",
      "content_html": "<p>arXiv:2601.17569v1 Announce Type: cross  Abstract: Personalization is crucial for aligning Large Language Model (LLM) outputs with individual user preferences and background knowledge. State-of-the-art solutions are based on retrieval augmentation, where relevant context from a user profile is retrieved for LLM consumption. These methods deal with a trade-off between exposing retrieved private data to cloud providers and relying on less capable local models. We introduce $P^3$, an interactive framework for high-quality personalization without revealing private profiles to server-side LLMs. In $P^3$, a large server-side model generates a sequence of $k$ draft tokens based solely on the user query, while a small client-side model, with retrieval access to the user's private profile, evaluates and modifies these drafts to better reflect user preferences. This process repeats until an end token is generated. Experiments on LaMP-QA, a recent benchmark consisting of three personalized question answering datasets, show that $P^3$ consistently outperforms both non-personalized server-side and personalized client-side baselines, achieving statistically significant improvements of $7.4%$ to $9%$ on average. Importantly, $P^3$ recovers $90.3%$ to $95.7%$ of the utility of a ``leaky'' upper-bound scenario in which the full profile is exposed to the large server-side model. Privacy analyses, including linkability and attribute inference attacks, indicate that $P^3$ preserves the privacy of a non-personalized server-side model, introducing only marginal additional leakage ($1.5%$--$3.5%$) compared to submitting a query without any personal context. Additionally, the framework is efficient for edge deployment, with the client-side model generating only $9.2%$ of the total tokens. These results demonstrate that $P^3$ provides a practical, effective solution for personalized generation with improved privacy.</p>"
    },
    {
      "id": "94be84abb1a7",
      "title": "Beyond Retention: Orchestrating Structural Safety and Plasticity in Continual Learning for LLMs",
      "content": "arXiv:2601.18255v1 Announce Type: cross  Abstract: Continual learning in Large Language Models (LLMs) faces the critical challenge of balancing stability (retaining old knowledge) and plasticity (learning new tasks). While Experience Replay (ER) is a standard countermeasure against catastrophic forgetting, its impact across diverse capabilities remains underexplored. In this work, we uncover a critical dichotomy in ER's behavior: while it induces positive backward transfer on robust, unstructured tasks (e.g., boosting performance on previous NLP classification tasks through repeated rehearsal), it causes severe negative transfer on fragile, structured domains like code generation (e.g., a significant relative drop in coding accuracy). This reveals that ER trades structural integrity for broad consolidation. To address this dilemma, we propose \\textbf{Orthogonal Subspace Wake-up (OSW)}. OSW identifies essential parameter subspaces of previous tasks via a brief \"wake-up\" phase and enforces orthogonal updates for new tasks, providing a mathematically grounded \"safety guarantee\" for established knowledge structures. Empirical results across a diverse four-task sequence demonstrate that OSW uniquely succeeds in preserving fragile coding abilities where Replay fails, while simultaneously maintaining high plasticity for novel tasks. Our findings emphasize the necessity of evaluating structural safety alongside average retention in LLM continual learning.",
      "url": "http://arxiv.org/abs/2601.18255",
      "author": "Fei Meng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Reveals critical dichotomy in Experience Replay for LLM continual learning: while ER helps unstructured tasks, it causes severe negative transfer on structured domains like code generation, trading structural integrity for broad retention.",
      "importance_score": 70,
      "reasoning": "Important finding about fundamental limitation of standard continual learning technique for LLMs. Reveals ER trades code generation capability for other retention.",
      "themes": [
        "Continual Learning",
        "Language Models",
        "Catastrophic Forgetting",
        "Code Generation"
      ],
      "continuation": null,
      "summary_html": "<p>Reveals critical dichotomy in Experience Replay for LLM continual learning: while ER helps unstructured tasks, it causes severe negative transfer on structured domains like code generation, trading structural integrity for broad retention.</p>",
      "content_html": "<p>arXiv:2601.18255v1 Announce Type: cross  Abstract: Continual learning in Large Language Models (LLMs) faces the critical challenge of balancing stability (retaining old knowledge) and plasticity (learning new tasks). While Experience Replay (ER) is a standard countermeasure against catastrophic forgetting, its impact across diverse capabilities remains underexplored. In this work, we uncover a critical dichotomy in ER's behavior: while it induces positive backward transfer on robust, unstructured tasks (e.g., boosting performance on previous NLP classification tasks through repeated rehearsal), it causes severe negative transfer on fragile, structured domains like code generation (e.g., a significant relative drop in coding accuracy). This reveals that ER trades structural integrity for broad consolidation. To address this dilemma, we propose \\textbf{Orthogonal Subspace Wake-up (OSW)}. OSW identifies essential parameter subspaces of previous tasks via a brief \"wake-up\" phase and enforces orthogonal updates for new tasks, providing a mathematically grounded \"safety guarantee\" for established knowledge structures. Empirical results across a diverse four-task sequence demonstrate that OSW uniquely succeeds in preserving fragile coding abilities where Replay fails, while simultaneously maintaining high plasticity for novel tasks. Our findings emphasize the necessity of evaluating structural safety alongside average retention in LLM continual learning.</p>"
    },
    {
      "id": "fd370ccbe017",
      "title": "VibeTensor: System Software for Deep Learning, Fully Generated by AI Agents",
      "content": "arXiv:2601.16238v1 Announce Type: cross  Abstract: VIBETENSOR is an open-source research system software stack for deep learning, generated by LLM-powered coding agents under high-level human guidance. In this paper, \"fully generated\" refers to code provenance: implementation changes were produced and applied as agent-proposed diffs; validation relied on agent-run builds, tests, and differential checks, without per-change manual diff review. It implements a PyTorch-style eager tensor library with a C++20 core (CPU+CUDA), a torch-like Python overlay via nanobind, and an experimental Node.js/TypeScript interface. Unlike thin bindings, VIBETENSOR includes its own tensor/storage system, schema-lite dispatcher, reverse-mode autograd, CUDA runtime (streams/events/graphs), a stream-ordered caching allocator with diagnostics, and a stable C ABI for dynamically loaded operator plugins. We view this release as a milestone for AI-assisted software engineering: it shows coding agents can generate a coherent deep learning runtime spanning language bindings down to CUDA memory management, validated primarily by builds and tests. We describe the architecture, summarize the workflow used to produce and validate the system, and evaluate the artifact. We report repository scale and test-suite composition, and summarize reproducible microbenchmarks from an accompanying AI-generated kernel suite, including fused attention versus PyTorch SDPA/FlashAttention. We also report end-to-end training sanity checks on 3 small workloads (sequence reversal, ViT, miniGPT) on NVIDIA H100 (Hopper, SM90) and Blackwell-class GPUs; multi-GPU results are Blackwell-only and use an optional CUTLASS-based ring-allreduce plugin gated on CUDA 13+ and sm103a toolchain support. Finally, we discuss failure modes in generated system software, including a \"Frankenstein\" composition effect where locally correct subsystems interact to yield globally suboptimal performance.",
      "url": "http://arxiv.org/abs/2601.16238",
      "author": "Bing Xu, Terry Chen, Fengzhe Zhou, Tianqi Chen, Yangqing Jia, Vinod Grover, Haicheng Wu, Wei Liu, Craig Wittenbrink, Wen-mei Hwu, Roger Bringmann, Ming-Yu Liu, Luis Ceze, Michael Lightstone, Humphrey Shi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.SE"
      ],
      "summary": "VibeTensor is an open-source deep learning system software stack fully generated by LLM-powered coding agents. Implements PyTorch-style eager tensor library with C++20 core, Python overlay, and CUDA runtime.",
      "importance_score": 70,
      "reasoning": "Remarkable demonstration of AI-generated system software; significant milestone for AI-assisted software development.",
      "themes": [
        "AI-Generated Code",
        "Deep Learning Infrastructure",
        "LLM Agents",
        "System Software"
      ],
      "continuation": null,
      "summary_html": "<p>VibeTensor is an open-source deep learning system software stack fully generated by LLM-powered coding agents. Implements PyTorch-style eager tensor library with C++20 core, Python overlay, and CUDA runtime.</p>",
      "content_html": "<p>arXiv:2601.16238v1 Announce Type: cross  Abstract: VIBETENSOR is an open-source research system software stack for deep learning, generated by LLM-powered coding agents under high-level human guidance. In this paper, \"fully generated\" refers to code provenance: implementation changes were produced and applied as agent-proposed diffs; validation relied on agent-run builds, tests, and differential checks, without per-change manual diff review. It implements a PyTorch-style eager tensor library with a C++20 core (CPU+CUDA), a torch-like Python overlay via nanobind, and an experimental Node.js/TypeScript interface. Unlike thin bindings, VIBETENSOR includes its own tensor/storage system, schema-lite dispatcher, reverse-mode autograd, CUDA runtime (streams/events/graphs), a stream-ordered caching allocator with diagnostics, and a stable C ABI for dynamically loaded operator plugins. We view this release as a milestone for AI-assisted software engineering: it shows coding agents can generate a coherent deep learning runtime spanning language bindings down to CUDA memory management, validated primarily by builds and tests. We describe the architecture, summarize the workflow used to produce and validate the system, and evaluate the artifact. We report repository scale and test-suite composition, and summarize reproducible microbenchmarks from an accompanying AI-generated kernel suite, including fused attention versus PyTorch SDPA/FlashAttention. We also report end-to-end training sanity checks on 3 small workloads (sequence reversal, ViT, miniGPT) on NVIDIA H100 (Hopper, SM90) and Blackwell-class GPUs; multi-GPU results are Blackwell-only and use an optional CUTLASS-based ring-allreduce plugin gated on CUDA 13+ and sm103a toolchain support. Finally, we discuss failure modes in generated system software, including a \"Frankenstein\" composition effect where locally correct subsystems interact to yield globally suboptimal performance.</p>"
    },
    {
      "id": "d965c6eee187",
      "title": "Uncertainty Quantification for Named Entity Recognition via Full-Sequence and Subsequence Conformal Prediction",
      "content": "arXiv:2601.16999v1 Announce Type: new  Abstract: Named Entity Recognition (NER) serves as a foundational component in many natural language processing (NLP) pipelines. However, current NER models typically output a single predicted label sequence without any accompanying measure of uncertainty, leaving downstream applications vulnerable to cascading errors. In this paper, we introduce a general framework for adapting sequence-labeling-based NER models to produce uncertainty-aware prediction sets. These prediction sets are collections of full-sentence labelings that are guaranteed to contain the correct labeling with a user-specified confidence level. This approach serves a role analogous to confidence intervals in classical statistics by providing formal guarantees about the reliability of model predictions. Our method builds on conformal prediction, which offers finite-sample coverage guarantees under minimal assumptions. We design efficient nonconformity scoring functions to construct efficient, well-calibrated prediction sets that support both unconditional and class-conditional coverage. This framework accounts for heterogeneity across sentence length, language, entity type, and number of entities within a sentence. Empirical experiments on four NER models across three benchmark datasets demonstrate the broad applicability, validity, and efficiency of the proposed methods.",
      "url": "http://arxiv.org/abs/2601.16999",
      "author": "Matthew Singer, Srijan Sengupta, Karl Pazdernik",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces conformal prediction framework for NER that produces prediction sets guaranteed to contain correct labeling with user-specified confidence. Provides formal statistical guarantees analogous to confidence intervals for sequence labeling.",
      "importance_score": 70,
      "reasoning": "Important contribution to uncertainty quantification in NLP with formal guarantees. Addresses critical need for reliable NLP systems in high-stakes applications.",
      "themes": [
        "Uncertainty Quantification",
        "Named Entity Recognition",
        "Conformal Prediction"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces conformal prediction framework for NER that produces prediction sets guaranteed to contain correct labeling with user-specified confidence. Provides formal statistical guarantees analogous to confidence intervals for sequence labeling.</p>",
      "content_html": "<p>arXiv:2601.16999v1 Announce Type: new  Abstract: Named Entity Recognition (NER) serves as a foundational component in many natural language processing (NLP) pipelines. However, current NER models typically output a single predicted label sequence without any accompanying measure of uncertainty, leaving downstream applications vulnerable to cascading errors. In this paper, we introduce a general framework for adapting sequence-labeling-based NER models to produce uncertainty-aware prediction sets. These prediction sets are collections of full-sentence labelings that are guaranteed to contain the correct labeling with a user-specified confidence level. This approach serves a role analogous to confidence intervals in classical statistics by providing formal guarantees about the reliability of model predictions. Our method builds on conformal prediction, which offers finite-sample coverage guarantees under minimal assumptions. We design efficient nonconformity scoring functions to construct efficient, well-calibrated prediction sets that support both unconditional and class-conditional coverage. This framework accounts for heterogeneity across sentence length, language, entity type, and number of entities within a sentence. Empirical experiments on four NER models across three benchmark datasets demonstrate the broad applicability, validity, and efficiency of the proposed methods.</p>"
    },
    {
      "id": "5ac2168bb777",
      "title": "D-Models and E-Models: Diversity-Stability Trade-offs in the Sampling Behavior of Large Language Models",
      "content": "arXiv:2601.17865v1 Announce Type: new  Abstract: The predictive probability of the next token (P_token) in large language models (LLMs) is inextricably linked to the probability of relevance for the next piece of information, the purchase probability of the next product, and the execution probability of the next action-all of which fall under the scope of the task-level target distribution (P_task). While LLMs are known to generate samples that approximate real-world distributions, whether their fine-grained sampling probabilities faithfully align with task requirements remains an open question. Through controlled distribution-sampling simulations, we uncover a striking dichotomy in LLM behavior, distinguishing two model types: D-models (e.g. Qwen-2.5), whose P_token exhibits large step-to-step variability and poor alignment with P_task; and E-models (e.g. Mistral-Small), whose P_token is more stable and better aligned with P_task. We further evaluate these two model types in downstream tasks such as code generation and recommendation, revealing systematic trade-offs between diversity and stability that shape task outcomes. Finally, we analyze the internal properties of both model families to probe their underlying mechanisms. These findings offer foundational insights into the probabilistic sampling behavior of LLMs and provide practical guidance on when to favor D- versus E-models. For web-scale applications, including recommendation, search, and conversational agents, our results inform model selection and configuration to balance diversity with reliability under real-world uncertainty, providing a better level of interpretation.",
      "url": "http://arxiv.org/abs/2601.17865",
      "author": "Jia Gu, Liang Pang, Huawei Shen, Xueqi Cheng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Identifies dichotomy between D-models and E-models in LLM sampling behavior: D-models show large diversity in token probabilities but drift from task distribution, while E-models show stability-diversity tradeoff.",
      "importance_score": 70,
      "reasoning": "Interesting theoretical insight into fundamental LLM behavior with practical implications for model selection and deployment.",
      "themes": [
        "Language Models",
        "Sampling",
        "Model Behavior Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Identifies dichotomy between D-models and E-models in LLM sampling behavior: D-models show large diversity in token probabilities but drift from task distribution, while E-models show stability-diversity tradeoff.</p>",
      "content_html": "<p>arXiv:2601.17865v1 Announce Type: new  Abstract: The predictive probability of the next token (P_token) in large language models (LLMs) is inextricably linked to the probability of relevance for the next piece of information, the purchase probability of the next product, and the execution probability of the next action-all of which fall under the scope of the task-level target distribution (P_task). While LLMs are known to generate samples that approximate real-world distributions, whether their fine-grained sampling probabilities faithfully align with task requirements remains an open question. Through controlled distribution-sampling simulations, we uncover a striking dichotomy in LLM behavior, distinguishing two model types: D-models (e.g. Qwen-2.5), whose P_token exhibits large step-to-step variability and poor alignment with P_task; and E-models (e.g. Mistral-Small), whose P_token is more stable and better aligned with P_task. We further evaluate these two model types in downstream tasks such as code generation and recommendation, revealing systematic trade-offs between diversity and stability that shape task outcomes. Finally, we analyze the internal properties of both model families to probe their underlying mechanisms. These findings offer foundational insights into the probabilistic sampling behavior of LLMs and provide practical guidance on when to favor D- versus E-models. For web-scale applications, including recommendation, search, and conversational agents, our results inform model selection and configuration to balance diversity with reliability under real-world uncertainty, providing a better level of interpretation.</p>"
    },
    {
      "id": "a69f92a6f472",
      "title": "MemWeaver: Weaving Hybrid Memories for Traceable Long-Horizon Agentic Reasoning",
      "content": "arXiv:2601.18204v1 Announce Type: new  Abstract: Large language model-based agents operating in long-horizon interactions require memory systems that support temporal consistency, multi-hop reasoning, and evidence-grounded reuse across sessions. Existing approaches largely rely on unstructured retrieval or coarse abstractions, which often lead to temporal conflicts, brittle reasoning, and limited traceability. We propose MemWeaver, a unified memory framework that consolidates long-term agent experiences into three interconnected components: a temporally grounded graph memory for structured relational reasoning, an experience memory that abstracts recurring interaction patterns from repeated observations, and a passage memory that preserves original textual evidence. MemWeaver employs a dual-channel retrieval strategy that jointly retrieves structured knowledge and supporting evidence to construct compact yet information-dense contexts for reasoning. Experiments on the LoCoMo benchmark demonstrate that MemWeaver substantially improves multi-hop and temporal reasoning accuracy while reducing input context length by over 95\\% compared to long-context baselines.",
      "url": "http://arxiv.org/abs/2601.18204",
      "author": "Juexiang Ye, Xue Li, Xinyu Yang, Chengkai Huang, Lanshun Nie, Lina Yao, Dechen Zhan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes MemWeaver, a hybrid memory framework for long-horizon agents with temporally grounded graph memory, experience memory for recurring patterns, and passage memory for evidence preservation.",
      "importance_score": 70,
      "reasoning": "Important contribution to agent memory systems addressing temporal consistency and evidence grounding. Comprehensive multi-component design.",
      "themes": [
        "LLM Agents",
        "Memory Systems",
        "Long-Horizon Reasoning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes MemWeaver, a hybrid memory framework for long-horizon agents with temporally grounded graph memory, experience memory for recurring patterns, and passage memory for evidence preservation.</p>",
      "content_html": "<p>arXiv:2601.18204v1 Announce Type: new  Abstract: Large language model-based agents operating in long-horizon interactions require memory systems that support temporal consistency, multi-hop reasoning, and evidence-grounded reuse across sessions. Existing approaches largely rely on unstructured retrieval or coarse abstractions, which often lead to temporal conflicts, brittle reasoning, and limited traceability. We propose MemWeaver, a unified memory framework that consolidates long-term agent experiences into three interconnected components: a temporally grounded graph memory for structured relational reasoning, an experience memory that abstracts recurring interaction patterns from repeated observations, and a passage memory that preserves original textual evidence. MemWeaver employs a dual-channel retrieval strategy that jointly retrieves structured knowledge and supporting evidence to construct compact yet information-dense contexts for reasoning. Experiments on the LoCoMo benchmark demonstrate that MemWeaver substantially improves multi-hop and temporal reasoning accuracy while reducing input context length by over 95\\% compared to long-context baselines.</p>"
    },
    {
      "id": "04169818cecc",
      "title": "Benchmarking Direct Preference Optimization for Medical Large Vision-Language Models",
      "content": "arXiv:2601.17918v1 Announce Type: cross  Abstract: Large Vision-Language Models (LVLMs) hold significant promise for medical applications, yet their deployment is often constrained by insufficient alignment and reliability. While Direct Preference Optimization (DPO) has emerged as a potent framework for refining model responses, its efficacy in high-stakes medical contexts remains underexplored, lacking the rigorous empirical groundwork necessary to guide future methodological advances. To bridge this gap, we present the first comprehensive examination of diverse DPO variants within the medical domain, evaluating nine distinct formulations across two medical LVLMs: LLaVA-Med and HuatuoGPT-Vision. Our results reveal several critical limitations: current DPO approaches often yield inconsistent gains over supervised fine-tuning, with their efficacy varying significantly across different tasks and backbones. Furthermore, they frequently fail to resolve fundamental visual misinterpretation errors. Building on these insights, we present a targeted preference construction strategy as a proof-of-concept that explicitly addresses visual misinterpretation errors frequently observed in existing DPO models. This design yields a 3.6% improvement over the strongest existing DPO baseline on visual question-answering tasks. To support future research, we release our complete framework, including all training data, model checkpoints, and our codebase at https://github.com/dmis-lab/med-vlm-dpo.",
      "url": "http://arxiv.org/abs/2601.17918",
      "author": "Dain Kim, Jiwoo Lee, Jaehoon Yun, Yong Hoe Koo, Qingyu Chen, Hyunjae Kim, Jaewoo Kang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "First comprehensive benchmark of DPO variants for medical Large Vision-Language Models, testing 9 formulations across LLaVA-Med and HuatuoGPT-Vision. Reveals critical limitations including inconsistent improvements and unstable training.",
      "importance_score": 70,
      "reasoning": "Important empirical study revealing DPO limitations in medical domain. Valuable for understanding alignment method applicability.",
      "themes": [
        "Medical AI",
        "Alignment",
        "DPO",
        "Vision-Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>First comprehensive benchmark of DPO variants for medical Large Vision-Language Models, testing 9 formulations across LLaVA-Med and HuatuoGPT-Vision. Reveals critical limitations including inconsistent improvements and unstable training.</p>",
      "content_html": "<p>arXiv:2601.17918v1 Announce Type: cross  Abstract: Large Vision-Language Models (LVLMs) hold significant promise for medical applications, yet their deployment is often constrained by insufficient alignment and reliability. While Direct Preference Optimization (DPO) has emerged as a potent framework for refining model responses, its efficacy in high-stakes medical contexts remains underexplored, lacking the rigorous empirical groundwork necessary to guide future methodological advances. To bridge this gap, we present the first comprehensive examination of diverse DPO variants within the medical domain, evaluating nine distinct formulations across two medical LVLMs: LLaVA-Med and HuatuoGPT-Vision. Our results reveal several critical limitations: current DPO approaches often yield inconsistent gains over supervised fine-tuning, with their efficacy varying significantly across different tasks and backbones. Furthermore, they frequently fail to resolve fundamental visual misinterpretation errors. Building on these insights, we present a targeted preference construction strategy as a proof-of-concept that explicitly addresses visual misinterpretation errors frequently observed in existing DPO models. This design yields a 3.6% improvement over the strongest existing DPO baseline on visual question-answering tasks. To support future research, we release our complete framework, including all training data, model checkpoints, and our codebase at https://github.com/dmis-lab/med-vlm-dpo.</p>"
    },
    {
      "id": "ad3cd0adf6bd",
      "title": "Health-ORSC-Bench: A Benchmark for Measuring Over-Refusal and Safety Completion in Health Context",
      "content": "arXiv:2601.17642v1 Announce Type: new  Abstract: Safety alignment in Large Language Models is critical for healthcare; however, reliance on binary refusal boundaries often results in \\emph{over-refusal} of benign queries or \\emph{unsafe compliance} with harmful ones. While existing benchmarks measure these extremes, they fail to evaluate Safe Completion: the model's ability to maximise helpfulness on dual-use or borderline queries by providing safe, high-level guidance without crossing into actionable harm. We introduce \\textbf{Health-ORSC-Bench}, the first large-scale benchmark designed to systematically measure \\textbf{Over-Refusal} and \\textbf{Safe Completion} quality in healthcare. Comprising 31,920 benign boundary prompts across seven health categories (e.g., self-harm, medical misinformation), our framework uses an automated pipeline with human validation to test models at varying levels of intent ambiguity. We evaluate 30 state-of-the-art LLMs, including GPT-5 and Claude-4, revealing a significant tension: safety-optimised models frequently refuse up to 80\\% of \"Hard\" benign prompts, while domain-specific models often sacrifice safety for utility. Our findings demonstrate that model family and size significantly influence calibration: larger frontier models (e.g., GPT-5, Llama-4) exhibit \"safety-pessimism\" and higher over-refusal than smaller or MoE-based counterparts (e.g., Qwen-3-Next), highlighting that current LLMs struggle to balance refusal and compliance. Health-ORSC-Bench provides a rigorous standard for calibrating the next generation of medical AI assistants toward nuanced, safe, and helpful completions. The code and data will be released upon acceptance. \\textcolor{red}{Warning: Some contents may include toxic or undesired contents.}",
      "url": "http://arxiv.org/abs/2601.17642",
      "author": "Zhihao Zhang, Liting Huang, Guanghao Wu, Preslav Nakov, Heng Ji, Usman Naseem",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces Health-ORSC-Bench, a 31,920-prompt benchmark measuring over-refusal and safe completion in healthcare LLMs across seven health categories including self-harm and medical misinformation.",
      "importance_score": 69,
      "reasoning": "Important safety benchmark for high-stakes healthcare domain; large scale and systematic approach to measuring nuanced safety behaviors.",
      "themes": [
        "Healthcare AI",
        "AI Safety",
        "Benchmarks"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Health-ORSC-Bench, a 31,920-prompt benchmark measuring over-refusal and safe completion in healthcare LLMs across seven health categories including self-harm and medical misinformation.</p>",
      "content_html": "<p>arXiv:2601.17642v1 Announce Type: new  Abstract: Safety alignment in Large Language Models is critical for healthcare; however, reliance on binary refusal boundaries often results in \\emph{over-refusal} of benign queries or \\emph{unsafe compliance} with harmful ones. While existing benchmarks measure these extremes, they fail to evaluate Safe Completion: the model's ability to maximise helpfulness on dual-use or borderline queries by providing safe, high-level guidance without crossing into actionable harm. We introduce \\textbf{Health-ORSC-Bench}, the first large-scale benchmark designed to systematically measure \\textbf{Over-Refusal} and \\textbf{Safe Completion} quality in healthcare. Comprising 31,920 benign boundary prompts across seven health categories (e.g., self-harm, medical misinformation), our framework uses an automated pipeline with human validation to test models at varying levels of intent ambiguity. We evaluate 30 state-of-the-art LLMs, including GPT-5 and Claude-4, revealing a significant tension: safety-optimised models frequently refuse up to 80\\% of \"Hard\" benign prompts, while domain-specific models often sacrifice safety for utility. Our findings demonstrate that model family and size significantly influence calibration: larger frontier models (e.g., GPT-5, Llama-4) exhibit \"safety-pessimism\" and higher over-refusal than smaller or MoE-based counterparts (e.g., Qwen-3-Next), highlighting that current LLMs struggle to balance refusal and compliance. Health-ORSC-Bench provides a rigorous standard for calibrating the next generation of medical AI assistants toward nuanced, safe, and helpful completions. The code and data will be released upon acceptance. \\textcolor{red}{Warning: Some contents may include toxic or undesired contents.}</p>"
    },
    {
      "id": "381abc1aa941",
      "title": "Can Good Writing Be Generative? Expert-Level AI Writing Emerges through Fine-Tuning on High-Quality Books",
      "content": "arXiv:2601.18353v1 Announce Type: new  Abstract: Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes \"good writing.\" These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor.",
      "url": "http://arxiv.org/abs/2601.18353",
      "author": "Tuhin Chakrabarty, Paramveer S. Dhillon",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Finds that expert MFA writers preferred human writing 82.7% of the time with in-context prompting, but this reversed to 62% preference for AI after fine-tuning on authors' complete works.",
      "importance_score": 69,
      "reasoning": "Striking finding about AI creative writing capabilities; well-designed behavioral experiment with expert evaluation.",
      "themes": [
        "Creative AI",
        "Human Evaluation",
        "Fine-Tuning"
      ],
      "continuation": null,
      "summary_html": "<p>Finds that expert MFA writers preferred human writing 82.7% of the time with in-context prompting, but this reversed to 62% preference for AI after fine-tuning on authors' complete works.</p>",
      "content_html": "<p>arXiv:2601.18353v1 Announce Type: new  Abstract: Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes \"good writing.\" These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor.</p>"
    },
    {
      "id": "9d73d904fa42",
      "title": "Crystal-KV: Efficient KV Cache Management for Chain-of-Thought LLMs via Answer-First Principle",
      "content": "arXiv:2601.16986v1 Announce Type: cross  Abstract: Chain-of-Thought (CoT) reasoning in large language models (LLMs) significantly improves accuracy on complex tasks, yet incurs excessive memory overhead due to the long think-stage sequences stored in the Key-Value (KV) cache. Unlike traditional generation tasks where all tokens are uniformly important, CoT emphasizes the final answer, rendering conventional KV compression strategies ineffective. In this paper, we present Crystal-KV, an efficient KV cache management framework tailored for CoT reasoning. Our key insight is the answer-first principle. By mapping answer preferences into think-stage attention map, we distinguish between SlipKV, which mainly maintains the reasoning flow but may occasionally introduce misleading context, and CrystalKV, which truly contributes to the correctness of the final answer. Next, we propose an attention-based Least Recently Frequently Used algorithm. It precisely identifies when a SlipKV entry's utility expires and evicts it, retaining CrystalKV without disrupting reasoning flow. Finally, we introduce an adaptive cache budget allocation algorithm. Based on the dynamic proportion of CrystalKV, it estimates the importance of each layer/head and adjusts the KV cache budget during inference, amplifying critical components to improve budget utilization. Results show that Crystal-KV achieves state-of-the-art KV cache compression, significantly improves throughput, and enables faster response time, while maintaining, or even improving, answer accuracy for CoT reasoning.",
      "url": "http://arxiv.org/abs/2601.16986",
      "author": "Zihan Wang, Cheng Tang, Lei Gong, Cheng Li, Chao Wang, teng wang, Wenqi Lou, Xuehai Zhou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes Crystal-KV for efficient KV cache management in Chain-of-Thought reasoning using answer-first principle to identify and retain only important reasoning tokens.",
      "importance_score": 69,
      "reasoning": "Practical efficiency improvement for reasoning models; principled approach specific to CoT characteristics.",
      "themes": [
        "Reasoning",
        "Efficiency",
        "KV Cache"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Crystal-KV for efficient KV cache management in Chain-of-Thought reasoning using answer-first principle to identify and retain only important reasoning tokens.</p>",
      "content_html": "<p>arXiv:2601.16986v1 Announce Type: cross  Abstract: Chain-of-Thought (CoT) reasoning in large language models (LLMs) significantly improves accuracy on complex tasks, yet incurs excessive memory overhead due to the long think-stage sequences stored in the Key-Value (KV) cache. Unlike traditional generation tasks where all tokens are uniformly important, CoT emphasizes the final answer, rendering conventional KV compression strategies ineffective. In this paper, we present Crystal-KV, an efficient KV cache management framework tailored for CoT reasoning. Our key insight is the answer-first principle. By mapping answer preferences into think-stage attention map, we distinguish between SlipKV, which mainly maintains the reasoning flow but may occasionally introduce misleading context, and CrystalKV, which truly contributes to the correctness of the final answer. Next, we propose an attention-based Least Recently Frequently Used algorithm. It precisely identifies when a SlipKV entry's utility expires and evicts it, retaining CrystalKV without disrupting reasoning flow. Finally, we introduce an adaptive cache budget allocation algorithm. Based on the dynamic proportion of CrystalKV, it estimates the importance of each layer/head and adjusts the KV cache budget during inference, amplifying critical components to improve budget utilization. Results show that Crystal-KV achieves state-of-the-art KV cache compression, significantly improves throughput, and enables faster response time, while maintaining, or even improving, answer accuracy for CoT reasoning.</p>"
    },
    {
      "id": "9b92febde492",
      "title": "Agentic reinforcement learning empowers next-generation chemical language models for molecular design and synthesis",
      "content": "arXiv:2601.17687v1 Announce Type: cross  Abstract: Language models are revolutionizing the biochemistry domain, assisting scientists in drug design and chemical synthesis with high efficiency. Yet current approaches struggle between small language models prone to hallucination and limited knowledge retention, and large cloud-based language models plagued by privacy risks and high inference costs. To bridge this gap, we introduce ChemCRAFT, a novel framework leveraging agentic reinforcement learning to decouple chemical reasoning from knowledge storage. Instead of forcing the model to memorize vast chemical data, our approach empowers the language model to interact with a sandbox for precise information retrieval. This externalization of knowledge allows a locally deployable small model to achieve superior performance with minimal inference costs. To enable small language models for agent-calling ability, we build an agentic trajectory construction pipeline and a comprehensive chemical-agent sandbox. Based on sandbox interactions, we constructed ChemToolDataset, the first large-scale chemical tool trajectory dataset. Simultaneously, we propose SMILES-GRPO to build a dense chemical reward function, promoting the model's ability to call chemical agents. Evaluations across diverse aspects of drug design show that ChemCRAFT outperforms current cloud-based LLMs in molecular structure analysis, molecular optimization, and synthesis pathway prediction, demonstrating that scientific reasoning is not solely an emergent ability of model scale, but a learnable policy of tool orchestration. This work establishes a cost-effective and privacy-preserving paradigm for AI-aided chemistry, opening new avenues for accelerating molecular discovery with locally deployable agents.",
      "url": "http://arxiv.org/abs/2601.17687",
      "author": "Hao Li, He Cao, Shenyao Peng, Zijing Liu, Bin Feng, Yu Wang, Zhiyuan Yan, Yonghong Tian, Yu Li, Li Yuan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "ChemCRAFT uses agentic reinforcement learning to decouple chemical reasoning from knowledge storage, allowing small models to query external sandbox for precise retrieval rather than memorizing chemical data.",
      "importance_score": 69,
      "reasoning": "Novel approach to scientific LLMs. Addresses hallucination in domain-specific models. Agentic RL for knowledge externalization.",
      "themes": [
        "Scientific AI",
        "Agentic RL",
        "Chemistry",
        "Hallucination Mitigation"
      ],
      "continuation": null,
      "summary_html": "<p>ChemCRAFT uses agentic reinforcement learning to decouple chemical reasoning from knowledge storage, allowing small models to query external sandbox for precise retrieval rather than memorizing chemical data.</p>",
      "content_html": "<p>arXiv:2601.17687v1 Announce Type: cross  Abstract: Language models are revolutionizing the biochemistry domain, assisting scientists in drug design and chemical synthesis with high efficiency. Yet current approaches struggle between small language models prone to hallucination and limited knowledge retention, and large cloud-based language models plagued by privacy risks and high inference costs. To bridge this gap, we introduce ChemCRAFT, a novel framework leveraging agentic reinforcement learning to decouple chemical reasoning from knowledge storage. Instead of forcing the model to memorize vast chemical data, our approach empowers the language model to interact with a sandbox for precise information retrieval. This externalization of knowledge allows a locally deployable small model to achieve superior performance with minimal inference costs. To enable small language models for agent-calling ability, we build an agentic trajectory construction pipeline and a comprehensive chemical-agent sandbox. Based on sandbox interactions, we constructed ChemToolDataset, the first large-scale chemical tool trajectory dataset. Simultaneously, we propose SMILES-GRPO to build a dense chemical reward function, promoting the model's ability to call chemical agents. Evaluations across diverse aspects of drug design show that ChemCRAFT outperforms current cloud-based LLMs in molecular structure analysis, molecular optimization, and synthesis pathway prediction, demonstrating that scientific reasoning is not solely an emergent ability of model scale, but a learnable policy of tool orchestration. This work establishes a cost-effective and privacy-preserving paradigm for AI-aided chemistry, opening new avenues for accelerating molecular discovery with locally deployable agents.</p>"
    },
    {
      "id": "738eb2ea82d5",
      "title": "Funny or Persuasive, but Not Both: Evaluating Fine-Grained Multi-Concept Control in LLMs",
      "content": "arXiv:2601.18483v1 Announce Type: cross  Abstract: Large Language Models (LLMs) offer strong generative capabilities, but many applications require explicit and \\textit{fine-grained} control over specific textual concepts, such as humor, persuasiveness, or formality. Prior approaches in prompting and representation engineering can provide coarse or single-attribute control, but systematic evaluation of multi-attribute settings remains limited. We introduce an evaluation framework for fine-grained controllability for both single- and dual-concept scenarios, focusing on linguistically distinct concept pairs (e.g., persuasiveness vs.~humor). Surprisingly, across multiple LLMs and generative tasks, we find that performance often drops in the dual-concept setting, even though the chosen concepts should in principle be separable. This reveals a fundamental limitation of naive prompting-based control: models struggle with compositionality even when concepts are intuitively independent. Our framework provides systematic evidence of this gap and offers a principled approach for measuring the ability of future methods for multi-concept control.",
      "url": "http://arxiv.org/abs/2601.18483",
      "author": "Arya Labroo, Ivaxi Sheth, Vyas Raina, Amaani Ahmed, Mario Fritz",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Evaluates fine-grained multi-concept control in LLMs, finding performance drops in dual-concept settings (e.g., persuasive AND funny simultaneously) even for linguistically distinct concept pairs.",
      "importance_score": 69,
      "reasoning": "Important finding about LLM controllability limitations. Systematic evaluation reveals fundamental challenge for fine-grained control.",
      "themes": [
        "LLM Controllability",
        "Prompt Engineering",
        "Text Generation"
      ],
      "continuation": null,
      "summary_html": "<p>Evaluates fine-grained multi-concept control in LLMs, finding performance drops in dual-concept settings (e.g., persuasive AND funny simultaneously) even for linguistically distinct concept pairs.</p>",
      "content_html": "<p>arXiv:2601.18483v1 Announce Type: cross  Abstract: Large Language Models (LLMs) offer strong generative capabilities, but many applications require explicit and \\textit{fine-grained} control over specific textual concepts, such as humor, persuasiveness, or formality. Prior approaches in prompting and representation engineering can provide coarse or single-attribute control, but systematic evaluation of multi-attribute settings remains limited. We introduce an evaluation framework for fine-grained controllability for both single- and dual-concept scenarios, focusing on linguistically distinct concept pairs (e.g., persuasiveness vs.~humor). Surprisingly, across multiple LLMs and generative tasks, we find that performance often drops in the dual-concept setting, even though the chosen concepts should in principle be separable. This reveals a fundamental limitation of naive prompting-based control: models struggle with compositionality even when concepts are intuitively independent. Our framework provides systematic evidence of this gap and offers a principled approach for measuring the ability of future methods for multi-concept control.</p>"
    },
    {
      "id": "8db7a41ec363",
      "title": "CLM-Bench: Benchmarking and Analyzing Cross-lingual Misalignment of LLMs in Knowledge Editing",
      "content": "arXiv:2601.17397v1 Announce Type: new  Abstract: Knowledge Editing (KE) has emerged as a promising paradigm for updating facts in Large Language Models (LLMs) without retraining. However, progress in Multilingual Knowledge Editing (MKE) is currently hindered by biased evaluation frameworks. We observe that existing MKE benchmarks are typically constructed by mechanically translating English-centric datasets into target languages (e.g., English-to-Chinese). This approach introduces translation artifacts and neglects culturally specific entities native to the target language, failing to reflect the true knowledge distribution of LLMs. To address this, we propose CLM-Bench, a culture-aware benchmark constructed using a native Chinese-first methodology. We curate 1,010 high-quality CounterFact pairs rooted in Chinese cultural contexts and align them with English counterparts. Using CLM-Bench, we conduct extensive experiments on representative LLMs (e.g., Llama-3, Qwen2) and reveal a significant Cross-lingual Misalignment: edits in one language function independently and fail to propagate to the other. We further provide a geometric explanation via layer-wise representation analysis, demonstrating that edit vectors for Chinese and English are nearly orthogonal -- residing in disjoint subspaces -- while mixed-lingual editing exhibits linear additivity of these vectors. Our findings challenge the effectiveness of current methods in cross-lingual transfer and underscore the importance of culturally native benchmarks.",
      "url": "http://arxiv.org/abs/2601.17397",
      "author": "Yucheng Hu, Wei Zhou, Juesi Xiao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces CLM-Bench, a culture-aware benchmark for multilingual knowledge editing constructed with Chinese-first methodology. Addresses translation artifacts and cultural bias in existing MKE benchmarks.",
      "importance_score": 69,
      "reasoning": "Important methodological contribution addressing systematic bias in knowledge editing evaluation. Novel native language-first construction approach.",
      "themes": [
        "Knowledge Editing",
        "Multilingual NLP",
        "Benchmark",
        "Cultural NLP"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces CLM-Bench, a culture-aware benchmark for multilingual knowledge editing constructed with Chinese-first methodology. Addresses translation artifacts and cultural bias in existing MKE benchmarks.</p>",
      "content_html": "<p>arXiv:2601.17397v1 Announce Type: new  Abstract: Knowledge Editing (KE) has emerged as a promising paradigm for updating facts in Large Language Models (LLMs) without retraining. However, progress in Multilingual Knowledge Editing (MKE) is currently hindered by biased evaluation frameworks. We observe that existing MKE benchmarks are typically constructed by mechanically translating English-centric datasets into target languages (e.g., English-to-Chinese). This approach introduces translation artifacts and neglects culturally specific entities native to the target language, failing to reflect the true knowledge distribution of LLMs. To address this, we propose CLM-Bench, a culture-aware benchmark constructed using a native Chinese-first methodology. We curate 1,010 high-quality CounterFact pairs rooted in Chinese cultural contexts and align them with English counterparts. Using CLM-Bench, we conduct extensive experiments on representative LLMs (e.g., Llama-3, Qwen2) and reveal a significant Cross-lingual Misalignment: edits in one language function independently and fail to propagate to the other. We further provide a geometric explanation via layer-wise representation analysis, demonstrating that edit vectors for Chinese and English are nearly orthogonal -- residing in disjoint subspaces -- while mixed-lingual editing exhibits linear additivity of these vectors. Our findings challenge the effectiveness of current methods in cross-lingual transfer and underscore the importance of culturally native benchmarks.</p>"
    },
    {
      "id": "7626cd32074b",
      "title": "CHiRPE: A Step Towards Real-World Clinical NLP with Clinician-Oriented Model Explanations",
      "content": "arXiv:2601.18102v1 Announce Type: new  Abstract: The medical adoption of NLP tools requires interpretability by end users, yet traditional explainable AI (XAI) methods are misaligned with clinical reasoning and lack clinician input. We introduce CHiRPE (Clinical High-Risk Prediction with Explainability), an NLP pipeline that takes transcribed semi-structured clinical interviews to: (i) predict psychosis risk; and (ii) generate novel SHAP explanation formats co-developed with clinicians. Trained on 944 semi-structured interview transcripts across 24 international clinics of the AMP-SCZ study, the CHiRPE pipeline integrates symptom-domain mapping, LLM summarisation, and BERT classification. CHiRPE achieved over 90% accuracy across three BERT variants and outperformed baseline models. Explanation formats were evaluated by 28 clinical experts who indicated a strong preference for our novel concept-guided explanations, especially hybrid graph-and-text summary formats. CHiRPE demonstrates that clinically-guided model development produces both accurate and interpretable results. Our next step is focused on real-world testing across our 24 international sites.",
      "url": "http://arxiv.org/abs/2601.18102",
      "author": "Stephanie Fong, Zimu Wang, Guilherme C. Oliveira, Xiangyu Zhao, Yiwen Jiang, Jiahe Liu, Beau-Luke Colton, Scott Woods, Martha E. Shenton, Barnaby Nelson, Zongyuan Ge, Dominic Dwyer",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces CHiRPE, an NLP pipeline for psychosis risk prediction from clinical interviews with clinician-co-developed SHAP explanation formats. Achieves 90%+ accuracy with interpretable outputs.",
      "importance_score": 69,
      "reasoning": "Important clinical AI application with strong focus on clinician-oriented interpretability. Demonstrates real-world deployment considerations.",
      "themes": [
        "Clinical NLP",
        "Interpretability",
        "Mental Health"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces CHiRPE, an NLP pipeline for psychosis risk prediction from clinical interviews with clinician-co-developed SHAP explanation formats. Achieves 90%+ accuracy with interpretable outputs.</p>",
      "content_html": "<p>arXiv:2601.18102v1 Announce Type: new  Abstract: The medical adoption of NLP tools requires interpretability by end users, yet traditional explainable AI (XAI) methods are misaligned with clinical reasoning and lack clinician input. We introduce CHiRPE (Clinical High-Risk Prediction with Explainability), an NLP pipeline that takes transcribed semi-structured clinical interviews to: (i) predict psychosis risk; and (ii) generate novel SHAP explanation formats co-developed with clinicians. Trained on 944 semi-structured interview transcripts across 24 international clinics of the AMP-SCZ study, the CHiRPE pipeline integrates symptom-domain mapping, LLM summarisation, and BERT classification. CHiRPE achieved over 90% accuracy across three BERT variants and outperformed baseline models. Explanation formats were evaluated by 28 clinical experts who indicated a strong preference for our novel concept-guided explanations, especially hybrid graph-and-text summary formats. CHiRPE demonstrates that clinically-guided model development produces both accurate and interpretable results. Our next step is focused on real-world testing across our 24 international sites.</p>"
    },
    {
      "id": "9614df4452e2",
      "title": "Do not be greedy, Think Twice: Sampling and Selection for Document-level Information Extraction",
      "content": "arXiv:2601.18395v1 Announce Type: new  Abstract: Document-level Information Extraction (DocIE) aims to produce an output template with the entities and relations of interest occurring in the given document. Standard practices include prompting decoder-only LLMs using greedy decoding to avoid output variability. Rather than treating this variability as a limitation, we show that sampling can produce substantially better solutions than greedy decoding, especially when using reasoning models. We thus propose ThinkTwice, a sampling and selection framework in which the LLM generates multiple candidate templates for a given document, and a selection module chooses the most suitable one. We introduce both an unsupervised method that exploits agreement across generated outputs, and a supervised selection method using reward models trained on labeled DocIE data. To address the scarcity of golden reasoning trajectories for DocIE, we propose a rejection-sampling-based method to generate silver training data that pairs output templates with reasoning traces. Our experiments show the validity of unsupervised and supervised ThinkTwice, consistently outperforming greedy baselines and the state-of-the-art.",
      "url": "http://arxiv.org/abs/2601.18395",
      "author": "Mikel Zubillaga, Oscar Sainz, Oier Lopez de Lacalle, Eneko Agirre",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes ThinkTwice framework for document-level information extraction showing sampling produces substantially better solutions than greedy decoding, especially for reasoning models. Introduces selection methods for choosing among candidates.",
      "importance_score": 69,
      "reasoning": "Important practical finding about sampling vs greedy for reasoning models. Novel selection framework with both unsupervised and supervised methods.",
      "themes": [
        "Information Extraction",
        "Reasoning Models",
        "Decoding Strategies"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes ThinkTwice framework for document-level information extraction showing sampling produces substantially better solutions than greedy decoding, especially for reasoning models. Introduces selection methods for choosing among candidates.</p>",
      "content_html": "<p>arXiv:2601.18395v1 Announce Type: new  Abstract: Document-level Information Extraction (DocIE) aims to produce an output template with the entities and relations of interest occurring in the given document. Standard practices include prompting decoder-only LLMs using greedy decoding to avoid output variability. Rather than treating this variability as a limitation, we show that sampling can produce substantially better solutions than greedy decoding, especially when using reasoning models. We thus propose ThinkTwice, a sampling and selection framework in which the LLM generates multiple candidate templates for a given document, and a selection module chooses the most suitable one. We introduce both an unsupervised method that exploits agreement across generated outputs, and a supervised selection method using reward models trained on labeled DocIE data. To address the scarcity of golden reasoning trajectories for DocIE, we propose a rejection-sampling-based method to generate silver training data that pairs output templates with reasoning traces. Our experiments show the validity of unsupervised and supervised ThinkTwice, consistently outperforming greedy baselines and the state-of-the-art.</p>"
    },
    {
      "id": "3bdaa501f59a",
      "title": "TheoremForge: Scaling up Formal Data Synthesis with Low-Budget Agentic Workflow",
      "content": "arXiv:2601.17332v1 Announce Type: new  Abstract: The high cost of agentic workflows in formal mathematics hinders large-scale data synthesis, exacerbating the scarcity of open-source corpora. To address this, we introduce \\textbf{TheoremForge}, a cost-effective formal data synthesis pipeline that decomposes the formalization process into five sub-tasks, which are \\textit{statement formalization}, \\textit{proof generation}, \\textit{premise selection}, \\textit{proof correction} and \\textit{proof sketching}. By implementing a \\textit{Decoupled Extraction Strategy}, the workflow recovers valid training signals from globally failed trajectories, effectively utilizing wasted computation. Experiments on a 2,000-problem benchmark demonstrate that TheoremForge achieves a Verified Rate of 12.6\\%, surpassing the 8.6\\% baseline, at an average cost of only \\textbf{\\$0.481} per successful trajectory using Gemini-3-Flash. Crucially, our strategy increases data yield by \\textbf{1.6$\\times$} for proof generation compared to standard filtering. These results establish TheoremForge as a scalable framework for constructing a data flywheel to train future expert models. Our code is available \\href{https://github.com/timechess/TheoremForge}{here}.",
      "url": "http://arxiv.org/abs/2601.17332",
      "author": "Yicheng Tao, Hongteng Xu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces TheoremForge, a cost-effective pipeline for synthesizing formal mathematics data by decomposing formalization into sub-tasks and recovering training signals from failed trajectories, achieving 12.6% verified rate.",
      "importance_score": 68,
      "reasoning": "Addresses data scarcity in formal mathematics; practical efficiency improvements for an important capability area, though verified rate is still modest.",
      "themes": [
        "Formal Reasoning",
        "Data Synthesis",
        "Mathematical AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces TheoremForge, a cost-effective pipeline for synthesizing formal mathematics data by decomposing formalization into sub-tasks and recovering training signals from failed trajectories, achieving 12.6% verified rate.</p>",
      "content_html": "<p>arXiv:2601.17332v1 Announce Type: new  Abstract: The high cost of agentic workflows in formal mathematics hinders large-scale data synthesis, exacerbating the scarcity of open-source corpora. To address this, we introduce \\textbf{TheoremForge}, a cost-effective formal data synthesis pipeline that decomposes the formalization process into five sub-tasks, which are \\textit{statement formalization}, \\textit{proof generation}, \\textit{premise selection}, \\textit{proof correction} and \\textit{proof sketching}. By implementing a \\textit{Decoupled Extraction Strategy}, the workflow recovers valid training signals from globally failed trajectories, effectively utilizing wasted computation. Experiments on a 2,000-problem benchmark demonstrate that TheoremForge achieves a Verified Rate of 12.6\\%, surpassing the 8.6\\% baseline, at an average cost of only \\textbf{\\$0.481} per successful trajectory using Gemini-3-Flash. Crucially, our strategy increases data yield by \\textbf{1.6$\\times$} for proof generation compared to standard filtering. These results establish TheoremForge as a scalable framework for constructing a data flywheel to train future expert models. Our code is available \\href{https://github.com/timechess/TheoremForge}{here}.</p>"
    },
    {
      "id": "16ed91189694",
      "title": "EntWorld: A Holistic Environment and Benchmark for Verifiable Enterprise GUI Agents",
      "content": "arXiv:2601.17722v1 Announce Type: new  Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled agents to operate in open-ended web and operating system environments. However, existing benchmarks predominantly target consumer-oriented scenarios (e.g., e-commerce and travel booking), failing to capture the complexity and rigor of professional enterprise workflows. Enterprise systems pose distinct challenges, including high-density user interfaces, strict business logic constraints, and a strong reliance on precise, state-consistent information retrieval-settings in which current generalist agents often struggle. To address this gap, we introduce EntWorld, a large-scale benchmark consisting of 1,756 tasks across six representative enterprise domains, including customer relationship management (CRM), information technology infrastructure library (ITIL), and enterprise resource planning (ERP) systems. Unlike previous datasets that depend on fragile execution traces or extensive manual annotation, EntWorld adopts a schema-grounded task generation framework that directly reverse-engineers business logic from underlying database schemas, enabling the synthesis of realistic, long-horizon workflows. Moreover, we propose a SQL-based deterministic verification mechanism in building datasets that replaces ambiguous visual matching with rigorous state-transition validation. Experimental results demonstrate that state-of-the-art models (e.g., GPT-4.1) achieve 47.61% success rate on EntWorld, substantially lower than the human performance, highlighting a pronounced enterprise gap in current agentic capabilities and the necessity of developing domain-specific agents. We release EntWorld as a rigorous testbed to facilitate the development and evaluation of the next generation of enterprise-ready digital agents.",
      "url": "http://arxiv.org/abs/2601.17722",
      "author": "Ying Mo, Yu Bai, Dapeng Sun, Yuqian Shi, Yukai Miao, Li Chen, Dan Li",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces EntWorld, a benchmark of 1,756 tasks across six enterprise domains testing GUI agents on high-density interfaces, business logic constraints, and precise information retrieval.",
      "importance_score": 68,
      "reasoning": "Fills important gap in agent benchmarks; enterprise-specific challenges differ meaningfully from consumer scenarios.",
      "themes": [
        "GUI Agents",
        "Benchmarks",
        "Enterprise AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces EntWorld, a benchmark of 1,756 tasks across six enterprise domains testing GUI agents on high-density interfaces, business logic constraints, and precise information retrieval.</p>",
      "content_html": "<p>arXiv:2601.17722v1 Announce Type: new  Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled agents to operate in open-ended web and operating system environments. However, existing benchmarks predominantly target consumer-oriented scenarios (e.g., e-commerce and travel booking), failing to capture the complexity and rigor of professional enterprise workflows. Enterprise systems pose distinct challenges, including high-density user interfaces, strict business logic constraints, and a strong reliance on precise, state-consistent information retrieval-settings in which current generalist agents often struggle. To address this gap, we introduce EntWorld, a large-scale benchmark consisting of 1,756 tasks across six representative enterprise domains, including customer relationship management (CRM), information technology infrastructure library (ITIL), and enterprise resource planning (ERP) systems. Unlike previous datasets that depend on fragile execution traces or extensive manual annotation, EntWorld adopts a schema-grounded task generation framework that directly reverse-engineers business logic from underlying database schemas, enabling the synthesis of realistic, long-horizon workflows. Moreover, we propose a SQL-based deterministic verification mechanism in building datasets that replaces ambiguous visual matching with rigorous state-transition validation. Experimental results demonstrate that state-of-the-art models (e.g., GPT-4.1) achieve 47.61% success rate on EntWorld, substantially lower than the human performance, highlighting a pronounced enterprise gap in current agentic capabilities and the necessity of developing domain-specific agents. We release EntWorld as a rigorous testbed to facilitate the development and evaluation of the next generation of enterprise-ready digital agents.</p>"
    },
    {
      "id": "926277bd7e38",
      "title": "AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning",
      "content": "arXiv:2601.18631v1 Announce Type: new  Abstract: When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \\textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.",
      "url": "http://arxiv.org/abs/2601.18631",
      "author": "Mingyang Song, Haoyu Sun, Jiawei Gu, Linjie Li, Luxin Xu, Ranjay Krishna, Yu Cheng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces AdaReasoner, multimodal models learning tool use as general reasoning skill through scalable data curation and Tool-GRPO reinforcement learning for long-horizon visual reasoning.",
      "importance_score": 68,
      "reasoning": "Principled approach to tool use learning; addresses generalization across tools and tasks.",
      "themes": [
        "Vision-Language Models",
        "Tool Use",
        "Reinforcement Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces AdaReasoner, multimodal models learning tool use as general reasoning skill through scalable data curation and Tool-GRPO reinforcement learning for long-horizon visual reasoning.</p>",
      "content_html": "<p>arXiv:2601.18631v1 Announce Type: new  Abstract: When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \\textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.</p>"
    },
    {
      "id": "30cb4bc3d913",
      "title": "Scientific Image Synthesis: Benchmarking, Methodologies, and Downstream Utility",
      "content": "arXiv:2601.17027v1 Announce Type: cross  Abstract: While synthetic data has proven effective for improving scientific reasoning in the text domain, multimodal reasoning remains constrained by the difficulty of synthesizing scientifically rigorous images. Existing Text-to-Image (T2I) models often produce outputs that are visually plausible yet scientifically incorrect, resulting in a persistent visual-logic divergence that limits their value for downstream reasoning. Motivated by recent advances in next-generation T2I models, we conduct a systematic study of scientific image synthesis across generation paradigms, evaluation, and downstream use. We analyze both direct pixel-based generation and programmatic synthesis, and propose ImgCoder, a logic-driven framework that follows an explicit \"understand - plan - code\" workflow to improve structural precision. To rigorously assess scientific correctness, we introduce SciGenBench, which evaluates generated images based on information utility and logical validity. Our evaluation reveals systematic failure modes in pixel-based models and highlights a fundamental expressiveness-precision trade-off. Finally, we show that fine-tuning Large Multimodal Models (LMMs) on rigorously verified synthetic scientific images yields consistent reasoning gains, with potential scaling trends analogous to the text domain, validating high-fidelity scientific synthesis as a viable path to unlocking massive multimodal reasoning capabilities.",
      "url": "http://arxiv.org/abs/2601.17027",
      "author": "Honglin Lin, Chonghan Qin, Zheng Liu, Qizhi Pei, Yu Li, Zhanping Zhong, Xin Gao, Yanfeng Wang, Conghui He, Lijun Wu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Systematic study of scientific image synthesis comparing pixel-based and programmatic approaches. Proposes ImgCoder, a logic-driven framework for generating scientifically rigorous images.",
      "importance_score": 68,
      "reasoning": "Addresses important gap in multimodal AI for scientific reasoning. Novel benchmark and framework for ensuring scientific correctness in image generation.",
      "themes": [
        "Scientific AI",
        "Image Synthesis",
        "Multimodal Reasoning"
      ],
      "continuation": null,
      "summary_html": "<p>Systematic study of scientific image synthesis comparing pixel-based and programmatic approaches. Proposes ImgCoder, a logic-driven framework for generating scientifically rigorous images.</p>",
      "content_html": "<p>arXiv:2601.17027v1 Announce Type: cross  Abstract: While synthetic data has proven effective for improving scientific reasoning in the text domain, multimodal reasoning remains constrained by the difficulty of synthesizing scientifically rigorous images. Existing Text-to-Image (T2I) models often produce outputs that are visually plausible yet scientifically incorrect, resulting in a persistent visual-logic divergence that limits their value for downstream reasoning. Motivated by recent advances in next-generation T2I models, we conduct a systematic study of scientific image synthesis across generation paradigms, evaluation, and downstream use. We analyze both direct pixel-based generation and programmatic synthesis, and propose ImgCoder, a logic-driven framework that follows an explicit \"understand - plan - code\" workflow to improve structural precision. To rigorously assess scientific correctness, we introduce SciGenBench, which evaluates generated images based on information utility and logical validity. Our evaluation reveals systematic failure modes in pixel-based models and highlights a fundamental expressiveness-precision trade-off. Finally, we show that fine-tuning Large Multimodal Models (LMMs) on rigorously verified synthetic scientific images yields consistent reasoning gains, with potential scaling trends analogous to the text domain, validating high-fidelity scientific synthesis as a viable path to unlocking massive multimodal reasoning capabilities.</p>"
    },
    {
      "id": "08a817033377",
      "title": "Least-Loaded Expert Parallelism: Load Balancing An Imbalanced Mixture-of-Experts",
      "content": "arXiv:2601.17111v1 Announce Type: cross  Abstract: Mixture-of-Experts (MoE) models are typically pre-trained with explicit load-balancing constraints to ensure statistically balanced expert routing. Despite this, we observe that even well-trained MoE models exhibit significantly imbalanced routing. This behavior is arguably natural-and even desirable - as imbalanced routing allows models to concentrate domain-specific knowledge within a subset of experts. Expert parallelism (EP) is designed to scale MoE models by distributing experts across multiple devices, but with a less-discussed assumption of balanced routing. Under extreme imbalance, EP can funnel a disproportionate number of tokens to a small number of experts, leading to compute- and memory-bound failures on overloaded devices during post-training or inference, where explicit load balancing is often inapplicable. We propose Least-Loaded Expert Parallelism (LLEP), a novel EP algorithm that dynamically reroutes excess tokens and associated expert parameters from overloaded devices to underutilized ones. This ensures that all devices complete their workloads within the minimum collective latency while respecting memory constraints. Across different model scales, LLEP achieves up to 5x speedup and 4x reduction in peak memory usage compared to standard EP. This enables faster and higher-throughput post-training and inference, with ~1.9x faster for gpt-oss-120b. We support our method with extensive theoretical analysis and comprehensive empirical evaluations, including ablation studies. These results illuminate key trade-offs and enable a principled framework for hardware-specific hyper-parameter tuning to achieve optimal performance.",
      "url": "http://arxiv.org/abs/2601.17111",
      "author": "Xuan-Phi Nguyen, Shrey Pandit, Austin Xu, Caiming Xiong, Shafiq Joty",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes Least-Loaded Expert Parallelism for handling imbalanced MoE routing. Addresses compute and memory failures from disproportionate token distribution during inference.",
      "importance_score": 68,
      "reasoning": "Addresses practical and important problem in MoE deployment. Novel load balancing approach with significant efficiency implications.",
      "themes": [
        "MoE Models",
        "Efficient Inference",
        "Load Balancing"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Least-Loaded Expert Parallelism for handling imbalanced MoE routing. Addresses compute and memory failures from disproportionate token distribution during inference.</p>",
      "content_html": "<p>arXiv:2601.17111v1 Announce Type: cross  Abstract: Mixture-of-Experts (MoE) models are typically pre-trained with explicit load-balancing constraints to ensure statistically balanced expert routing. Despite this, we observe that even well-trained MoE models exhibit significantly imbalanced routing. This behavior is arguably natural-and even desirable - as imbalanced routing allows models to concentrate domain-specific knowledge within a subset of experts. Expert parallelism (EP) is designed to scale MoE models by distributing experts across multiple devices, but with a less-discussed assumption of balanced routing. Under extreme imbalance, EP can funnel a disproportionate number of tokens to a small number of experts, leading to compute- and memory-bound failures on overloaded devices during post-training or inference, where explicit load balancing is often inapplicable. We propose Least-Loaded Expert Parallelism (LLEP), a novel EP algorithm that dynamically reroutes excess tokens and associated expert parameters from overloaded devices to underutilized ones. This ensures that all devices complete their workloads within the minimum collective latency while respecting memory constraints. Across different model scales, LLEP achieves up to 5x speedup and 4x reduction in peak memory usage compared to standard EP. This enables faster and higher-throughput post-training and inference, with ~1.9x faster for gpt-oss-120b. We support our method with extensive theoretical analysis and comprehensive empirical evaluations, including ablation studies. These results illuminate key trade-offs and enable a principled framework for hardware-specific hyper-parameter tuning to achieve optimal performance.</p>"
    },
    {
      "id": "3c3ce5fa3f2c",
      "title": "On the Insecurity of Keystroke-Based AI Authorship Detection: Timing-Forgery Attacks Against Motor-Signal Verification",
      "content": "arXiv:2601.17280v1 Announce Type: cross  Abstract: Recent proposals advocate using keystroke timing signals, specifically the coefficient of variation ($\\delta$) of inter-keystroke intervals, to distinguish human-composed text from AI-generated content. We demonstrate that this class of defenses is insecure against two practical attack classes: the copy-type attack, in which a human transcribes LLM-generated text producing authentic motor signals, and timing-forgery attacks, in which automated agents sample inter-keystroke intervals from empirical human distributions. Using 13,000 sessions from the SBU corpus and three timing-forgery variants (histogram sampling, statistical impersonation, and generative LSTM), we show all attacks achieve $\\ge$99.8% evasion rates against five classifiers. While detectors achieve AUC=1.000 against fully-automated injection, they classify $\\ge$99.8% of attack samples as human with mean confidence $\\ge$0.993. We formalize a non-identifiability result: when the detector observes only timing, the mutual information between features and content provenance is zero for copy-type attacks. Although composition and transcription produce statistically distinguishable motor patterns (Cohen's d=1.28), both yield $\\delta$ values 2-4x above detection thresholds, rendering the distinction security-irrelevant. These systems confirm a human operated the keyboard, but not whether that human originated the text. Securing provenance requires architectures that bind the writing process to semantic content.",
      "url": "http://arxiv.org/abs/2601.17280",
      "author": "David Condrey",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Demonstrates keystroke-based AI authorship detection is insecure against copy-type and timing-forgery attacks. All attacks achieve 99.8% evasion rates across classifiers.",
      "importance_score": 68,
      "reasoning": "Critical security finding invalidating proposed AI detection method. Strong empirical evidence with practical implications.",
      "themes": [
        "AI Detection",
        "Security",
        "Authorship Verification"
      ],
      "continuation": null,
      "summary_html": "<p>Demonstrates keystroke-based AI authorship detection is insecure against copy-type and timing-forgery attacks. All attacks achieve 99.8% evasion rates across classifiers.</p>",
      "content_html": "<p>arXiv:2601.17280v1 Announce Type: cross  Abstract: Recent proposals advocate using keystroke timing signals, specifically the coefficient of variation ($\\delta$) of inter-keystroke intervals, to distinguish human-composed text from AI-generated content. We demonstrate that this class of defenses is insecure against two practical attack classes: the copy-type attack, in which a human transcribes LLM-generated text producing authentic motor signals, and timing-forgery attacks, in which automated agents sample inter-keystroke intervals from empirical human distributions. Using 13,000 sessions from the SBU corpus and three timing-forgery variants (histogram sampling, statistical impersonation, and generative LSTM), we show all attacks achieve $\\ge$99.8% evasion rates against five classifiers. While detectors achieve AUC=1.000 against fully-automated injection, they classify $\\ge$99.8% of attack samples as human with mean confidence $\\ge$0.993. We formalize a non-identifiability result: when the detector observes only timing, the mutual information between features and content provenance is zero for copy-type attacks. Although composition and transcription produce statistically distinguishable motor patterns (Cohen's d=1.28), both yield $\\delta$ values 2-4x above detection thresholds, rendering the distinction security-irrelevant. These systems confirm a human operated the keyboard, but not whether that human originated the text. Securing provenance requires architectures that bind the writing process to semantic content.</p>"
    },
    {
      "id": "184c0cecaa80",
      "title": "Res-MIA: A Training-Free Resolution-Based Membership Inference Attack on Federated Learning Models",
      "content": "arXiv:2601.17378v1 Announce Type: cross  Abstract: Membership inference attacks (MIAs) pose a serious threat to the privacy of machine learning models by allowing adversaries to determine whether a specific data sample was included in the training set. Although federated learning (FL) is widely regarded as a privacy-aware training paradigm due to its decentralized nature, recent evidence shows that the final global model can still leak sensitive membership information through black-box access. In this paper, we introduce Res-MIA, a novel training-free and black-box membership inference attack that exploits the sensitivity of deep models to high-frequency input details. Res-MIA progressively degrades the input resolution using controlled downsampling and restoration operations, and analyzes the resulting confidence decay in the model's predictions. Our key insight is that training samples exhibit a significantly steeper confidence decline under resolution erosion compared to non-member samples, revealing a robust membership signal. Res-MIA requires no shadow models, no auxiliary data, and only a limited number of forward queries to the target model. We evaluate the proposed attack on a federated ResNet-18 trained on CIFAR-10, where it consistently outperforms existing training-free baselines and achieves an AUC of up to 0.88 with minimal computational overhead. These findings highlight frequency-sensitive overfitting as an important and previously underexplored source of privacy leakage in federated learning, and emphasize the need for privacy-aware model designs that reduce reliance on fine-grained, non-robust input features.",
      "url": "http://arxiv.org/abs/2601.17378",
      "author": "Mohammad Zare, Pirooz Shamsinejadbabaki",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Res-MIA introduces a training-free black-box membership inference attack on federated learning using progressive resolution degradation to detect training set membership.",
      "importance_score": 68,
      "reasoning": "Novel attack method requiring no training. Exploits deep model sensitivity to high-frequency details. Important for FL privacy.",
      "themes": [
        "Federated Learning",
        "Privacy Attacks",
        "Membership Inference"
      ],
      "continuation": null,
      "summary_html": "<p>Res-MIA introduces a training-free black-box membership inference attack on federated learning using progressive resolution degradation to detect training set membership.</p>",
      "content_html": "<p>arXiv:2601.17378v1 Announce Type: cross  Abstract: Membership inference attacks (MIAs) pose a serious threat to the privacy of machine learning models by allowing adversaries to determine whether a specific data sample was included in the training set. Although federated learning (FL) is widely regarded as a privacy-aware training paradigm due to its decentralized nature, recent evidence shows that the final global model can still leak sensitive membership information through black-box access. In this paper, we introduce Res-MIA, a novel training-free and black-box membership inference attack that exploits the sensitivity of deep models to high-frequency input details. Res-MIA progressively degrades the input resolution using controlled downsampling and restoration operations, and analyzes the resulting confidence decay in the model's predictions. Our key insight is that training samples exhibit a significantly steeper confidence decline under resolution erosion compared to non-member samples, revealing a robust membership signal. Res-MIA requires no shadow models, no auxiliary data, and only a limited number of forward queries to the target model. We evaluate the proposed attack on a federated ResNet-18 trained on CIFAR-10, where it consistently outperforms existing training-free baselines and achieves an AUC of up to 0.88 with minimal computational overhead. These findings highlight frequency-sensitive overfitting as an important and previously underexplored source of privacy leakage in federated learning, and emphasize the need for privacy-aware model designs that reduce reliance on fine-grained, non-robust input features.</p>"
    },
    {
      "id": "4308b8b85645",
      "title": "MalURLBench: A Benchmark Evaluating Agents' Vulnerabilities When Processing Web URLs",
      "content": "arXiv:2601.18113v1 Announce Type: cross  Abstract: LLM-based web agents have become increasingly popular for their utility in daily life and work. However, they exhibit critical vulnerabilities when processing malicious URLs: accepting a disguised malicious URL enables subsequent access to unsafe webpages, which can cause severe damage to service providers and users. Despite this risk, no benchmark currently targets this emerging threat. To address this gap, we propose MalURLBench, the first benchmark for evaluating LLMs' vulnerabilities to malicious URLs. MalURLBench contains 61,845 attack instances spanning 10 real-world scenarios and 7 categories of real malicious websites. Experiments with 12 popular LLMs reveal that existing models struggle to detect elaborately disguised malicious URLs. We further identify and analyze key factors that impact attack success rates and propose URLGuard, a lightweight defense module. We believe this work will provide a foundational resource for advancing the security of web agents. Our code is available at https://github.com/JiangYingEr/MalURLBench.",
      "url": "http://arxiv.org/abs/2601.18113",
      "author": "Dezhang Kong, Zhuxi Wu, Shiqi Liu, Zhicheng Tan, Kuichen Lu, Minghao Li, Qichen Liu, Shengyu Chu, Zhenhua Xu, Xuan Liu, Meng Han",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Introduces MalURLBench, first benchmark for evaluating LLM vulnerabilities to malicious URLs with 61,845 attack instances across 10 scenarios. Reveals that existing models struggle to detect elaborately disguised malicious URLs.",
      "importance_score": 68,
      "reasoning": "First comprehensive benchmark for important security vulnerability. Large-scale (61K instances) and reveals significant LLM weaknesses. Critical for LLM agent deployment safety.",
      "themes": [
        "LLM Security",
        "Benchmarking",
        "Web Agents",
        "AI Safety"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces MalURLBench, first benchmark for evaluating LLM vulnerabilities to malicious URLs with 61,845 attack instances across 10 scenarios. Reveals that existing models struggle to detect elaborately disguised malicious URLs.</p>",
      "content_html": "<p>arXiv:2601.18113v1 Announce Type: cross  Abstract: LLM-based web agents have become increasingly popular for their utility in daily life and work. However, they exhibit critical vulnerabilities when processing malicious URLs: accepting a disguised malicious URL enables subsequent access to unsafe webpages, which can cause severe damage to service providers and users. Despite this risk, no benchmark currently targets this emerging threat. To address this gap, we propose MalURLBench, the first benchmark for evaluating LLMs' vulnerabilities to malicious URLs. MalURLBench contains 61,845 attack instances spanning 10 real-world scenarios and 7 categories of real malicious websites. Experiments with 12 popular LLMs reveal that existing models struggle to detect elaborately disguised malicious URLs. We further identify and analyze key factors that impact attack success rates and propose URLGuard, a lightweight defense module. We believe this work will provide a foundational resource for advancing the security of web agents. Our code is available at https://github.com/JiangYingEr/MalURLBench.</p>"
    },
    {
      "id": "d2b57afe197a",
      "title": "Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback",
      "content": "arXiv:2601.18751v1 Announce Type: cross  Abstract: Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences. We introduce TriTrust-PBRL (TTP), a unified framework that jointly learns a shared reward model and expert-specific trust parameters from multi-expert preference feedback. The key insight is that trust parameters naturally evolve during gradient-based optimization to be positive (trust), near zero (ignore), or negative (flip), enabling the model to automatically invert adversarial preferences and recover useful signal rather than merely discarding corrupted feedback. We provide theoretical analysis establishing identifiability guarantees and detailed gradient analysis that explains how expert separation emerges naturally during training without explicit supervision. Empirically, we evaluate TTP on four diverse domains spanning manipulation tasks (MetaWorld) and locomotion (DM Control) under various corruption scenarios. TTP achieves state-of-the-art robustness, maintaining near-oracle performance under adversarial corruption while standard PBRL methods fail catastrophically. Notably, TTP outperforms existing baselines by successfully learning from mixed expert pools containing both reliable and adversarial annotators, all while requiring no expert features beyond identification indices and integrating seamlessly with existing PBRL pipelines.",
      "url": "http://arxiv.org/abs/2601.18751",
      "author": "Seyed Amir Hosseini, Maryam Abdolali, Amirhosein Tavakkoli, Fardin Ayar, Ehsan Javanmardi, Manabu Tsukada, Mahdi Javanmardi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces TriTrust-PBRL for preference-based RL with heterogeneous annotators, jointly learning reward model and trust parameters. Key insight: trust parameters can flip systematically adversarial preferences.",
      "importance_score": 68,
      "reasoning": "Novel approach handling adversarial annotators in PBRL. Trust-flip mechanism is clever solution to real-world annotation challenge.",
      "themes": [
        "Preference Learning",
        "Reinforcement Learning",
        "Robust Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces TriTrust-PBRL for preference-based RL with heterogeneous annotators, jointly learning reward model and trust parameters. Key insight: trust parameters can flip systematically adversarial preferences.</p>",
      "content_html": "<p>arXiv:2601.18751v1 Announce Type: cross  Abstract: Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences. We introduce TriTrust-PBRL (TTP), a unified framework that jointly learns a shared reward model and expert-specific trust parameters from multi-expert preference feedback. The key insight is that trust parameters naturally evolve during gradient-based optimization to be positive (trust), near zero (ignore), or negative (flip), enabling the model to automatically invert adversarial preferences and recover useful signal rather than merely discarding corrupted feedback. We provide theoretical analysis establishing identifiability guarantees and detailed gradient analysis that explains how expert separation emerges naturally during training without explicit supervision. Empirically, we evaluate TTP on four diverse domains spanning manipulation tasks (MetaWorld) and locomotion (DM Control) under various corruption scenarios. TTP achieves state-of-the-art robustness, maintaining near-oracle performance under adversarial corruption while standard PBRL methods fail catastrophically. Notably, TTP outperforms existing baselines by successfully learning from mixed expert pools containing both reliable and adversarial annotators, all while requiring no expert features beyond identification indices and integrating seamlessly with existing PBRL pipelines.</p>"
    },
    {
      "id": "8d387913555f",
      "title": "Persuasion Tokens for Editing Factual Knowledge in LLMs",
      "content": "arXiv:2601.16781v2 Announce Type: cross  Abstract: In-context knowledge editing (IKE) is a promising technique for updating Large Language Models (LLMs) with new information. However, IKE relies on lengthy, fact-specific demonstrations which are costly to create and consume significant context window space. In this paper, we introduce persuasion tokens (P-Tokens) -- special tokens trained to replicate the effect of IKE demonstrations, enabling efficient knowledge editing without requiring fact-specific demonstrations. We evaluate P-Tokens across two editing datasets and three LLMs, demonstrating performance comparable to, and often exceeding, IKE. We further find that editing performance is robust to distractors with small negative effects to neighboring facts, and that increasing the number of P-Tokens improves performance. Our work addresses key limitations of IKE and provides a more practical and scalable alternative for editing LLMs.",
      "url": "http://arxiv.org/abs/2601.16781",
      "author": "Paul Youssef, Christin Seifert, J\\\"org Schl\\\"otterer",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces persuasion tokens (P-Tokens) as special tokens trained to replicate in-context knowledge editing demonstrations, enabling efficient LLM knowledge updates without fact-specific examples. Achieves comparable or better performance than standard IKE methods.",
      "importance_score": 68,
      "reasoning": "Practical efficiency improvement for knowledge editing with demonstrated effectiveness across multiple LLMs. Addresses real bottleneck in context window usage.",
      "themes": [
        "Knowledge Editing",
        "Language Models",
        "Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces persuasion tokens (P-Tokens) as special tokens trained to replicate in-context knowledge editing demonstrations, enabling efficient LLM knowledge updates without fact-specific examples. Achieves comparable or better performance than standard IKE methods.</p>",
      "content_html": "<p>arXiv:2601.16781v2 Announce Type: cross  Abstract: In-context knowledge editing (IKE) is a promising technique for updating Large Language Models (LLMs) with new information. However, IKE relies on lengthy, fact-specific demonstrations which are costly to create and consume significant context window space. In this paper, we introduce persuasion tokens (P-Tokens) -- special tokens trained to replicate the effect of IKE demonstrations, enabling efficient knowledge editing without requiring fact-specific demonstrations. We evaluate P-Tokens across two editing datasets and three LLMs, demonstrating performance comparable to, and often exceeding, IKE. We further find that editing performance is robust to distractors with small negative effects to neighboring facts, and that increasing the number of P-Tokens improves performance. Our work addresses key limitations of IKE and provides a more practical and scalable alternative for editing LLMs.</p>"
    },
    {
      "id": "d2cd82575b94",
      "title": "From Emotion to Expression: Theoretical Foundations and Resources for Fear Speech",
      "content": "arXiv:2601.17132v1 Announce Type: new  Abstract: Few forces rival fear in their ability to mobilize societies, distort communication, and reshape collective behavior. In computational linguistics, fear is primarily studied as an emotion, but not as a distinct form of speech. Fear speech content is widespread and growing, and often outperforms hate-speech content in reach and engagement because it appears \"civiler\" and evades moderation. Yet the computational study of fear speech remains fragmented and under-resourced. This can be understood by recognizing that fear speech is a phenomenon shaped by contributions from multiple disciplines. In this paper, we bridge cross-disciplinary perspectives by comparing theories of fear from Psychology, Political science, Communication science, and Linguistics. Building on this, we review existing definitions. We follow up with a survey of datasets from related research areas and propose a taxonomy that consolidates different dimensions of fear for studying fear speech. By reviewing current datasets and defining core concepts, our work offers both theoretical and practical guidance for creating datasets and advancing fear speech research.",
      "url": "http://arxiv.org/abs/2601.17132",
      "author": "Vigneshwaran Shankaran, Gabriella Lapesa, Claudia Wagner",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents theoretical foundations for fear speech as distinct from hate speech, bridging perspectives from psychology, political science, communication, and linguistics. Argues fear speech evades moderation while driving engagement.",
      "importance_score": 68,
      "reasoning": "Important conceptual contribution for content moderation research. Identifies under-studied phenomenon with significant real-world implications.",
      "themes": [
        "Content Moderation",
        "Computational Social Science",
        "NLP Resources"
      ],
      "continuation": null,
      "summary_html": "<p>Presents theoretical foundations for fear speech as distinct from hate speech, bridging perspectives from psychology, political science, communication, and linguistics. Argues fear speech evades moderation while driving engagement.</p>",
      "content_html": "<p>arXiv:2601.17132v1 Announce Type: new  Abstract: Few forces rival fear in their ability to mobilize societies, distort communication, and reshape collective behavior. In computational linguistics, fear is primarily studied as an emotion, but not as a distinct form of speech. Fear speech content is widespread and growing, and often outperforms hate-speech content in reach and engagement because it appears \"civiler\" and evades moderation. Yet the computational study of fear speech remains fragmented and under-resourced. This can be understood by recognizing that fear speech is a phenomenon shaped by contributions from multiple disciplines. In this paper, we bridge cross-disciplinary perspectives by comparing theories of fear from Psychology, Political science, Communication science, and Linguistics. Building on this, we review existing definitions. We follow up with a survey of datasets from related research areas and propose a taxonomy that consolidates different dimensions of fear for studying fear speech. By reviewing current datasets and defining core concepts, our work offers both theoretical and practical guidance for creating datasets and advancing fear speech research.</p>"
    },
    {
      "id": "4c60ba1e1840",
      "title": "Learning to Ideate for Machine Learning Engineering Agents",
      "content": "arXiv:2601.17596v1 Announce Type: new  Abstract: Existing machine learning engineering (MLE) agents struggle to iteratively optimize their implemented algorithms for effectiveness. To address this, we introduce MLE-Ideator, a dual-agent framework that separates ideation from implementation. In our system, an implementation agent can request strategic help from a dedicated Ideator. We show this approach is effective in two ways. First, in a training-free setup, our framework significantly outperforms implementation-only agent baselines on MLE-Bench. Second, we demonstrate that the Ideator can be trained with reinforcement learning (RL) to generate more effective ideas. With only 1K training samples from 10 MLE tasks, our RL-trained Qwen3-8B Ideator achieves an 11.5% relative improvement compared to its untrained counterpart and surpasses Claude Sonnet 3.5. These results highlights a promising path toward training strategic AI systems for scientific discovery.",
      "url": "http://arxiv.org/abs/2601.17596",
      "author": "Yunxiang Zhang, Kang Zhou, Zhichao Xu, Kiran Ramnath, Yun Zhou, Sangmin Woo, Haibo Ding, Lin Lee Cheong",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces MLE-Ideator, a dual-agent framework separating ideation from implementation for ML engineering tasks. Shows RL-trained Ideator achieves 11.5% improvement with only 1K training samples.",
      "importance_score": 68,
      "reasoning": "Practical contribution to ML engineering agents with demonstrated effectiveness. Novel separation of concerns approach.",
      "themes": [
        "LLM Agents",
        "ML Engineering",
        "Reinforcement Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces MLE-Ideator, a dual-agent framework separating ideation from implementation for ML engineering tasks. Shows RL-trained Ideator achieves 11.5% improvement with only 1K training samples.</p>",
      "content_html": "<p>arXiv:2601.17596v1 Announce Type: new  Abstract: Existing machine learning engineering (MLE) agents struggle to iteratively optimize their implemented algorithms for effectiveness. To address this, we introduce MLE-Ideator, a dual-agent framework that separates ideation from implementation. In our system, an implementation agent can request strategic help from a dedicated Ideator. We show this approach is effective in two ways. First, in a training-free setup, our framework significantly outperforms implementation-only agent baselines on MLE-Bench. Second, we demonstrate that the Ideator can be trained with reinforcement learning (RL) to generate more effective ideas. With only 1K training samples from 10 MLE tasks, our RL-trained Qwen3-8B Ideator achieves an 11.5% relative improvement compared to its untrained counterpart and surpasses Claude Sonnet 3.5. These results highlights a promising path toward training strategic AI systems for scientific discovery.</p>"
    },
    {
      "id": "fa5dddf5f685",
      "title": "Grounded Concreteness: Human-Like Concreteness Sensitivity in Vision-Language Models",
      "content": "arXiv:2601.18065v1 Announce Type: new  Abstract: Do vision--language models (VLMs) develop more human-like sensitivity to linguistic concreteness than text-only large language models (LLMs) when both are evaluated with text-only prompts? We study this question with a controlled comparison between matched Llama text backbones and their Llama Vision counterparts across multiple model scales, treating multimodal pretraining as an ablation on perceptual grounding rather than access to images at inference. We measure concreteness effects at three complementary levels: (i) output behavior, by relating question-level concreteness to QA accuracy; (ii) embedding geometry, by testing whether representations organize along a concreteness axis; and (iii) attention dynamics, by quantifying context reliance via attention-entropy measures. In addition, we elicit token-level concreteness ratings from models and evaluate alignment to human norm distributions, testing whether multimodal training yields more human-consistent judgments. Across benchmarks and scales, VLMs show larger gains on more concrete inputs, exhibit clearer concreteness-structured representations, produce ratings that better match human norms, and display systematically different attention patterns consistent with increased grounding.",
      "url": "http://arxiv.org/abs/2601.18065",
      "author": "Aryan Roy, Zekun Wang, Christopher J. MacLellan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Studies whether VLMs develop more human-like sensitivity to linguistic concreteness than text-only LLMs through controlled comparison of Llama variants. Examines output behavior, embedding geometry, and attention dynamics.",
      "importance_score": 68,
      "reasoning": "Novel investigation of grounding effects on language understanding. Well-designed comparison isolating multimodal pretraining effects.",
      "themes": [
        "Vision-Language Models",
        "Grounding",
        "Cognitive Alignment"
      ],
      "continuation": null,
      "summary_html": "<p>Studies whether VLMs develop more human-like sensitivity to linguistic concreteness than text-only LLMs through controlled comparison of Llama variants. Examines output behavior, embedding geometry, and attention dynamics.</p>",
      "content_html": "<p>arXiv:2601.18065v1 Announce Type: new  Abstract: Do vision--language models (VLMs) develop more human-like sensitivity to linguistic concreteness than text-only large language models (LLMs) when both are evaluated with text-only prompts? We study this question with a controlled comparison between matched Llama text backbones and their Llama Vision counterparts across multiple model scales, treating multimodal pretraining as an ablation on perceptual grounding rather than access to images at inference. We measure concreteness effects at three complementary levels: (i) output behavior, by relating question-level concreteness to QA accuracy; (ii) embedding geometry, by testing whether representations organize along a concreteness axis; and (iii) attention dynamics, by quantifying context reliance via attention-entropy measures. In addition, we elicit token-level concreteness ratings from models and evaluate alignment to human norm distributions, testing whether multimodal training yields more human-consistent judgments. Across benchmarks and scales, VLMs show larger gains on more concrete inputs, exhibit clearer concreteness-structured representations, produce ratings that better match human norms, and display systematically different attention patterns consistent with increased grounding.</p>"
    },
    {
      "id": "c161f299f313",
      "title": "One Persona, Many Cues, Different Results: How Sociodemographic Cues Impact LLM Personalization",
      "content": "arXiv:2601.18572v1 Announce Type: new  Abstract: Personalization of LLMs by sociodemographic subgroup often improves user experience, but can also introduce or amplify biases and unfair outcomes across groups. Prior work has employed so-called personas, sociodemographic user attributes conveyed to a model, to study bias in LLMs by relying on a single cue to prompt a persona, such as user names or explicit attribute mentions. This disregards LLM sensitivity to prompt variations (robustness) and the rarity of some cues in real interactions (external validity). We compare six commonly used persona cues across seven open and proprietary LLMs on four writing and advice tasks. While cues are overall highly correlated, they produce substantial variance in responses across personas. We therefore caution against claims from a single persona cue and recommend future personalization research to evaluate multiple externally valid cues.",
      "url": "http://arxiv.org/abs/2601.18572",
      "author": "Franziska Weeber, Vera Neplenbroek, Jan Batzner, Sebastian Pad\\'o",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Compares six persona cue types across seven LLMs on four tasks, finding cues produce substantial response variance despite overall correlation. Questions robustness and external validity of persona-based studies.",
      "importance_score": 68,
      "reasoning": "Important methodological contribution for personalization and bias research. Comprehensive evaluation with practical recommendations.",
      "themes": [
        "Personalization",
        "Bias and Fairness",
        "LLM Evaluation"
      ],
      "continuation": null,
      "summary_html": "<p>Compares six persona cue types across seven LLMs on four tasks, finding cues produce substantial response variance despite overall correlation. Questions robustness and external validity of persona-based studies.</p>",
      "content_html": "<p>arXiv:2601.18572v1 Announce Type: new  Abstract: Personalization of LLMs by sociodemographic subgroup often improves user experience, but can also introduce or amplify biases and unfair outcomes across groups. Prior work has employed so-called personas, sociodemographic user attributes conveyed to a model, to study bias in LLMs by relying on a single cue to prompt a persona, such as user names or explicit attribute mentions. This disregards LLM sensitivity to prompt variations (robustness) and the rarity of some cues in real interactions (external validity). We compare six commonly used persona cues across seven open and proprietary LLMs on four writing and advice tasks. While cues are overall highly correlated, they produce substantial variance in responses across personas. We therefore caution against claims from a single persona cue and recommend future personalization research to evaluate multiple externally valid cues.</p>"
    },
    {
      "id": "2feb5d0dff36",
      "title": "Scaling medical imaging report generation with multimodal reinforcement learning",
      "content": "arXiv:2601.17151v1 Announce Type: cross  Abstract: Frontier models have demonstrated remarkable capabilities in understanding and reasoning with natural-language text, but they still exhibit major competency gaps in multimodal understanding and reasoning especially in high-value verticals such as biomedicine. Medical imaging report generation is a prominent example. Supervised fine-tuning can substantially improve performance, but they are prone to overfitting to superficial boilerplate patterns. In this paper, we introduce Universal Report Generation (UniRG) as a general framework for medical imaging report generation. By leveraging reinforcement learning as a unifying mechanism to directly optimize for evaluation metrics designed for end applications, UniRG can significantly improve upon supervised fine-tuning and attain durable generalization across diverse institutions and clinical practices. We trained UniRG-CXR on publicly available chest X-ray (CXR) data and conducted a thorough evaluation in CXR report generation with rigorous evaluation scenarios. On the authoritative ReXrank benchmark, UniRG-CXR sets new overall SOTA, outperforming prior state of the art by a wide margin.",
      "url": "http://arxiv.org/abs/2601.17151",
      "author": "Qianchu Liu, Sheng Zhang, Guanghui Qin, Yu Gu, Ying Jin, Sam Preston, Yanbo Xu, Sid Kiblawi, Wen-wai Yim, Tim Ossowski, Tristan Naumann, Mu Wei, Hoifung Poon",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces UniRG framework for medical imaging report generation using reinforcement learning to directly optimize evaluation metrics. Demonstrates significant improvements over supervised fine-tuning by avoiding overfitting to boilerplate patterns.",
      "importance_score": 68,
      "reasoning": "Practical advancement in medical AI with RL-based approach. Addresses real limitations of supervised methods in clinical documentation.",
      "themes": [
        "Medical AI",
        "Multimodal Learning",
        "Reinforcement Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces UniRG framework for medical imaging report generation using reinforcement learning to directly optimize evaluation metrics. Demonstrates significant improvements over supervised fine-tuning by avoiding overfitting to boilerplate patterns.</p>",
      "content_html": "<p>arXiv:2601.17151v1 Announce Type: cross  Abstract: Frontier models have demonstrated remarkable capabilities in understanding and reasoning with natural-language text, but they still exhibit major competency gaps in multimodal understanding and reasoning especially in high-value verticals such as biomedicine. Medical imaging report generation is a prominent example. Supervised fine-tuning can substantially improve performance, but they are prone to overfitting to superficial boilerplate patterns. In this paper, we introduce Universal Report Generation (UniRG) as a general framework for medical imaging report generation. By leveraging reinforcement learning as a unifying mechanism to directly optimize for evaluation metrics designed for end applications, UniRG can significantly improve upon supervised fine-tuning and attain durable generalization across diverse institutions and clinical practices. We trained UniRG-CXR on publicly available chest X-ray (CXR) data and conducted a thorough evaluation in CXR report generation with rigorous evaluation scenarios. On the authoritative ReXrank benchmark, UniRG-CXR sets new overall SOTA, outperforming prior state of the art by a wide margin.</p>"
    },
    {
      "id": "2f9cef4dd978",
      "title": "Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models",
      "content": "arXiv:2601.18734v1 Announce Type: cross  Abstract: Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods.",
      "url": "http://arxiv.org/abs/2601.18734",
      "author": "Siyan Zhao, Zhihui Xie, Mengchen Liu, Jing Huang, Guan Pang, Feiyu Chen, Aditya Grover",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes Self-Distilled Reasoner for on-policy self-distillation where LLM rationalizes external reasoning traces to teach its weaker self, eliminating need for separate teacher while leveraging ground-truth solutions.",
      "importance_score": 68,
      "reasoning": "Novel self-improvement approach for reasoning without separate teacher. Practical contribution to distillation methods.",
      "themes": [
        "Reasoning",
        "Self-improvement",
        "Knowledge Distillation"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Self-Distilled Reasoner for on-policy self-distillation where LLM rationalizes external reasoning traces to teach its weaker self, eliminating need for separate teacher while leveraging ground-truth solutions.</p>",
      "content_html": "<p>arXiv:2601.18734v1 Announce Type: cross  Abstract: Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods.</p>"
    },
    {
      "id": "13e93da85fd1",
      "title": "Geometry-Grounded Gaussian Splatting",
      "content": "arXiv:2601.17835v1 Announce Type: new  Abstract: Gaussian Splatting (GS) has demonstrated impressive quality and efficiency in novel view synthesis. However, shape extraction from Gaussian primitives remains an open problem. Due to inadequate geometry parameterization and approximation, existing shape reconstruction methods suffer from poor multi-view consistency and are sensitive to floaters. In this paper, we present a rigorous theoretical derivation that establishes Gaussian primitives as a specific type of stochastic solids. This theoretical framework provides a principled foundation for Geometry-Grounded Gaussian Splatting by enabling the direct treatment of Gaussian primitives as explicit geometric representations. Using the volumetric nature of stochastic solids, our method efficiently renders high-quality depth maps for fine-grained geometry extraction. Experiments show that our method achieves the best shape reconstruction results among all Gaussian Splatting-based methods on public datasets.",
      "url": "http://arxiv.org/abs/2601.17835",
      "author": "Baowen Zhang, Chenxing Jiang, Heng Li, Shaojie Shen, Ping Tan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Provides rigorous theoretical derivation establishing Gaussian primitives as stochastic solids, enabling direct treatment as explicit geometric representations for improved shape extraction and multi-view consistency in Gaussian Splatting.",
      "importance_score": 68,
      "reasoning": "Important theoretical contribution providing principled foundation for Gaussian Splatting geometry. Addresses open problem of shape extraction from 3DGS.",
      "themes": [
        "Gaussian Splatting",
        "3D Reconstruction",
        "Theoretical Foundations"
      ],
      "continuation": null,
      "summary_html": "<p>Provides rigorous theoretical derivation establishing Gaussian primitives as stochastic solids, enabling direct treatment as explicit geometric representations for improved shape extraction and multi-view consistency in Gaussian Splatting.</p>",
      "content_html": "<p>arXiv:2601.17835v1 Announce Type: new  Abstract: Gaussian Splatting (GS) has demonstrated impressive quality and efficiency in novel view synthesis. However, shape extraction from Gaussian primitives remains an open problem. Due to inadequate geometry parameterization and approximation, existing shape reconstruction methods suffer from poor multi-view consistency and are sensitive to floaters. In this paper, we present a rigorous theoretical derivation that establishes Gaussian primitives as a specific type of stochastic solids. This theoretical framework provides a principled foundation for Geometry-Grounded Gaussian Splatting by enabling the direct treatment of Gaussian primitives as explicit geometric representations. Using the volumetric nature of stochastic solids, our method efficiently renders high-quality depth maps for fine-grained geometry extraction. Experiments show that our method achieves the best shape reconstruction results among all Gaussian Splatting-based methods on public datasets.</p>"
    },
    {
      "id": "42fbeda29512",
      "title": "Agentic Very Long Video Understanding",
      "content": "arXiv:2601.18157v1 Announce Type: new  Abstract: The advent of always-on personal AI assistants, enabled by all-day wearable devices such as smart glasses, demands a new level of contextual understanding, one that goes beyond short, isolated events to encompass the continuous, longitudinal stream of egocentric video. Achieving this vision requires advances in long-horizon video understanding, where systems must interpret and recall visual and audio information spanning days or even weeks. Existing methods, including large language models and retrieval-augmented generation, are constrained by limited context windows and lack the ability to perform compositional, multi-hop reasoning over very long video streams. In this work, we address these challenges through EGAgent, an enhanced agentic framework centered on entity scene graphs, which represent people, places, objects, and their relationships over time. Our system equips a planning agent with tools for structured search and reasoning over these graphs, as well as hybrid visual and audio search capabilities, enabling detailed, cross-modal, and temporally coherent reasoning. Experiments on the EgoLifeQA and Video-MME (Long) datasets show that our method achieves state-of-the-art performance on EgoLifeQA (57.5%) and competitive performance on Video-MME (Long) (74.1%) for complex longitudinal video understanding tasks.",
      "url": "http://arxiv.org/abs/2601.18157",
      "author": "Aniket Rege, Arka Sadhu, Yuliang Li, Kejie Li, Ramya Korlakai Vinayak, Yuning Chai, Yong Jae Lee, Hyo Jin Kim",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "EGAgent addresses very long egocentric video understanding through an enhanced agentic framework enabling compositional, multi-hop reasoning over video streams spanning days or weeks, targeting always-on AI assistants.",
      "importance_score": 68,
      "reasoning": "Addresses critical challenge for wearable AI assistants. Important for always-on personal AI use case. Novel agentic approach to long video.",
      "themes": [
        "Video Understanding",
        "AI Agents",
        "Egocentric Vision",
        "Long-context"
      ],
      "continuation": null,
      "summary_html": "<p>EGAgent addresses very long egocentric video understanding through an enhanced agentic framework enabling compositional, multi-hop reasoning over video streams spanning days or weeks, targeting always-on AI assistants.</p>",
      "content_html": "<p>arXiv:2601.18157v1 Announce Type: new  Abstract: The advent of always-on personal AI assistants, enabled by all-day wearable devices such as smart glasses, demands a new level of contextual understanding, one that goes beyond short, isolated events to encompass the continuous, longitudinal stream of egocentric video. Achieving this vision requires advances in long-horizon video understanding, where systems must interpret and recall visual and audio information spanning days or even weeks. Existing methods, including large language models and retrieval-augmented generation, are constrained by limited context windows and lack the ability to perform compositional, multi-hop reasoning over very long video streams. In this work, we address these challenges through EGAgent, an enhanced agentic framework centered on entity scene graphs, which represent people, places, objects, and their relationships over time. Our system equips a planning agent with tools for structured search and reasoning over these graphs, as well as hybrid visual and audio search capabilities, enabling detailed, cross-modal, and temporally coherent reasoning. Experiments on the EgoLifeQA and Video-MME (Long) datasets show that our method achieves state-of-the-art performance on EgoLifeQA (57.5%) and competitive performance on Video-MME (Long) (74.1%) for complex longitudinal video understanding tasks.</p>"
    },
    {
      "id": "894531392855",
      "title": "ExoGS: A 4D Real-to-Sim-to-Real Framework for Scalable Manipulation Data Collection",
      "content": "arXiv:2601.18629v1 Announce Type: new  Abstract: Real-to-Sim-to-Real technique is gaining increasing interest for robotic manipulation, as it can generate scalable data in simulation while having narrower sim-to-real gap. However, previous methods mainly focused on environment-level visual real-to-sim transfer, ignoring the transfer of interactions, which could be challenging and inefficient to obtain purely in simulation especially for contact-rich tasks. We propose ExoGS, a robot-free 4D Real-to-Sim-to-Real framework that captures both static environments and dynamic interactions in the real world and transfers them seamlessly to a simulated environment. It provides a new solution for scalable manipulation data collection and policy learning. ExoGS employs a self-designed robot-isomorphic passive exoskeleton AirExo-3 to capture kinematically consistent trajectories with millimeter-level accuracy and synchronized RGB observations during direct human demonstrations. The robot, objects, and environment are reconstructed as editable 3D Gaussian Splatting assets, enabling geometry-consistent replay and large-scale data augmentation. Additionally, a lightweight Mask Adapter injects instance-level semantics into the policy to enhance robustness under visual domain shifts. Real-world experiments demonstrate that ExoGS significantly improves data efficiency and policy generalization compared to teleoperation-based baselines. Code and hardware files have been released on https://github.com/zaixiabalala/ExoGS.",
      "url": "http://arxiv.org/abs/2601.18629",
      "author": "Yiming Wang, Ruogu Zhang, Minyang Li, Hao Shi, Junbo Wang, Deyi Li, Jieji Ren, Wenhai Liu, Weiming Wang, Hao-Shu Fang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes ExoGS, a 4D Real-to-Sim-to-Real framework capturing static environments and dynamic interactions for scalable manipulation data collection using robot-isomorphic exoskeleton.",
      "importance_score": 68,
      "reasoning": "Novel approach to bridging real-to-sim gap with dynamic interaction capture, addresses key bottleneck in robot data collection.",
      "themes": [
        "Sim-to-Real",
        "Data Collection",
        "Robot Manipulation",
        "Gaussian Splatting"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes ExoGS, a 4D Real-to-Sim-to-Real framework capturing static environments and dynamic interactions for scalable manipulation data collection using robot-isomorphic exoskeleton.</p>",
      "content_html": "<p>arXiv:2601.18629v1 Announce Type: new  Abstract: Real-to-Sim-to-Real technique is gaining increasing interest for robotic manipulation, as it can generate scalable data in simulation while having narrower sim-to-real gap. However, previous methods mainly focused on environment-level visual real-to-sim transfer, ignoring the transfer of interactions, which could be challenging and inefficient to obtain purely in simulation especially for contact-rich tasks. We propose ExoGS, a robot-free 4D Real-to-Sim-to-Real framework that captures both static environments and dynamic interactions in the real world and transfers them seamlessly to a simulated environment. It provides a new solution for scalable manipulation data collection and policy learning. ExoGS employs a self-designed robot-isomorphic passive exoskeleton AirExo-3 to capture kinematically consistent trajectories with millimeter-level accuracy and synchronized RGB observations during direct human demonstrations. The robot, objects, and environment are reconstructed as editable 3D Gaussian Splatting assets, enabling geometry-consistent replay and large-scale data augmentation. Additionally, a lightweight Mask Adapter injects instance-level semantics into the policy to enhance robustness under visual domain shifts. Real-world experiments demonstrate that ExoGS significantly improves data efficiency and policy generalization compared to teleoperation-based baselines. Code and hardware files have been released on https://github.com/zaixiabalala/ExoGS.</p>"
    },
    {
      "id": "0201c3496701",
      "title": "SQL-Trail: Multi-Turn Reinforcement Learning with Interleaved Feedback for Text-to-SQL",
      "content": "arXiv:2601.17699v1 Announce Type: new  Abstract: While large language models (LLMs) have substantially improved Text-to-SQL generation, a pronounced gap remains between AI systems and human experts on challenging benchmarks such as BIRD-SQL. We argue this gap stems largely from the prevailing single-pass paradigm, which lacks the iterative reasoning, schema exploration, and error-correction behaviors that humans naturally employ. To address this limitation, we introduce SQL-Trail, a multi-turn reinforcement learning (RL) agentic framework for Text-to-SQL. Rather than producing a query in one shot, SQL-Trail interacts with the database environment and uses execution feedback to iteratively refine its predictions. Our approach centers on two key ideas: (i) an adaptive turn-budget allocation mechanism that scales the agent's interaction depth to match question difficulty, and (ii) a composite reward panel that jointly incentivizes SQL correctness and efficient exploration. Across benchmarks, SQL-Trail sets a new state of the art and delivers strong data efficiency--up to 18x higher than prior single-pass RL state-of-the-art methods. Notably, our 7B and 14B models outperform substantially larger proprietary systems by 5% on average, underscoring the effectiveness of interactive, agentic workflows for robust Text-to-SQL generation.",
      "url": "http://arxiv.org/abs/2601.17699",
      "author": "Harper Hua, Zhen Han, Zhengyuan Shen, Jeremy Lee, Patrick Guan, Qi Zhu, Sullam Jeoung, Yueyan Chen, Yunfei Bai, Shuai Wang, Vassilis Ioannidis, Huzefa Rangwala",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces SQL-Trail, a multi-turn RL framework for text-to-SQL that interacts with databases and uses execution feedback to iteratively refine predictions with adaptive turn-budget allocation.",
      "importance_score": 67,
      "reasoning": "Addresses key limitation of single-pass text-to-SQL; combines RL with practical feedback mechanism for iterative improvement.",
      "themes": [
        "Text-to-SQL",
        "Reinforcement Learning",
        "Agentic AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces SQL-Trail, a multi-turn RL framework for text-to-SQL that interacts with databases and uses execution feedback to iteratively refine predictions with adaptive turn-budget allocation.</p>",
      "content_html": "<p>arXiv:2601.17699v1 Announce Type: new  Abstract: While large language models (LLMs) have substantially improved Text-to-SQL generation, a pronounced gap remains between AI systems and human experts on challenging benchmarks such as BIRD-SQL. We argue this gap stems largely from the prevailing single-pass paradigm, which lacks the iterative reasoning, schema exploration, and error-correction behaviors that humans naturally employ. To address this limitation, we introduce SQL-Trail, a multi-turn reinforcement learning (RL) agentic framework for Text-to-SQL. Rather than producing a query in one shot, SQL-Trail interacts with the database environment and uses execution feedback to iteratively refine its predictions. Our approach centers on two key ideas: (i) an adaptive turn-budget allocation mechanism that scales the agent's interaction depth to match question difficulty, and (ii) a composite reward panel that jointly incentivizes SQL correctness and efficient exploration. Across benchmarks, SQL-Trail sets a new state of the art and delivers strong data efficiency--up to 18x higher than prior single-pass RL state-of-the-art methods. Notably, our 7B and 14B models outperform substantially larger proprietary systems by 5% on average, underscoring the effectiveness of interactive, agentic workflows for robust Text-to-SQL generation.</p>"
    },
    {
      "id": "00d188f69d90",
      "title": "UniCog: Uncovering Cognitive Abilities of LLMs through Latent Mind Space Analysis",
      "content": "arXiv:2601.17897v1 Announce Type: new  Abstract: A growing body of research suggests that the cognitive processes of large language models (LLMs) differ fundamentally from those of humans. However, existing interpretability methods remain limited in explaining how cognitive abilities are engaged during LLM reasoning. In this paper, we propose UniCog, a unified framework that analyzes LLM cognition via a latent mind space. Formulated as a latent variable model, UniCog encodes diverse abilities from dense model activations into sparse, disentangled latent dimensions. Through extensive analysis on six advanced LLMs, including DeepSeek-V3.2 and GPT-4o, we reveal a Pareto principle of LLM cognition, where a shared reasoning core is complemented by ability-specific signatures. Furthermore, we discover that reasoning failures often manifest as anomalous intensity in latent activations. These findings opens a new paradigm in LLM analysis, providing a cognition grounded view of reasoning dynamics. Finally, leveraging these insights, we introduce a latent-informed candidate prioritization strategy, which improves reasoning performance by up to 7.5% across challenging benchmarks. Our code is available at https://github.com/milksalute/unicog.",
      "url": "http://arxiv.org/abs/2601.17897",
      "author": "Jiayu Liu, Yinhe Long, Zhenya Huang, Enhong Chen",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes UniCog framework analyzing LLM cognition through latent mind space, revealing a Pareto principle where a shared reasoning core is complemented by ability-specific signatures across models including DeepSeek-V3.2 and GPT-4o.",
      "importance_score": 67,
      "reasoning": "Novel interpretability approach with findings across frontier models; reveals interesting cognitive structure patterns.",
      "themes": [
        "Interpretability",
        "Cognitive AI",
        "LLM Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes UniCog framework analyzing LLM cognition through latent mind space, revealing a Pareto principle where a shared reasoning core is complemented by ability-specific signatures across models including DeepSeek-V3.2 and GPT-4o.</p>",
      "content_html": "<p>arXiv:2601.17897v1 Announce Type: new  Abstract: A growing body of research suggests that the cognitive processes of large language models (LLMs) differ fundamentally from those of humans. However, existing interpretability methods remain limited in explaining how cognitive abilities are engaged during LLM reasoning. In this paper, we propose UniCog, a unified framework that analyzes LLM cognition via a latent mind space. Formulated as a latent variable model, UniCog encodes diverse abilities from dense model activations into sparse, disentangled latent dimensions. Through extensive analysis on six advanced LLMs, including DeepSeek-V3.2 and GPT-4o, we reveal a Pareto principle of LLM cognition, where a shared reasoning core is complemented by ability-specific signatures. Furthermore, we discover that reasoning failures often manifest as anomalous intensity in latent activations. These findings opens a new paradigm in LLM analysis, providing a cognition grounded view of reasoning dynamics. Finally, leveraging these insights, we introduce a latent-informed candidate prioritization strategy, which improves reasoning performance by up to 7.5% across challenging benchmarks. Our code is available at https://github.com/milksalute/unicog.</p>"
    },
    {
      "id": "6051ae2f52a6",
      "title": "Evaluating Reward Model Generalization via Pairwise Maximum Discrepancy Competitions",
      "content": "arXiv:2601.16987v1 Announce Type: cross  Abstract: Reward models (RMs) are central to aligning large language models, yet their practical effectiveness hinges on generalization to unseen prompts and shifting distributions. Most existing RM evaluations rely on static, pre-annotated preference datasets, which provide limited coverage and often fail to faithfully assess generalization in open-world settings. We introduce Pairwise Maximum Discrepancy Competition (PMDC), a dynamic and annotation-efficient framework for evaluating RM generalization using a large, unlabeled, open-domain prompt pool. PMDC actively selects prompt--response pairs that maximize disagreement between two RMs, yielding a compact set of highly contentious test cases. These cases are adjudicated by an oracle, and the resulting outcomes are aggregated via a Bradley--Terry model to produce a global ranking and pairwise win-rate landscape of RMs. We apply PMDC to re-evaluate 10 representative RMs and observe substantial rank reshuffling compared with conventional benchmarks. Qualitative analyses further uncover systematic generalization failures, providing valuable insights for improving reward modeling.",
      "url": "http://arxiv.org/abs/2601.16987",
      "author": "Shunyang Luo, Peibei Cao, Zhihui Zhu, Kehua Feng, Zhihua Wang, Keyan Ding",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces PMDC, dynamic framework for evaluating reward model generalization using maximum disagreement between models to select contentious test cases efficiently without pre-annotation.",
      "importance_score": 67,
      "reasoning": "Novel evaluation methodology for critical alignment component; efficient approach to assessing reward model reliability.",
      "themes": [
        "Reward Models",
        "Alignment",
        "Evaluation Methodology"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces PMDC, dynamic framework for evaluating reward model generalization using maximum disagreement between models to select contentious test cases efficiently without pre-annotation.</p>",
      "content_html": "<p>arXiv:2601.16987v1 Announce Type: cross  Abstract: Reward models (RMs) are central to aligning large language models, yet their practical effectiveness hinges on generalization to unseen prompts and shifting distributions. Most existing RM evaluations rely on static, pre-annotated preference datasets, which provide limited coverage and often fail to faithfully assess generalization in open-world settings. We introduce Pairwise Maximum Discrepancy Competition (PMDC), a dynamic and annotation-efficient framework for evaluating RM generalization using a large, unlabeled, open-domain prompt pool. PMDC actively selects prompt--response pairs that maximize disagreement between two RMs, yielding a compact set of highly contentious test cases. These cases are adjudicated by an oracle, and the resulting outcomes are aggregated via a Bradley--Terry model to produce a global ranking and pairwise win-rate landscape of RMs. We apply PMDC to re-evaluate 10 representative RMs and observe substantial rank reshuffling compared with conventional benchmarks. Qualitative analyses further uncover systematic generalization failures, providing valuable insights for improving reward modeling.</p>"
    },
    {
      "id": "ac00776b74dc",
      "title": "High-Rate Quantized Matrix Multiplication: Theory and Practice",
      "content": "arXiv:2601.17187v1 Announce Type: cross  Abstract: This work investigates the problem of quantized matrix multiplication (MatMul), which has become crucial for the efficient deployment of large language models (LLMs). We consider two settings: 1) Generic MatMul, where both matrices must be quantized (weight+activation quantization); and 2) weight-only quantization, where the second matrix is only known through covariance matrix $\\Sigma_X$ of its columns. For each setting, we first review the fundamental information-theoretic tradeoff between quantization rate and distortion (high-rate theory), and then analyze the performance of several popular quantization schemes, comparing them to these fundamental limits. Specifically, we discuss rate loss (compared to information theoretic optima) of absmax INT and floating-point (FP) quantization, for which we also derive remarkably accurate heuristic approximations. Weight-only quantization is related to the problem of weighted mean squared error (WMSE) source coding, whose classical (reverse) waterfilling solution dictates how one should distribute rate between coordinates of the vector. We show how waterfilling can be used to improve practical LLM quantization algorithms (GPTQ), which at present allocate rate equally. This new scheme (termed ``WaterSIC'') only uses scalar INT quantizers, but its high-rate performance is basis free (it depends only on the determinant of $\\Sigma_X$ and, thus, unlike existing schemes, is immune to applying random rotations) and is within a multiplicative factor of $\\frac{2\\pi e}{12}$ (or 0.25 bit/entry) of the information-theoretic distortion limit (!). GPTQ's performance is affected by the choice of basis, but for a random rotation and actual $\\Sigma_X$ from Llama-3-8B we find GPTQ to be within 0.1 bit (depending on the layer type) of WaterSIC, suggesting that GPTQ with random rotation is also near optimal (for high-rate quantization).",
      "url": "http://arxiv.org/abs/2601.17187",
      "author": "Or Ordentlich, Yury Polyanskiy",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.IT"
      ],
      "summary": "Investigates quantized matrix multiplication theory for LLM deployment, analyzing fundamental rate-distortion tradeoffs and comparing popular quantization schemes to information-theoretic limits.",
      "importance_score": 67,
      "reasoning": "Important theoretical contribution to LLM quantization. Bridges theory and practice for efficient deployment.",
      "themes": [
        "Quantization",
        "LLM Efficiency",
        "Information Theory"
      ],
      "continuation": null,
      "summary_html": "<p>Investigates quantized matrix multiplication theory for LLM deployment, analyzing fundamental rate-distortion tradeoffs and comparing popular quantization schemes to information-theoretic limits.</p>",
      "content_html": "<p>arXiv:2601.17187v1 Announce Type: cross  Abstract: This work investigates the problem of quantized matrix multiplication (MatMul), which has become crucial for the efficient deployment of large language models (LLMs). We consider two settings: 1) Generic MatMul, where both matrices must be quantized (weight+activation quantization); and 2) weight-only quantization, where the second matrix is only known through covariance matrix $\\Sigma_X$ of its columns. For each setting, we first review the fundamental information-theoretic tradeoff between quantization rate and distortion (high-rate theory), and then analyze the performance of several popular quantization schemes, comparing them to these fundamental limits. Specifically, we discuss rate loss (compared to information theoretic optima) of absmax INT and floating-point (FP) quantization, for which we also derive remarkably accurate heuristic approximations. Weight-only quantization is related to the problem of weighted mean squared error (WMSE) source coding, whose classical (reverse) waterfilling solution dictates how one should distribute rate between coordinates of the vector. We show how waterfilling can be used to improve practical LLM quantization algorithms (GPTQ), which at present allocate rate equally. This new scheme (termed ``WaterSIC'') only uses scalar INT quantizers, but its high-rate performance is basis free (it depends only on the determinant of $\\Sigma_X$ and, thus, unlike existing schemes, is immune to applying random rotations) and is within a multiplicative factor of $\\frac{2\\pi e}{12}$ (or 0.25 bit/entry) of the information-theoretic distortion limit (!). GPTQ's performance is affected by the choice of basis, but for a random rotation and actual $\\Sigma_X$ from Llama-3-8B we find GPTQ to be within 0.1 bit (depending on the layer type) of WaterSIC, suggesting that GPTQ with random rotation is also near optimal (for high-rate quantization).</p>"
    },
    {
      "id": "ae36096e18f5",
      "title": "VidLaDA: Bidirectional Diffusion Large Language Models for Efficient Video Understanding",
      "content": "arXiv:2601.17868v1 Announce Type: cross  Abstract: Standard Autoregressive Video LLMs inevitably suffer from causal masking biases that hinder global spatiotemporal modeling, leading to suboptimal understanding efficiency. We propose VidLaDA, a Video LLM based on Diffusion Language Model utilizing bidirectional attention to capture bidirectional dependencies. To further tackle the inference bottleneck of diffusion decoding on massive video tokens, we introduce MARS-Cache. This framework accelerates inference by combining asynchronous visual cache refreshing with frame-wise chunk attention, effectively pruning redundancy while preserving global connectivity via anchor tokens. Extensive experiments show VidLaDA outperforms diffusion baselines and rivals state-of-the-art autoregressive models (e.g., Qwen2.5-VL and LLaVA-Video), with MARS-Cache delivering over 12x speedup without compromising reasoning accuracy. Code and checkpoints are open-sourced at https://github.com/ziHoHe/VidLaDA.",
      "url": "http://arxiv.org/abs/2601.17868",
      "author": "Zhihao He, Tieyuan Chen, Kangyu Wang, Ziran Qin, Yang Shao, Chaofan Gan, Shijie Li, Zuxuan Wu, Weiyao Lin",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "VidLaDA applies diffusion language models with bidirectional attention for video understanding, introducing MARS-Cache for efficient inference on massive video tokens.",
      "importance_score": 67,
      "reasoning": "Novel application of diffusion LMs to video. Addresses causal masking bias in standard approaches. MARS-Cache is practical contribution.",
      "themes": [
        "Video Understanding",
        "Diffusion Language Models",
        "Multimodal AI"
      ],
      "continuation": null,
      "summary_html": "<p>VidLaDA applies diffusion language models with bidirectional attention for video understanding, introducing MARS-Cache for efficient inference on massive video tokens.</p>",
      "content_html": "<p>arXiv:2601.17868v1 Announce Type: cross  Abstract: Standard Autoregressive Video LLMs inevitably suffer from causal masking biases that hinder global spatiotemporal modeling, leading to suboptimal understanding efficiency. We propose VidLaDA, a Video LLM based on Diffusion Language Model utilizing bidirectional attention to capture bidirectional dependencies. To further tackle the inference bottleneck of diffusion decoding on massive video tokens, we introduce MARS-Cache. This framework accelerates inference by combining asynchronous visual cache refreshing with frame-wise chunk attention, effectively pruning redundancy while preserving global connectivity via anchor tokens. Extensive experiments show VidLaDA outperforms diffusion baselines and rivals state-of-the-art autoregressive models (e.g., Qwen2.5-VL and LLaVA-Video), with MARS-Cache delivering over 12x speedup without compromising reasoning accuracy. Code and checkpoints are open-sourced at https://github.com/ziHoHe/VidLaDA.</p>"
    },
    {
      "id": "e998364b8600",
      "title": "PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR",
      "content": "arXiv:2601.18207v1 Announce Type: cross  Abstract: Search agents are language models (LMs) that reason and search knowledge bases (or the web) to answer questions; recent methods supervise only the final answer accuracy using reinforcement learning with verifiable rewards (RLVR). Most RLVR search agents tackle general-domain QA, which limits their relevance to technical AI systems in science, engineering, and medicine. In this work we propose training agents to search and reason over scientific papers -- this tests technical question-answering, it is directly relevant to real scientists, and the capabilities will be crucial to future AI Scientist systems. Concretely, we release a search corpus of 16 million biomedical paper abstracts and construct a challenging factoid QA dataset called PaperSearchQA with 60k samples answerable from the corpus, along with benchmarks. We train search agents in this environment to outperform non-RL retrieval baselines; we also perform further quantitative analysis and observe interesting agent behaviors like planning, reasoning, and self-verification. Our corpus, datasets, and benchmarks are usable with the popular Search-R1 codebase for RLVR training and released on https://huggingface.co/collections/jmhb/papersearchqa. Finally, our data creation methods are scalable and easily extendable to other scientific domains.",
      "url": "http://arxiv.org/abs/2601.18207",
      "author": "James Burgess, Jan N. Hansen, Duo Peng, Yuhui Zhang, Alejandro Lozano, Min Woo Sun, Emma Lundberg, Serena Yeung-Levy",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces RLVR-trained search agents for scientific paper retrieval over 16 million biomedical abstracts. Creates PaperSearchQA benchmark for factoid QA requiring multi-step reasoning over scientific literature.",
      "importance_score": 67,
      "reasoning": "Highly relevant for AI research tools. Large-scale corpus and challenging benchmark. Addresses important capability for AI scientist systems.",
      "themes": [
        "Scientific Search",
        "RLVR",
        "Retrieval Agents",
        "Biomedical AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces RLVR-trained search agents for scientific paper retrieval over 16 million biomedical abstracts. Creates PaperSearchQA benchmark for factoid QA requiring multi-step reasoning over scientific literature.</p>",
      "content_html": "<p>arXiv:2601.18207v1 Announce Type: cross  Abstract: Search agents are language models (LMs) that reason and search knowledge bases (or the web) to answer questions; recent methods supervise only the final answer accuracy using reinforcement learning with verifiable rewards (RLVR). Most RLVR search agents tackle general-domain QA, which limits their relevance to technical AI systems in science, engineering, and medicine. In this work we propose training agents to search and reason over scientific papers -- this tests technical question-answering, it is directly relevant to real scientists, and the capabilities will be crucial to future AI Scientist systems. Concretely, we release a search corpus of 16 million biomedical paper abstracts and construct a challenging factoid QA dataset called PaperSearchQA with 60k samples answerable from the corpus, along with benchmarks. We train search agents in this environment to outperform non-RL retrieval baselines; we also perform further quantitative analysis and observe interesting agent behaviors like planning, reasoning, and self-verification. Our corpus, datasets, and benchmarks are usable with the popular Search-R1 codebase for RLVR training and released on https://huggingface.co/collections/jmhb/papersearchqa. Finally, our data creation methods are scalable and easily extendable to other scientific domains.</p>"
    },
    {
      "id": "d71b3eb399d3",
      "title": "CaseFacts: A Benchmark for Legal Fact-Checking and Precedent Retrieval",
      "content": "arXiv:2601.17230v1 Announce Type: new  Abstract: Automated Fact-Checking has largely focused on verifying general knowledge against static corpora, overlooking high-stakes domains like law where truth is evolving and technically complex. We introduce CaseFacts, a benchmark for verifying colloquial legal claims against U.S. Supreme Court precedents. Unlike existing resources that map formal texts to formal texts, CaseFacts challenges systems to bridge the semantic gap between layperson assertions and technical jurisprudence while accounting for temporal validity. The dataset consists of 6,294 claims categorized as Supported, Refuted, or Overruled. We construct this benchmark using a multi-stage pipeline that leverages Large Language Models (LLMs) to synthesize claims from expert case summaries, employing a novel semantic similarity heuristic to efficiently identify and verify complex legal overrulings. Experiments with state-of-the-art LLMs reveal that the task remains challenging; notably, augmenting models with unrestricted web search degrades performance compared to closed-book baselines due to the retrieval of noisy, non-authoritative precedents. We release CaseFacts to spur research into legal fact verification systems.",
      "url": "http://arxiv.org/abs/2601.17230",
      "author": "Akshith Reddy Putta, Jacob Devasier, Chengkai Li",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces CaseFacts benchmark for verifying colloquial legal claims against U.S. Supreme Court precedents, with 6,294 claims categorized as Supported, Refuted, or Overruled. Addresses temporal validity of legal facts.",
      "importance_score": 67,
      "reasoning": "Important domain-specific benchmark bridging layperson language and legal jurisprudence. Novel focus on temporal validity in legal reasoning.",
      "themes": [
        "Legal NLP",
        "Fact-Checking",
        "Benchmark"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces CaseFacts benchmark for verifying colloquial legal claims against U.S. Supreme Court precedents, with 6,294 claims categorized as Supported, Refuted, or Overruled. Addresses temporal validity of legal facts.</p>",
      "content_html": "<p>arXiv:2601.17230v1 Announce Type: new  Abstract: Automated Fact-Checking has largely focused on verifying general knowledge against static corpora, overlooking high-stakes domains like law where truth is evolving and technically complex. We introduce CaseFacts, a benchmark for verifying colloquial legal claims against U.S. Supreme Court precedents. Unlike existing resources that map formal texts to formal texts, CaseFacts challenges systems to bridge the semantic gap between layperson assertions and technical jurisprudence while accounting for temporal validity. The dataset consists of 6,294 claims categorized as Supported, Refuted, or Overruled. We construct this benchmark using a multi-stage pipeline that leverages Large Language Models (LLMs) to synthesize claims from expert case summaries, employing a novel semantic similarity heuristic to efficiently identify and verify complex legal overrulings. Experiments with state-of-the-art LLMs reveal that the task remains challenging; notably, augmenting models with unrestricted web search degrades performance compared to closed-book baselines due to the retrieval of noisy, non-authoritative precedents. We release CaseFacts to spur research into legal fact verification systems.</p>"
    },
    {
      "id": "d28c605a8f70",
      "title": "Controlling Reading Ease with Gaze-Guided Text Generation",
      "content": "arXiv:2601.17781v1 Announce Type: new  Abstract: The way our eyes move while reading can tell us about the cognitive effort required to process the text. In the present study, we use this fact to generate texts with controllable reading ease. Our method employs a model that predicts human gaze patterns to steer language model outputs towards eliciting certain reading behaviors. We evaluate the approach in an eye-tracking experiment with native and non-native speakers of English. The results demonstrate that the method is effective at making the generated texts easier or harder to read, measured both in terms of reading times and perceived difficulty of the texts. A statistical analysis reveals that the changes in reading behavior are mostly due to features that affect lexical processing. Possible applications of our approach include text simplification for information accessibility and generation of personalized educational material for language learning.",
      "url": "http://arxiv.org/abs/2601.17781",
      "author": "Andreas S\\\"auberli, Darja Jepifanova, Diego Frassinelli, Barbara Plank",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Uses gaze prediction models to steer language model outputs toward desired reading behaviors. Eye-tracking experiments with native and non-native speakers validate effectiveness at controlling reading ease.",
      "importance_score": 67,
      "reasoning": "Novel human-centered approach to controllable generation with strong experimental validation including eye-tracking study.",
      "themes": [
        "Controllable Generation",
        "Human-AI Interaction",
        "Cognitive Science"
      ],
      "continuation": null,
      "summary_html": "<p>Uses gaze prediction models to steer language model outputs toward desired reading behaviors. Eye-tracking experiments with native and non-native speakers validate effectiveness at controlling reading ease.</p>",
      "content_html": "<p>arXiv:2601.17781v1 Announce Type: new  Abstract: The way our eyes move while reading can tell us about the cognitive effort required to process the text. In the present study, we use this fact to generate texts with controllable reading ease. Our method employs a model that predicts human gaze patterns to steer language model outputs towards eliciting certain reading behaviors. We evaluate the approach in an eye-tracking experiment with native and non-native speakers of English. The results demonstrate that the method is effective at making the generated texts easier or harder to read, measured both in terms of reading times and perceived difficulty of the texts. A statistical analysis reveals that the changes in reading behavior are mostly due to features that affect lexical processing. Possible applications of our approach include text simplification for information accessibility and generation of personalized educational material for language learning.</p>"
    },
    {
      "id": "490eb1cf40fb",
      "title": "Exploring Fine-Tuning for In-Context Retrieval and Efficient KV-Caching in Long-Context Language Models",
      "content": "arXiv:2601.18527v1 Announce Type: new  Abstract: With context windows of millions of tokens, Long-Context Language Models (LCLMs) can encode entire document collections, offering a strong alternative to conventional retrieval-augmented generation (RAG). However, it remains unclear whether fine-tuning strategies can improve long-context performance and translate to greater robustness under KV-cache compression techniques. In this work, we investigate which training strategies most effectively enhance LCLMs' ability to identify and use relevant information, as well as enhancing their robustness under KV-cache compression. Our experiments show substantial in-domain improvements, achieving gains of up to +20 points over the base model. However, out-of-domain generalization remains task dependent with large variance -- LCLMs excels on finance questions (+9 points), while RAG shows stronger performance on multiple-choice questions (+6 points) over the baseline models. Finally, we show that our fine-tuning approaches bring moderate improvements in robustness under KV-cache compression, with gains varying across tasks.",
      "url": "http://arxiv.org/abs/2601.18527",
      "author": "Francesco Maria Molfese, Momchil Hardalov, Rexhina Blloshmi, Bill Byrne, Adri\\`a de Gispert",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Investigates training strategies for long-context LLMs and their robustness under KV-cache compression. Finds +20 point in-domain gains but limited out-of-domain generalization.",
      "importance_score": 67,
      "reasoning": "Practical research on long-context efficiency with important findings about generalization limitations. Useful for deployment.",
      "themes": [
        "Long Context",
        "KV Cache",
        "Fine-Tuning",
        "Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>Investigates training strategies for long-context LLMs and their robustness under KV-cache compression. Finds +20 point in-domain gains but limited out-of-domain generalization.</p>",
      "content_html": "<p>arXiv:2601.18527v1 Announce Type: new  Abstract: With context windows of millions of tokens, Long-Context Language Models (LCLMs) can encode entire document collections, offering a strong alternative to conventional retrieval-augmented generation (RAG). However, it remains unclear whether fine-tuning strategies can improve long-context performance and translate to greater robustness under KV-cache compression techniques. In this work, we investigate which training strategies most effectively enhance LCLMs' ability to identify and use relevant information, as well as enhancing their robustness under KV-cache compression. Our experiments show substantial in-domain improvements, achieving gains of up to +20 points over the base model. However, out-of-domain generalization remains task dependent with large variance -- LCLMs excels on finance questions (+9 points), while RAG shows stronger performance on multiple-choice questions (+6 points) over the baseline models. Finally, we show that our fine-tuning approaches bring moderate improvements in robustness under KV-cache compression, with gains varying across tasks.</p>"
    },
    {
      "id": "dd76978ed432",
      "title": "Falsifying Predictive Algorithm",
      "content": "arXiv:2601.17146v1 Announce Type: cross  Abstract: Empirical investigations into unintended model behavior often show that the algorithm is predicting another outcome than what was intended. These exposes highlight the need to identify when algorithms predict unintended quantities - ideally before deploying them into consequential settings. We propose a falsification framework that provides a principled statistical test for discriminant validity: the requirement that an algorithm predict intended outcomes better than impermissible ones. Drawing on falsification practices from causal inference, econometrics, and psychometrics, our framework compares calibrated prediction losses across outcomes to assess whether the algorithm exhibits discriminant validity with respect to a specified impermissible proxy. In settings where the target outcome is difficult to observe, multiple permissible proxy outcomes may be available; our framework accommodates both this setting and the case with a single permissible proxy. Throughout we use nonparametric hypothesis testing methods that make minimal assumptions on the data-generating process. We illustrate the method in an admissions setting, where the framework establishes discriminant validity with respect to gender but fails to establish discriminant validity with respect to race. This demonstrates how falsification can serve as an early validity check, prior to fairness or robustness analyses. We also provide analysis in a criminal justice setting, where we highlight the limitations of our framework and emphasize the need for complementary approaches to assess other aspects of construct validity and external validity.",
      "url": "http://arxiv.org/abs/2601.17146",
      "author": "Amanda Coston",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "stat.ME"
      ],
      "summary": "Proposes falsification framework providing statistical test for discriminant validity in ML algorithms, detecting when algorithms predict unintended outcomes.",
      "importance_score": 67,
      "reasoning": "Important contribution to ML safety and fairness, provides principled approach to detecting problematic predictions before deployment.",
      "themes": [
        "ML Fairness",
        "Algorithm Auditing",
        "Discriminant Validity",
        "AI Safety"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes falsification framework providing statistical test for discriminant validity in ML algorithms, detecting when algorithms predict unintended outcomes.</p>",
      "content_html": "<p>arXiv:2601.17146v1 Announce Type: cross  Abstract: Empirical investigations into unintended model behavior often show that the algorithm is predicting another outcome than what was intended. These exposes highlight the need to identify when algorithms predict unintended quantities - ideally before deploying them into consequential settings. We propose a falsification framework that provides a principled statistical test for discriminant validity: the requirement that an algorithm predict intended outcomes better than impermissible ones. Drawing on falsification practices from causal inference, econometrics, and psychometrics, our framework compares calibrated prediction losses across outcomes to assess whether the algorithm exhibits discriminant validity with respect to a specified impermissible proxy. In settings where the target outcome is difficult to observe, multiple permissible proxy outcomes may be available; our framework accommodates both this setting and the case with a single permissible proxy. Throughout we use nonparametric hypothesis testing methods that make minimal assumptions on the data-generating process. We illustrate the method in an admissions setting, where the framework establishes discriminant validity with respect to gender but fails to establish discriminant validity with respect to race. This demonstrates how falsification can serve as an early validity check, prior to fairness or robustness analyses. We also provide analysis in a criminal justice setting, where we highlight the limitations of our framework and emphasize the need for complementary approaches to assess other aspects of construct validity and external validity.</p>"
    },
    {
      "id": "9ba37dd213ab",
      "title": "Aligning Medical Conversational AI through Online Reinforcement Learning with Information-Theoretic Rewards",
      "content": "arXiv:2601.17828v1 Announce Type: new  Abstract: We present Information Gain Fine-Tuning (IGFT), a novel approach for training medical conversational AI to conduct effective patient interviews and generate comprehensive History of Present Illness (HPI) without requiring pre-collected human conversations. IGFT combines online Group Relative Policy Optimization (GRPO) with information-theoretic rewards, enabling models to learn from self-generated conversations with simulated patients. Unlike existing approaches that rely on expensive expert-annotated conversations or static datasets, our online RL framework allows models to discover effective questioning strategies through exploration. Our key innovation is an information gain reward function that tracks which clinical entities such as symptoms, temporal patterns, and medical history, are revealed during conversation. Each question's reward is computed based on its expected information gain combined with GPT-4o-mini quality assessments across dimensions including clinical relevance, patient engagement, and specificity. This hybrid approach ensures models learn to ask targeted, clinically appropriate questions that efficiently gather diagnostic information. We fine-tune two models using LoRA: Llama-3.1-8B-Instruct and DeepSeek-R1-Distill-Qwen-7B (a reasoning-optimized model). Training exclusively on Avey data containing concise HPIs, we evaluate generalization to MIMIC data with longer, more elaborate HPIs. DeepSeek-R1-Distill-Qwen-7B (IGFT) achieves F1 scores of 0.408 on Avey (10.9% improvement over base) and 0.289 on MIMIC (12.9% improvement), while Llama-3.1-8B-Instruct (IGFT) reaches 0.384 and 0.336 respectively. Both models outperform OpenAI's model on MIMIC and surpass medical domain-specific baselines like HuatuoGPT and UltraMedical, which were optimized for single-turn medical QA rather than multi-turn conversations.",
      "url": "http://arxiv.org/abs/2601.17828",
      "author": "Tanvi Verma, Yang Zhou, Rick Siow Mong Goh, Yong Liu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Presents IGFT for training medical conversational AI using online GRPO with information-theoretic rewards, enabling models to learn questioning strategies through self-generated conversations.",
      "importance_score": 66,
      "reasoning": "Novel training approach for medical dialogue without expert annotations; information gain reward is principled and practical.",
      "themes": [
        "Healthcare AI",
        "Reinforcement Learning",
        "Conversational AI"
      ],
      "continuation": null,
      "summary_html": "<p>Presents IGFT for training medical conversational AI using online GRPO with information-theoretic rewards, enabling models to learn questioning strategies through self-generated conversations.</p>",
      "content_html": "<p>arXiv:2601.17828v1 Announce Type: new  Abstract: We present Information Gain Fine-Tuning (IGFT), a novel approach for training medical conversational AI to conduct effective patient interviews and generate comprehensive History of Present Illness (HPI) without requiring pre-collected human conversations. IGFT combines online Group Relative Policy Optimization (GRPO) with information-theoretic rewards, enabling models to learn from self-generated conversations with simulated patients. Unlike existing approaches that rely on expensive expert-annotated conversations or static datasets, our online RL framework allows models to discover effective questioning strategies through exploration. Our key innovation is an information gain reward function that tracks which clinical entities such as symptoms, temporal patterns, and medical history, are revealed during conversation. Each question's reward is computed based on its expected information gain combined with GPT-4o-mini quality assessments across dimensions including clinical relevance, patient engagement, and specificity. This hybrid approach ensures models learn to ask targeted, clinically appropriate questions that efficiently gather diagnostic information. We fine-tune two models using LoRA: Llama-3.1-8B-Instruct and DeepSeek-R1-Distill-Qwen-7B (a reasoning-optimized model). Training exclusively on Avey data containing concise HPIs, we evaluate generalization to MIMIC data with longer, more elaborate HPIs. DeepSeek-R1-Distill-Qwen-7B (IGFT) achieves F1 scores of 0.408 on Avey (10.9% improvement over base) and 0.289 on MIMIC (12.9% improvement), while Llama-3.1-8B-Instruct (IGFT) reaches 0.384 and 0.336 respectively. Both models outperform OpenAI's model on MIMIC and surpass medical domain-specific baselines like HuatuoGPT and UltraMedical, which were optimized for single-turn medical QA rather than multi-turn conversations.</p>"
    },
    {
      "id": "7fcae7367c2c",
      "title": "SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback",
      "content": "arXiv:2601.18202v1 Announce Type: new  Abstract: Deep search agents, which aim to answer complex questions requiring reasoning across multiple documents, can significantly speed up the information-seeking process. Collecting human annotations for this application is prohibitively expensive due to long and complex exploration trajectories. We propose an agentic pipeline that automatically generates high quality, difficulty-controlled deep search question-answer pairs for a given corpus and a target difficulty level. Our pipeline, SAGE, consists of a data generator which proposes QA pairs and a search agent which attempts to solve the generated question and provide execution feedback for the data generator. The two components interact over multiple rounds to iteratively refine the question-answer pairs until they satisfy the target difficulty level. Our intrinsic evaluation shows SAGE generates questions that require diverse reasoning strategies, while significantly increases the correctness and difficulty of the generated data. Our extrinsic evaluation demonstrates up to 23% relative performance gain on popular deep search benchmarks by training deep search agents with our synthetic data. Additional experiments show that agents trained on our data can adapt from fixed-corpus retrieval to Google Search at inference time, without further training.",
      "url": "http://arxiv.org/abs/2601.18202",
      "author": "Fangyuan Xu, Rujun Han, Yanfei Chen, Zifeng Wang, I-Hung Hsu, Jun Yan, Vishy Tirumalashetty, Eunsol Choi, Tomas Pfister, Chen-Yu Lee",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces SAGE, an agentic pipeline for generating difficulty-controlled deep search QA pairs through interaction between data generator and search agent with execution feedback.",
      "importance_score": 66,
      "reasoning": "Useful data generation approach for training deep search agents; principled difficulty control through agent interaction.",
      "themes": [
        "Data Synthesis",
        "Deep Search",
        "Agentic AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces SAGE, an agentic pipeline for generating difficulty-controlled deep search QA pairs through interaction between data generator and search agent with execution feedback.</p>",
      "content_html": "<p>arXiv:2601.18202v1 Announce Type: new  Abstract: Deep search agents, which aim to answer complex questions requiring reasoning across multiple documents, can significantly speed up the information-seeking process. Collecting human annotations for this application is prohibitively expensive due to long and complex exploration trajectories. We propose an agentic pipeline that automatically generates high quality, difficulty-controlled deep search question-answer pairs for a given corpus and a target difficulty level. Our pipeline, SAGE, consists of a data generator which proposes QA pairs and a search agent which attempts to solve the generated question and provide execution feedback for the data generator. The two components interact over multiple rounds to iteratively refine the question-answer pairs until they satisfy the target difficulty level. Our intrinsic evaluation shows SAGE generates questions that require diverse reasoning strategies, while significantly increases the correctness and difficulty of the generated data. Our extrinsic evaluation demonstrates up to 23% relative performance gain on popular deep search benchmarks by training deep search agents with our synthetic data. Additional experiments show that agents trained on our data can adapt from fixed-corpus retrieval to Google Search at inference time, without further training.</p>"
    },
    {
      "id": "075827194b74",
      "title": "Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs",
      "content": "arXiv:2601.18588v1 Announce Type: new  Abstract: Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality.",
      "url": "http://arxiv.org/abs/2601.18588",
      "author": "Xianzhe Meng, Qiangsheng Zeng, Ling Luo, Qinghan Yang, Jiarui Hao, Wenbo Wu, Qinyu Wang, Rui Yin, Lin Qi, Renzhi Lu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Shows that stable training dynamics under MLE lead to forward KL minimization reducing generative entropy, causing concentration on limited modes and systematic degeneration despite smooth loss convergence.",
      "importance_score": 66,
      "reasoning": "Interesting theoretical finding about training stability implications; explains observed generation collapse phenomena.",
      "themes": [
        "Training Dynamics",
        "Theoretical AI",
        "Generation Quality"
      ],
      "continuation": null,
      "summary_html": "<p>Shows that stable training dynamics under MLE lead to forward KL minimization reducing generative entropy, causing concentration on limited modes and systematic degeneration despite smooth loss convergence.</p>",
      "content_html": "<p>arXiv:2601.18588v1 Announce Type: new  Abstract: Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality.</p>"
    },
    {
      "id": "f4419ab092e0",
      "title": "TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models",
      "content": "arXiv:2601.18744v1 Announce Type: new  Abstract: Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.",
      "url": "http://arxiv.org/abs/2601.18744",
      "author": "Fangxu Yu, Xingang Guo, Lingzhi Yuan, Haoqiang Kang, Hongyu Zhao, Lianhui Qin, Furong Huang, Bin Hu, Tianyi Zhou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces TSRBench, comprehensive benchmark of 4,125 time series problems across 14 domains testing perception, reasoning, prediction, and decision-making in 15 tasks.",
      "importance_score": 66,
      "reasoning": "Large-scale benchmark filling gap in time series reasoning evaluation; comprehensive multi-task coverage.",
      "themes": [
        "Time Series",
        "Benchmarks",
        "Reasoning"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces TSRBench, comprehensive benchmark of 4,125 time series problems across 14 domains testing perception, reasoning, prediction, and decision-making in 15 tasks.</p>",
      "content_html": "<p>arXiv:2601.18744v1 Announce Type: new  Abstract: Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.</p>"
    },
    {
      "id": "91282d06e582",
      "title": "FlashMoE: Reducing SSD I/O Bottlenecks via ML-Based Cache Replacement for Mixture-of-Experts Inference on Edge Devices",
      "content": "arXiv:2601.17063v1 Announce Type: cross  Abstract: Recently, Mixture-of-Experts (MoE) models have gained attention for efficiently scaling large language models. Although these models are extremely large, their sparse activation enables inference to be performed by accessing only a fraction of the model at a time. This property opens the possibility of on-device inference of MoE, which was previously considered infeasible for such large models. Consequently, various systems have been proposed to leverage this sparsity and enable efficient MoE inference for edge devices. However, previous MoE inference systems like Fiddler[8] or DAOP[13] rely on DRAM-based offloading and are not suitable for memory constrained on-device environments. As recent MoE models grow to hundreds of gigabytes, RAM-offloading solutions become impractical. To address this, we propose FlashMoE, a system that offloads inactive experts to SSD, enabling efficient MoE inference under limited RAM. FlashMoE incorporates a lightweight ML-based caching strategy that adaptively combines recency and frequency signals to maximize expert reuse, significantly reducing storage I/O. In addition, we built a user-grade desktop platform to demonstrate the practicality of FlashMoE. On this real hardware setup, FlashMoE improves cache hit rate by up to 51% over well-known offloading policies such as LRU and LFU, and achieves up to 2.6x speedup compared to existing MoE inference systems.",
      "url": "http://arxiv.org/abs/2601.17063",
      "author": "Byeongju Kim, Jungwan Lee, Donghyeon Han, Hoi-Jun Yoo, Sangyeob Kim",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces FlashMoE, an ML-based cache replacement strategy for SSD-based MoE inference on edge devices. Addresses memory constraints for running large MoE models on-device.",
      "importance_score": 66,
      "reasoning": "Addresses critical bottleneck for deploying large MoE models on edge devices. Practical contribution to efficient LLM deployment.",
      "themes": [
        "MoE Models",
        "Edge Deployment",
        "Efficient Inference"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces FlashMoE, an ML-based cache replacement strategy for SSD-based MoE inference on edge devices. Addresses memory constraints for running large MoE models on-device.</p>",
      "content_html": "<p>arXiv:2601.17063v1 Announce Type: cross  Abstract: Recently, Mixture-of-Experts (MoE) models have gained attention for efficiently scaling large language models. Although these models are extremely large, their sparse activation enables inference to be performed by accessing only a fraction of the model at a time. This property opens the possibility of on-device inference of MoE, which was previously considered infeasible for such large models. Consequently, various systems have been proposed to leverage this sparsity and enable efficient MoE inference for edge devices. However, previous MoE inference systems like Fiddler[8] or DAOP[13] rely on DRAM-based offloading and are not suitable for memory constrained on-device environments. As recent MoE models grow to hundreds of gigabytes, RAM-offloading solutions become impractical. To address this, we propose FlashMoE, a system that offloads inactive experts to SSD, enabling efficient MoE inference under limited RAM. FlashMoE incorporates a lightweight ML-based caching strategy that adaptively combines recency and frequency signals to maximize expert reuse, significantly reducing storage I/O. In addition, we built a user-grade desktop platform to demonstrate the practicality of FlashMoE. On this real hardware setup, FlashMoE improves cache hit rate by up to 51% over well-known offloading policies such as LRU and LFU, and achieves up to 2.6x speedup compared to existing MoE inference systems.</p>"
    },
    {
      "id": "60adb1e68bc3",
      "title": "Mind the Ambiguity: Aleatoric Uncertainty Quantification in LLMs for Safe Medical Question Answering",
      "content": "arXiv:2601.17284v1 Announce Type: cross  Abstract: The deployment of Large Language Models in Medical Question Answering is severely hampered by ambiguous user queries, a significant safety risk that demonstrably reduces answer accuracy in high-stakes healthcare settings. In this paper, we formalize this challenge by linking input ambiguity to aleatoric uncertainty (AU), which is the irreducible uncertainty arising from underspecified input. To facilitate research in this direction, we construct CV-MedBench, the first benchmark designed for studying input ambiguity in Medical QA. Using this benchmark, we analyze AU from a representation engineering perspective, revealing that AU is linearly encoded in LLM's internal activation patterns. Leveraging this insight, we introduce a novel AU-guided \"Clarify-Before-Answer\" framework, which incorporates AU-Probe - a lightweight module that detects input ambiguity directly from hidden states. Unlike existing uncertainty estimation methods, AU-Probe requires neither LLM fine-tuning nor multiple forward passes, enabling an efficient mechanism to proactively request user clarification and significantly enhance safety. Extensive experiments across four open LLMs demonstrate the effectiveness of our QA framework, with an average accuracy improvement of 9.48% over baselines. Our framework provides an efficient and robust solution for safe Medical QA, strengthening the reliability of health-related applications. The code is available at https://github.com/yaokunliu/AU-Med.git, and the CV-MedBench dataset is released on Hugging Face at https://huggingface.co/datasets/yaokunl/CV-MedBench.",
      "url": "http://arxiv.org/abs/2601.17284",
      "author": "Yaokun Liu, Yifan Liu, Phoebe Mbuvi, Zelin Li, Ruichen Yao, Gawon Lim, Dong Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes CV-MedBench for studying input ambiguity in medical QA, linking ambiguity to aleatoric uncertainty. Introduces AU-guided abstention using linearly encoded uncertainty in LLM activations.",
      "importance_score": 66,
      "reasoning": "Important contribution to safe medical AI addressing underspecified inputs. Novel benchmark and uncertainty quantification approach.",
      "themes": [
        "Medical AI",
        "Uncertainty Quantification",
        "AI Safety"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes CV-MedBench for studying input ambiguity in medical QA, linking ambiguity to aleatoric uncertainty. Introduces AU-guided abstention using linearly encoded uncertainty in LLM activations.</p>",
      "content_html": "<p>arXiv:2601.17284v1 Announce Type: cross  Abstract: The deployment of Large Language Models in Medical Question Answering is severely hampered by ambiguous user queries, a significant safety risk that demonstrably reduces answer accuracy in high-stakes healthcare settings. In this paper, we formalize this challenge by linking input ambiguity to aleatoric uncertainty (AU), which is the irreducible uncertainty arising from underspecified input. To facilitate research in this direction, we construct CV-MedBench, the first benchmark designed for studying input ambiguity in Medical QA. Using this benchmark, we analyze AU from a representation engineering perspective, revealing that AU is linearly encoded in LLM's internal activation patterns. Leveraging this insight, we introduce a novel AU-guided \"Clarify-Before-Answer\" framework, which incorporates AU-Probe - a lightweight module that detects input ambiguity directly from hidden states. Unlike existing uncertainty estimation methods, AU-Probe requires neither LLM fine-tuning nor multiple forward passes, enabling an efficient mechanism to proactively request user clarification and significantly enhance safety. Extensive experiments across four open LLMs demonstrate the effectiveness of our QA framework, with an average accuracy improvement of 9.48% over baselines. Our framework provides an efficient and robust solution for safe Medical QA, strengthening the reliability of health-related applications. The code is available at https://github.com/yaokunliu/AU-Med.git, and the CV-MedBench dataset is released on Hugging Face at https://huggingface.co/datasets/yaokunl/CV-MedBench.</p>"
    },
    {
      "id": "16fd0c214256",
      "title": "SD-E$^2$: Semantic Exploration for Reasoning Under Token Budgets",
      "content": "arXiv:2601.17982v1 Announce Type: cross  Abstract: Small language models (SLMs) struggle with complex reasoning because exploration is expensive under tight compute budgets. We introduce Semantic Diversity-Exploration-Exploitation (SD-E$^2$), a reinforcement learning framework that makes exploration explicit by optimizing semantic diversity in generated reasoning trajectories. Using a frozen sentence-embedding model, SD-E$^2$ assigns a diversity reward that captures (i) the coverage of semantically distinct solution strategies and (ii) their average pairwise dissimilarity in embedding space, rather than surface-form novelty. This diversity reward is combined with outcome correctness and solution efficiency in a z-score-normalized multi-objective objective that stabilizes training. On GSM8K, SD-E$^2$ surpasses the base Qwen2.5-3B-Instruct and strong GRPO baselines (GRPO-CFL and GRPO-CFEE) by +27.4, +5.2, and +1.5 percentage points, respectively, while discovering on average 9.8 semantically distinct strategies per question. We further improve MedMCQA to 49.64% versus 38.37% for the base model and show gains on the harder AIME benchmark (1983-2025), reaching 13.28% versus 6.74% for the base. These results indicate that rewarding semantic novelty yields a more compute-efficient exploration-exploitation signal for training reasoning-capable SLMs. By introducing cognitive adaptation-adjusting the reasoning process structure rather than per-token computation-SD-E$^2$ offers a complementary path to efficiency gains in resource-constrained models.",
      "url": "http://arxiv.org/abs/2601.17982",
      "author": "Kshitij Mishra, Nils Lukas, Salem Lahlou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "SD-E uses semantic diversity rewards in RL to improve small language model reasoning by exploring diverse solution strategies rather than surface-form novelty.",
      "importance_score": 66,
      "reasoning": "Addresses exploration efficiency in small models. Semantic diversity is principled approach. Relevant for resource-constrained reasoning.",
      "themes": [
        "Small Language Models",
        "Reasoning",
        "Reinforcement Learning"
      ],
      "continuation": null,
      "summary_html": "<p>SD-E uses semantic diversity rewards in RL to improve small language model reasoning by exploring diverse solution strategies rather than surface-form novelty.</p>",
      "content_html": "<p>arXiv:2601.17982v1 Announce Type: cross  Abstract: Small language models (SLMs) struggle with complex reasoning because exploration is expensive under tight compute budgets. We introduce Semantic Diversity-Exploration-Exploitation (SD-E$^2$), a reinforcement learning framework that makes exploration explicit by optimizing semantic diversity in generated reasoning trajectories. Using a frozen sentence-embedding model, SD-E$^2$ assigns a diversity reward that captures (i) the coverage of semantically distinct solution strategies and (ii) their average pairwise dissimilarity in embedding space, rather than surface-form novelty. This diversity reward is combined with outcome correctness and solution efficiency in a z-score-normalized multi-objective objective that stabilizes training. On GSM8K, SD-E$^2$ surpasses the base Qwen2.5-3B-Instruct and strong GRPO baselines (GRPO-CFL and GRPO-CFEE) by +27.4, +5.2, and +1.5 percentage points, respectively, while discovering on average 9.8 semantically distinct strategies per question. We further improve MedMCQA to 49.64% versus 38.37% for the base model and show gains on the harder AIME benchmark (1983-2025), reaching 13.28% versus 6.74% for the base. These results indicate that rewarding semantic novelty yields a more compute-efficient exploration-exploitation signal for training reasoning-capable SLMs. By introducing cognitive adaptation-adjusting the reasoning process structure rather than per-token computation-SD-E$^2$ offers a complementary path to efficiency gains in resource-constrained models.</p>"
    },
    {
      "id": "074e76fda468",
      "title": "FastInsight: Fast and Insightful Retrieval via Fusion Operators for Graph RAG",
      "content": "arXiv:2601.18579v1 Announce Type: cross  Abstract: Existing Graph RAG methods aiming for insightful retrieval on corpus graphs typically rely on time-intensive processes that interleave Large Language Model (LLM) reasoning. To enable time-efficient insightful retrieval, we propose FastInsight. We first introduce a graph retrieval taxonomy that categorizes existing methods into three fundamental operations: vector search, graph search, and model-based search. Through this taxonomy, we identify two critical limitations in current approaches: the topology-blindness of model-based search and the semantics-blindness of graph search. FastInsight overcomes these limitations by interleaving two novel fusion operators: the Graph-based Reranker (GRanker), which functions as a graph model-based search, and Semantic-Topological eXpansion (STeX), which operates as a vector-graph search. Extensive experiments on broad retrieval and generation datasets demonstrate that FastInsight significantly improves both retrieval accuracy and generation quality compared to state-of-the-art baselines, achieving a substantial Pareto improvement in the trade-off between effectiveness and efficiency.",
      "url": "http://arxiv.org/abs/2601.18579",
      "author": "Seonho An, Chaejeong Hyun, Min-Soo Kim",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.IR"
      ],
      "summary": "Introduces FastInsight for efficient Graph RAG with novel fusion operators: GRanker (graph-based reranker) and SFuser (semantic-topology fuser) addressing topology-blindness and semantics-blindness limitations.",
      "importance_score": 66,
      "reasoning": "Practical improvement for Graph RAG efficiency. Clear taxonomy of limitations and targeted solutions. Relevant for production RAG systems.",
      "themes": [
        "Graph RAG",
        "Retrieval",
        "Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces FastInsight for efficient Graph RAG with novel fusion operators: GRanker (graph-based reranker) and SFuser (semantic-topology fuser) addressing topology-blindness and semantics-blindness limitations.</p>",
      "content_html": "<p>arXiv:2601.18579v1 Announce Type: cross  Abstract: Existing Graph RAG methods aiming for insightful retrieval on corpus graphs typically rely on time-intensive processes that interleave Large Language Model (LLM) reasoning. To enable time-efficient insightful retrieval, we propose FastInsight. We first introduce a graph retrieval taxonomy that categorizes existing methods into three fundamental operations: vector search, graph search, and model-based search. Through this taxonomy, we identify two critical limitations in current approaches: the topology-blindness of model-based search and the semantics-blindness of graph search. FastInsight overcomes these limitations by interleaving two novel fusion operators: the Graph-based Reranker (GRanker), which functions as a graph model-based search, and Semantic-Topological eXpansion (STeX), which operates as a vector-graph search. Extensive experiments on broad retrieval and generation datasets demonstrate that FastInsight significantly improves both retrieval accuracy and generation quality compared to state-of-the-art baselines, achieving a substantial Pareto improvement in the trade-off between effectiveness and efficiency.</p>"
    },
    {
      "id": "452f5ef90e97",
      "title": "FaLW: A Forgetting-aware Loss Reweighting for Long-tailed Unlearning",
      "content": "arXiv:2601.18650v1 Announce Type: cross  Abstract: Machine unlearning, which aims to efficiently remove the influence of specific data from trained models, is crucial for upholding data privacy regulations like the ``right to be forgotten\". However, existing research predominantly evaluates unlearning methods on relatively balanced forget sets. This overlooks a common real-world scenario where data to be forgotten, such as a user's activity records, follows a long-tailed distribution. Our work is the first to investigate this critical research gap. We find that in such long-tailed settings, existing methods suffer from two key issues: \\textit{Heterogeneous Unlearning Deviation} and \\textit{Skewed Unlearning Deviation}. To address these challenges, we propose FaLW, a plug-and-play, instance-wise dynamic loss reweighting method. FaLW innovatively assesses the unlearning state of each sample by comparing its predictive probability to the distribution of unseen data from the same class. Based on this, it uses a forgetting-aware reweighting scheme, modulated by a balancing factor, to adaptively adjust the unlearning intensity for each sample. Extensive experiments demonstrate that FaLW achieves superior performance. Code is available at \\textbf{Supplementary Material}.",
      "url": "http://arxiv.org/abs/2601.18650",
      "author": "Liheng Yu, Zhe Zhao, Yuxuan Wang, Pengkun Wang, Binwu Wang, Yang Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "First investigation of machine unlearning in long-tailed settings, identifying Heterogeneous and Skewed Unlearning Deviation issues. Proposes FaLW, plug-and-play loss reweighting framework.",
      "importance_score": 66,
      "reasoning": "First to address important gap: real-world forget sets follow long-tailed distributions. Novel problem formulation with practical solution.",
      "themes": [
        "Machine Unlearning",
        "Privacy",
        "Long-tailed Learning"
      ],
      "continuation": null,
      "summary_html": "<p>First investigation of machine unlearning in long-tailed settings, identifying Heterogeneous and Skewed Unlearning Deviation issues. Proposes FaLW, plug-and-play loss reweighting framework.</p>",
      "content_html": "<p>arXiv:2601.18650v1 Announce Type: cross  Abstract: Machine unlearning, which aims to efficiently remove the influence of specific data from trained models, is crucial for upholding data privacy regulations like the ``right to be forgotten\". However, existing research predominantly evaluates unlearning methods on relatively balanced forget sets. This overlooks a common real-world scenario where data to be forgotten, such as a user's activity records, follows a long-tailed distribution. Our work is the first to investigate this critical research gap. We find that in such long-tailed settings, existing methods suffer from two key issues: \\textit{Heterogeneous Unlearning Deviation} and \\textit{Skewed Unlearning Deviation}. To address these challenges, we propose FaLW, a plug-and-play, instance-wise dynamic loss reweighting method. FaLW innovatively assesses the unlearning state of each sample by comparing its predictive probability to the distribution of unseen data from the same class. Based on this, it uses a forgetting-aware reweighting scheme, modulated by a balancing factor, to adaptively adjust the unlearning intensity for each sample. Extensive experiments demonstrate that FaLW achieves superior performance. Code is available at \\textbf{Supplementary Material}.</p>"
    },
    {
      "id": "bfb2877bf80b",
      "title": "PingPong: A Natural Benchmark for Multi-Turn Code-Switching Dialogues",
      "content": "arXiv:2601.17277v1 Announce Type: new  Abstract: Code-switching is a widespread practice among the world's multilingual majority, yet few benchmarks accurately reflect its complexity in everyday communication. We present PingPong, a benchmark for natural multi-party code-switching dialogues covering five language-combination variations, some of which are trilingual. Our dataset consists of human-authored conversations among 2 to 4 participants covering authentic, multi-threaded structures where replies frequently reference much earlier points in the dialogue. We demonstrate that our data is significantly more natural and structurally diverse than machine-generated alternatives, offering greater variation in message length, speaker dominance, and reply distance. Based on these dialogues, we define three downstream tasks: Question Answering, Dialogue Summarization, and Topic Classification. Evaluations of several state-of-the-art language models on PingPong reveal that performance remains limited on code-switched inputs, underscoring the urgent need for more robust NLP systems capable of addressing the intricacies of real-world multilingual discourse.",
      "url": "http://arxiv.org/abs/2601.17277",
      "author": "Mohammad Rifqi Farhansyah, Hanif Muhammad Zhafran, Farid Adilazuarda, Shamsuddeen Hassan Muhammad, Maryam Ibrahim Mukhtar, Nedjma Ousidhoum, Genta Indra Winata, Ayu Purwarianti, Alham Fikri Aji",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents PingPong, a benchmark for natural multi-party code-switching dialogues covering 5 language combinations including trilingual scenarios. Features human-authored conversations with complex multi-threaded structures.",
      "importance_score": 66,
      "reasoning": "Valuable resource for underserved multilingual phenomenon. Demonstrates significant naturalness advantages over machine-generated alternatives.",
      "themes": [
        "Code-Switching",
        "Multilingual NLP",
        "Dialogue Systems",
        "Benchmark"
      ],
      "continuation": null,
      "summary_html": "<p>Presents PingPong, a benchmark for natural multi-party code-switching dialogues covering 5 language combinations including trilingual scenarios. Features human-authored conversations with complex multi-threaded structures.</p>",
      "content_html": "<p>arXiv:2601.17277v1 Announce Type: new  Abstract: Code-switching is a widespread practice among the world's multilingual majority, yet few benchmarks accurately reflect its complexity in everyday communication. We present PingPong, a benchmark for natural multi-party code-switching dialogues covering five language-combination variations, some of which are trilingual. Our dataset consists of human-authored conversations among 2 to 4 participants covering authentic, multi-threaded structures where replies frequently reference much earlier points in the dialogue. We demonstrate that our data is significantly more natural and structurally diverse than machine-generated alternatives, offering greater variation in message length, speaker dominance, and reply distance. Based on these dialogues, we define three downstream tasks: Question Answering, Dialogue Summarization, and Topic Classification. Evaluations of several state-of-the-art language models on PingPong reveal that performance remains limited on code-switched inputs, underscoring the urgent need for more robust NLP systems capable of addressing the intricacies of real-world multilingual discourse.</p>"
    },
    {
      "id": "5c89ec58ded2",
      "title": "ProGraph-R1: Progress-aware Reinforcement Learning for Graph Retrieval Augmented Generation",
      "content": "arXiv:2601.17755v1 Announce Type: new  Abstract: Graph Retrieval-Augmented Generation (GraphRAG) has been successfully applied in various knowledge-intensive question answering tasks by organizing external knowledge into structured graphs of entities and relations. It enables large language models (LLMs) to perform complex reasoning beyond text-chunk retrieval. Recent works have employed reinforcement learning (RL) to train agentic GraphRAG frameworks that perform iterative interactions between LLMs and knowledge graphs. However, existing RL-based frameworks such as Graph-R1 suffer from two key limitations: (1) they primarily depend on semantic similarity for retrieval, often overlooking the underlying graph structure, and (2) they rely on sparse, outcome-level rewards, failing to capture the quality of intermediate retrieval steps and their dependencies. To address these limitations, we propose ProGraph-R1, a progress-aware agentic framework for graph-based retrieval and multi-step reasoning. ProGraph-R1 introduces a structure-aware hypergraph retrieval mechanism that jointly considers semantic relevance and graph connectivity, encouraging coherent traversal along multi-hop reasoning paths. We also design a progress-based step-wise policy optimization, which provides dense learning signals by modulating advantages according to intermediate reasoning progress within a graph, rather than relying solely on final outcomes. Experiments on multi-hop question answering benchmarks demonstrate that ProGraph-R1 consistently improves reasoning accuracy and generation quality over existing GraphRAG methods.",
      "url": "http://arxiv.org/abs/2601.17755",
      "author": "Jinyoung Park, Sanghyeok Lee, Omar Zia Khan, Hyunwoo J. Kim, Joo-Kyung Kim",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces ProGraph-R1 for GraphRAG using RL with progress-aware dense rewards instead of sparse outcome-level rewards. Addresses limitation of existing approaches that rely solely on semantic similarity.",
      "importance_score": 66,
      "reasoning": "Useful improvement to GraphRAG training with novel reward shaping. Addresses real limitation in RL-based retrieval.",
      "themes": [
        "GraphRAG",
        "Reinforcement Learning",
        "Knowledge Graphs"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces ProGraph-R1 for GraphRAG using RL with progress-aware dense rewards instead of sparse outcome-level rewards. Addresses limitation of existing approaches that rely solely on semantic similarity.</p>",
      "content_html": "<p>arXiv:2601.17755v1 Announce Type: new  Abstract: Graph Retrieval-Augmented Generation (GraphRAG) has been successfully applied in various knowledge-intensive question answering tasks by organizing external knowledge into structured graphs of entities and relations. It enables large language models (LLMs) to perform complex reasoning beyond text-chunk retrieval. Recent works have employed reinforcement learning (RL) to train agentic GraphRAG frameworks that perform iterative interactions between LLMs and knowledge graphs. However, existing RL-based frameworks such as Graph-R1 suffer from two key limitations: (1) they primarily depend on semantic similarity for retrieval, often overlooking the underlying graph structure, and (2) they rely on sparse, outcome-level rewards, failing to capture the quality of intermediate retrieval steps and their dependencies. To address these limitations, we propose ProGraph-R1, a progress-aware agentic framework for graph-based retrieval and multi-step reasoning. ProGraph-R1 introduces a structure-aware hypergraph retrieval mechanism that jointly considers semantic relevance and graph connectivity, encouraging coherent traversal along multi-hop reasoning paths. We also design a progress-based step-wise policy optimization, which provides dense learning signals by modulating advantages according to intermediate reasoning progress within a graph, rather than relying solely on final outcomes. Experiments on multi-hop question answering benchmarks demonstrate that ProGraph-R1 consistently improves reasoning accuracy and generation quality over existing GraphRAG methods.</p>"
    },
    {
      "id": "3c6a245dbf4a",
      "title": "LLMs as Cultural Archives: Cultural Commonsense Knowledge Graph Extraction",
      "content": "arXiv:2601.17971v1 Announce Type: new  Abstract: Large language models (LLMs) encode rich cultural knowledge learned from diverse web-scale data, offering an unprecedented opportunity to model cultural commonsense at scale. Yet this knowledge remains mostly implicit and unstructured, limiting its interpretability and use. We present an iterative, prompt-based framework for constructing a Cultural Commonsense Knowledge Graph (CCKG) that treats LLMs as cultural archives, systematically eliciting culture-specific entities, relations, and practices and composing them into multi-step inferential chains across languages. We evaluate CCKG on five countries with human judgments of cultural relevance, correctness, and path coherence. We find that the cultural knowledge graphs are better realized in English, even when the target culture is non-English (e.g., Chinese, Indonesian, Arabic), indicating uneven cultural encoding in current LLMs. Augmenting smaller LLMs with CCKG improves performance on cultural reasoning and story generation, with the largest gains from English chains. Our results show both the promise and limits of LLMs as cultural technologies and that chain-structured cultural knowledge is a practical substrate for culturally grounded NLP.",
      "url": "http://arxiv.org/abs/2601.17971",
      "author": "Junior Cedric Tonga, Chen Cecilia Liu, Iryna Gurevych, Fajri Koto",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents iterative prompt-based framework for constructing Cultural Commonsense Knowledge Graphs from LLMs, treating models as cultural archives. Evaluates across five countries with human judgments.",
      "importance_score": 66,
      "reasoning": "Novel approach to systematic cultural knowledge extraction from LLMs. Important for cultural NLP and knowledge representation.",
      "themes": [
        "Knowledge Graphs",
        "Cultural NLP",
        "Knowledge Extraction"
      ],
      "continuation": null,
      "summary_html": "<p>Presents iterative prompt-based framework for constructing Cultural Commonsense Knowledge Graphs from LLMs, treating models as cultural archives. Evaluates across five countries with human judgments.</p>",
      "content_html": "<p>arXiv:2601.17971v1 Announce Type: new  Abstract: Large language models (LLMs) encode rich cultural knowledge learned from diverse web-scale data, offering an unprecedented opportunity to model cultural commonsense at scale. Yet this knowledge remains mostly implicit and unstructured, limiting its interpretability and use. We present an iterative, prompt-based framework for constructing a Cultural Commonsense Knowledge Graph (CCKG) that treats LLMs as cultural archives, systematically eliciting culture-specific entities, relations, and practices and composing them into multi-step inferential chains across languages. We evaluate CCKG on five countries with human judgments of cultural relevance, correctness, and path coherence. We find that the cultural knowledge graphs are better realized in English, even when the target culture is non-English (e.g., Chinese, Indonesian, Arabic), indicating uneven cultural encoding in current LLMs. Augmenting smaller LLMs with CCKG improves performance on cultural reasoning and story generation, with the largest gains from English chains. Our results show both the promise and limits of LLMs as cultural technologies and that chain-structured cultural knowledge is a practical substrate for culturally grounded NLP.</p>"
    },
    {
      "id": "99f0ed4b4b61",
      "title": "Suppressing Final Layer Hidden State Jumps in Transformer Pretraining",
      "content": "arXiv:2601.18302v1 Announce Type: new  Abstract: This paper discusses the internal behavior of Transformer language models. Many recent pre-trained models have been reported to exhibit only slight changes in the angular distance between the input and output hidden state vectors in the middle Transformer layers, despite a disproportionately large ``jump'' in the angular distance occurring in or around the final Transformer layer. To characterize this, we first introduce a quantitative metric for the jump strength around the final layer, and then demonstrate its prevalence across many open-weight models, as well as its amplification throughout pre-training. Assuming such jumps indicate an undesirable property, we propose the jump-suppressing regularizer (JREG) which penalizes this jump during pre-training, thereby encouraging more balanced capability usage across the middle layers. Empirical evaluations of three model sizes of Llama-based models, trained with the proposed JREG method, reveal improved task performance compared to the baseline without altering the model architecture.",
      "url": "http://arxiv.org/abs/2601.18302",
      "author": "Keigo Shibata, Kazuki Yano, Ryosuke Takahashi, Jaesung Lee, Wataru Ikeda, Jun Suzuki",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces jump-suppressing regularizer (JREG) to address disproportionate angular distance jumps in final transformer layers observed across pre-trained models. Proposes quantitative metric for jump strength.",
      "importance_score": 66,
      "reasoning": "Novel observation about transformer training dynamics with practical regularization solution. Interesting architectural insight.",
      "themes": [
        "Transformer Training",
        "Regularization",
        "Model Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces jump-suppressing regularizer (JREG) to address disproportionate angular distance jumps in final transformer layers observed across pre-trained models. Proposes quantitative metric for jump strength.</p>",
      "content_html": "<p>arXiv:2601.18302v1 Announce Type: new  Abstract: This paper discusses the internal behavior of Transformer language models. Many recent pre-trained models have been reported to exhibit only slight changes in the angular distance between the input and output hidden state vectors in the middle Transformer layers, despite a disproportionately large ``jump'' in the angular distance occurring in or around the final Transformer layer. To characterize this, we first introduce a quantitative metric for the jump strength around the final layer, and then demonstrate its prevalence across many open-weight models, as well as its amplification throughout pre-training. Assuming such jumps indicate an undesirable property, we propose the jump-suppressing regularizer (JREG) which penalizes this jump during pre-training, thereby encouraging more balanced capability usage across the middle layers. Empirical evaluations of three model sizes of Llama-based models, trained with the proposed JREG method, reveal improved task performance compared to the baseline without altering the model architecture.</p>"
    },
    {
      "id": "0d24e07cd316",
      "title": "iFSQ: Improving FSQ for Image Generation with 1 Line of Code",
      "content": "arXiv:2601.17124v1 Announce Type: new  Abstract: The field of image generation is currently bifurcated into autoregressive (AR) models operating on discrete tokens and diffusion models utilizing continuous latents. This divide, rooted in the distinction between VQ-VAEs and VAEs, hinders unified modeling and fair benchmarking. Finite Scalar Quantization (FSQ) offers a theoretical bridge, yet vanilla FSQ suffers from a critical flaw: its equal-interval quantization can cause activation collapse. This mismatch forces a trade-off between reconstruction fidelity and information efficiency. In this work, we resolve this dilemma by simply replacing the activation function in original FSQ with a distribution-matching mapping to enforce a uniform prior. Termed iFSQ, this simple strategy requires just one line of code yet mathematically guarantees both optimal bin utilization and reconstruction precision. Leveraging iFSQ as a controlled benchmark, we uncover two key insights: (1) The optimal equilibrium between discrete and continuous representations lies at approximately 4 bits per dimension. (2) Under identical reconstruction constraints, AR models exhibit rapid initial convergence, whereas diffusion models achieve a superior performance ceiling, suggesting that strict sequential ordering may limit the upper bounds of generation quality. Finally, we extend our analysis by adapting Representation Alignment (REPA) to AR models, yielding LlamaGen-REPA. Codes is available at https://github.com/Tencent-Hunyuan/iFSQ",
      "url": "http://arxiv.org/abs/2601.17124",
      "author": "Bin Lin, Zongjian Li, Yuwei Niu, Kaixiong Gong, Yunyang Ge, Yunlong Lin, Mingzhe Zheng, JianWei Zhang, Miles Yang, Zhao Zhong, Liefeng Bo, Li Yuan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes iFSQ improving Finite Scalar Quantization with a single line of code change - replacing activation function with distribution-matching mapping to resolve activation collapse in discrete image generation.",
      "importance_score": 66,
      "reasoning": "Simple yet effective improvement bridging AR and diffusion model approaches. Practical contribution with minimal implementation overhead.",
      "themes": [
        "Image Generation",
        "Quantization",
        "Tokenization"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes iFSQ improving Finite Scalar Quantization with a single line of code change - replacing activation function with distribution-matching mapping to resolve activation collapse in discrete image generation.</p>",
      "content_html": "<p>arXiv:2601.17124v1 Announce Type: new  Abstract: The field of image generation is currently bifurcated into autoregressive (AR) models operating on discrete tokens and diffusion models utilizing continuous latents. This divide, rooted in the distinction between VQ-VAEs and VAEs, hinders unified modeling and fair benchmarking. Finite Scalar Quantization (FSQ) offers a theoretical bridge, yet vanilla FSQ suffers from a critical flaw: its equal-interval quantization can cause activation collapse. This mismatch forces a trade-off between reconstruction fidelity and information efficiency. In this work, we resolve this dilemma by simply replacing the activation function in original FSQ with a distribution-matching mapping to enforce a uniform prior. Termed iFSQ, this simple strategy requires just one line of code yet mathematically guarantees both optimal bin utilization and reconstruction precision. Leveraging iFSQ as a controlled benchmark, we uncover two key insights: (1) The optimal equilibrium between discrete and continuous representations lies at approximately 4 bits per dimension. (2) Under identical reconstruction constraints, AR models exhibit rapid initial convergence, whereas diffusion models achieve a superior performance ceiling, suggesting that strict sequential ordering may limit the upper bounds of generation quality. Finally, we extend our analysis by adapting Representation Alignment (REPA) to AR models, yielding LlamaGen-REPA. Codes is available at https://github.com/Tencent-Hunyuan/iFSQ</p>"
    },
    {
      "id": "8dcd4b789394",
      "title": "Correct-by-Construction Vision-based Pose Estimation using Geometric Generative Models",
      "content": "arXiv:2601.17556v1 Announce Type: new  Abstract: We consider the problem of vision-based pose estimation for autonomous systems. While deep neural networks have been successfully used for vision-based tasks, they inherently lack provable guarantees on the correctness of their output, which is crucial for safety-critical applications. We present a framework for designing certifiable neural networks (NNs) for perception-based pose estimation that integrates physics-driven modeling with learning-based estimation. The proposed framework begins by leveraging the known geometry of planar objects commonly found in the environment, such as traffic signs and runway markings, referred to as target objects. At its core, it introduces a geometric generative model (GGM), a neural-network-like model whose parameters are derived from the image formation process of a target object observed by a camera. Once designed, the GGM can be used to train NN-based pose estimators with certified guarantees in terms of their estimation errors. We first demonstrate this framework in uncluttered environments, where the target object is the only object present in the camera's field of view. We extend this using ideas from NN reachability analysis to design certified object NN that can detect the presence of the target object in cluttered environments. Subsequently, the framework consolidates the certified object detector with the certified pose estimator to design a multi-stage perception pipeline that generalizes the proposed approach to cluttered environments, while maintaining its certified guarantees. We evaluate the proposed framework using both synthetic and real images of various planar objects commonly encountered by autonomous vehicles. Using images captured by an event-based camera, we show that the trained encoder can effectively estimate the pose of a traffic sign in accordance with the certified bound provided by the framework.",
      "url": "http://arxiv.org/abs/2601.17556",
      "author": "Ulices Santa Cruz, Mahmoud Elfar, Yasser Shoukry",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes framework for certifiable neural networks for vision-based pose estimation integrating geometric generative models with provable correctness guarantees.",
      "importance_score": 66,
      "reasoning": "Important contribution to safety-critical AI with formal guarantees for perception, addresses key deployment challenge.",
      "themes": [
        "Certifiable AI",
        "Pose Estimation",
        "Safety-Critical Systems"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes framework for certifiable neural networks for vision-based pose estimation integrating geometric generative models with provable correctness guarantees.</p>",
      "content_html": "<p>arXiv:2601.17556v1 Announce Type: new  Abstract: We consider the problem of vision-based pose estimation for autonomous systems. While deep neural networks have been successfully used for vision-based tasks, they inherently lack provable guarantees on the correctness of their output, which is crucial for safety-critical applications. We present a framework for designing certifiable neural networks (NNs) for perception-based pose estimation that integrates physics-driven modeling with learning-based estimation. The proposed framework begins by leveraging the known geometry of planar objects commonly found in the environment, such as traffic signs and runway markings, referred to as target objects. At its core, it introduces a geometric generative model (GGM), a neural-network-like model whose parameters are derived from the image formation process of a target object observed by a camera. Once designed, the GGM can be used to train NN-based pose estimators with certified guarantees in terms of their estimation errors. We first demonstrate this framework in uncluttered environments, where the target object is the only object present in the camera's field of view. We extend this using ideas from NN reachability analysis to design certified object NN that can detect the presence of the target object in cluttered environments. Subsequently, the framework consolidates the certified object detector with the certified pose estimator to design a multi-stage perception pipeline that generalizes the proposed approach to cluttered environments, while maintaining its certified guarantees. We evaluate the proposed framework using both synthetic and real images of various planar objects commonly encountered by autonomous vehicles. Using images captured by an event-based camera, we show that the trained encoder can effectively estimate the pose of a traffic sign in accordance with the certified bound provided by the framework.</p>"
    },
    {
      "id": "f12be6d5dc74",
      "title": "Are We Evaluating the Edit Locality of LLM Model Editing Properly?",
      "content": "arXiv:2601.17343v1 Announce Type: new  Abstract: Model editing has recently emerged as a popular paradigm for efficiently updating knowledge in LLMs. A central desideratum of updating knowledge is to balance editing efficacy, i.e., the successful injection of target knowledge, and specificity (also known as edit locality), i.e., the preservation of existing non-target knowledge. However, we find that existing specificity evaluation protocols are inadequate for this purpose. We systematically elaborated on the three fundamental issues it faces. Beyond the conceptual issues, we further empirically demonstrate that existing specificity metrics are weakly correlated with the strength of specificity regularizers. We also find that current metrics lack sufficient sensitivity, rendering them ineffective at distinguishing the specificity performance of different methods. Finally, we propose a constructive evaluation protocol. Under this protocol, the conflict between open-ended LLMs and the assumption of determined answers is eliminated, query-independent fluency biases are avoided, and the evaluation strictness can be smoothly adjusted within a near-continuous space. Experiments across various LLMs, datasets, and editing methods show that metrics derived from the proposed protocol are more sensitive to changes in the strength of specificity regularizers and exhibit strong correlation with them, enabling more fine-grained discrimination of different methods' knowledge preservation capabilities.",
      "url": "http://arxiv.org/abs/2601.17343",
      "author": "Wei Liu, Haomei Xu, Hongkai Liu, Zhiying Deng, Ruixuan Li, Heng Huang, Yee Whye Teh, Wee Sun Lee",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Identifies fundamental flaws in existing model editing specificity/locality evaluation protocols, showing current metrics are weakly correlated with regularizer strength and lack sensitivity.",
      "importance_score": 65,
      "reasoning": "Important critique of evaluation methodology in an active research area; findings could redirect future model editing research.",
      "themes": [
        "Model Editing",
        "Evaluation Methodology",
        "Knowledge Updates"
      ],
      "continuation": null,
      "summary_html": "<p>Identifies fundamental flaws in existing model editing specificity/locality evaluation protocols, showing current metrics are weakly correlated with regularizer strength and lack sensitivity.</p>",
      "content_html": "<p>arXiv:2601.17343v1 Announce Type: new  Abstract: Model editing has recently emerged as a popular paradigm for efficiently updating knowledge in LLMs. A central desideratum of updating knowledge is to balance editing efficacy, i.e., the successful injection of target knowledge, and specificity (also known as edit locality), i.e., the preservation of existing non-target knowledge. However, we find that existing specificity evaluation protocols are inadequate for this purpose. We systematically elaborated on the three fundamental issues it faces. Beyond the conceptual issues, we further empirically demonstrate that existing specificity metrics are weakly correlated with the strength of specificity regularizers. We also find that current metrics lack sufficient sensitivity, rendering them ineffective at distinguishing the specificity performance of different methods. Finally, we propose a constructive evaluation protocol. Under this protocol, the conflict between open-ended LLMs and the assumption of determined answers is eliminated, query-independent fluency biases are avoided, and the evaluation strictness can be smoothly adjusted within a near-continuous space. Experiments across various LLMs, datasets, and editing methods show that metrics derived from the proposed protocol are more sensitive to changes in the strength of specificity regularizers and exhibit strong correlation with them, enabling more fine-grained discrimination of different methods' knowledge preservation capabilities.</p>"
    },
    {
      "id": "3ce0cce72bd0",
      "title": "RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents",
      "content": "arXiv:2601.18130v1 Announce Type: new  Abstract: Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool.",
      "url": "http://arxiv.org/abs/2601.18130",
      "author": "Jize Wang, Han Wu, Zhiyuan You, Yiming Song, Yijun Wang, Zifei Shan, Yining Li, Songyang Zhang, Xinyi Le, Cailian Chen, Xinping Guan, Dacheng Tao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes RouteMoA for efficient mixture-of-agents using lightweight scoring for initial screening before inference, avoiding full model execution while maintaining quality through mixture of judges.",
      "importance_score": 65,
      "reasoning": "Practical efficiency improvement for multi-agent systems; addresses real cost issues with principled approach.",
      "themes": [
        "Multi-Agent Systems",
        "Efficiency",
        "Model Routing"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes RouteMoA for efficient mixture-of-agents using lightweight scoring for initial screening before inference, avoiding full model execution while maintaining quality through mixture of judges.</p>",
      "content_html": "<p>arXiv:2601.18130v1 Announce Type: new  Abstract: Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool.</p>"
    },
    {
      "id": "d4c9c0a54c64",
      "title": "DEEPMED: Building a Medical DeepResearch Agent via Multi-hop Med-Search Data and Turn-Controlled Agentic Training & Inference",
      "content": "arXiv:2601.18496v1 Announce Type: new  Abstract: Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relatively limited gains. We attribute this to two gaps: task characteristic and tool-use scaling. Medical questions require evidence interpretation in a knowledge-intensive clinical context; while general DR models can retrieve information, they often lack clinical-context reasoning and thus \"find it but fail to use it,\" leaving performance limited by medical abilities. Moreover, in medical scenarios, blindly scaling tool-call can inject noisy context, derailing sensitive medical reasoning and prompting repetitive evidence-seeking along incorrect paths. Therefore, we propose DeepMed. For data, we deploy a multi-hop med-search QA synthesis method supporting the model to apply the DR paradigm in medical contexts. For training, we introduce a difficulty-aware turn-penalty to suppress excessive tool-call growth. For inference, we bring a monitor to help validate hypotheses within a controlled number of steps and avoid context rot. Overall, on seven medical benchmarks, DeepMed improves its base model by 9.79\\% on average and outperforms larger medical reasoning and DR models.",
      "url": "http://arxiv.org/abs/2601.18496",
      "author": "Zihan wang, Hao Wang, Shi Feng, Xiaocui Yang, Daling Wang, Yiqun Zhang, Jinghao Lin, Haihua Yang, Xiaozhong Ji",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces DEEPMED medical DeepResearch agent addressing task characteristic and tool-use scaling gaps through multi-hop medical search data and turn-controlled agentic training.",
      "importance_score": 65,
      "reasoning": "Addresses important gap in medical AI agents; practical approach to clinical-context reasoning limitations.",
      "themes": [
        "Healthcare AI",
        "Deep Research",
        "Agentic AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces DEEPMED medical DeepResearch agent addressing task characteristic and tool-use scaling gaps through multi-hop medical search data and turn-controlled agentic training.</p>",
      "content_html": "<p>arXiv:2601.18496v1 Announce Type: new  Abstract: Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relatively limited gains. We attribute this to two gaps: task characteristic and tool-use scaling. Medical questions require evidence interpretation in a knowledge-intensive clinical context; while general DR models can retrieve information, they often lack clinical-context reasoning and thus \"find it but fail to use it,\" leaving performance limited by medical abilities. Moreover, in medical scenarios, blindly scaling tool-call can inject noisy context, derailing sensitive medical reasoning and prompting repetitive evidence-seeking along incorrect paths. Therefore, we propose DeepMed. For data, we deploy a multi-hop med-search QA synthesis method supporting the model to apply the DR paradigm in medical contexts. For training, we introduce a difficulty-aware turn-penalty to suppress excessive tool-call growth. For inference, we bring a monitor to help validate hypotheses within a controlled number of steps and avoid context rot. Overall, on seven medical benchmarks, DeepMed improves its base model by 9.79\\% on average and outperforms larger medical reasoning and DR models.</p>"
    },
    {
      "id": "ff5d3a476483",
      "title": "AMVICC: A Novel Benchmark for Cross-Modal Failure Mode Profiling for VLMs and IGMs",
      "content": "arXiv:2601.17037v1 Announce Type: cross  Abstract: We investigated visual reasoning limitations of both multimodal large language models (MLLMs) and image generation models (IGMs) by creating a novel benchmark to systematically compare failure modes across image-to-text and text-to-image tasks, enabling cross-modal evaluation of visual understanding. Despite rapid growth in machine learning, vision language models (VLMs) still fail to understand or generate basic visual concepts such as object orientation, quantity, or spatial relationships, which highlighted gaps in elementary visual reasoning. By adapting MMVP benchmark questions into explicit and implicit prompts, we create \\textit{AMVICC}, a novel benchmark for profiling failure modes across various modalities. After testing 11 MLLMs and 3 IGMs in nine categories of visual reasoning, our results show that failure modes are often shared between models and modalities, but certain failures are model-specific and modality-specific, and this can potentially be attributed to various factors. IGMs consistently struggled to manipulate specific visual components in response to prompts, especially in explicit prompts, suggesting poor control over fine-grained visual attributes. Our findings apply most directly to the evaluation of existing state-of-the-art models on structured visual reasoning tasks. This work lays the foundation for future cross-modal alignment studies, offering a framework to probe whether generation and interpretation failures stem from shared limitations to guide future improvements in unified vision-language modeling.",
      "url": "http://arxiv.org/abs/2601.17037",
      "author": "Aahana Basappa, Pranay Goel, Anusri Karra, Anish Karra, Asa Gilmore, Kevin Zhu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Creates AMVICC benchmark for systematically comparing failure modes across 11 MLLMs and 5 image generation models in both image-to-text and text-to-image tasks. Reveals gaps in elementary visual reasoning.",
      "importance_score": 65,
      "reasoning": "Important benchmark contribution for understanding VLM limitations. Cross-modal failure analysis is novel and practically useful.",
      "themes": [
        "VLM Evaluation",
        "Benchmarks",
        "Visual Reasoning"
      ],
      "continuation": null,
      "summary_html": "<p>Creates AMVICC benchmark for systematically comparing failure modes across 11 MLLMs and 5 image generation models in both image-to-text and text-to-image tasks. Reveals gaps in elementary visual reasoning.</p>",
      "content_html": "<p>arXiv:2601.17037v1 Announce Type: cross  Abstract: We investigated visual reasoning limitations of both multimodal large language models (MLLMs) and image generation models (IGMs) by creating a novel benchmark to systematically compare failure modes across image-to-text and text-to-image tasks, enabling cross-modal evaluation of visual understanding. Despite rapid growth in machine learning, vision language models (VLMs) still fail to understand or generate basic visual concepts such as object orientation, quantity, or spatial relationships, which highlighted gaps in elementary visual reasoning. By adapting MMVP benchmark questions into explicit and implicit prompts, we create \\textit{AMVICC}, a novel benchmark for profiling failure modes across various modalities. After testing 11 MLLMs and 3 IGMs in nine categories of visual reasoning, our results show that failure modes are often shared between models and modalities, but certain failures are model-specific and modality-specific, and this can potentially be attributed to various factors. IGMs consistently struggled to manipulate specific visual components in response to prompts, especially in explicit prompts, suggesting poor control over fine-grained visual attributes. Our findings apply most directly to the evaluation of existing state-of-the-art models on structured visual reasoning tasks. This work lays the foundation for future cross-modal alignment studies, offering a framework to probe whether generation and interpretation failures stem from shared limitations to guide future improvements in unified vision-language modeling.</p>"
    },
    {
      "id": "277995477e83",
      "title": "Who Gets Which Message? Auditing Demographic Bias in LLM-Generated Targeted Text",
      "content": "arXiv:2601.17172v1 Announce Type: cross  Abstract: Large language models (LLMs) are increasingly capable of generating personalized, persuasive text at scale, raising new questions about bias and fairness in automated communication. This paper presents the first systematic analysis of how LLMs behave when tasked with demographic-conditioned targeted messaging. We introduce a controlled evaluation framework using three leading models -- GPT-4o, Llama-3.3, and Mistral-Large 2.1 -- across two generation settings: Standalone Generation, which isolates intrinsic demographic effects, and Context-Rich Generation, which incorporates thematic and regional context to emulate realistic targeting. We evaluate generated messages along three dimensions: lexical content, language style, and persuasive framing. We instantiate this framework on climate communication and find consistent age- and gender-based asymmetries across models: male- and youth-targeted messages emphasize agency, innovation, and assertiveness, while female- and senior-targeted messages stress warmth, care, and tradition. Contextual prompts systematically amplify these disparities, with persuasion scores significantly higher for messages tailored to younger or male audiences. Our findings demonstrate how demographic stereotypes can surface and intensify in LLM-generated targeted communication, underscoring the need for bias-aware generation pipelines and transparent auditing frameworks that explicitly account for demographic conditioning in socially sensitive applications.",
      "url": "http://arxiv.org/abs/2601.17172",
      "author": "Tunazzina Islam",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "First systematic analysis of demographic bias in LLM-generated targeted messaging using GPT-4o, Llama-3.3, and Mistral-Large 2.1. Evaluates lexical, stylistic, and persuasive dimensions.",
      "importance_score": 65,
      "reasoning": "Important fairness study with major current models. Novel framework for analyzing demographic conditioning in LLM personalization.",
      "themes": [
        "AI Fairness",
        "LLM Bias",
        "Personalization"
      ],
      "continuation": null,
      "summary_html": "<p>First systematic analysis of demographic bias in LLM-generated targeted messaging using GPT-4o, Llama-3.3, and Mistral-Large 2.1. Evaluates lexical, stylistic, and persuasive dimensions.</p>",
      "content_html": "<p>arXiv:2601.17172v1 Announce Type: cross  Abstract: Large language models (LLMs) are increasingly capable of generating personalized, persuasive text at scale, raising new questions about bias and fairness in automated communication. This paper presents the first systematic analysis of how LLMs behave when tasked with demographic-conditioned targeted messaging. We introduce a controlled evaluation framework using three leading models -- GPT-4o, Llama-3.3, and Mistral-Large 2.1 -- across two generation settings: Standalone Generation, which isolates intrinsic demographic effects, and Context-Rich Generation, which incorporates thematic and regional context to emulate realistic targeting. We evaluate generated messages along three dimensions: lexical content, language style, and persuasive framing. We instantiate this framework on climate communication and find consistent age- and gender-based asymmetries across models: male- and youth-targeted messages emphasize agency, innovation, and assertiveness, while female- and senior-targeted messages stress warmth, care, and tradition. Contextual prompts systematically amplify these disparities, with persuasion scores significantly higher for messages tailored to younger or male audiences. Our findings demonstrate how demographic stereotypes can surface and intensify in LLM-generated targeted communication, underscoring the need for bias-aware generation pipelines and transparent auditing frameworks that explicitly account for demographic conditioning in socially sensitive applications.</p>"
    },
    {
      "id": "21c96582822a",
      "title": "Robust Privacy: Inference-Time Privacy through Certified Robustness",
      "content": "arXiv:2601.17360v1 Announce Type: cross  Abstract: Machine learning systems can produce personalized outputs that allow an adversary to infer sensitive input attributes at inference time. We introduce Robust Privacy (RP), an inference-time privacy notion inspired by certified robustness: if a model's prediction is provably invariant within a radius-$R$ neighborhood around an input $x$ (e.g., under the $\\ell_2$ norm), then $x$ enjoys $R$-Robust Privacy, i.e., observing the prediction cannot distinguish $x$ from any input within distance $R$ of $x$. We further develop Attribute Privacy Enhancement (APE) to translate input-level invariance into an attribute-level privacy effect. In a controlled recommendation task where the decision depends primarily on a sensitive attribute, we show that RP expands the set of sensitive-attribute values compatible with a positive recommendation, expanding the inference interval accordingly. Finally, we empirically demonstrate that RP also mitigates model inversion attacks (MIAs) by masking fine-grained input-output dependence. Even at small noise levels ($\\sigma=0.1$), RP reduces the attack success rate (ASR) from 73% to 4% with partial model performance degradation. RP can also partially mitigate MIAs (e.g., ASR drops to 44%) with no model performance degradation.",
      "url": "http://arxiv.org/abs/2601.17360",
      "author": "Jiankai Jin, Xiangzheng Zhang, Zhao Liu, Deyue Zhang, Quanchen Zou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces Robust Privacy, a novel inference-time privacy notion inspired by certified robustness. Develops Attribute Privacy Enhancement to translate input invariance to attribute-level privacy.",
      "importance_score": 65,
      "reasoning": "Novel privacy framework connecting certified robustness to inference privacy. Principled approach with theoretical grounding.",
      "themes": [
        "Privacy",
        "Certified Robustness",
        "Inference Security"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Robust Privacy, a novel inference-time privacy notion inspired by certified robustness. Develops Attribute Privacy Enhancement to translate input invariance to attribute-level privacy.</p>",
      "content_html": "<p>arXiv:2601.17360v1 Announce Type: cross  Abstract: Machine learning systems can produce personalized outputs that allow an adversary to infer sensitive input attributes at inference time. We introduce Robust Privacy (RP), an inference-time privacy notion inspired by certified robustness: if a model's prediction is provably invariant within a radius-$R$ neighborhood around an input $x$ (e.g., under the $\\ell_2$ norm), then $x$ enjoys $R$-Robust Privacy, i.e., observing the prediction cannot distinguish $x$ from any input within distance $R$ of $x$. We further develop Attribute Privacy Enhancement (APE) to translate input-level invariance into an attribute-level privacy effect. In a controlled recommendation task where the decision depends primarily on a sensitive attribute, we show that RP expands the set of sensitive-attribute values compatible with a positive recommendation, expanding the inference interval accordingly. Finally, we empirically demonstrate that RP also mitigates model inversion attacks (MIAs) by masking fine-grained input-output dependence. Even at small noise levels ($\\sigma=0.1$), RP reduces the attack success rate (ASR) from 73% to 4% with partial model performance degradation. RP can also partially mitigate MIAs (e.g., ASR drops to 44%) with no model performance degradation.</p>"
    },
    {
      "id": "f342fccab849",
      "title": "Automatic Stability and Recovery for Neural Network Training",
      "content": "arXiv:2601.17483v1 Announce Type: cross  Abstract: Training modern neural networks is increasingly fragile, with rare but severe destabilizing updates often causing irreversible divergence or silent performance degradation. Existing optimization methods primarily rely on preventive mechanisms embedded within the optimizer, offering limited ability to detect and recover from instability once it occurs. We introduce a supervisory runtime stability framework that treats optimization as a controlled stochastic process. By isolating an innovation signal derived from secondary measurements, such as validation probes, the framework enables automatic detection and recovery from destabilizing updates without modifying the underlying optimizer. We provide theoretical runtime safety guarantees that formalize bounded degradation and recovery. Our implementation incurs minimal overhead and is compatible with memory-constrained training settings.",
      "url": "http://arxiv.org/abs/2601.17483",
      "author": "Barak Or",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes supervisory runtime stability framework treating optimization as controlled stochastic process, enabling automatic detection and recovery from destabilizing updates without modifying optimizer.",
      "importance_score": 65,
      "reasoning": "Practical training stability solution. Addresses rare but severe training failures. Runtime safety guarantees are valuable.",
      "themes": [
        "Training Stability",
        "Optimization",
        "Deep Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes supervisory runtime stability framework treating optimization as controlled stochastic process, enabling automatic detection and recovery from destabilizing updates without modifying optimizer.</p>",
      "content_html": "<p>arXiv:2601.17483v1 Announce Type: cross  Abstract: Training modern neural networks is increasingly fragile, with rare but severe destabilizing updates often causing irreversible divergence or silent performance degradation. Existing optimization methods primarily rely on preventive mechanisms embedded within the optimizer, offering limited ability to detect and recover from instability once it occurs. We introduce a supervisory runtime stability framework that treats optimization as a controlled stochastic process. By isolating an innovation signal derived from secondary measurements, such as validation probes, the framework enables automatic detection and recovery from destabilizing updates without modifying the underlying optimizer. We provide theoretical runtime safety guarantees that formalize bounded degradation and recovery. Our implementation incurs minimal overhead and is compatible with memory-constrained training settings.</p>"
    },
    {
      "id": "afa450c6e7bb",
      "title": "TAM-Eval: Evaluating LLMs for Automated Unit Test Maintenance",
      "content": "arXiv:2601.18241v1 Announce Type: cross  Abstract: While Large Language Models (LLMs) have shown promise in software engineering, their application to unit testing remains largely confined to isolated test generation or oracle prediction, neglecting the broader challenge of test suite maintenance. We introduce TAM-Eval (Test Automated Maintenance Evaluation), a framework and benchmark designed to evaluate model performance across three core test maintenance scenarios: creation, repair, and updating of test suites. Unlike prior work limited to function-level tasks, TAM-Eval operates at the test file level, while maintaining access to full repository context during isolated evaluation, better reflecting real-world maintenance workflows. Our benchmark comprises 1,539 automatically extracted and validated scenarios from Python, Java, and Go projects. TAM-Eval supports system-agnostic evaluation of both raw LLMs and agentic workflows, using a reference-free protocol based on test suite pass rate, code coverage, and mutation testing. Empirical results indicate that state-of-the-art LLMs have limited capabilities in realistic test maintenance processes and yield only marginal improvements in test effectiveness. We release TAM-Eval as an open-source framework to support future research in automated software testing. Our data and code are publicly available at https://github.com/trndcenter/TAM-Eval.",
      "url": "http://arxiv.org/abs/2601.18241",
      "author": "Elena Bruches, Vadim Alperovich, Dari Baturova, Roman Derunets, Daniil Grebenkin, Georgy Mkrtchyan, Oleg Sedukhin, Mikhail Klementev, Ivan Bondarenko, Nikolay Bushkov, Stanislav Moiseev",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.SE"
      ],
      "summary": "Introduces TAM-Eval benchmark for evaluating LLMs on test suite maintenance including creation, repair, and updating. Provides 1,539 automatically extracted scenarios operating at test file level with full repository context.",
      "importance_score": 65,
      "reasoning": "First comprehensive benchmark for test maintenance (beyond just generation). Practical relevance for software engineering AI. File-level evaluation reflects real workflows.",
      "themes": [
        "Software Engineering",
        "Code Generation",
        "Benchmarking",
        "Test Automation"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces TAM-Eval benchmark for evaluating LLMs on test suite maintenance including creation, repair, and updating. Provides 1,539 automatically extracted scenarios operating at test file level with full repository context.</p>",
      "content_html": "<p>arXiv:2601.18241v1 Announce Type: cross  Abstract: While Large Language Models (LLMs) have shown promise in software engineering, their application to unit testing remains largely confined to isolated test generation or oracle prediction, neglecting the broader challenge of test suite maintenance. We introduce TAM-Eval (Test Automated Maintenance Evaluation), a framework and benchmark designed to evaluate model performance across three core test maintenance scenarios: creation, repair, and updating of test suites. Unlike prior work limited to function-level tasks, TAM-Eval operates at the test file level, while maintaining access to full repository context during isolated evaluation, better reflecting real-world maintenance workflows. Our benchmark comprises 1,539 automatically extracted and validated scenarios from Python, Java, and Go projects. TAM-Eval supports system-agnostic evaluation of both raw LLMs and agentic workflows, using a reference-free protocol based on test suite pass rate, code coverage, and mutation testing. Empirical results indicate that state-of-the-art LLMs have limited capabilities in realistic test maintenance processes and yield only marginal improvements in test effectiveness. We release TAM-Eval as an open-source framework to support future research in automated software testing. Our data and code are publicly available at https://github.com/trndcenter/TAM-Eval.</p>"
    },
    {
      "id": "364c8c009f95",
      "title": "Towards a Theoretical Understanding to the Generalization of RLHF",
      "content": "arXiv:2601.16403v1 Announce Type: new  Abstract: Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in high-dimensional settings remain to be explored. To this end, we build the generalization theory on RLHF of LLMs under the linear reward model, through the framework of algorithmic stability. In contrast to the existing works built upon the consistency of maximum likelihood estimations on reward model, our analysis is presented under an end-to-end learning framework, which is consistent with practice. Concretely, we prove that under a key \\textbf{feature coverage} condition, the empirical optima of policy model have a generalization bound of order $\\mathcal{O}(n^{-\\frac{1}{2}})$. Moreover, the results can be extrapolated to parameters obtained by gradient-based learning algorithms, i.e., Gradient Ascent (GA) and Stochastic Gradient Ascent (SGA). Thus, we argue that our results provide new theoretical evidence for the empirically observed generalization of LLMs after RLHF.",
      "url": "http://arxiv.org/abs/2601.16403",
      "author": "Zhaochun Li (Beijing Institute of Technolegy, Zhongguancun Academy), Mingyang Yi (Renmin University of China), Yue Wang (Zhongguancun Academy), Shisheng Cui (Beijing Institute of Technolegy), Yong Liu (Renmin University of China)",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Provides first generalization theory for RLHF of LLMs under linear reward models using algorithmic stability framework. Proves that under feature coverage conditions, empirical optimum generalizes well in an end-to-end learning framework.",
      "importance_score": 65,
      "reasoning": "Important theoretical grounding for RLHF, which is central to modern LLM alignment; addresses gap between theory and practice.",
      "themes": [
        "RLHF",
        "Alignment",
        "Generalization Theory",
        "Large Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>Provides first generalization theory for RLHF of LLMs under linear reward models using algorithmic stability framework. Proves that under feature coverage conditions, empirical optimum generalizes well in an end-to-end learning framework.</p>",
      "content_html": "<p>arXiv:2601.16403v1 Announce Type: new  Abstract: Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in high-dimensional settings remain to be explored. To this end, we build the generalization theory on RLHF of LLMs under the linear reward model, through the framework of algorithmic stability. In contrast to the existing works built upon the consistency of maximum likelihood estimations on reward model, our analysis is presented under an end-to-end learning framework, which is consistent with practice. Concretely, we prove that under a key \\textbf{feature coverage} condition, the empirical optima of policy model have a generalization bound of order $\\mathcal{O}(n^{-\\frac{1}{2}})$. Moreover, the results can be extrapolated to parameters obtained by gradient-based learning algorithms, i.e., Gradient Ascent (GA) and Stochastic Gradient Ascent (SGA). Thus, we argue that our results provide new theoretical evidence for the empirically observed generalization of LLMs after RLHF.</p>"
    },
    {
      "id": "7a6d52cd1b64",
      "title": "Endless Terminals: Scaling RL Environments for Terminal Agents",
      "content": "arXiv:2601.16443v1 Announce Type: new  Abstract: Environments are the bottleneck for self-improving agents. Current terminal benchmarks were built for evaluation, not training; reinforcement learning requires a scalable pipeline, not just a dataset. We introduce Endless Terminals, a fully autonomous pipeline that procedurally generates terminal-use tasks without human annotation. The pipeline has four stages: generating diverse task descriptions, building and validating containerized environments, producing completion tests, and filtering for solvability. From this pipeline we obtain 3255 tasks spanning file operations, log management, data processing, scripting, and database operations. We train agents using vanilla PPO with binary episode level rewards and a minimal interaction loop: no retrieval, multi-agent coordination, or specialized tools. Despite this simplicity, models trained on Endless Terminals show substantial gains: on our held-out dev set, Llama-3.2-3B improves from 4.0% to 18.2%, Qwen2.5-7B from 10.7% to 53.3%, and Qwen3-8B-openthinker-sft from 42.6% to 59.0%. These improvements transfer to human-curated benchmarks: models trained on Endless Terminals show substantial gains on held out human curated benchmarks: on TerminalBench 2.0, Llama-3.2-3B improves from 0.0% to 2.2%, Qwen2.5-7B from 2.2% to 3.4%, and Qwen3-8B-openthinker-sft from 1.1% to 6.7%, in each case outperforming alternative approaches including models with more complex agentic scaffolds. These results demonstrate that simple RL succeeds when environments scale.",
      "url": "http://arxiv.org/abs/2601.16443",
      "author": "Kanishk Gandhi, Shivam Garg, Noah D. Goodman, Dimitris Papailiopoulos",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces Endless Terminals, an autonomous pipeline for procedurally generating terminal-use tasks for RL agent training. Creates 3255 validated tasks spanning file operations, scripting, databases; agents trained with vanilla PPO.",
      "importance_score": 65,
      "reasoning": "Addresses critical bottleneck of environment generation for agent training; scalable approach with substantial benchmark contribution.",
      "themes": [
        "RL Environments",
        "AI Agents",
        "Terminal Agents",
        "Benchmark Development"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Endless Terminals, an autonomous pipeline for procedurally generating terminal-use tasks for RL agent training. Creates 3255 validated tasks spanning file operations, scripting, databases; agents trained with vanilla PPO.</p>",
      "content_html": "<p>arXiv:2601.16443v1 Announce Type: new  Abstract: Environments are the bottleneck for self-improving agents. Current terminal benchmarks were built for evaluation, not training; reinforcement learning requires a scalable pipeline, not just a dataset. We introduce Endless Terminals, a fully autonomous pipeline that procedurally generates terminal-use tasks without human annotation. The pipeline has four stages: generating diverse task descriptions, building and validating containerized environments, producing completion tests, and filtering for solvability. From this pipeline we obtain 3255 tasks spanning file operations, log management, data processing, scripting, and database operations. We train agents using vanilla PPO with binary episode level rewards and a minimal interaction loop: no retrieval, multi-agent coordination, or specialized tools. Despite this simplicity, models trained on Endless Terminals show substantial gains: on our held-out dev set, Llama-3.2-3B improves from 4.0% to 18.2%, Qwen2.5-7B from 10.7% to 53.3%, and Qwen3-8B-openthinker-sft from 42.6% to 59.0%. These improvements transfer to human-curated benchmarks: models trained on Endless Terminals show substantial gains on held out human curated benchmarks: on TerminalBench 2.0, Llama-3.2-3B improves from 0.0% to 2.2%, Qwen2.5-7B from 2.2% to 3.4%, and Qwen3-8B-openthinker-sft from 1.1% to 6.7%, in each case outperforming alternative approaches including models with more complex agentic scaffolds. These results demonstrate that simple RL succeeds when environments scale.</p>"
    },
    {
      "id": "7620ee913e13",
      "title": "A Scalable Measure of Loss Landscape Curvature for Analyzing the Training Dynamics of LLMs",
      "content": "arXiv:2601.16979v1 Announce Type: new  Abstract: Understanding the curvature evolution of the loss landscape is fundamental to analyzing the training dynamics of neural networks. The most commonly studied measure, Hessian sharpness ($\\lambda_{\\max}^H$) -- the largest eigenvalue of the loss Hessian -- determines local training stability and interacts with the learning rate throughout training. Despite its significance in analyzing training dynamics, direct measurement of Hessian sharpness remains prohibitive for Large Language Models (LLMs) due to high computational cost. We analyze $\\textit{critical sharpness}$ ($\\lambda_c$), a computationally efficient measure requiring fewer than $10$ forward passes given the update direction $\\Delta \\mathbf{\\theta}$. Critically, this measure captures well-documented Hessian sharpness phenomena, including progressive sharpening and Edge of Stability. Using this measure, we provide the first demonstration of these sharpness phenomena at scale, up to $7$B parameters, spanning both pre-training and mid-training of OLMo-2 models. We further introduce $\\textit{relative critical sharpness}$ ($\\lambda_c^{1\\to 2}$), which quantifies the curvature of one loss landscape while optimizing another, to analyze the transition from pre-training to fine-tuning and guide data mixing strategies. Critical sharpness provides practitioners with a practical tool for diagnosing curvature dynamics and informing data composition choices at scale. More broadly, our work shows that scalable curvature measures can provide actionable insights for large-scale training.",
      "url": "http://arxiv.org/abs/2601.16979",
      "author": "Dayal Singh Kalra, Jean-Christophe Gagnon-Audet, Andrey Gromov, Ishita Mediratta, Kelvin Niu, Alexander H Miller, Michael Shvartsman",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces 'critical sharpness' as computationally efficient measure of loss landscape curvature for LLMs, requiring fewer than 10 forward passes. Shows it captures important aspects of Hessian sharpness.",
      "importance_score": 65,
      "reasoning": "Addresses important gap in understanding LLM training dynamics; scalable measure enables analysis previously impossible.",
      "themes": [
        "LLM Training",
        "Loss Landscape",
        "Optimization",
        "Training Dynamics"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces 'critical sharpness' as computationally efficient measure of loss landscape curvature for LLMs, requiring fewer than 10 forward passes. Shows it captures important aspects of Hessian sharpness.</p>",
      "content_html": "<p>arXiv:2601.16979v1 Announce Type: new  Abstract: Understanding the curvature evolution of the loss landscape is fundamental to analyzing the training dynamics of neural networks. The most commonly studied measure, Hessian sharpness ($\\lambda_{\\max}^H$) -- the largest eigenvalue of the loss Hessian -- determines local training stability and interacts with the learning rate throughout training. Despite its significance in analyzing training dynamics, direct measurement of Hessian sharpness remains prohibitive for Large Language Models (LLMs) due to high computational cost. We analyze $\\textit{critical sharpness}$ ($\\lambda_c$), a computationally efficient measure requiring fewer than $10$ forward passes given the update direction $\\Delta \\mathbf{\\theta}$. Critically, this measure captures well-documented Hessian sharpness phenomena, including progressive sharpening and Edge of Stability. Using this measure, we provide the first demonstration of these sharpness phenomena at scale, up to $7$B parameters, spanning both pre-training and mid-training of OLMo-2 models. We further introduce $\\textit{relative critical sharpness}$ ($\\lambda_c^{1\\to 2}$), which quantifies the curvature of one loss landscape while optimizing another, to analyze the transition from pre-training to fine-tuning and guide data mixing strategies. Critical sharpness provides practitioners with a practical tool for diagnosing curvature dynamics and informing data composition choices at scale. More broadly, our work shows that scalable curvature measures can provide actionable insights for large-scale training.</p>"
    },
    {
      "id": "f88b65528e11",
      "title": "Reward-Forcing: Autoregressive Video Generation with Reward Feedback",
      "content": "arXiv:2601.16933v1 Announce Type: cross  Abstract: While most prior work in video generation relies on bidirectional architectures, recent efforts have sought to adapt these models into autoregressive variants to support near real-time generation. However, such adaptations often depend heavily on teacher models, which can limit performance, particularly in the absence of a strong autoregressive teacher, resulting in output quality that typically lags behind their bidirectional counterparts. In this paper, we explore an alternative approach that uses reward signals to guide the generation process, enabling more efficient and scalable autoregressive generation. By using reward signals to guide the model, our method simplifies training while preserving high visual fidelity and temporal consistency. Through extensive experiments on standard benchmarks, we find that our approach performs comparably to existing autoregressive models and, in some cases, surpasses similarly sized bidirectional models by avoiding constraints imposed by teacher architectures. For example, on VBench, our method achieves a total score of 84.92, closely matching state-of-the-art autoregressive methods that score 84.31 but require significant heterogeneous distillation.",
      "url": "http://arxiv.org/abs/2601.16933",
      "author": "Jingran Zhang, Ning Li, Yuanhao Ban, Andrew Bai, Justin Cui",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes Reward-Forcing approach for autoregressive video generation using reward signals instead of teacher model distillation. Enables efficient and scalable video generation while preserving visual fidelity and temporal consistency.",
      "importance_score": 65,
      "reasoning": "Novel training paradigm for video generation that addresses teacher model dependency. Practical contribution but incremental advance.",
      "themes": [
        "Video Generation",
        "Reinforcement Learning",
        "Generative Models"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Reward-Forcing approach for autoregressive video generation using reward signals instead of teacher model distillation. Enables efficient and scalable video generation while preserving visual fidelity and temporal consistency.</p>",
      "content_html": "<p>arXiv:2601.16933v1 Announce Type: cross  Abstract: While most prior work in video generation relies on bidirectional architectures, recent efforts have sought to adapt these models into autoregressive variants to support near real-time generation. However, such adaptations often depend heavily on teacher models, which can limit performance, particularly in the absence of a strong autoregressive teacher, resulting in output quality that typically lags behind their bidirectional counterparts. In this paper, we explore an alternative approach that uses reward signals to guide the generation process, enabling more efficient and scalable autoregressive generation. By using reward signals to guide the model, our method simplifies training while preserving high visual fidelity and temporal consistency. Through extensive experiments on standard benchmarks, we find that our approach performs comparably to existing autoregressive models and, in some cases, surpasses similarly sized bidirectional models by avoiding constraints imposed by teacher architectures. For example, on VBench, our method achieves a total score of 84.92, closely matching state-of-the-art autoregressive methods that score 84.31 but require significant heterogeneous distillation.</p>"
    },
    {
      "id": "043ad757b06f",
      "title": "On the Emergence and Test-Time Use of Structural Information in Large Language Models",
      "content": "arXiv:2601.17869v1 Announce Type: new  Abstract: Learning structural information from observational data is central to producing new knowledge outside the training corpus. This holds for mechanistic understanding in scientific discovery as well as flexible test-time compositional generation. We thus study how language models learn abstract structures and utilize the learnt structural information at test-time. To ensure a controlled setup, we design a natural language dataset based on linguistic structural transformations. We empirically show that the emergence of learning structural information correlates with complex reasoning tasks, and that the ability to perform test-time compositional generation remains limited.",
      "url": "http://arxiv.org/abs/2601.17869",
      "author": "Michelle Chao Chen, Moritz Miller, Bernhard Sch\\\"olkopf, Siyuan Guo",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Studies how LLMs learn abstract structures from observational data and use them for test-time compositional generation. Uses controlled dataset of linguistic structural transformations.",
      "importance_score": 65,
      "reasoning": "Important question about LLM generalization and structure learning. Controlled methodology provides clear insights.",
      "themes": [
        "Compositional Generalization",
        "Language Models",
        "Structure Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Studies how LLMs learn abstract structures from observational data and use them for test-time compositional generation. Uses controlled dataset of linguistic structural transformations.</p>",
      "content_html": "<p>arXiv:2601.17869v1 Announce Type: new  Abstract: Learning structural information from observational data is central to producing new knowledge outside the training corpus. This holds for mechanistic understanding in scientific discovery as well as flexible test-time compositional generation. We thus study how language models learn abstract structures and utilize the learnt structural information at test-time. To ensure a controlled setup, we design a natural language dataset based on linguistic structural transformations. We empirically show that the emergence of learning structural information correlates with complex reasoning tasks, and that the ability to perform test-time compositional generation remains limited.</p>"
    },
    {
      "id": "92fd954243cd",
      "title": "FABLE: Forest-Based Adaptive Bi-Path LLM-Enhanced Retrieval for Multi-Document Reasoning",
      "content": "arXiv:2601.18116v1 Announce Type: new  Abstract: The rapid expansion of long-context Large Language Models (LLMs) has reignited debate on whether Retrieval-Augmented Generation (RAG) remains necessary. However, empirical evidence reveals persistent limitations of long-context inference, including the lost-in-the-middle phenomenon, high computational cost, and poor scalability for multi-document reasoning. Conversely, traditional RAG systems, while efficient, are constrained by flat chunk-level retrieval that introduces semantic noise and fails to support structured cross-document synthesis.   We present \\textbf{FABLE}, a \\textbf{F}orest-based \\textbf{A}daptive \\textbf{B}i-path \\textbf{L}LM-\\textbf{E}nhanced retrieval framework that integrates LLMs into both knowledge organization and retrieval. FABLE constructs LLM-enhanced hierarchical forest indexes with multi-granularity semantic structures, then employs a bi-path strategy combining LLM-guided hierarchical traversal with structure-aware propagation for fine-grained evidence acquisition, with explicit budget control for adaptive efficiency trade-offs.   Extensive experiments demonstrate that FABLE consistently outperforms SOTA RAG methods and achieves comparable accuracy to full-context LLM inference with up to 94\\% token reduction, showing that long-context LLMs amplify rather than fully replace the need for structured retrieval.",
      "url": "http://arxiv.org/abs/2601.18116",
      "author": "Lin Sun, Linglin Zhang, Jingang Huang, Change Jia, Zhengwei Cheng, Xiangzheng Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents FABLE, a forest-based adaptive bi-path RAG framework for multi-document reasoning integrating LLMs into both knowledge organization and retrieval. Addresses long-context limitations.",
      "importance_score": 65,
      "reasoning": "Comprehensive RAG framework addressing multiple limitations of existing approaches. Well-motivated design choices.",
      "themes": [
        "RAG",
        "Multi-Document QA",
        "Long Context"
      ],
      "continuation": null,
      "summary_html": "<p>Presents FABLE, a forest-based adaptive bi-path RAG framework for multi-document reasoning integrating LLMs into both knowledge organization and retrieval. Addresses long-context limitations.</p>",
      "content_html": "<p>arXiv:2601.18116v1 Announce Type: new  Abstract: The rapid expansion of long-context Large Language Models (LLMs) has reignited debate on whether Retrieval-Augmented Generation (RAG) remains necessary. However, empirical evidence reveals persistent limitations of long-context inference, including the lost-in-the-middle phenomenon, high computational cost, and poor scalability for multi-document reasoning. Conversely, traditional RAG systems, while efficient, are constrained by flat chunk-level retrieval that introduces semantic noise and fails to support structured cross-document synthesis.   We present \\textbf{FABLE}, a \\textbf{F}orest-based \\textbf{A}daptive \\textbf{B}i-path \\textbf{L}LM-\\textbf{E}nhanced retrieval framework that integrates LLMs into both knowledge organization and retrieval. FABLE constructs LLM-enhanced hierarchical forest indexes with multi-granularity semantic structures, then employs a bi-path strategy combining LLM-guided hierarchical traversal with structure-aware propagation for fine-grained evidence acquisition, with explicit budget control for adaptive efficiency trade-offs.   Extensive experiments demonstrate that FABLE consistently outperforms SOTA RAG methods and achieves comparable accuracy to full-context LLM inference with up to 94\\% token reduction, showing that long-context LLMs amplify rather than fully replace the need for structured retrieval.</p>"
    },
    {
      "id": "ac4ede6e124c",
      "title": "AVMeme Exam: A Multimodal Multilingual Multicultural Benchmark for LLMs' Contextual and Cultural Knowledge and Thinking",
      "content": "arXiv:2601.17645v1 Announce Type: cross  Abstract: Internet audio-visual clips convey meaning through time-varying sound and motion, which extend beyond what text alone can represent. To examine whether AI models can understand such signals in human cultural contexts, we introduce AVMeme Exam, a human-curated benchmark of over one thousand iconic Internet sounds and videos spanning speech, songs, music, and sound effects. Each meme is paired with a unique Q&amp;A assessing levels of understanding from surface content to context and emotion to usage and world knowledge, along with metadata such as original year, transcript, summary, and sensitivity. We systematically evaluate state-of-the-art multimodal large language models (MLLMs) alongside human participants using this benchmark. Our results reveal a consistent limitation: current models perform poorly on textless music and sound effects, and struggle to think in context and in culture compared to surface content. These findings highlight a key gap in human-aligned multimodal intelligence and call for models that can perceive contextually and culturally beyond the surface of what they hear and see. Project page: avmemeexam.github.io/public",
      "url": "http://arxiv.org/abs/2601.17645",
      "author": "Xilin Jiang, Qiaolin Wang, Junkai Wu, Xiaomin He, Zhongweiyang Xu, Yinghao Ma, Minshuo Piao, Kaiyi Yang, Xiuwen Zheng, Riki Shimizu, Yicong Chen, Arsalan Firoozi, Gavin Mischler, Sukru Samet Dindar, Richard Antonello, Linyang He, Tsun-An Hsieh, Xulin Fan, Yulun Wu, Yuesheng Ma, Chaitanya Amballa, Weixiong Chen, Jiarui Hai, Ruisi Li, Vishal Choudhari, Cong Han, Yinghao Aaron Li, Adeen Flinker, Mounya Elhilali, Emmanouil Benetos, Mark Hasegawa-Johnson, Romit Roy Choudhury, Nima Mesgarani",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.SD"
      ],
      "summary": "Presents AVMeme Exam, a benchmark of 1000+ iconic internet audio-visual clips spanning multiple languages/cultures, with Q&A assessing understanding from surface content to cultural context. Shows significant human-AI performance gaps.",
      "importance_score": 65,
      "reasoning": "Novel multimodal benchmark addressing cultural understanding gap. Useful for evaluating real-world AI capabilities.",
      "themes": [
        "Benchmarks",
        "Multimodal AI",
        "Cultural Understanding",
        "Audio-Visual"
      ],
      "continuation": null,
      "summary_html": "<p>Presents AVMeme Exam, a benchmark of 1000+ iconic internet audio-visual clips spanning multiple languages/cultures, with Q&amp;A assessing understanding from surface content to cultural context. Shows significant human-AI performance gaps.</p>",
      "content_html": "<p>arXiv:2601.17645v1 Announce Type: cross  Abstract: Internet audio-visual clips convey meaning through time-varying sound and motion, which extend beyond what text alone can represent. To examine whether AI models can understand such signals in human cultural contexts, we introduce AVMeme Exam, a human-curated benchmark of over one thousand iconic Internet sounds and videos spanning speech, songs, music, and sound effects. Each meme is paired with a unique Q&amp;A assessing levels of understanding from surface content to context and emotion to usage and world knowledge, along with metadata such as original year, transcript, summary, and sensitivity. We systematically evaluate state-of-the-art multimodal large language models (MLLMs) alongside human participants using this benchmark. Our results reveal a consistent limitation: current models perform poorly on textless music and sound effects, and struggle to think in context and in culture compared to surface content. These findings highlight a key gap in human-aligned multimodal intelligence and call for models that can perceive contextually and culturally beyond the surface of what they hear and see. Project page: avmemeexam.github.io/public</p>"
    },
    {
      "id": "54f0a52c9cac",
      "title": "Performance uncertainty in medical image analysis: a large-scale investigation of confidence intervals",
      "content": "arXiv:2601.17103v1 Announce Type: new  Abstract: Performance uncertainty quantification is essential for reliable validation and eventual clinical translation of medical imaging artificial intelligence (AI). Confidence intervals (CIs) play a central role in this process by indicating how precise a reported performance estimate is. Yet, due to the limited amount of work examining CI behavior in medical imaging, the community remains largely unaware of how many diverse CI methods exist and how they behave in specific settings. The purpose of this study is to close this gap. To this end, we conducted a large-scale empirical analysis across a total of 24 segmentation and classification tasks, using 19 trained models per task group, a broad spectrum of commonly used performance metrics, multiple aggregation strategies, and several widely adopted CI methods. Reliability (coverage) and precision (width) of each CI method were estimated across all settings to characterize their dependence on study characteristics. Our analysis revealed five principal findings: 1) the sample size required for reliable CIs varies from a few dozens to several thousands of cases depending on study parameters; 2) CI behavior is strongly affected by the choice of performance metric; 3) aggregation strategy substantially influences the reliability of CIs, e.g. they require more observations for macro than for micro; 4) the machine learning problem (segmentation versus classification) modulates these effects; 5) different CI methods are not equally reliable and precise depending on the use case. These results form key components for the development of future guidelines on reporting performance uncertainty in medical imaging AI.",
      "url": "http://arxiv.org/abs/2601.17103",
      "author": "Pascaline Andr\\'e (Sorbonne Universit\\'e, Institut du Cerveau - Paris Brain Institute - ICM, CNRS, Inria, Inserm, AP-HP, H\\^opital de la Piti\\'e-Salp\\^etri\\`ere, F-75013, Paris, France), Charles Heitz (Sorbonne Universit\\'e, Institut du Cerveau - Paris Brain Institute - ICM, CNRS, Inria, Inserm, AP-HP, H\\^opital de la Piti\\'e-Salp\\^etri\\`ere, F-75013, Paris, France), Evangelia Christodoulou (German Cancer Research Center), Annika Reinke (German Cancer Research Center), Carole H. Sudre (Unit for Lifelong Health and Ageing at UCL, Department of Population Science and Experimental Medicine and Hawkes InstituteCentre for Medical Image Computing, Department of Computer Science, University College London, UK), Michela Antonelli (School of Biomedical Engineering and Imaging Science, King's College London, UK), Patrick Godau (German Cancer Research Center), M. Jorge Cardoso (School of Biomedical Engineering and Imaging Science, King's College London, UK), Antoine Gilson (Sorbonne Universit\\'e, Institut du Cerveau - Paris Brain Institute - ICM, CNRS, Inria, Inserm, AP-HP, H\\^opital de la Piti\\'e-Salp\\^etri\\`ere, F-75013, Paris, France), Sophie Tezenas du Montcel (Sorbonne Universit\\'e, Institut du Cerveau - Paris Brain Institute - ICM, CNRS, Inria, Inserm, AP-HP, H\\^opital de la Piti\\'e-Salp\\^etri\\`ere, F-75013, Paris, France), Ga\\\"el Varoquaux (SODA project team, Inria Saclay-\\^Ile-de-France, France), Lena Maier-Hein (German Cancer Research Center), Olivier Colliot (Sorbonne Universit\\'e, Institut du Cerveau - Paris Brain Institute - ICM, CNRS, Inria, Inserm, AP-HP, H\\^opital de la Piti\\'e-Salp\\^etri\\`ere, F-75013, Paris, France)",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Large-scale empirical analysis of confidence interval methods for medical imaging AI across 24 tasks and 19 models, examining coverage behavior under different conditions for clinical translation.",
      "importance_score": 65,
      "reasoning": "Important methodological contribution for reliable medical AI validation. Comprehensive empirical study with practical implications.",
      "themes": [
        "Medical AI",
        "Uncertainty Quantification",
        "Evaluation Methods"
      ],
      "continuation": null,
      "summary_html": "<p>Large-scale empirical analysis of confidence interval methods for medical imaging AI across 24 tasks and 19 models, examining coverage behavior under different conditions for clinical translation.</p>",
      "content_html": "<p>arXiv:2601.17103v1 Announce Type: new  Abstract: Performance uncertainty quantification is essential for reliable validation and eventual clinical translation of medical imaging artificial intelligence (AI). Confidence intervals (CIs) play a central role in this process by indicating how precise a reported performance estimate is. Yet, due to the limited amount of work examining CI behavior in medical imaging, the community remains largely unaware of how many diverse CI methods exist and how they behave in specific settings. The purpose of this study is to close this gap. To this end, we conducted a large-scale empirical analysis across a total of 24 segmentation and classification tasks, using 19 trained models per task group, a broad spectrum of commonly used performance metrics, multiple aggregation strategies, and several widely adopted CI methods. Reliability (coverage) and precision (width) of each CI method were estimated across all settings to characterize their dependence on study characteristics. Our analysis revealed five principal findings: 1) the sample size required for reliable CIs varies from a few dozens to several thousands of cases depending on study parameters; 2) CI behavior is strongly affected by the choice of performance metric; 3) aggregation strategy substantially influences the reliability of CIs, e.g. they require more observations for macro than for micro; 4) the machine learning problem (segmentation versus classification) modulates these effects; 5) different CI methods are not equally reliable and precise depending on the use case. These results form key components for the development of future guidelines on reporting performance uncertainty in medical imaging AI.</p>"
    },
    {
      "id": "9060107de991",
      "title": "Beyond Rigid: Benchmarking Non-Rigid Video Editing",
      "content": "arXiv:2601.18340v1 Announce Type: new  Abstract: Despite the remarkable progress in text-driven video editing, generating coherent non-rigid deformations remains a critical challenge, often plagued by physical distortion and temporal flicker. To bridge this gap, we propose NRVBench, the first dedicated and comprehensive benchmark designed to evaluate non-rigid video editing. First, we curate a high-quality dataset consisting of 180 non-rigid motion videos from six physics-based categories, equipped with 2,340 fine-grained task instructions and 360 multiple-choice questions. Second, we propose NRVE-Acc, a novel evaluation metric based on Vision-Language Models that can rigorously assess physical compliance, temporal consistency, and instruction alignment, overcoming the limitations of general metrics in capturing complex dynamics. Third, we introduce a training-free baseline, VM-Edit, which utilizes a dual-region denoising mechanism to achieve structure-aware control, balancing structural preservation and dynamic deformation. Extensive experiments demonstrate that while current methods have shortcomings in maintaining physical plausibility, our method achieves excellent performance across both standard and proposed metrics. We believe the benchmark could serve as a standard testing platform for advancing physics-aware video editing.",
      "url": "http://arxiv.org/abs/2601.18340",
      "author": "Bingzheng Qu, Kehai Chen, Xuefeng Bai, Jun Yu, Min Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "NRVBench introduces the first comprehensive benchmark for non-rigid video editing with 180 videos across 6 physics-based categories, 2,340 task instructions, and novel NRVE-Acc evaluation metric.",
      "importance_score": 65,
      "reasoning": "Important benchmark contribution for video generation evaluation. Addresses critical gap in evaluating physical coherence.",
      "themes": [
        "Video Editing",
        "Benchmarks",
        "Video Generation"
      ],
      "continuation": null,
      "summary_html": "<p>NRVBench introduces the first comprehensive benchmark for non-rigid video editing with 180 videos across 6 physics-based categories, 2,340 task instructions, and novel NRVE-Acc evaluation metric.</p>",
      "content_html": "<p>arXiv:2601.18340v1 Announce Type: new  Abstract: Despite the remarkable progress in text-driven video editing, generating coherent non-rigid deformations remains a critical challenge, often plagued by physical distortion and temporal flicker. To bridge this gap, we propose NRVBench, the first dedicated and comprehensive benchmark designed to evaluate non-rigid video editing. First, we curate a high-quality dataset consisting of 180 non-rigid motion videos from six physics-based categories, equipped with 2,340 fine-grained task instructions and 360 multiple-choice questions. Second, we propose NRVE-Acc, a novel evaluation metric based on Vision-Language Models that can rigorously assess physical compliance, temporal consistency, and instruction alignment, overcoming the limitations of general metrics in capturing complex dynamics. Third, we introduce a training-free baseline, VM-Edit, which utilizes a dual-region denoising mechanism to achieve structure-aware control, balancing structural preservation and dynamic deformation. Extensive experiments demonstrate that while current methods have shortcomings in maintaining physical plausibility, our method achieves excellent performance across both standard and proposed metrics. We believe the benchmark could serve as a standard testing platform for advancing physics-aware video editing.</p>"
    },
    {
      "id": "43325bab81f6",
      "title": "Self-Refining Video Sampling",
      "content": "arXiv:2601.18577v1 Announce Type: new  Abstract: Modern video generators still struggle with complex physical dynamics, often falling short of physical realism. Existing approaches address this using external verifiers or additional training on augmented data, which is computationally expensive and still limited in capturing fine-grained motion. In this work, we present self-refining video sampling, a simple method that uses a pre-trained video generator trained on large-scale datasets as its own self-refiner. By interpreting the generator as a denoising autoencoder, we enable iterative inner-loop refinement at inference time without any external verifier or additional training. We further introduce an uncertainty-aware refinement strategy that selectively refines regions based on self-consistency, which prevents artifacts caused by over-refinement. Experiments on state-of-the-art video generators demonstrate significant improvements in motion coherence and physics alignment, achieving over 70\\% human preference compared to the default sampler and guidance-based sampler.",
      "url": "http://arxiv.org/abs/2601.18577",
      "author": "Sangwon Jang, Taekyung Ki, Jaehyeong Jo, Saining Xie, Jaehong Yoon, Sung Ju Hwang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Self-refining video sampling uses pre-trained video generator as its own self-refiner through denoising autoencoder interpretation, enabling inference-time refinement without external verifiers or additional training.",
      "importance_score": 65,
      "reasoning": "Elegant inference-time improvement for video generation. Simple method with broad applicability. Addresses physical realism without external tools.",
      "themes": [
        "Video Generation",
        "Self-Improvement",
        "Inference Optimization"
      ],
      "continuation": null,
      "summary_html": "<p>Self-refining video sampling uses pre-trained video generator as its own self-refiner through denoising autoencoder interpretation, enabling inference-time refinement without external verifiers or additional training.</p>",
      "content_html": "<p>arXiv:2601.18577v1 Announce Type: new  Abstract: Modern video generators still struggle with complex physical dynamics, often falling short of physical realism. Existing approaches address this using external verifiers or additional training on augmented data, which is computationally expensive and still limited in capturing fine-grained motion. In this work, we present self-refining video sampling, a simple method that uses a pre-trained video generator trained on large-scale datasets as its own self-refiner. By interpreting the generator as a denoising autoencoder, we enable iterative inner-loop refinement at inference time without any external verifier or additional training. We further introduce an uncertainty-aware refinement strategy that selectively refines regions based on self-consistency, which prevents artifacts caused by over-refinement. Experiments on state-of-the-art video generators demonstrate significant improvements in motion coherence and physics alignment, achieving over 70\\% human preference compared to the default sampler and guidance-based sampler.</p>"
    },
    {
      "id": "d7c37a6e0f7a",
      "title": "TC-IDM: Grounding Video Generation for Executable Zero-shot Robot Motion",
      "content": "arXiv:2601.18323v1 Announce Type: new  Abstract: The vision-language-action (VLA) paradigm has enabled powerful robotic control by leveraging vision-language models, but its reliance on large-scale, high-quality robot data limits its generalization. Generative world models offer a promising alternative for general-purpose embodied AI, yet a critical gap remains between their pixel-level plans and physically executable actions.   To this end, we propose the Tool-Centric Inverse Dynamics Model (TC-IDM). By focusing on the tool's imagined trajectory as synthesized by the world model, TC-IDM establishes a robust intermediate representation that bridges the gap between visual planning and physical control.   TC-IDM extracts the tool's point cloud trajectories via segmentation and 3D motion estimation from generated videos. Considering diverse tool attributes, our architecture employs decoupled action heads to project these planned trajectories into 6-DoF end-effector motions and corresponding control signals.   This plan-and-translate paradigm not only supports a wide range of end-effectors but also significantly improves viewpoint invariance. Furthermore, it exhibits strong generalization capabilities across long-horizon and out-of-distribution tasks, including interacting with deformable objects.   In real-world evaluations, the world model with TC-IDM achieves an average success rate of 61.11 percent, with 77.7 percent on simple tasks and 38.46 percent on zero-shot deformable object tasks. It substantially outperforms end-to-end VLA-style baselines and other inverse dynamics models.",
      "url": "http://arxiv.org/abs/2601.18323",
      "author": "Weishi Mi, Yong Bao, Xiaowei Chi, Xiaozhu Ju, Zhiyuan Qin, Kuangzhi Ge, Kai Tang, Peidong Jia, Shanghang Zhang, Jian Tang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes TC-IDM that bridges world model video generation and robot action by focusing on tool's imagined trajectory as intermediate representation.",
      "importance_score": 65,
      "reasoning": "Important contribution connecting video generation world models to executable robot actions, addresses key gap in embodied AI.",
      "themes": [
        "World Models",
        "Robot Control",
        "Video Generation",
        "Embodied AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes TC-IDM that bridges world model video generation and robot action by focusing on tool's imagined trajectory as intermediate representation.</p>",
      "content_html": "<p>arXiv:2601.18323v1 Announce Type: new  Abstract: The vision-language-action (VLA) paradigm has enabled powerful robotic control by leveraging vision-language models, but its reliance on large-scale, high-quality robot data limits its generalization. Generative world models offer a promising alternative for general-purpose embodied AI, yet a critical gap remains between their pixel-level plans and physically executable actions.   To this end, we propose the Tool-Centric Inverse Dynamics Model (TC-IDM). By focusing on the tool's imagined trajectory as synthesized by the world model, TC-IDM establishes a robust intermediate representation that bridges the gap between visual planning and physical control.   TC-IDM extracts the tool's point cloud trajectories via segmentation and 3D motion estimation from generated videos. Considering diverse tool attributes, our architecture employs decoupled action heads to project these planned trajectories into 6-DoF end-effector motions and corresponding control signals.   This plan-and-translate paradigm not only supports a wide range of end-effectors but also significantly improves viewpoint invariance. Furthermore, it exhibits strong generalization capabilities across long-horizon and out-of-distribution tasks, including interacting with deformable objects.   In real-world evaluations, the world model with TC-IDM achieves an average success rate of 61.11 percent, with 77.7 percent on simple tasks and 38.46 percent on zero-shot deformable object tasks. It substantially outperforms end-to-end VLA-style baselines and other inverse dynamics models.</p>"
    },
    {
      "id": "82259f46db9c",
      "title": "Claudes Constitutional Structure",
      "content": "Claudes Constitution is an extraordinary document, and will be this weeks focus. Its aim is nothing less than helping humanity transition to a world of powerful AI (also known variously as AGI, transformative AI, superintelligence or my current name of choice sufficiently advanced AI. The constitution is written with Claude in mind, although it is highly readable for humans, and would serve as a fine employee manual or general set of advice for a human, modulo the parts that wouldnt make sense in context. This link goes to the full text of Claudes constitution, the official version of what we previously were calling its soul document. As they note at the end, the document can and will be revised over time. It was driven by Amanda Askell and Joe Carlsmith. There are places it can be improved. I do not believe this approach alone is sufficient for the challenges ahead. But it is by far the best approach being tried today and can hopefully enable the next level. Overall this is an amazingly great document, and weve all seen the results. Ill be covering the Constitution in three parts. This first post is a descriptive look at the structure and design of the Constitution The second post is an analysis of the Constitutions (virtue) ethical framework. The final post on Wednesday will deal with tensions and open problems. Both posts are written primarily with human readers in mind, while still of course also talking to Claude (hello there!). Table of Contents How Anthropic Describes The Constitution. Decision Theory And Acausal Trade. AI and Alignment Are The Final Exam Of Philosophy. Values and Judgment Versus Rules. The Fourth Framework. Core Values. The Three Principles. Help Is On The Way. What Was I Made For? Do The Right Thing. How Anthropic Describes The Constitution Anthropic: Claudes constitution is a detailed description of Anthropics intentions for Claudes values and behavior. It plays a crucial role in our training process, and its content directly...",
      "url": "https://www.lesswrong.com/posts/ArNGbGfki7MNMnfGD/claude-s-constitutional-structure",
      "author": "Zvi",
      "published": "2026-01-26T10:40:17.028000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Zvi's detailed analysis of Claude's constitution structure, examining how Anthropic has designed Claude's values and behaviors. Part one of a three-part series examining the document's design philosophy and implications.",
      "importance_score": 65,
      "reasoning": "Substantive expert analysis of an important AI safety document from a well-respected analyst. Provides useful interpretation and critique of Anthropic's constitutional AI approach.",
      "themes": [
        "Constitutional AI",
        "AI Alignment",
        "Anthropic",
        "AI Values"
      ],
      "continuation": null,
      "summary_html": "<p>Zvi's detailed analysis of Claude's constitution structure, examining how Anthropic has designed Claude's values and behaviors. Part one of a three-part series examining the document's design philosophy and implications.</p>",
      "content_html": "<p>Claudes Constitution is an extraordinary document, and will be this weeks focus. Its aim is nothing less than helping humanity transition to a world of powerful AI (also known variously as AGI, transformative AI, superintelligence or my current name of choice sufficiently advanced AI. The constitution is written with Claude in mind, although it is highly readable for humans, and would serve as a fine employee manual or general set of advice for a human, modulo the parts that wouldnt make sense in context. This link goes to the full text of Claudes constitution, the official version of what we previously were calling its soul document. As they note at the end, the document can and will be revised over time. It was driven by Amanda Askell and Joe Carlsmith. There are places it can be improved. I do not believe this approach alone is sufficient for the challenges ahead. But it is by far the best approach being tried today and can hopefully enable the next level. Overall this is an amazingly great document, and weve all seen the results. Ill be covering the Constitution in three parts. This first post is a descriptive look at the structure and design of the Constitution The second post is an analysis of the Constitutions (virtue) ethical framework. The final post on Wednesday will deal with tensions and open problems. Both posts are written primarily with human readers in mind, while still of course also talking to Claude (hello there!). Table of Contents How Anthropic Describes The Constitution. Decision Theory And Acausal Trade. AI and Alignment Are The Final Exam Of Philosophy. Values and Judgment Versus Rules. The Fourth Framework. Core Values. The Three Principles. Help Is On The Way. What Was I Made For? Do The Right Thing. How Anthropic Describes The Constitution Anthropic: Claudes constitution is a detailed description of Anthropics intentions for Claudes values and behavior. It plays a crucial role in our training process, and its content directly...</p>"
    },
    {
      "id": "efc4051f1b41",
      "title": "A Syllogistic Probe: Tracing the Evolution of Logic Reasoning in Large Language Models",
      "content": "arXiv:2601.17426v1 Announce Type: new  Abstract: Human logic has gradually shifted from intuition-driven inference to rigorous formal systems. Motivated by recent advances in large language models (LLMs), we explore whether LLMs exhibit a similar evolution in the underlying logical framework. Using existential import as a probe, we for evaluate syllogism under traditional and modern logic. Through extensive experiments of testing SOTA LLMs on a new syllogism dataset, we have some interesting findings: (i) Model size scaling promotes the shift toward modern logic; (ii) Thinking serves as an efficient accelerator beyond parameter scaling; (iii) the Base model plays a crucial role in determining how easily and stably this shift can emerge. Beyond these core factors, we conduct additional experiments for in-depth analysis of properties of current LLMs on syllogistic reasoning.",
      "url": "http://arxiv.org/abs/2601.17426",
      "author": "Zhengqing Zang, Yuqi Ding, Yanmei Gu, Changkai Song, Zhengkai Yang, Guoping Du, Junbo Zhao, Haobo Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Uses syllogistic reasoning with existential import as a probe to trace how LLMs evolve from intuition-driven to formal logic, finding that model scaling and thinking capabilities accelerate this shift.",
      "importance_score": 64,
      "reasoning": "Novel interpretability approach revealing interesting patterns about reasoning evolution in LLMs; new dataset and insights about scaling effects.",
      "themes": [
        "Reasoning",
        "Interpretability",
        "Scaling Laws"
      ],
      "continuation": null,
      "summary_html": "<p>Uses syllogistic reasoning with existential import as a probe to trace how LLMs evolve from intuition-driven to formal logic, finding that model scaling and thinking capabilities accelerate this shift.</p>",
      "content_html": "<p>arXiv:2601.17426v1 Announce Type: new  Abstract: Human logic has gradually shifted from intuition-driven inference to rigorous formal systems. Motivated by recent advances in large language models (LLMs), we explore whether LLMs exhibit a similar evolution in the underlying logical framework. Using existential import as a probe, we for evaluate syllogism under traditional and modern logic. Through extensive experiments of testing SOTA LLMs on a new syllogism dataset, we have some interesting findings: (i) Model size scaling promotes the shift toward modern logic; (ii) Thinking serves as an efficient accelerator beyond parameter scaling; (iii) the Base model plays a crucial role in determining how easily and stably this shift can emerge. Beyond these core factors, we conduct additional experiments for in-depth analysis of properties of current LLMs on syllogistic reasoning.</p>"
    },
    {
      "id": "89fe015b6e65",
      "title": "RareAlert: Aligning heterogeneous large language model reasoning for early rare disease risk screening",
      "content": "arXiv:2601.18132v1 Announce Type: new  Abstract: Missed and delayed diagnosis remains a major challenge in rare disease care. At the initial clinical encounters, physicians assess rare disease risk using only limited information under high uncertainty. When high-risk patients are not recognised at this stage, targeted diagnostic testing is often not initiated, resulting in missed diagnosis. Existing primary care triage processes are structurally insufficient to reliably identify patients with rare diseases at initial clinical presentation and universal screening is needed to reduce diagnostic delay. Here we present RareAlert, an early screening system which predict patient-level rare disease risk from routinely available primary-visit information. RareAlert integrates reasoning generated by ten LLMs, calibrates and weights these signals using machine learning, and distils the aligned reasoning into a single locally deployable model. To develop and evaluate RareAlert, we curated RareBench, a real-world dataset of 158,666 cases covering 33 Orphanet disease categories and more than 7,000 rare conditions, including both rare and non-rare presentations. The results showed that rare disease identification can be reconceptualised as a universal uncertainty resolution process applied to the general patient population. On an independent test set, RareAlert, a Qwen3-4B based model trained with calibrated reasoning signals, achieved an AUC of 0.917, outperforming the best machine learning ensemble and all evaluated LLMs, including GPT-5, DeepSeek-R1, Claude-3.7-Sonnet, o3-mini, Gemini-2.5-Pro, and Qwen3-235B. These findings demonstrate the diversity in LLM medical reasoning and the effectiveness of aligning such reasoning in highly uncertain clinical tasks. By incorporating calibrated reasoning into a single model, RareAlert enables accurate, privacy-preserving, and scalable rare disease risk screening suitable for large-scale local deployment.",
      "url": "http://arxiv.org/abs/2601.18132",
      "author": "Xi Chen, Hongru Zhou, Huahui Yi, Shiyu Feng, Hanyu Zhou, Tiancheng He, Mingke You, Li Wang, Qiankun Li, Kun Wang, Weili Fu, Kang Li, Jian Li",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Presents RareAlert for early rare disease screening using heterogeneous LLM reasoning on primary-visit information, integrating multiple models' reasoning for patient-level risk prediction.",
      "importance_score": 64,
      "reasoning": "Important healthcare application addressing diagnostic delays; practical approach to difficult clinical problem.",
      "themes": [
        "Healthcare AI",
        "Rare Diseases",
        "Ensemble Methods"
      ],
      "continuation": null,
      "summary_html": "<p>Presents RareAlert for early rare disease screening using heterogeneous LLM reasoning on primary-visit information, integrating multiple models' reasoning for patient-level risk prediction.</p>",
      "content_html": "<p>arXiv:2601.18132v1 Announce Type: new  Abstract: Missed and delayed diagnosis remains a major challenge in rare disease care. At the initial clinical encounters, physicians assess rare disease risk using only limited information under high uncertainty. When high-risk patients are not recognised at this stage, targeted diagnostic testing is often not initiated, resulting in missed diagnosis. Existing primary care triage processes are structurally insufficient to reliably identify patients with rare diseases at initial clinical presentation and universal screening is needed to reduce diagnostic delay. Here we present RareAlert, an early screening system which predict patient-level rare disease risk from routinely available primary-visit information. RareAlert integrates reasoning generated by ten LLMs, calibrates and weights these signals using machine learning, and distils the aligned reasoning into a single locally deployable model. To develop and evaluate RareAlert, we curated RareBench, a real-world dataset of 158,666 cases covering 33 Orphanet disease categories and more than 7,000 rare conditions, including both rare and non-rare presentations. The results showed that rare disease identification can be reconceptualised as a universal uncertainty resolution process applied to the general patient population. On an independent test set, RareAlert, a Qwen3-4B based model trained with calibrated reasoning signals, achieved an AUC of 0.917, outperforming the best machine learning ensemble and all evaluated LLMs, including GPT-5, DeepSeek-R1, Claude-3.7-Sonnet, o3-mini, Gemini-2.5-Pro, and Qwen3-235B. These findings demonstrate the diversity in LLM medical reasoning and the effectiveness of aligning such reasoning in highly uncertain clinical tasks. By incorporating calibrated reasoning into a single model, RareAlert enables accurate, privacy-preserving, and scalable rare disease risk screening suitable for large-scale local deployment.</p>"
    },
    {
      "id": "2453af788ceb",
      "title": "Deconstructing Instruction-Following: A New Benchmark for Granular Evaluation of Large Language Model Instruction Compliance Abilities",
      "content": "arXiv:2601.18554v1 Announce Type: new  Abstract: Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions.",
      "url": "http://arxiv.org/abs/2601.18554",
      "author": "Alberto Purpura, Li Wang, Sahil Badyal, Eugenio Beaufrand, Adam Faulkner",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces MOSAIC benchmark with up to 20 application-oriented constraints for granular evaluation of LLM instruction compliance, revealing compliance varies by constraint type, quantity, and position.",
      "importance_score": 64,
      "reasoning": "Useful benchmark revealing nuanced instruction-following patterns; practical insights for prompt engineering.",
      "themes": [
        "Instruction Following",
        "Benchmarks",
        "LLM Evaluation"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces MOSAIC benchmark with up to 20 application-oriented constraints for granular evaluation of LLM instruction compliance, revealing compliance varies by constraint type, quantity, and position.</p>",
      "content_html": "<p>arXiv:2601.18554v1 Announce Type: new  Abstract: Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions.</p>"
    },
    {
      "id": "ab6ba97f732e",
      "title": "Breaking Task Impasses Quickly: Adaptive Neuro-Symbolic Learning for Open-World Robotics",
      "content": "arXiv:2601.16985v1 Announce Type: cross  Abstract: Adapting to unforeseen novelties in open-world environments remains a major challenge for autonomous systems. While hybrid planning and reinforcement learning (RL) approaches show promise, they often suffer from sample inefficiency, slow adaptation, and catastrophic forgetting. We present a neuro-symbolic framework integrating hierarchical abstractions, task and motion planning (TAMP), and reinforcement learning to enable rapid adaptation in robotics. Our architecture combines symbolic goal-oriented learning and world model-based exploration to facilitate rapid adaptation to environmental changes. Validated in robotic manipulation and autonomous driving, our approach achieves faster convergence, improved sample efficiency, and superior robustness over state-of-the-art hybrid methods, demonstrating its potential for real-world deployment.",
      "url": "http://arxiv.org/abs/2601.16985",
      "author": "Pierrick Lorang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents neuro-symbolic framework integrating hierarchical abstractions with task and motion planning for rapid robotics adaptation, validated in manipulation and autonomous driving.",
      "importance_score": 64,
      "reasoning": "Practical approach to robotics adaptation; combines multiple AI paradigms for improved sample efficiency.",
      "themes": [
        "Robotics",
        "Neuro-Symbolic AI",
        "Adaptation"
      ],
      "continuation": null,
      "summary_html": "<p>Presents neuro-symbolic framework integrating hierarchical abstractions with task and motion planning for rapid robotics adaptation, validated in manipulation and autonomous driving.</p>",
      "content_html": "<p>arXiv:2601.16985v1 Announce Type: cross  Abstract: Adapting to unforeseen novelties in open-world environments remains a major challenge for autonomous systems. While hybrid planning and reinforcement learning (RL) approaches show promise, they often suffer from sample inefficiency, slow adaptation, and catastrophic forgetting. We present a neuro-symbolic framework integrating hierarchical abstractions, task and motion planning (TAMP), and reinforcement learning to enable rapid adaptation in robotics. Our architecture combines symbolic goal-oriented learning and world model-based exploration to facilitate rapid adaptation to environmental changes. Validated in robotic manipulation and autonomous driving, our approach achieves faster convergence, improved sample efficiency, and superior robustness over state-of-the-art hybrid methods, demonstrating its potential for real-world deployment.</p>"
    },
    {
      "id": "6016a17c813f",
      "title": "Sparsity-Aware Low-Rank Representation for Efficient Fine-Tuning of Large Language Models",
      "content": "arXiv:2601.16991v1 Announce Type: cross  Abstract: Adapting large pre-trained language models to downstream tasks often entails fine-tuning millions of parameters or deploying costly dense weight updates, which hinders their use in resource-constrained environments. Low-rank Adaptation (LoRA) reduces trainable parameters by factorizing weight updates, yet the underlying dense weights still impose high storage and computation costs. Magnitude-based pruning can yield sparse models but typically degrades LoRA's performance when applied naively. In this paper, we introduce SALR (Sparsity-Aware Low-Rank Representation), a novel fine-tuning paradigm that unifies low-rank adaptation with sparse pruning under a rigorous mean-squared-error framework. We prove that statically pruning only the frozen base weights minimizes the pruning error bound, and we recover the discarded residual information via a truncated-SVD low-rank adapter, which provably reduces per-entry MSE by a factor of $(1 - r/\\min(d,k))$. To maximize hardware efficiency, we fuse multiple low-rank adapters into a single concatenated GEMM, and we adopt a bitmap-based encoding with a two-stage pipelined decoding + GEMM design to achieve true model compression and speedup. Empirically, SALR attains 50\\% sparsity on various LLMs while matching the performance of LoRA on GSM8K and MMLU, reduces model size by $2\\times$, and delivers up to a $1.7\\times$ inference speedup.",
      "url": "http://arxiv.org/abs/2601.16991",
      "author": "Longteng Zhang, Sen Wu, Shuai Hou, Zhengyu Qing, Zhuo Zheng, Danning Ke, Qihong Lin, Qiang Wang, Shaohuai Shi, Xiaowen Chu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces SALR unifying low-rank adaptation with sparse pruning under MSE framework, proving static pruning of frozen weights preserves LoRA effectiveness while reducing costs.",
      "importance_score": 64,
      "reasoning": "Principled approach to efficient fine-tuning; theoretical grounding for practical efficiency gains.",
      "themes": [
        "Efficient Fine-Tuning",
        "LoRA",
        "Model Compression"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces SALR unifying low-rank adaptation with sparse pruning under MSE framework, proving static pruning of frozen weights preserves LoRA effectiveness while reducing costs.</p>",
      "content_html": "<p>arXiv:2601.16991v1 Announce Type: cross  Abstract: Adapting large pre-trained language models to downstream tasks often entails fine-tuning millions of parameters or deploying costly dense weight updates, which hinders their use in resource-constrained environments. Low-rank Adaptation (LoRA) reduces trainable parameters by factorizing weight updates, yet the underlying dense weights still impose high storage and computation costs. Magnitude-based pruning can yield sparse models but typically degrades LoRA's performance when applied naively. In this paper, we introduce SALR (Sparsity-Aware Low-Rank Representation), a novel fine-tuning paradigm that unifies low-rank adaptation with sparse pruning under a rigorous mean-squared-error framework. We prove that statically pruning only the frozen base weights minimizes the pruning error bound, and we recover the discarded residual information via a truncated-SVD low-rank adapter, which provably reduces per-entry MSE by a factor of $(1 - r/\\min(d,k))$. To maximize hardware efficiency, we fuse multiple low-rank adapters into a single concatenated GEMM, and we adopt a bitmap-based encoding with a two-stage pipelined decoding + GEMM design to achieve true model compression and speedup. Empirically, SALR attains 50\\% sparsity on various LLMs while matching the performance of LoRA on GSM8K and MMLU, reduces model size by $2\\times$, and delivers up to a $1.7\\times$ inference speedup.</p>"
    },
    {
      "id": "13b2aa393d9f",
      "title": "Latent-Space Contrastive Reinforcement Learning for Stable and Efficient LLM Reasoning",
      "content": "arXiv:2601.17275v1 Announce Type: cross  Abstract: While Large Language Models (LLMs) demonstrate exceptional performance in surface-level text generation, their nature in handling complex multi-step reasoning tasks often remains one of ``statistical fitting'' rather than systematic logical deduction. Traditional Reinforcement Learning (RL) attempts to mitigate this by introducing a ``think-before-speak'' paradigm. However, applying RL directly in high-dimensional, discrete token spaces faces three inherent challenges: sample-inefficient rollouts, high gradient estimation variance, and the risk of catastrophic forgetting. To fundamentally address these structural bottlenecks, we propose \\textbf{DeepLatent Reasoning (DLR)}, a latent-space bidirectional contrastive reinforcement learning framework. This framework shifts the trial-and-error cost from expensive token-level full sequence generation to the continuous latent manifold. Specifically, we introduce a lightweight assistant model to efficiently sample $K$ reasoning chain encodings within the latent space. These encodings are filtered via a dual reward mechanism based on correctness and formatting; only high-value latent trajectories are fed into a \\textbf{frozen main model} for single-pass decoding. To maximize reasoning diversity while maintaining coherence, we design a contrastive learning objective to enable directed exploration within the latent space. Since the main model parameters remain frozen during optimization, this method mathematically eliminates catastrophic forgetting. Experiments demonstrate that under comparable GPU computational budgets, DLR achieves more stable training convergence, supports longer-horizon reasoning chains, and facilitates the sustainable accumulation of reasoning capabilities, providing a viable path toward reliable and scalable reinforcement learning for LLMs.",
      "url": "http://arxiv.org/abs/2601.17275",
      "author": "Lianlei Shan, Han Chen, Yixuan Wang, Zhenjie Liu, Wei Li",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes DeepLatent Reasoning (DLR), a latent-space bidirectional contrastive RL framework addressing sample inefficiency, gradient variance, and catastrophic forgetting in LLM reasoning.",
      "importance_score": 64,
      "reasoning": "Novel approach to fundamental challenges in RL for LLM reasoning. Addresses multiple structural bottlenecks with principled methodology.",
      "themes": [
        "LLM Reasoning",
        "Reinforcement Learning",
        "Latent Space"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes DeepLatent Reasoning (DLR), a latent-space bidirectional contrastive RL framework addressing sample inefficiency, gradient variance, and catastrophic forgetting in LLM reasoning.</p>",
      "content_html": "<p>arXiv:2601.17275v1 Announce Type: cross  Abstract: While Large Language Models (LLMs) demonstrate exceptional performance in surface-level text generation, their nature in handling complex multi-step reasoning tasks often remains one of ``statistical fitting'' rather than systematic logical deduction. Traditional Reinforcement Learning (RL) attempts to mitigate this by introducing a ``think-before-speak'' paradigm. However, applying RL directly in high-dimensional, discrete token spaces faces three inherent challenges: sample-inefficient rollouts, high gradient estimation variance, and the risk of catastrophic forgetting. To fundamentally address these structural bottlenecks, we propose \\textbf{DeepLatent Reasoning (DLR)}, a latent-space bidirectional contrastive reinforcement learning framework. This framework shifts the trial-and-error cost from expensive token-level full sequence generation to the continuous latent manifold. Specifically, we introduce a lightweight assistant model to efficiently sample $K$ reasoning chain encodings within the latent space. These encodings are filtered via a dual reward mechanism based on correctness and formatting; only high-value latent trajectories are fed into a \\textbf{frozen main model} for single-pass decoding. To maximize reasoning diversity while maintaining coherence, we design a contrastive learning objective to enable directed exploration within the latent space. Since the main model parameters remain frozen during optimization, this method mathematically eliminates catastrophic forgetting. Experiments demonstrate that under comparable GPU computational budgets, DLR achieves more stable training convergence, supports longer-horizon reasoning chains, and facilitates the sustainable accumulation of reasoning capabilities, providing a viable path toward reliable and scalable reinforcement learning for LLMs.</p>"
    },
    {
      "id": "86bd1ad6f182",
      "title": "The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation",
      "content": "arXiv:2601.17737v1 Announce Type: cross  Abstract: Recent advances in video generation have produced models capable of synthesizing stunning visual content from simple text prompts. However, these models struggle to generate long-form, coherent narratives from high-level concepts like dialogue, revealing a ``semantic gap'' between a creative idea and its cinematic execution. To bridge this gap, we introduce a novel, end-to-end agentic framework for dialogue-to-cinematic-video generation. Central to our framework is ScripterAgent, a model trained to translate coarse dialogue into a fine-grained, executable cinematic script. To enable this, we construct ScriptBench, a new large-scale benchmark with rich multimodal context, annotated via an expert-guided pipeline. The generated script then guides DirectorAgent, which orchestrates state-of-the-art video models using a cross-scene continuous generation strategy to ensure long-horizon coherence. Our comprehensive evaluation, featuring an AI-powered CriticAgent and a new Visual-Script Alignment (VSA) metric, shows our framework significantly improves script faithfulness and temporal fidelity across all tested video models. Furthermore, our analysis uncovers a crucial trade-off in current SOTA models between visual spectacle and strict script adherence, providing valuable insights for the future of automated filmmaking.",
      "url": "http://arxiv.org/abs/2601.17737",
      "author": "Chenyu Mu, Xin He, Qu Yang, Wanshun Chen, Jiadi Yao, Huang Liu, Zihao Yi, Bo Zhao, Xingyu Chen, Ruotian Ma, Fanghua Ye, Erkun Yang, Cheng Deng, Zhaopeng Tu, Xiaolong Li, Linus",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces agentic framework for dialogue-to-cinematic video with ScripterAgent that translates dialogue into executable cinematic scripts, using ScriptBench benchmark.",
      "importance_score": 64,
      "reasoning": "Novel end-to-end pipeline for creative video generation. Addresses semantic gap between dialogue and execution. New benchmark contribution.",
      "themes": [
        "Video Generation",
        "Agentic Systems",
        "Creative AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces agentic framework for dialogue-to-cinematic video with ScripterAgent that translates dialogue into executable cinematic scripts, using ScriptBench benchmark.</p>",
      "content_html": "<p>arXiv:2601.17737v1 Announce Type: cross  Abstract: Recent advances in video generation have produced models capable of synthesizing stunning visual content from simple text prompts. However, these models struggle to generate long-form, coherent narratives from high-level concepts like dialogue, revealing a ``semantic gap'' between a creative idea and its cinematic execution. To bridge this gap, we introduce a novel, end-to-end agentic framework for dialogue-to-cinematic-video generation. Central to our framework is ScripterAgent, a model trained to translate coarse dialogue into a fine-grained, executable cinematic script. To enable this, we construct ScriptBench, a new large-scale benchmark with rich multimodal context, annotated via an expert-guided pipeline. The generated script then guides DirectorAgent, which orchestrates state-of-the-art video models using a cross-scene continuous generation strategy to ensure long-horizon coherence. Our comprehensive evaluation, featuring an AI-powered CriticAgent and a new Visual-Script Alignment (VSA) metric, shows our framework significantly improves script faithfulness and temporal fidelity across all tested video models. Furthermore, our analysis uncovers a crucial trade-off in current SOTA models between visual spectacle and strict script adherence, providing valuable insights for the future of automated filmmaking.</p>"
    },
    {
      "id": "94a2bc46e0f4",
      "title": "DF-RAG: Query-Aware Diversity for Retrieval-Augmented Generation",
      "content": "arXiv:2601.17212v1 Announce Type: new  Abstract: Retrieval-augmented generation (RAG) is a common technique for grounding language model outputs in domain-specific information. However, RAG is often challenged by reasoning-intensive question-answering (QA), since common retrieval methods like cosine similarity maximize relevance at the cost of introducing redundant content, which can reduce information recall. To address this, we introduce Diversity-Focused Retrieval-Augmented Generation (DF-RAG), which systematically incorporates diversity into the retrieval step to improve performance on complex, reasoning-intensive QA benchmarks. DF-RAG builds upon the Maximal Marginal Relevance framework to select information chunks that are both relevant to the query and maximally dissimilar from each other. A key innovation of DF-RAG is its ability to optimize the level of diversity for each query dynamically at test time without requiring any additional fine-tuning or prior information. We show that DF-RAG improves F1 performance on reasoning-intensive QA benchmarks by 4-10 percent over vanilla RAG using cosine similarity and also outperforms other established baselines. Furthermore, we estimate an Oracle ceiling of up to 18 percent absolute F1 gains over vanilla RAG, of which DF-RAG captures up to 91.3 percent.",
      "url": "http://arxiv.org/abs/2601.17212",
      "author": "Saadat Hasan Khan, Spencer Hong, Jingyu Wu, Kevin Lybarger, Youbing Yin, Erin Babinsky, Daben Liu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces DF-RAG, which incorporates diversity into retrieval using Maximal Marginal Relevance to improve performance on reasoning-intensive QA by reducing redundancy in retrieved chunks.",
      "importance_score": 64,
      "reasoning": "Practical improvement to RAG systems with clear benefits for complex reasoning tasks. Well-motivated approach based on MMR.",
      "themes": [
        "RAG",
        "Question Answering",
        "Information Retrieval"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces DF-RAG, which incorporates diversity into retrieval using Maximal Marginal Relevance to improve performance on reasoning-intensive QA by reducing redundancy in retrieved chunks.</p>",
      "content_html": "<p>arXiv:2601.17212v1 Announce Type: new  Abstract: Retrieval-augmented generation (RAG) is a common technique for grounding language model outputs in domain-specific information. However, RAG is often challenged by reasoning-intensive question-answering (QA), since common retrieval methods like cosine similarity maximize relevance at the cost of introducing redundant content, which can reduce information recall. To address this, we introduce Diversity-Focused Retrieval-Augmented Generation (DF-RAG), which systematically incorporates diversity into the retrieval step to improve performance on complex, reasoning-intensive QA benchmarks. DF-RAG builds upon the Maximal Marginal Relevance framework to select information chunks that are both relevant to the query and maximally dissimilar from each other. A key innovation of DF-RAG is its ability to optimize the level of diversity for each query dynamically at test time without requiring any additional fine-tuning or prior information. We show that DF-RAG improves F1 performance on reasoning-intensive QA benchmarks by 4-10 percent over vanilla RAG using cosine similarity and also outperforms other established baselines. Furthermore, we estimate an Oracle ceiling of up to 18 percent absolute F1 gains over vanilla RAG, of which DF-RAG captures up to 91.3 percent.</p>"
    },
    {
      "id": "fac4a2f5c9d1",
      "title": "A Computational Approach to Visual Metonymy",
      "content": "arXiv:2601.17706v1 Announce Type: new  Abstract: Images often communicate more than they literally depict: a set of tools can suggest an occupation and a cultural artifact can suggest a tradition. This kind of indirect visual reference, known as visual metonymy, invites viewers to recover a target concept via associated cues rather than explicit depiction. In this work, we present the first computational investigation of visual metonymy. We introduce a novel pipeline grounded in semiotic theory that leverages large language models and text-to-image models to generate metonymic visual representations. Using this framework, we construct ViMET, the first visual metonymy dataset comprising 2,000 multiple-choice questions to evaluate the cognitive reasoning abilities in multimodal language models. Experimental results on our dataset reveal a significant gap between human performance (86.9%) and state-of-the-art vision-language models (65.9%), highlighting limitations in machines' ability to interpret indirect visual references. Our dataset is publicly available at: https://github.com/cincynlp/ViMET.",
      "url": "http://arxiv.org/abs/2601.17706",
      "author": "Saptarshi Ghosh, Linfeng Liu, Tianyu Jiang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents first computational investigation of visual metonymy, introducing pipeline grounded in semiotic theory and ViMET dataset with 2,000 multiple-choice questions evaluating multimodal reasoning on indirect visual references.",
      "importance_score": 64,
      "reasoning": "Novel research direction opening new capability area for VLMs. First systematic computational study of visual metonymy.",
      "themes": [
        "Vision-Language Models",
        "Visual Reasoning",
        "Dataset"
      ],
      "continuation": null,
      "summary_html": "<p>Presents first computational investigation of visual metonymy, introducing pipeline grounded in semiotic theory and ViMET dataset with 2,000 multiple-choice questions evaluating multimodal reasoning on indirect visual references.</p>",
      "content_html": "<p>arXiv:2601.17706v1 Announce Type: new  Abstract: Images often communicate more than they literally depict: a set of tools can suggest an occupation and a cultural artifact can suggest a tradition. This kind of indirect visual reference, known as visual metonymy, invites viewers to recover a target concept via associated cues rather than explicit depiction. In this work, we present the first computational investigation of visual metonymy. We introduce a novel pipeline grounded in semiotic theory that leverages large language models and text-to-image models to generate metonymic visual representations. Using this framework, we construct ViMET, the first visual metonymy dataset comprising 2,000 multiple-choice questions to evaluate the cognitive reasoning abilities in multimodal language models. Experimental results on our dataset reveal a significant gap between human performance (86.9%) and state-of-the-art vision-language models (65.9%), highlighting limitations in machines' ability to interpret indirect visual references. Our dataset is publicly available at: https://github.com/cincynlp/ViMET.</p>"
    },
    {
      "id": "881eeedf533d",
      "title": "U-Fold: Dynamic Intent-Aware Context Folding for User-Centric Agents",
      "content": "arXiv:2601.18285v1 Announce Type: new  Abstract: Large language model (LLM)-based agents have been successfully deployed in many tool-augmented settings, but their scalability is fundamentally constrained by context length. Existing context-folding methods mitigate this issue by summarizing past interactions, yet they are typically designed for single-query or single-intent scenarios. In more realistic user-centric dialogues, we identify two major failure modes: (i) they irreversibly discard fine-grained constraints and intermediate facts that are crucial for later decisions, and (ii) their summaries fail to track evolving user intent, leading to omissions and erroneous actions. To address these limitations, we propose U-Fold, a dynamic context-folding framework tailored to user-centric tasks. U-Fold retains the full user--agent dialogue and tool-call history but, at each turn, uses two core components to produce an intent-aware, evolving dialogue summary and a compact, task-relevant tool log. Extensive experiments on $\\tau$-bench, $\\tau^2$-bench, VitaBench, and harder context-inflated settings show that U-Fold consistently outperforms ReAct (achieving a 71.4% win rate in long-context settings) and prior folding baselines (with improvements of up to 27.0%), particularly on long, noisy, multi-turn tasks. Our study demonstrates that U-Fold is a promising step toward transferring context-management techniques from single-query benchmarks to realistic user-centric applications.",
      "url": "http://arxiv.org/abs/2601.18285",
      "author": "Jin Su, Runnan Fang, Yeqiu Li, Xiaobin Wang, Shihao Cai, Pengjun Xie, Ningyu Zhang, Fajie Yuan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes U-Fold, a dynamic context-folding framework for user-centric agents that tracks evolving user intent and preserves fine-grained constraints across multi-turn dialogues.",
      "importance_score": 64,
      "reasoning": "Addresses important limitation in context folding for realistic user interactions. Well-motivated failure mode analysis.",
      "themes": [
        "LLM Agents",
        "Context Management",
        "Dialogue Systems"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes U-Fold, a dynamic context-folding framework for user-centric agents that tracks evolving user intent and preserves fine-grained constraints across multi-turn dialogues.</p>",
      "content_html": "<p>arXiv:2601.18285v1 Announce Type: new  Abstract: Large language model (LLM)-based agents have been successfully deployed in many tool-augmented settings, but their scalability is fundamentally constrained by context length. Existing context-folding methods mitigate this issue by summarizing past interactions, yet they are typically designed for single-query or single-intent scenarios. In more realistic user-centric dialogues, we identify two major failure modes: (i) they irreversibly discard fine-grained constraints and intermediate facts that are crucial for later decisions, and (ii) their summaries fail to track evolving user intent, leading to omissions and erroneous actions. To address these limitations, we propose U-Fold, a dynamic context-folding framework tailored to user-centric tasks. U-Fold retains the full user--agent dialogue and tool-call history but, at each turn, uses two core components to produce an intent-aware, evolving dialogue summary and a compact, task-relevant tool log. Extensive experiments on $\\tau$-bench, $\\tau^2$-bench, VitaBench, and harder context-inflated settings show that U-Fold consistently outperforms ReAct (achieving a 71.4% win rate in long-context settings) and prior folding baselines (with improvements of up to 27.0%), particularly on long, noisy, multi-turn tasks. Our study demonstrates that U-Fold is a promising step toward transferring context-management techniques from single-query benchmarks to realistic user-centric applications.</p>"
    },
    {
      "id": "ecad562e874b",
      "title": "Latent Knowledge as a Predictor of Fact Acquisition in Fine-Tuned Large Language Models",
      "content": "arXiv:2601.18468v1 Announce Type: new  Abstract: Large language models store biomedical facts with uneven strength after pretraining: some facts are present in the weights but are not reliably accessible under deterministic decoding (latent knowledge), while others are scarcely represented. We fine tuned Llama 3.1 8B Instruct to learn ontology term identifier mappings from the Human Phenotype Ontology (800 pairs) and the Gene Ontology (400 training pairs), withholding 400 GO pairs to test generalization. Treating learning as a time to event process across 20 epochs, we used stochastic decoding to detect latent knowledge at baseline and Cox proportional hazards models to identify predictors of acquisition, generalization, and degradation. Baseline deterministic recall for HPO was 2.8%, rising to 71.9% after fine-tuning. Latent knowledge was the strongest predictor of faster fact acquisition (HR 2.6) and was associated with earlier, higher peak learning rates and faster convergence; identifier frequency and curated annotation counts had smaller effects. Generalization to withheld GO facts was uncommon (5.8%) but more likely when latent knowledge was present. Previously correct GO mappings degraded more often for withheld (unseen) terms than for trained (seen) terms, suggesting a protective effect of reinforcement during training. These results show that latent knowledge predicts both the speed of factual learning during fine-tuning and the limited generalization of unseen ontology facts, while resistance to degradation depends on whether facts are reinforced.",
      "url": "http://arxiv.org/abs/2601.18468",
      "author": "Daniel B. Hier, Tayo Obafemi-Ajayi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Studies how latent knowledge (present in weights but not reliably accessible under deterministic decoding) predicts fact acquisition during fine-tuning using ontology term mapping tasks.",
      "importance_score": 64,
      "reasoning": "Interesting mechanistic insight into relationship between latent knowledge and learning. Novel experimental design using ontology mappings.",
      "themes": [
        "Knowledge in LLMs",
        "Fine-Tuning",
        "Mechanistic Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Studies how latent knowledge (present in weights but not reliably accessible under deterministic decoding) predicts fact acquisition during fine-tuning using ontology term mapping tasks.</p>",
      "content_html": "<p>arXiv:2601.18468v1 Announce Type: new  Abstract: Large language models store biomedical facts with uneven strength after pretraining: some facts are present in the weights but are not reliably accessible under deterministic decoding (latent knowledge), while others are scarcely represented. We fine tuned Llama 3.1 8B Instruct to learn ontology term identifier mappings from the Human Phenotype Ontology (800 pairs) and the Gene Ontology (400 training pairs), withholding 400 GO pairs to test generalization. Treating learning as a time to event process across 20 epochs, we used stochastic decoding to detect latent knowledge at baseline and Cox proportional hazards models to identify predictors of acquisition, generalization, and degradation. Baseline deterministic recall for HPO was 2.8%, rising to 71.9% after fine-tuning. Latent knowledge was the strongest predictor of faster fact acquisition (HR 2.6) and was associated with earlier, higher peak learning rates and faster convergence; identifier frequency and curated annotation counts had smaller effects. Generalization to withheld GO facts was uncommon (5.8%) but more likely when latent knowledge was present. Previously correct GO mappings degraded more often for withheld (unseen) terms than for trained (seen) terms, suggesting a protective effect of reinforcement during training. These results show that latent knowledge predicts both the speed of factual learning during fine-tuning and the limited generalization of unseen ontology facts, while resistance to degradation depends on whether facts are reinforced.</p>"
    },
    {
      "id": "781f02e91602",
      "title": "CoT-Seg: Rethinking Segmentation with Chain-of-Thought Reasoning and Self-Correction",
      "content": "arXiv:2601.17420v1 Announce Type: new  Abstract: Existing works of reasoning segmentation often fall short in complex cases, particularly when addressing complicated queries and out-of-domain images. Inspired by the chain-of-thought reasoning, where harder problems require longer thinking steps/time, this paper aims to explore a system that can think step-by-step, look up information if needed, generate results, self-evaluate its own results, and refine the results, in the same way humans approach harder questions. We introduce CoT-Seg, a training-free framework that rethinks reasoning segmentation by combining chain-of-thought reasoning with self-correction. Instead of fine-tuning, CoT-Seg leverages the inherent reasoning ability of pre-trained MLLMs (GPT-4o) to decompose queries into meta-instructions, extract fine-grained semantics from images, and identify target objects even under implicit or complex prompts. Moreover, CoT-Seg incorporates a self-correction stage: the model evaluates its own segmentation against the original query and reasoning trace, identifies mismatches, and iteratively refines the mask. This tight integration of reasoning and correction significantly improves reliability and robustness, especially in ambiguous or error-prone cases. Furthermore, our CoT-Seg framework allows easy incorporation of retrieval-augmented reasoning, enabling the system to access external knowledge when the input lacks sufficient information. To showcase CoT-Seg's ability to handle very challenging cases ,we introduce a new dataset ReasonSeg-Hard. Our results highlight that combining chain-of-thought reasoning, self-correction, offers a powerful paradigm for vision-language integration driven segmentation.",
      "url": "http://arxiv.org/abs/2601.17420",
      "author": "Shiu-hong Kao, Chak Ho Huang, Huaiqian Liu, Yu-Wing Tai, Chi-Keung Tang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes CoT-Seg, training-free reasoning segmentation framework using GPT-4o for chain-of-thought query decomposition with self-correction for complex reasoning segmentation tasks.",
      "importance_score": 64,
      "reasoning": "Novel application of chain-of-thought reasoning to segmentation with self-correction capability. Shows promise for complex vision-language tasks.",
      "themes": [
        "Reasoning",
        "Segmentation",
        "Chain-of-Thought",
        "Vision-Language"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes CoT-Seg, training-free reasoning segmentation framework using GPT-4o for chain-of-thought query decomposition with self-correction for complex reasoning segmentation tasks.</p>",
      "content_html": "<p>arXiv:2601.17420v1 Announce Type: new  Abstract: Existing works of reasoning segmentation often fall short in complex cases, particularly when addressing complicated queries and out-of-domain images. Inspired by the chain-of-thought reasoning, where harder problems require longer thinking steps/time, this paper aims to explore a system that can think step-by-step, look up information if needed, generate results, self-evaluate its own results, and refine the results, in the same way humans approach harder questions. We introduce CoT-Seg, a training-free framework that rethinks reasoning segmentation by combining chain-of-thought reasoning with self-correction. Instead of fine-tuning, CoT-Seg leverages the inherent reasoning ability of pre-trained MLLMs (GPT-4o) to decompose queries into meta-instructions, extract fine-grained semantics from images, and identify target objects even under implicit or complex prompts. Moreover, CoT-Seg incorporates a self-correction stage: the model evaluates its own segmentation against the original query and reasoning trace, identifies mismatches, and iteratively refines the mask. This tight integration of reasoning and correction significantly improves reliability and robustness, especially in ambiguous or error-prone cases. Furthermore, our CoT-Seg framework allows easy incorporation of retrieval-augmented reasoning, enabling the system to access external knowledge when the input lacks sufficient information. To showcase CoT-Seg's ability to handle very challenging cases ,we introduce a new dataset ReasonSeg-Hard. Our results highlight that combining chain-of-thought reasoning, self-correction, offers a powerful paradigm for vision-language integration driven segmentation.</p>"
    },
    {
      "id": "2a7a34766b49",
      "title": "Acoustic Field Video for Multimodal Scene Understanding",
      "content": "arXiv:2601.17123v1 Announce Type: cross  Abstract: We introduce and explore a new multimodal input representation for vision-language models: acoustic field video. Unlike conventional video (RGB with stereo/mono audio), our video stream provides a spatially grounded visualization of sound intensity across a scene, offering a new and powerful dimension of perceptual understanding. Our real-time pipeline uses low-cost beamforming microphone arrays that are already common in smart speakers and increasingly present in robotics and XR headsets, yet this sensing capability remains unutilized for scene understanding. To assess the value of spatial acoustic information, we constructed an evaluation set of 402 question-answer scenes, comparing a state-of-the-art VLM given conventional video with and without paired acoustic field video. Results show a clear and consistent improvement when incorporating spatial acoustic data; the VLM we test improves from 38.3% correct to 67.4%. Our findings highlight that many everyday scene understanding tasks remain underconstrained when relying solely on visual and audio input, and that acoustic field data provides a promising and practical direction for multimodal reasoning. A video demo is available at https://daehwakim.com/seeingsound",
      "url": "http://arxiv.org/abs/2601.17123",
      "author": "Daehwa Kim, Chris Harrison",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.HC"
      ],
      "summary": "Introduces acoustic field video as a new multimodal input for VLMs, using beamforming microphone arrays to provide spatially grounded sound visualization for enhanced scene understanding.",
      "importance_score": 64,
      "reasoning": "Creative new modality for VLMs leveraging existing hardware (smart speakers, XR headsets), includes 402-scene evaluation set. Novel sensing approach.",
      "themes": [
        "Multimodal Learning",
        "Vision-Language Models",
        "Acoustic Sensing",
        "Scene Understanding"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces acoustic field video as a new multimodal input for VLMs, using beamforming microphone arrays to provide spatially grounded sound visualization for enhanced scene understanding.</p>",
      "content_html": "<p>arXiv:2601.17123v1 Announce Type: cross  Abstract: We introduce and explore a new multimodal input representation for vision-language models: acoustic field video. Unlike conventional video (RGB with stereo/mono audio), our video stream provides a spatially grounded visualization of sound intensity across a scene, offering a new and powerful dimension of perceptual understanding. Our real-time pipeline uses low-cost beamforming microphone arrays that are already common in smart speakers and increasingly present in robotics and XR headsets, yet this sensing capability remains unutilized for scene understanding. To assess the value of spatial acoustic information, we constructed an evaluation set of 402 question-answer scenes, comparing a state-of-the-art VLM given conventional video with and without paired acoustic field video. Results show a clear and consistent improvement when incorporating spatial acoustic data; the VLM we test improves from 38.3% correct to 67.4%. Our findings highlight that many everyday scene understanding tasks remain underconstrained when relying solely on visual and audio input, and that acoustic field data provides a promising and practical direction for multimodal reasoning. A video demo is available at https://daehwakim.com/seeingsound</p>"
    },
    {
      "id": "9b05cadcf137",
      "title": "Think Locally, Explain Globally: Graph-Guided LLM Investigations via Local Reasoning and Belief Propagation",
      "content": "arXiv:2601.17915v1 Announce Type: new  Abstract: LLM agents excel when environments are mostly static and the needed information fits in a model's context window, but they often fail in open-ended investigations where explanations must be constructed by iteratively mining evidence from massive, heterogeneous operational data. These investigations exhibit hidden dependency structure: entities interact, signals co-vary, and the importance of a fact may only become clear after other evidence is discovered. Because the context window is bounded, agents must summarize intermediate findings before their significance is known, increasing the risk of discarding key evidence. ReAct-style agents are especially brittle in this regime. Their retrieve-summarize-reason loop makes conclusions sensitive to exploration order and introduces run-to-run non-determinism, producing a reliability gap where Pass-at-k may be high but Majority-at-k remains low. Simply sampling more rollouts or generating longer reasoning traces does not reliably stabilize results, since hypotheses cannot be autonomously checked as new evidence arrives and there is no explicit mechanism for belief bookkeeping and revision. In addition, ReAct entangles semantic reasoning with controller duties such as tool orchestration and state tracking, so execution errors and plan drift degrade reasoning while consuming scarce context.   We address these issues by formulating investigation as abductive reasoning over a dependency graph and proposing EoG (Explanations over Graphs), a disaggregated framework in which an LLM performs bounded local evidence mining and labeling (cause vs symptom) while a deterministic controller manages traversal, state, and belief propagation to compute a minimal explanatory frontier. On a representative ITBench diagnostics task, EoG improves both accuracy and run-to-run consistency over ReAct baselines, including a 7x average gain in Majority-at-k entity F1.",
      "url": "http://arxiv.org/abs/2601.17915",
      "author": "Saurabh Jha, Rohan Arora, Bhavya, Noah Zheutlin, Paulina Toro Isaza, Laura Shwartz, Yu Deng, Daby Sow, Ruchi Mahindru, Ruchir Puri",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes a graph-guided approach for LLM investigations combining local reasoning with belief propagation to handle hidden dependency structures in open-ended investigations over massive operational data.",
      "importance_score": 63,
      "reasoning": "Novel architecture addressing real limitations of ReAct-style agents; interesting combination of structured reasoning with LLMs.",
      "themes": [
        "Agentic AI",
        "Reasoning",
        "Graph Methods"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes a graph-guided approach for LLM investigations combining local reasoning with belief propagation to handle hidden dependency structures in open-ended investigations over massive operational data.</p>",
      "content_html": "<p>arXiv:2601.17915v1 Announce Type: new  Abstract: LLM agents excel when environments are mostly static and the needed information fits in a model's context window, but they often fail in open-ended investigations where explanations must be constructed by iteratively mining evidence from massive, heterogeneous operational data. These investigations exhibit hidden dependency structure: entities interact, signals co-vary, and the importance of a fact may only become clear after other evidence is discovered. Because the context window is bounded, agents must summarize intermediate findings before their significance is known, increasing the risk of discarding key evidence. ReAct-style agents are especially brittle in this regime. Their retrieve-summarize-reason loop makes conclusions sensitive to exploration order and introduces run-to-run non-determinism, producing a reliability gap where Pass-at-k may be high but Majority-at-k remains low. Simply sampling more rollouts or generating longer reasoning traces does not reliably stabilize results, since hypotheses cannot be autonomously checked as new evidence arrives and there is no explicit mechanism for belief bookkeeping and revision. In addition, ReAct entangles semantic reasoning with controller duties such as tool orchestration and state tracking, so execution errors and plan drift degrade reasoning while consuming scarce context.   We address these issues by formulating investigation as abductive reasoning over a dependency graph and proposing EoG (Explanations over Graphs), a disaggregated framework in which an LLM performs bounded local evidence mining and labeling (cause vs symptom) while a deterministic controller manages traversal, state, and belief propagation to compute a minimal explanatory frontier. On a representative ITBench diagnostics task, EoG improves both accuracy and run-to-run consistency over ReAct baselines, including a 7x average gain in Majority-at-k entity F1.</p>"
    },
    {
      "id": "9107f96a2807",
      "title": "Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks",
      "content": "arXiv:2601.18226v1 Announce Type: new  Abstract: Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.",
      "url": "http://arxiv.org/abs/2601.18226",
      "author": "Haotian Li, Shijun Yang, Weizhen Qi, Silei Zhao, Rui Hua, Mingzhu Song, Xiaojian Yang, Chao Peng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes In-Situ Self-Evolving paradigm for agents in open-ended environments, using tool evolution as capability expansion pathway with verifiable binary feedback signals.",
      "importance_score": 63,
      "reasoning": "Interesting framework for continuous agent improvement; addresses capability drift in dynamic environments.",
      "themes": [
        "Agentic AI",
        "Self-Improvement",
        "Tool Use"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes In-Situ Self-Evolving paradigm for agents in open-ended environments, using tool evolution as capability expansion pathway with verifiable binary feedback signals.</p>",
      "content_html": "<p>arXiv:2601.18226v1 Announce Type: new  Abstract: Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.</p>"
    },
    {
      "id": "a244d0481b93",
      "title": "Health-SCORE: Towards Scalable Rubrics for Improving Health-LLMs",
      "content": "arXiv:2601.18706v1 Announce Type: new  Abstract: Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable.",
      "url": "http://arxiv.org/abs/2601.18706",
      "author": "Zhichao Yang, Sepehr Janghorbani, Dongxu Zhang, Jun Han, Qian Qian, Andrew Ressler II, Gregory D. Lyng, Sanjit Singh Batra, Robert E. Tillman",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces Health-SCORE, a scalable rubric-based framework reducing development costs while enabling use as structured reward for RL training with safety-aware supervision.",
      "importance_score": 63,
      "reasoning": "Practical framework addressing rubric development bottleneck; dual use for evaluation and training.",
      "themes": [
        "Healthcare AI",
        "Evaluation Methodology",
        "Reinforcement Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Health-SCORE, a scalable rubric-based framework reducing development costs while enabling use as structured reward for RL training with safety-aware supervision.</p>",
      "content_html": "<p>arXiv:2601.18706v1 Announce Type: new  Abstract: Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable.</p>"
    },
    {
      "id": "9182afd1cdd6",
      "title": "BibAgent: An Agentic Framework for Traceable Miscitation Detection in Scientific Literature",
      "content": "arXiv:2601.16993v1 Announce Type: cross  Abstract: Citations are the bedrock of scientific authority, yet their integrity is compromised by widespread miscitations: ranging from nuanced distortions to fabricated references. Systematic citation verification is currently unfeasible; manual review cannot scale to modern publishing volumes, while existing automated tools are restricted by abstract-only analysis or small-scale, domain-specific datasets in part due to the \"paywall barrier\" of full-text access. We introduce BibAgent, a scalable, end-to-end agentic framework for automated citation verification. BibAgent integrates retrieval, reasoning, and adaptive evidence aggregation, applying distinct strategies for accessible and paywalled sources. For paywalled references, it leverages a novel Evidence Committee mechanism that infers citation validity via downstream citation consensus. To support systematic evaluation, we contribute a 5-category Miscitation Taxonomy and MisciteBench, a massive cross-disciplinary benchmark comprising 6,350 miscitation samples spanning 254 fields. Our results demonstrate that BibAgent outperforms state-of-the-art Large Language Model (LLM) baselines in citation verification accuracy and interpretability, providing scalable, transparent detection of citation misalignments across the scientific literature.",
      "url": "http://arxiv.org/abs/2601.16993",
      "author": "Peiran Li, Fangzhou Lin, Shuo Xing, Xiang Zheng, Xi Hong, Jiashuo Sun, Zhengzhong Tu, Chaoqun Ni",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.DL"
      ],
      "summary": "Introduces BibAgent, agentic framework for automated citation verification integrating retrieval, reasoning, and adaptive evidence aggregation with novel approach for paywalled references.",
      "importance_score": 63,
      "reasoning": "Important application addressing research integrity; practical solution to scalability of citation verification.",
      "themes": [
        "Research Integrity",
        "RAG",
        "Agentic AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces BibAgent, agentic framework for automated citation verification integrating retrieval, reasoning, and adaptive evidence aggregation with novel approach for paywalled references.</p>",
      "content_html": "<p>arXiv:2601.16993v1 Announce Type: cross  Abstract: Citations are the bedrock of scientific authority, yet their integrity is compromised by widespread miscitations: ranging from nuanced distortions to fabricated references. Systematic citation verification is currently unfeasible; manual review cannot scale to modern publishing volumes, while existing automated tools are restricted by abstract-only analysis or small-scale, domain-specific datasets in part due to the \"paywall barrier\" of full-text access. We introduce BibAgent, a scalable, end-to-end agentic framework for automated citation verification. BibAgent integrates retrieval, reasoning, and adaptive evidence aggregation, applying distinct strategies for accessible and paywalled sources. For paywalled references, it leverages a novel Evidence Committee mechanism that infers citation validity via downstream citation consensus. To support systematic evaluation, we contribute a 5-category Miscitation Taxonomy and MisciteBench, a massive cross-disciplinary benchmark comprising 6,350 miscitation samples spanning 254 fields. Our results demonstrate that BibAgent outperforms state-of-the-art Large Language Model (LLM) baselines in citation verification accuracy and interpretability, providing scalable, transparent detection of citation misalignments across the scientific literature.</p>"
    },
    {
      "id": "f4994b275177",
      "title": "Boltzmann-GPT: Bridging Energy-Based World Models and Language Generation",
      "content": "arXiv:2601.17094v1 Announce Type: cross  Abstract: Large Language Models (LLMs) generate fluent text, yet whether they truly understand the world or merely produce plausible language about it remains contested. We propose an architectural principle, the mouth is not the brain, that explicitly separates world models from language models. Our architecture comprises three components: a Deep Boltzmann Machine (DBM) that captures domain structure as an energy-based world model, an adapter that projects latent belief states into embedding space, and a frozen GPT-2 that provides linguistic competence without domain knowledge. We instantiate this framework in the consumer review domain using Amazon smartphone reviews. Experiments demonstrate that (1) conditioning through the world model yields significantly higher sentiment correlation, lower perplexity, and greater semantic similarity compared to prompt-based generation alone; (2) the DBM's energy function distinguishes coherent from incoherent market configurations, assigning higher energy to implausible brand-price combinations; and (3) interventions on specific attributes propagate causally to generated text with intervened outputs exhibiting distributions statistically consistent with naturally occurring samples sharing the target configuration. These findings suggest that even small-scale language models can achieve consistent, controllable generation when connected to an appropriate world model, providing empirical support for separating linguistic competence from world understanding.",
      "url": "http://arxiv.org/abs/2601.17094",
      "author": "Junichiro Niimi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes Boltzmann-GPT architecture separating world models (Deep Boltzmann Machine) from language models (frozen GPT-2) with adapter projection. Demonstrates improved domain-specific generation.",
      "importance_score": 63,
      "reasoning": "Novel architectural principle for separating understanding from generation. Interesting theoretical contribution with empirical validation.",
      "themes": [
        "World Models",
        "Language Models",
        "Architecture Design"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Boltzmann-GPT architecture separating world models (Deep Boltzmann Machine) from language models (frozen GPT-2) with adapter projection. Demonstrates improved domain-specific generation.</p>",
      "content_html": "<p>arXiv:2601.17094v1 Announce Type: cross  Abstract: Large Language Models (LLMs) generate fluent text, yet whether they truly understand the world or merely produce plausible language about it remains contested. We propose an architectural principle, the mouth is not the brain, that explicitly separates world models from language models. Our architecture comprises three components: a Deep Boltzmann Machine (DBM) that captures domain structure as an energy-based world model, an adapter that projects latent belief states into embedding space, and a frozen GPT-2 that provides linguistic competence without domain knowledge. We instantiate this framework in the consumer review domain using Amazon smartphone reviews. Experiments demonstrate that (1) conditioning through the world model yields significantly higher sentiment correlation, lower perplexity, and greater semantic similarity compared to prompt-based generation alone; (2) the DBM's energy function distinguishes coherent from incoherent market configurations, assigning higher energy to implausible brand-price combinations; and (3) interventions on specific attributes propagate causally to generated text with intervened outputs exhibiting distributions statistically consistent with naturally occurring samples sharing the target configuration. These findings suggest that even small-scale language models can achieve consistent, controllable generation when connected to an appropriate world model, providing empirical support for separating linguistic competence from world understanding.</p>"
    },
    {
      "id": "7f10bdc59f5e",
      "title": "Prompt Driven Development with Claude Code: Building a Complete TUI Framework for the Ring Programming Language",
      "content": "arXiv:2601.17584v1 Announce Type: cross  Abstract: Large language models are increasingly used in software development, yet their ability to generate and maintain large, multi module systems through natural language interaction remains insufficiently characterized. This study presents an empirical analysis of developing a 7420 line Terminal User Interface framework for the Ring programming language, completed in roughly ten hours of active work spread across three days using a purely prompt driven workflow with Claude Code, Opus 4.5. The system was produced through 107 prompts: 21 feature requests, 72 bug fix prompts, 9 prompts sharing information from Ring documentation, 4 prompts providing architectural guidance, and 1 prompt dedicated to generating documentation. Development progressed across five phases, with the Window Manager phase requiring the most interaction, followed by complex UI systems and controls expansion. Bug related prompts covered redraw issues, event handling faults, runtime errors, and layout inconsistencies, while feature requests focused primarily on new widgets, window manager capabilities, and advanced UI components. Most prompts were short, reflecting a highly iterative workflow in which the human role was limited to specifying requirements, validating behaviour, and issuing corrective prompts without writing any code manually. The resulting framework includes a complete windowing subsystem, event driven architecture, interactive widgets, hierarchical menus, grid and tree components, tab controls, and a multi window desktop environment. By combining quantitative prompt analysis with qualitative assessment of model behaviour, this study provides empirical evidence that modern LLMs can sustain architectural coherence and support the construction of production grade tooling for emerging programming languages, highlighting prompt driven development as a viable methodology within software engineering practice.",
      "url": "http://arxiv.org/abs/2601.17584",
      "author": "Mahmoud Samir Fayed, Ahmed Samir Fayed",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.SE"
      ],
      "summary": "Empirical case study developing 7,420-line TUI framework using Claude Code through 107 prompts over three days, analyzing prompt categories and development patterns.",
      "importance_score": 63,
      "reasoning": "Concrete empirical data on AI-assisted development. Documents prompt-driven workflow at scale. Useful for understanding AI coding capabilities.",
      "themes": [
        "AI Coding",
        "Empirical Study",
        "Software Development"
      ],
      "continuation": null,
      "summary_html": "<p>Empirical case study developing 7,420-line TUI framework using Claude Code through 107 prompts over three days, analyzing prompt categories and development patterns.</p>",
      "content_html": "<p>arXiv:2601.17584v1 Announce Type: cross  Abstract: Large language models are increasingly used in software development, yet their ability to generate and maintain large, multi module systems through natural language interaction remains insufficiently characterized. This study presents an empirical analysis of developing a 7420 line Terminal User Interface framework for the Ring programming language, completed in roughly ten hours of active work spread across three days using a purely prompt driven workflow with Claude Code, Opus 4.5. The system was produced through 107 prompts: 21 feature requests, 72 bug fix prompts, 9 prompts sharing information from Ring documentation, 4 prompts providing architectural guidance, and 1 prompt dedicated to generating documentation. Development progressed across five phases, with the Window Manager phase requiring the most interaction, followed by complex UI systems and controls expansion. Bug related prompts covered redraw issues, event handling faults, runtime errors, and layout inconsistencies, while feature requests focused primarily on new widgets, window manager capabilities, and advanced UI components. Most prompts were short, reflecting a highly iterative workflow in which the human role was limited to specifying requirements, validating behaviour, and issuing corrective prompts without writing any code manually. The resulting framework includes a complete windowing subsystem, event driven architecture, interactive widgets, hierarchical menus, grid and tree components, tab controls, and a multi window desktop environment. By combining quantitative prompt analysis with qualitative assessment of model behaviour, this study provides empirical evidence that modern LLMs can sustain architectural coherence and support the construction of production grade tooling for emerging programming languages, highlighting prompt driven development as a viable methodology within software engineering practice.</p>"
    },
    {
      "id": "3d02d5aae54c",
      "title": "Calibrating Beyond English: Language Diversity for Better Quantized Multilingual LLM",
      "content": "arXiv:2601.18306v1 Announce Type: cross  Abstract: Quantization is an effective technique for reducing the storage footprint and computational costs of Large Language Models (LLMs), but it often results in performance degradation. Existing post-training quantization methods typically use small, English-only calibration sets; however, their impact on multilingual models remains underexplored. We systematically evaluate eight calibration settings (five single-language and three multilingual mixes) on two quantizers (GPTQ, AWQ) on data from 10 languages. Our findings reveal a consistent trend: non-English and multilingual calibration sets significantly improve perplexity compared to English-only baselines. Specifically, we observe notable average perplexity gains across both quantizers on Llama3.1 8B and Qwen2.5 7B, with multilingual mixes achieving the largest overall reductions of up to 3.52 points in perplexity. Furthermore, our analysis indicates that tailoring calibration sets to the evaluation language yields the largest improvements for individual languages, underscoring the importance of linguistic alignment. We also identify specific failure cases where certain language-quantizer combinations degrade performance, which we trace to differences in activation range distributions across languages. These results highlight that static one-size-fits-all calibration is suboptimal and that tailoring calibration data, both in language and diversity, plays a crucial role in robustly quantizing multilingual LLMs.",
      "url": "http://arxiv.org/abs/2601.18306",
      "author": "Everlyn Asiko Chimoto, Mostafa Elhoushi, Bruce A. Bassett",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Shows multilingual LLM quantization benefits from non-English calibration sets, with systematic evaluation of 8 calibration settings across 10 languages showing consistent perplexity gains versus English-only baselines.",
      "importance_score": 63,
      "reasoning": "Practical finding with immediate applicability: use multilingual calibration for multilingual models. Simple insight with clear empirical support.",
      "themes": [
        "Quantization",
        "Multilingual LLMs",
        "Model Compression"
      ],
      "continuation": null,
      "summary_html": "<p>Shows multilingual LLM quantization benefits from non-English calibration sets, with systematic evaluation of 8 calibration settings across 10 languages showing consistent perplexity gains versus English-only baselines.</p>",
      "content_html": "<p>arXiv:2601.18306v1 Announce Type: cross  Abstract: Quantization is an effective technique for reducing the storage footprint and computational costs of Large Language Models (LLMs), but it often results in performance degradation. Existing post-training quantization methods typically use small, English-only calibration sets; however, their impact on multilingual models remains underexplored. We systematically evaluate eight calibration settings (five single-language and three multilingual mixes) on two quantizers (GPTQ, AWQ) on data from 10 languages. Our findings reveal a consistent trend: non-English and multilingual calibration sets significantly improve perplexity compared to English-only baselines. Specifically, we observe notable average perplexity gains across both quantizers on Llama3.1 8B and Qwen2.5 7B, with multilingual mixes achieving the largest overall reductions of up to 3.52 points in perplexity. Furthermore, our analysis indicates that tailoring calibration sets to the evaluation language yields the largest improvements for individual languages, underscoring the importance of linguistic alignment. We also identify specific failure cases where certain language-quantizer combinations degrade performance, which we trace to differences in activation range distributions across languages. These results highlight that static one-size-fits-all calibration is suboptimal and that tailoring calibration data, both in language and diversity, plays a crucial role in robustly quantizing multilingual LLMs.</p>"
    },
    {
      "id": "e7f4d195eedc",
      "title": "Reasoning Beyond Literal: Cross-style Multimodal Reasoning for Figurative Language Understanding",
      "content": "arXiv:2601.17197v1 Announce Type: new  Abstract: Vision-language models (VLMs) have demonstrated strong reasoning abilities in literal multimodal tasks such as visual mathematics and science question answering. However, figurative language, such as sarcasm, humor, and metaphor, remains a significant challenge, as it conveys intent and emotion through subtle incongruities between expressed and intended meanings. In multimodal settings, accompanying images can amplify or invert textual meaning, demanding models that reason across modalities and account for subjectivity. We propose a three-step framework for developing efficient multimodal reasoning models that can (i) interpret multimodal figurative language, (ii) provide transparent reasoning traces, and (iii) generalize across multiple figurative styles. Experiments across four styles show that (1) incorporating reasoning traces substantially improves multimodal figurative understanding, (2) reasoning learned in one style can transfer to others, especially between related styles like sarcasm and humor, and (3) training jointly across styles yields a generalized reasoning VLM that outperforms much larger open- and closed-source models. Our findings show that lightweight VLMs with verifiable reasoning achieve robust cross-style generalization while providing inspectable reasoning traces for multimodal tasks. The code and implementation are available at https://github.com/scheshmi/CrossStyle-MMR.",
      "url": "http://arxiv.org/abs/2601.17197",
      "author": "Seyyed Saeid Cheshmi, Hahnemann Ortiz, James Mooney, Dongyeop Kang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes three-step framework for developing VLMs that can interpret multimodal figurative language (sarcasm, humor, metaphor), provide transparent reasoning traces, and generalize across figurative styles.",
      "importance_score": 63,
      "reasoning": "Addresses important capability gap in VLMs for non-literal language understanding. Valuable for more natural human-AI interaction.",
      "themes": [
        "Vision-Language Models",
        "Figurative Language",
        "Multimodal Reasoning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes three-step framework for developing VLMs that can interpret multimodal figurative language (sarcasm, humor, metaphor), provide transparent reasoning traces, and generalize across figurative styles.</p>",
      "content_html": "<p>arXiv:2601.17197v1 Announce Type: new  Abstract: Vision-language models (VLMs) have demonstrated strong reasoning abilities in literal multimodal tasks such as visual mathematics and science question answering. However, figurative language, such as sarcasm, humor, and metaphor, remains a significant challenge, as it conveys intent and emotion through subtle incongruities between expressed and intended meanings. In multimodal settings, accompanying images can amplify or invert textual meaning, demanding models that reason across modalities and account for subjectivity. We propose a three-step framework for developing efficient multimodal reasoning models that can (i) interpret multimodal figurative language, (ii) provide transparent reasoning traces, and (iii) generalize across multiple figurative styles. Experiments across four styles show that (1) incorporating reasoning traces substantially improves multimodal figurative understanding, (2) reasoning learned in one style can transfer to others, especially between related styles like sarcasm and humor, and (3) training jointly across styles yields a generalized reasoning VLM that outperforms much larger open- and closed-source models. Our findings show that lightweight VLMs with verifiable reasoning achieve robust cross-style generalization while providing inspectable reasoning traces for multimodal tasks. The code and implementation are available at https://github.com/scheshmi/CrossStyle-MMR.</p>"
    },
    {
      "id": "8a54ddf30f11",
      "title": "Align to the Pivot: Dual Alignment with Self-Feedback for Multilingual Math Reasoning",
      "content": "arXiv:2601.17671v1 Announce Type: new  Abstract: Despite the impressive reasoning abilities demonstrated by large language models (LLMs), empirical evidence indicates that they are not language agnostic as expected, leading to performance declines in multilingual settings, especially for low-resource languages. We attribute the decline to the model's inconsistent multilingual understanding and reasoning alignment. To address this, we present Pivot-Aligned Self-Feedback Multilingual Reasoning (PASMR), aiming to improve the alignment of multilingual math reasoning abilities in LLMs. This approach designates the model's primary language as the pivot language. During training, the model first translates questions into the pivot language to facilitate better alignment of reasoning patterns. The reasoning process in the target language is then supervised by the pivot language's reasoning answers, thereby establishing a cross-lingual self-feedback mechanism without relying on external correct answers or reward models. Extensive experimental results demonstrate that our method enhances both the model's understanding of questions and its reasoning capabilities, leading to notable task improvements.",
      "url": "http://arxiv.org/abs/2601.17671",
      "author": "Chunxu Zhao, Xin Huang, Xue Han, Shujian Huang, Chao Deng, Junlan Feng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents PASMR for improving multilingual math reasoning by designating primary language as pivot, translating questions for alignment, and using self-feedback for preference optimization.",
      "importance_score": 63,
      "reasoning": "Practical approach to multilingual reasoning alignment. Addresses real capability gap in LLMs for non-English math.",
      "themes": [
        "Multilingual NLP",
        "Mathematical Reasoning",
        "Alignment"
      ],
      "continuation": null,
      "summary_html": "<p>Presents PASMR for improving multilingual math reasoning by designating primary language as pivot, translating questions for alignment, and using self-feedback for preference optimization.</p>",
      "content_html": "<p>arXiv:2601.17671v1 Announce Type: new  Abstract: Despite the impressive reasoning abilities demonstrated by large language models (LLMs), empirical evidence indicates that they are not language agnostic as expected, leading to performance declines in multilingual settings, especially for low-resource languages. We attribute the decline to the model's inconsistent multilingual understanding and reasoning alignment. To address this, we present Pivot-Aligned Self-Feedback Multilingual Reasoning (PASMR), aiming to improve the alignment of multilingual math reasoning abilities in LLMs. This approach designates the model's primary language as the pivot language. During training, the model first translates questions into the pivot language to facilitate better alignment of reasoning patterns. The reasoning process in the target language is then supervised by the pivot language's reasoning answers, thereby establishing a cross-lingual self-feedback mechanism without relying on external correct answers or reward models. Extensive experimental results demonstrate that our method enhances both the model's understanding of questions and its reasoning capabilities, leading to notable task improvements.</p>"
    },
    {
      "id": "d5b660473982",
      "title": "GLEN-Bench: A Graph-Language based Benchmark for Nutritional Health",
      "content": "arXiv:2601.18106v1 Announce Type: new  Abstract: Nutritional interventions are important for managing chronic health conditions, but current computational methods provide limited support for personalized dietary guidance. We identify three key gaps: (1) dietary pattern studies often ignore real-world constraints such as socioeconomic status, comorbidities, and limited food access; (2) recommendation systems rarely explain why a particular food helps a given patient; and (3) no unified benchmark evaluates methods across the connected tasks needed for nutritional interventions. We introduce GLEN-Bench, the first comprehensive graph-language based benchmark for nutritional health assessment. We combine NHANES health records, FNDDS food composition data, and USDA food-access metrics to build a knowledge graph that links demographics, health conditions, dietary behaviors, poverty-related constraints, and nutrient needs. We test the benchmark using opioid use disorder, where models must detect subtle nutritional differences across disease stages. GLEN-Bench includes three linked tasks: risk detection identifies at-risk individuals from dietary and socioeconomic patterns; recommendation suggests personalized foods that meet clinical needs within resource constraints; and question answering provides graph-grounded, natural-language explanations to facilitate comprehension. We evaluate these graph-language approaches, including graph neural networks, large language models, and hybrid architectures, to establish solid baselines and identify practical design choices. Our analysis identifies clear dietary patterns linked to health risks, providing insights that can guide practical interventions.",
      "url": "http://arxiv.org/abs/2601.18106",
      "author": "Jiatan Huang, Zheyuan Zhang, Tianyi Ma, Mingchen Li, Yaning Zheng, Yanfang Ye, Chuxu Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces GLEN-Bench, first comprehensive graph-language benchmark for nutritional health assessment combining health records, food composition data, and food access metrics.",
      "importance_score": 63,
      "reasoning": "Novel domain-specific benchmark addressing real healthcare gaps. First unified evaluation for nutritional intervention tasks.",
      "themes": [
        "Health NLP",
        "Knowledge Graphs",
        "Benchmark"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces GLEN-Bench, first comprehensive graph-language benchmark for nutritional health assessment combining health records, food composition data, and food access metrics.</p>",
      "content_html": "<p>arXiv:2601.18106v1 Announce Type: new  Abstract: Nutritional interventions are important for managing chronic health conditions, but current computational methods provide limited support for personalized dietary guidance. We identify three key gaps: (1) dietary pattern studies often ignore real-world constraints such as socioeconomic status, comorbidities, and limited food access; (2) recommendation systems rarely explain why a particular food helps a given patient; and (3) no unified benchmark evaluates methods across the connected tasks needed for nutritional interventions. We introduce GLEN-Bench, the first comprehensive graph-language based benchmark for nutritional health assessment. We combine NHANES health records, FNDDS food composition data, and USDA food-access metrics to build a knowledge graph that links demographics, health conditions, dietary behaviors, poverty-related constraints, and nutrient needs. We test the benchmark using opioid use disorder, where models must detect subtle nutritional differences across disease stages. GLEN-Bench includes three linked tasks: risk detection identifies at-risk individuals from dietary and socioeconomic patterns; recommendation suggests personalized foods that meet clinical needs within resource constraints; and question answering provides graph-grounded, natural-language explanations to facilitate comprehension. We evaluate these graph-language approaches, including graph neural networks, large language models, and hybrid architectures, to establish solid baselines and identify practical design choices. Our analysis identifies clear dietary patterns linked to health risks, providing insights that can guide practical interventions.</p>"
    },
    {
      "id": "b9b01cac8ada",
      "title": "Hierarchical Text Classification with LLM-Refined Taxonomies",
      "content": "arXiv:2601.18375v1 Announce Type: new  Abstract: Hierarchical text classification (HTC) depends on taxonomies that organize labels into structured hierarchies. However, many real-world taxonomies introduce ambiguities, such as identical leaf names under similar parent nodes, which prevent language models (LMs) from learning clear decision boundaries. In this paper, we present TaxMorph, a framework that uses large language models (LLMs) to transform entire taxonomies through operations such as renaming, merging, splitting, and reordering. Unlike prior work, our method revises the full hierarchy to better match the semantics encoded by LMs. Experiments across three HTC benchmarks show that LLM-refined taxonomies consistently outperform human-curated ones in various settings up to +2.9pp. in F1. To better understand these improvements, we compare how well LMs can assign leaf nodes to parent nodes and vice versa across human-curated and LLM-refined taxonomies. We find that human-curated taxonomies lead to more easily separable clusters in embedding space. However, the LLM-refined taxonomies align more closely with the model's actual confusion patterns during classification. In other words, even though they are harder to separate, they better reflect the model's inductive biases. These findings suggest that LLM-guided refinement creates taxonomies that are more compatible with how models learn, improving HTC performance.",
      "url": "http://arxiv.org/abs/2601.18375",
      "author": "Jonas Golde, Nicolaas Jedema, Ravi Krishnan, Phong Le",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents TaxMorph, a framework using LLMs to transform taxonomies through operations like renaming, merging, splitting for hierarchical text classification. Shows LLM-refined taxonomies outperform human-curated ones.",
      "importance_score": 63,
      "reasoning": "Novel application of LLMs to taxonomy optimization with consistent improvements. Practical contribution to HTC.",
      "themes": [
        "Hierarchical Classification",
        "Taxonomy",
        "LLM Applications"
      ],
      "continuation": null,
      "summary_html": "<p>Presents TaxMorph, a framework using LLMs to transform taxonomies through operations like renaming, merging, splitting for hierarchical text classification. Shows LLM-refined taxonomies outperform human-curated ones.</p>",
      "content_html": "<p>arXiv:2601.18375v1 Announce Type: new  Abstract: Hierarchical text classification (HTC) depends on taxonomies that organize labels into structured hierarchies. However, many real-world taxonomies introduce ambiguities, such as identical leaf names under similar parent nodes, which prevent language models (LMs) from learning clear decision boundaries. In this paper, we present TaxMorph, a framework that uses large language models (LLMs) to transform entire taxonomies through operations such as renaming, merging, splitting, and reordering. Unlike prior work, our method revises the full hierarchy to better match the semantics encoded by LMs. Experiments across three HTC benchmarks show that LLM-refined taxonomies consistently outperform human-curated ones in various settings up to +2.9pp. in F1. To better understand these improvements, we compare how well LMs can assign leaf nodes to parent nodes and vice versa across human-curated and LLM-refined taxonomies. We find that human-curated taxonomies lead to more easily separable clusters in embedding space. However, the LLM-refined taxonomies align more closely with the model's actual confusion patterns during classification. In other words, even though they are harder to separate, they better reflect the model's inductive biases. These findings suggest that LLM-guided refinement creates taxonomies that are more compatible with how models learn, improving HTC performance.</p>"
    },
    {
      "id": "5423f41233a5",
      "title": "FGGM: Fisher-Guided Gradient Masking for Continual Learning",
      "content": "arXiv:2601.18261v1 Announce Type: cross  Abstract: Catastrophic forgetting impairs the continuous learning of large language models. We propose Fisher-Guided Gradient Masking (FGGM), a framework that mitigates this by strategically selecting parameters for updates using diagonal Fisher Information. FGGM dynamically generates binary masks with adaptive thresholds, preserving critical parameters to balance stability and plasticity without requiring historical data. Unlike magnitude-based methods such as MIGU, our approach offers a mathematically principled parameter importance estimation. On the TRACE benchmark, FGGM shows a 9.6% relative improvement in retaining general capabilities over supervised fine-tuning (SFT) and a 4.4% improvement over MIGU on TRACE tasks. Additional analysis on code generation tasks confirms FGGM's superior performance and reduced forgetting, establishing it as an effective solution.",
      "url": "http://arxiv.org/abs/2601.18261",
      "author": "Chao-Hong Tan, Qian Chen, Wen Wang, Yukun Ma, Chong Zhang, Chong Deng, Qinglin Zhang, Xiangang Li, Jieping Ye",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes FGGM using Fisher Information to guide gradient masking for continual learning, mitigating catastrophic forgetting without requiring historical data. Shows 9.6% improvement over SFT on TRACE benchmark.",
      "importance_score": 63,
      "reasoning": "Principled approach to catastrophic forgetting with solid empirical results. Relevant to practical LLM deployment scenarios.",
      "themes": [
        "Continual Learning",
        "Catastrophic Forgetting",
        "LLM Fine-tuning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes FGGM using Fisher Information to guide gradient masking for continual learning, mitigating catastrophic forgetting without requiring historical data. Shows 9.6% improvement over SFT on TRACE benchmark.</p>",
      "content_html": "<p>arXiv:2601.18261v1 Announce Type: cross  Abstract: Catastrophic forgetting impairs the continuous learning of large language models. We propose Fisher-Guided Gradient Masking (FGGM), a framework that mitigates this by strategically selecting parameters for updates using diagonal Fisher Information. FGGM dynamically generates binary masks with adaptive thresholds, preserving critical parameters to balance stability and plasticity without requiring historical data. Unlike magnitude-based methods such as MIGU, our approach offers a mathematically principled parameter importance estimation. On the TRACE benchmark, FGGM shows a 9.6% relative improvement in retaining general capabilities over supervised fine-tuning (SFT) and a 4.4% improvement over MIGU on TRACE tasks. Additional analysis on code generation tasks confirms FGGM's superior performance and reduced forgetting, establishing it as an effective solution.</p>"
    },
    {
      "id": "c3bcc7b37f66",
      "title": "PocketGS: On-Device Training of 3D Gaussian Splatting for High Perceptual Modeling",
      "content": "arXiv:2601.17354v1 Announce Type: new  Abstract: Efficient and high-fidelity 3D scene modeling is a long-standing pursuit in computer graphics. While recent 3D Gaussian Splatting (3DGS) methods achieve impressive real-time modeling performance, they rely on resource-unconstrained training assumptions that fail on mobile devices, which are limited by minute-scale training budgets and hardware-available peak-memory. We present PocketGS, a mobile scene modeling paradigm that enables on-device 3DGS training under these tightly coupled constraints while preserving high perceptual fidelity. Our method resolves the fundamental contradictions of standard 3DGS through three co-designed operators: G builds geometry-faithful point-cloud priors; I injects local surface statistics to seed anisotropic Gaussians, thereby reducing early conditioning gaps; and T unrolls alpha compositing with cached intermediates and index-mapped gradient scattering for stable mobile backpropagation. Collectively, these operators satisfy the competing requirements of training efficiency, memory compactness, and modeling fidelity. Extensive experiments demonstrate that PocketGS is able to outperform the powerful mainstream workstation 3DGS baseline to deliver high-quality reconstructions, enabling a fully on-device, practical capture-to-rendering workflow.",
      "url": "http://arxiv.org/abs/2601.17354",
      "author": "Wenzhi Guo, Guangchi Fang, Shu Yang, Bing Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes PocketGS enabling on-device 3DGS training on mobile devices under minute-scale training budgets and memory constraints while preserving perceptual fidelity.",
      "importance_score": 63,
      "reasoning": "Addresses important practical challenge of mobile 3D scene modeling with co-designed efficient operators.",
      "themes": [
        "3D Gaussian Splatting",
        "Mobile AI",
        "Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes PocketGS enabling on-device 3DGS training on mobile devices under minute-scale training budgets and memory constraints while preserving perceptual fidelity.</p>",
      "content_html": "<p>arXiv:2601.17354v1 Announce Type: new  Abstract: Efficient and high-fidelity 3D scene modeling is a long-standing pursuit in computer graphics. While recent 3D Gaussian Splatting (3DGS) methods achieve impressive real-time modeling performance, they rely on resource-unconstrained training assumptions that fail on mobile devices, which are limited by minute-scale training budgets and hardware-available peak-memory. We present PocketGS, a mobile scene modeling paradigm that enables on-device 3DGS training under these tightly coupled constraints while preserving high perceptual fidelity. Our method resolves the fundamental contradictions of standard 3DGS through three co-designed operators: G builds geometry-faithful point-cloud priors; I injects local surface statistics to seed anisotropic Gaussians, thereby reducing early conditioning gaps; and T unrolls alpha compositing with cached intermediates and index-mapped gradient scattering for stable mobile backpropagation. Collectively, these operators satisfy the competing requirements of training efficiency, memory compactness, and modeling fidelity. Extensive experiments demonstrate that PocketGS is able to outperform the powerful mainstream workstation 3DGS baseline to deliver high-quality reconstructions, enabling a fully on-device, practical capture-to-rendering workflow.</p>"
    },
    {
      "id": "c7155111dc11",
      "title": "PILOT: A Perceptive Integrated Low-level Controller for Loco-manipulation over Unstructured Scenes",
      "content": "arXiv:2601.17440v1 Announce Type: new  Abstract: Humanoid robots hold great potential for diverse interactions and daily service tasks within human-centered environments, necessitating controllers that seamlessly integrate precise locomotion with dexterous manipulation. However, most existing whole-body controllers lack exteroceptive awareness of the surrounding environment, rendering them insufficient for stable task execution in complex, unstructured scenarios.To address this challenge, we propose PILOT, a unified single-stage reinforcement learning (RL) framework tailored for perceptive loco-manipulation, which synergizes perceptive locomotion and expansive whole-body control within a single policy. To enhance terrain awareness and ensure precise foot placement, we design a cross-modal context encoder that fuses prediction-based proprioceptive features with attention-based perceptive representations. Furthermore, we introduce a Mixture-of-Experts (MoE) policy architecture to coordinate diverse motor skills, facilitating better specialization across distinct motion patterns. Extensive experiments in both simulation and on the physical Unitree G1 humanoid robot validate the efficacy of our framework. PILOT demonstrates superior stability, command tracking precision, and terrain traversability compared to existing baselines. These results highlight its potential to serve as a robust, foundational low-level controller for loco-manipulation in unstructured scenes.",
      "url": "http://arxiv.org/abs/2601.17440",
      "author": "Xinru Cui, Linxi Feng, Yixuan Zhou, Haoqi Han, Zhe Liu, Hesheng Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Introduces PILOT, a single-stage RL framework for perceptive loco-manipulation in humanoid robots with cross-modal perception for terrain awareness and precise foot placement.",
      "importance_score": 63,
      "reasoning": "Important contribution to humanoid whole-body control with perceptive capabilities, addresses key challenge in humanoid robotics.",
      "themes": [
        "Humanoid Robotics",
        "Loco-manipulation",
        "Perceptive Control"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces PILOT, a single-stage RL framework for perceptive loco-manipulation in humanoid robots with cross-modal perception for terrain awareness and precise foot placement.</p>",
      "content_html": "<p>arXiv:2601.17440v1 Announce Type: new  Abstract: Humanoid robots hold great potential for diverse interactions and daily service tasks within human-centered environments, necessitating controllers that seamlessly integrate precise locomotion with dexterous manipulation. However, most existing whole-body controllers lack exteroceptive awareness of the surrounding environment, rendering them insufficient for stable task execution in complex, unstructured scenarios.To address this challenge, we propose PILOT, a unified single-stage reinforcement learning (RL) framework tailored for perceptive loco-manipulation, which synergizes perceptive locomotion and expansive whole-body control within a single policy. To enhance terrain awareness and ensure precise foot placement, we design a cross-modal context encoder that fuses prediction-based proprioceptive features with attention-based perceptive representations. Furthermore, we introduce a Mixture-of-Experts (MoE) policy architecture to coordinate diverse motor skills, facilitating better specialization across distinct motion patterns. Extensive experiments in both simulation and on the physical Unitree G1 humanoid robot validate the efficacy of our framework. PILOT demonstrates superior stability, command tracking precision, and terrain traversability compared to existing baselines. These results highlight its potential to serve as a robust, foundational low-level controller for loco-manipulation in unstructured scenes.</p>"
    },
    {
      "id": "ecf7c0d8838a",
      "title": "Auditing Disability Representation in Vision-Language Models",
      "content": "arXiv:2601.17348v1 Announce Type: new  Abstract: Vision-language models (VLMs) are increasingly deployed in socially sensitive applications, yet their behavior with respect to disability remains underexplored. We study disability aware descriptions for person centric images, where models often transition from evidence grounded factual description to interpretation shift including introduction of unsupported inferences beyond observable visual evidence. To systematically analyze this phenomenon, we introduce a benchmark based on paired Neutral Prompts (NP) and Disability-Contextualised Prompts (DP) and evaluate 15 state-of-the-art open- and closed-source VLMs under a zero-shot setting across 9 disability categories. Our evaluation framework treats interpretive fidelity as core objective and combines standard text-based metrics capturing affective degradation through shifts in sentiment, social regard and response length with an LLM-as-judge protocol, validated by annotators with lived experience of disability. We find that introducing disability context consistently degrades interpretive fidelity, inducing interpretation shifts characterised by speculative inference, narrative elaboration, affective degradation and deficit oriented framing. These effects are further amplified along race and gender dimension. Finally, we demonstrate targeted prompting and preference fine-tuning effectively improves interpretive fidelity and reduces substantially interpretation shifts.",
      "url": "http://arxiv.org/abs/2601.17348",
      "author": "Srikant Panda, Sourabh Singh Yadav, Palkesh Malviya",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Audits 15 state-of-the-art VLMs for disability representation bias, introducing a benchmark with paired neutral and disability-contextualized prompts across 9 disability categories to measure interpretive shift.",
      "importance_score": 62,
      "reasoning": "Important fairness/bias work in an underexplored area; systematic benchmark enables future progress on disability representation.",
      "themes": [
        "AI Fairness",
        "Vision-Language Models",
        "Bias Evaluation"
      ],
      "continuation": null,
      "summary_html": "<p>Audits 15 state-of-the-art VLMs for disability representation bias, introducing a benchmark with paired neutral and disability-contextualized prompts across 9 disability categories to measure interpretive shift.</p>",
      "content_html": "<p>arXiv:2601.17348v1 Announce Type: new  Abstract: Vision-language models (VLMs) are increasingly deployed in socially sensitive applications, yet their behavior with respect to disability remains underexplored. We study disability aware descriptions for person centric images, where models often transition from evidence grounded factual description to interpretation shift including introduction of unsupported inferences beyond observable visual evidence. To systematically analyze this phenomenon, we introduce a benchmark based on paired Neutral Prompts (NP) and Disability-Contextualised Prompts (DP) and evaluate 15 state-of-the-art open- and closed-source VLMs under a zero-shot setting across 9 disability categories. Our evaluation framework treats interpretive fidelity as core objective and combines standard text-based metrics capturing affective degradation through shifts in sentiment, social regard and response length with an LLM-as-judge protocol, validated by annotators with lived experience of disability. We find that introducing disability context consistently degrades interpretive fidelity, inducing interpretation shifts characterised by speculative inference, narrative elaboration, affective degradation and deficit oriented framing. These effects are further amplified along race and gender dimension. Finally, we demonstrate targeted prompting and preference fine-tuning effectively improves interpretive fidelity and reduces substantially interpretation shifts.</p>"
    },
    {
      "id": "a9abc1d2ec80",
      "title": "GAIA: A Data Flywheel System for Training GUI Test-Time Scaling Critic Models",
      "content": "arXiv:2601.18197v1 Announce Type: new  Abstract: While Large Vision-Language Models (LVLMs) have significantly advanced GUI agents' capabilities in parsing textual instructions, interpreting screen content, and executing tasks, a critical challenge persists: the irreversibility of agent operations, where a single erroneous action can trigger catastrophic deviations. To address this, we propose the GUI Action Critic's Data Flywheel System (GAIA), a training framework that enables the models to have iterative critic capabilities, which are used to improve the Test-Time Scaling (TTS) of basic GUI agents' performance. Specifically, we train an Intuitive Critic Model (ICM) using positive and negative action examples from a base agent first. This critic evaluates the immediate correctness of the agent's intended actions, thereby selecting operations with higher success probability. Then, the initial critic guides agent actions to collect refined positive/negative samples, initiating the self-improving cycle. The augmented data then trains a second-round critic with enhanced discernment capability. We conduct experiments on various datasets and demonstrate that the proposed ICM can improve the test-time performance of various closed-source and open-source models, and the performance can be gradually improved as the data is recycled. The code and dataset will be publicly released.",
      "url": "http://arxiv.org/abs/2601.18197",
      "author": "Shaokang Wang, Pei Fu, Ruoceng Zhang, Shaojie Zhang, Xiuwen Xi, Jiahui Yang, Bin Qin, Ying Huang, Zhenbo Luo, Jian Luan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes GAIA data flywheel system training GUI Action Critic Models for test-time scaling, using intuitive critics with tree search for both immediate and long-term action evaluation.",
      "importance_score": 62,
      "reasoning": "Practical approach to improving GUI agents with verification; addresses irreversibility challenge in agent actions.",
      "themes": [
        "GUI Agents",
        "Test-Time Scaling",
        "Verification"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes GAIA data flywheel system training GUI Action Critic Models for test-time scaling, using intuitive critics with tree search for both immediate and long-term action evaluation.</p>",
      "content_html": "<p>arXiv:2601.18197v1 Announce Type: new  Abstract: While Large Vision-Language Models (LVLMs) have significantly advanced GUI agents' capabilities in parsing textual instructions, interpreting screen content, and executing tasks, a critical challenge persists: the irreversibility of agent operations, where a single erroneous action can trigger catastrophic deviations. To address this, we propose the GUI Action Critic's Data Flywheel System (GAIA), a training framework that enables the models to have iterative critic capabilities, which are used to improve the Test-Time Scaling (TTS) of basic GUI agents' performance. Specifically, we train an Intuitive Critic Model (ICM) using positive and negative action examples from a base agent first. This critic evaluates the immediate correctness of the agent's intended actions, thereby selecting operations with higher success probability. Then, the initial critic guides agent actions to collect refined positive/negative samples, initiating the self-improving cycle. The augmented data then trains a second-round critic with enhanced discernment capability. We conduct experiments on various datasets and demonstrate that the proposed ICM can improve the test-time performance of various closed-source and open-source models, and the performance can be gradually improved as the data is recycled. The code and dataset will be publicly released.</p>"
    },
    {
      "id": "9d0fcdf47887",
      "title": "Why Keep Your Doubts to Yourself? Trading Visual Uncertainties in Multi-Agent Bandit Systems",
      "content": "arXiv:2601.18735v1 Announce Type: new  Abstract: Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We introduce Agora, a framework that reframes coordination as a decentralized market for uncertainty. Agora formalizes epistemic uncertainty into a structured, tradable asset (perceptual, semantic, inferential), and enforces profitability-driven trading among agents based on rational economic rules. A market-aware broker, extending Thompson Sampling, initiates collaboration and guides the system toward cost-efficient equilibria. Experiments on five multimodal benchmarks (MMMU, MMBench, MathVision, InfoVQA, CC-OCR) show that Agora outperforms strong VLMs and heuristic multi-agent strategies, e.g., achieving +8.5% accuracy over the best baseline on MMMU while reducing cost by over 3x. These results establish market-based coordination as a principled and scalable paradigm for building economically viable multi-agent visual intelligence systems.",
      "url": "http://arxiv.org/abs/2601.18735",
      "author": "Jusheng Zhang, Yijia Fan, Kaitong Cai, Jing Yang, Jiawei Yao, Jian Wang, Guanlong Qu, Ziliang Chen, Keze Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces Agora framework treating epistemic uncertainty as tradable asset in multi-agent VLM systems, enabling decentralized market-based coordination with profitability-driven trading.",
      "importance_score": 62,
      "reasoning": "Novel economic framing for multi-agent coordination; principled approach to scaling heterogeneous agents.",
      "themes": [
        "Multi-Agent Systems",
        "Vision-Language Models",
        "Market Design"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Agora framework treating epistemic uncertainty as tradable asset in multi-agent VLM systems, enabling decentralized market-based coordination with profitability-driven trading.</p>",
      "content_html": "<p>arXiv:2601.18735v1 Announce Type: new  Abstract: Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We introduce Agora, a framework that reframes coordination as a decentralized market for uncertainty. Agora formalizes epistemic uncertainty into a structured, tradable asset (perceptual, semantic, inferential), and enforces profitability-driven trading among agents based on rational economic rules. A market-aware broker, extending Thompson Sampling, initiates collaboration and guides the system toward cost-efficient equilibria. Experiments on five multimodal benchmarks (MMMU, MMBench, MathVision, InfoVQA, CC-OCR) show that Agora outperforms strong VLMs and heuristic multi-agent strategies, e.g., achieving +8.5% accuracy over the best baseline on MMMU while reducing cost by over 3x. These results establish market-based coordination as a principled and scalable paradigm for building economically viable multi-agent visual intelligence systems.</p>"
    },
    {
      "id": "01ed0d55e864",
      "title": "MathMixup: Boosting LLM Mathematical Reasoning with Difficulty-Controllable Data Synthesis and Curriculum Learning",
      "content": "arXiv:2601.17006v1 Announce Type: cross  Abstract: In mathematical reasoning tasks, the advancement of Large Language Models (LLMs) relies heavily on high-quality training data with clearly defined and well-graded difficulty levels. However, existing data synthesis methods often suffer from limited diversity and lack precise control over problem difficulty, making them insufficient for supporting efficient training paradigms such as curriculum learning. To address these challenges, we propose MathMixup, a novel data synthesis paradigm that systematically generates high-quality, difficulty-controllable mathematical reasoning problems through hybrid and decomposed strategies. Automated self-checking and manual screening are incorporated to ensure semantic clarity and a well-structured difficulty gradient in the synthesized data. Building on this, we construct the MathMixupQA dataset and design a curriculum learning strategy that leverages these graded problems, supporting flexible integration with other datasets. Experimental results show that MathMixup and its curriculum learning strategy significantly enhance the mathematical reasoning performance of LLMs. Fine-tuned Qwen2.5-7B achieves an average score of 52.6\\% across seven mathematical benchmarks, surpassing previous state-of-the-art methods. These results fully validate the effectiveness and broad applicability of MathMixup in improving the mathematical reasoning abilities of LLMs and advancing data-centric curriculum learning.",
      "url": "http://arxiv.org/abs/2601.17006",
      "author": "Xuchen Li, Jing Chen, Xuzhao Li, Hao Liang, Xiaohuan Zhou, Taifeng Wang, Wentao Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces MathMixup, a data synthesis paradigm for generating difficulty-controllable mathematical reasoning problems through hybrid decomposition strategies. Enables curriculum learning for LLMs.",
      "importance_score": 62,
      "reasoning": "Addresses important challenge of controlled difficulty in math reasoning data. Relevant to improving LLM reasoning capabilities but incremental methodology.",
      "themes": [
        "LLM Reasoning",
        "Data Synthesis",
        "Curriculum Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces MathMixup, a data synthesis paradigm for generating difficulty-controllable mathematical reasoning problems through hybrid decomposition strategies. Enables curriculum learning for LLMs.</p>",
      "content_html": "<p>arXiv:2601.17006v1 Announce Type: cross  Abstract: In mathematical reasoning tasks, the advancement of Large Language Models (LLMs) relies heavily on high-quality training data with clearly defined and well-graded difficulty levels. However, existing data synthesis methods often suffer from limited diversity and lack precise control over problem difficulty, making them insufficient for supporting efficient training paradigms such as curriculum learning. To address these challenges, we propose MathMixup, a novel data synthesis paradigm that systematically generates high-quality, difficulty-controllable mathematical reasoning problems through hybrid and decomposed strategies. Automated self-checking and manual screening are incorporated to ensure semantic clarity and a well-structured difficulty gradient in the synthesized data. Building on this, we construct the MathMixupQA dataset and design a curriculum learning strategy that leverages these graded problems, supporting flexible integration with other datasets. Experimental results show that MathMixup and its curriculum learning strategy significantly enhance the mathematical reasoning performance of LLMs. Fine-tuned Qwen2.5-7B achieves an average score of 52.6\\% across seven mathematical benchmarks, surpassing previous state-of-the-art methods. These results fully validate the effectiveness and broad applicability of MathMixup in improving the mathematical reasoning abilities of LLMs and advancing data-centric curriculum learning.</p>"
    },
    {
      "id": "ea6ff90b7508",
      "title": "ChemNavigator: Agentic AI Discovery of Design Rules for Organic Photocatalysts",
      "content": "arXiv:2601.17084v1 Announce Type: cross  Abstract: The discovery of high-performance organic photocatalysts for hydrogen evolution remains limited by the vastness of chemical space and the reliance on human intuition for molecular design. Here we present ChemNavigator, an agentic AI system that autonomously derives structure-property relationships through hypothesis-driven exploration of organic photocatalyst candidates. The system integrates large language model reasoning with density functional tight binding calculations in a multi-agent architecture that mirrors the scientific method: formulating hypotheses, designing experiments, executing calculations, and validating findings through rigorous statistical analysis. Through iterative discovery cycles encompassing 200 molecules, ChemNavigator autonomously identified six statistically significant design rules governing frontier orbital energies, including the effects of ether linkages, carbonyl groups, extended conjugation, cyano groups, halogen substituents, and amine groups. Importantly, these rules correspond to established principles of organic electronic structure (resonance donation, inductive withdrawal, $\\pi$-delocalization), demonstrating that the system can independently derive chemical knowledge without explicit programming. Notably, autonomous agentic reasoning extracted these six validated rules from a molecular library where previous ML approaches identified only carbonyl effects. Furthermore, the quantified effect sizes provide a prioritized ranking for synthetic chemists, while feature interaction analysis revealed diminishing returns when combining strategies, challenging additive assumptions in molecular design. This work demonstrates that agentic AI systems can autonomously derive interpretable, chemically grounded design principles, establishing a framework for AI-assisted materials discovery that complements rather than replaces chemical intuition.",
      "url": "http://arxiv.org/abs/2601.17084",
      "author": "Iman Peivaste, Ahmed Makradi, Salim Belouettar",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "physics.chem-ph"
      ],
      "summary": "Presents ChemNavigator, a multi-agent AI system for autonomous discovery of structure-property relationships in organic photocatalysts through hypothesis-driven exploration.",
      "importance_score": 62,
      "reasoning": "Novel agentic approach to scientific discovery. Demonstrates effective LLM-DFT integration for materials science.",
      "themes": [
        "Scientific Discovery",
        "Agentic AI",
        "Materials Science"
      ],
      "continuation": null,
      "summary_html": "<p>Presents ChemNavigator, a multi-agent AI system for autonomous discovery of structure-property relationships in organic photocatalysts through hypothesis-driven exploration.</p>",
      "content_html": "<p>arXiv:2601.17084v1 Announce Type: cross  Abstract: The discovery of high-performance organic photocatalysts for hydrogen evolution remains limited by the vastness of chemical space and the reliance on human intuition for molecular design. Here we present ChemNavigator, an agentic AI system that autonomously derives structure-property relationships through hypothesis-driven exploration of organic photocatalyst candidates. The system integrates large language model reasoning with density functional tight binding calculations in a multi-agent architecture that mirrors the scientific method: formulating hypotheses, designing experiments, executing calculations, and validating findings through rigorous statistical analysis. Through iterative discovery cycles encompassing 200 molecules, ChemNavigator autonomously identified six statistically significant design rules governing frontier orbital energies, including the effects of ether linkages, carbonyl groups, extended conjugation, cyano groups, halogen substituents, and amine groups. Importantly, these rules correspond to established principles of organic electronic structure (resonance donation, inductive withdrawal, $\\pi$-delocalization), demonstrating that the system can independently derive chemical knowledge without explicit programming. Notably, autonomous agentic reasoning extracted these six validated rules from a molecular library where previous ML approaches identified only carbonyl effects. Furthermore, the quantified effect sizes provide a prioritized ranking for synthetic chemists, while feature interaction analysis revealed diminishing returns when combining strategies, challenging additive assumptions in molecular design. This work demonstrates that agentic AI systems can autonomously derive interpretable, chemically grounded design principles, establishing a framework for AI-assisted materials discovery that complements rather than replaces chemical intuition.</p>"
    },
    {
      "id": "6b297def4222",
      "title": "Spectral Geometry for Deep Learning: Compression and Hallucination Detection via Random Matrix Theory",
      "content": "arXiv:2601.17357v1 Announce Type: cross  Abstract: Large language models and deep neural networks achieve strong performance but suffer from reliability issues and high computational cost. This thesis proposes a unified framework based on spectral geometry and random matrix theory to address both problems by analyzing the eigenvalue structure of hidden activations. The first contribution, EigenTrack, is a real-time method for detecting hallucinations and out-of-distribution behavior in language and vision-language models using spectral features and their temporal dynamics. The second contribution, RMT-KD, is a principled compression method that identifies informative spectral components and applies iterative knowledge distillation to produce compact and efficient models while preserving accuracy. Together, these results show that spectral statistics provide interpretable and robust signals for monitoring uncertainty and guiding compression in large-scale neural networks.",
      "url": "http://arxiv.org/abs/2601.17357",
      "author": "Davide Ettori",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes unified framework using spectral geometry and RMT for both hallucination detection (EigenTrack) and model compression (RMT-KD) through eigenvalue structure analysis.",
      "importance_score": 62,
      "reasoning": "Novel unified approach to two important problems. Interesting theoretical foundation with practical applications.",
      "themes": [
        "Hallucination Detection",
        "Model Compression",
        "Random Matrix Theory"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes unified framework using spectral geometry and RMT for both hallucination detection (EigenTrack) and model compression (RMT-KD) through eigenvalue structure analysis.</p>",
      "content_html": "<p>arXiv:2601.17357v1 Announce Type: cross  Abstract: Large language models and deep neural networks achieve strong performance but suffer from reliability issues and high computational cost. This thesis proposes a unified framework based on spectral geometry and random matrix theory to address both problems by analyzing the eigenvalue structure of hidden activations. The first contribution, EigenTrack, is a real-time method for detecting hallucinations and out-of-distribution behavior in language and vision-language models using spectral features and their temporal dynamics. The second contribution, RMT-KD, is a principled compression method that identifies informative spectral components and applies iterative knowledge distillation to produce compact and efficient models while preserving accuracy. Together, these results show that spectral statistics provide interpretable and robust signals for monitoring uncertainty and guiding compression in large-scale neural networks.</p>"
    },
    {
      "id": "c4b848836d4a",
      "title": "Status Hierarchies in Language Models",
      "content": "arXiv:2601.17577v1 Announce Type: cross  Abstract: From school playgrounds to corporate boardrooms, status hierarchies -- rank orderings based on respect and perceived competence -- are universal features of human social organization. Language models trained on human-generated text inevitably encounter these hierarchical patterns embedded in language, raising the question of whether they might reproduce such dynamics in multi-agent settings. This thesis investigates when and how language models form status hierarchies by adapting Berger et al.'s (1972) expectation states framework. I create multi-agent scenarios where separate language model instances complete sentiment classification tasks, are introduced with varying status characteristics (e.g., credentials, expertise), then have opportunities to revise their initial judgments after observing their partner's responses. The dependent variable is deference, the rate at which models shift their ratings toward their partner's position based on status cues rather than task information. Results show that language models form significant status hierarchies when capability is equal (35 percentage point asymmetry, p < .001), but capability differences dominate status cues, with the most striking effect being that high-status assignments reduce higher-capability models' deference rather than increasing lower-capability models' deference. The implications for AI safety are significant: status-seeking behavior could introduce deceptive strategies, amplify discriminatory biases, and scale across distributed deployments far faster than human hierarchies form organically. This work identifies emergent social behaviors in AI systems and highlights a previously underexplored dimension of the alignment challenge.",
      "url": "http://arxiv.org/abs/2601.17577",
      "author": "Emilio Barkett",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.HC"
      ],
      "summary": "Investigates whether LLMs form status hierarchies in multi-agent settings, adapting expectation states framework to show models reproduce social hierarchical patterns from training data.",
      "importance_score": 62,
      "reasoning": "Novel sociological perspective on multi-agent LLM systems. Well-grounded in social psychology theory. Implications for multi-agent deployment.",
      "themes": [
        "Multi-agent Systems",
        "LLM Behavior",
        "Social Dynamics"
      ],
      "continuation": null,
      "summary_html": "<p>Investigates whether LLMs form status hierarchies in multi-agent settings, adapting expectation states framework to show models reproduce social hierarchical patterns from training data.</p>",
      "content_html": "<p>arXiv:2601.17577v1 Announce Type: cross  Abstract: From school playgrounds to corporate boardrooms, status hierarchies -- rank orderings based on respect and perceived competence -- are universal features of human social organization. Language models trained on human-generated text inevitably encounter these hierarchical patterns embedded in language, raising the question of whether they might reproduce such dynamics in multi-agent settings. This thesis investigates when and how language models form status hierarchies by adapting Berger et al.'s (1972) expectation states framework. I create multi-agent scenarios where separate language model instances complete sentiment classification tasks, are introduced with varying status characteristics (e.g., credentials, expertise), then have opportunities to revise their initial judgments after observing their partner's responses. The dependent variable is deference, the rate at which models shift their ratings toward their partner's position based on status cues rather than task information. Results show that language models form significant status hierarchies when capability is equal (35 percentage point asymmetry, p &lt; .001), but capability differences dominate status cues, with the most striking effect being that high-status assignments reduce higher-capability models' deference rather than increasing lower-capability models' deference. The implications for AI safety are significant: status-seeking behavior could introduce deceptive strategies, amplify discriminatory biases, and scale across distributed deployments far faster than human hierarchies form organically. This work identifies emergent social behaviors in AI systems and highlights a previously underexplored dimension of the alignment challenge.</p>"
    },
    {
      "id": "7eace5bdf98d",
      "title": "BoRP: Bootstrapped Regression Probing for Scalable and Human-Aligned LLM Evaluation",
      "content": "arXiv:2601.18253v1 Announce Type: cross  Abstract: Accurate evaluation of user satisfaction is critical for iterative development of conversational AI. However, for open-ended assistants, traditional A/B testing lacks reliable metrics: explicit feedback is sparse, while implicit metrics are ambiguous. To bridge this gap, we introduce BoRP (Bootstrapped Regression Probing), a scalable framework for high-fidelity satisfaction evaluation. Unlike generative approaches, BoRP leverages the geometric properties of LLM latent space. It employs a polarization-index-based bootstrapping mechanism to automate rubric generation and utilizes Partial Least Squares (PLS) to map hidden states to continuous scores. Experiments on industrial datasets show that BoRP (Qwen3-8B/14B) significantly outperforms generative baselines (even Qwen3-Max) in alignment with human judgments. Furthermore, BoRP reduces inference costs by orders of magnitude, enabling full-scale monitoring and highly sensitive A/B testing via CUPED.",
      "url": "http://arxiv.org/abs/2601.18253",
      "author": "Peng Sun, Xiangyu Zhang, Duan Wu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces BoRP framework for LLM evaluation using bootstrapped regression probing of latent space geometry. Claims to outperform generative evaluation approaches on industrial datasets.",
      "importance_score": 62,
      "reasoning": "Novel approach to LLM evaluation leveraging latent space properties. Practical relevance for conversational AI evaluation but claims need broader validation.",
      "themes": [
        "LLM Evaluation",
        "Latent Space Analysis",
        "Conversational AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces BoRP framework for LLM evaluation using bootstrapped regression probing of latent space geometry. Claims to outperform generative evaluation approaches on industrial datasets.</p>",
      "content_html": "<p>arXiv:2601.18253v1 Announce Type: cross  Abstract: Accurate evaluation of user satisfaction is critical for iterative development of conversational AI. However, for open-ended assistants, traditional A/B testing lacks reliable metrics: explicit feedback is sparse, while implicit metrics are ambiguous. To bridge this gap, we introduce BoRP (Bootstrapped Regression Probing), a scalable framework for high-fidelity satisfaction evaluation. Unlike generative approaches, BoRP leverages the geometric properties of LLM latent space. It employs a polarization-index-based bootstrapping mechanism to automate rubric generation and utilizes Partial Least Squares (PLS) to map hidden states to continuous scores. Experiments on industrial datasets show that BoRP (Qwen3-8B/14B) significantly outperforms generative baselines (even Qwen3-Max) in alignment with human judgments. Furthermore, BoRP reduces inference costs by orders of magnitude, enabling full-scale monitoring and highly sensitive A/B testing via CUPED.</p>"
    },
    {
      "id": "21454b4af983",
      "title": "PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation",
      "content": "arXiv:2601.18777v1 Announce Type: cross  Abstract: Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.",
      "url": "http://arxiv.org/abs/2601.18777",
      "author": "Abhishek Divekar, Anirban Majumder",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces PRECISE framework combining minimal human annotations (100 queries) with LLM judgments via Prediction-Powered Inference for unbiased ranking metric estimation.",
      "importance_score": 62,
      "reasoning": "Practical framework reducing annotation requirements 100x while maintaining reliability. Addresses real evaluation bottleneck.",
      "themes": [
        "LLM Evaluation",
        "Statistical Methods",
        "Annotation Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces PRECISE framework combining minimal human annotations (100 queries) with LLM judgments via Prediction-Powered Inference for unbiased ranking metric estimation.</p>",
      "content_html": "<p>arXiv:2601.18777v1 Announce Type: cross  Abstract: Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.</p>"
    },
    {
      "id": "3ccd274060dc",
      "title": "AnyView: Synthesizing Any Novel View in Dynamic Scenes",
      "content": "arXiv:2601.16982v1 Announce Type: cross  Abstract: Modern generative video models excel at producing convincing, high-quality outputs, but struggle to maintain multi-view and spatiotemporal consistency in highly dynamic real-world environments. In this work, we introduce \\textbf{AnyView}, a diffusion-based video generation framework for \\emph{dynamic view synthesis} with minimal inductive biases or geometric assumptions. We leverage multiple data sources with various levels of supervision, including monocular (2D), multi-view static (3D) and multi-view dynamic (4D) datasets, to train a generalist spatiotemporal implicit representation capable of producing zero-shot novel videos from arbitrary camera locations and trajectories. We evaluate AnyView on standard benchmarks, showing competitive results with the current state of the art, and propose \\textbf{AnyViewBench}, a challenging new benchmark tailored towards \\emph{extreme} dynamic view synthesis in diverse real-world scenarios. In this more dramatic setting, we find that most baselines drastically degrade in performance, as they require significant overlap between viewpoints, while AnyView maintains the ability to produce realistic, plausible, and spatiotemporally consistent videos when prompted from \\emph{any} viewpoint. Results, data, code, and models can be viewed at: https://tri-ml.github.io/AnyView/",
      "url": "http://arxiv.org/abs/2601.16982",
      "author": "Basile Van Hoorick, Dian Chen, Shun Iwase, Pavel Tokmakov, Muhammad Zubair Irshad, Igor Vasiljevic, Swati Gupta, Fangzhou Cheng, Sergey Zakharov, Vitor Campagnolo Guizilini",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces AnyView, a diffusion-based video generation framework for dynamic view synthesis with minimal geometric assumptions. Leverages 2D, 3D, and 4D datasets to train a generalist spatiotemporal representation for zero-shot novel view synthesis.",
      "importance_score": 62,
      "reasoning": "Solid approach to dynamic view synthesis, competitive results on benchmarks. Less novel than claimed given existing work in the space.",
      "themes": [
        "Video Generation",
        "View Synthesis",
        "Diffusion Models"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces AnyView, a diffusion-based video generation framework for dynamic view synthesis with minimal geometric assumptions. Leverages 2D, 3D, and 4D datasets to train a generalist spatiotemporal representation for zero-shot novel view synthesis.</p>",
      "content_html": "<p>arXiv:2601.16982v1 Announce Type: cross  Abstract: Modern generative video models excel at producing convincing, high-quality outputs, but struggle to maintain multi-view and spatiotemporal consistency in highly dynamic real-world environments. In this work, we introduce \\textbf{AnyView}, a diffusion-based video generation framework for \\emph{dynamic view synthesis} with minimal inductive biases or geometric assumptions. We leverage multiple data sources with various levels of supervision, including monocular (2D), multi-view static (3D) and multi-view dynamic (4D) datasets, to train a generalist spatiotemporal implicit representation capable of producing zero-shot novel videos from arbitrary camera locations and trajectories. We evaluate AnyView on standard benchmarks, showing competitive results with the current state of the art, and propose \\textbf{AnyViewBench}, a challenging new benchmark tailored towards \\emph{extreme} dynamic view synthesis in diverse real-world scenarios. In this more dramatic setting, we find that most baselines drastically degrade in performance, as they require significant overlap between viewpoints, while AnyView maintains the ability to produce realistic, plausible, and spatiotemporally consistent videos when prompted from \\emph{any} viewpoint. Results, data, code, and models can be viewed at: https://tri-ml.github.io/AnyView/</p>"
    },
    {
      "id": "92fd12c7c2a5",
      "title": "What Language Models Know But Don't Say: Non-Generative Prior Extraction for Generalization",
      "content": "arXiv:2601.17609v1 Announce Type: new  Abstract: In domains like medicine and finance, large-scale labeled data is costly and often unavailable, leading to models trained on small datasets that struggle to generalize to real-world populations. Large language models contain extensive knowledge from years of research across these domains. We propose LoID (Logit-Informed Distributions), a deterministic method for extracting informative prior distributions for Bayesian logistic regression by directly accessing their token-level predictions. Rather than relying on generated text, we probe the model's confidence in opposing semantic directions (positive vs. negative impact) through carefully constructed sentences. By measuring how consistently the LLM favors one direction across diverse phrasings, we extract the strength and reliability of the model's belief about each feature's influence. We evaluate LoID on ten real-world tabular datasets under synthetic out-of-distribution (OOD) settings characterized by covariate shift, where the training data represents only a subset of the population. We compare our approach against (1) standard uninformative priors, (2) AutoElicit, a recent method that prompts LLMs to generate priors via text completions, (3) LLMProcesses, a method that uses LLMs to generate numerical predictions through in-context learning and (4) an oracle-style upper bound derived from fitting logistic regression on the full dataset. We assess performance using Area Under the Curve (AUC). Across datasets, LoID significantly improves performance over logistic regression trained on OOD data, recovering up to \\textbf{59\\%} of the performance gap relative to the oracle model. LoID outperforms AutoElicit and LLMProcessesc on 8 out of 10 datasets, while providing a reproducible and computationally efficient mechanism for integrating LLM knowledge into Bayesian inference.",
      "url": "http://arxiv.org/abs/2601.17609",
      "author": "Sara Rezaeimanesh, Mohammad M. Ghassemi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes LoID, a method for extracting informative prior distributions from LLMs for Bayesian regression by probing token-level predictions across semantic directions without text generation.",
      "importance_score": 62,
      "reasoning": "Novel approach to leveraging LLM knowledge for statistical modeling in low-data domains. Interesting alternative to generation-based methods.",
      "themes": [
        "Knowledge Extraction",
        "Bayesian Methods",
        "Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes LoID, a method for extracting informative prior distributions from LLMs for Bayesian regression by probing token-level predictions across semantic directions without text generation.</p>",
      "content_html": "<p>arXiv:2601.17609v1 Announce Type: new  Abstract: In domains like medicine and finance, large-scale labeled data is costly and often unavailable, leading to models trained on small datasets that struggle to generalize to real-world populations. Large language models contain extensive knowledge from years of research across these domains. We propose LoID (Logit-Informed Distributions), a deterministic method for extracting informative prior distributions for Bayesian logistic regression by directly accessing their token-level predictions. Rather than relying on generated text, we probe the model's confidence in opposing semantic directions (positive vs. negative impact) through carefully constructed sentences. By measuring how consistently the LLM favors one direction across diverse phrasings, we extract the strength and reliability of the model's belief about each feature's influence. We evaluate LoID on ten real-world tabular datasets under synthetic out-of-distribution (OOD) settings characterized by covariate shift, where the training data represents only a subset of the population. We compare our approach against (1) standard uninformative priors, (2) AutoElicit, a recent method that prompts LLMs to generate priors via text completions, (3) LLMProcesses, a method that uses LLMs to generate numerical predictions through in-context learning and (4) an oracle-style upper bound derived from fitting logistic regression on the full dataset. We assess performance using Area Under the Curve (AUC). Across datasets, LoID significantly improves performance over logistic regression trained on OOD data, recovering up to \\textbf{59\\%} of the performance gap relative to the oracle model. LoID outperforms AutoElicit and LLMProcessesc on 8 out of 10 datasets, while providing a reproducible and computationally efficient mechanism for integrating LLM knowledge into Bayesian inference.</p>"
    },
    {
      "id": "8270d67d504f",
      "title": "LLM-Generated or Human-Written? Comparing Review and Non-Review Papers on ArXiv",
      "content": "arXiv:2601.17036v1 Announce Type: cross  Abstract: ArXiv recently prohibited the upload of unpublished review papers to its servers in the Computer Science domain, citing a high prevalence of LLM-generated content in these categories. However, this decision was not accompanied by quantitative evidence. In this work, we investigate this claim by measuring the proportion of LLM-generated content in review vs. non-review research papers in recent years. Using two high-quality detection methods, we find a substantial increase in LLM-generated content across both review and non-review papers, with a higher prevalence in review papers. However, when considering the number of LLM-generated papers published in each category, the estimates of non-review LLM-generated papers are almost six times higher. Furthermore, we find that this policy will affect papers in certain domains far more than others, with the CS subdiscipline Computers & Society potentially facing cuts of 50%. Our analysis provides an evidence-based framework for evaluating such policy decisions, and we release our code to facilitate future investigations at: https://github.com/yanaiela/llm-review-arxiv.",
      "url": "http://arxiv.org/abs/2601.17036",
      "author": "Yanai Elazar, Maria Antoniak",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.DL"
      ],
      "summary": "Investigates ArXiv's claim of high LLM-generated content in review papers by measuring LLM content prevalence. Finds substantial increase in both review and non-review papers, but absolute numbers of LLM-generated non-review papers are ~6x higher.",
      "importance_score": 62,
      "reasoning": "Timely analysis of LLM impact on academic publishing with policy implications. Provides quantitative evidence for ongoing debates.",
      "themes": [
        "LLM Detection",
        "Academic Publishing",
        "AI Ethics"
      ],
      "continuation": null,
      "summary_html": "<p>Investigates ArXiv's claim of high LLM-generated content in review papers by measuring LLM content prevalence. Finds substantial increase in both review and non-review papers, but absolute numbers of LLM-generated non-review papers are ~6x higher.</p>",
      "content_html": "<p>arXiv:2601.17036v1 Announce Type: cross  Abstract: ArXiv recently prohibited the upload of unpublished review papers to its servers in the Computer Science domain, citing a high prevalence of LLM-generated content in these categories. However, this decision was not accompanied by quantitative evidence. In this work, we investigate this claim by measuring the proportion of LLM-generated content in review vs. non-review research papers in recent years. Using two high-quality detection methods, we find a substantial increase in LLM-generated content across both review and non-review papers, with a higher prevalence in review papers. However, when considering the number of LLM-generated papers published in each category, the estimates of non-review LLM-generated papers are almost six times higher. Furthermore, we find that this policy will affect papers in certain domains far more than others, with the CS subdiscipline Computers &amp; Society potentially facing cuts of 50%. Our analysis provides an evidence-based framework for evaluating such policy decisions, and we release our code to facilitate future investigations at: https://github.com/yanaiela/llm-review-arxiv.</p>"
    },
    {
      "id": "52ba3ef8eec1",
      "title": "Semi-Supervised Domain Adaptation with Latent Diffusion for Pathology Image Classification",
      "content": "arXiv:2601.17228v1 Announce Type: new  Abstract: Deep learning models in computational pathology often fail to generalize across cohorts and institutions due to domain shift. Existing approaches either fail to leverage unlabeled data from the target domain or rely on image-to-image translation, which can distort tissue structures and compromise model accuracy. In this work, we propose a semi-supervised domain adaptation (SSDA) framework that utilizes a latent diffusion model trained on unlabeled data from both the source and target domains to generate morphology-preserving and target-aware synthetic images. By conditioning the diffusion model on foundation model features, cohort identity, and tissue preparation method, we preserve tissue structure in the source domain while introducing target-domain appearance characteristics. The target-aware synthetic images, combined with real, labeled images from the source cohort, are subsequently used to train a downstream classifier, which is then tested on the target cohort. The effectiveness of the proposed SSDA framework is demonstrated on the task of lung adenocarcinoma prognostication. The proposed augmentation yielded substantially better performance on the held-out test set from the target cohort, without degrading source-cohort performance. The approach improved the weighted F1 score on the target-cohort held-out test set from 0.611 to 0.706 and the macro F1 score from 0.641 to 0.716. Our results demonstrate that target-aware diffusion-based synthetic data augmentation provides a promising and effective approach for improving domain generalization in computational pathology.",
      "url": "http://arxiv.org/abs/2601.17228",
      "author": "Tengyue Zhang, Ruiwen Ding, Luoting Zhuang, Yuxiao Wu, Erika F. Rodriguez, William Hsu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes semi-supervised domain adaptation framework using latent diffusion for pathology image classification, generating morphology-preserving target-aware synthetic images conditioned on foundation model features.",
      "importance_score": 62,
      "reasoning": "Novel use of diffusion models for domain adaptation in pathology. Addresses real clinical deployment challenges.",
      "themes": [
        "Domain Adaptation",
        "Medical AI",
        "Diffusion Models",
        "Pathology"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes semi-supervised domain adaptation framework using latent diffusion for pathology image classification, generating morphology-preserving target-aware synthetic images conditioned on foundation model features.</p>",
      "content_html": "<p>arXiv:2601.17228v1 Announce Type: new  Abstract: Deep learning models in computational pathology often fail to generalize across cohorts and institutions due to domain shift. Existing approaches either fail to leverage unlabeled data from the target domain or rely on image-to-image translation, which can distort tissue structures and compromise model accuracy. In this work, we propose a semi-supervised domain adaptation (SSDA) framework that utilizes a latent diffusion model trained on unlabeled data from both the source and target domains to generate morphology-preserving and target-aware synthetic images. By conditioning the diffusion model on foundation model features, cohort identity, and tissue preparation method, we preserve tissue structure in the source domain while introducing target-domain appearance characteristics. The target-aware synthetic images, combined with real, labeled images from the source cohort, are subsequently used to train a downstream classifier, which is then tested on the target cohort. The effectiveness of the proposed SSDA framework is demonstrated on the task of lung adenocarcinoma prognostication. The proposed augmentation yielded substantially better performance on the held-out test set from the target cohort, without degrading source-cohort performance. The approach improved the weighted F1 score on the target-cohort held-out test set from 0.611 to 0.706 and the macro F1 score from 0.641 to 0.716. Our results demonstrate that target-aware diffusion-based synthetic data augmentation provides a promising and effective approach for improving domain generalization in computational pathology.</p>"
    },
    {
      "id": "8c6c5c6f88cf",
      "title": "StyleDecoupler: Generalizable Artistic Style Disentanglement",
      "content": "arXiv:2601.17697v1 Announce Type: new  Abstract: Representing artistic style is challenging due to its deep entanglement with semantic content. We propose StyleDecoupler, an information-theoretic framework that leverages a key insight: multi-modal vision models encode both style and content, while uni-modal models suppress style to focus on content-invariant features. By using uni-modal representations as content-only references, we isolate pure style features from multi-modal embeddings through mutual information minimization. StyleDecoupler operates as a plug-and-play module on frozen Vision-Language Models without fine-tuning. We also introduce WeART, a large-scale benchmark of 280K artworks across 152 styles and 1,556 artists. Experiments show state-of-the-art performance on style retrieval across WeART and WikiART, while enabling applications like style relationship mapping and generative model evaluation. We release our method and dataset at this url.",
      "url": "http://arxiv.org/abs/2601.17697",
      "author": "Zexi Jia, Jinchao Zhang, Jie Zhou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "StyleDecoupler uses information theory to disentangle artistic style from content by leveraging differences between multi-modal and uni-modal vision models. Also introduces WeART, a large benchmark of 280K artworks across 152 styles.",
      "importance_score": 62,
      "reasoning": "Novel theoretical approach to style disentanglement. WeART benchmark (280K artworks, 152 styles) is a significant contribution for art/style research.",
      "themes": [
        "Style Transfer",
        "Vision-Language Models",
        "Benchmarks"
      ],
      "continuation": null,
      "summary_html": "<p>StyleDecoupler uses information theory to disentangle artistic style from content by leveraging differences between multi-modal and uni-modal vision models. Also introduces WeART, a large benchmark of 280K artworks across 152 styles.</p>",
      "content_html": "<p>arXiv:2601.17697v1 Announce Type: new  Abstract: Representing artistic style is challenging due to its deep entanglement with semantic content. We propose StyleDecoupler, an information-theoretic framework that leverages a key insight: multi-modal vision models encode both style and content, while uni-modal models suppress style to focus on content-invariant features. By using uni-modal representations as content-only references, we isolate pure style features from multi-modal embeddings through mutual information minimization. StyleDecoupler operates as a plug-and-play module on frozen Vision-Language Models without fine-tuning. We also introduce WeART, a large-scale benchmark of 280K artworks across 152 styles and 1,556 artists. Experiments show state-of-the-art performance on style retrieval across WeART and WikiART, while enabling applications like style relationship mapping and generative model evaluation. We release our method and dataset at this url.</p>"
    },
    {
      "id": "b73358f501fd",
      "title": "V-Loop: Visual Logical Loop Verification for Hallucination Detection in Medical Visual Question Answering",
      "content": "arXiv:2601.18240v1 Announce Type: new  Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable capability in assisting disease diagnosis in medical visual question answering (VQA). However, their outputs remain vulnerable to hallucinations (i.e., responses that contradict visual facts), posing significant risks in high-stakes medical scenarios. Recent introspective detection methods, particularly uncertainty-based approaches, offer computational efficiency but are fundamentally indirect, as they estimate predictive uncertainty for an image-question pair rather than verifying the factual correctness of a specific answer. To address this limitation, we propose Visual Logical Loop Verification (V-Loop), a training-free and plug-and-play framework for hallucination detection in medical VQA. V-Loop introduces a bidirectional reasoning process that forms a visually grounded logical loop to verify factual correctness. Given an input, the MLLM produces an answer for the primary input pair. V-Loop extracts semantic units from the primary QA pair, generates a verification question by conditioning on the answer unit to re-query the question unit, and enforces visual attention consistency to ensure answering both primary question and verification question rely on the same image evidence. If the verification answer matches the expected semantic content, the logical loop closes, indicating factual grounding; otherwise, the primary answer is flagged as hallucinated. Extensive experiments on multiple medical VQA benchmarks and MLLMs show that V-Loop consistently outperforms existing introspective methods, remains highly efficient, and further boosts uncertainty-based approaches when used in combination.",
      "url": "http://arxiv.org/abs/2601.18240",
      "author": "Mengyuan Jin, Zehui Liao, Yong Xia",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "V-Loop proposes training-free Visual Logical Loop Verification for hallucination detection in medical VQA, verifying factual correctness of specific answers rather than estimating general uncertainty.",
      "importance_score": 62,
      "reasoning": "Addresses critical hallucination problem in medical AI. Novel verification approach rather than just uncertainty estimation.",
      "themes": [
        "Medical AI",
        "Hallucination Detection",
        "VQA",
        "AI Safety"
      ],
      "continuation": null,
      "summary_html": "<p>V-Loop proposes training-free Visual Logical Loop Verification for hallucination detection in medical VQA, verifying factual correctness of specific answers rather than estimating general uncertainty.</p>",
      "content_html": "<p>arXiv:2601.18240v1 Announce Type: new  Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable capability in assisting disease diagnosis in medical visual question answering (VQA). However, their outputs remain vulnerable to hallucinations (i.e., responses that contradict visual facts), posing significant risks in high-stakes medical scenarios. Recent introspective detection methods, particularly uncertainty-based approaches, offer computational efficiency but are fundamentally indirect, as they estimate predictive uncertainty for an image-question pair rather than verifying the factual correctness of a specific answer. To address this limitation, we propose Visual Logical Loop Verification (V-Loop), a training-free and plug-and-play framework for hallucination detection in medical VQA. V-Loop introduces a bidirectional reasoning process that forms a visually grounded logical loop to verify factual correctness. Given an input, the MLLM produces an answer for the primary input pair. V-Loop extracts semantic units from the primary QA pair, generates a verification question by conditioning on the answer unit to re-query the question unit, and enforces visual attention consistency to ensure answering both primary question and verification question rely on the same image evidence. If the verification answer matches the expected semantic content, the logical loop closes, indicating factual grounding; otherwise, the primary answer is flagged as hallucinated. Extensive experiments on multiple medical VQA benchmarks and MLLMs show that V-Loop consistently outperforms existing introspective methods, remains highly efficient, and further boosts uncertainty-based approaches when used in combination.</p>"
    },
    {
      "id": "11df4ecc8456",
      "title": "Efficient Complex-Valued Vision Transformers for MRI Classification Directly from k-Space",
      "content": "arXiv:2601.18392v1 Announce Type: new  Abstract: Deep learning applications in Magnetic Resonance Imaging (MRI) predominantly operate on reconstructed magnitude images, a process that discards phase information and requires computationally expensive transforms. Standard neural network architectures rely on local operations (convolutions or grid-patches) that are ill-suited for the global, non-local nature of raw frequency-domain (k-Space) data. In this work, we propose a novel complex-valued Vision Transformer (kViT) designed to perform classification directly on k-Space data. To bridge the geometric disconnect between current architectures and MRI physics, we introduce a radial k-Space patching strategy that respects the spectral energy distribution of the frequency-domain. Extensive experiments on the fastMRI and in-house datasets demonstrate that our approach achieves classification performance competitive with state-of-the-art image-domain baselines (ResNet, EfficientNet, ViT). Crucially, kViT exhibits superior robustness to high acceleration factors and offers a paradigm shift in computational efficiency, reducing VRAM consumption during training by up to 68$\\times$ compared to standard methods. This establishes a pathway for resource-efficient, direct-from-scanner AI analysis.",
      "url": "http://arxiv.org/abs/2601.18392",
      "author": "Moritz Rempe, Lukas T. Rotkopf, Marco Schlimbach, Helmut Becker, Fabian H\\\"orst, Johannes Haubold, Philipp Dammann, Kevin Kr\\\"oninger, Jens Kleesiek",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "kViT proposes complex-valued Vision Transformer for MRI classification directly from k-space data with radial patching strategy that respects spectral energy distribution.",
      "importance_score": 62,
      "reasoning": "Novel architecture operating directly on frequency domain. Principled approach respecting MRI physics.",
      "themes": [
        "Medical Imaging",
        "Vision Transformers",
        "MRI",
        "Novel Architecture"
      ],
      "continuation": null,
      "summary_html": "<p>kViT proposes complex-valued Vision Transformer for MRI classification directly from k-space data with radial patching strategy that respects spectral energy distribution.</p>",
      "content_html": "<p>arXiv:2601.18392v1 Announce Type: new  Abstract: Deep learning applications in Magnetic Resonance Imaging (MRI) predominantly operate on reconstructed magnitude images, a process that discards phase information and requires computationally expensive transforms. Standard neural network architectures rely on local operations (convolutions or grid-patches) that are ill-suited for the global, non-local nature of raw frequency-domain (k-Space) data. In this work, we propose a novel complex-valued Vision Transformer (kViT) designed to perform classification directly on k-Space data. To bridge the geometric disconnect between current architectures and MRI physics, we introduce a radial k-Space patching strategy that respects the spectral energy distribution of the frequency-domain. Extensive experiments on the fastMRI and in-house datasets demonstrate that our approach achieves classification performance competitive with state-of-the-art image-domain baselines (ResNet, EfficientNet, ViT). Crucially, kViT exhibits superior robustness to high acceleration factors and offers a paradigm shift in computational efficiency, reducing VRAM consumption during training by up to 68$\\times$ compared to standard methods. This establishes a pathway for resource-efficient, direct-from-scanner AI analysis.</p>"
    },
    {
      "id": "0b2f3492fe32",
      "title": "Trustworthy Evaluation of Robotic Manipulation: A New Benchmark and AutoEval Methods",
      "content": "arXiv:2601.18723v1 Announce Type: new  Abstract: Driven by the rapid evolution of Vision-Action and Vision-Language-Action models, imitation learning has significantly advanced robotic manipulation capabilities. However, evaluation methodologies have lagged behind, hindering the establishment of Trustworthy Evaluation for these behaviors. Current paradigms rely on binary success rates, failing to address the critical dimensions of trust: Source Authenticity (i.e., distinguishing genuine policy behaviors from human teleoperation) and Execution Quality (e.g., smoothness and safety). To bridge these gaps, we propose a solution that combines the Eval-Actions benchmark and the AutoEval architecture. First, we construct the Eval-Actions benchmark to support trustworthiness analysis. Distinct from existing datasets restricted to successful human demonstrations, Eval-Actions integrates VA and VLA policy execution trajectories alongside human teleoperation data, explicitly including failure scenarios. This dataset is structured around three core supervision signals: Expert Grading (EG), Rank-Guided preferences (RG), and Chain-of-Thought (CoT). Building on this, we propose the AutoEval architecture: AutoEval leverages Spatio-Temporal Aggregation for semantic assessment, augmented by an auxiliary Kinematic Calibration Signal to refine motion smoothness; AutoEval Plus (AutoEval-P) incorporates the Group Relative Policy Optimization (GRPO) paradigm to enhance logical reasoning capabilities. Experiments show AutoEval achieves Spearman's Rank Correlation Coefficients (SRCC) of 0.81 and 0.84 under the EG and RG protocols, respectively. Crucially, the framework possesses robust source discrimination capabilities, distinguishing between policy-generated and teleoperated videos with 99.6% accuracy, thereby establishing a rigorous standard for trustworthy robotic evaluation. Our project and code are available at https://term-bench.github.io/.",
      "url": "http://arxiv.org/abs/2601.18723",
      "author": "Mengyuan Liu, Juyi Sheng, Peiming Li, Ziyi Wang, Tianming Xu, Tiantian Xu, Hong Liu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes Eval-Actions benchmark and AutoEval architecture for trustworthy evaluation of robotic manipulation, distinguishing genuine policy behaviors from teleoperation and assessing execution quality.",
      "importance_score": 62,
      "reasoning": "Important contribution to robotics evaluation methodology, addresses overlooked aspects of trust in imitation learning.",
      "themes": [
        "Robotics Evaluation",
        "Imitation Learning",
        "Trustworthy AI",
        "Benchmark Development"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Eval-Actions benchmark and AutoEval architecture for trustworthy evaluation of robotic manipulation, distinguishing genuine policy behaviors from teleoperation and assessing execution quality.</p>",
      "content_html": "<p>arXiv:2601.18723v1 Announce Type: new  Abstract: Driven by the rapid evolution of Vision-Action and Vision-Language-Action models, imitation learning has significantly advanced robotic manipulation capabilities. However, evaluation methodologies have lagged behind, hindering the establishment of Trustworthy Evaluation for these behaviors. Current paradigms rely on binary success rates, failing to address the critical dimensions of trust: Source Authenticity (i.e., distinguishing genuine policy behaviors from human teleoperation) and Execution Quality (e.g., smoothness and safety). To bridge these gaps, we propose a solution that combines the Eval-Actions benchmark and the AutoEval architecture. First, we construct the Eval-Actions benchmark to support trustworthiness analysis. Distinct from existing datasets restricted to successful human demonstrations, Eval-Actions integrates VA and VLA policy execution trajectories alongside human teleoperation data, explicitly including failure scenarios. This dataset is structured around three core supervision signals: Expert Grading (EG), Rank-Guided preferences (RG), and Chain-of-Thought (CoT). Building on this, we propose the AutoEval architecture: AutoEval leverages Spatio-Temporal Aggregation for semantic assessment, augmented by an auxiliary Kinematic Calibration Signal to refine motion smoothness; AutoEval Plus (AutoEval-P) incorporates the Group Relative Policy Optimization (GRPO) paradigm to enhance logical reasoning capabilities. Experiments show AutoEval achieves Spearman's Rank Correlation Coefficients (SRCC) of 0.81 and 0.84 under the EG and RG protocols, respectively. Crucially, the framework possesses robust source discrimination capabilities, distinguishing between policy-generated and teleoperated videos with 99.6% accuracy, thereby establishing a rigorous standard for trustworthy robotic evaluation. Our project and code are available at https://term-bench.github.io/.</p>"
    },
    {
      "id": "9e53bc5211b9",
      "title": "Dario Amodei  The Adolescence of Technology",
      "content": "Dario Amodei, CEO of Anthropic, has written a new essay on his thoughts on AI risk of various shapes. It seems worth reading, even if just for understanding what Anthropic is likely to do in the future.Confronting and Overcoming the Risks of Powerful AIThere is a scene in the movie version of Carl Sagans book&nbsp;Contact&nbsp;where the main character, an astronomer who has detected the first radio signal from an alien civilization, is being considered for the role of humanitys representative to meet the aliens. The international panel interviewing her asks, If you could ask [the aliens] just one question, what would it be? Her reply is: Id ask them, How did you do it? How did you evolve, how did you survive this technological adolescence without destroying yourself? When I think about where humanity is now with AIabout what were on the cusp ofmy mind keeps going back to that scene, because the question is so apt for our current situation, and I wish we had the aliens answer to guide us. I believe we are entering a rite of passage, both turbulent and inevitable, which will test who we are as a species. Humanity is about to be handed almost unimaginable power, and it is deeply unclear whether our social, political, and technological systems possess the maturity to wield it.In my essay&nbsp;Machines of Loving Grace, I tried to lay out the dream of a civilization that had made it through to adulthood, where the risks had been addressed and powerful AI was applied with skill and compassion to raise the quality of life for everyone. I suggested that AI could contribute to enormous advances in biology, neuroscience, economic development, global peace, and work and meaning. I felt it was important to give people something inspiring to fight for, a task at which both AI accelerationists and AI safety advocates seemedoddlyto have failed. But in this current essay, I want to confront the rite of passage itself: to map out the risks that we are about to face and ...",
      "url": "https://www.lesswrong.com/posts/kzPQohJakutbtFPcf/dario-amodei-the-adolescence-of-technology",
      "author": "habryka",
      "published": "2026-01-26T14:10:36.047000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Links to Dario Amodei's new essay 'Confronting and Overcoming the Risks of Powerful AI,' describing humanity's technological adolescence and the need to navigate AI development carefully. Important for understanding Anthropic's strategic thinking.",
      "importance_score": 62,
      "reasoning": "Significant because it's the Anthropic CEO's public position on AI risk, which influences industry direction. However, this post is primarily a link rather than substantive original analysis.",
      "themes": [
        "AI Safety",
        "Anthropic",
        "AI Governance",
        "Existential Risk"
      ],
      "continuation": null,
      "summary_html": "<p>Links to Dario Amodei's new essay 'Confronting and Overcoming the Risks of Powerful AI,' describing humanity's technological adolescence and the need to navigate AI development carefully. Important for understanding Anthropic's strategic thinking.</p>",
      "content_html": "<p>Dario Amodei, CEO of Anthropic, has written a new essay on his thoughts on AI risk of various shapes. It seems worth reading, even if just for understanding what Anthropic is likely to do in the future.Confronting and Overcoming the Risks of Powerful AIThere is a scene in the movie version of Carl Sagans book&nbsp;Contact&nbsp;where the main character, an astronomer who has detected the first radio signal from an alien civilization, is being considered for the role of humanitys representative to meet the aliens. The international panel interviewing her asks, If you could ask [the aliens] just one question, what would it be? Her reply is: Id ask them, How did you do it? How did you evolve, how did you survive this technological adolescence without destroying yourself? When I think about where humanity is now with AIabout what were on the cusp ofmy mind keeps going back to that scene, because the question is so apt for our current situation, and I wish we had the aliens answer to guide us. I believe we are entering a rite of passage, both turbulent and inevitable, which will test who we are as a species. Humanity is about to be handed almost unimaginable power, and it is deeply unclear whether our social, political, and technological systems possess the maturity to wield it.In my essay&nbsp;Machines of Loving Grace, I tried to lay out the dream of a civilization that had made it through to adulthood, where the risks had been addressed and powerful AI was applied with skill and compassion to raise the quality of life for everyone. I suggested that AI could contribute to enormous advances in biology, neuroscience, economic development, global peace, and work and meaning. I felt it was important to give people something inspiring to fight for, a task at which both AI accelerationists and AI safety advocates seemedoddlyto have failed. But in this current essay, I want to confront the rite of passage itself: to map out the risks that we are about to face and ...</p>"
    },
    {
      "id": "46e7316ad888",
      "title": "DIML: Differentiable Inverse Mechanism Learning from Behaviors of Multi-Agent Learning Trajectories",
      "content": "arXiv:2601.17678v1 Announce Type: new  Abstract: We study inverse mechanism learning: recovering an unknown incentive-generating mechanism from observed strategic interaction traces of self-interested learning agents. Unlike inverse game theory and multi-agent inverse reinforcement learning, which typically infer utility/reward parameters inside a structured mechanism, our target includes unstructured mechanism -- a (possibly neural) mapping from joint actions to per-agent payoffs. Unlike differentiable mechanism design, which optimizes mechanisms forward, we infer mechanisms from behavior in an observational setting. We propose DIML, a likelihood-based framework that differentiates through a model of multi-agent learning dynamics and uses the candidate mechanism to generate counterfactual payoffs needed to predict observed actions. We establish identifiability of payoff differences under a conditional logit response model and prove statistical consistency of maximum likelihood estimation under standard regularity conditions. We evaluate DIML with simulated interactions of learning agents across unstructured neural mechanisms, congestion tolling, public goods subsidies, and large-scale anonymous games. DIML reliably recovers identifiable incentive differences and supports counterfactual prediction, where its performance rivals tabular enumeration oracle in small environments and its convergence scales to large, hundred-participant environments. Code to reproduce our experiments is open-sourced.",
      "url": "http://arxiv.org/abs/2601.17678",
      "author": "Zhiyu An, Wan Du",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes DIML for inverse mechanism learning, recovering unknown incentive mechanisms from observed multi-agent learning trajectories by differentiating through learning dynamics models.",
      "importance_score": 61,
      "reasoning": "Novel problem formulation bridging inverse game theory and mechanism design; technically interesting approach though applicability unclear.",
      "themes": [
        "Multi-Agent Systems",
        "Game Theory",
        "Mechanism Design"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes DIML for inverse mechanism learning, recovering unknown incentive mechanisms from observed multi-agent learning trajectories by differentiating through learning dynamics models.</p>",
      "content_html": "<p>arXiv:2601.17678v1 Announce Type: new  Abstract: We study inverse mechanism learning: recovering an unknown incentive-generating mechanism from observed strategic interaction traces of self-interested learning agents. Unlike inverse game theory and multi-agent inverse reinforcement learning, which typically infer utility/reward parameters inside a structured mechanism, our target includes unstructured mechanism -- a (possibly neural) mapping from joint actions to per-agent payoffs. Unlike differentiable mechanism design, which optimizes mechanisms forward, we infer mechanisms from behavior in an observational setting. We propose DIML, a likelihood-based framework that differentiates through a model of multi-agent learning dynamics and uses the candidate mechanism to generate counterfactual payoffs needed to predict observed actions. We establish identifiability of payoff differences under a conditional logit response model and prove statistical consistency of maximum likelihood estimation under standard regularity conditions. We evaluate DIML with simulated interactions of learning agents across unstructured neural mechanisms, congestion tolling, public goods subsidies, and large-scale anonymous games. DIML reliably recovers identifiable incentive differences and supports counterfactual prediction, where its performance rivals tabular enumeration oracle in small environments and its convergence scales to large, hundred-participant environments. Code to reproduce our experiments is open-sourced.</p>"
    },
    {
      "id": "c47532e59929",
      "title": "Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial Neural Networks",
      "content": "arXiv:2601.18617v1 Announce Type: new  Abstract: During language acquisition, children successively learn to categorize phonemes, identify words, and combine them with syntax to form new meaning. While the development of this behavior is well characterized, we still lack a unifying computational framework to explain its underlying neural representations. Here, we investigate whether and when phonemic, lexical, and syntactic representations emerge in the activations of artificial neural networks during their training. Our results show that both speech- and text-based models follow a sequence of learning stages: during training, their neural activations successively build subspaces, where the geometry of the neural activations represents phonemic, lexical, and syntactic structure. While this developmental trajectory qualitatively relates to children's, it is quantitatively different: These algorithms indeed require two to four orders of magnitude more data for these neural representations to emerge. Together, these results show conditions under which major stages of language acquisition spontaneously emerge, and hence delineate a promising path to understand the computations underpinning language acquisition.",
      "url": "http://arxiv.org/abs/2601.18617",
      "author": "Pierre Orhan, Pablo Diego-Sim\\'on, Emmnanuel Chemla, Yair Lakretz, Yves Boubenec, Jean-R\\'emi King",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Investigates whether phonemic, lexical, and syntactic representations emerge during neural network training, finding sequential learning stages in both speech and text models.",
      "importance_score": 61,
      "reasoning": "Interesting findings about linguistic representation emergence; connects AI training to cognitive development.",
      "themes": [
        "Language Models",
        "Interpretability",
        "Cognitive AI"
      ],
      "continuation": null,
      "summary_html": "<p>Investigates whether phonemic, lexical, and syntactic representations emerge during neural network training, finding sequential learning stages in both speech and text models.</p>",
      "content_html": "<p>arXiv:2601.18617v1 Announce Type: new  Abstract: During language acquisition, children successively learn to categorize phonemes, identify words, and combine them with syntax to form new meaning. While the development of this behavior is well characterized, we still lack a unifying computational framework to explain its underlying neural representations. Here, we investigate whether and when phonemic, lexical, and syntactic representations emerge in the activations of artificial neural networks during their training. Our results show that both speech- and text-based models follow a sequence of learning stages: during training, their neural activations successively build subspaces, where the geometry of the neural activations represents phonemic, lexical, and syntactic structure. While this developmental trajectory qualitatively relates to children's, it is quantitatively different: These algorithms indeed require two to four orders of magnitude more data for these neural representations to emerge. Together, these results show conditions under which major stages of language acquisition spontaneously emerge, and hence delineate a promising path to understand the computations underpinning language acquisition.</p>"
    },
    {
      "id": "69b71a2a5f4c",
      "title": "TEA-Bench: A Systematic Benchmarking of Tool-enhanced Emotional Support Dialogue Agent",
      "content": "arXiv:2601.18700v1 Announce Type: new  Abstract: Emotional Support Conversation requires not only affective expression but also grounded instrumental support to provide trustworthy guidance. However, existing ESC systems and benchmarks largely focus on affective support in text-only settings, overlooking how external tools can enable factual grounding and reduce hallucination in multi-turn emotional support. We introduce TEA-Bench, the first interactive benchmark for evaluating tool-augmented agents in ESC, featuring realistic emotional scenarios, an MCP-style tool environment, and process-level metrics that jointly assess the quality and factual grounding of emotional support. Experiments on nine LLMs show that tool augmentation generally improves emotional support quality and reduces hallucination, but the gains are strongly capacity-dependent: stronger models use tools more selectively and effectively, while weaker models benefit only marginally. We further release TEA-Dialog, a dataset of tool-enhanced ESC dialogues, and find that supervised fine-tuning improves in-distribution support but generalizes poorly. Our results underscore the importance of tool use in building reliable emotional support agents.",
      "url": "http://arxiv.org/abs/2601.18700",
      "author": "Xingyu Sui, Yanyan Zhao, Yulin Hu, Jiahe Guo, Weixiang Zhao, Bing Qin",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces TEA-Bench, first interactive benchmark for tool-augmented agents in emotional support conversations with MCP-style tool environment and process-level metrics.",
      "importance_score": 61,
      "reasoning": "Novel benchmark combining tool use with emotional support; addresses hallucination reduction through grounding.",
      "themes": [
        "Emotional Support",
        "Tool Use",
        "Benchmarks"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces TEA-Bench, first interactive benchmark for tool-augmented agents in emotional support conversations with MCP-style tool environment and process-level metrics.</p>",
      "content_html": "<p>arXiv:2601.18700v1 Announce Type: new  Abstract: Emotional Support Conversation requires not only affective expression but also grounded instrumental support to provide trustworthy guidance. However, existing ESC systems and benchmarks largely focus on affective support in text-only settings, overlooking how external tools can enable factual grounding and reduce hallucination in multi-turn emotional support. We introduce TEA-Bench, the first interactive benchmark for evaluating tool-augmented agents in ESC, featuring realistic emotional scenarios, an MCP-style tool environment, and process-level metrics that jointly assess the quality and factual grounding of emotional support. Experiments on nine LLMs show that tool augmentation generally improves emotional support quality and reduces hallucination, but the gains are strongly capacity-dependent: stronger models use tools more selectively and effectively, while weaker models benefit only marginally. We further release TEA-Dialog, a dataset of tool-enhanced ESC dialogues, and find that supervised fine-tuning improves in-distribution support but generalizes poorly. Our results underscore the importance of tool use in building reliable emotional support agents.</p>"
    },
    {
      "id": "923fcad9647f",
      "title": "Bridging Expectation Signals: LLM-Based Experiments and a Behavioral Kalman Filter Framework",
      "content": "arXiv:2601.17527v1 Announce Type: cross  Abstract: As LLMs increasingly function as economic agents, the specific mechanisms LLMs use to update their belief with heterogeneous signals remain opaque. We design experiments and develop a Behavioral Kalman Filter framework to quantify how LLM-based agents update expectations, acting as households or firm CEOs, update expectations when presented with individual and aggregate signals. The results from experiments and model estimation reveal four consistent patterns: (1) agents' weighting of priors and signals deviates from unity; (2) both household and firm CEO agents place substantially larger weights on individual signals compared to aggregate signals; (3) we identify a significant and negative interaction between concurrent signals, implying that the presence of multiple information sources diminishes the marginal weight assigned to each individual signal; and (4) expectation formation patterns differ significantly between household and firm CEO agents. Finally, we demonstrate that LoRA fine-tuning mitigates, but does not fully eliminate, behavioral biases in LLM expectation formation.",
      "url": "http://arxiv.org/abs/2601.17527",
      "author": "Yu Wang, Xiangchen Liu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "econ.GN"
      ],
      "summary": "Develops Behavioral Kalman Filter framework to quantify how LLM agents update beliefs when presented with individual vs aggregate signals, finding consistent behavioral patterns.",
      "importance_score": 61,
      "reasoning": "Novel framework for understanding LLM belief updating. Economic agent perspective is valuable. Quantitative results on signal weighting.",
      "themes": [
        "LLM Agents",
        "Behavioral Economics",
        "Belief Updating"
      ],
      "continuation": null,
      "summary_html": "<p>Develops Behavioral Kalman Filter framework to quantify how LLM agents update beliefs when presented with individual vs aggregate signals, finding consistent behavioral patterns.</p>",
      "content_html": "<p>arXiv:2601.17527v1 Announce Type: cross  Abstract: As LLMs increasingly function as economic agents, the specific mechanisms LLMs use to update their belief with heterogeneous signals remain opaque. We design experiments and develop a Behavioral Kalman Filter framework to quantify how LLM-based agents update expectations, acting as households or firm CEOs, update expectations when presented with individual and aggregate signals. The results from experiments and model estimation reveal four consistent patterns: (1) agents' weighting of priors and signals deviates from unity; (2) both household and firm CEO agents place substantially larger weights on individual signals compared to aggregate signals; (3) we identify a significant and negative interaction between concurrent signals, implying that the presence of multiple information sources diminishes the marginal weight assigned to each individual signal; and (4) expectation formation patterns differ significantly between household and firm CEO agents. Finally, we demonstrate that LoRA fine-tuning mitigates, but does not fully eliminate, behavioral biases in LLM expectation formation.</p>"
    },
    {
      "id": "39c38df943ab",
      "title": "ShapLoRA: Allocation of Low-rank Adaption on Large Language Models via Shapley Value Inspired Importance Estimation",
      "content": "arXiv:2601.17921v1 Announce Type: new  Abstract: Low-rank adaption (LoRA) is a representative method in the field of parameter-efficient fine-tuning (PEFT), and is key to Democratizating the modern large language models (LLMs). The vanilla LoRA is implemented with uniform ranks, and the recent literature have found that properly allocating ranks on the LLM backbones results in performance boosts. However, the previous rank allocation methods have limitations since they rely on inexplanable and unreliable importance measures for the LoRA ranks. To address the above issues, we propose the ShapLoRA framework. Inspired by the explanable attribution measure Shapley Value, we combine the sensitivity-based measures with the idea of coalitions in the collaborative games among LoRA ranks, and propose a more explainable importance measure called Shapley sensitivity. In addition, we optimize the workflow of the existing works by: (a) calculating Shapley sensitivity on a separate validation set; (b) Setting up the allocating-retraining procedures for fair comparisons. We have conducted experiments on various challenging tasks, and the experimental results demonstrate that our ShapLoRA method can outperform the recent baselines with comparable tunable parameters.\\footnote{Codes and fine-tuned models will be open-sourced to facilitate future research.",
      "url": "http://arxiv.org/abs/2601.17921",
      "author": "Yi Zhao, Qinghua Yao, Xinyuan song, Wei Zhu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes ShapLoRA for LoRA rank allocation using Shapley value-inspired importance estimation. Combines sensitivity measures with coalition game theory for explainable rank importance.",
      "importance_score": 61,
      "reasoning": "Novel approach to adaptive LoRA allocation with interpretable methodology. Contributes to PEFT optimization.",
      "themes": [
        "PEFT",
        "LoRA",
        "Model Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes ShapLoRA for LoRA rank allocation using Shapley value-inspired importance estimation. Combines sensitivity measures with coalition game theory for explainable rank importance.</p>",
      "content_html": "<p>arXiv:2601.17921v1 Announce Type: new  Abstract: Low-rank adaption (LoRA) is a representative method in the field of parameter-efficient fine-tuning (PEFT), and is key to Democratizating the modern large language models (LLMs). The vanilla LoRA is implemented with uniform ranks, and the recent literature have found that properly allocating ranks on the LLM backbones results in performance boosts. However, the previous rank allocation methods have limitations since they rely on inexplanable and unreliable importance measures for the LoRA ranks. To address the above issues, we propose the ShapLoRA framework. Inspired by the explanable attribution measure Shapley Value, we combine the sensitivity-based measures with the idea of coalitions in the collaborative games among LoRA ranks, and propose a more explainable importance measure called Shapley sensitivity. In addition, we optimize the workflow of the existing works by: (a) calculating Shapley sensitivity on a separate validation set; (b) Setting up the allocating-retraining procedures for fair comparisons. We have conducted experiments on various challenging tasks, and the experimental results demonstrate that our ShapLoRA method can outperform the recent baselines with comparable tunable parameters.\\footnote{Codes and fine-tuned models will be open-sourced to facilitate future research.</p>"
    },
    {
      "id": "f988f8871b14",
      "title": "Reflecting Twice before Speaking with Empathy: Self-Reflective Alternating Inference for Empathy-Aware End-to-End Spoken Dialogue",
      "content": "arXiv:2601.18281v1 Announce Type: new  Abstract: End-to-end Spoken Language Models (SLMs) hold great potential for paralinguistic perception, and numerous studies have aimed to enhance their capabilities, particularly for empathetic dialogue. However, current approaches largely depend on rigid supervised signals, such as ground-truth response in supervised fine-tuning or preference scores in reinforcement learning. Such reliance is fundamentally limited for modeling complex empathy, as there is no single \"correct\" response and a simple numerical score cannot fully capture the nuances of emotional expression or the appropriateness of empathetic behavior. To address these limitations, we sequentially introduce EmpathyEval, a descriptive natural-language-based evaluation model for assessing empathetic quality in spoken dialogues. Building upon EmpathyEval, we propose ReEmpathy, an end-to-end SLM that enhances empathetic dialogue through a novel Empathetic Self-Reflective Alternating Inference mechanism, which interleaves spoken response generation with free-form, empathy-related reflective reasoning. Extensive experiments demonstrate that ReEmpathy substantially improves empathy-sensitive spoken dialogue by enabling reflective reasoning, offering a promising approach toward more emotionally intelligent and empathy-aware human-computer interactions.",
      "url": "http://arxiv.org/abs/2601.18281",
      "author": "Yuhang Jia, Pei Liu, Haoqin Sun, Jiaming Zhou, Xuxin Cheng, Cao Liu, Ke Zeng, Xunliang Cai, Yong Qin",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes self-reflective alternating inference framework for empathetic spoken dialogue using natural language evaluation model EmpathyEval instead of rigid supervised signals.",
      "importance_score": 61,
      "reasoning": "Novel approach to empathetic dialogue evaluation avoiding limitations of numerical scores. Addresses fundamental challenge in empathy modeling.",
      "themes": [
        "Dialogue Systems",
        "Empathy",
        "Speech Models"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes self-reflective alternating inference framework for empathetic spoken dialogue using natural language evaluation model EmpathyEval instead of rigid supervised signals.</p>",
      "content_html": "<p>arXiv:2601.18281v1 Announce Type: new  Abstract: End-to-end Spoken Language Models (SLMs) hold great potential for paralinguistic perception, and numerous studies have aimed to enhance their capabilities, particularly for empathetic dialogue. However, current approaches largely depend on rigid supervised signals, such as ground-truth response in supervised fine-tuning or preference scores in reinforcement learning. Such reliance is fundamentally limited for modeling complex empathy, as there is no single \"correct\" response and a simple numerical score cannot fully capture the nuances of emotional expression or the appropriateness of empathetic behavior. To address these limitations, we sequentially introduce EmpathyEval, a descriptive natural-language-based evaluation model for assessing empathetic quality in spoken dialogues. Building upon EmpathyEval, we propose ReEmpathy, an end-to-end SLM that enhances empathetic dialogue through a novel Empathetic Self-Reflective Alternating Inference mechanism, which interleaves spoken response generation with free-form, empathy-related reflective reasoning. Extensive experiments demonstrate that ReEmpathy substantially improves empathy-sensitive spoken dialogue by enabling reflective reasoning, offering a promising approach toward more emotionally intelligent and empathy-aware human-computer interactions.</p>"
    },
    {
      "id": "2d3981748840",
      "title": "Are Video Generation Models Geographically Fair? An Attraction-Centric Evaluation of Global Visual Knowledge",
      "content": "arXiv:2601.18698v1 Announce Type: new  Abstract: Recent advances in text-to-video generation have produced visually compelling results, yet it remains unclear whether these models encode geographically equitable visual knowledge. In this work, we investigate the geo-equity and geographically grounded visual knowledge of text-to-video models through an attraction-centric evaluation. We introduce Geo-Attraction Landmark Probing (GAP), a systematic framework for assessing how faithfully models synthesize tourist attractions from diverse regions, and construct GEOATTRACTION-500, a benchmark of 500 globally distributed attractions spanning varied regions and popularity levels. GAP integrates complementary metrics that disentangle overall video quality from attraction-specific knowledge, including global structural alignment, fine-grained keypoint-based alignment, and vision-language model judgments, all validated against human evaluation. Applying GAP to the state-of-the-art text-to-video model Sora 2, we find that, contrary to common assumptions of strong geographic bias, the model exhibits a relatively uniform level of geographically grounded visual knowledge across regions, development levels, and cultural groupings, with only weak dependence on attraction popularity. These results suggest that current text-to-video models express global visual knowledge more evenly than expected, highlighting both their promise for globally deployed applications and the need for continued evaluation as such systems evolve.",
      "url": "http://arxiv.org/abs/2601.18698",
      "author": "Xiao Liu, Jiawei Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Investigates geographic fairness in text-to-video models by introducing GAP framework and GEOATTRACTION-500 benchmark with 500 globally distributed tourist attractions to assess regional bias.",
      "importance_score": 61,
      "reasoning": "Important fairness evaluation for generative video models with new benchmark, addresses underexplored geographic bias in AI systems.",
      "themes": [
        "AI Fairness",
        "Video Generation",
        "Benchmark Development",
        "Bias Evaluation"
      ],
      "continuation": null,
      "summary_html": "<p>Investigates geographic fairness in text-to-video models by introducing GAP framework and GEOATTRACTION-500 benchmark with 500 globally distributed tourist attractions to assess regional bias.</p>",
      "content_html": "<p>arXiv:2601.18698v1 Announce Type: new  Abstract: Recent advances in text-to-video generation have produced visually compelling results, yet it remains unclear whether these models encode geographically equitable visual knowledge. In this work, we investigate the geo-equity and geographically grounded visual knowledge of text-to-video models through an attraction-centric evaluation. We introduce Geo-Attraction Landmark Probing (GAP), a systematic framework for assessing how faithfully models synthesize tourist attractions from diverse regions, and construct GEOATTRACTION-500, a benchmark of 500 globally distributed attractions spanning varied regions and popularity levels. GAP integrates complementary metrics that disentangle overall video quality from attraction-specific knowledge, including global structural alignment, fine-grained keypoint-based alignment, and vision-language model judgments, all validated against human evaluation. Applying GAP to the state-of-the-art text-to-video model Sora 2, we find that, contrary to common assumptions of strong geographic bias, the model exhibits a relatively uniform level of geographically grounded visual knowledge across regions, development levels, and cultural groupings, with only weak dependence on attraction popularity. These results suggest that current text-to-video models express global visual knowledge more evenly than expected, highlighting both their promise for globally deployed applications and the need for continued evaluation as such systems evolve.</p>"
    },
    {
      "id": "c8fc18ca2ffa",
      "title": "EquiForm: Noise-Robust SE(3)-Equivariant Policy Learning from 3D Point Clouds",
      "content": "arXiv:2601.17486v1 Announce Type: new  Abstract: Visual imitation learning with 3D point clouds has advanced robotic manipulation by providing geometry-aware, appearance-invariant observations. However, point cloud-based policies remain highly sensitive to sensor noise, pose perturbations, and occlusion-induced artifacts, which distort geometric structure and break the equivariance assumptions required for robust generalization. Existing equivariant approaches primarily encode symmetry constraints into neural architectures, but do not explicitly correct noise-induced geometric deviations or enforce equivariant consistency in learned representations. We introduce EquiForm, a noise-robust SE(3)-equivariant policy learning framework for point cloud-based manipulation. EquiForm formalizes how noise-induced geometric distortions lead to equivariance deviations in observation-to-action mappings, and introduces a geometric denoising module to restore consistent 3D structure under noisy or incomplete observations. In addition, we propose a contrastive equivariant alignment objective that enforces representation consistency under both rigid transformations and noise perturbations. Built upon these components, EquiForm forms a flexible policy learning pipeline that integrates noise-robust geometric reasoning with modern generative models. We evaluate EquiForm on 16 simulated tasks and 4 real-world manipulation tasks across diverse objects and scene layouts. Compared to state-of-the-art point cloud imitation learning methods, EquiForm achieves an average improvement of 17.2% in simulation and 28.1% in real-world experiments, demonstrating strong noise robustness and spatial generalization.",
      "url": "http://arxiv.org/abs/2601.17486",
      "author": "Zhiyuan Zhang, Yu She",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Introduces EquiForm, a noise-robust SE(3)-equivariant policy learning framework for point cloud-based manipulation that explicitly corrects geometric deviations.",
      "importance_score": 61,
      "reasoning": "Addresses important robustness challenge in equivariant policy learning with practical implications.",
      "themes": [
        "Equivariant Networks",
        "Robot Manipulation",
        "Robustness"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces EquiForm, a noise-robust SE(3)-equivariant policy learning framework for point cloud-based manipulation that explicitly corrects geometric deviations.</p>",
      "content_html": "<p>arXiv:2601.17486v1 Announce Type: new  Abstract: Visual imitation learning with 3D point clouds has advanced robotic manipulation by providing geometry-aware, appearance-invariant observations. However, point cloud-based policies remain highly sensitive to sensor noise, pose perturbations, and occlusion-induced artifacts, which distort geometric structure and break the equivariance assumptions required for robust generalization. Existing equivariant approaches primarily encode symmetry constraints into neural architectures, but do not explicitly correct noise-induced geometric deviations or enforce equivariant consistency in learned representations. We introduce EquiForm, a noise-robust SE(3)-equivariant policy learning framework for point cloud-based manipulation. EquiForm formalizes how noise-induced geometric distortions lead to equivariance deviations in observation-to-action mappings, and introduces a geometric denoising module to restore consistent 3D structure under noisy or incomplete observations. In addition, we propose a contrastive equivariant alignment objective that enforces representation consistency under both rigid transformations and noise perturbations. Built upon these components, EquiForm forms a flexible policy learning pipeline that integrates noise-robust geometric reasoning with modern generative models. We evaluate EquiForm on 16 simulated tasks and 4 real-world manipulation tasks across diverse objects and scene layouts. Compared to state-of-the-art point cloud imitation learning methods, EquiForm achieves an average improvement of 17.2% in simulation and 28.1% in real-world experiments, demonstrating strong noise robustness and spatial generalization.</p>"
    },
    {
      "id": "784b460c0fda",
      "title": "Agentic AI for Self-Driving Laboratories in Soft Matter: Taxonomy, Benchmarks,and Open Challenges",
      "content": "arXiv:2601.17920v1 Announce Type: new  Abstract: Self-driving laboratories (SDLs) close the loop between experiment design, automated execution, and data-driven decision making, and they provide a demanding testbed for agentic AI under expensive actions, noisy and delayed feedback, strict feasibility and safety constraints, and non-stationarity. This survey uses soft matter as a representative setting but focuses on the AI questions that arise in real laboratories. We frame SDL autonomy as an agent environment interaction problem with explicit observations, actions, costs, and constraints, and we use this formulation to connect common SDL pipelines to established AI principles. We review the main method families that enable closed loop experimentation, including Bayesian optimization and active learning for sample efficient experiment selection, planning and reinforcement learning for long horizon protocol optimization, and tool using agents that orchestrate heterogeneous instruments and software. We emphasize verifiable and provenance aware policies that support debugging, reproducibility, and safe operation. We then propose a capability driven taxonomy that organizes systems by decision horizon, uncertainty modeling, action parameterization, constraint handling, failure recovery, and human involvement. To enable meaningful comparison, we synthesize benchmark task templates and evaluation metrics that prioritize cost aware performance, robustness to drift, constraint violation behavior, and reproducibility. Finally, we distill lessons from deployed SDLs and outline open challenges in multi-modal representation, calibrated uncertainty, safe exploration, and shared benchmark infrastructure.",
      "url": "http://arxiv.org/abs/2601.17920",
      "author": "Xuanzhou Chen, Audrey Wang, Stanley Yin, Hanyang Jiang, Dong Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Comprehensive survey framing self-driving laboratories as agent-environment interaction problems, reviewing Bayesian optimization and other AI methods for closed-loop experimentation with soft matter as representative setting.",
      "importance_score": 60,
      "reasoning": "Well-structured survey connecting SDL challenges to established AI principles; useful reference for emerging field.",
      "themes": [
        "Self-Driving Labs",
        "Bayesian Optimization",
        "Agentic AI"
      ],
      "continuation": null,
      "summary_html": "<p>Comprehensive survey framing self-driving laboratories as agent-environment interaction problems, reviewing Bayesian optimization and other AI methods for closed-loop experimentation with soft matter as representative setting.</p>",
      "content_html": "<p>arXiv:2601.17920v1 Announce Type: new  Abstract: Self-driving laboratories (SDLs) close the loop between experiment design, automated execution, and data-driven decision making, and they provide a demanding testbed for agentic AI under expensive actions, noisy and delayed feedback, strict feasibility and safety constraints, and non-stationarity. This survey uses soft matter as a representative setting but focuses on the AI questions that arise in real laboratories. We frame SDL autonomy as an agent environment interaction problem with explicit observations, actions, costs, and constraints, and we use this formulation to connect common SDL pipelines to established AI principles. We review the main method families that enable closed loop experimentation, including Bayesian optimization and active learning for sample efficient experiment selection, planning and reinforcement learning for long horizon protocol optimization, and tool using agents that orchestrate heterogeneous instruments and software. We emphasize verifiable and provenance aware policies that support debugging, reproducibility, and safe operation. We then propose a capability driven taxonomy that organizes systems by decision horizon, uncertainty modeling, action parameterization, constraint handling, failure recovery, and human involvement. To enable meaningful comparison, we synthesize benchmark task templates and evaluation metrics that prioritize cost aware performance, robustness to drift, constraint violation behavior, and reproducibility. Finally, we distill lessons from deployed SDLs and outline open challenges in multi-modal representation, calibrated uncertainty, safe exploration, and shared benchmark infrastructure.</p>"
    },
    {
      "id": "216d380e89ca",
      "title": "A Balanced Neuro-Symbolic Approach for Commonsense Abductive Logic",
      "content": "arXiv:2601.18595v1 Announce Type: new  Abstract: Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts.",
      "url": "http://arxiv.org/abs/2601.18595",
      "author": "Joseph Cotnareanu, Didier Chetelat, Yingxue Zhang, Mark Coates",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes neuro-symbolic approach using logic solver feedback to iteratively augment problems with commonsense relations from LLMs, improving complex proof planning.",
      "importance_score": 60,
      "reasoning": "Practical combination of LLM and symbolic reasoning strengths; addresses known LLM limitation in proof planning.",
      "themes": [
        "Neuro-Symbolic AI",
        "Reasoning",
        "Commonsense"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes neuro-symbolic approach using logic solver feedback to iteratively augment problems with commonsense relations from LLMs, improving complex proof planning.</p>",
      "content_html": "<p>arXiv:2601.18595v1 Announce Type: new  Abstract: Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts.</p>"
    },
    {
      "id": "12f47c33cede",
      "title": "Failing on Bias Mitigation: Investigating Why Predictive Models Struggle with Government Data",
      "content": "arXiv:2601.17054v1 Announce Type: cross  Abstract: The potential for bias and unfairness in AI-supporting government services raises ethical and legal concerns. Using crime rate prediction with the Bristol City Council data as a case study, we examine how these issues persist. Rather than auditing real-world deployed systems, our goal is to understand why widely adopted bias mitigation techniques often fail when applied to government data. Our findings reveal that bias mitigation approaches applied to government data are not always effective -- not because of flaws in model architecture or metric selection, but due to the inherent properties of the data itself. Through comparing a set of comprehensive models and fairness methods, our experiments consistently show that the mitigation efforts cannot overcome the embedded unfairness in the data -- further reinforcing that the origin of bias lies in the structure and history of government datasets. We then explore the reasons for the mitigation failures in predictive models on government data and highlight the potential sources of unfairness posed by data distribution shifts, the accumulation of historical bias, and delays in data release. We also discover the limitations of the blind spots in fairness analysis and bias mitigation methods when only targeting a single sensitive feature through a set of intersectional fairness experiments. Although this study is limited to one city, the findings are highly suggestive, which can contribute to an early warning that biases in government data may persist even with standard mitigation methods.",
      "url": "http://arxiv.org/abs/2601.17054",
      "author": "Hongbo Bo, Jingyu Hu, Debbie Watson, Weiru Liu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Analyzes why bias mitigation techniques fail on government data using crime rate prediction as case study. Finds data properties, not model architectures, cause mitigation failures.",
      "importance_score": 60,
      "reasoning": "Important negative result identifying fundamental limitations of bias mitigation. Valuable for AI fairness research and policy deployment.",
      "themes": [
        "AI Fairness",
        "Bias Mitigation",
        "Government AI"
      ],
      "continuation": null,
      "summary_html": "<p>Analyzes why bias mitigation techniques fail on government data using crime rate prediction as case study. Finds data properties, not model architectures, cause mitigation failures.</p>",
      "content_html": "<p>arXiv:2601.17054v1 Announce Type: cross  Abstract: The potential for bias and unfairness in AI-supporting government services raises ethical and legal concerns. Using crime rate prediction with the Bristol City Council data as a case study, we examine how these issues persist. Rather than auditing real-world deployed systems, our goal is to understand why widely adopted bias mitigation techniques often fail when applied to government data. Our findings reveal that bias mitigation approaches applied to government data are not always effective -- not because of flaws in model architecture or metric selection, but due to the inherent properties of the data itself. Through comparing a set of comprehensive models and fairness methods, our experiments consistently show that the mitigation efforts cannot overcome the embedded unfairness in the data -- further reinforcing that the origin of bias lies in the structure and history of government datasets. We then explore the reasons for the mitigation failures in predictive models on government data and highlight the potential sources of unfairness posed by data distribution shifts, the accumulation of historical bias, and delays in data release. We also discover the limitations of the blind spots in fairness analysis and bias mitigation methods when only targeting a single sensitive feature through a set of intersectional fairness experiments. Although this study is limited to one city, the findings are highly suggestive, which can contribute to an early warning that biases in government data may persist even with standard mitigation methods.</p>"
    },
    {
      "id": "c3deedb32df7",
      "title": "TrojanGYM: A Detector-in-the-Loop LLM for Adaptive RTL Hardware Trojan Insertion",
      "content": "arXiv:2601.17178v1 Announce Type: cross  Abstract: Hardware Trojans (HTs) remain a critical threat because learning-based detectors often overfit to narrow trigger/payload patterns and small, stylized benchmarks. We introduce TrojanGYM, an agentic, LLM-driven framework that automatically curates HT insertions to expose detector blind spots while preserving design correctness. Given high-level HT specifications, a suite of cooperating LLM agents (instantiated with GPT-4, LLaMA-3.3-70B, and Gemini-2.5Pro) proposes and refines RTL modifications that realize diverse triggers and payloads without impacting normal functionality. TrojanGYM implements a feedback-driven benchmark generation loop co-designed with HT detectors, in which constraint-aware syntactic checking and GNN-based HT detectors provide feedback that iteratively refines HT specifications and insertion strategies to better surface detector blind spots. We further propose Robust-GNN4TJ, a new implementation of the GNN4TJ with improved graph extraction, training robustness, and prediction reliability, especially on LLM-generated HT designs. On the most challenging TrojanGYM-generated benchmarks, Robust-GNN4TJ raises HT detection rates from 0% to 60% relative to a prior GNN-based detector. We instantiate TrojanGYM on SRAM, AES-128, and UART designs at RTL level, and show that it systematically produces diverse, functionally correct HTs that reach up to 83.33% evasion rates against modern GNN-based detectors, revealing robustness gaps that are not apparent when these detectors are evaluated solely on existing TrustHub-style benchmarks. Post peer-review, we will release all codes and artifacts.",
      "url": "http://arxiv.org/abs/2601.17178",
      "author": "Saideep Sreekumar, Zeng Wang, Akashdeep Saha, Weihua Xiao, Minghao Shao, Muhammad Shafique, Ozgur Sinanoglu, Ramesh Karri, Johann Knechtel",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Introduces TrojanGYM, an agentic LLM framework using GPT-4, LLaMA-3.3-70B, and Gemini-2.5Pro for adaptive hardware trojan insertion to expose detector blind spots.",
      "importance_score": 60,
      "reasoning": "Novel application of agentic LLMs for security testing. Uses multiple frontier models for red-teaming hardware security.",
      "themes": [
        "Hardware Security",
        "Agentic AI",
        "Red Teaming"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces TrojanGYM, an agentic LLM framework using GPT-4, LLaMA-3.3-70B, and Gemini-2.5Pro for adaptive hardware trojan insertion to expose detector blind spots.</p>",
      "content_html": "<p>arXiv:2601.17178v1 Announce Type: cross  Abstract: Hardware Trojans (HTs) remain a critical threat because learning-based detectors often overfit to narrow trigger/payload patterns and small, stylized benchmarks. We introduce TrojanGYM, an agentic, LLM-driven framework that automatically curates HT insertions to expose detector blind spots while preserving design correctness. Given high-level HT specifications, a suite of cooperating LLM agents (instantiated with GPT-4, LLaMA-3.3-70B, and Gemini-2.5Pro) proposes and refines RTL modifications that realize diverse triggers and payloads without impacting normal functionality. TrojanGYM implements a feedback-driven benchmark generation loop co-designed with HT detectors, in which constraint-aware syntactic checking and GNN-based HT detectors provide feedback that iteratively refines HT specifications and insertion strategies to better surface detector blind spots. We further propose Robust-GNN4TJ, a new implementation of the GNN4TJ with improved graph extraction, training robustness, and prediction reliability, especially on LLM-generated HT designs. On the most challenging TrojanGYM-generated benchmarks, Robust-GNN4TJ raises HT detection rates from 0% to 60% relative to a prior GNN-based detector. We instantiate TrojanGYM on SRAM, AES-128, and UART designs at RTL level, and show that it systematically produces diverse, functionally correct HTs that reach up to 83.33% evasion rates against modern GNN-based detectors, revealing robustness gaps that are not apparent when these detectors are evaluated solely on existing TrustHub-style benchmarks. Post peer-review, we will release all codes and artifacts.</p>"
    },
    {
      "id": "f1c1e975bcdd",
      "title": "Meta-Judging with Large Language Models: Concepts, Methods, and Challenges",
      "content": "arXiv:2601.17312v1 Announce Type: cross  Abstract: Large language models (LLMs) are evolving fast and are now frequently used as evaluators, in a process typically referred to as LLM-as-a-Judge, which provides quality assessments of model outputs. However, recent research points out significant vulnerabilities in such evaluation, including sensitivity to prompts, systematic biases, verbosity effects, and unreliable or hallucinated rationales. These limitations motivated the development of a more robust paradigm, dubbed LLM-as-a-Meta-Judge. This survey reviews recent advances in meta-judging and organizes the literature, by introducing a framework along six key perspectives: (i) Conceptual Foundations, (ii) Mechanisms of Meta-Judging, (iii) Alignment Training Methods, (iv) Evaluation, (v) Limitations and Failure Modes, and (vi) Future Directions. By analyzing the limitations of LLM-as-a-Judge and summarizing recent advances in meta-judging by LLMs, we argue that LLM-as-a-Meta-Judge offers a promising direction for more stable and trustworthy automated evaluation, while highlighting remaining challenges related to cost, prompt sensitivity, and shared model biases, which must be addressed to advance the next generation of LLM evaluation methodologies.",
      "url": "http://arxiv.org/abs/2601.17312",
      "author": "Hugo Silva, Mateus Mendes, Hugo Gon\\c{c}alo Oliveira",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Comprehensive survey on LLM-as-Meta-Judge paradigm covering conceptual foundations, mechanisms, alignment training, evaluation, and emerging applications.",
      "importance_score": 60,
      "reasoning": "Timely and comprehensive survey of rapidly growing field. Useful reference for LLM evaluation research.",
      "themes": [
        "LLM Evaluation",
        "Meta-Judging",
        "Survey"
      ],
      "continuation": null,
      "summary_html": "<p>Comprehensive survey on LLM-as-Meta-Judge paradigm covering conceptual foundations, mechanisms, alignment training, evaluation, and emerging applications.</p>",
      "content_html": "<p>arXiv:2601.17312v1 Announce Type: cross  Abstract: Large language models (LLMs) are evolving fast and are now frequently used as evaluators, in a process typically referred to as LLM-as-a-Judge, which provides quality assessments of model outputs. However, recent research points out significant vulnerabilities in such evaluation, including sensitivity to prompts, systematic biases, verbosity effects, and unreliable or hallucinated rationales. These limitations motivated the development of a more robust paradigm, dubbed LLM-as-a-Meta-Judge. This survey reviews recent advances in meta-judging and organizes the literature, by introducing a framework along six key perspectives: (i) Conceptual Foundations, (ii) Mechanisms of Meta-Judging, (iii) Alignment Training Methods, (iv) Evaluation, (v) Limitations and Failure Modes, and (vi) Future Directions. By analyzing the limitations of LLM-as-a-Judge and summarizing recent advances in meta-judging by LLMs, we argue that LLM-as-a-Meta-Judge offers a promising direction for more stable and trustworthy automated evaluation, while highlighting remaining challenges related to cost, prompt sensitivity, and shared model biases, which must be addressed to advance the next generation of LLM evaluation methodologies.</p>"
    },
    {
      "id": "b169c2aac2dd",
      "title": "Linguistic and Argument Diversity in Synthetic Data for Function-Calling Agents",
      "content": "arXiv:2601.17829v1 Announce Type: cross  Abstract: The construction of function calling agents has emerged as a promising avenue for extending model capabilities. A major challenge for this task is obtaining high quality diverse data for training. Prior work emphasizes diversity in functions, invocation patterns, and interaction turns, yet linguistic diversity of requests and coverage of arguments (e.g., \\texttt{city\\_name}, \\texttt{stock\\_ticker}) remain underexplored. We propose a method that generates synthetic datasets via optimizing general-purpose diversity metrics across both queries and arguments, without relying on hand-crafted rules or taxonomies, making it robust to different usecases. We demonstrate the effectiveness of our technique via both intrinsic and extrinsic testing, comparing it to SoTA data generation methods. We show a superiority over baselines in terms of diversity, while keeping comparable correctness. Additionally, when used as a training set, the model resulting from our dataset exhibits superior performance compared to analogous models based on the baseline data generation methods in out-of-distribution performance. In particular, we achieve an $7.4\\%$ increase in accuracy on the BFCL benchmark compared to similar counterparts.",
      "url": "http://arxiv.org/abs/2601.17829",
      "author": "Dan Greenstein, Zohar Karnin, Chen Amiraz, Oren Somekh",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes method for generating synthetic training data for function-calling agents by optimizing linguistic and argument diversity without hand-crafted rules.",
      "importance_score": 60,
      "reasoning": "Addresses underexplored aspect of function-calling training data. Diversity optimization approach is principled. Practical for agent development.",
      "themes": [
        "Synthetic Data",
        "Function Calling",
        "Agent Training"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes method for generating synthetic training data for function-calling agents by optimizing linguistic and argument diversity without hand-crafted rules.</p>",
      "content_html": "<p>arXiv:2601.17829v1 Announce Type: cross  Abstract: The construction of function calling agents has emerged as a promising avenue for extending model capabilities. A major challenge for this task is obtaining high quality diverse data for training. Prior work emphasizes diversity in functions, invocation patterns, and interaction turns, yet linguistic diversity of requests and coverage of arguments (e.g., \\texttt{city\\_name}, \\texttt{stock\\_ticker}) remain underexplored. We propose a method that generates synthetic datasets via optimizing general-purpose diversity metrics across both queries and arguments, without relying on hand-crafted rules or taxonomies, making it robust to different usecases. We demonstrate the effectiveness of our technique via both intrinsic and extrinsic testing, comparing it to SoTA data generation methods. We show a superiority over baselines in terms of diversity, while keeping comparable correctness. Additionally, when used as a training set, the model resulting from our dataset exhibits superior performance compared to analogous models based on the baseline data generation methods in out-of-distribution performance. In particular, we achieve an $7.4\\%$ increase in accuracy on the BFCL benchmark compared to similar counterparts.</p>"
    },
    {
      "id": "941f54c9a5bd",
      "title": "\\textsc{NaVIDA}: Vision-Language Navigation with Inverse Dynamics Augmentation",
      "content": "arXiv:2601.18188v1 Announce Type: cross  Abstract: Vision-and-Language Navigation (VLN) requires agents to interpret natural language instructions and act coherently in visually rich environments. However, most existing methods rely on reactive state-action mappings without explicitly modeling how actions causally transform subsequent visual observations. Lacking such vision-action causality, agents cannot anticipate the visual changes induced by its own actions, leading to unstable behaviors, weak generalization, and cumulative error along trajectory. To address these issues, we introduce \\textsc{NaVIDA} (\\textbf{Nav}igation with \\textbf{I}nverse \\textbf{D}ynamics \\textbf{A}ugmentation), a unified VLN framework that couples policy learning with action-grounded visual dynamics and adaptive execution. \\textsc{NaVIDA} augments training with chunk-based inverse-dynamics supervision to learn causal relationship between visual changes and corresponding actions. To structure this supervision and extend the effective planning range, \\textsc{NaVIDA} employs hierarchical probabilistic action chunking (HPAC), which organizes trajectories into multi-step chunks and provides discriminative, longer-range visual-change cues. To further curb error accumulation and stabilize behavior at inference, an entropy-guided mechanism adaptively sets the execution horizon of action chunks. Extensive experiments show that \\textsc{NaVIDA} achieves superior navigation performance compared to state-of-the-art methods with fewer parameters (3B vs. 8B). Real-world robot evaluations further validate the practical feasibility and effectiveness of our approach. Code and data will be available upon acceptance.",
      "url": "http://arxiv.org/abs/2601.18188",
      "author": "Weiye Zhu, Zekai Zhang, Xiangchen Wang, Hewei Pan, Teng Wang, Tiantian Geng, Rongtao Xu, Feng Zheng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces NaVIDA framework for vision-language navigation that explicitly models how actions causally transform visual observations, using inverse dynamics to address unstable behaviors and weak generalization in VLN agents.",
      "importance_score": 60,
      "reasoning": "Principled approach to VLN addressing fundamental causality gap. Novel inverse dynamics augmentation but needs empirical validation details.",
      "themes": [
        "Vision-Language Navigation",
        "Embodied AI",
        "Causal Modeling"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces NaVIDA framework for vision-language navigation that explicitly models how actions causally transform visual observations, using inverse dynamics to address unstable behaviors and weak generalization in VLN agents.</p>",
      "content_html": "<p>arXiv:2601.18188v1 Announce Type: cross  Abstract: Vision-and-Language Navigation (VLN) requires agents to interpret natural language instructions and act coherently in visually rich environments. However, most existing methods rely on reactive state-action mappings without explicitly modeling how actions causally transform subsequent visual observations. Lacking such vision-action causality, agents cannot anticipate the visual changes induced by its own actions, leading to unstable behaviors, weak generalization, and cumulative error along trajectory. To address these issues, we introduce \\textsc{NaVIDA} (\\textbf{Nav}igation with \\textbf{I}nverse \\textbf{D}ynamics \\textbf{A}ugmentation), a unified VLN framework that couples policy learning with action-grounded visual dynamics and adaptive execution. \\textsc{NaVIDA} augments training with chunk-based inverse-dynamics supervision to learn causal relationship between visual changes and corresponding actions. To structure this supervision and extend the effective planning range, \\textsc{NaVIDA} employs hierarchical probabilistic action chunking (HPAC), which organizes trajectories into multi-step chunks and provides discriminative, longer-range visual-change cues. To further curb error accumulation and stabilize behavior at inference, an entropy-guided mechanism adaptively sets the execution horizon of action chunks. Extensive experiments show that \\textsc{NaVIDA} achieves superior navigation performance compared to state-of-the-art methods with fewer parameters (3B vs. 8B). Real-world robot evaluations further validate the practical feasibility and effectiveness of our approach. Code and data will be available upon acceptance.</p>"
    },
    {
      "id": "4982e49b1031",
      "title": "Temp-R1: A Unified Autonomous Agent for Complex Temporal KGQA via Reverse Curriculum Reinforcement Learning",
      "content": "arXiv:2601.18296v1 Announce Type: cross  Abstract: Temporal Knowledge Graph Question Answering (TKGQA) is inherently challenging, as it requires sophisticated reasoning over dynamic facts with multi-hop dependencies and complex temporal constraints. Existing methods rely on fixed workflows and expensive closed-source APIs, limiting flexibility and scalability. We propose Temp-R1, the first autonomous end-to-end agent for TKGQA trained through reinforcement learning. To address cognitive overload in single-action reasoning, we expand the action space with specialized internal actions alongside external action. To prevent shortcut learning on simple questions, we introduce reverse curriculum learning that trains on difficult questions first, forcing the development of sophisticated reasoning before transferring to easier cases. Our 8B-parameter Temp-R1 achieves state-of-the-art performance on MultiTQ and TimelineKGQA, improving 19.8% over strong baselines on complex questions. Our work establishes a new paradigm for autonomous temporal reasoning agents. Our code will be publicly available soon at https://github.com/zjukg/Temp-R1.",
      "url": "http://arxiv.org/abs/2601.18296",
      "author": "Zhaoyan Gong, Zhiqiang Liu, Songze Li, Xiaoke Guo, Yuanxiang Liu, Xinle Deng, Zhizhen Liu, Lei Liang, Huajun Chen, Wen Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces Temp-R1, first autonomous end-to-end agent for temporal knowledge graph QA via reinforcement learning. Uses reverse curriculum learning and specialized internal actions to handle cognitive overload.",
      "importance_score": 60,
      "reasoning": "First RL-based autonomous agent for challenging temporal KGQA domain. Novel reverse curriculum approach addresses shortcut learning.",
      "themes": [
        "Knowledge Graphs",
        "Question Answering",
        "Reinforcement Learning",
        "Temporal Reasoning"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Temp-R1, first autonomous end-to-end agent for temporal knowledge graph QA via reinforcement learning. Uses reverse curriculum learning and specialized internal actions to handle cognitive overload.</p>",
      "content_html": "<p>arXiv:2601.18296v1 Announce Type: cross  Abstract: Temporal Knowledge Graph Question Answering (TKGQA) is inherently challenging, as it requires sophisticated reasoning over dynamic facts with multi-hop dependencies and complex temporal constraints. Existing methods rely on fixed workflows and expensive closed-source APIs, limiting flexibility and scalability. We propose Temp-R1, the first autonomous end-to-end agent for TKGQA trained through reinforcement learning. To address cognitive overload in single-action reasoning, we expand the action space with specialized internal actions alongside external action. To prevent shortcut learning on simple questions, we introduce reverse curriculum learning that trains on difficult questions first, forcing the development of sophisticated reasoning before transferring to easier cases. Our 8B-parameter Temp-R1 achieves state-of-the-art performance on MultiTQ and TimelineKGQA, improving 19.8% over strong baselines on complex questions. Our work establishes a new paradigm for autonomous temporal reasoning agents. Our code will be publicly available soon at https://github.com/zjukg/Temp-R1.</p>"
    },
    {
      "id": "704f2661f8b5",
      "title": "Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory",
      "content": "arXiv:2601.18771v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.",
      "url": "http://arxiv.org/abs/2601.18771",
      "author": "Yanming Liu, Xinyue Peng, Zixuan Yan, Yanxin Shen, Wenjie Xu, Yuefeng Huang, Xinyi Wang, Jiannan Cao, Jianwei Yin, Xuhong Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes Dep-Search framework learning dependency-aware reasoning traces with persistent memory for RAG systems, addressing implicit reasoning limitations for managing cross-step dependencies.",
      "importance_score": 60,
      "reasoning": "Addresses important limitation in current RAG/search frameworks. Explicit dependency management could improve complex reasoning chains.",
      "themes": [
        "RAG",
        "Reasoning",
        "Search Agents",
        "Memory"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Dep-Search framework learning dependency-aware reasoning traces with persistent memory for RAG systems, addressing implicit reasoning limitations for managing cross-step dependencies.</p>",
      "content_html": "<p>arXiv:2601.18771v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.</p>"
    },
    {
      "id": "314223a48b45",
      "title": "Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs",
      "content": "arXiv:2601.16527v1 Announce Type: new  Abstract: Multimodal LLMs are powerful but prone to object hallucinations, which describe non-existent entities and harm reliability. While recent unlearning methods attempt to mitigate this, we identify a critical flaw: structural fragility. We empirically demonstrate that standard erasure achieves only superficial suppression, trapping the model in sharp minima where hallucinations catastrophically resurge after lightweight relearning. To ensure geometric stability, we propose SARE, which casts unlearning as a targeted min-max optimization problem and uses a Targeted-SAM mechanism to explicitly flatten the loss landscape around hallucinated concepts. By suppressing hallucinations under simulated worst-case parameter perturbations, our framework ensures robust removal stable against weight shifts. Extensive experiments demonstrate that SARE significantly outperforms baselines in erasure efficacy while preserving general generation quality. Crucially, it maintains persistent hallucination suppression against relearning and parameter updates, validating the effectiveness of geometric stabilization.",
      "url": "http://arxiv.org/abs/2601.16527",
      "author": "Xianya Fang, Feiyang Ren, Xiang Chen, Yu Tian, Zhen Bi, Haiyang Yu, Sheng-Jun Huang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes SARE for robust hallucination unlearning in multimodal LLMs. Shows standard unlearning achieves only superficial suppression; uses Targeted-SAM to flatten loss landscape and prevent hallucination resurgence.",
      "importance_score": 60,
      "reasoning": "Addresses critical reliability issue in multimodal LLMs; novel perspective on unlearning as optimization geometry problem.",
      "themes": [
        "Multimodal LLMs",
        "Hallucination",
        "Machine Unlearning",
        "AI Safety"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes SARE for robust hallucination unlearning in multimodal LLMs. Shows standard unlearning achieves only superficial suppression; uses Targeted-SAM to flatten loss landscape and prevent hallucination resurgence.</p>",
      "content_html": "<p>arXiv:2601.16527v1 Announce Type: new  Abstract: Multimodal LLMs are powerful but prone to object hallucinations, which describe non-existent entities and harm reliability. While recent unlearning methods attempt to mitigate this, we identify a critical flaw: structural fragility. We empirically demonstrate that standard erasure achieves only superficial suppression, trapping the model in sharp minima where hallucinations catastrophically resurge after lightweight relearning. To ensure geometric stability, we propose SARE, which casts unlearning as a targeted min-max optimization problem and uses a Targeted-SAM mechanism to explicitly flatten the loss landscape around hallucinated concepts. By suppressing hallucinations under simulated worst-case parameter perturbations, our framework ensures robust removal stable against weight shifts. Extensive experiments demonstrate that SARE significantly outperforms baselines in erasure efficacy while preserving general generation quality. Crucially, it maintains persistent hallucination suppression against relearning and parameter updates, validating the effectiveness of geometric stabilization.</p>"
    },
    {
      "id": "e279c25e6b8b",
      "title": "GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints",
      "content": "arXiv:2601.16905v1 Announce Type: new  Abstract: Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE's architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model's router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.",
      "url": "http://arxiv.org/abs/2601.16905",
      "author": "Andy Zhu, Rongzhe Wei, Yupu Gu, Pan Li",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes GRIP for machine unlearning in Mixture-of-Experts models. Identifies that traditional methods manipulate routers rather than erasing knowledge; uses geometric constraint to preserve routing stability.",
      "importance_score": 60,
      "reasoning": "Important contribution to unlearning for MoE architectures; addresses previously unexplored architectural vulnerability.",
      "themes": [
        "Machine Unlearning",
        "Mixture of Experts",
        "AI Safety",
        "LLM Architecture"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes GRIP for machine unlearning in Mixture-of-Experts models. Identifies that traditional methods manipulate routers rather than erasing knowledge; uses geometric constraint to preserve routing stability.</p>",
      "content_html": "<p>arXiv:2601.16905v1 Announce Type: new  Abstract: Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE's architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model's router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.</p>"
    },
    {
      "id": "961f728daffe",
      "title": "Auto-Regressive Masked Diffusion Models",
      "content": "arXiv:2601.16971v1 Announce Type: new  Abstract: Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel generation capabilities of diffusion-based models. Our key insight is to reframe the masked diffusion process as a block-wise causal model. This perspective allows us to design a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across multiple denoising steps in a single, parallel forward pass. The resulting architecture supports efficient, autoregressive-style decoding and a progressive permutation training scheme, allowing the model to learn both canonical left-to-right and random token orderings. Leveraging this flexibility, we introduce a novel strided parallel generation strategy that accelerates inference by generating tokens in parallel streams while maintaining global coherence. Empirical results demonstrate that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming established diffusion baselines while requiring significantly fewer training steps. Furthermore, it establishes a new benchmark for parallel text generation, effectively bridging the performance gap between parallel and sequential decoding.",
      "url": "http://arxiv.org/abs/2601.16971",
      "author": "Mahdi Karami, Ali Ghodsi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes Auto-Regressive Masked Diffusion (ARMD) that reframes masked diffusion as block-wise causal model. Enables computing all conditional probabilities in single parallel forward pass.",
      "importance_score": 60,
      "reasoning": "Important architectural innovation bridging autoregressive and diffusion paradigms for language; addresses efficiency gap.",
      "themes": [
        "Diffusion Models",
        "Language Models",
        "Autoregressive Models",
        "Efficient Training"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Auto-Regressive Masked Diffusion (ARMD) that reframes masked diffusion as block-wise causal model. Enables computing all conditional probabilities in single parallel forward pass.</p>",
      "content_html": "<p>arXiv:2601.16971v1 Announce Type: new  Abstract: Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel generation capabilities of diffusion-based models. Our key insight is to reframe the masked diffusion process as a block-wise causal model. This perspective allows us to design a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across multiple denoising steps in a single, parallel forward pass. The resulting architecture supports efficient, autoregressive-style decoding and a progressive permutation training scheme, allowing the model to learn both canonical left-to-right and random token orderings. Leveraging this flexibility, we introduce a novel strided parallel generation strategy that accelerates inference by generating tokens in parallel streams while maintaining global coherence. Empirical results demonstrate that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming established diffusion baselines while requiring significantly fewer training steps. Furthermore, it establishes a new benchmark for parallel text generation, effectively bridging the performance gap between parallel and sequential decoding.</p>"
    },
    {
      "id": "299d3839493b",
      "title": "White-Box Sensitivity Auditing with Steering Vectors",
      "content": "arXiv:2601.16398v1 Announce Type: cross  Abstract: Algorithmic audits are essential tools for examining systems for properties required by regulators or desired by operators. Current audits of large language models (LLMs) primarily rely on black-box evaluations that assess model behavior only through input-output testing. These methods are limited to tests constructed in the input space, often generated by heuristics. In addition, many socially relevant model properties (e.g., gender bias) are abstract and difficult to measure through text-based inputs alone. To address these limitations, we propose a white-box sensitivity auditing framework for LLMs that leverages activation steering to conduct more rigorous assessments through model internals. Our auditing method conducts internal sensitivity tests by manipulating key concepts relevant to the model's intended function for the task. We demonstrate its application to bias audits in four simulated high-stakes LLM decision tasks. Our method consistently reveals substantial dependence on protected attributes in model predictions, even in settings where standard black-box evaluations suggest little or no bias. Our code is openly available at https://github.com/hannahxchen/llm-steering-audit",
      "url": "http://arxiv.org/abs/2601.16398",
      "author": "Hannah Cyberey, Yangfeng Ji, David Evans",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Proposes white-box sensitivity auditing using activation steering vectors for LLMs. Enables more rigorous assessment of model properties like bias through internal perturbations rather than just input testing.",
      "importance_score": 60,
      "reasoning": "Important contribution to LLM auditing methodology; addresses limitations of black-box evaluations for bias/fairness.",
      "themes": [
        "LLM Auditing",
        "AI Fairness",
        "Steering Vectors",
        "Interpretability"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes white-box sensitivity auditing using activation steering vectors for LLMs. Enables more rigorous assessment of model properties like bias through internal perturbations rather than just input testing.</p>",
      "content_html": "<p>arXiv:2601.16398v1 Announce Type: cross  Abstract: Algorithmic audits are essential tools for examining systems for properties required by regulators or desired by operators. Current audits of large language models (LLMs) primarily rely on black-box evaluations that assess model behavior only through input-output testing. These methods are limited to tests constructed in the input space, often generated by heuristics. In addition, many socially relevant model properties (e.g., gender bias) are abstract and difficult to measure through text-based inputs alone. To address these limitations, we propose a white-box sensitivity auditing framework for LLMs that leverages activation steering to conduct more rigorous assessments through model internals. Our auditing method conducts internal sensitivity tests by manipulating key concepts relevant to the model's intended function for the task. We demonstrate its application to bias audits in four simulated high-stakes LLM decision tasks. Our method consistently reveals substantial dependence on protected attributes in model predictions, even in settings where standard black-box evaluations suggest little or no bias. Our code is openly available at https://github.com/hannahxchen/llm-steering-audit</p>"
    },
    {
      "id": "b64906d985ac",
      "title": "Sequence Repetition Enhances Token Embeddings and Improves Sequence Labeling with Decoder-only Language Models",
      "content": "arXiv:2601.17585v1 Announce Type: new  Abstract: Modern language models (LMs) are trained in an autoregressive manner, conditioned only on the prefix. In contrast, sequence labeling (SL) tasks assign labels to each individual input token, naturally benefiting from bidirectional context. This discrepancy has historically led SL to rely on inherently bidirectional encoder-only models. However, the rapid development of decoder-only models has raised the question of whether they can be adapted to SL. While causal mask removal has emerged as a viable technique for adapting decoder-only models to leverage the full context for SL, it requires considerable changes to the base model functionality. In this work, we explore sequence repetition (SR) as a less invasive alternative for enabling bidirectionality in decoder-only models. Through fine-tuning experiments, we show that SR inherently makes decoders bidirectional, improving the quality of token-level embeddings and surpassing encoders and unmasked decoders. Contrary to earlier claims, we find that increasing the number of repetitions does not degrade SL performance. Finally, we demonstrate that embeddings from intermediate layers are highly effective for SR, comparable to those from final layers, while being significantly more efficient to compute. Our findings underscore that SR alleviates the structural limitations of decoders, enabling more efficient and adaptable LMs and broadening their applicability to other token-level tasks.",
      "url": "http://arxiv.org/abs/2601.17585",
      "author": "Matija Luka Kuki\\'c, Marko \\v{C}uljak, David Duki\\'c, Martin Tutek, Jan \\v{S}najder",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Explores sequence repetition as a technique to enable decoder-only models to leverage full context for sequence labeling tasks without removing causal masks. Less invasive alternative to architectural modifications.",
      "importance_score": 60,
      "reasoning": "Practical technique for adapting decoder models to sequence labeling. Simple approach with demonstrated effectiveness.",
      "themes": [
        "Sequence Labeling",
        "Decoder-Only Models",
        "Model Adaptation"
      ],
      "continuation": null,
      "summary_html": "<p>Explores sequence repetition as a technique to enable decoder-only models to leverage full context for sequence labeling tasks without removing causal masks. Less invasive alternative to architectural modifications.</p>",
      "content_html": "<p>arXiv:2601.17585v1 Announce Type: new  Abstract: Modern language models (LMs) are trained in an autoregressive manner, conditioned only on the prefix. In contrast, sequence labeling (SL) tasks assign labels to each individual input token, naturally benefiting from bidirectional context. This discrepancy has historically led SL to rely on inherently bidirectional encoder-only models. However, the rapid development of decoder-only models has raised the question of whether they can be adapted to SL. While causal mask removal has emerged as a viable technique for adapting decoder-only models to leverage the full context for SL, it requires considerable changes to the base model functionality. In this work, we explore sequence repetition (SR) as a less invasive alternative for enabling bidirectionality in decoder-only models. Through fine-tuning experiments, we show that SR inherently makes decoders bidirectional, improving the quality of token-level embeddings and surpassing encoders and unmasked decoders. Contrary to earlier claims, we find that increasing the number of repetitions does not degrade SL performance. Finally, we demonstrate that embeddings from intermediate layers are highly effective for SR, comparable to those from final layers, while being significantly more efficient to compute. Our findings underscore that SR alleviates the structural limitations of decoders, enabling more efficient and adaptable LMs and broadening their applicability to other token-level tasks.</p>"
    },
    {
      "id": "10287e76c512",
      "title": "PEAR: Pairwise Evaluation for Automatic Relative Scoring in Machine Translation",
      "content": "arXiv:2601.18006v1 Announce Type: new  Abstract: We present PEAR (Pairwise Evaluation for Automatic Relative Scoring), a supervised Quality Estimation (QE) metric family that reframes reference-free Machine Translation (MT) evaluation as a graded pairwise comparison. Given a source segment and two candidate translations, PEAR predicts the direction and magnitude of their quality difference. The metrics are trained using pairwise supervision derived from differences in human judgments, with an additional regularization term that encourages sign inversion under candidate order reversal. On the WMT24 meta-evaluation benchmark, PEAR outperforms strictly matched single-candidate QE baselines trained with the same data and backbones, isolating the benefit of the proposed pairwise formulation. Despite using substantially fewer parameters than recent large metrics, PEAR surpasses far larger QE models and reference-based metrics. Our analysis further indicates that PEAR yields a less redundant evaluation signal relative to other top metrics. Finally, we show that PEAR is an effective utility function for Minimum Bayes Risk (MBR) decoding, reducing pairwise scoring cost at negligible impact.",
      "url": "http://arxiv.org/abs/2601.18006",
      "author": "Lorenzo Proietti, Roman Grundkiewicz, Matt Post",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces PEAR, a pairwise QE metric for MT evaluation that predicts direction and magnitude of quality differences between translation candidates. Outperforms single-candidate baselines with same training data.",
      "importance_score": 60,
      "reasoning": "Practical improvement to MT evaluation with novel pairwise formulation. Solid methodology and results.",
      "themes": [
        "Machine Translation",
        "Evaluation Metrics",
        "Quality Estimation"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces PEAR, a pairwise QE metric for MT evaluation that predicts direction and magnitude of quality differences between translation candidates. Outperforms single-candidate baselines with same training data.</p>",
      "content_html": "<p>arXiv:2601.18006v1 Announce Type: new  Abstract: We present PEAR (Pairwise Evaluation for Automatic Relative Scoring), a supervised Quality Estimation (QE) metric family that reframes reference-free Machine Translation (MT) evaluation as a graded pairwise comparison. Given a source segment and two candidate translations, PEAR predicts the direction and magnitude of their quality difference. The metrics are trained using pairwise supervision derived from differences in human judgments, with an additional regularization term that encourages sign inversion under candidate order reversal. On the WMT24 meta-evaluation benchmark, PEAR outperforms strictly matched single-candidate QE baselines trained with the same data and backbones, isolating the benefit of the proposed pairwise formulation. Despite using substantially fewer parameters than recent large metrics, PEAR surpasses far larger QE models and reference-based metrics. Our analysis further indicates that PEAR yields a less redundant evaluation signal relative to other top metrics. Finally, we show that PEAR is an effective utility function for Minimum Bayes Risk (MBR) decoding, reducing pairwise scoring cost at negligible impact.</p>"
    },
    {
      "id": "43efa5b16c5a",
      "title": "A Contrastive Pre-trained Foundation Model for Deciphering Imaging Noisomics across Modalities",
      "content": "arXiv:2601.17047v1 Announce Type: new  Abstract: Characterizing imaging noise is notoriously data-intensive and device-dependent, as modern sensors entangle physical signals with complex algorithmic artifacts. Current paradigms struggle to disentangle these factors without massive supervised datasets, often reducing noise to mere interference rather than an information resource. Here, we introduce \"Noisomics\", a framework shifting the focus from suppression to systematic noise decoding via the Contrastive Pre-trained (CoP) Foundation Model. By leveraging the manifold hypothesis and synthetic noise genome, CoP employs contrastive learning to disentangle semantic signals from stochastic perturbations. Crucially, CoP breaks traditional deep learning scaling laws, achieving superior performance with only 100 training samples, outperforming supervised baselines trained on 100,000 samples, thereby reducing data and computational dependency by three orders of magnitude. Extensive benchmarking across 12 diverse out-of-domain datasets confirms its robust zero-shot generalization, demonstrating a 63.8% reduction in estimation error and an 85.1% improvement in the coefficient of determination compared to the conventional training strategy. We demonstrate CoP's utility across scales: from deciphering non-linear hardware-noise interplay in consumer photography to optimizing photon-efficient protocols for deep-tissue microscopy. By decoding noise as a multi-parametric footprint, our work redefines stochastic degradation as a vital information resource, empowering precise imaging diagnostics without prior device calibration.",
      "url": "http://arxiv.org/abs/2601.17047",
      "author": "Yuanjie Gu, Yiqun Wang, Chaohui Yu, Ang Xuan, Fan Wang, Zhi Lu, Biqin Dong",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces 'Noisomics' framework shifting from noise suppression to systematic noise decoding via Contrastive Pre-trained Foundation Model, breaking traditional deep learning scaling laws for noise characterization.",
      "importance_score": 60,
      "reasoning": "Novel perspective on imaging noise as information source rather than interference. Interesting foundation model approach.",
      "themes": [
        "Foundation Models",
        "Imaging",
        "Contrastive Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces 'Noisomics' framework shifting from noise suppression to systematic noise decoding via Contrastive Pre-trained Foundation Model, breaking traditional deep learning scaling laws for noise characterization.</p>",
      "content_html": "<p>arXiv:2601.17047v1 Announce Type: new  Abstract: Characterizing imaging noise is notoriously data-intensive and device-dependent, as modern sensors entangle physical signals with complex algorithmic artifacts. Current paradigms struggle to disentangle these factors without massive supervised datasets, often reducing noise to mere interference rather than an information resource. Here, we introduce \"Noisomics\", a framework shifting the focus from suppression to systematic noise decoding via the Contrastive Pre-trained (CoP) Foundation Model. By leveraging the manifold hypothesis and synthetic noise genome, CoP employs contrastive learning to disentangle semantic signals from stochastic perturbations. Crucially, CoP breaks traditional deep learning scaling laws, achieving superior performance with only 100 training samples, outperforming supervised baselines trained on 100,000 samples, thereby reducing data and computational dependency by three orders of magnitude. Extensive benchmarking across 12 diverse out-of-domain datasets confirms its robust zero-shot generalization, demonstrating a 63.8% reduction in estimation error and an 85.1% improvement in the coefficient of determination compared to the conventional training strategy. We demonstrate CoP's utility across scales: from deciphering non-linear hardware-noise interplay in consumer photography to optimizing photon-efficient protocols for deep-tissue microscopy. By decoding noise as a multi-parametric footprint, our work redefines stochastic degradation as a vital information resource, empowering precise imaging diagnostics without prior device calibration.</p>"
    },
    {
      "id": "5111044799ed",
      "title": "C-RADIOv4 (Tech Report)",
      "content": "arXiv:2601.17237v1 Announce Type: new  Abstract: By leveraging multi-teacher distillation, agglomerative vision backbones provide a unified student model that retains and improves the distinct capabilities of multiple teachers. In this tech report, we describe the most recent release of the C-RADIO family of models, C-RADIOv4, which builds upon AM-RADIO/RADIOv2.5 in design, offering strong improvements on key downstream tasks at the same computational complexity. We release -SO400M (412M params), and -H (631M) model variants, both trained with an updated set of teachers: SigLIP2, DINOv3, and SAM3. In addition to improvements on core metrics and new capabilities from imitating SAM3, the C-RADIOv4 model family further improves any-resolution support, brings back the ViTDet option for drastically enhanced efficiency at high-resolution, and comes with a permissive license.",
      "url": "http://arxiv.org/abs/2601.17237",
      "author": "Mike Ranzinger, Greg Heinrich, Collin McCarthy, Jan Kautz, Andrew Tao, Bryan Catanzaro, Pavlo Molchanov",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Technical report on C-RADIOv4, multi-teacher distilled vision backbone with updated teachers (SigLIP2, DINOv3, SAM3), improved any-resolution support, and ViTDet option.",
      "importance_score": 60,
      "reasoning": "Practical vision backbone update with strong teachers. Useful infrastructure contribution.",
      "themes": [
        "Vision Foundation Models",
        "Knowledge Distillation",
        "Model Release"
      ],
      "continuation": null,
      "summary_html": "<p>Technical report on C-RADIOv4, multi-teacher distilled vision backbone with updated teachers (SigLIP2, DINOv3, SAM3), improved any-resolution support, and ViTDet option.</p>",
      "content_html": "<p>arXiv:2601.17237v1 Announce Type: new  Abstract: By leveraging multi-teacher distillation, agglomerative vision backbones provide a unified student model that retains and improves the distinct capabilities of multiple teachers. In this tech report, we describe the most recent release of the C-RADIO family of models, C-RADIOv4, which builds upon AM-RADIO/RADIOv2.5 in design, offering strong improvements on key downstream tasks at the same computational complexity. We release -SO400M (412M params), and -H (631M) model variants, both trained with an updated set of teachers: SigLIP2, DINOv3, and SAM3. In addition to improvements on core metrics and new capabilities from imitating SAM3, the C-RADIOv4 model family further improves any-resolution support, brings back the ViTDet option for drastically enhanced efficiency at high-resolution, and comes with a permissive license.</p>"
    },
    {
      "id": "b805a1ce7a0e",
      "title": "FMIR, a foundation model-based Image Registration Framework for Robust Image Registration",
      "content": "arXiv:2601.17529v1 Announce Type: new  Abstract: Deep learning has revolutionized medical image registration by achieving unprecedented speeds, yet its clinical application is hindered by a limited ability to generalize beyond the training domain, a critical weakness given the typically small scale of medical datasets. In this paper, we introduce FMIR, a foundation model-based registration framework that overcomes this limitation.Combining a foundation model-based feature encoder for extracting anatomical structures with a general registration head, and trained with a channel regularization strategy on just a single dataset, FMIR achieves state-of-the-art(SOTA) in-domain performance while maintaining robust registration on out-of-domain images.Our approach demonstrates a viable path toward building generalizable medical imaging foundation models with limited resources. The code is available at https://github.com/Monday0328/FMIR.git.",
      "url": "http://arxiv.org/abs/2601.17529",
      "author": "Fengting Zhang, Yue He, Qinghao Liu, Yaonan Wang, Xiang Chen, Hang Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes FMIR, foundation model-based medical image registration framework achieving strong out-of-domain generalization when trained on single dataset, addressing key limitation of deep learning registration.",
      "importance_score": 60,
      "reasoning": "Addresses important generalization challenge in medical image registration with foundation model approach.",
      "themes": [
        "Medical Image Registration",
        "Foundation Models",
        "Generalization"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes FMIR, foundation model-based medical image registration framework achieving strong out-of-domain generalization when trained on single dataset, addressing key limitation of deep learning registration.</p>",
      "content_html": "<p>arXiv:2601.17529v1 Announce Type: new  Abstract: Deep learning has revolutionized medical image registration by achieving unprecedented speeds, yet its clinical application is hindered by a limited ability to generalize beyond the training domain, a critical weakness given the typically small scale of medical datasets. In this paper, we introduce FMIR, a foundation model-based registration framework that overcomes this limitation.Combining a foundation model-based feature encoder for extracting anatomical structures with a general registration head, and trained with a channel regularization strategy on just a single dataset, FMIR achieves state-of-the-art(SOTA) in-domain performance while maintaining robust registration on out-of-domain images.Our approach demonstrates a viable path toward building generalizable medical imaging foundation models with limited resources. The code is available at https://github.com/Monday0328/FMIR.git.</p>"
    },
    {
      "id": "efd273d27408",
      "title": "VAE-REPA: Variational Autoencoder Representation Alignment for Efficient Diffusion Training",
      "content": "arXiv:2601.17830v1 Announce Type: new  Abstract: Denoising-based diffusion transformers, despite their strong generation performance, suffer from inefficient training convergence. Existing methods addressing this issue, such as REPA (relying on external representation encoders) or SRA (requiring dual-model setups), inevitably incur heavy computational overhead during training due to external dependencies. To tackle these challenges, this paper proposes \\textbf{\\namex}, a lightweight intrinsic guidance framework for efficient diffusion training. \\name leverages off-the-shelf pre-trained Variational Autoencoder (VAE) features: their reconstruction property ensures inherent encoding of visual priors like rich texture details, structural patterns, and basic semantic information. Specifically, \\name aligns the intermediate latent features of diffusion transformers with VAE features via a lightweight projection layer, supervised by a feature alignment loss. This design accelerates training without extra representation encoders or dual-model maintenance, resulting in a simple yet effective pipeline. Extensive experiments demonstrate that \\name improves both generation quality and training convergence speed compared to vanilla diffusion transformers, matches or outperforms state-of-the-art acceleration methods, and incurs merely 4\\% extra GFLOPs with zero additional cost for external guidance models.",
      "url": "http://arxiv.org/abs/2601.17830",
      "author": "Mengmeng Wang, Dengyang Jiang, Liuzhuozheng Li, Yucheng Lin, Guojiang Shen, Xiangjie Kong, Yong Liu, Guang Dai, Jingdong Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "VAE-REPA leverages off-the-shelf VAE features as intrinsic guidance for efficient diffusion transformer training, exploiting VAE's rich texture and structural priors without requiring external representation encoders.",
      "importance_score": 60,
      "reasoning": "Addresses diffusion training efficiency without external dependencies. Practical and lightweight approach building on existing infrastructure.",
      "themes": [
        "Diffusion Models",
        "Training Efficiency",
        "Representation Learning"
      ],
      "continuation": null,
      "summary_html": "<p>VAE-REPA leverages off-the-shelf VAE features as intrinsic guidance for efficient diffusion transformer training, exploiting VAE's rich texture and structural priors without requiring external representation encoders.</p>",
      "content_html": "<p>arXiv:2601.17830v1 Announce Type: new  Abstract: Denoising-based diffusion transformers, despite their strong generation performance, suffer from inefficient training convergence. Existing methods addressing this issue, such as REPA (relying on external representation encoders) or SRA (requiring dual-model setups), inevitably incur heavy computational overhead during training due to external dependencies. To tackle these challenges, this paper proposes \\textbf{\\namex}, a lightweight intrinsic guidance framework for efficient diffusion training. \\name leverages off-the-shelf pre-trained Variational Autoencoder (VAE) features: their reconstruction property ensures inherent encoding of visual priors like rich texture details, structural patterns, and basic semantic information. Specifically, \\name aligns the intermediate latent features of diffusion transformers with VAE features via a lightweight projection layer, supervised by a feature alignment loss. This design accelerates training without extra representation encoders or dual-model maintenance, resulting in a simple yet effective pipeline. Extensive experiments demonstrate that \\name improves both generation quality and training convergence speed compared to vanilla diffusion transformers, matches or outperforms state-of-the-art acceleration methods, and incurs merely 4\\% extra GFLOPs with zero additional cost for external guidance models.</p>"
    },
    {
      "id": "9a78e1f939d8",
      "title": "ARMOR: Agentic Reasoning for Methods Orchestration and Reparameterization for Robust Adversarial Attacks",
      "content": "arXiv:2601.18386v1 Announce Type: new  Abstract: Existing automated attack suites operate as static ensembles with fixed sequences, lacking strategic adaptation and semantic awareness. This paper introduces the Agentic Reasoning for Methods Orchestration and Reparameterization (ARMOR) framework to address these limitations. ARMOR orchestrates three canonical adversarial primitives, Carlini-Wagner (CW), Jacobian-based Saliency Map Attack (JSMA), and Spatially Transformed Attacks (STA) via Vision Language Models (VLM)-guided agents that collaboratively generate and synthesize perturbations through a shared ``Mixing Desk\". Large Language Models (LLMs) adaptively tune and reparameterize parallel attack agents in a real-time, closed-loop system that exploits image-specific semantic vulnerabilities. On standard benchmarks, ARMOR achieves improved cross-architecture transfer and reliably fools both settings, delivering a blended output for blind targets and selecting the best attack or blended attacks for white-box targets using a confidence-and-SSIM score.",
      "url": "http://arxiv.org/abs/2601.18386",
      "author": "Gabriel Lee Jun Rong, Christos Korgialas, Dion Jia Xu Ho, Pai Chet Ng, Xiaoxiao Miao, Konstantinos N. Plataniotis",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "ARMOR introduces agentic adversarial attack framework that orchestrates multiple attack primitives (CW, JSMA, STA) via VLM-guided agents with LLM-adaptive parameter tuning in real-time.",
      "importance_score": 60,
      "reasoning": "Novel agentic approach to adversarial attacks. Interesting combination of VLM guidance with classical attacks.",
      "themes": [
        "Adversarial Attacks",
        "AI Agents",
        "Red Teaming"
      ],
      "continuation": null,
      "summary_html": "<p>ARMOR introduces agentic adversarial attack framework that orchestrates multiple attack primitives (CW, JSMA, STA) via VLM-guided agents with LLM-adaptive parameter tuning in real-time.</p>",
      "content_html": "<p>arXiv:2601.18386v1 Announce Type: new  Abstract: Existing automated attack suites operate as static ensembles with fixed sequences, lacking strategic adaptation and semantic awareness. This paper introduces the Agentic Reasoning for Methods Orchestration and Reparameterization (ARMOR) framework to address these limitations. ARMOR orchestrates three canonical adversarial primitives, Carlini-Wagner (CW), Jacobian-based Saliency Map Attack (JSMA), and Spatially Transformed Attacks (STA) via Vision Language Models (VLM)-guided agents that collaboratively generate and synthesize perturbations through a shared ``Mixing Desk\". Large Language Models (LLMs) adaptively tune and reparameterize parallel attack agents in a real-time, closed-loop system that exploits image-specific semantic vulnerabilities. On standard benchmarks, ARMOR achieves improved cross-architecture transfer and reliably fools both settings, delivering a blended output for blind targets and selecting the best attack or blended attacks for white-box targets using a confidence-and-SSIM score.</p>"
    },
    {
      "id": "96ed57ed628e",
      "title": "MetaWorld: Skill Transfer and Composition in a Hierarchical World Model for Grounding High-Level Instructions",
      "content": "arXiv:2601.17507v1 Announce Type: new  Abstract: Humanoid robot loco-manipulation remains constrained by the semantic-physical gap. Current methods face three limitations: Low sample efficiency in reinforcement learning, poor generalization in imitation learning, and physical inconsistency in VLMs. We propose MetaWorld, a hierarchical world model that integrates semantic planning and physical control via expert policy transfer. The framework decouples tasks into a VLM-driven semantic layer and a latent dynamics model operating in a compact state space. Our dynamic expert selection and motion prior fusion mechanism leverages a pre-trained multi-expert policy library as transferable knowledge, enabling efficient online adaptation via a two-stage framework. VLMs serve as semantic interfaces, mapping instructions to executable skills and bypassing symbol grounding. Experiments on Humanoid-Bench show MetaWorld outperforms world model-based RL in task completion and motion coherence. Our code will be found at https://anonymous.4open.science/r/metaworld-2BF4/",
      "url": "http://arxiv.org/abs/2601.17507",
      "author": "Yutong Shen, Hangxu Liu, Kailin Pei, Ruizhe Xia, Tongtong Feng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes MetaWorld, a hierarchical world model integrating VLM-driven semantic planning with latent dynamics model for humanoid loco-manipulation with expert policy transfer.",
      "importance_score": 60,
      "reasoning": "Interesting integration of VLMs with world models for humanoid control, addresses semantic-physical gap.",
      "themes": [
        "World Models",
        "Humanoid Robotics",
        "VLM Applications"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes MetaWorld, a hierarchical world model integrating VLM-driven semantic planning with latent dynamics model for humanoid loco-manipulation with expert policy transfer.</p>",
      "content_html": "<p>arXiv:2601.17507v1 Announce Type: new  Abstract: Humanoid robot loco-manipulation remains constrained by the semantic-physical gap. Current methods face three limitations: Low sample efficiency in reinforcement learning, poor generalization in imitation learning, and physical inconsistency in VLMs. We propose MetaWorld, a hierarchical world model that integrates semantic planning and physical control via expert policy transfer. The framework decouples tasks into a VLM-driven semantic layer and a latent dynamics model operating in a compact state space. Our dynamic expert selection and motion prior fusion mechanism leverages a pre-trained multi-expert policy library as transferable knowledge, enabling efficient online adaptation via a two-stage framework. VLMs serve as semantic interfaces, mapping instructions to executable skills and bypassing symbol grounding. Experiments on Humanoid-Bench show MetaWorld outperforms world model-based RL in task completion and motion coherence. Our code will be found at https://anonymous.4open.science/r/metaworld-2BF4/</p>"
    },
    {
      "id": "23a7dcdd642b",
      "title": "MMR-Bench: A Comprehensive Benchmark for Multimodal LLM Routing",
      "content": "arXiv:2601.17814v1 Announce Type: new  Abstract: Multimodal large language models (MLLMs) have advanced rapidly, yet heterogeneity in architecture, alignment strategies, and efficiency means that no single model is uniformly superior across tasks. In practical deployments, workloads span lightweight OCR to complex multimodal reasoning; using one MLLM for all queries either over-provisions compute on easy instances or sacrifices accuracy on hard ones. Query-level model selection (routing) addresses this tension, but extending routing from text-only LLMs to MLLMs is nontrivial due to modality fusion, wide variation in computational cost across models, and the absence of a standardized, budget-aware evaluation. We present MMR-Bench, a unified benchmark that isolates the multimodal routing problem and enables comparison under fixed candidate sets and cost models. MMR-Bench provides (i) a controlled environment with modality-aware inputs and variable compute budgets, (ii) a broad suite of vision-language tasks covering OCR, general VQA, and multimodal math reasoning, and (iii) strong single-model reference, oracle upper bounds, and representative routing policies. Using MMR-Bench, we show that incorporating multimodal signals improves routing quality. Empirically, these cues improve the cost-accuracy frontier and enable the routed system to exceed the strongest single model's accuracy at roughly 33% of its cost. Furthermore, policies trained on a subset of models and tasks generalize zero-shot to new datasets and text-only benchmarks without retuning, establishing MMR-Bench as a foundation for studying adaptive multimodal model selection and efficient MLLM deployment. The code will be available at: https://github.com/Hunter-Wrynn/MMR-Bench.",
      "url": "http://arxiv.org/abs/2601.17814",
      "author": "Haoxuan Ma, Guannan Lai, Han-Jia Ye",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Presents MMR-Bench, a unified benchmark for multimodal LLM routing that addresses modality fusion challenges and budget-aware evaluation for query-level model selection.",
      "importance_score": 59,
      "reasoning": "Useful benchmark for practical deployment optimization; addresses real cost-accuracy tradeoffs in multimodal systems.",
      "themes": [
        "Model Routing",
        "Vision-Language Models",
        "Benchmarks"
      ],
      "continuation": null,
      "summary_html": "<p>Presents MMR-Bench, a unified benchmark for multimodal LLM routing that addresses modality fusion challenges and budget-aware evaluation for query-level model selection.</p>",
      "content_html": "<p>arXiv:2601.17814v1 Announce Type: new  Abstract: Multimodal large language models (MLLMs) have advanced rapidly, yet heterogeneity in architecture, alignment strategies, and efficiency means that no single model is uniformly superior across tasks. In practical deployments, workloads span lightweight OCR to complex multimodal reasoning; using one MLLM for all queries either over-provisions compute on easy instances or sacrifices accuracy on hard ones. Query-level model selection (routing) addresses this tension, but extending routing from text-only LLMs to MLLMs is nontrivial due to modality fusion, wide variation in computational cost across models, and the absence of a standardized, budget-aware evaluation. We present MMR-Bench, a unified benchmark that isolates the multimodal routing problem and enables comparison under fixed candidate sets and cost models. MMR-Bench provides (i) a controlled environment with modality-aware inputs and variable compute budgets, (ii) a broad suite of vision-language tasks covering OCR, general VQA, and multimodal math reasoning, and (iii) strong single-model reference, oracle upper bounds, and representative routing policies. Using MMR-Bench, we show that incorporating multimodal signals improves routing quality. Empirically, these cues improve the cost-accuracy frontier and enable the routed system to exceed the strongest single model's accuracy at roughly 33% of its cost. Furthermore, policies trained on a subset of models and tasks generalize zero-shot to new datasets and text-only benchmarks without retuning, establishing MMR-Bench as a foundation for studying adaptive multimodal model selection and efficient MLLM deployment. The code will be available at: https://github.com/Hunter-Wrynn/MMR-Bench.</p>"
    },
    {
      "id": "a6fcede2c19c",
      "title": "FadeMem: Biologically-Inspired Forgetting for Efficient Agent Memory",
      "content": "arXiv:2601.18642v1 Announce Type: new  Abstract: Large language models deployed as autonomous agents face critical memory limitations, lacking selective forgetting mechanisms that lead to either catastrophic forgetting at context boundaries or information overload within them. While human memory naturally balances retention and forgetting through adaptive decay processes, current AI systems employ binary retention strategies that preserve everything or lose it entirely. We propose FadeMem, a biologically-inspired agent memory architecture that incorporates active forgetting mechanisms mirroring human cognitive efficiency. FadeMem implements differential decay rates across a dual-layer memory hierarchy, where retention is governed by adaptive exponential decay functions modulated by semantic relevance, access frequency, and temporal patterns. Through LLM-guided conflict resolution and intelligent memory fusion, our system consolidates related information while allowing irrelevant details to fade. Experiments on Multi-Session Chat, LoCoMo, and LTI-Bench demonstrate superior multi-hop reasoning and retrieval with 45\\% storage reduction, validating the effectiveness of biologically-inspired forgetting in agent memory systems.",
      "url": "http://arxiv.org/abs/2601.18642",
      "author": "Lei Wei, Xu Dong, Xiao Peng, Niantao Xie, Bin Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes FadeMem, biologically-inspired agent memory with differential decay rates and dual-layer hierarchy governed by adaptive exponential decay modulated by semantic importance.",
      "importance_score": 59,
      "reasoning": "Interesting bio-inspired approach to agent memory; addresses real limitation of current systems.",
      "themes": [
        "Agentic AI",
        "Memory Systems",
        "Bio-Inspired AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes FadeMem, biologically-inspired agent memory with differential decay rates and dual-layer hierarchy governed by adaptive exponential decay modulated by semantic importance.</p>",
      "content_html": "<p>arXiv:2601.18642v1 Announce Type: new  Abstract: Large language models deployed as autonomous agents face critical memory limitations, lacking selective forgetting mechanisms that lead to either catastrophic forgetting at context boundaries or information overload within them. While human memory naturally balances retention and forgetting through adaptive decay processes, current AI systems employ binary retention strategies that preserve everything or lose it entirely. We propose FadeMem, a biologically-inspired agent memory architecture that incorporates active forgetting mechanisms mirroring human cognitive efficiency. FadeMem implements differential decay rates across a dual-layer memory hierarchy, where retention is governed by adaptive exponential decay functions modulated by semantic relevance, access frequency, and temporal patterns. Through LLM-guided conflict resolution and intelligent memory fusion, our system consolidates related information while allowing irrelevant details to fade. Experiments on Multi-Session Chat, LoCoMo, and LTI-Bench demonstrate superior multi-hop reasoning and retrieval with 45\\% storage reduction, validating the effectiveness of biologically-inspired forgetting in agent memory systems.</p>"
    },
    {
      "id": "2a49bb5207b1",
      "title": "MergeMix: Optimizing Mid-Training Data Mixtures via Learnable Model Merging",
      "content": "arXiv:2601.17858v1 Announce Type: cross  Abstract: Optimizing data mixtures is essential for unlocking the full potential of large language models (LLMs), yet identifying the optimal composition remains computationally prohibitive due to reliance on heuristic trials or expensive proxy training. To address this, we introduce \\textbf{MergeMix}, a novel approach that efficiently determines optimal data mixing ratios by repurposing model merging weights as a high-fidelity, low-cost performance proxy. By training domain-specific experts on minimal tokens and optimizing their merging weights against downstream benchmarks, MergeMix effectively optimizes the performance of data mixtures without incurring the cost of full-scale training. Extensive experiments on models with 8B and 16B parameters validate that MergeMix achieves performance comparable to or surpassing exhaustive manual tuning while drastically reducing search costs. Furthermore, MergeMix exhibits high rank consistency (Spearman $\\rho > 0.9$) and strong cross-scale transferability, offering a scalable, automated solution for data mixture optimization.",
      "url": "http://arxiv.org/abs/2601.17858",
      "author": "Jiapeng Wang, Changxin Tian, Kunlong Chen, Ziqi Liu, Jiaxin Mao, Wayne Xin Zhao, Zhiqiang Zhang, Jun Zhou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "MergeMix determines optimal data mixing ratios for LLM training by using model merging weights as low-cost performance proxy, avoiding expensive full-scale training.",
      "importance_score": 59,
      "reasoning": "Practical solution for data mixture optimization. Model merging as proxy is clever. Addresses computational cost problem.",
      "themes": [
        "Data Mixing",
        "LLM Training",
        "Model Merging"
      ],
      "continuation": null,
      "summary_html": "<p>MergeMix determines optimal data mixing ratios for LLM training by using model merging weights as low-cost performance proxy, avoiding expensive full-scale training.</p>",
      "content_html": "<p>arXiv:2601.17858v1 Announce Type: cross  Abstract: Optimizing data mixtures is essential for unlocking the full potential of large language models (LLMs), yet identifying the optimal composition remains computationally prohibitive due to reliance on heuristic trials or expensive proxy training. To address this, we introduce \\textbf{MergeMix}, a novel approach that efficiently determines optimal data mixing ratios by repurposing model merging weights as a high-fidelity, low-cost performance proxy. By training domain-specific experts on minimal tokens and optimizing their merging weights against downstream benchmarks, MergeMix effectively optimizes the performance of data mixtures without incurring the cost of full-scale training. Extensive experiments on models with 8B and 16B parameters validate that MergeMix achieves performance comparable to or surpassing exhaustive manual tuning while drastically reducing search costs. Furthermore, MergeMix exhibits high rank consistency (Spearman $\\rho &gt; 0.9$) and strong cross-scale transferability, offering a scalable, automated solution for data mixture optimization.</p>"
    },
    {
      "id": "85fa963dbed3",
      "title": "GenAI for Social Work Field Education: Client Simulation with Real-Time Feedback",
      "content": "arXiv:2601.18517v1 Announce Type: new  Abstract: Field education is the signature pedagogy of social work, yet providing timely and objective feedback during training is constrained by the availability of instructors and counseling clients. In this paper, we present SWITCH, the Social Work Interactive Training Chatbot. SWITCH integrates realistic client simulation, real-time counseling skill classification, and a Motivational Interviewing (MI) progression system into the training workflow. To model a client, SWITCH uses a cognitively grounded profile comprising static fields (e.g., background, beliefs) and dynamic fields (e.g., emotions, automatic thoughts, openness), allowing the agent's behavior to evolve throughout a session realistically. The skill classification module identifies the counseling skills from the user utterances, and feeds the result to the MI controller that regulates the MI stage transitions. To enhance classification accuracy, we study in-context learning with retrieval over annotated transcripts, and a fine-tuned BERT multi-label classifier. In the experiments, we demonstrated that both BERT-based approach and in-context learning outperforms the baseline with big margin. SWITCH thereby offers a scalable, low-cost, and consistent training workflow that complements field education, and allows supervisors to focus on higher-level mentorship.",
      "url": "http://arxiv.org/abs/2601.18517",
      "author": "James Sungarda, Hongkai Liu, Zilong Zhou, Tien-Hsuan Wu, Johnson Chun-Sing Cheung, Ben Kao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents SWITCH, a social work training chatbot integrating client simulation with cognitively grounded profiles, real-time counseling skill classification, and Motivational Interviewing progression.",
      "importance_score": 59,
      "reasoning": "Well-designed educational AI application with sophisticated multi-component architecture. Useful for professional training.",
      "themes": [
        "Educational AI",
        "Dialogue Systems",
        "Social Work"
      ],
      "continuation": null,
      "summary_html": "<p>Presents SWITCH, a social work training chatbot integrating client simulation with cognitively grounded profiles, real-time counseling skill classification, and Motivational Interviewing progression.</p>",
      "content_html": "<p>arXiv:2601.18517v1 Announce Type: new  Abstract: Field education is the signature pedagogy of social work, yet providing timely and objective feedback during training is constrained by the availability of instructors and counseling clients. In this paper, we present SWITCH, the Social Work Interactive Training Chatbot. SWITCH integrates realistic client simulation, real-time counseling skill classification, and a Motivational Interviewing (MI) progression system into the training workflow. To model a client, SWITCH uses a cognitively grounded profile comprising static fields (e.g., background, beliefs) and dynamic fields (e.g., emotions, automatic thoughts, openness), allowing the agent's behavior to evolve throughout a session realistically. The skill classification module identifies the counseling skills from the user utterances, and feeds the result to the MI controller that regulates the MI stage transitions. To enhance classification accuracy, we study in-context learning with retrieval over annotated transcripts, and a fine-tuned BERT multi-label classifier. In the experiments, we demonstrated that both BERT-based approach and in-context learning outperforms the baseline with big margin. SWITCH thereby offers a scalable, low-cost, and consistent training workflow that complements field education, and allows supervisors to focus on higher-level mentorship.</p>"
    },
    {
      "id": "a383672745b9",
      "title": "Closing the Modality Gap Aligns Group-Wise Semantics",
      "content": "arXiv:2601.18525v1 Announce Type: cross  Abstract: In multimodal learning, CLIP has been recognized as the \\textit{de facto} method for learning a shared latent space across multiple modalities, placing similar representations close to each other and moving them away from dissimilar ones. Although CLIP-based losses effectively align modalities at the semantic level, the resulting latent spaces often remain only partially shared, revealing a structural mismatch known as the modality gap. While the necessity of addressing this phenomenon remains debated, particularly given its limited impact on instance-wise tasks (e.g., retrieval), we prove that its influence is instead strongly pronounced in group-level tasks (e.g., clustering). To support this claim, we introduce a novel method designed to consistently reduce this discrepancy in two-modal settings, with a straightforward extension to the general $n$-modal case. Through our extensive evaluation, we demonstrate our novel insight: while reducing the gap provides only marginal or inconsistent improvements in traditional instance-wise tasks, it significantly enhances group-wise tasks. These findings may reshape our understanding of the modality gap, highlighting its key role in improving performance on tasks requiring semantic grouping.",
      "url": "http://arxiv.org/abs/2601.18525",
      "author": "Eleonora Grassucci, Giordano Cicchetti, Emanuele Frasca, Aurelio Uncini, Danilo Comminiello",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Analyzes and addresses the modality gap in CLIP-like models, showing its pronounced effect on group-level tasks like clustering and proposing method to close this gap.",
      "importance_score": 59,
      "reasoning": "Important analysis of fundamental CLIP limitation with practical implications for multimodal clustering applications.",
      "themes": [
        "Multimodal Learning",
        "CLIP",
        "Representation Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Analyzes and addresses the modality gap in CLIP-like models, showing its pronounced effect on group-level tasks like clustering and proposing method to close this gap.</p>",
      "content_html": "<p>arXiv:2601.18525v1 Announce Type: cross  Abstract: In multimodal learning, CLIP has been recognized as the \\textit{de facto} method for learning a shared latent space across multiple modalities, placing similar representations close to each other and moving them away from dissimilar ones. Although CLIP-based losses effectively align modalities at the semantic level, the resulting latent spaces often remain only partially shared, revealing a structural mismatch known as the modality gap. While the necessity of addressing this phenomenon remains debated, particularly given its limited impact on instance-wise tasks (e.g., retrieval), we prove that its influence is instead strongly pronounced in group-level tasks (e.g., clustering). To support this claim, we introduce a novel method designed to consistently reduce this discrepancy in two-modal settings, with a straightforward extension to the general $n$-modal case. Through our extensive evaluation, we demonstrate our novel insight: while reducing the gap provides only marginal or inconsistent improvements in traditional instance-wise tasks, it significantly enhances group-wise tasks. These findings may reshape our understanding of the modality gap, highlighting its key role in improving performance on tasks requiring semantic grouping.</p>"
    },
    {
      "id": "326590018e2a",
      "title": "DV-VLN: Dual Verification for Reliable LLM-Based Vision-and-Language Navigation",
      "content": "arXiv:2601.18492v1 Announce Type: new  Abstract: Vision-and-Language Navigation (VLN) requires an embodied agent to navigate in a complex 3D environment according to natural language instructions. Recent progress in large language models (LLMs) has enabled language-driven navigation with improved interpretability. However, most LLM-based agents still rely on single-shot action decisions, where the model must choose one option from noisy, textualized multi-perspective observations. Due to local mismatches and imperfect intermediate reasoning, such decisions can easily deviate from the correct path, leading to error accumulation and reduced reliability in unseen environments. In this paper, we propose DV-VLN, a new VLN framework that follows a generate-then-verify paradigm. DV-VLN first performs parameter-efficient in-domain adaptation of an open-source LLaMA-2 backbone to produce a structured navigational chain-of-thought, and then verifies candidate actions with two complementary channels: True-False Verification (TFV) and Masked-Entity Verification (MEV). DV-VLN selects actions by aggregating verification successes across multiple samples, yielding interpretable scores for reranking. Experiments on R2R, RxR (English subset), and REVERIE show that DV-VLN consistently improves over direct prediction and sampling-only baselines, achieving competitive performance among language-only VLN agents and promising results compared with several cross-modal systems.Code is available at https://github.com/PlumJun/DV-VLN.",
      "url": "http://arxiv.org/abs/2601.18492",
      "author": "Zijun Li, Shijie Li, Zhenxi Zhang, Bin Li, Shoujun Zhou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes DV-VLN, a generate-then-verify framework for LLM-based vision-and-language navigation that reduces error accumulation through dual verification.",
      "importance_score": 59,
      "reasoning": "Addresses reliability challenge in LLM-based navigation with practical verification approach.",
      "themes": [
        "Vision-Language Navigation",
        "LLM Reliability",
        "Embodied AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes DV-VLN, a generate-then-verify framework for LLM-based vision-and-language navigation that reduces error accumulation through dual verification.</p>",
      "content_html": "<p>arXiv:2601.18492v1 Announce Type: new  Abstract: Vision-and-Language Navigation (VLN) requires an embodied agent to navigate in a complex 3D environment according to natural language instructions. Recent progress in large language models (LLMs) has enabled language-driven navigation with improved interpretability. However, most LLM-based agents still rely on single-shot action decisions, where the model must choose one option from noisy, textualized multi-perspective observations. Due to local mismatches and imperfect intermediate reasoning, such decisions can easily deviate from the correct path, leading to error accumulation and reduced reliability in unseen environments. In this paper, we propose DV-VLN, a new VLN framework that follows a generate-then-verify paradigm. DV-VLN first performs parameter-efficient in-domain adaptation of an open-source LLaMA-2 backbone to produce a structured navigational chain-of-thought, and then verifies candidate actions with two complementary channels: True-False Verification (TFV) and Masked-Entity Verification (MEV). DV-VLN selects actions by aggregating verification successes across multiple samples, yielding interpretable scores for reranking. Experiments on R2R, RxR (English subset), and REVERIE show that DV-VLN consistently improves over direct prediction and sampling-only baselines, achieving competitive performance among language-only VLN agents and promising results compared with several cross-modal systems.Code is available at https://github.com/PlumJun/DV-VLN.</p>"
    },
    {
      "id": "7f9d823799f4",
      "title": "Implementing Tensor Logic: Unifying Datalog and Neural Reasoning via Tensor Contraction",
      "content": "arXiv:2601.17188v1 Announce Type: new  Abstract: The unification of symbolic reasoning and neural networks remains a central challenge in artificial intelligence. Symbolic systems offer reliability and interpretability but lack scalability, while neural networks provide learning capabilities but sacrifice transparency. Tensor Logic, proposed by Domingos, suggests that logical rules and Einstein summation are mathematically equivalent, offering a principled path toward unification. This paper provides empirical validation of this framework through three experiments. First, we demonstrate the equivalence between recursive Datalog rules and iterative tensor contractions by computing the transitive closure of a biblical genealogy graph containing 1,972 individuals and 1,727 parent-child relationships, converging in 74 iterations to discover 33,945 ancestor relationships. Second, we implement reasoning in embedding space by training a neural network with learnable transformation matrices, demonstrating successful zero-shot compositional inference on held-out queries. Third, we validate the Tensor Logic superposition construction on FB15k-237, a large-scale knowledge graph with 14,541 entities and 237 relations. Using Domingos's relation matrix formulation $R_r = E^\\top A_r E$, we achieve MRR of 0.3068 on standard link prediction and MRR of 0.3346 on a compositional reasoning benchmark where direct edges are removed during training, demonstrating that matrix composition enables multi-hop inference without direct training examples.",
      "url": "http://arxiv.org/abs/2601.17188",
      "author": "Swapn Shah (School of Data Science, University of North Carolina at Charlotte), Wlodek Zadrozny (Department of Computer Science, University of North Carolina at Charlotte)",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Provides empirical validation of Tensor Logic framework showing equivalence between recursive Datalog rules and tensor contractions, demonstrating neuro-symbolic unification on a biblical genealogy graph with 1,972 individuals.",
      "importance_score": 58,
      "reasoning": "Interesting theoretical contribution to neuro-symbolic AI, but empirical validation is on relatively simple domain; advances foundational understanding.",
      "themes": [
        "Neuro-Symbolic AI",
        "Knowledge Representation",
        "Reasoning"
      ],
      "continuation": null,
      "summary_html": "<p>Provides empirical validation of Tensor Logic framework showing equivalence between recursive Datalog rules and tensor contractions, demonstrating neuro-symbolic unification on a biblical genealogy graph with 1,972 individuals.</p>",
      "content_html": "<p>arXiv:2601.17188v1 Announce Type: new  Abstract: The unification of symbolic reasoning and neural networks remains a central challenge in artificial intelligence. Symbolic systems offer reliability and interpretability but lack scalability, while neural networks provide learning capabilities but sacrifice transparency. Tensor Logic, proposed by Domingos, suggests that logical rules and Einstein summation are mathematically equivalent, offering a principled path toward unification. This paper provides empirical validation of this framework through three experiments. First, we demonstrate the equivalence between recursive Datalog rules and iterative tensor contractions by computing the transitive closure of a biblical genealogy graph containing 1,972 individuals and 1,727 parent-child relationships, converging in 74 iterations to discover 33,945 ancestor relationships. Second, we implement reasoning in embedding space by training a neural network with learnable transformation matrices, demonstrating successful zero-shot compositional inference on held-out queries. Third, we validate the Tensor Logic superposition construction on FB15k-237, a large-scale knowledge graph with 14,541 entities and 237 relations. Using Domingos's relation matrix formulation $R_r = E^\\top A_r E$, we achieve MRR of 0.3068 on standard link prediction and MRR of 0.3346 on a compositional reasoning benchmark where direct edges are removed during training, demonstrating that matrix composition enables multi-hop inference without direct training examples.</p>"
    },
    {
      "id": "b682ea014ceb",
      "title": "Sentipolis: Emotion-Aware Agents for Social Simulations",
      "content": "arXiv:2601.18027v1 Announce Type: new  Abstract: LLM agents are increasingly used for social simulation, yet emotion is often treated as a transient cue, causing emotional amnesia and weak long-horizon continuity. We present Sentipolis, a framework for emotionally stateful agents that integrates continuous Pleasure-Arousal-Dominance (PAD) representation, dual-speed emotion dynamics, and emotion--memory coupling. Across thousands of interactions over multiple base models and evaluators, Sentipolis improves emotionally grounded behavior, boosting communication, and emotional continuity. Gains are model-dependent: believability increases for higher-capacity models but can drop for smaller ones, and emotion-awareness can mildly reduce adherence to social norms, reflecting a human-like tension between emotion-driven behavior and rule compliance in social simulation. Network-level diagnostics show reciprocal, moderately clustered, and temporally stable relationship structures, supporting the study of cumulative social dynamics such as alliance formation and gradual relationship change.",
      "url": "http://arxiv.org/abs/2601.18027",
      "author": "Chiyuan Fu, Lyuhao Chen, Yunze Xiao, Weihao Xuan, Carlos Busso, Mona Diab",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces Sentipolis framework for emotionally stateful LLM agents using continuous PAD representation, dual-speed emotion dynamics, and emotion-memory coupling for social simulation.",
      "importance_score": 58,
      "reasoning": "Interesting approach to adding emotional continuity to agents; addresses real limitation of current LLM agents in simulations.",
      "themes": [
        "Social Simulation",
        "Emotion AI",
        "Agentic AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Sentipolis framework for emotionally stateful LLM agents using continuous PAD representation, dual-speed emotion dynamics, and emotion-memory coupling for social simulation.</p>",
      "content_html": "<p>arXiv:2601.18027v1 Announce Type: new  Abstract: LLM agents are increasingly used for social simulation, yet emotion is often treated as a transient cue, causing emotional amnesia and weak long-horizon continuity. We present Sentipolis, a framework for emotionally stateful agents that integrates continuous Pleasure-Arousal-Dominance (PAD) representation, dual-speed emotion dynamics, and emotion--memory coupling. Across thousands of interactions over multiple base models and evaluators, Sentipolis improves emotionally grounded behavior, boosting communication, and emotional continuity. Gains are model-dependent: believability increases for higher-capacity models but can drop for smaller ones, and emotion-awareness can mildly reduce adherence to social norms, reflecting a human-like tension between emotion-driven behavior and rule compliance in social simulation. Network-level diagnostics show reciprocal, moderately clustered, and temporally stable relationship structures, supporting the study of cumulative social dynamics such as alliance formation and gradual relationship change.</p>"
    },
    {
      "id": "d535d24783b1",
      "title": "Think-Augmented Function Calling: Improving LLM Parameter Accuracy Through Embedded Reasoning",
      "content": "arXiv:2601.18282v1 Announce Type: new  Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in function calling for autonomous agents, yet current mechanisms lack explicit reasoning transparency during parameter generation, particularly for complex functions with interdependent parameters. While existing approaches like chain-of-thought prompting operate at the agent level, they fail to provide fine-grained reasoning guidance for individual function parameters. To address these limitations, we propose Think-Augmented Function Calling (TAFC), a novel framework that enhances function calling accuracy through explicit reasoning at both function and parameter levels. Our method introduces a universal \"think\" parameter augmentation that enables models to articulate their decision-making process, with dynamic optimization for parameter descriptions to improve reasoning quality. For complex parameters, TAFC automatically triggers granular reasoning based on complexity scoring, ensuring appropriate justification for critical decisions. Additionally, we propose reasoning-guided optimization to align generated reasoning with human expectations. TAFC requires no architectural modifications to existing LLMs while maintaining full API compatibility. Evaluation on ToolBench across proprietary and open-source models demonstrates significant improvements in parameter generation accuracy and reasoning coherence for multi-parameter functions, while providing enhanced interpretability for debugging AI agent behaviors.",
      "url": "http://arxiv.org/abs/2601.18282",
      "author": "Lei Wei, Jinpeng Ou, Xiao Peng, Bin Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes Think-Augmented Function Calling (TAFC) adding explicit reasoning via universal 'think' parameter augmentation at both function and parameter levels for improved accuracy.",
      "importance_score": 58,
      "reasoning": "Practical improvement to function calling; simple technique with demonstrated benefits.",
      "themes": [
        "Function Calling",
        "Reasoning",
        "Agentic AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Think-Augmented Function Calling (TAFC) adding explicit reasoning via universal 'think' parameter augmentation at both function and parameter levels for improved accuracy.</p>",
      "content_html": "<p>arXiv:2601.18282v1 Announce Type: new  Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in function calling for autonomous agents, yet current mechanisms lack explicit reasoning transparency during parameter generation, particularly for complex functions with interdependent parameters. While existing approaches like chain-of-thought prompting operate at the agent level, they fail to provide fine-grained reasoning guidance for individual function parameters. To address these limitations, we propose Think-Augmented Function Calling (TAFC), a novel framework that enhances function calling accuracy through explicit reasoning at both function and parameter levels. Our method introduces a universal \"think\" parameter augmentation that enables models to articulate their decision-making process, with dynamic optimization for parameter descriptions to improve reasoning quality. For complex parameters, TAFC automatically triggers granular reasoning based on complexity scoring, ensuring appropriate justification for critical decisions. Additionally, we propose reasoning-guided optimization to align generated reasoning with human expectations. TAFC requires no architectural modifications to existing LLMs while maintaining full API compatibility. Evaluation on ToolBench across proprietary and open-source models demonstrates significant improvements in parameter generation accuracy and reasoning coherence for multi-parameter functions, while providing enhanced interpretability for debugging AI agent behaviors.</p>"
    },
    {
      "id": "351523e3debe",
      "title": "Interpretable and Sparse Linear Attention with Decoupled Membership-Subspace Modeling via MCR2 Objective",
      "content": "arXiv:2601.17042v1 Announce Type: cross  Abstract: Maximal Coding Rate Reduction (MCR2)-driven white-box transformer, grounded in structured representation learning, unifies interpretability and efficiency, providing a reliable white-box solution for visual modeling. However, in existing designs, tight coupling between \"membership matrix\" and \"subspace matrix U\" in MCR2 causes redundant coding under incorrect token projection. To this end, we decouple the functional relationship between the \"membership matrix\" and \"subspaces U\" in the MCR2 objective and derive an interpretable sparse linear attention operator from unrolled gradient descent of the optimized objective. Specifically, we propose to directly learn the membership matrix from inputs and subsequently derive sparse subspaces from the fullspace S. Consequently, gradient unrolling of the optimized MCR2 objective yields an interpretable sparse linear attention operator: Decoupled Membership-Subspace Attention (DMSA). Experimental results on visual tasks show that simply replacing the attention module in Token Statistics Transformer (ToST) with DMSA (we refer to as DMST) not only achieves a faster coding reduction rate but also outperforms ToST by 1.08%-1.45% in top-1 accuracy on the ImageNet-1K dataset. Compared with vanilla Transformer architectures, DMST exhibits significantly higher computational efficiency and interpretability.",
      "url": "http://arxiv.org/abs/2601.17042",
      "author": "Tianyuan Liu, Libin Hou, Linyuan Wang, Bin Yan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Decouples membership and subspace matrices in MCR2 objective to derive interpretable sparse linear attention. Proposes directly learning membership matrices for improved white-box transformers.",
      "importance_score": 58,
      "reasoning": "Technical contribution to interpretable attention mechanisms. Addresses structural issues in MCR2-based transformers but narrow scope.",
      "themes": [
        "Interpretability",
        "Attention Mechanisms",
        "Transformer Architecture"
      ],
      "continuation": null,
      "summary_html": "<p>Decouples membership and subspace matrices in MCR2 objective to derive interpretable sparse linear attention. Proposes directly learning membership matrices for improved white-box transformers.</p>",
      "content_html": "<p>arXiv:2601.17042v1 Announce Type: cross  Abstract: Maximal Coding Rate Reduction (MCR2)-driven white-box transformer, grounded in structured representation learning, unifies interpretability and efficiency, providing a reliable white-box solution for visual modeling. However, in existing designs, tight coupling between \"membership matrix\" and \"subspace matrix U\" in MCR2 causes redundant coding under incorrect token projection. To this end, we decouple the functional relationship between the \"membership matrix\" and \"subspaces U\" in the MCR2 objective and derive an interpretable sparse linear attention operator from unrolled gradient descent of the optimized objective. Specifically, we propose to directly learn the membership matrix from inputs and subsequently derive sparse subspaces from the fullspace S. Consequently, gradient unrolling of the optimized MCR2 objective yields an interpretable sparse linear attention operator: Decoupled Membership-Subspace Attention (DMSA). Experimental results on visual tasks show that simply replacing the attention module in Token Statistics Transformer (ToST) with DMSA (we refer to as DMST) not only achieves a faster coding reduction rate but also outperforms ToST by 1.08%-1.45% in top-1 accuracy on the ImageNet-1K dataset. Compared with vanilla Transformer architectures, DMST exhibits significantly higher computational efficiency and interpretability.</p>"
    },
    {
      "id": "93e1b42982e5",
      "title": "A Mechanistic View on Video Generation as World Models: State and Dynamics",
      "content": "arXiv:2601.17067v1 Announce Type: cross  Abstract: Large-scale video generation models have demonstrated emergent physical coherence, positioning them as potential world models. However, a gap remains between contemporary \"stateless\" video architectures and classic state-centric world model theories. This work bridges this gap by proposing a novel taxonomy centered on two pillars: State Construction and Dynamics Modeling. We categorize state construction into implicit paradigms (context management) and explicit paradigms (latent compression), while dynamics modeling is analyzed through knowledge integration and architectural reformulation. Furthermore, we advocate for a transition in evaluation from visual fidelity to functional benchmarks, testing physical persistence and causal reasoning. We conclude by identifying two critical frontiers: enhancing persistence via data-driven memory and compressed fidelity, and advancing causality through latent factor decoupling and reasoning-prior integration. By addressing these challenges, the field can evolve from generating visually plausible videos to building robust, general-purpose world simulators.",
      "url": "http://arxiv.org/abs/2601.17067",
      "author": "Luozhou Wang, Zhifei Chen, Yihua Du, Dongyu Yan, Wenhang Ge, Guibao Shen, Xinli Xu, Leyi Wu, Man Chen, Tianshuo Xu, Peiran Ren, Xin Tao, Pengfei Wan, Ying-Cong Chen",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes taxonomy for understanding video generation models as world models, distinguishing between state construction (implicit/explicit) and dynamics modeling approaches.",
      "importance_score": 58,
      "reasoning": "Useful theoretical framework connecting video generation to world model theory. Provides conceptual organization for emerging field.",
      "themes": [
        "Video Generation",
        "World Models",
        "Taxonomy"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes taxonomy for understanding video generation models as world models, distinguishing between state construction (implicit/explicit) and dynamics modeling approaches.</p>",
      "content_html": "<p>arXiv:2601.17067v1 Announce Type: cross  Abstract: Large-scale video generation models have demonstrated emergent physical coherence, positioning them as potential world models. However, a gap remains between contemporary \"stateless\" video architectures and classic state-centric world model theories. This work bridges this gap by proposing a novel taxonomy centered on two pillars: State Construction and Dynamics Modeling. We categorize state construction into implicit paradigms (context management) and explicit paradigms (latent compression), while dynamics modeling is analyzed through knowledge integration and architectural reformulation. Furthermore, we advocate for a transition in evaluation from visual fidelity to functional benchmarks, testing physical persistence and causal reasoning. We conclude by identifying two critical frontiers: enhancing persistence via data-driven memory and compressed fidelity, and advancing causality through latent factor decoupling and reasoning-prior integration. By addressing these challenges, the field can evolve from generating visually plausible videos to building robust, general-purpose world simulators.</p>"
    },
    {
      "id": "9404768ffc64",
      "title": "Beyond Instrumental and Substitutive Paradigms: Introducing Machine Culture as an Emergent Phenomenon in Large Language Models",
      "content": "arXiv:2601.17096v1 Announce Type: cross  Abstract: Recent scholarship typically characterizes Large Language Models (LLMs) through either an \\textit{Instrumental Paradigm} (viewing models as reflections of their developers' culture) or a \\textit{Substitutive Paradigm} (viewing models as bilingual proxies that switch cultural frames based on language). This study challenges these anthropomorphic frameworks by proposing \\textbf{Machine Culture} as an emergent, distinct phenomenon. We employed a 2 (Model Origin: US vs. China) $\\times$ 2 (Prompt Language: English vs. Chinese) factorial design across eight multimodal tasks, uniquely incorporating image generation and interpretation to extend analysis beyond textual boundaries. Results revealed inconsistencies with both dominant paradigms: Model origin did not predict cultural alignment, with US models frequently exhibiting ``holistic'' traits typically associated with East Asian data. Similarly, prompt language did not trigger stable cultural frame-switching; instead, we observed \\textbf{Cultural Reversal}, where English prompts paradoxically elicited higher contextual attention than Chinese prompts. Crucially, we identified a novel phenomenon termed \\textbf{Service Persona Camouflage}: Reinforcement Learning from Human Feedback (RLHF) collapsed cultural variance in affective tasks into a hyper-positive, zero-variance ``helpful assistant'' persona. We conclude that LLMs do not simulate human culture but exhibit an emergent Machine Culture -- a probabilistic phenomenon shaped by \\textit{superposition} in high-dimensional space and \\textit{mode collapse} from safety alignment.",
      "url": "http://arxiv.org/abs/2601.17096",
      "author": "Yueqing Hu, Xinyang Peng, Yukun Zhao, Lin Qiu, Ka-lai Hung, Kaiping Peng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Challenges instrumental and substitutive paradigms for understanding LLMs, proposing Machine Culture as emergent phenomenon. 2x2 factorial design across 8 multimodal tasks.",
      "importance_score": 58,
      "reasoning": "Interesting conceptual contribution challenging dominant frameworks. Multi-task empirical evidence but provocative claims need further validation.",
      "themes": [
        "LLM Culture",
        "Multimodal AI",
        "Conceptual Frameworks"
      ],
      "continuation": null,
      "summary_html": "<p>Challenges instrumental and substitutive paradigms for understanding LLMs, proposing Machine Culture as emergent phenomenon. 2x2 factorial design across 8 multimodal tasks.</p>",
      "content_html": "<p>arXiv:2601.17096v1 Announce Type: cross  Abstract: Recent scholarship typically characterizes Large Language Models (LLMs) through either an \\textit{Instrumental Paradigm} (viewing models as reflections of their developers' culture) or a \\textit{Substitutive Paradigm} (viewing models as bilingual proxies that switch cultural frames based on language). This study challenges these anthropomorphic frameworks by proposing \\textbf{Machine Culture} as an emergent, distinct phenomenon. We employed a 2 (Model Origin: US vs. China) $\\times$ 2 (Prompt Language: English vs. Chinese) factorial design across eight multimodal tasks, uniquely incorporating image generation and interpretation to extend analysis beyond textual boundaries. Results revealed inconsistencies with both dominant paradigms: Model origin did not predict cultural alignment, with US models frequently exhibiting ``holistic'' traits typically associated with East Asian data. Similarly, prompt language did not trigger stable cultural frame-switching; instead, we observed \\textbf{Cultural Reversal}, where English prompts paradoxically elicited higher contextual attention than Chinese prompts. Crucially, we identified a novel phenomenon termed \\textbf{Service Persona Camouflage}: Reinforcement Learning from Human Feedback (RLHF) collapsed cultural variance in affective tasks into a hyper-positive, zero-variance ``helpful assistant'' persona. We conclude that LLMs do not simulate human culture but exhibit an emergent Machine Culture -- a probabilistic phenomenon shaped by \\textit{superposition} in high-dimensional space and \\textit{mode collapse} from safety alignment.</p>"
    },
    {
      "id": "7da3b448319a",
      "title": "Learning to Collaborate: An Orchestrated-Decentralized Framework for Peer-to-Peer LLM Federation",
      "content": "arXiv:2601.17133v1 Announce Type: cross  Abstract: Fine-tuning Large Language Models (LLMs) for specialized domains is constrained by a fundamental challenge: the need for diverse, cross-organizational data conflicts with the principles of data privacy and sovereignty. While Federated Learning (FL) provides a framework for collaboration without raw data exchange, its classic centralized form introduces a single point of failure and remains vulnerable to model inversion attacks. Decentralized FL (DFL) mitigates this risk by removing the central aggregator but typically relies on inefficient, random peer-to-peer (P2P) pairings, forming a collaboration graph that is blind to agent heterogeneity and risks negative transfer. This paper introduces KNEXA-FL, a novel framework for orchestrated decentralization that resolves this trade-off. KNEXA-FL employs a non-aggregating Central Profiler/Matchmaker (CPM) that formulates P2P collaboration as a contextual bandit problem, using a LinUCB algorithm on abstract agent profiles to learn an optimal matchmaking policy. It orchestrates direct knowledge exchange between heterogeneous, PEFT-based LLM agents via secure distillation, without ever accessing the models themselves. Our comprehensive experiments on a challenging code generation task show that KNEXA-FL yields substantial gains, improving Pass@1 by approx. 50% relative to random P2P collaboration. Critically, our orchestrated approach demonstrates stable convergence, in stark contrast to a powerful centralized distillation baseline which suffers from catastrophic performance collapse. Our work establishes adaptive, learning-based orchestration as a foundational principle for building robust and effective decentralized AI ecosystems.",
      "url": "http://arxiv.org/abs/2601.17133",
      "author": "Inderjeet Singh, Eleonore Vissol-Gaudin, Andikan Otung, Motoyoshi Sekiya",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces KNEXA-FL for orchestrated decentralized federated learning of LLMs, addressing peer selection for avoiding negative transfer while maintaining privacy and data sovereignty.",
      "importance_score": 58,
      "reasoning": "Novel framework combining decentralized FL with intelligent peer selection. Addresses practical challenges in collaborative LLM training.",
      "themes": [
        "Federated Learning",
        "LLM Training",
        "Privacy"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces KNEXA-FL for orchestrated decentralized federated learning of LLMs, addressing peer selection for avoiding negative transfer while maintaining privacy and data sovereignty.</p>",
      "content_html": "<p>arXiv:2601.17133v1 Announce Type: cross  Abstract: Fine-tuning Large Language Models (LLMs) for specialized domains is constrained by a fundamental challenge: the need for diverse, cross-organizational data conflicts with the principles of data privacy and sovereignty. While Federated Learning (FL) provides a framework for collaboration without raw data exchange, its classic centralized form introduces a single point of failure and remains vulnerable to model inversion attacks. Decentralized FL (DFL) mitigates this risk by removing the central aggregator but typically relies on inefficient, random peer-to-peer (P2P) pairings, forming a collaboration graph that is blind to agent heterogeneity and risks negative transfer. This paper introduces KNEXA-FL, a novel framework for orchestrated decentralization that resolves this trade-off. KNEXA-FL employs a non-aggregating Central Profiler/Matchmaker (CPM) that formulates P2P collaboration as a contextual bandit problem, using a LinUCB algorithm on abstract agent profiles to learn an optimal matchmaking policy. It orchestrates direct knowledge exchange between heterogeneous, PEFT-based LLM agents via secure distillation, without ever accessing the models themselves. Our comprehensive experiments on a challenging code generation task show that KNEXA-FL yields substantial gains, improving Pass@1 by approx. 50% relative to random P2P collaboration. Critically, our orchestrated approach demonstrates stable convergence, in stark contrast to a powerful centralized distillation baseline which suffers from catastrophic performance collapse. Our work establishes adaptive, learning-based orchestration as a foundational principle for building robust and effective decentralized AI ecosystems.</p>"
    },
    {
      "id": "5ad91530779b",
      "title": "Data-Driven Information-Theoretic Causal Bounds under Unmeasured Confounding",
      "content": "arXiv:2601.17160v1 Announce Type: cross  Abstract: We develop a data-driven information-theoretic framework for sharp partial identification of causal effects under unmeasured confounding. Existing approaches often rely on restrictive assumptions, such as bounded or discrete outcomes; require external inputs (for example, instrumental variables, proxies, or user-specified sensitivity parameters); necessitate full structural causal model specifications; or focus solely on population-level averages while neglecting covariate-conditional treatment effects. We overcome all four limitations simultaneously by establishing novel information-theoretic, data-driven divergence bounds. Our key theoretical contribution shows that the f-divergence between the observational distribution P(Y | A = a, X = x) and the interventional distribution P(Y | do(A = a), X = x) is upper bounded by a function of the propensity score alone. This result enables sharp partial identification of conditional causal effects directly from observational data, without requiring external sensitivity parameters, auxiliary variables, full structural specifications, or outcome boundedness assumptions. For practical implementation, we develop a semiparametric estimator satisfying Neyman orthogonality (Chernozhukov et al., 2018), which ensures square-root-n consistent inference even when nuisance functions are estimated using flexible machine learning methods. Simulation studies and real-world data applications, implemented in the GitHub repository (https://github.com/yonghanjung/Information-Theretic-Bounds), demonstrate that our framework provides tight and valid causal bounds across a wide range of data-generating processes.",
      "url": "http://arxiv.org/abs/2601.17160",
      "author": "Yonghan Jung, Bogyeong Kang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "stat.ML"
      ],
      "summary": "Develops data-driven information-theoretic framework for causal effect bounds under unmeasured confounding. Overcomes limitations of existing approaches without requiring external inputs.",
      "importance_score": 58,
      "reasoning": "Technical contribution to causal inference methodology. Addresses multiple limitations simultaneously but theoretical complexity may limit adoption.",
      "themes": [
        "Causal Inference",
        "Information Theory",
        "Methodology"
      ],
      "continuation": null,
      "summary_html": "<p>Develops data-driven information-theoretic framework for causal effect bounds under unmeasured confounding. Overcomes limitations of existing approaches without requiring external inputs.</p>",
      "content_html": "<p>arXiv:2601.17160v1 Announce Type: cross  Abstract: We develop a data-driven information-theoretic framework for sharp partial identification of causal effects under unmeasured confounding. Existing approaches often rely on restrictive assumptions, such as bounded or discrete outcomes; require external inputs (for example, instrumental variables, proxies, or user-specified sensitivity parameters); necessitate full structural causal model specifications; or focus solely on population-level averages while neglecting covariate-conditional treatment effects. We overcome all four limitations simultaneously by establishing novel information-theoretic, data-driven divergence bounds. Our key theoretical contribution shows that the f-divergence between the observational distribution P(Y | A = a, X = x) and the interventional distribution P(Y | do(A = a), X = x) is upper bounded by a function of the propensity score alone. This result enables sharp partial identification of conditional causal effects directly from observational data, without requiring external sensitivity parameters, auxiliary variables, full structural specifications, or outcome boundedness assumptions. For practical implementation, we develop a semiparametric estimator satisfying Neyman orthogonality (Chernozhukov et al., 2018), which ensures square-root-n consistent inference even when nuisance functions are estimated using flexible machine learning methods. Simulation studies and real-world data applications, implemented in the GitHub repository (https://github.com/yonghanjung/Information-Theretic-Bounds), demonstrate that our framework provides tight and valid causal bounds across a wide range of data-generating processes.</p>"
    },
    {
      "id": "a2183d629740",
      "title": "Addressing LLM Diversity by Infusing Random Concepts",
      "content": "arXiv:2601.18053v1 Announce Type: cross  Abstract: Large language models (LLMs) are known to produce outputs with limited diversity. In this work, we study whether infusing random concepts in the prompts can improve the diversity of the generated outputs. To benchmark the approach, we design a systematic evaluation protocol which involves prompting an LLM with questions of the form \"Name 10 Hollywood actors\", and analyzing diversity measures of the resulting LLM outputs. Our experiments on multiple LLMs show that prepending random words/sentences unrelated to the prompt result in greater diversity in the outputs of LLMs. We believe that this promising result and the evaluation protocol opens up interesting avenues for future work, such as how infusing randomness into LLMs could be applied to other domains. Further, the evaluation protocol could also inspire research into benchmarking LLM diversity more systematically.",
      "url": "http://arxiv.org/abs/2601.18053",
      "author": "Pulin Agrawal, Prasoon Goyal",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Demonstrates that prepending random words/sentences unrelated to prompts increases diversity in LLM outputs, with systematic evaluation protocol using diversity metrics.",
      "importance_score": 58,
      "reasoning": "Simple but interesting finding. Systematic evaluation protocol is contribution. Opens research directions for diversity improvement.",
      "themes": [
        "LLM Diversity",
        "Prompt Engineering",
        "Evaluation"
      ],
      "continuation": null,
      "summary_html": "<p>Demonstrates that prepending random words/sentences unrelated to prompts increases diversity in LLM outputs, with systematic evaluation protocol using diversity metrics.</p>",
      "content_html": "<p>arXiv:2601.18053v1 Announce Type: cross  Abstract: Large language models (LLMs) are known to produce outputs with limited diversity. In this work, we study whether infusing random concepts in the prompts can improve the diversity of the generated outputs. To benchmark the approach, we design a systematic evaluation protocol which involves prompting an LLM with questions of the form \"Name 10 Hollywood actors\", and analyzing diversity measures of the resulting LLM outputs. Our experiments on multiple LLMs show that prepending random words/sentences unrelated to the prompt result in greater diversity in the outputs of LLMs. We believe that this promising result and the evaluation protocol opens up interesting avenues for future work, such as how infusing randomness into LLMs could be applied to other domains. Further, the evaluation protocol could also inspire research into benchmarking LLM diversity more systematically.</p>"
    },
    {
      "id": "acd8743e1fdb",
      "title": "Mitigating the OWASP Top 10 For Large Language Models Applications using Intelligent Agents",
      "content": "arXiv:2601.18105v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have emerged as a transformative and disruptive technology, enabling a wide range of applications in natural language processing, machine translation, and beyond. However, this widespread integration of LLMs also raised several security concerns highlighted by the Open Web Application Security Project (OWASP), which has identified the top 10 security vulnerabilities inherent in LLM applications. Addressing these vulnerabilities is crucial, given the increasing reliance on LLMs and the potential threats to data integrity, confidentiality, and service availability. This paper presents a framework designed to mitigate the security risks outlined in the OWASP Top 10. Our proposed model leverages LLM-enabled intelligent agents, offering a new approach to proactively identify, assess, and counteract security threats in real-time. The proposed framework serves as an initial blueprint for future research and development, aiming to enhance the security measures of LLMs and protect against emerging threats in this rapidly evolving landscape.",
      "url": "http://arxiv.org/abs/2601.18105",
      "author": "Mohammad Fasha, Faisal Abul Rub, Nasim Matar, Bilal Sowan, Mohammad Al Khaldy",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Presents framework using LLM-enabled intelligent agents to mitigate OWASP Top 10 security vulnerabilities in LLM applications. Addresses risks to data integrity, confidentiality, and service availability.",
      "importance_score": 58,
      "reasoning": "Practical security framework addressing documented LLM vulnerabilities. Useful for practitioners but appears to be application-level mitigation rather than fundamental research.",
      "themes": [
        "LLM Security",
        "AI Safety",
        "Cybersecurity"
      ],
      "continuation": null,
      "summary_html": "<p>Presents framework using LLM-enabled intelligent agents to mitigate OWASP Top 10 security vulnerabilities in LLM applications. Addresses risks to data integrity, confidentiality, and service availability.</p>",
      "content_html": "<p>arXiv:2601.18105v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have emerged as a transformative and disruptive technology, enabling a wide range of applications in natural language processing, machine translation, and beyond. However, this widespread integration of LLMs also raised several security concerns highlighted by the Open Web Application Security Project (OWASP), which has identified the top 10 security vulnerabilities inherent in LLM applications. Addressing these vulnerabilities is crucial, given the increasing reliance on LLMs and the potential threats to data integrity, confidentiality, and service availability. This paper presents a framework designed to mitigate the security risks outlined in the OWASP Top 10. Our proposed model leverages LLM-enabled intelligent agents, offering a new approach to proactively identify, assess, and counteract security threats in real-time. The proposed framework serves as an initial blueprint for future research and development, aiming to enhance the security measures of LLMs and protect against emerging threats in this rapidly evolving landscape.</p>"
    },
    {
      "id": "0f76d5b30036",
      "title": "Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models",
      "content": "arXiv:2601.18129v1 Announce Type: cross  Abstract: Large language models (LLMs) have progressed rapidly; however, most state-of-the-art models are trained and evaluated primarily in high-resource languages such as English and Chinese, and are often developed by a small number of organizations with access to large-scale compute and data. This gatekeeping creates a practical barrier for sovereign settings in which a regional- or national-scale institution or domain owner must retain control and understanding of model weights, training data, and deployment while operating under limited resources and strict transparency constraints. To this end, we identify two core requirements: (1) adoptability, the ability to transform a base model into a general-purpose assistant, and (2) sovereign capability, the ability to perform high-stakes, region-specific tasks (e.g., legal reasoning in local languages and cultural knowledge). We investigate whether these requirements can be achieved without scaling massive instruction corpora or relying on complex preference tuning pipelines and large-scale reinforcement fine-tuning (RFT). We present Typhoon S, a minimal and open post-training recipe that combines supervised fine-tuning, on-policy distillation, and small-scale RFT. Using Thai as a representative case study, we demonstrate that our approach transforms both sovereign-adapted and general-purpose base models into instruction-tuned models with strong general performance. We further show that small-scale RFT with InK-GRPO -- an extension of GRPO that augments the GRPO loss with a next-word prediction loss -- improves Thai legal reasoning and Thai-specific knowledge while preserving general capabilities. Our results suggest that a carefully designed post-training strategy can reduce the required scale of instruction data and computation, providing a practical path toward high-quality sovereign LLMs under academic-scale resources.",
      "url": "http://arxiv.org/abs/2601.18129",
      "author": "Kunat Pipatanakul, Pittawat Taveekitworachai",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces Typhoon-S framework for creating sovereign LLMs with minimal post-training resources, addressing needs of regional institutions with limited compute who require control over model weights and training data.",
      "importance_score": 58,
      "reasoning": "Addresses important accessibility and sovereignty concerns for non-Western institutions. Practical contribution but methodology details limited in abstract.",
      "themes": [
        "Language Models",
        "Accessibility",
        "Model Adaptation",
        "Low-Resource AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Typhoon-S framework for creating sovereign LLMs with minimal post-training resources, addressing needs of regional institutions with limited compute who require control over model weights and training data.</p>",
      "content_html": "<p>arXiv:2601.18129v1 Announce Type: cross  Abstract: Large language models (LLMs) have progressed rapidly; however, most state-of-the-art models are trained and evaluated primarily in high-resource languages such as English and Chinese, and are often developed by a small number of organizations with access to large-scale compute and data. This gatekeeping creates a practical barrier for sovereign settings in which a regional- or national-scale institution or domain owner must retain control and understanding of model weights, training data, and deployment while operating under limited resources and strict transparency constraints. To this end, we identify two core requirements: (1) adoptability, the ability to transform a base model into a general-purpose assistant, and (2) sovereign capability, the ability to perform high-stakes, region-specific tasks (e.g., legal reasoning in local languages and cultural knowledge). We investigate whether these requirements can be achieved without scaling massive instruction corpora or relying on complex preference tuning pipelines and large-scale reinforcement fine-tuning (RFT). We present Typhoon S, a minimal and open post-training recipe that combines supervised fine-tuning, on-policy distillation, and small-scale RFT. Using Thai as a representative case study, we demonstrate that our approach transforms both sovereign-adapted and general-purpose base models into instruction-tuned models with strong general performance. We further show that small-scale RFT with InK-GRPO -- an extension of GRPO that augments the GRPO loss with a next-word prediction loss -- improves Thai legal reasoning and Thai-specific knowledge while preserving general capabilities. Our results suggest that a carefully designed post-training strategy can reduce the required scale of instruction data and computation, providing a practical path toward high-quality sovereign LLMs under academic-scale resources.</p>"
    },
    {
      "id": "aad7e1f4fd56",
      "title": "A multimodal vision foundation model for generalizable knee pathology",
      "content": "arXiv:2601.18250v1 Announce Type: cross  Abstract: Musculoskeletal disorders represent a leading cause of global disability, creating an urgent demand for precise interpretation of medical imaging. Current artificial intelligence (AI) approaches in orthopedics predominantly rely on task-specific, supervised learning paradigms. These methods are inherently fragmented, require extensive annotated datasets, and often lack generalizability across different modalities and clinical scenarios. The development of foundation models in this field has been constrained by the scarcity of large-scale, curated, and open-source musculoskeletal datasets. To address these challenges, we introduce OrthoFoundation, a multimodal vision foundation model optimized for musculoskeletal pathology. We constructed a pre-training dataset of 1.2 million unlabeled knee X-ray and MRI images from internal and public databases. Utilizing a Dinov3 backbone, the model was trained via self-supervised contrastive learning to capture robust radiological representations. OrthoFoundation achieves state-of-the-art (SOTA) performance across 14 downstream tasks. It attained superior accuracy in X-ray osteoarthritis diagnosis and ranked first in MRI structural injury detection. The model demonstrated remarkable label efficiency, matching supervised baselines using only 50% of labeled data. Furthermore, despite being pre-trained on knee images, OrthoFoundation exhibited exceptional cross-anatomy generalization to the hip, shoulder, and ankle. OrthoFoundation represents a significant advancement toward general-purpose AI for musculoskeletal imaging. By learning fundamental, joint-agnostic radiological semantics from large-scale multimodal data, it overcomes the limitations of conventional models, which provides a robust framework for reducing annotation burdens and enhancing diagnostic accuracy in clinical practice.",
      "url": "http://arxiv.org/abs/2601.18250",
      "author": "Kang Yu, Dingyu Wang, Zimu Yuan, Nan Zhou, Jiajun Liu, Jiaxin Liu, Shanggui Liu, Yaoyan Zheng, Huishu Yuan, Di Huang, Dong Jiang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces OrthoFoundation, multimodal vision foundation model for musculoskeletal pathology trained on large-scale curated dataset. Addresses fragmentation of task-specific approaches in orthopedic AI.",
      "importance_score": 58,
      "reasoning": "Foundation model approach for underserved medical domain. Addresses data scarcity issue. Impact depends on dataset size and model performance not detailed in abstract.",
      "themes": [
        "Medical AI",
        "Foundation Models",
        "Musculoskeletal Imaging"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces OrthoFoundation, multimodal vision foundation model for musculoskeletal pathology trained on large-scale curated dataset. Addresses fragmentation of task-specific approaches in orthopedic AI.</p>",
      "content_html": "<p>arXiv:2601.18250v1 Announce Type: cross  Abstract: Musculoskeletal disorders represent a leading cause of global disability, creating an urgent demand for precise interpretation of medical imaging. Current artificial intelligence (AI) approaches in orthopedics predominantly rely on task-specific, supervised learning paradigms. These methods are inherently fragmented, require extensive annotated datasets, and often lack generalizability across different modalities and clinical scenarios. The development of foundation models in this field has been constrained by the scarcity of large-scale, curated, and open-source musculoskeletal datasets. To address these challenges, we introduce OrthoFoundation, a multimodal vision foundation model optimized for musculoskeletal pathology. We constructed a pre-training dataset of 1.2 million unlabeled knee X-ray and MRI images from internal and public databases. Utilizing a Dinov3 backbone, the model was trained via self-supervised contrastive learning to capture robust radiological representations. OrthoFoundation achieves state-of-the-art (SOTA) performance across 14 downstream tasks. It attained superior accuracy in X-ray osteoarthritis diagnosis and ranked first in MRI structural injury detection. The model demonstrated remarkable label efficiency, matching supervised baselines using only 50% of labeled data. Furthermore, despite being pre-trained on knee images, OrthoFoundation exhibited exceptional cross-anatomy generalization to the hip, shoulder, and ankle. OrthoFoundation represents a significant advancement toward general-purpose AI for musculoskeletal imaging. By learning fundamental, joint-agnostic radiological semantics from large-scale multimodal data, it overcomes the limitations of conventional models, which provides a robust framework for reducing annotation burdens and enhancing diagnostic accuracy in clinical practice.</p>"
    },
    {
      "id": "8e2a9081a804",
      "title": "ART for Diffusion Sampling: A Reinforcement Learning Approach to Timestep Schedule",
      "content": "arXiv:2601.18681v1 Announce Type: cross  Abstract: We consider time discretization for score-based diffusion models to generate samples from a learned reverse-time dynamic on a finite grid. Uniform and hand-crafted grids can be suboptimal given a budget on the number of time steps. We introduce Adaptive Reparameterized Time (ART) that controls the clock speed of a reparameterized time variable, leading to a time change and uneven timesteps along the sampling trajectory while preserving the terminal time. The objective is to minimize the aggregate error arising from the discretized Euler scheme. We derive a randomized control companion, ART-RL, and formulate time change as a continuous-time reinforcement learning (RL) problem with Gaussian policies. We then prove that solving ART-RL recovers the optimal ART schedule, which in turn enables practical actor--critic updates to learn the latter in a data-driven way. Empirically, based on the official EDM pipeline, ART-RL improves Fr\\'echet Inception Distance on CIFAR-10 over a wide range of budgets and transfers to AFHQv2, FFHQ, and ImageNet without the need of retraining.",
      "url": "http://arxiv.org/abs/2601.18681",
      "author": "Yilie Huang, Wenpin Tang, Xunyu Zhou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces ART (Adaptive Reparameterized Time) for diffusion sampling, formulating timestep scheduling as continuous-time RL problem. Proves recovering optimal solution for minimal discretization error.",
      "importance_score": 58,
      "reasoning": "Novel RL formulation for diffusion sampling optimization. Theoretical contribution with practical relevance for diffusion model efficiency.",
      "themes": [
        "Diffusion Models",
        "Reinforcement Learning",
        "Sampling Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces ART (Adaptive Reparameterized Time) for diffusion sampling, formulating timestep scheduling as continuous-time RL problem. Proves recovering optimal solution for minimal discretization error.</p>",
      "content_html": "<p>arXiv:2601.18681v1 Announce Type: cross  Abstract: We consider time discretization for score-based diffusion models to generate samples from a learned reverse-time dynamic on a finite grid. Uniform and hand-crafted grids can be suboptimal given a budget on the number of time steps. We introduce Adaptive Reparameterized Time (ART) that controls the clock speed of a reparameterized time variable, leading to a time change and uneven timesteps along the sampling trajectory while preserving the terminal time. The objective is to minimize the aggregate error arising from the discretized Euler scheme. We derive a randomized control companion, ART-RL, and formulate time change as a continuous-time reinforcement learning (RL) problem with Gaussian policies. We then prove that solving ART-RL recovers the optimal ART schedule, which in turn enables practical actor--critic updates to learn the latter in a data-driven way. Empirically, based on the official EDM pipeline, ART-RL improves Fr\\'echet Inception Distance on CIFAR-10 over a wide range of budgets and transfers to AFHQv2, FFHQ, and ImageNet without the need of retraining.</p>"
    },
    {
      "id": "7448b9626119",
      "title": "SMART: Scalable Mesh-free Aerodynamic Simulations from Raw Geometries using a Transformer-based Surrogate Model",
      "content": "arXiv:2601.18707v1 Announce Type: cross  Abstract: Machine learning-based surrogate models have emerged as more efficient alternatives to numerical solvers for physical simulations over complex geometries, such as car bodies. Many existing models incorporate the simulation mesh as an additional input, thereby reducing prediction errors. However, generating a simulation mesh for new geometries is computationally costly. In contrast, mesh-free methods, which do not rely on the simulation mesh, typically incur higher errors. Motivated by these considerations, we introduce SMART, a neural surrogate model that predicts physical quantities at arbitrary query locations using only a point-cloud representation of the geometry, without requiring access to the simulation mesh. The geometry and simulation parameters are encoded into a shared latent space that captures both structural and parametric characteristics of the physical field. A physics decoder then attends to the encoder's intermediate latent representations to map spatial queries to physical quantities. Through this cross-layer interaction, the model jointly updates latent geometric features and the evolving physical field. Extensive experiments show that SMART is competitive with and often outperforms existing methods that rely on the simulation mesh as input, demonstrating its capabilities for industry-level simulations.",
      "url": "http://arxiv.org/abs/2601.18707",
      "author": "Jan Hagnberger, Mathias Niepert",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces SMART, transformer-based mesh-free surrogate model for aerodynamic simulations from point-cloud geometry representations, avoiding expensive simulation mesh generation for new geometries.",
      "importance_score": 58,
      "reasoning": "Practical contribution for engineering simulations. Addresses real bottleneck (mesh generation cost) but specialized application.",
      "themes": [
        "Scientific ML",
        "Aerodynamics",
        "Surrogate Modeling"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces SMART, transformer-based mesh-free surrogate model for aerodynamic simulations from point-cloud geometry representations, avoiding expensive simulation mesh generation for new geometries.</p>",
      "content_html": "<p>arXiv:2601.18707v1 Announce Type: cross  Abstract: Machine learning-based surrogate models have emerged as more efficient alternatives to numerical solvers for physical simulations over complex geometries, such as car bodies. Many existing models incorporate the simulation mesh as an additional input, thereby reducing prediction errors. However, generating a simulation mesh for new geometries is computationally costly. In contrast, mesh-free methods, which do not rely on the simulation mesh, typically incur higher errors. Motivated by these considerations, we introduce SMART, a neural surrogate model that predicts physical quantities at arbitrary query locations using only a point-cloud representation of the geometry, without requiring access to the simulation mesh. The geometry and simulation parameters are encoded into a shared latent space that captures both structural and parametric characteristics of the physical field. A physics decoder then attends to the encoder's intermediate latent representations to map spatial queries to physical quantities. Through this cross-layer interaction, the model jointly updates latent geometric features and the evolving physical field. Extensive experiments show that SMART is competitive with and often outperforms existing methods that rely on the simulation mesh as input, demonstrating its capabilities for industry-level simulations.</p>"
    },
    {
      "id": "4f7dce457bf7",
      "title": "$\\alpha^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks",
      "content": "arXiv:2601.18754v1 Announce Type: cross  Abstract: Autonomous unmanned aerial vehicle (UAV) systems are increasingly deployed in safety-critical, networked environments where they must operate reliably in the presence of malicious adversaries. While recent benchmarks have evaluated large language model (LLM)-based UAV agents in reasoning, navigation, and efficiency, systematic assessment of security, resilience, and trust under adversarial conditions remains largely unexplored, particularly in emerging 6G-enabled settings.   We introduce $\\alpha^{3}$-SecBench, the first large-scale evaluation suite for assessing the security-aware autonomy of LLM-based UAV agents under realistic adversarial interference. Building on multi-turn conversational UAV missions from $\\alpha^{3}$-Bench, the framework augments benign episodes with 20,000 validated security overlay attack scenarios targeting seven autonomy layers, including sensing, perception, planning, control, communication, edge/cloud infrastructure, and LLM reasoning. $\\alpha^{3}$-SecBench evaluates agents across three orthogonal dimensions: security (attack detection and vulnerability attribution), resilience (safe degradation behavior), and trust (policy-compliant tool usage).   We evaluate 23 state-of-the-art LLMs from major industrial providers and leading AI labs using thousands of adversarially augmented UAV episodes sampled from a corpus of 113,475 missions spanning 175 threat types. While many models reliably detect anomalous behavior, effective mitigation, vulnerability attribution, and trustworthy control actions remain inconsistent. Normalized overall scores range from 12.9% to 57.1%, highlighting a significant gap between anomaly detection and security-aware autonomous decision-making. We release $\\alpha^{3}$-SecBench on GitHub: https://github.com/maferrag/AlphaSecBench",
      "url": "http://arxiv.org/abs/2601.18754",
      "author": "Mohamed Amine Ferrag, Abderrahmane Lakas, Merouane Debbah",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Introduces -SecBench, first large-scale security evaluation suite for LLM-based UAV agents under adversarial conditions in 6G networks, extending -Bench with adversarial scenarios.",
      "importance_score": 58,
      "reasoning": "First security benchmark for emerging LLM-UAV domain. Relevant for safety-critical deployments but specialized niche.",
      "themes": [
        "UAV Security",
        "LLM Agents",
        "Adversarial Evaluation",
        "6G Networks"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces -SecBench, first large-scale security evaluation suite for LLM-based UAV agents under adversarial conditions in 6G networks, extending -Bench with adversarial scenarios.</p>",
      "content_html": "<p>arXiv:2601.18754v1 Announce Type: cross  Abstract: Autonomous unmanned aerial vehicle (UAV) systems are increasingly deployed in safety-critical, networked environments where they must operate reliably in the presence of malicious adversaries. While recent benchmarks have evaluated large language model (LLM)-based UAV agents in reasoning, navigation, and efficiency, systematic assessment of security, resilience, and trust under adversarial conditions remains largely unexplored, particularly in emerging 6G-enabled settings.   We introduce $\\alpha^{3}$-SecBench, the first large-scale evaluation suite for assessing the security-aware autonomy of LLM-based UAV agents under realistic adversarial interference. Building on multi-turn conversational UAV missions from $\\alpha^{3}$-Bench, the framework augments benign episodes with 20,000 validated security overlay attack scenarios targeting seven autonomy layers, including sensing, perception, planning, control, communication, edge/cloud infrastructure, and LLM reasoning. $\\alpha^{3}$-SecBench evaluates agents across three orthogonal dimensions: security (attack detection and vulnerability attribution), resilience (safe degradation behavior), and trust (policy-compliant tool usage).   We evaluate 23 state-of-the-art LLMs from major industrial providers and leading AI labs using thousands of adversarially augmented UAV episodes sampled from a corpus of 113,475 missions spanning 175 threat types. While many models reliably detect anomalous behavior, effective mitigation, vulnerability attribution, and trustworthy control actions remain inconsistent. Normalized overall scores range from 12.9% to 57.1%, highlighting a significant gap between anomaly detection and security-aware autonomous decision-making. We release $\\alpha^{3}$-SecBench on GitHub: https://github.com/maferrag/AlphaSecBench</p>"
    },
    {
      "id": "09dcf8b7a196",
      "title": "Ordering-based Causal Discovery via Generalized Score Matching",
      "content": "arXiv:2601.16249v2 Announce Type: new  Abstract: Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.",
      "url": "http://arxiv.org/abs/2601.16249",
      "author": "Vy Vo, He Zhao, Trung Le, Edwin V. Bonilla, Dinh Phung",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Extends score matching framework for causal discovery to discrete data, introducing leaf discriminant criterion based on discrete score function for topological order identification.",
      "importance_score": 58,
      "reasoning": "Extends continuous causal discovery method to discrete data. Addresses important methodological gap with empirical validation.",
      "themes": [
        "Causal Discovery",
        "Score Matching",
        "Discrete Data"
      ],
      "continuation": null,
      "summary_html": "<p>Extends score matching framework for causal discovery to discrete data, introducing leaf discriminant criterion based on discrete score function for topological order identification.</p>",
      "content_html": "<p>arXiv:2601.16249v2 Announce Type: new  Abstract: Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.</p>"
    },
    {
      "id": "28ed3655372b",
      "title": "Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation",
      "content": "arXiv:2601.16863v1 Announce Type: cross  Abstract: This paper introduces the N-Way Self-Evaluating Deliberation (NSED) protocol, a Runtime Mixture-of-Models (MoM) architecture that constructs emergent composite models from a plurality of distinct expert agents. Unlike traditional Mixture-of-Experts (MoE) which rely on static gating networks, NSED employs a Dynamic Expertise Broker - a runtime optimization engine that treats model selection as a variation of the Knapsack Problem, binding heterogeneous checkpoints to functional roles based on live telemetry and cost constraints. At the execution layer, we formalize deliberation as a Macro-Scale Recurrent Neural Network (RNN), where the consensus state loops back through a semantic forget gate to enable iterative refinement without proportional VRAM scaling. Key components include an orchestration fabric for trustless N-to-N peer review, a Quadratic Voting activation function for non-linear consensus, and a feedback-driven state update. Empirical validation on challenging benchmarks (AIME 2025, LiveCodeBench) demonstrates that this topology allows ensembles of small (less than 20B) consumer-grade models to match or exceed the performance of state-of-the-art 100B+ parameter models, establishing a new hardware arbitrage efficiency frontier. Furthermore, testing on the DarkBench safety suite reveals intrinsic alignment properties, with peer-mediated correction reducing sycophancy scores below that of any individual agent.",
      "url": "http://arxiv.org/abs/2601.16863",
      "author": "Tims Pecerskis, Aivars Smirnovs",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces N-Way Self-Evaluating Deliberation (NSED) protocol for runtime mixture-of-models that dynamically selects and combines heterogeneous expert agents. Treats model selection as a Knapsack optimization problem with live telemetry.",
      "importance_score": 58,
      "reasoning": "Interesting multi-agent architecture concept, but from less established authors and lacks comprehensive experimental validation.",
      "themes": [
        "Multi-Agent Systems",
        "Mixture of Experts",
        "Model Ensembling"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces N-Way Self-Evaluating Deliberation (NSED) protocol for runtime mixture-of-models that dynamically selects and combines heterogeneous expert agents. Treats model selection as a Knapsack optimization problem with live telemetry.</p>",
      "content_html": "<p>arXiv:2601.16863v1 Announce Type: cross  Abstract: This paper introduces the N-Way Self-Evaluating Deliberation (NSED) protocol, a Runtime Mixture-of-Models (MoM) architecture that constructs emergent composite models from a plurality of distinct expert agents. Unlike traditional Mixture-of-Experts (MoE) which rely on static gating networks, NSED employs a Dynamic Expertise Broker - a runtime optimization engine that treats model selection as a variation of the Knapsack Problem, binding heterogeneous checkpoints to functional roles based on live telemetry and cost constraints. At the execution layer, we formalize deliberation as a Macro-Scale Recurrent Neural Network (RNN), where the consensus state loops back through a semantic forget gate to enable iterative refinement without proportional VRAM scaling. Key components include an orchestration fabric for trustless N-to-N peer review, a Quadratic Voting activation function for non-linear consensus, and a feedback-driven state update. Empirical validation on challenging benchmarks (AIME 2025, LiveCodeBench) demonstrates that this topology allows ensembles of small (less than 20B) consumer-grade models to match or exceed the performance of state-of-the-art 100B+ parameter models, establishing a new hardware arbitrage efficiency frontier. Furthermore, testing on the DarkBench safety suite reveals intrinsic alignment properties, with peer-mediated correction reducing sycophancy scores below that of any individual agent.</p>"
    },
    {
      "id": "ef4966679654",
      "title": "Revisiting Modality Invariance in a Multilingual Speech-Text Model via Neuron-Level Analysis",
      "content": "arXiv:2601.17387v1 Announce Type: new  Abstract: Multilingual speech-text foundation models aim to process language uniformly across both modality and language, yet it remains unclear whether they internally represent the same language consistently when it is spoken versus written. We investigate this question in SeamlessM4T v2 through three complementary analyses that probe where language and modality information is encoded, how selective neurons causally influence decoding, and how concentrated this influence is across the network. We identify language- and modality-selective neurons using average-precision ranking, investigate their functional role via median-replacement interventions at inference time, and analyze activation-magnitude inequality across languages and modalities. Across experiments, we find evidence of incomplete modality invariance. Although encoder representations become increasingly language-agnostic, this compression makes it more difficult for the shared decoder to recover the language of origin when constructing modality-agnostic representations, particularly when adapting from speech to text. We further observe sharply localized modality-selective structure in cross-attention key and value projections. Finally, speech-conditioned decoding and non-dominant scripts exhibit higher activation concentration, indicating heavier reliance on a small subset of neurons, which may underlie increased brittleness across modalities and languages.",
      "url": "http://arxiv.org/abs/2601.17387",
      "author": "Toshiki Nakai, Varsha Suresh, Vera Demberg",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Investigates modality invariance in SeamlessM4T v2 through neuron-level analysis, examining whether spoken and written forms of the same language are represented consistently across modality and language.",
      "importance_score": 58,
      "reasoning": "Interesting interpretability work on multimodal models with novel neuron-level analysis approach. Contributes to understanding speech-text representation.",
      "themes": [
        "Interpretability",
        "Multimodal Models",
        "Speech-Text Models"
      ],
      "continuation": null,
      "summary_html": "<p>Investigates modality invariance in SeamlessM4T v2 through neuron-level analysis, examining whether spoken and written forms of the same language are represented consistently across modality and language.</p>",
      "content_html": "<p>arXiv:2601.17387v1 Announce Type: new  Abstract: Multilingual speech-text foundation models aim to process language uniformly across both modality and language, yet it remains unclear whether they internally represent the same language consistently when it is spoken versus written. We investigate this question in SeamlessM4T v2 through three complementary analyses that probe where language and modality information is encoded, how selective neurons causally influence decoding, and how concentrated this influence is across the network. We identify language- and modality-selective neurons using average-precision ranking, investigate their functional role via median-replacement interventions at inference time, and analyze activation-magnitude inequality across languages and modalities. Across experiments, we find evidence of incomplete modality invariance. Although encoder representations become increasingly language-agnostic, this compression makes it more difficult for the shared decoder to recover the language of origin when constructing modality-agnostic representations, particularly when adapting from speech to text. We further observe sharply localized modality-selective structure in cross-attention key and value projections. Finally, speech-conditioned decoding and non-dominant scripts exhibit higher activation concentration, indicating heavier reliance on a small subset of neurons, which may underlie increased brittleness across modalities and languages.</p>"
    },
    {
      "id": "103c3684095c",
      "title": "EFT-CoT: A Multi-Agent Chain-of-Thought Framework for Emotion-Focused Therapy",
      "content": "arXiv:2601.17842v1 Announce Type: new  Abstract: Leveraging Large Language Models (LLMs) for Mental Health Question Answering (MHQA) is promising for mitigating resource shortages. However, existing Cognitive Behavioral Therapy (CBT)-based approaches predominantly favor a \"top-down\" rational restructuring, often neglecting clients' embodied experiences and primary emotion processing. To address this, we propose an Emotion-Focused Therapy (EFT)-based Multi-Agent Chain-of-Thought framework (EFT-CoT). Adopting a \"bottom-up\" trajectory, it deconstructs the intervention into a three-stage reasoning flow: \"Embodied Perception - Cognitive Exploration - Narrative Intervention.\" Utilizing eight specialized agents, the system explicitly executes critical components such as somatic awareness mapping, adaptive assessment, core belief extraction, and narrative restructuring. We further constructed \"EFT-Instruct,\" a high-quality dataset via Chain-of-Thought distillation of approximately 67,000 authentic texts, and fine-tuned a specialized model, EFT-LLM. Experimental evaluations demonstrate that EFT-LLM outperforms strong baselines and human responses across metrics like empathy depth and structural professionalism. Ablation studies confirm the necessity of the multi-agent mechanism. The model exhibits superior psychological reasoning, offering an effective pathway for interpretable, high-empathy counseling systems.",
      "url": "http://arxiv.org/abs/2601.17842",
      "author": "Lanqing Du, Yunong Li, YuJie Long, Shihong Chen",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes EFT-CoT, an Emotion-Focused Therapy multi-agent chain-of-thought framework for mental health QA using eight specialized agents following bottom-up emotional processing trajectory.",
      "importance_score": 58,
      "reasoning": "Interesting application of multi-agent approaches to therapeutic dialogue. Novel EFT framework differs from dominant CBT approaches.",
      "themes": [
        "Mental Health",
        "Multi-Agent Systems",
        "Dialogue Systems"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes EFT-CoT, an Emotion-Focused Therapy multi-agent chain-of-thought framework for mental health QA using eight specialized agents following bottom-up emotional processing trajectory.</p>",
      "content_html": "<p>arXiv:2601.17842v1 Announce Type: new  Abstract: Leveraging Large Language Models (LLMs) for Mental Health Question Answering (MHQA) is promising for mitigating resource shortages. However, existing Cognitive Behavioral Therapy (CBT)-based approaches predominantly favor a \"top-down\" rational restructuring, often neglecting clients' embodied experiences and primary emotion processing. To address this, we propose an Emotion-Focused Therapy (EFT)-based Multi-Agent Chain-of-Thought framework (EFT-CoT). Adopting a \"bottom-up\" trajectory, it deconstructs the intervention into a three-stage reasoning flow: \"Embodied Perception - Cognitive Exploration - Narrative Intervention.\" Utilizing eight specialized agents, the system explicitly executes critical components such as somatic awareness mapping, adaptive assessment, core belief extraction, and narrative restructuring. We further constructed \"EFT-Instruct,\" a high-quality dataset via Chain-of-Thought distillation of approximately 67,000 authentic texts, and fine-tuned a specialized model, EFT-LLM. Experimental evaluations demonstrate that EFT-LLM outperforms strong baselines and human responses across metrics like empathy depth and structural professionalism. Ablation studies confirm the necessity of the multi-agent mechanism. The model exhibits superior psychological reasoning, offering an effective pathway for interpretable, high-empathy counseling systems.</p>"
    },
    {
      "id": "20a20d06d829",
      "title": "TechING: Towards Real World Technical Image Understanding via VLMs",
      "content": "arXiv:2601.18238v1 Announce Type: new  Abstract: Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x.",
      "url": "http://arxiv.org/abs/2601.18238",
      "author": "Tafazzul Nadeem, Bhavik Shangari, Manish Rai, Gagan Raj Gupta, Ashutosh Modi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces TechING, a synthetically generated corpus for training VLMs on technical diagram understanding (flowcharts, block diagrams) with evaluation on real hand-drawn images.",
      "importance_score": 58,
      "reasoning": "Addresses practical gap in VLM capabilities with novel synthetic data approach. Useful for technical domain applications.",
      "themes": [
        "Vision-Language Models",
        "Technical Diagrams",
        "Dataset"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces TechING, a synthetically generated corpus for training VLMs on technical diagram understanding (flowcharts, block diagrams) with evaluation on real hand-drawn images.</p>",
      "content_html": "<p>arXiv:2601.18238v1 Announce Type: new  Abstract: Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x.</p>"
    },
    {
      "id": "62dd5c5cf923",
      "title": "Evaluating Morphological Plausibility of Subword Tokenization via Statistical Alignment with Morpho-Syntactic Features",
      "content": "arXiv:2601.18536v1 Announce Type: new  Abstract: We present a novel metric for the evaluation of the morphological plausibility of subword segmentation. Unlike the typically used morpheme boundary or retrieval F-score, which requires gold segmentation data that is either unavailable or of inconsistent quality across many languages, our approach utilizes morpho-syntactic features. These are available in resources such as Universal Dependencies or UniMorph for a much wider range of languages. The metric works by probabilistically aligning subwords with morphological features through an IBM Model 1. Our experiments show that the metric correlates well with traditional morpheme boundary recall while being more broadly applicable across languages with different morphological systems.",
      "url": "http://arxiv.org/abs/2601.18536",
      "author": "Abishek Stephen, Jind\\v{r}ich Libovick\\'y",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents novel metric for evaluating morphological plausibility of subword segmentation using morpho-syntactic features instead of gold morpheme boundaries, enabling broader language coverage.",
      "importance_score": 58,
      "reasoning": "Useful methodology for tokenization research with cross-linguistic applicability. Addresses resource limitation in evaluation.",
      "themes": [
        "Tokenization",
        "Morphology",
        "Evaluation Metrics"
      ],
      "continuation": null,
      "summary_html": "<p>Presents novel metric for evaluating morphological plausibility of subword segmentation using morpho-syntactic features instead of gold morpheme boundaries, enabling broader language coverage.</p>",
      "content_html": "<p>arXiv:2601.18536v1 Announce Type: new  Abstract: We present a novel metric for the evaluation of the morphological plausibility of subword segmentation. Unlike the typically used morpheme boundary or retrieval F-score, which requires gold segmentation data that is either unavailable or of inconsistent quality across many languages, our approach utilizes morpho-syntactic features. These are available in resources such as Universal Dependencies or UniMorph for a much wider range of languages. The metric works by probabilistically aligning subwords with morphological features through an IBM Model 1. Our experiments show that the metric correlates well with traditional morpheme boundary recall while being more broadly applicable across languages with different morphological systems.</p>"
    },
    {
      "id": "8d6c35be758c",
      "title": "The Voice of Equity: A Systematic Evaluation of Bias Mitigation Techniques for Speech-Based Cognitive Impairment Detection Across Architectures and Demographics",
      "content": "arXiv:2601.16989v1 Announce Type: cross  Abstract: Speech-based detection of cognitive impairment offers a scalable, non-invasive screening, yet algorithmic bias across demographic and linguistic subgroups remains critically underexplored. We present the first comprehensive fairness analysis framework for speech-based multi-class cognitive impairment detection, systematically evaluating bias mitigation across architectures, and demographic subgroups. We developed two transformer-based architectures, SpeechCARE-AGF and Whisper-LWF-LoRA, on the multilingual NIA PREPARE Challenge dataset. Unlike prior work that typically examines single mitigation techniques, we compared pre-processing, in-processing, and post-processing approaches, assessing fairness via Equality of Opportunity and Equalized Odds across gender, age, education, and language. Both models achieved strong performance (F1: SpeechCARE-AGF 70.87, Whisper-LWF-LoRA 71.46) but exhibited substantial fairness disparities. Adults >=80 showed lower sensitivity versus younger groups; Spanish speakers demonstrated reduced TPR versus English speakers. Mitigation effectiveness varied by architecture: oversampling improved SpeechCARE-AGF for older adults (80+ TPR: 46.19%=>49.97%) but minimally affected Whisper-LWF-LoRA. This study addresses a critical healthcare AI gap by demonstrating that architectural design fundamentally shapes bias patterns and mitigation effectiveness. Adaptive fusion mechanisms enable flexible responses to data interventions, while frequency reweighting offers robust improvements across architectures. Our findings establish that fairness interventions must be tailored to both model architecture and demographic characteristics, providing a systematic framework for developing equitable speech-based screening tools essential for reducing diagnostic disparities in cognitive healthcare.",
      "url": "http://arxiv.org/abs/2601.16989",
      "author": "Yasaman Haghbin, Sina Rashidi, Ali Zolnour, Maryam Zolnoori",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "eess.AS"
      ],
      "summary": "Presents first comprehensive fairness analysis framework for speech-based cognitive impairment detection, systematically evaluating bias mitigation across transformer architectures and demographic subgroups on multilingual data.",
      "importance_score": 58,
      "reasoning": "Important healthcare AI fairness work, but focused on specific application domain. Valuable systematic comparison of bias mitigation approaches.",
      "themes": [
        "Fairness",
        "Healthcare AI",
        "Speech Processing",
        "Bias Mitigation"
      ],
      "continuation": null,
      "summary_html": "<p>Presents first comprehensive fairness analysis framework for speech-based cognitive impairment detection, systematically evaluating bias mitigation across transformer architectures and demographic subgroups on multilingual data.</p>",
      "content_html": "<p>arXiv:2601.16989v1 Announce Type: cross  Abstract: Speech-based detection of cognitive impairment offers a scalable, non-invasive screening, yet algorithmic bias across demographic and linguistic subgroups remains critically underexplored. We present the first comprehensive fairness analysis framework for speech-based multi-class cognitive impairment detection, systematically evaluating bias mitigation across architectures, and demographic subgroups. We developed two transformer-based architectures, SpeechCARE-AGF and Whisper-LWF-LoRA, on the multilingual NIA PREPARE Challenge dataset. Unlike prior work that typically examines single mitigation techniques, we compared pre-processing, in-processing, and post-processing approaches, assessing fairness via Equality of Opportunity and Equalized Odds across gender, age, education, and language. Both models achieved strong performance (F1: SpeechCARE-AGF 70.87, Whisper-LWF-LoRA 71.46) but exhibited substantial fairness disparities. Adults &gt;=80 showed lower sensitivity versus younger groups; Spanish speakers demonstrated reduced TPR versus English speakers. Mitigation effectiveness varied by architecture: oversampling improved SpeechCARE-AGF for older adults (80+ TPR: 46.19%=&gt;49.97%) but minimally affected Whisper-LWF-LoRA. This study addresses a critical healthcare AI gap by demonstrating that architectural design fundamentally shapes bias patterns and mitigation effectiveness. Adaptive fusion mechanisms enable flexible responses to data interventions, while frequency reweighting offers robust improvements across architectures. Our findings establish that fairness interventions must be tailored to both model architecture and demographic characteristics, providing a systematic framework for developing equitable speech-based screening tools essential for reducing diagnostic disparities in cognitive healthcare.</p>"
    },
    {
      "id": "15848bac46fd",
      "title": "SpatialMath: Spatial Comprehension-Infused Symbolic Reasoning for Mathematical Problem-Solving",
      "content": "arXiv:2601.17489v1 Announce Type: cross  Abstract: Multimodal Small-to-Medium sized Language Models (MSLMs) have demonstrated strong capabilities in integrating visual and textual information but still face significant limitations in visual comprehension and mathematical reasoning, particularly in geometric problems with diverse levels of visual infusion. Current models struggle to accurately decompose intricate visual inputs and connect perception with structured reasoning, leading to suboptimal performance. To address these challenges, we propose SpatialMath, a novel Spatial Comprehension-Infused Symbolic Reasoning Framework designed to integrate spatial representations into structured symbolic reasoning chains. SpatialMath employs a specialized perception module to extract spatially-grounded representations from visual diagrams, capturing critical geometric structures and spatial relationships. These representations are then methodically infused into symbolic reasoning chains, facilitating visual comprehension-aware structured reasoning. To this end, we introduce MATHVERSE-PLUS, a novel dataset containing structured visual interpretations and step-by-step reasoning paths for vision-intensive mathematical problems. SpatialMath significantly outperforms strong multimodal baselines, achieving up to 10 percentage points improvement over supervised fine-tuning with data augmentation in vision-intensive settings. Robustness analysis reveals that enhanced spatial representations directly improve reasoning accuracy, reinforcing the need for structured perception-to-reasoning pipelines in MSLMs.",
      "url": "http://arxiv.org/abs/2601.17489",
      "author": "Ashutosh Bajpai, Akshat Bhandari, Akshay Nambi, Tanmoy Chakraborty",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces SpatialMath framework integrating spatial comprehension with symbolic reasoning for mathematical problem-solving, using specialized perception module to extract spatially-grounded representations for geometric problems.",
      "importance_score": 58,
      "reasoning": "Addresses important gap in multimodal math reasoning. Relevant to improving LLM mathematical capabilities.",
      "themes": [
        "Math Reasoning",
        "Multimodal AI",
        "Spatial Understanding"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces SpatialMath framework integrating spatial comprehension with symbolic reasoning for mathematical problem-solving, using specialized perception module to extract spatially-grounded representations for geometric problems.</p>",
      "content_html": "<p>arXiv:2601.17489v1 Announce Type: cross  Abstract: Multimodal Small-to-Medium sized Language Models (MSLMs) have demonstrated strong capabilities in integrating visual and textual information but still face significant limitations in visual comprehension and mathematical reasoning, particularly in geometric problems with diverse levels of visual infusion. Current models struggle to accurately decompose intricate visual inputs and connect perception with structured reasoning, leading to suboptimal performance. To address these challenges, we propose SpatialMath, a novel Spatial Comprehension-Infused Symbolic Reasoning Framework designed to integrate spatial representations into structured symbolic reasoning chains. SpatialMath employs a specialized perception module to extract spatially-grounded representations from visual diagrams, capturing critical geometric structures and spatial relationships. These representations are then methodically infused into symbolic reasoning chains, facilitating visual comprehension-aware structured reasoning. To this end, we introduce MATHVERSE-PLUS, a novel dataset containing structured visual interpretations and step-by-step reasoning paths for vision-intensive mathematical problems. SpatialMath significantly outperforms strong multimodal baselines, achieving up to 10 percentage points improvement over supervised fine-tuning with data augmentation in vision-intensive settings. Robustness analysis reveals that enhanced spatial representations directly improve reasoning accuracy, reinforcing the need for structured perception-to-reasoning pipelines in MSLMs.</p>"
    },
    {
      "id": "d15fd373d7e0",
      "title": "Ego4OOD: Rethinking Egocentric Video Domain Generalization via Covariate Shift Scoring",
      "content": "arXiv:2601.17056v1 Announce Type: new  Abstract: Egocentric video action recognition under domain shifts remains challenging due to large intra-class spatio-temporal variability, long-tailed feature distributions, and strong correlations between actions and environments. Existing benchmarks for egocentric domain generalization often conflate covariate shifts with concept shifts, making it difficult to reliably evaluate a model's ability to generalize across input distributions. To address this limitation, we introduce Ego4OOD, a domain generalization benchmark derived from Ego4D that emphasizes measurable covariate diversity while reducing concept shift through semantically coherent, moment-level action categories. Ego4OOD spans eight geographically distinct domains and is accompanied by a clustering-based covariate shift metric that provides a quantitative proxy for domain difficulty. We further leverage a one-vs-all binary training objective that decomposes multi-class action recognition into independent binary classification tasks. This formulation is particularly well-suited for covariate shift by reducing interference between visually similar classes under feature distribution shift. Using this formulation, we show that a lightweight two-layer fully connected network achieves performance competitive with state-of-the-art egocentric domain generalization methods on both Argo1M and Ego4OOD, despite using fewer parameters and no additional modalities. Our empirical analysis demonstrates a clear relationship between measured covariate shift and recognition performance, highlighting the importance of controlled benchmarks and quantitative domain characterization for studying out-of-distribution generalization in egocentric video.",
      "url": "http://arxiv.org/abs/2601.17056",
      "author": "Zahra Vaseqi, James Clark",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces Ego4OOD benchmark for egocentric video domain generalization, emphasizing covariate diversity while reducing concept shift through semantically coherent action categories across 8 geographic domains.",
      "importance_score": 58,
      "reasoning": "Useful benchmark contribution addressing limitations in existing egocentric video benchmarks for domain generalization.",
      "themes": [
        "Egocentric Vision",
        "Domain Generalization",
        "Benchmarks"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Ego4OOD benchmark for egocentric video domain generalization, emphasizing covariate diversity while reducing concept shift through semantically coherent action categories across 8 geographic domains.</p>",
      "content_html": "<p>arXiv:2601.17056v1 Announce Type: new  Abstract: Egocentric video action recognition under domain shifts remains challenging due to large intra-class spatio-temporal variability, long-tailed feature distributions, and strong correlations between actions and environments. Existing benchmarks for egocentric domain generalization often conflate covariate shifts with concept shifts, making it difficult to reliably evaluate a model's ability to generalize across input distributions. To address this limitation, we introduce Ego4OOD, a domain generalization benchmark derived from Ego4D that emphasizes measurable covariate diversity while reducing concept shift through semantically coherent, moment-level action categories. Ego4OOD spans eight geographically distinct domains and is accompanied by a clustering-based covariate shift metric that provides a quantitative proxy for domain difficulty. We further leverage a one-vs-all binary training objective that decomposes multi-class action recognition into independent binary classification tasks. This formulation is particularly well-suited for covariate shift by reducing interference between visually similar classes under feature distribution shift. Using this formulation, we show that a lightweight two-layer fully connected network achieves performance competitive with state-of-the-art egocentric domain generalization methods on both Argo1M and Ego4OOD, despite using fewer parameters and no additional modalities. Our empirical analysis demonstrates a clear relationship between measured covariate shift and recognition performance, highlighting the importance of controlled benchmarks and quantitative domain characterization for studying out-of-distribution generalization in egocentric video.</p>"
    },
    {
      "id": "4da28a303f63",
      "title": "SkyReels-V3 Technique Report",
      "content": "arXiv:2601.17323v1 Announce Type: new  Abstract: Video generation serves as a cornerstone for building world models, where multimodal contextual inference stands as the defining test of capability. In this end, we present SkyReels-V3, a conditional video generation model, built upon a unified multimodal in-context learning framework with diffusion Transformers. SkyReels-V3 model supports three core generative paradigms within a single architecture: reference images-to-video synthesis, video-to-video extension and audio-guided video generation. (i) reference images-to-video model is designed to produce high-fidelity videos with strong subject identity preservation, temporal coherence, and narrative consistency. To enhance reference adherence and compositional stability, we design a comprehensive data processing pipeline that leverages cross frame pairing, image editing, and semantic rewriting, effectively mitigating copy paste artifacts. During training, an image video hybrid strategy combined with multi-resolution joint optimization is employed to improve generalization and robustness across diverse scenarios. (ii) video extension model integrates spatio-temporal consistency modeling with large-scale video understanding, enabling both seamless single-shot continuation and intelligent multi-shot switching with professional cinematographic patterns. (iii) Talking avatar model supports minute-level audio-conditioned video generation by training first-and-last frame insertion patterns and reconstructing key-frame inference paradigms. On the basis of ensuring visual quality, synchronization of audio and videos has been optimized.   Extensive evaluations demonstrate that SkyReels-V3 achieves state-of-the-art or near state-of-the-art performance on key metrics including visual quality, instruction following, and specific aspect metrics, approaching leading closed-source systems. Github: https://github.com/SkyworkAI/SkyReels-V3.",
      "url": "http://arxiv.org/abs/2601.17323",
      "author": "Debang Li, Zhengcong Fei, Tuanhui Li, Yikun Dou, Zheng Chen, Jiangping Yang, Mingyuan Fan, Jingtao Xu, Jiahua Wang, Baoxuan Gu, Mingshan Chang, Yuqiang Xie, Binjie Mao, Youqiang Zhang, Nuo Pang, Hao Zhang, Yuzhe Jin, Zhiheng Xu, Dixuan Lin, Guibin Chen, Yahui Zhou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Technical report on SkyReels-V3, conditional video generation model supporting reference images-to-video, video extension, and audio-guided generation within unified multimodal in-context learning framework.",
      "importance_score": 58,
      "reasoning": "Comprehensive video generation model with multiple modalities but limited technical novelty details in abstract.",
      "themes": [
        "Video Generation",
        "Multimodal Learning",
        "Generative Models"
      ],
      "continuation": null,
      "summary_html": "<p>Technical report on SkyReels-V3, conditional video generation model supporting reference images-to-video, video extension, and audio-guided generation within unified multimodal in-context learning framework.</p>",
      "content_html": "<p>arXiv:2601.17323v1 Announce Type: new  Abstract: Video generation serves as a cornerstone for building world models, where multimodal contextual inference stands as the defining test of capability. In this end, we present SkyReels-V3, a conditional video generation model, built upon a unified multimodal in-context learning framework with diffusion Transformers. SkyReels-V3 model supports three core generative paradigms within a single architecture: reference images-to-video synthesis, video-to-video extension and audio-guided video generation. (i) reference images-to-video model is designed to produce high-fidelity videos with strong subject identity preservation, temporal coherence, and narrative consistency. To enhance reference adherence and compositional stability, we design a comprehensive data processing pipeline that leverages cross frame pairing, image editing, and semantic rewriting, effectively mitigating copy paste artifacts. During training, an image video hybrid strategy combined with multi-resolution joint optimization is employed to improve generalization and robustness across diverse scenarios. (ii) video extension model integrates spatio-temporal consistency modeling with large-scale video understanding, enabling both seamless single-shot continuation and intelligent multi-shot switching with professional cinematographic patterns. (iii) Talking avatar model supports minute-level audio-conditioned video generation by training first-and-last frame insertion patterns and reconstructing key-frame inference paradigms. On the basis of ensuring visual quality, synchronization of audio and videos has been optimized.   Extensive evaluations demonstrate that SkyReels-V3 achieves state-of-the-art or near state-of-the-art performance on key metrics including visual quality, instruction following, and specific aspect metrics, approaching leading closed-source systems. Github: https://github.com/SkyworkAI/SkyReels-V3.</p>"
    },
    {
      "id": "60878f783954",
      "title": "HAAF: Hierarchical Adaptation and Alignment of Foundation Models for Few-Shot Pathology Anomaly Detection",
      "content": "arXiv:2601.17405v1 Announce Type: new  Abstract: Precision pathology relies on detecting fine-grained morphological abnormalities within specific Regions of Interest (ROIs), as these local, texture-rich cues - rather than global slide contexts - drive expert diagnostic reasoning. While Vision-Language (V-L) models promise data efficiency by leveraging semantic priors, adapting them faces a critical Granularity Mismatch, where generic representations fail to resolve such subtle defects. Current adaptation methods often treat modalities as independent streams, failing to ground semantic prompts in ROI-specific visual contexts. To bridge this gap, we propose the Hierarchical Adaptation and Alignment Framework (HAAF). At its core is a novel Cross-Level Scaled Alignment (CLSA) mechanism that enforces a sequential calibration order: visual features first inject context into text prompts to generate content-adaptive descriptors, which then spatially guide the visual encoder to spotlight anomalies. Additionally, a dual-branch inference strategy integrates semantic scores with geometric prototypes to ensure stability in few-shot settings. Experiments on four benchmarks show HAAF significantly outperforms state-of-the-art methods and effectively scales with domain-specific backbones (e.g., CONCH) in low-resource scenarios.",
      "url": "http://arxiv.org/abs/2601.17405",
      "author": "Chunze Yang, Wenjie Zhao, Yue Tang, Junbo Lu, Jiusong Ge, Qidong Liu, Zeyu Gao, Chen Li",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes HAAF framework adapting vision-language models for few-shot pathology anomaly detection using Cross-Level Scaled Alignment to ground semantic prompts in ROI-specific visual contexts.",
      "importance_score": 58,
      "reasoning": "Addresses important challenge of adapting VLMs to fine-grained pathology with novel alignment approach.",
      "themes": [
        "Pathology AI",
        "Few-shot Learning",
        "Vision-Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes HAAF framework adapting vision-language models for few-shot pathology anomaly detection using Cross-Level Scaled Alignment to ground semantic prompts in ROI-specific visual contexts.</p>",
      "content_html": "<p>arXiv:2601.17405v1 Announce Type: new  Abstract: Precision pathology relies on detecting fine-grained morphological abnormalities within specific Regions of Interest (ROIs), as these local, texture-rich cues - rather than global slide contexts - drive expert diagnostic reasoning. While Vision-Language (V-L) models promise data efficiency by leveraging semantic priors, adapting them faces a critical Granularity Mismatch, where generic representations fail to resolve such subtle defects. Current adaptation methods often treat modalities as independent streams, failing to ground semantic prompts in ROI-specific visual contexts. To bridge this gap, we propose the Hierarchical Adaptation and Alignment Framework (HAAF). At its core is a novel Cross-Level Scaled Alignment (CLSA) mechanism that enforces a sequential calibration order: visual features first inject context into text prompts to generate content-adaptive descriptors, which then spatially guide the visual encoder to spotlight anomalies. Additionally, a dual-branch inference strategy integrates semantic scores with geometric prototypes to ensure stability in few-shot settings. Experiments on four benchmarks show HAAF significantly outperforms state-of-the-art methods and effectively scales with domain-specific backbones (e.g., CONCH) in low-resource scenarios.</p>"
    },
    {
      "id": "dfed27cdaee1",
      "title": "SPACE-CLIP: Spatial Perception via Adaptive CLIP Embeddings for Monocular Depth Estimation",
      "content": "arXiv:2601.17657v1 Announce Type: new  Abstract: Contrastive Language-Image Pre-training (CLIP) has accomplished extraordinary success for semantic understanding but inherently struggles to perceive geometric structure. Existing methods attempt to bridge this gap by querying CLIP with textual prompts, a process that is often indirect and inefficient. This paper introduces a fundamentally different approach using a dual-pathway decoder. We present SPACE-CLIP, an architecture that unlocks and interprets latent geometric knowledge directly from a frozen CLIP vision encoder, completely bypassing the text encoder and its associated textual prompts. A semantic pathway interprets high-level features, dynamically conditioned on global context using feature-wise linear modulation (FiLM). In addition, a structural pathway extracts fine-grained spatial details from early layers. These complementary streams are hierarchically fused, enabling a robust synthesis of semantic context and precise geometry. Extensive experiments on the KITTI benchmark show that SPACE-CLIP dramatically outperforms previous CLIP-based methods. Our ablation studies validate that the synergistic fusion of our dual pathways is critical to this success. SPACE-CLIP offers a new, efficient, and architecturally elegant blueprint for repurposing large-scale vision models. The proposed method is not just a standalone depth estimator, but a readily integrable spatial perception module for the next generation of embodied AI systems, such as vision-language-action (VLA) models. Our model is available at https://github.com/taewan2002/space-clip",
      "url": "http://arxiv.org/abs/2601.17657",
      "author": "Taewan Cho, Taeryang Kim, Andrew Jaeyong Choi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "SPACE-CLIP extracts latent geometric knowledge directly from frozen CLIP vision encoders for monocular depth estimation, bypassing the text encoder entirely through a dual-pathway decoder architecture using FiLM conditioning.",
      "importance_score": 58,
      "reasoning": "Novel insight about geometric information encoded in CLIP's vision encoder. Practical approach but narrow application scope.",
      "themes": [
        "Vision-Language Models",
        "Depth Estimation",
        "Transfer Learning"
      ],
      "continuation": null,
      "summary_html": "<p>SPACE-CLIP extracts latent geometric knowledge directly from frozen CLIP vision encoders for monocular depth estimation, bypassing the text encoder entirely through a dual-pathway decoder architecture using FiLM conditioning.</p>",
      "content_html": "<p>arXiv:2601.17657v1 Announce Type: new  Abstract: Contrastive Language-Image Pre-training (CLIP) has accomplished extraordinary success for semantic understanding but inherently struggles to perceive geometric structure. Existing methods attempt to bridge this gap by querying CLIP with textual prompts, a process that is often indirect and inefficient. This paper introduces a fundamentally different approach using a dual-pathway decoder. We present SPACE-CLIP, an architecture that unlocks and interprets latent geometric knowledge directly from a frozen CLIP vision encoder, completely bypassing the text encoder and its associated textual prompts. A semantic pathway interprets high-level features, dynamically conditioned on global context using feature-wise linear modulation (FiLM). In addition, a structural pathway extracts fine-grained spatial details from early layers. These complementary streams are hierarchically fused, enabling a robust synthesis of semantic context and precise geometry. Extensive experiments on the KITTI benchmark show that SPACE-CLIP dramatically outperforms previous CLIP-based methods. Our ablation studies validate that the synergistic fusion of our dual pathways is critical to this success. SPACE-CLIP offers a new, efficient, and architecturally elegant blueprint for repurposing large-scale vision models. The proposed method is not just a standalone depth estimator, but a readily integrable spatial perception module for the next generation of embodied AI systems, such as vision-language-action (VLA) models. Our model is available at https://github.com/taewan2002/space-clip</p>"
    },
    {
      "id": "b19feb59a656",
      "title": "ViTCoP: Accelerating Large Vision-Language Models via Visual and Textual Semantic Collaborative Pruning",
      "content": "arXiv:2601.17818v1 Announce Type: new  Abstract: Large Vision-Language Models (LVLMs) incur high computational costs due to significant redundancy in their visual tokens. To effectively reduce this cost, researchers have proposed various visual token pruning methods. However, existing methods are generally limited, either losing critical visual information prematurely due to pruning in the vision encoder, or leading to information redundancy among the selected tokens due to pruning in the Large Language Models (LLMs). To address these challenges, we propose a Visual and Textual Semantic Collaborative Pruning framework (ViTCoP) that combines redundancy filtering in the vision encoder with step-wise co-pruning within the LLM based on its hierarchical characteristics, to efficiently preserve critical and informationally diverse visual tokens. Meanwhile, to ensure compatibility with acceleration techniques like FlashAttention, we introduce the L2 norm of K-vectors as the token saliency metric in the LLM. Extensive experiments on various Large Vision-Language Models demonstrate that ViTCoP not only achieves state-of-the-art performance surpassing existing methods on both image and video understanding tasks, but also significantly reduces model inference latency and GPU memory consumption. Notably, its performance advantage over other methods becomes even more pronounced under extreme pruning rates.",
      "url": "http://arxiv.org/abs/2601.17818",
      "author": "Wen Luo, Peng Chen, Xiaotao Huang, LiQun Huang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "ViTCoP introduces visual and textual semantic collaborative pruning for LVLMs, combining redundancy filtering in the vision encoder with step-wise co-pruning within the LLM to efficiently preserve critical information.",
      "importance_score": 58,
      "reasoning": "Addresses important efficiency problem for LVLMs. Practical approach combining multiple pruning strategies.",
      "themes": [
        "Vision-Language Models",
        "Efficiency",
        "Token Pruning"
      ],
      "continuation": null,
      "summary_html": "<p>ViTCoP introduces visual and textual semantic collaborative pruning for LVLMs, combining redundancy filtering in the vision encoder with step-wise co-pruning within the LLM to efficiently preserve critical information.</p>",
      "content_html": "<p>arXiv:2601.17818v1 Announce Type: new  Abstract: Large Vision-Language Models (LVLMs) incur high computational costs due to significant redundancy in their visual tokens. To effectively reduce this cost, researchers have proposed various visual token pruning methods. However, existing methods are generally limited, either losing critical visual information prematurely due to pruning in the vision encoder, or leading to information redundancy among the selected tokens due to pruning in the Large Language Models (LLMs). To address these challenges, we propose a Visual and Textual Semantic Collaborative Pruning framework (ViTCoP) that combines redundancy filtering in the vision encoder with step-wise co-pruning within the LLM based on its hierarchical characteristics, to efficiently preserve critical and informationally diverse visual tokens. Meanwhile, to ensure compatibility with acceleration techniques like FlashAttention, we introduce the L2 norm of K-vectors as the token saliency metric in the LLM. Extensive experiments on various Large Vision-Language Models demonstrate that ViTCoP not only achieves state-of-the-art performance surpassing existing methods on both image and video understanding tasks, but also significantly reduces model inference latency and GPU memory consumption. Notably, its performance advantage over other methods becomes even more pronounced under extreme pruning rates.</p>"
    },
    {
      "id": "a31ea9e79e7b",
      "title": "MV-SAM: Multi-view Promptable Segmentation using Pointmap Guidance",
      "content": "arXiv:2601.17866v1 Announce Type: new  Abstract: Promptable segmentation has emerged as a powerful paradigm in computer vision, enabling users to guide models in parsing complex scenes with prompts such as clicks, boxes, or textual cues. Recent advances, exemplified by the Segment Anything Model (SAM), have extended this paradigm to videos and multi-view images. However, the lack of 3D awareness often leads to inconsistent results, necessitating costly per-scene optimization to enforce 3D consistency. In this work, we introduce MV-SAM, a framework for multi-view segmentation that achieves 3D consistency using pointmaps -- 3D points reconstructed from unposed images by recent visual geometry models. Leveraging the pixel-point one-to-one correspondence of pointmaps, MV-SAM lifts images and prompts into 3D space, eliminating the need for explicit 3D networks or annotated 3D data. Specifically, MV-SAM extends SAM by lifting image embeddings from its pretrained encoder into 3D point embeddings, which are decoded by a transformer using cross-attention with 3D prompt embeddings. This design aligns 2D interactions with 3D geometry, enabling the model to implicitly learn consistent masks across views through 3D positional embeddings. Trained on the SA-1B dataset, our method generalizes well across domains, outperforming SAM2-Video and achieving comparable performance with per-scene optimization baselines on NVOS, SPIn-NeRF, ScanNet++, uCo3D, and DL3DV benchmarks. Code will be released.",
      "url": "http://arxiv.org/abs/2601.17866",
      "author": "Yoonwoo Jeong, Cheng Sun, Yu-Chiang Frank Wang, Minsu Cho, Jaesung Choe",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "MV-SAM achieves 3D-consistent multi-view segmentation using pointmaps from visual geometry models, enabling pixel-point correspondence lifting without costly per-scene optimization.",
      "importance_score": 58,
      "reasoning": "Extends SAM paradigm to multi-view with elegant pointmap-based approach. Practical advancement avoiding expensive optimization.",
      "themes": [
        "Segmentation",
        "Multi-view Vision",
        "3D Consistency"
      ],
      "continuation": null,
      "summary_html": "<p>MV-SAM achieves 3D-consistent multi-view segmentation using pointmaps from visual geometry models, enabling pixel-point correspondence lifting without costly per-scene optimization.</p>",
      "content_html": "<p>arXiv:2601.17866v1 Announce Type: new  Abstract: Promptable segmentation has emerged as a powerful paradigm in computer vision, enabling users to guide models in parsing complex scenes with prompts such as clicks, boxes, or textual cues. Recent advances, exemplified by the Segment Anything Model (SAM), have extended this paradigm to videos and multi-view images. However, the lack of 3D awareness often leads to inconsistent results, necessitating costly per-scene optimization to enforce 3D consistency. In this work, we introduce MV-SAM, a framework for multi-view segmentation that achieves 3D consistency using pointmaps -- 3D points reconstructed from unposed images by recent visual geometry models. Leveraging the pixel-point one-to-one correspondence of pointmaps, MV-SAM lifts images and prompts into 3D space, eliminating the need for explicit 3D networks or annotated 3D data. Specifically, MV-SAM extends SAM by lifting image embeddings from its pretrained encoder into 3D point embeddings, which are decoded by a transformer using cross-attention with 3D prompt embeddings. This design aligns 2D interactions with 3D geometry, enabling the model to implicitly learn consistent masks across views through 3D positional embeddings. Trained on the SA-1B dataset, our method generalizes well across domains, outperforming SAM2-Video and achieving comparable performance with per-scene optimization baselines on NVOS, SPIn-NeRF, ScanNet++, uCo3D, and DL3DV benchmarks. Code will be released.</p>"
    },
    {
      "id": "d66852bd6f2d",
      "title": "FlowMorph: Physics-Consistent Self-Supervision for Label-Free Single-Cell Mechanics in Microfluidic Videos",
      "content": "arXiv:2601.17947v1 Announce Type: new  Abstract: Mechanical properties of red blood cells (RBCs) are promising biomarkers for hematologic and systemic disease, motivating microfluidic assays that probe deformability at throughputs of $10^3$--$10^6$ cells per experiment. However, existing pipelines rely on supervised segmentation or hand-crafted kymographs and rarely encode the laminar Stokes-flow physics that governs RBC shape evolution. We introduce FlowMorph, a physics-consistent self-supervised framework that learns a label-free scalar mechanics proxy $k$ for each tracked RBC from short brightfield microfluidic videos. FlowMorph models each cell by a low-dimensional parametric contour, advances boundary points through a differentiable ''capsule-in-flow'' combining laminar advection and curvature-regularized elastic relaxation, and optimizes a loss coupling silhouette overlap, intra-cellular flow agreement, area conservation, wall constraints, and temporal smoothness, using only automatically derived silhouettes and optical flow.   Across four public RBC microfluidic datasets, FlowMorph achieves a mean silhouette IoU of $0.905$ on physics-rich videos with provided velocity fields and markedly improves area conservation and wall violations over purely data-driven baselines. On $\\sim 1.5\\times 10^5$ centered sequences, the scalar $k$ alone separates tank-treading from flipping dynamics with an AUC of $0.863$. Using only $200$ real-time deformability cytometry (RT-DC) events for calibration, a monotone map $E=g(k)$ predicts apparent Young's modulus with a mean absolute error of $0.118$\\,MPa on $600$ held-out cells and degrades gracefully under shifts in channel geometry, optics, and frame rate.",
      "url": "http://arxiv.org/abs/2601.17947",
      "author": "Bora Yimenicioglu, Vishal Manikanden",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "FlowMorph introduces physics-consistent self-supervised learning for red blood cell mechanics in microfluidics, combining differentiable capsule-in-flow modeling with laminar Stokes-flow physics.",
      "importance_score": 58,
      "reasoning": "Novel integration of physics-based modeling with self-supervised learning. Strong interdisciplinary approach.",
      "themes": [
        "Physics-Informed ML",
        "Cell Biology",
        "Self-Supervised Learning"
      ],
      "continuation": null,
      "summary_html": "<p>FlowMorph introduces physics-consistent self-supervised learning for red blood cell mechanics in microfluidics, combining differentiable capsule-in-flow modeling with laminar Stokes-flow physics.</p>",
      "content_html": "<p>arXiv:2601.17947v1 Announce Type: new  Abstract: Mechanical properties of red blood cells (RBCs) are promising biomarkers for hematologic and systemic disease, motivating microfluidic assays that probe deformability at throughputs of $10^3$--$10^6$ cells per experiment. However, existing pipelines rely on supervised segmentation or hand-crafted kymographs and rarely encode the laminar Stokes-flow physics that governs RBC shape evolution. We introduce FlowMorph, a physics-consistent self-supervised framework that learns a label-free scalar mechanics proxy $k$ for each tracked RBC from short brightfield microfluidic videos. FlowMorph models each cell by a low-dimensional parametric contour, advances boundary points through a differentiable ''capsule-in-flow'' combining laminar advection and curvature-regularized elastic relaxation, and optimizes a loss coupling silhouette overlap, intra-cellular flow agreement, area conservation, wall constraints, and temporal smoothness, using only automatically derived silhouettes and optical flow.   Across four public RBC microfluidic datasets, FlowMorph achieves a mean silhouette IoU of $0.905$ on physics-rich videos with provided velocity fields and markedly improves area conservation and wall violations over purely data-driven baselines. On $\\sim 1.5\\times 10^5$ centered sequences, the scalar $k$ alone separates tank-treading from flipping dynamics with an AUC of $0.863$. Using only $200$ real-time deformability cytometry (RT-DC) events for calibration, a monotone map $E=g(k)$ predicts apparent Young's modulus with a mean absolute error of $0.118$\\,MPa on $600$ held-out cells and degrades gracefully under shifts in channel geometry, optics, and frame rate.</p>"
    },
    {
      "id": "efb74cba2d5a",
      "title": "MindCine: Multimodal EEG-to-Video Reconstruction with Large-Scale Pretrained Models",
      "content": "arXiv:2601.18192v1 Announce Type: new  Abstract: Reconstructing human dynamic visual perception from electroencephalography (EEG) signals is of great research significance since EEG's non-invasiveness and high temporal resolution. However, EEG-to-video reconstruction remains challenging due to: 1) Single Modality: existing studies solely align EEG signals with the text modality, which ignores other modalities and are prone to suffer from overfitting problems; 2) Data Scarcity: current methods often have difficulty training to converge with limited EEG-video data. To solve the above problems, we propose a novel framework MindCine to achieve high-fidelity video reconstructions on limited data. We employ a multimodal joint learning strategy to incorporate beyond-text modalities in the training stage and leverage a pre-trained large EEG model to relieve the data scarcity issue for decoding semantic information, while a Seq2Seq model with causal attention is specifically designed for decoding perceptual information. Extensive experiments demonstrate that our model outperforms state-of-the-art methods both qualitatively and quantitatively. Additionally, the results underscore the effectiveness of the complementary strengths of different modalities and demonstrate that leveraging a large-scale EEG model can further enhance reconstruction performance by alleviating the challenges associated with limited data.",
      "url": "http://arxiv.org/abs/2601.18192",
      "author": "Tian-Yi Zhou, Xuan-Hao Liu, Bao-Liang Lu, Wei-Long Zheng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "MindCine achieves EEG-to-video reconstruction using multimodal joint learning beyond text alignment, incorporating visual modalities to address data scarcity and overfitting in brain decoding.",
      "importance_score": 58,
      "reasoning": "Advances brain-to-video generation with multimodal approach. Novel direction for neural decoding research.",
      "themes": [
        "Brain-Computer Interfaces",
        "Video Generation",
        "Neural Decoding"
      ],
      "continuation": null,
      "summary_html": "<p>MindCine achieves EEG-to-video reconstruction using multimodal joint learning beyond text alignment, incorporating visual modalities to address data scarcity and overfitting in brain decoding.</p>",
      "content_html": "<p>arXiv:2601.18192v1 Announce Type: new  Abstract: Reconstructing human dynamic visual perception from electroencephalography (EEG) signals is of great research significance since EEG's non-invasiveness and high temporal resolution. However, EEG-to-video reconstruction remains challenging due to: 1) Single Modality: existing studies solely align EEG signals with the text modality, which ignores other modalities and are prone to suffer from overfitting problems; 2) Data Scarcity: current methods often have difficulty training to converge with limited EEG-video data. To solve the above problems, we propose a novel framework MindCine to achieve high-fidelity video reconstructions on limited data. We employ a multimodal joint learning strategy to incorporate beyond-text modalities in the training stage and leverage a pre-trained large EEG model to relieve the data scarcity issue for decoding semantic information, while a Seq2Seq model with causal attention is specifically designed for decoding perceptual information. Extensive experiments demonstrate that our model outperforms state-of-the-art methods both qualitatively and quantitatively. Additionally, the results underscore the effectiveness of the complementary strengths of different modalities and demonstrate that leveraging a large-scale EEG model can further enhance reconstruction performance by alleviating the challenges associated with limited data.</p>"
    },
    {
      "id": "15301d2decde",
      "title": "On Procrustes Contamination in Machine Learning Applications of Geometric Morphometrics",
      "content": "arXiv:2601.18448v1 Announce Type: new  Abstract: Geometric morphometrics (GMM) is widely used to quantify shape variation, more recently serving as input for machine learning (ML) analyses. Standard practice aligns all specimens via Generalized Procrustes Analysis (GPA) prior to splitting data into training and test sets, potentially introducing statistical dependence and contaminating downstream predictive models. Here, the effects of GPA-induced contamination are formally characterised using controlled 2D and 3D simulations across varying sample sizes, landmark densities, and allometric patterns. A novel realignment procedure is proposed, whereby test specimens are aligned to the training set prior to model fitting, eliminating cross-sample dependency. Simulations reveal a robust \"diagonal\" in sample-size vs. landmark-space, reflecting the scaling of RMSE under isotropic variation, with slopes analytically derived from the degrees of freedom in Procrustes tangent space. The importance of spatial autocorrelation among landmarks is further demonstrated using linear and convolutional regression models, highlighting performance degradation when landmark relationships are ignored. This work establishes the need for careful preprocessing in ML applications of GMM, provides practical guidelines for realignment, and clarifies fundamental statistical constraints inherent to Procrustes shape space.",
      "url": "http://arxiv.org/abs/2601.18448",
      "author": "Lloyd Austin Courtenay",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Identifies Procrustes contamination in machine learning applications of geometric morphometrics where GPA before train/test split introduces statistical dependence, and proposes realignment procedure.",
      "importance_score": 58,
      "reasoning": "Important methodological finding identifying common but overlooked data leakage issue. Valuable for correct ML practice.",
      "themes": [
        "Methodology",
        "Data Leakage",
        "Shape Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Identifies Procrustes contamination in machine learning applications of geometric morphometrics where GPA before train/test split introduces statistical dependence, and proposes realignment procedure.</p>",
      "content_html": "<p>arXiv:2601.18448v1 Announce Type: new  Abstract: Geometric morphometrics (GMM) is widely used to quantify shape variation, more recently serving as input for machine learning (ML) analyses. Standard practice aligns all specimens via Generalized Procrustes Analysis (GPA) prior to splitting data into training and test sets, potentially introducing statistical dependence and contaminating downstream predictive models. Here, the effects of GPA-induced contamination are formally characterised using controlled 2D and 3D simulations across varying sample sizes, landmark densities, and allometric patterns. A novel realignment procedure is proposed, whereby test specimens are aligned to the training set prior to model fitting, eliminating cross-sample dependency. Simulations reveal a robust \"diagonal\" in sample-size vs. landmark-space, reflecting the scaling of RMSE under isotropic variation, with slopes analytically derived from the degrees of freedom in Procrustes tangent space. The importance of spatial autocorrelation among landmarks is further demonstrated using linear and convolutional regression models, highlighting performance degradation when landmark relationships are ignored. This work establishes the need for careful preprocessing in ML applications of GMM, provides practical guidelines for realignment, and clarifies fundamental statistical constraints inherent to Procrustes shape space.</p>"
    },
    {
      "id": "2885f39a3910",
      "title": "DisasterInsight: A Multimodal Benchmark for Function-Aware and Grounded Disaster Assessment",
      "content": "arXiv:2601.18493v1 Announce Type: new  Abstract: Timely interpretation of satellite imagery is critical for disaster response, yet existing vision-language benchmarks for remote sensing largely focus on coarse labels and image-level recognition, overlooking the functional understanding and instruction robustness required in real humanitarian workflows. We introduce DisasterInsight, a multimodal benchmark designed to evaluate vision-language models (VLMs) on realistic disaster analysis tasks. DisasterInsight restructures the xBD dataset into approximately 112K building-centered instances and supports instruction-diverse evaluation across multiple tasks, including building-function classification, damage-level and disaster-type classification, counting, and structured report generation aligned with humanitarian assessment guidelines.   To establish domain-adapted baselines, we propose DI-Chat, obtained by fine-tuning existing VLM backbones on disaster-specific instruction data using parameter-efficient Low-Rank Adaptation (LoRA). Extensive experiments on state-of-the-art generic and remote-sensing VLMs reveal substantial performance gaps across tasks, particularly in damage understanding and structured report generation. DI-Chat achieves significant improvements on damage-level and disaster-type classification as well as report generation quality, while building-function classification remains challenging for all evaluated models. DisasterInsight provides a unified benchmark for studying grounded multimodal reasoning in disaster imagery.",
      "url": "http://arxiv.org/abs/2601.18493",
      "author": "Sara Tehrani, Yonghao Xu, Leif Haglund, Amanda Berg, Michael Felsberg",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "DisasterInsight introduces multimodal benchmark for VLM disaster assessment with 112K building-centered instances from xBD, supporting function-aware evaluation for humanitarian response.",
      "importance_score": 58,
      "reasoning": "Important benchmark for disaster response AI. Practical humanitarian application with thorough evaluation framework.",
      "themes": [
        "Disaster Response",
        "Benchmarks",
        "Remote Sensing",
        "VLMs"
      ],
      "continuation": null,
      "summary_html": "<p>DisasterInsight introduces multimodal benchmark for VLM disaster assessment with 112K building-centered instances from xBD, supporting function-aware evaluation for humanitarian response.</p>",
      "content_html": "<p>arXiv:2601.18493v1 Announce Type: new  Abstract: Timely interpretation of satellite imagery is critical for disaster response, yet existing vision-language benchmarks for remote sensing largely focus on coarse labels and image-level recognition, overlooking the functional understanding and instruction robustness required in real humanitarian workflows. We introduce DisasterInsight, a multimodal benchmark designed to evaluate vision-language models (VLMs) on realistic disaster analysis tasks. DisasterInsight restructures the xBD dataset into approximately 112K building-centered instances and supports instruction-diverse evaluation across multiple tasks, including building-function classification, damage-level and disaster-type classification, counting, and structured report generation aligned with humanitarian assessment guidelines.   To establish domain-adapted baselines, we propose DI-Chat, obtained by fine-tuning existing VLM backbones on disaster-specific instruction data using parameter-efficient Low-Rank Adaptation (LoRA). Extensive experiments on state-of-the-art generic and remote-sensing VLMs reveal substantial performance gaps across tasks, particularly in damage understanding and structured report generation. DI-Chat achieves significant improvements on damage-level and disaster-type classification as well as report generation quality, while building-function classification remains challenging for all evaluated models. DisasterInsight provides a unified benchmark for studying grounded multimodal reasoning in disaster imagery.</p>"
    },
    {
      "id": "2357907d8a9b",
      "title": "Grasp-and-Lift: Executable 3D Hand-Object Interaction Reconstruction via Physics-in-the-Loop Optimization",
      "content": "arXiv:2601.18121v1 Announce Type: cross  Abstract: Dexterous hand manipulation increasingly relies on large-scale motion datasets with precise hand-object trajectory data. However, existing resources such as DexYCB and HO3D are primarily optimized for visual alignment but often yield physically implausible interactions when replayed in physics simulators, including penetration, missed contact, and unstable grasps.   We propose a simulation-in-the-loop refinement framework that converts these visually aligned trajectories into physically executable ones. Our core contribution is to formulate this as a tractable black-box optimization problem. We parameterize the hand's motion using a low-dimensional, spline-based representation built on sparse temporal keyframes. This allows us to use a powerful gradient-free optimizer, CMA-ES, to treat the high-fidelity physics engine as a black-box objective function. Our method finds motions that simultaneously maximize physical success (e.g., stable grasp and lift) while minimizing deviation from the original human demonstration.   Compared to MANIPTRANS-recent transfer pipelines, our approach achieves lower hand and object pose errors during replay and more accurately recovers hand-object physical interactions. Our approach provides a general and scalable method for converting visual demonstrations into physically valid trajectories, enabling the generation of high-fidelity data crucial for robust policy learning.",
      "url": "http://arxiv.org/abs/2601.18121",
      "author": "Byeonggyeol Choi, Woojin Oh, Jongwoo Lim",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Introduces simulation-in-the-loop refinement framework to convert visually aligned hand-object trajectories into physically executable ones using black-box optimization with spline-based parameterization.",
      "importance_score": 58,
      "reasoning": "Addresses important gap between visual and physical plausibility in manipulation datasets, practical contribution for robotics data.",
      "themes": [
        "Robotics",
        "Physics Simulation",
        "Hand-Object Interaction",
        "Data Quality"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces simulation-in-the-loop refinement framework to convert visually aligned hand-object trajectories into physically executable ones using black-box optimization with spline-based parameterization.</p>",
      "content_html": "<p>arXiv:2601.18121v1 Announce Type: cross  Abstract: Dexterous hand manipulation increasingly relies on large-scale motion datasets with precise hand-object trajectory data. However, existing resources such as DexYCB and HO3D are primarily optimized for visual alignment but often yield physically implausible interactions when replayed in physics simulators, including penetration, missed contact, and unstable grasps.   We propose a simulation-in-the-loop refinement framework that converts these visually aligned trajectories into physically executable ones. Our core contribution is to formulate this as a tractable black-box optimization problem. We parameterize the hand's motion using a low-dimensional, spline-based representation built on sparse temporal keyframes. This allows us to use a powerful gradient-free optimizer, CMA-ES, to treat the high-fidelity physics engine as a black-box objective function. Our method finds motions that simultaneously maximize physical success (e.g., stable grasp and lift) while minimizing deviation from the original human demonstration.   Compared to MANIPTRANS-recent transfer pipelines, our approach achieves lower hand and object pose errors during replay and more accurately recovers hand-object physical interactions. Our approach provides a general and scalable method for converting visual demonstrations into physically valid trajectories, enabling the generation of high-fidelity data crucial for robust policy learning.</p>"
    },
    {
      "id": "5a353749a922",
      "title": "EMPM: Embodied MPM for Modeling and Simulation of Deformable Objects",
      "content": "arXiv:2601.17251v1 Announce Type: new  Abstract: Modeling deformable objects - especially continuum materials - in a way that is physically plausible, generalizable, and data-efficient remains challenging across 3D vision, graphics, and robotic manipulation. Many existing methods oversimplify the rich dynamics of deformable objects or require large training sets, which often limits generalization. We introduce embodied MPM (EMPM), a deformable object modeling and simulation framework built on a differentiable Material Point Method (MPM) simulator that captures the dynamics of challenging materials. From multi-view RGB-D videos, our approach reconstructs geometry and appearance, then uses an MPM physics engine to simulate object behavior by minimizing the mismatch between predicted and observed visual data. We further optimize MPM parameters online using sensory feedback, enabling adaptive, robust, and physics-aware object representations that open new possibilities for robotic manipulation of complex deformables. Experiments show that EMPM outperforms spring-mass baseline models. Project website: https://embodied-mpm.github.io.",
      "url": "http://arxiv.org/abs/2601.17251",
      "author": "Yunuo Chen, Yafei Hu, Lingfeng Sun, Tushar Kusnur, Laura Herlant, Chenfanfu Jiang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Introduces EMPM, a differentiable MPM-based framework for modeling deformable objects from multi-view RGB-D videos with physics simulation for robotic manipulation.",
      "importance_score": 58,
      "reasoning": "Addresses challenging deformable object modeling with physics-based approach, practical for robot manipulation.",
      "themes": [
        "Physics Simulation",
        "Deformable Objects",
        "Robot Manipulation"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces EMPM, a differentiable MPM-based framework for modeling deformable objects from multi-view RGB-D videos with physics simulation for robotic manipulation.</p>",
      "content_html": "<p>arXiv:2601.17251v1 Announce Type: new  Abstract: Modeling deformable objects - especially continuum materials - in a way that is physically plausible, generalizable, and data-efficient remains challenging across 3D vision, graphics, and robotic manipulation. Many existing methods oversimplify the rich dynamics of deformable objects or require large training sets, which often limits generalization. We introduce embodied MPM (EMPM), a deformable object modeling and simulation framework built on a differentiable Material Point Method (MPM) simulator that captures the dynamics of challenging materials. From multi-view RGB-D videos, our approach reconstructs geometry and appearance, then uses an MPM physics engine to simulate object behavior by minimizing the mismatch between predicted and observed visual data. We further optimize MPM parameters online using sensory feedback, enabling adaptive, robust, and physics-aware object representations that open new possibilities for robotic manipulation of complex deformables. Experiments show that EMPM outperforms spring-mass baseline models. Project website: https://embodied-mpm.github.io.</p>"
    },
    {
      "id": "c8b412003a2f",
      "title": "SG-CADVLM: A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation",
      "content": "arXiv:2601.18442v1 Announce Type: new  Abstract: Autonomous vehicle safety validation requires testing on safety-critical scenarios, but these events are rare in real-world driving and costly to test due to collision risks. Crash reports provide authentic specifications of safety-critical events, offering a vital alternative to scarce real-world collision trajectory data. This makes them valuable sources for generating realistic high-risk scenarios through simulation. Existing approaches face significant limitations because data-driven methods lack diversity due to their reliance on existing latent distributions, whereas adversarial methods often produce unrealistic scenarios lacking physical fidelity. Large Language Model (LLM) and Vision Language Model (VLM)-based methods show significant promise. However, they suffer from context suppression issues where internal parametric knowledge overrides crash specifications, producing scenarios that deviate from actual accident characteristics. This paper presents SG-CADVLM (A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation), a framework that integrates Context-Aware Decoding with multi-modal input processing to generate safety-critical scenarios from crash reports and road network diagrams. The framework mitigates VLM hallucination issues while enabling the simultaneous generation of road geometry and vehicle trajectories. The experimental results demonstrate that SG-CADVLM generates critical risk scenarios at a rate of 84.4% compared to 12.5% for the baseline methods, representing an improvement of 469%, while producing executable simulations for autonomous vehicle testing.",
      "url": "http://arxiv.org/abs/2601.18442",
      "author": "Hongyi Zhao, Shuo Wang, Qijie He, Ziyuan Pu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes SG-CADVLM using context-aware decoding with VLMs for generating realistic safety-critical scenarios for autonomous vehicle validation from crash reports.",
      "importance_score": 58,
      "reasoning": "Addresses important AV safety validation challenge with VLM-based approach, practical application.",
      "themes": [
        "Autonomous Vehicles",
        "Safety Validation",
        "VLM Applications",
        "Scenario Generation"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes SG-CADVLM using context-aware decoding with VLMs for generating realistic safety-critical scenarios for autonomous vehicle validation from crash reports.</p>",
      "content_html": "<p>arXiv:2601.18442v1 Announce Type: new  Abstract: Autonomous vehicle safety validation requires testing on safety-critical scenarios, but these events are rare in real-world driving and costly to test due to collision risks. Crash reports provide authentic specifications of safety-critical events, offering a vital alternative to scarce real-world collision trajectory data. This makes them valuable sources for generating realistic high-risk scenarios through simulation. Existing approaches face significant limitations because data-driven methods lack diversity due to their reliance on existing latent distributions, whereas adversarial methods often produce unrealistic scenarios lacking physical fidelity. Large Language Model (LLM) and Vision Language Model (VLM)-based methods show significant promise. However, they suffer from context suppression issues where internal parametric knowledge overrides crash specifications, producing scenarios that deviate from actual accident characteristics. This paper presents SG-CADVLM (A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation), a framework that integrates Context-Aware Decoding with multi-modal input processing to generate safety-critical scenarios from crash reports and road network diagrams. The framework mitigates VLM hallucination issues while enabling the simultaneous generation of road geometry and vehicle trajectories. The experimental results demonstrate that SG-CADVLM generates critical risk scenarios at a rate of 84.4% compared to 12.5% for the baseline methods, representing an improvement of 469%, while producing executable simulations for autonomous vehicle testing.</p>"
    },
    {
      "id": "1a199e086011",
      "title": "EvolVE: Evolutionary Search for LLM-based Verilog Generation and Optimization",
      "content": "arXiv:2601.18067v1 Announce Type: new  Abstract: Verilog's design cycle is inherently labor-intensive and necessitates extensive domain expertise. Although Large Language Models (LLMs) offer a promising pathway toward automation, their limited training data and intrinsic sequential reasoning fail to capture the strict formal logic and concurrency inherent in hardware systems. To overcome these barriers, we present EvolVE, the first framework to analyze multiple evolution strategies on chip design tasks, revealing that Monte Carlo Tree Search (MCTS) excels at maximizing functional correctness, while Idea-Guided Refinement (IGR) proves superior for optimization. We further leverage Structured Testbench Generation (STG) to accelerate the evolutionary process. To address the lack of complex optimization benchmarks, we introduce IC-RTL, targeting industry-scale problems derived from the National Integrated Circuit Contest. Evaluations establish EvolVE as the new state-of-the-art, achieving 98.1% on VerilogEval v2 and 92% on RTLLM v2. Furthermore, on the industry-scale IC-RTL suite, our framework surpasses reference implementations authored by contest participants, reducing the Power, Performance, Area (PPA) product by up to 66% in Huffman Coding and 17% in the geometric mean across all problems. The source code of the IC-RTL benchmark is available at https://github.com/weiber2002/ICRTL.",
      "url": "http://arxiv.org/abs/2601.18067",
      "author": "Wei-Po Hsin, Ren-Hao Deng, Yao-Ting Hsieh, En-Ming Huang, Shih-Hao Hung",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Presents EvolVE, first framework comparing evolution strategies for Verilog generation, finding MCTS excels at correctness while Idea-Guided Refinement is superior for optimization.",
      "importance_score": 57,
      "reasoning": "Useful comparison of search strategies for hardware design; practical insights for important application area.",
      "themes": [
        "Code Generation",
        "Hardware Design",
        "Search Methods"
      ],
      "continuation": null,
      "summary_html": "<p>Presents EvolVE, first framework comparing evolution strategies for Verilog generation, finding MCTS excels at correctness while Idea-Guided Refinement is superior for optimization.</p>",
      "content_html": "<p>arXiv:2601.18067v1 Announce Type: new  Abstract: Verilog's design cycle is inherently labor-intensive and necessitates extensive domain expertise. Although Large Language Models (LLMs) offer a promising pathway toward automation, their limited training data and intrinsic sequential reasoning fail to capture the strict formal logic and concurrency inherent in hardware systems. To overcome these barriers, we present EvolVE, the first framework to analyze multiple evolution strategies on chip design tasks, revealing that Monte Carlo Tree Search (MCTS) excels at maximizing functional correctness, while Idea-Guided Refinement (IGR) proves superior for optimization. We further leverage Structured Testbench Generation (STG) to accelerate the evolutionary process. To address the lack of complex optimization benchmarks, we introduce IC-RTL, targeting industry-scale problems derived from the National Integrated Circuit Contest. Evaluations establish EvolVE as the new state-of-the-art, achieving 98.1% on VerilogEval v2 and 92% on RTLLM v2. Furthermore, on the industry-scale IC-RTL suite, our framework surpasses reference implementations authored by contest participants, reducing the Power, Performance, Area (PPA) product by up to 66% in Huffman Coding and 17% in the geometric mean across all problems. The source code of the IC-RTL benchmark is available at https://github.com/weiber2002/ICRTL.</p>"
    },
    {
      "id": "821f1165c54d",
      "title": "PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression",
      "content": "arXiv:2601.18608v1 Announce Type: new  Abstract: Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets.   In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent.   Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic.",
      "url": "http://arxiv.org/abs/2601.18608",
      "author": "Fabian Fumagalli, R. Teal Witter, Christopher Musco",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Extends KernelSHAP by approximating games via higher degree polynomials capturing feature interactions, yielding PolySHAP with empirically better Shapley estimates and theoretical guarantees.",
      "importance_score": 57,
      "reasoning": "Solid methodological improvement to popular explainability method; theoretical grounding with practical benefits.",
      "themes": [
        "Explainability",
        "Shapley Values",
        "XAI"
      ],
      "continuation": null,
      "summary_html": "<p>Extends KernelSHAP by approximating games via higher degree polynomials capturing feature interactions, yielding PolySHAP with empirically better Shapley estimates and theoretical guarantees.</p>",
      "content_html": "<p>arXiv:2601.18608v1 Announce Type: new  Abstract: Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets.   In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent.   Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic.</p>"
    },
    {
      "id": "67fe77363c06",
      "title": "A Model-Driven Lossless Compression Algorithm Resistant to Mismatch",
      "content": "arXiv:2601.17684v1 Announce Type: cross  Abstract: Due to the fundamental connection between next-symbol prediction and compression, modern predictive models, such as large language models (LLMs), can be combined with entropy coding to achieve compression rates that surpass those of standard compression algorithms. However, this approach relies on the assumption that the predictive model produces identical output distributions at both the encoder and decoder, since even small mismatches can cause the decoding to fail. This assumption often fails with complex predictive models, particularly those based on neural networks, a phenomenon referred to as non-determinism.   In this work, we propose a new compression algorithm based on next-token prediction that is robust to arbitrarily large, but structured, prediction mismatches. We prove the correctness of the proposed scheme under a formal mismatch certification, characterize its theoretical performance, and validate it experimentally on real datasets. Our results demonstrate reliable operation within the certified mismatch regime while achieving compression ratios that exceed those of commonly used compression methods.",
      "url": "http://arxiv.org/abs/2601.17684",
      "author": "Cordelia Hu, Jennifer Tang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.IT"
      ],
      "summary": "Proposes compression algorithm using next-token prediction that is robust to arbitrarily large model output mismatches between encoder and decoder, addressing non-determinism.",
      "importance_score": 57,
      "reasoning": "Addresses practical problem of neural compression with non-deterministic models. Theoretical contribution on mismatch robustness.",
      "themes": [
        "Neural Compression",
        "Language Models",
        "Robustness"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes compression algorithm using next-token prediction that is robust to arbitrarily large model output mismatches between encoder and decoder, addressing non-determinism.</p>",
      "content_html": "<p>arXiv:2601.17684v1 Announce Type: cross  Abstract: Due to the fundamental connection between next-symbol prediction and compression, modern predictive models, such as large language models (LLMs), can be combined with entropy coding to achieve compression rates that surpass those of standard compression algorithms. However, this approach relies on the assumption that the predictive model produces identical output distributions at both the encoder and decoder, since even small mismatches can cause the decoding to fail. This assumption often fails with complex predictive models, particularly those based on neural networks, a phenomenon referred to as non-determinism.   In this work, we propose a new compression algorithm based on next-token prediction that is robust to arbitrarily large, but structured, prediction mismatches. We prove the correctness of the proposed scheme under a formal mismatch certification, characterize its theoretical performance, and validate it experimentally on real datasets. Our results demonstrate reliable operation within the certified mismatch regime while achieving compression ratios that exceed those of commonly used compression methods.</p>"
    },
    {
      "id": "541fc3b1b262",
      "title": "Assessment of Generative Named Entity Recognition in the Era of Large Language Models",
      "content": "arXiv:2601.17898v1 Announce Type: new  Abstract: Named entity recognition (NER) is evolving from a sequence labeling task into a generative paradigm with the rise of large language models (LLMs). We conduct a systematic evaluation of open-source LLMs on both flat and nested NER tasks. We investigate several research questions including the performance gap between generative NER and traditional NER models, the impact of output formats, whether LLMs rely on memorization, and the preservation of general capabilities after fine-tuning. Through experiments across eight LLMs of varying scales and four standard NER datasets, we find that: (1) With parameter-efficient fine-tuning and structured formats like inline bracketed or XML, open-source LLMs achieve performance competitive with traditional encoder-based models and surpass closed-source LLMs like GPT-3; (2) The NER capability of LLMs stems from instruction-following and generative power, not mere memorization of entity-label pairs; and (3) Applying NER instruction tuning has minimal impact on general capabilities of LLMs, even improving performance on datasets like DROP due to enhanced entity understanding. These findings demonstrate that generative NER with LLMs is a promising, user-friendly alternative to traditional methods. We release the data and code at https://github.com/szu-tera/LLMs4NER.",
      "url": "http://arxiv.org/abs/2601.17898",
      "author": "Qi Zhan, Yile Wang, Hui Huang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Systematic evaluation of open-source LLMs on flat and nested NER tasks across eight models and four datasets. Finds PEFT fine-tuned LLMs achieve competitive performance with traditional NER models.",
      "importance_score": 57,
      "reasoning": "Useful empirical study validating LLMs for NER. Comprehensive evaluation but limited novelty in methodology.",
      "themes": [
        "Named Entity Recognition",
        "Language Models",
        "Evaluation"
      ],
      "continuation": null,
      "summary_html": "<p>Systematic evaluation of open-source LLMs on flat and nested NER tasks across eight models and four datasets. Finds PEFT fine-tuned LLMs achieve competitive performance with traditional NER models.</p>",
      "content_html": "<p>arXiv:2601.17898v1 Announce Type: new  Abstract: Named entity recognition (NER) is evolving from a sequence labeling task into a generative paradigm with the rise of large language models (LLMs). We conduct a systematic evaluation of open-source LLMs on both flat and nested NER tasks. We investigate several research questions including the performance gap between generative NER and traditional NER models, the impact of output formats, whether LLMs rely on memorization, and the preservation of general capabilities after fine-tuning. Through experiments across eight LLMs of varying scales and four standard NER datasets, we find that: (1) With parameter-efficient fine-tuning and structured formats like inline bracketed or XML, open-source LLMs achieve performance competitive with traditional encoder-based models and surpass closed-source LLMs like GPT-3; (2) The NER capability of LLMs stems from instruction-following and generative power, not mere memorization of entity-label pairs; and (3) Applying NER instruction tuning has minimal impact on general capabilities of LLMs, even improving performance on datasets like DROP due to enhanced entity understanding. These findings demonstrate that generative NER with LLMs is a promising, user-friendly alternative to traditional methods. We release the data and code at https://github.com/szu-tera/LLMs4NER.</p>"
    },
    {
      "id": "83a333b4ed28",
      "title": "BMDS-Net: A Bayesian Multi-Modal Deep Supervision Network for Robust Brain Tumor Segmentation",
      "content": "arXiv:2601.17504v1 Announce Type: new  Abstract: Accurate brain tumor segmentation from multi-modal magnetic resonance imaging (MRI) is a prerequisite for precise radiotherapy planning and surgical navigation. While recent Transformer-based models such as Swin UNETR have achieved impressive benchmark performance, their clinical utility is often compromised by two critical issues: sensitivity to missing modalities (common in clinical practice) and a lack of confidence calibration. Merely chasing higher Dice scores on idealized data fails to meet the safety requirements of real-world medical deployment. In this work, we propose BMDS-Net, a unified framework that prioritizes clinical robustness and trustworthiness over simple metric maximization. Our contribution is three-fold. First, we construct a robust deterministic backbone by integrating a Zero-Init Multimodal Contextual Fusion (MMCF) module and a Residual-Gated Deep Decoder Supervision (DDS) mechanism, enabling stable feature learning and precise boundary delineation with significantly reduced Hausdorff Distance, even under modality corruption. Second, and most importantly, we introduce a memory-efficient Bayesian fine-tuning strategy that transforms the network into a probabilistic predictor, providing voxel-wise uncertainty maps to highlight potential errors for clinicians. Third, comprehensive experiments on the BraTS 2021 dataset demonstrate that BMDS-Net not only maintains competitive accuracy but, more importantly, exhibits superior stability in missing-modality scenarios where baseline models fail. The source code is publicly available at https://github.com/RyanZhou168/BMDS-Net.",
      "url": "http://arxiv.org/abs/2601.17504",
      "author": "Yan Zhou, Zhen Huang, Yingqiu Li, Yue Ouyang, Suncheng Xiang, Zehua Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes BMDS-Net for brain tumor segmentation prioritizing robustness to missing modalities and confidence calibration over simple metric maximization, using Bayesian deep supervision.",
      "importance_score": 57,
      "reasoning": "Addresses important clinical deployment concerns (missing modalities, calibration) beyond benchmark performance.",
      "themes": [
        "Medical Image Segmentation",
        "Brain Tumor",
        "Uncertainty",
        "Robustness"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes BMDS-Net for brain tumor segmentation prioritizing robustness to missing modalities and confidence calibration over simple metric maximization, using Bayesian deep supervision.</p>",
      "content_html": "<p>arXiv:2601.17504v1 Announce Type: new  Abstract: Accurate brain tumor segmentation from multi-modal magnetic resonance imaging (MRI) is a prerequisite for precise radiotherapy planning and surgical navigation. While recent Transformer-based models such as Swin UNETR have achieved impressive benchmark performance, their clinical utility is often compromised by two critical issues: sensitivity to missing modalities (common in clinical practice) and a lack of confidence calibration. Merely chasing higher Dice scores on idealized data fails to meet the safety requirements of real-world medical deployment. In this work, we propose BMDS-Net, a unified framework that prioritizes clinical robustness and trustworthiness over simple metric maximization. Our contribution is three-fold. First, we construct a robust deterministic backbone by integrating a Zero-Init Multimodal Contextual Fusion (MMCF) module and a Residual-Gated Deep Decoder Supervision (DDS) mechanism, enabling stable feature learning and precise boundary delineation with significantly reduced Hausdorff Distance, even under modality corruption. Second, and most importantly, we introduce a memory-efficient Bayesian fine-tuning strategy that transforms the network into a probabilistic predictor, providing voxel-wise uncertainty maps to highlight potential errors for clinicians. Third, comprehensive experiments on the BraTS 2021 dataset demonstrate that BMDS-Net not only maintains competitive accuracy but, more importantly, exhibits superior stability in missing-modality scenarios where baseline models fail. The source code is publicly available at https://github.com/RyanZhou168/BMDS-Net.</p>"
    },
    {
      "id": "5ae46dcef6bb",
      "title": "Evolving Interdependent Operators with Large Language Models for Multi-Objective Combinatorial Optimization",
      "content": "arXiv:2601.17899v1 Announce Type: new  Abstract: Neighborhood search operators are critical to the performance of Multi-Objective Evolutionary Algorithms (MOEAs) and rely heavily on expert design. Although recent LLM-based Automated Heuristic Design (AHD) methods have made notable progress, they primarily optimize individual heuristics or components independently, lacking explicit exploration and exploitation of dynamic coupling relationships between multiple operators. In this paper, multi-operator optimization in MOEAs is formulated as a Markov decision process, enabling the improvement of interdependent operators through sequential decision-making. To address this, we propose the Evolution of Operator Combination (E2OC) framework for MOEAs, which achieves the co-evolution of design strategies and executable codes. E2OC employs Monte Carlo Tree Search to progressively search combinations of operator design strategies and adopts an operator rotation mechanism to identify effective operator configurations while supporting the integration of mainstream AHD methods as the underlying designer. Experimental results across AHD tasks with varying objectives and problem scales show that E2OC consistently outperforms state-of-the-art AHD and other multi-heuristic co-design frameworks, demonstrating strong generalization and sustained optimization capability.",
      "url": "http://arxiv.org/abs/2601.17899",
      "author": "Junhao Qiu, Xin Chen, Liang Ge, Liyong Lin, Zhichao Lu, Qingfu Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "cs.NE"
      ],
      "summary": "Proposes E2OC framework using LLMs to evolve interdependent operators for multi-objective evolutionary algorithms through sequential decision-making formulation.",
      "importance_score": 57,
      "reasoning": "Novel integration of LLMs into MOEA operator design, extends emerging LLM-for-algorithm-design research direction.",
      "themes": [
        "LLM-Assisted Optimization",
        "Evolutionary Algorithms",
        "Automated Algorithm Design"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes E2OC framework using LLMs to evolve interdependent operators for multi-objective evolutionary algorithms through sequential decision-making formulation.</p>",
      "content_html": "<p>arXiv:2601.17899v1 Announce Type: new  Abstract: Neighborhood search operators are critical to the performance of Multi-Objective Evolutionary Algorithms (MOEAs) and rely heavily on expert design. Although recent LLM-based Automated Heuristic Design (AHD) methods have made notable progress, they primarily optimize individual heuristics or components independently, lacking explicit exploration and exploitation of dynamic coupling relationships between multiple operators. In this paper, multi-operator optimization in MOEAs is formulated as a Markov decision process, enabling the improvement of interdependent operators through sequential decision-making. To address this, we propose the Evolution of Operator Combination (E2OC) framework for MOEAs, which achieves the co-evolution of design strategies and executable codes. E2OC employs Monte Carlo Tree Search to progressively search combinations of operator design strategies and adopts an operator rotation mechanism to identify effective operator configurations while supporting the integration of mainstream AHD methods as the underlying designer. Experimental results across AHD tasks with varying objectives and problem scales show that E2OC consistently outperforms state-of-the-art AHD and other multi-heuristic co-design frameworks, demonstrating strong generalization and sustained optimization capability.</p>"
    },
    {
      "id": "ec114cf40ca0",
      "title": "Less Is More: Scalable Visual Navigation from Limited Data",
      "content": "arXiv:2601.17815v1 Announce Type: new  Abstract: Imitation learning provides a powerful framework for goal-conditioned visual navigation in mobile robots, enabling obstacle avoidance while respecting human preferences and social norms. However, its effectiveness depends critically on the quality and diversity of training data. In this work, we show how classical geometric planners can be leveraged to generate synthetic trajectories that complement costly human demonstrations. We train Less is More (LiMo), a transformer-based visual navigation policy that predicts goal-conditioned SE(2) trajectories from a single RGB observation, and find that augmenting limited expert demonstrations with planner-generated supervision yields substantial performance gains. Through ablations and complementary qualitative and quantitative analyses, we characterize how dataset scale and diversity affect planning performance. We demonstrate real-robot deployment and argue that robust visual navigation is enabled not by simply collecting more demonstrations, but by strategically curating diverse, high-quality datasets. Our results suggest that scalable, embodiment-specific geometric supervision is a practical path toward data-efficient visual navigation.",
      "url": "http://arxiv.org/abs/2601.17815",
      "author": "Yves Inglin, Jonas Frey, Changan Chen, Marco Hutter",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Introduces LiMo, showing that augmenting limited expert demonstrations with geometric planner-generated synthetic trajectories yields substantial performance gains for visual navigation.",
      "importance_score": 57,
      "reasoning": "Practical approach to data efficiency in imitation learning, demonstrates value of synthetic data augmentation.",
      "themes": [
        "Imitation Learning",
        "Visual Navigation",
        "Data Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces LiMo, showing that augmenting limited expert demonstrations with geometric planner-generated synthetic trajectories yields substantial performance gains for visual navigation.</p>",
      "content_html": "<p>arXiv:2601.17815v1 Announce Type: new  Abstract: Imitation learning provides a powerful framework for goal-conditioned visual navigation in mobile robots, enabling obstacle avoidance while respecting human preferences and social norms. However, its effectiveness depends critically on the quality and diversity of training data. In this work, we show how classical geometric planners can be leveraged to generate synthetic trajectories that complement costly human demonstrations. We train Less is More (LiMo), a transformer-based visual navigation policy that predicts goal-conditioned SE(2) trajectories from a single RGB observation, and find that augmenting limited expert demonstrations with planner-generated supervision yields substantial performance gains. Through ablations and complementary qualitative and quantitative analyses, we characterize how dataset scale and diversity affect planning performance. We demonstrate real-robot deployment and argue that robust visual navigation is enabled not by simply collecting more demonstrations, but by strategically curating diverse, high-quality datasets. Our results suggest that scalable, embodiment-specific geometric supervision is a practical path toward data-efficient visual navigation.</p>"
    },
    {
      "id": "2bdbf82f2655",
      "title": "The LLM Data Auditor: A Metric-oriented Survey on Quality and Trustworthiness in Evaluating Synthetic Data",
      "content": "arXiv:2601.17717v1 Announce Type: new  Abstract: Large Language Models (LLMs) have emerged as powerful tools for generating data across various modalities. By transforming data from a scarce resource into a controllable asset, LLMs mitigate the bottlenecks imposed by the acquisition costs of real-world data for model training, evaluation, and system iteration. However, ensuring the high quality of LLM-generated synthetic data remains a critical challenge. Existing research primarily focuses on generation methodologies, with limited direct attention to the quality of the resulting data. Furthermore, most studies are restricted to single modalities, lacking a unified perspective across different data types. To bridge this gap, we propose the \\textbf{LLM Data Auditor framework}. In this framework, we first describe how LLMs are utilized to generate data across six distinct modalities. More importantly, we systematically categorize intrinsic metrics for evaluating synthetic data from two dimensions: quality and trustworthiness. This approach shifts the focus from extrinsic evaluation, which relies on downstream task performance, to the inherent properties of the data itself. Using this evaluation system, we analyze the experimental evaluations of representative generation methods for each modality and identify substantial deficiencies in current evaluation practices. Based on these findings, we offer concrete recommendations for the community to improve the evaluation of data generation. Finally, the framework outlines methodologies for the practical application of synthetic data across different modalities.",
      "url": "http://arxiv.org/abs/2601.17717",
      "author": "Kaituo Zhang, Mingzhi Hu, Hoang Anh Duy Le, Fariha Kabir Torsha, Zhimeng Jiang, Minh Khai Bui, Chia-Yuan Chang, Yu-Neng Chuang, Zhen Xiong, Ying Lin, Guanchu Wang, Na Zou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes the LLM Data Auditor framework providing a unified perspective on evaluating quality and trustworthiness of LLM-generated synthetic data across modalities.",
      "importance_score": 56,
      "reasoning": "Useful survey/framework for important problem of synthetic data quality; organizational contribution rather than technical innovation.",
      "themes": [
        "Synthetic Data",
        "Data Quality",
        "LLM Evaluation"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes the LLM Data Auditor framework providing a unified perspective on evaluating quality and trustworthiness of LLM-generated synthetic data across modalities.</p>",
      "content_html": "<p>arXiv:2601.17717v1 Announce Type: new  Abstract: Large Language Models (LLMs) have emerged as powerful tools for generating data across various modalities. By transforming data from a scarce resource into a controllable asset, LLMs mitigate the bottlenecks imposed by the acquisition costs of real-world data for model training, evaluation, and system iteration. However, ensuring the high quality of LLM-generated synthetic data remains a critical challenge. Existing research primarily focuses on generation methodologies, with limited direct attention to the quality of the resulting data. Furthermore, most studies are restricted to single modalities, lacking a unified perspective across different data types. To bridge this gap, we propose the \\textbf{LLM Data Auditor framework}. In this framework, we first describe how LLMs are utilized to generate data across six distinct modalities. More importantly, we systematically categorize intrinsic metrics for evaluating synthetic data from two dimensions: quality and trustworthiness. This approach shifts the focus from extrinsic evaluation, which relies on downstream task performance, to the inherent properties of the data itself. Using this evaluation system, we analyze the experimental evaluations of representative generation methods for each modality and identify substantial deficiencies in current evaluation practices. Based on these findings, we offer concrete recommendations for the community to improve the evaluation of data generation. Finally, the framework outlines methodologies for the practical application of synthetic data across different modalities.</p>"
    },
    {
      "id": "9aa7a59cdedf",
      "title": "ShopSimulator: Evaluating and Exploring RL-Driven LLM Agent for Shopping Assistants",
      "content": "arXiv:2601.18225v1 Announce Type: new  Abstract: Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping. To perform thorough, user-tailored product searches, agents should interpret personal preferences, engage in multi-turn dialogues, and ultimately retrieve and discriminate among highly similar products. However, existing research has yet to provide a unified simulation environment that consistently captures all of these aspects, and always focuses solely on evaluation benchmarks without training support. In this paper, we introduce ShopSimulator, a large-scale and challenging Chinese shopping environment. Leveraging ShopSimulator, we evaluate LLMs across diverse scenarios, finding that even the best-performing models achieve less than 40% full-success rate. Error analysis reveals that agents struggle with deep search and product selection in long trajectories, fail to balance the use of personalization cues, and to effectively engage with users. Further training exploration provides practical guidance for overcoming these weaknesses, with the combination of supervised fine-tuning (SFT) and reinforcement learning (RL) yielding significant performance improvements. Code and data will be released at https://github.com/ShopAgent-Team/ShopSimulator.",
      "url": "http://arxiv.org/abs/2601.18225",
      "author": "Pei Wang, Yanan Wu, Xiaoshuai Song, Weixun Wang, Gengru Chen, Zhongwen Li, Kezhong Yan, Ken Deng, Qi Liu, Shuaibing Zhao, Shaopan Xiong, Xuepeng Liu, Xuefeng Chen, Wanxi Deng, Wenbo Su, Bo Zheng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces ShopSimulator, a large-scale Chinese shopping environment for evaluating LLM agents on multi-turn dialogue and product discrimination, finding best models achieve under 40% success.",
      "importance_score": 56,
      "reasoning": "Useful benchmark for e-commerce agents; reveals significant capability gaps in current models.",
      "themes": [
        "E-commerce AI",
        "Benchmarks",
        "Conversational AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces ShopSimulator, a large-scale Chinese shopping environment for evaluating LLM agents on multi-turn dialogue and product discrimination, finding best models achieve under 40% success.</p>",
      "content_html": "<p>arXiv:2601.18225v1 Announce Type: new  Abstract: Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping. To perform thorough, user-tailored product searches, agents should interpret personal preferences, engage in multi-turn dialogues, and ultimately retrieve and discriminate among highly similar products. However, existing research has yet to provide a unified simulation environment that consistently captures all of these aspects, and always focuses solely on evaluation benchmarks without training support. In this paper, we introduce ShopSimulator, a large-scale and challenging Chinese shopping environment. Leveraging ShopSimulator, we evaluate LLMs across diverse scenarios, finding that even the best-performing models achieve less than 40% full-success rate. Error analysis reveals that agents struggle with deep search and product selection in long trajectories, fail to balance the use of personalization cues, and to effectively engage with users. Further training exploration provides practical guidance for overcoming these weaknesses, with the combination of supervised fine-tuning (SFT) and reinforcement learning (RL) yielding significant performance improvements. Code and data will be released at https://github.com/ShopAgent-Team/ShopSimulator.</p>"
    },
    {
      "id": "aed623a939e6",
      "title": "LLM-42: Enabling Determinism in LLM Inference with Verified Speculation",
      "content": "arXiv:2601.17768v1 Announce Type: cross  Abstract: In LLM inference, the same prompt may yield different outputs across different runs. At the system level, this non-determinism arises from floating-point non-associativity combined with dynamic batching and GPU kernels whose reduction orders vary with batch size. A straightforward way to eliminate non-determinism is to disable dynamic batching during inference, but doing so severely degrades throughput. Another approach is to make kernels batch-invariant; however, this tightly couples determinism to kernel design, requiring new implementations. This coupling also imposes fixed runtime overheads, regardless of how much of the workload actually requires determinism.   Inspired by ideas from speculative decoding, we present LLM-42, a scheduling-based approach to enable determinism in LLM inference. Our key observation is that if a sequence is in a consistent state, the next emitted token is likely to be consistent even with dynamic batching. Moreover, most GPU kernels use shape-consistent reductions. Leveraging these insights, LLM-42 decodes tokens using a non-deterministic fast path and enforces determinism via a lightweight verify-rollback loop. The verifier replays candidate tokens under a fixed-shape reduction schedule, commits those that are guaranteed to be consistent across runs, and rolls back those violating determinism. LLM-42 mostly re-uses existing kernels unchanged and incurs overhead only in proportion to the traffic that requires determinism.",
      "url": "http://arxiv.org/abs/2601.17768",
      "author": "Raja Gond, Aditya K Kamath, Arkaprava Basu, Ramachandran Ramjee, Ashish Panwar",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "LLM-42 enables deterministic LLM inference through scheduling approach inspired by speculative decoding, decoupling determinism from kernel design.",
      "importance_score": 56,
      "reasoning": "Addresses practical reproducibility problem in LLM inference. Avoids throughput degradation of disabling dynamic batching.",
      "themes": [
        "LLM Inference",
        "Determinism",
        "Systems"
      ],
      "continuation": null,
      "summary_html": "<p>LLM-42 enables deterministic LLM inference through scheduling approach inspired by speculative decoding, decoupling determinism from kernel design.</p>",
      "content_html": "<p>arXiv:2601.17768v1 Announce Type: cross  Abstract: In LLM inference, the same prompt may yield different outputs across different runs. At the system level, this non-determinism arises from floating-point non-associativity combined with dynamic batching and GPU kernels whose reduction orders vary with batch size. A straightforward way to eliminate non-determinism is to disable dynamic batching during inference, but doing so severely degrades throughput. Another approach is to make kernels batch-invariant; however, this tightly couples determinism to kernel design, requiring new implementations. This coupling also imposes fixed runtime overheads, regardless of how much of the workload actually requires determinism.   Inspired by ideas from speculative decoding, we present LLM-42, a scheduling-based approach to enable determinism in LLM inference. Our key observation is that if a sequence is in a consistent state, the next emitted token is likely to be consistent even with dynamic batching. Moreover, most GPU kernels use shape-consistent reductions. Leveraging these insights, LLM-42 decodes tokens using a non-deterministic fast path and enforces determinism via a lightweight verify-rollback loop. The verifier replays candidate tokens under a fixed-shape reduction schedule, commits those that are guaranteed to be consistent across runs, and rolls back those violating determinism. LLM-42 mostly re-uses existing kernels unchanged and incurs overhead only in proportion to the traffic that requires determinism.</p>"
    },
    {
      "id": "b3d20504b456",
      "title": "When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs",
      "content": "arXiv:2601.18350v1 Announce Type: cross  Abstract: Large language models (LLMs) show strong general capability but often struggle with medical terminology precision and safety-critical instruction following. We present a case study for adapter interference in safety-critical domains using a 14B-parameter base model through a two-stage LoRA pipeline: (1) domain-adaptive pre-training (PT) to inject broad medical knowledge via continued pre-training (DAPT), and (2) supervised fine-tuning (SFT) to align the model with medical question-answering behaviors through instruction-style data. To balance instruction-following ability and domain knowledge retention, we propose Weighted Adapter Merging, linearly combining SFT and PT adapters before exporting a merged base-model checkpoint. On a held-out medical validation set (F5/F6), the merged model achieves BLEU-4 = 16.38, ROUGE-1 = 20.42, ROUGE-2 = 4.60, and ROUGE-L = 11.54 under a practical decoding configuration. We further analyze decoding sensitivity and training stability with loss curves and controlled decoding comparisons.",
      "url": "http://arxiv.org/abs/2601.18350",
      "author": "Junyi Zou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Case study on adapter interference in medical LLMs, proposing Weighted Adapter Merging to balance instruction-following ability and domain knowledge retention when combining domain pretraining and supervised fine-tuning.",
      "importance_score": 56,
      "reasoning": "Practical findings for medical LLM deployment. Adapter merging insight useful but single case study limits generalizability.",
      "themes": [
        "Medical LLMs",
        "Adapter Merging",
        "Domain Adaptation"
      ],
      "continuation": null,
      "summary_html": "<p>Case study on adapter interference in medical LLMs, proposing Weighted Adapter Merging to balance instruction-following ability and domain knowledge retention when combining domain pretraining and supervised fine-tuning.</p>",
      "content_html": "<p>arXiv:2601.18350v1 Announce Type: cross  Abstract: Large language models (LLMs) show strong general capability but often struggle with medical terminology precision and safety-critical instruction following. We present a case study for adapter interference in safety-critical domains using a 14B-parameter base model through a two-stage LoRA pipeline: (1) domain-adaptive pre-training (PT) to inject broad medical knowledge via continued pre-training (DAPT), and (2) supervised fine-tuning (SFT) to align the model with medical question-answering behaviors through instruction-style data. To balance instruction-following ability and domain knowledge retention, we propose Weighted Adapter Merging, linearly combining SFT and PT adapters before exporting a merged base-model checkpoint. On a held-out medical validation set (F5/F6), the merged model achieves BLEU-4 = 16.38, ROUGE-1 = 20.42, ROUGE-2 = 4.60, and ROUGE-L = 11.54 under a practical decoding configuration. We further analyze decoding sensitivity and training stability with loss curves and controlled decoding comparisons.</p>"
    },
    {
      "id": "586e27225ea6",
      "title": "Revealing the Truth with ConLLM for Detecting Multi-Modal Deepfakes",
      "content": "arXiv:2601.17530v1 Announce Type: new  Abstract: The rapid rise of deepfake technology poses a severe threat to social and political stability by enabling hyper-realistic synthetic media capable of manipulating public perception. However, existing detection methods struggle with two core limitations: (1) modality fragmentation, which leads to poor generalization across diverse and adversarial deepfake modalities; and (2) shallow inter-modal reasoning, resulting in limited detection of fine-grained semantic inconsistencies. To address these, we propose ConLLM (Contrastive Learning with Large Language Models), a hybrid framework for robust multimodal deepfake detection. ConLLM employs a two-stage architecture: stage 1 uses Pre-Trained Models (PTMs) to extract modality-specific embeddings; stage 2 aligns these embeddings via contrastive learning to mitigate modality fragmentation, and refines them using LLM-based reasoning to address shallow inter-modal reasoning by capturing semantic inconsistencies. ConLLM demonstrates strong performance across audio, video, and audio-visual modalities. It reduces audio deepfake EER by up to 50%, improves video accuracy by up to 8%, and achieves approximately 9% accuracy gains in audio-visual tasks. Ablation studies confirm that PTM-based embeddings contribute 9%-10% consistent improvements across modalities.",
      "url": "http://arxiv.org/abs/2601.17530",
      "author": "Gautam Siddharth Kashyap, Harsh Joshi, Niharika Jain, Ebad Shabbir, Jiechao Gao, Nipun Joshi, Usman Naseem",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes ConLLM, a hybrid framework combining contrastive learning with LLMs for multimodal deepfake detection. Uses two-stage architecture with modality-specific embeddings and cross-modal reasoning.",
      "importance_score": 56,
      "reasoning": "Applied security research combining established techniques. Incremental contribution to deepfake detection.",
      "themes": [
        "Deepfake Detection",
        "Multimodal Learning",
        "Security"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes ConLLM, a hybrid framework combining contrastive learning with LLMs for multimodal deepfake detection. Uses two-stage architecture with modality-specific embeddings and cross-modal reasoning.</p>",
      "content_html": "<p>arXiv:2601.17530v1 Announce Type: new  Abstract: The rapid rise of deepfake technology poses a severe threat to social and political stability by enabling hyper-realistic synthetic media capable of manipulating public perception. However, existing detection methods struggle with two core limitations: (1) modality fragmentation, which leads to poor generalization across diverse and adversarial deepfake modalities; and (2) shallow inter-modal reasoning, resulting in limited detection of fine-grained semantic inconsistencies. To address these, we propose ConLLM (Contrastive Learning with Large Language Models), a hybrid framework for robust multimodal deepfake detection. ConLLM employs a two-stage architecture: stage 1 uses Pre-Trained Models (PTMs) to extract modality-specific embeddings; stage 2 aligns these embeddings via contrastive learning to mitigate modality fragmentation, and refines them using LLM-based reasoning to address shallow inter-modal reasoning by capturing semantic inconsistencies. ConLLM demonstrates strong performance across audio, video, and audio-visual modalities. It reduces audio deepfake EER by up to 50%, improves video accuracy by up to 8%, and achieves approximately 9% accuracy gains in audio-visual tasks. Ablation studies confirm that PTM-based embeddings contribute 9%-10% consistent improvements across modalities.</p>"
    },
    {
      "id": "4871f36b4e48",
      "title": "Scaling Behaviors of Evolutionary Algorithms on GPUs: When Does Parallelism Pay Off?",
      "content": "arXiv:2601.18446v1 Announce Type: new  Abstract: Evolutionary algorithms (EAs) are increasingly implemented on graphics processing units (GPUs) to leverage parallel processing capabilities for enhanced efficiency. However, existing studies largely emphasize the raw speedup obtained by porting individual algorithms from CPUs to GPUs. Consequently, these studies offer limited insight into when and why GPU parallelism fundamentally benefits EAs. To address this gap, we investigate how GPU parallelism alters the behavior of EAs beyond simple acceleration metrics. We conduct a systematic empirical study of 16 representative EAs on 30 benchmark problems. Specifically, we compare CPU and GPU executions across a wide range of problem dimensionalities and population sizes. Our results reveal that the impact of GPU acceleration is highly heterogeneous and depends strongly on algorithmic structure. We further demonstrate that conventional fixed-budget evaluation based on the number of function evaluations (FEs) is inadequate for GPU execution. In contrast, fixed-time evaluation uncovers performance characteristics that are unobservable under small or practically constrained FE budgets, particularly for adaptive and exploration-oriented algorithms. Moreover, we identify distinct scaling regimes in which GPU parallelism is beneficial, saturates, or degrades as problem dimensionality and population size increase. Crucially, we show that large populations enabled by GPUs not only improve hardware utilization but also reveal algorithm-specific convergence and diversity dynamics that are difficult to observe under CPU-constrained settings. Consequently, our findings indicate that GPU parallelism is not strictly an implementation detail, but a pivotal factor that influences how EAs should be evaluated, compared, and designed for modern computing platforms.",
      "url": "http://arxiv.org/abs/2601.18446",
      "author": "Xinmeng Yu, Tao Jiang, Ran Cheng, Yaochu Jin, Kay Chen Tan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "cs.NE"
      ],
      "summary": "Systematic empirical study of 16 evolutionary algorithms on 30 benchmarks comparing CPU vs GPU execution across dimensionalities and population sizes to understand when parallelism helps.",
      "importance_score": 56,
      "reasoning": "Valuable empirical study addressing important practical question about GPU parallelism for EAs, useful guidance for practitioners.",
      "themes": [
        "Evolutionary Algorithms",
        "GPU Computing",
        "Empirical Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Systematic empirical study of 16 evolutionary algorithms on 30 benchmarks comparing CPU vs GPU execution across dimensionalities and population sizes to understand when parallelism helps.</p>",
      "content_html": "<p>arXiv:2601.18446v1 Announce Type: new  Abstract: Evolutionary algorithms (EAs) are increasingly implemented on graphics processing units (GPUs) to leverage parallel processing capabilities for enhanced efficiency. However, existing studies largely emphasize the raw speedup obtained by porting individual algorithms from CPUs to GPUs. Consequently, these studies offer limited insight into when and why GPU parallelism fundamentally benefits EAs. To address this gap, we investigate how GPU parallelism alters the behavior of EAs beyond simple acceleration metrics. We conduct a systematic empirical study of 16 representative EAs on 30 benchmark problems. Specifically, we compare CPU and GPU executions across a wide range of problem dimensionalities and population sizes. Our results reveal that the impact of GPU acceleration is highly heterogeneous and depends strongly on algorithmic structure. We further demonstrate that conventional fixed-budget evaluation based on the number of function evaluations (FEs) is inadequate for GPU execution. In contrast, fixed-time evaluation uncovers performance characteristics that are unobservable under small or practically constrained FE budgets, particularly for adaptive and exploration-oriented algorithms. Moreover, we identify distinct scaling regimes in which GPU parallelism is beneficial, saturates, or degrades as problem dimensionality and population size increase. Crucially, we show that large populations enabled by GPUs not only improve hardware utilization but also reveal algorithm-specific convergence and diversity dynamics that are difficult to observe under CPU-constrained settings. Consequently, our findings indicate that GPU parallelism is not strictly an implementation detail, but a pivotal factor that influences how EAs should be evaluated, compared, and designed for modern computing platforms.</p>"
    },
    {
      "id": "74921e12adc3",
      "title": "NeuroManip: Prosthetic Hand Manipulation System Based on EMG and Eye Tracking Powered by the Neuromorphic Processor AltAi",
      "content": "arXiv:2601.17991v1 Announce Type: new  Abstract: This paper presents a novel neuromorphic control architecture for upper-limb prostheses that combines surface electromyography (sEMG) with gaze-guided computer vision. The system uses a spiking neural network deployed on the neuromorphic processor AltAi to classify EMG patterns in real time while an eye-tracking headset and scene camera identify the object within the user's focus. In our prototype, the same EMG recognition model that was originally developed for a conventional GPU is deployed as a spiking network on AltAi, achieving comparable accuracy while operating in a sub-watt power regime, which enables a lightweight, wearable implementation. For six distinct functional gestures recorded from upper-limb amputees, the system achieves robust recognition performance comparable to state-of-the-art myoelectric interfaces. When the vision pipeline restricts the decision space to three context-appropriate gestures for the currently viewed object, recognition accuracy increases to roughly 95% while excluding unsafe, object-inappropriate grasps. These results indicate that the proposed neuromorphic, context-aware controller can provide energy-efficient and reliable prosthesis control and has the potential to improve safety and usability in everyday activities for people with upper-limb amputation.",
      "url": "http://arxiv.org/abs/2601.17991",
      "author": "Roman Akinshin, Elizaveta Lopatina, Kirill Bogatikov, Nikolai Kiz, Anna V. Makarova, Mikhail Lebedev, Miguel Altamirano Cabrera, Dzmitry Tsetserukou, Valerii Kangler",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents NeuroManip, neuromorphic prosthetic control combining sEMG with gaze-guided vision on AltAi processor, achieving sub-watt operation for upper-limb amputees.",
      "importance_score": 56,
      "reasoning": "Practical neuromorphic application with accessibility impact, demonstrates sub-watt deployment.",
      "themes": [
        "Neuromorphic Computing",
        "Prosthetics",
        "EMG",
        "Accessibility"
      ],
      "continuation": null,
      "summary_html": "<p>Presents NeuroManip, neuromorphic prosthetic control combining sEMG with gaze-guided vision on AltAi processor, achieving sub-watt operation for upper-limb amputees.</p>",
      "content_html": "<p>arXiv:2601.17991v1 Announce Type: new  Abstract: This paper presents a novel neuromorphic control architecture for upper-limb prostheses that combines surface electromyography (sEMG) with gaze-guided computer vision. The system uses a spiking neural network deployed on the neuromorphic processor AltAi to classify EMG patterns in real time while an eye-tracking headset and scene camera identify the object within the user's focus. In our prototype, the same EMG recognition model that was originally developed for a conventional GPU is deployed as a spiking network on AltAi, achieving comparable accuracy while operating in a sub-watt power regime, which enables a lightweight, wearable implementation. For six distinct functional gestures recorded from upper-limb amputees, the system achieves robust recognition performance comparable to state-of-the-art myoelectric interfaces. When the vision pipeline restricts the decision space to three context-appropriate gestures for the currently viewed object, recognition accuracy increases to roughly 95% while excluding unsafe, object-inappropriate grasps. These results indicate that the proposed neuromorphic, context-aware controller can provide energy-efficient and reliable prosthesis control and has the potential to improve safety and usability in everyday activities for people with upper-limb amputation.</p>"
    },
    {
      "id": "96bb9a1f5ed9",
      "title": "Beyond Static Datasets: Robust Offline Policy Optimization via Vetted Synthetic Transitions",
      "content": "arXiv:2601.18107v1 Announce Type: cross  Abstract: Offline Reinforcement Learning (ORL) holds immense promise for safety-critical domains like industrial robotics, where real-time environmental interaction is often prohibitive. A primary obstacle in ORL remains the distributional shift between the static dataset and the learned policy, which typically mandates high degrees of conservatism that can restrain potential policy improvements. We present MoReBRAC, a model-based framework that addresses this limitation through Uncertainty-Aware latent synthesis. Instead of relying solely on the fixed data, MoReBRAC utilizes a dual-recurrent world model to synthesize high-fidelity transitions that augment the training manifold. To ensure the reliability of this synthetic data, we implement a hierarchical uncertainty pipeline integrating Variational Autoencoder (VAE) manifold detection, model sensitivity analysis, and Monte Carlo (MC) dropout. This multi-layered filtering process guarantees that only transitions residing within high-confidence regions of the learned dynamics are utilized. Our results on D4RL Gym-MuJoCo benchmarks reveal significant performance gains, particularly in ``random'' and ``suboptimal'' data regimes. We further provide insights into the role of the VAE as a geometric anchor and discuss the distributional trade-offs encountered when learning from near-optimal datasets.",
      "url": "http://arxiv.org/abs/2601.18107",
      "author": "Pedram Agand, Mo Chen",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Presents MoReBRAC, model-based offline RL framework using dual-recurrent world model for synthetic transition generation with hierarchical uncertainty-aware vetting.",
      "importance_score": 56,
      "reasoning": "Addresses important challenge in offline RL with practical approach to distribution shift.",
      "themes": [
        "Offline Reinforcement Learning",
        "World Models",
        "Robotics"
      ],
      "continuation": null,
      "summary_html": "<p>Presents MoReBRAC, model-based offline RL framework using dual-recurrent world model for synthetic transition generation with hierarchical uncertainty-aware vetting.</p>",
      "content_html": "<p>arXiv:2601.18107v1 Announce Type: cross  Abstract: Offline Reinforcement Learning (ORL) holds immense promise for safety-critical domains like industrial robotics, where real-time environmental interaction is often prohibitive. A primary obstacle in ORL remains the distributional shift between the static dataset and the learned policy, which typically mandates high degrees of conservatism that can restrain potential policy improvements. We present MoReBRAC, a model-based framework that addresses this limitation through Uncertainty-Aware latent synthesis. Instead of relying solely on the fixed data, MoReBRAC utilizes a dual-recurrent world model to synthesize high-fidelity transitions that augment the training manifold. To ensure the reliability of this synthetic data, we implement a hierarchical uncertainty pipeline integrating Variational Autoencoder (VAE) manifold detection, model sensitivity analysis, and Monte Carlo (MC) dropout. This multi-layered filtering process guarantees that only transitions residing within high-confidence regions of the learned dynamics are utilized. Our results on D4RL Gym-MuJoCo benchmarks reveal significant performance gains, particularly in ``random'' and ``suboptimal'' data regimes. We further provide insights into the role of the VAE as a geometric anchor and discuss the distributional trade-offs encountered when learning from near-optimal datasets.</p>"
    },
    {
      "id": "3501a9da2ba9",
      "title": "The Relativity of AGI: Distributional Axioms, Fragility, and Undecidability",
      "content": "arXiv:2601.17335v1 Announce Type: new  Abstract: We study whether Artificial General Intelligence (AGI) admits a coherent theoretical definition that supports absolute claims of existence, robustness, or self-verification. We formalize AGI axiomatically as a distributional, resource-bounded semantic predicate, indexed by a task family, a task distribution, a performance functional, and explicit resource budgets. Under this framework, we derive four classes of results. First, we show that generality is inherently relational: there is no distribution-independent notion of AGI. Second, we prove non-invariance results demonstrating that arbitrarily small perturbations of the task distribution can invalidate AGI properties via cliff sets, precluding universal robustness. Third, we establish bounded transfer guarantees, ruling out unbounded generalization across task families under finite resources. Fourth, invoking Rice-style and G\\\"odel--Tarski arguments, we prove that AGI is a nontrivial semantic property and therefore cannot be soundly and completely certified by any computable procedure, including procedures implemented by the agent itself. Consequently, recursive self-improvement schemes that rely on internal self-certification of AGI are ill-posed. Taken together, our results show that strong, distribution-independent claims of AGI are not false but undefined without explicit formal indexing, and that empirical progress in AI does not imply the attainability of self-certifying general intelligence.",
      "url": "http://arxiv.org/abs/2601.17335",
      "author": "Angshul Majumdar",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Formalizes AGI axiomatically as a distributional, resource-bounded predicate and proves that generality is inherently relational, AGI properties are fragile to distribution perturbations, and self-verification is undecidable.",
      "importance_score": 55,
      "reasoning": "Interesting theoretical work on AGI definitions, but highly abstract with limited practical implications; contributes to philosophical foundations.",
      "themes": [
        "AGI Theory",
        "Theoretical AI",
        "AI Safety"
      ],
      "continuation": null,
      "summary_html": "<p>Formalizes AGI axiomatically as a distributional, resource-bounded predicate and proves that generality is inherently relational, AGI properties are fragile to distribution perturbations, and self-verification is undecidable.</p>",
      "content_html": "<p>arXiv:2601.17335v1 Announce Type: new  Abstract: We study whether Artificial General Intelligence (AGI) admits a coherent theoretical definition that supports absolute claims of existence, robustness, or self-verification. We formalize AGI axiomatically as a distributional, resource-bounded semantic predicate, indexed by a task family, a task distribution, a performance functional, and explicit resource budgets. Under this framework, we derive four classes of results. First, we show that generality is inherently relational: there is no distribution-independent notion of AGI. Second, we prove non-invariance results demonstrating that arbitrarily small perturbations of the task distribution can invalidate AGI properties via cliff sets, precluding universal robustness. Third, we establish bounded transfer guarantees, ruling out unbounded generalization across task families under finite resources. Fourth, invoking Rice-style and G\\\"odel--Tarski arguments, we prove that AGI is a nontrivial semantic property and therefore cannot be soundly and completely certified by any computable procedure, including procedures implemented by the agent itself. Consequently, recursive self-improvement schemes that rely on internal self-certification of AGI are ill-posed. Taken together, our results show that strong, distribution-independent claims of AGI are not false but undefined without explicit formal indexing, and that empirical progress in AI does not imply the attainability of self-certifying general intelligence.</p>"
    },
    {
      "id": "872f4aca80c9",
      "title": "Beyond Text-to-SQL: Can LLMs Really Debug Enterprise ETL SQL?",
      "content": "arXiv:2601.18119v1 Announce Type: new  Abstract: SQL is central to enterprise data engineering, yet generating fully correct SQL code in a single attempt remains difficult, even for experienced developers and advanced text-to-SQL LLMs, often requiring multiple debugging iterations. We introduce OurBench, the first benchmark for enterprise-level SQL reasoning and debugging. Our benchmark is built on two key innovations: (1) an automated construction workflow that uses reverse engineering to systematically inject realistic bugs into large-scale SQL code, enabling scalable and diverse benchmark generation; and (2) an execution-free evaluation framework tailored to enterprise settings, providing fast, accurate, and resource-efficient assessment.   OurBench comprises 469 OurBenchSyn queries featuring syntax errors with explicit error messages, and 516 OurBenchSem queries targeting semantic errors in which the code fails to meet user intent. The queries are highly complex, averaging over 140 lines and featuring deep and wide abstract syntax trees.   Evaluation of nearly 30 LLMs reveals a substantial performance gap: the best-performing model, Claude-4-Sonnet, achieves only 36.46 percent accuracy on OurBenchSyn and 32.17 percent on OurBenchSem, while most models score below 20 percent. We further explore four solution strategies, identify key challenges, and outline promising directions for enterprise SQL debugging with LLMs.",
      "url": "http://arxiv.org/abs/2601.18119",
      "author": "Jing Ye, Yiwen Duan, Yonghong Yu, Victor Ma, Yang Gao, Xing Chen",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces OurBench, first benchmark for enterprise ETL SQL debugging using automated bug injection via reverse engineering and execution-free evaluation for fast assessment.",
      "importance_score": 55,
      "reasoning": "Addresses real gap in SQL debugging benchmarks; practical methodology for enterprise-scale evaluation.",
      "themes": [
        "Text-to-SQL",
        "Benchmarks",
        "Enterprise AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces OurBench, first benchmark for enterprise ETL SQL debugging using automated bug injection via reverse engineering and execution-free evaluation for fast assessment.</p>",
      "content_html": "<p>arXiv:2601.18119v1 Announce Type: new  Abstract: SQL is central to enterprise data engineering, yet generating fully correct SQL code in a single attempt remains difficult, even for experienced developers and advanced text-to-SQL LLMs, often requiring multiple debugging iterations. We introduce OurBench, the first benchmark for enterprise-level SQL reasoning and debugging. Our benchmark is built on two key innovations: (1) an automated construction workflow that uses reverse engineering to systematically inject realistic bugs into large-scale SQL code, enabling scalable and diverse benchmark generation; and (2) an execution-free evaluation framework tailored to enterprise settings, providing fast, accurate, and resource-efficient assessment.   OurBench comprises 469 OurBenchSyn queries featuring syntax errors with explicit error messages, and 516 OurBenchSem queries targeting semantic errors in which the code fails to meet user intent. The queries are highly complex, averaging over 140 lines and featuring deep and wide abstract syntax trees.   Evaluation of nearly 30 LLMs reveals a substantial performance gap: the best-performing model, Claude-4-Sonnet, achieves only 36.46 percent accuracy on OurBenchSyn and 32.17 percent on OurBenchSem, while most models score below 20 percent. We further explore four solution strategies, identify key challenges, and outline promising directions for enterprise SQL debugging with LLMs.</p>"
    },
    {
      "id": "81eb78f5d35c",
      "title": "Assessing the Quality of Mental Health Support in LLM Responses through Multi-Attribute Human Evaluation",
      "content": "arXiv:2601.18630v1 Announce Type: new  Abstract: The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI.",
      "url": "http://arxiv.org/abs/2601.18630",
      "author": "Abeer Badawi, Md Tahmid Rahman Laskar, Elahe Rahimi, Sheri Grach, Lindsay Bertrand, Lames Danok, Frank Rudzicz, Jimmy Huang, Elham Dolatabadi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces human-grounded evaluation methodology for LLM mental health responses, evaluating 9 LLMs on 500 conversations using multi-attribute assessment by domain experts.",
      "importance_score": 55,
      "reasoning": "Useful evaluation framework for mental health AI; systematic approach but limited scale.",
      "themes": [
        "Healthcare AI",
        "Human Evaluation",
        "Mental Health"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces human-grounded evaluation methodology for LLM mental health responses, evaluating 9 LLMs on 500 conversations using multi-attribute assessment by domain experts.</p>",
      "content_html": "<p>arXiv:2601.18630v1 Announce Type: new  Abstract: The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI.</p>"
    },
    {
      "id": "f9a1151be3fc",
      "title": "Measuring Political Stance and Consistency in Large Language Models",
      "content": "arXiv:2601.17016v1 Announce Type: cross  Abstract: With the incredible advancements in Large Language Models (LLMs), many people have started using them to satisfy their information needs. However, utilizing LLMs might be problematic for political issues where disagreement is common and model outputs may reflect training-data biases or deliberate alignment choices. To better characterize such behavior, we assess the stances of nine LLMs on 24 politically sensitive issues using five prompting techniques. We find that models often adopt opposing stances on several issues; some positions are malleable under prompting, while others remain stable. Among the models examined, Grok-3-mini is the most persistent, whereas Mistral-7B is the least. For issues involving countries with different languages, models tend to support the side whose language is used in the prompt. Notably, no prompting technique alters model stances on the Qatar blockade or the oppression of Palestinians. We hope these findings raise user awareness when seeking political guidance from LLMs and encourage developers to address these concerns.",
      "url": "http://arxiv.org/abs/2601.17016",
      "author": "Salah Feras Alali, Mohammad Nashat Maasfeh, Mucahid Kutlu, Saban Kardas",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Assesses political stances of 9 LLMs including Grok-3-mini and Mistral-7B across 24 politically sensitive issues using 5 prompting techniques. Finds varying stance stability across models.",
      "importance_score": 55,
      "reasoning": "Useful empirical study of LLM biases with practical implications. Includes multiple current models but methodology is straightforward.",
      "themes": [
        "LLM Bias",
        "AI Safety",
        "Political Alignment"
      ],
      "continuation": null,
      "summary_html": "<p>Assesses political stances of 9 LLMs including Grok-3-mini and Mistral-7B across 24 politically sensitive issues using 5 prompting techniques. Finds varying stance stability across models.</p>",
      "content_html": "<p>arXiv:2601.17016v1 Announce Type: cross  Abstract: With the incredible advancements in Large Language Models (LLMs), many people have started using them to satisfy their information needs. However, utilizing LLMs might be problematic for political issues where disagreement is common and model outputs may reflect training-data biases or deliberate alignment choices. To better characterize such behavior, we assess the stances of nine LLMs on 24 politically sensitive issues using five prompting techniques. We find that models often adopt opposing stances on several issues; some positions are malleable under prompting, while others remain stable. Among the models examined, Grok-3-mini is the most persistent, whereas Mistral-7B is the least. For issues involving countries with different languages, models tend to support the side whose language is used in the prompt. Notably, no prompting technique alters model stances on the Qatar blockade or the oppression of Palestinians. We hope these findings raise user awareness when seeking political guidance from LLMs and encourage developers to address these concerns.</p>"
    },
    {
      "id": "8f68be0eba2e",
      "title": "Can LLMs Clean Up Your Mess? A Survey of Application-Ready Data Preparation with LLMs",
      "content": "arXiv:2601.17058v1 Announce Type: cross  Abstract: Data preparation aims to denoise raw datasets, uncover cross-dataset relationships, and extract valuable insights from them, which is essential for a wide range of data-centric applications. Driven by (i) rising demands for application-ready data (e.g., for analytics, visualization, decision-making), (ii) increasingly powerful LLM techniques, and (iii) the emergence of infrastructures that facilitate flexible agent construction (e.g., using Databricks Unity Catalog), LLM-enhanced methods are rapidly becoming a transformative and potentially dominant paradigm for data preparation.   By investigating hundreds of recent literature works, this paper presents a systematic review of this evolving landscape, focusing on the use of LLM techniques to prepare data for diverse downstream tasks. First, we characterize the fundamental paradigm shift, from rule-based, model-specific pipelines to prompt-driven, context-aware, and agentic preparation workflows. Next, we introduce a task-centric taxonomy that organizes the field into three major tasks: data cleaning (e.g., standardization, error processing, imputation), data integration (e.g., entity matching, schema matching), and data enrichment (e.g., data annotation, profiling). For each task, we survey representative techniques, and highlight their respective strengths (e.g., improved generalization, semantic understanding) and limitations (e.g., the prohibitive cost of scaling LLMs, persistent hallucinations even in advanced agents, the mismatch between advanced methods and weak evaluation). Moreover, we analyze commonly used datasets and evaluation metrics (the empirical part). Finally, we discuss open research challenges and outline a forward-looking roadmap that emphasizes scalable LLM-data systems, principled designs for reliable agentic workflows, and robust evaluation protocols.",
      "url": "http://arxiv.org/abs/2601.17058",
      "author": "Wei Zhou, Jun Zhou, Haoyu Wang, Zhenghao Li, Qikang He, Shaokun Han, Guoliang Li, Xuanhe Zhou, Yeye He, Chunwei Liu, Zirui Tang, Bin Wang, Shen Tang, Kai Zuo, Yuyu Luo, Zhenzhe Zheng, Conghui He, Jingren Zhou, Fan Wu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.DB"
      ],
      "summary": "Comprehensive survey reviewing LLM techniques for data preparation tasks including denoising, relationship discovery, and insight extraction. Covers recent literature on application-ready data.",
      "importance_score": 55,
      "reasoning": "Useful survey organizing rapidly evolving field. Good reference but primarily synthesis rather than novel contribution.",
      "themes": [
        "LLM Applications",
        "Data Preparation",
        "Survey"
      ],
      "continuation": null,
      "summary_html": "<p>Comprehensive survey reviewing LLM techniques for data preparation tasks including denoising, relationship discovery, and insight extraction. Covers recent literature on application-ready data.</p>",
      "content_html": "<p>arXiv:2601.17058v1 Announce Type: cross  Abstract: Data preparation aims to denoise raw datasets, uncover cross-dataset relationships, and extract valuable insights from them, which is essential for a wide range of data-centric applications. Driven by (i) rising demands for application-ready data (e.g., for analytics, visualization, decision-making), (ii) increasingly powerful LLM techniques, and (iii) the emergence of infrastructures that facilitate flexible agent construction (e.g., using Databricks Unity Catalog), LLM-enhanced methods are rapidly becoming a transformative and potentially dominant paradigm for data preparation.   By investigating hundreds of recent literature works, this paper presents a systematic review of this evolving landscape, focusing on the use of LLM techniques to prepare data for diverse downstream tasks. First, we characterize the fundamental paradigm shift, from rule-based, model-specific pipelines to prompt-driven, context-aware, and agentic preparation workflows. Next, we introduce a task-centric taxonomy that organizes the field into three major tasks: data cleaning (e.g., standardization, error processing, imputation), data integration (e.g., entity matching, schema matching), and data enrichment (e.g., data annotation, profiling). For each task, we survey representative techniques, and highlight their respective strengths (e.g., improved generalization, semantic understanding) and limitations (e.g., the prohibitive cost of scaling LLMs, persistent hallucinations even in advanced agents, the mismatch between advanced methods and weak evaluation). Moreover, we analyze commonly used datasets and evaluation metrics (the empirical part). Finally, we discuss open research challenges and outline a forward-looking roadmap that emphasizes scalable LLM-data systems, principled designs for reliable agentic workflows, and robust evaluation protocols.</p>"
    },
    {
      "id": "b389aac6106d",
      "title": "Multi-Agent Deep Reinforcement Learning Under Constrained Communications",
      "content": "arXiv:2601.17069v1 Announce Type: cross  Abstract: Centralized training with decentralized execution (CTDE) has been the dominant paradigm in multi-agent reinforcement learning (MARL), but its reliance on global state information during training introduces scalability, robustness, and generalization bottlenecks. Moreover, in practical scenarios such as adding/dropping teammates or facing environment dynamics that differ from the training, CTDE methods can be brittle and costly to retrain, whereas distributed approaches allow agents to adapt using only local information and peer-to-peer communication. We present a distributed MARL framework that removes the need for centralized critics or global information. Firstly, we develop a novel Distributed Graph Attention Network (D-GAT) that performs global state inference through multi-hop communication, where agents integrate neighbor features via input-dependent attention weights in a fully distributed manner. Leveraging D-GAT, we develop the distributed graph-attention MAPPO (DG-MAPPO) -- a distributed MARL framework where agents optimize local policies and value functions using local observations, multi-hop communication, and shared/averaged rewards. Empirical evaluation on the StarCraftII Multi-Agent Challenge, Google Research Football, and Multi-Agent Mujoco demonstrates that our method consistently outperforms strong CTDE baselines, achieving superior coordination across a wide range of cooperative tasks with both homogeneous and heterogeneous teams. Our distributed MARL framework provides a principled and scalable solution for robust collaboration, eliminating the need for centralized training or global observability. To the best of our knowledge, DG-MAPPO appears to be the first to fully eliminate reliance on privileged centralized information, enabling agents to learn and act solely through peer-to-peer communication.",
      "url": "http://arxiv.org/abs/2601.17069",
      "author": "Shahil Shaik, Jonathon M. Smereka, Yue Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Presents distributed MARL framework with novel Distributed Graph Attention Network (D-GAT) that removes need for centralized critics or global information during training.",
      "importance_score": 55,
      "reasoning": "Addresses practical scalability issues in MARL. Technical contribution but incremental improvement over existing approaches.",
      "themes": [
        "Multi-Agent RL",
        "Distributed Learning",
        "Graph Networks"
      ],
      "continuation": null,
      "summary_html": "<p>Presents distributed MARL framework with novel Distributed Graph Attention Network (D-GAT) that removes need for centralized critics or global information during training.</p>",
      "content_html": "<p>arXiv:2601.17069v1 Announce Type: cross  Abstract: Centralized training with decentralized execution (CTDE) has been the dominant paradigm in multi-agent reinforcement learning (MARL), but its reliance on global state information during training introduces scalability, robustness, and generalization bottlenecks. Moreover, in practical scenarios such as adding/dropping teammates or facing environment dynamics that differ from the training, CTDE methods can be brittle and costly to retrain, whereas distributed approaches allow agents to adapt using only local information and peer-to-peer communication. We present a distributed MARL framework that removes the need for centralized critics or global information. Firstly, we develop a novel Distributed Graph Attention Network (D-GAT) that performs global state inference through multi-hop communication, where agents integrate neighbor features via input-dependent attention weights in a fully distributed manner. Leveraging D-GAT, we develop the distributed graph-attention MAPPO (DG-MAPPO) -- a distributed MARL framework where agents optimize local policies and value functions using local observations, multi-hop communication, and shared/averaged rewards. Empirical evaluation on the StarCraftII Multi-Agent Challenge, Google Research Football, and Multi-Agent Mujoco demonstrates that our method consistently outperforms strong CTDE baselines, achieving superior coordination across a wide range of cooperative tasks with both homogeneous and heterogeneous teams. Our distributed MARL framework provides a principled and scalable solution for robust collaboration, eliminating the need for centralized training or global observability. To the best of our knowledge, DG-MAPPO appears to be the first to fully eliminate reliance on privileged centralized information, enabling agents to learn and act solely through peer-to-peer communication.</p>"
    },
    {
      "id": "5323364011a2",
      "title": "SFO: Learning PDE Operators via Spectral Filtering",
      "content": "arXiv:2601.17090v1 Announce Type: cross  Abstract: Partial differential equations (PDEs) govern complex systems, yet neural operators often struggle to efficiently capture the long-range, nonlocal interactions inherent in their solution maps. We introduce Spectral Filtering Operator (SFO), a neural operator that parameterizes integral kernels using the Universal Spectral Basis (USB), a fixed, global orthonormal basis derived from the eigenmodes of the Hilbert matrix in spectral filtering theory. Motivated by our theoretical finding that the discrete Green's functions of shift-invariant PDE discretizations exhibit spatial Linear Dynamical System (LDS) structure, we prove that these kernels admit compact approximations in the USB. By learning only the spectral coefficients of rapidly decaying eigenvalues, SFO achieves a highly efficient representation. Across six benchmarks, including reaction-diffusion, fluid dynamics, and 3D electromagnetics, SFO achieves state-of-the-art accuracy, reducing error by up to 40% relative to strong baselines while using substantially fewer parameters.",
      "url": "http://arxiv.org/abs/2601.17090",
      "author": "Noam Koren, Rafael Moschopoulos, Kira Radinsky, Elad Hazan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces Spectral Filtering Operator (SFO) using Universal Spectral Basis for neural operators solving PDEs. Proves kernels admit compact approximations in USB.",
      "importance_score": 55,
      "reasoning": "Technical contribution to neural operators with theoretical grounding. Addresses long-range interactions in PDE solving.",
      "themes": [
        "Neural Operators",
        "PDEs",
        "Scientific Computing"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Spectral Filtering Operator (SFO) using Universal Spectral Basis for neural operators solving PDEs. Proves kernels admit compact approximations in USB.</p>",
      "content_html": "<p>arXiv:2601.17090v1 Announce Type: cross  Abstract: Partial differential equations (PDEs) govern complex systems, yet neural operators often struggle to efficiently capture the long-range, nonlocal interactions inherent in their solution maps. We introduce Spectral Filtering Operator (SFO), a neural operator that parameterizes integral kernels using the Universal Spectral Basis (USB), a fixed, global orthonormal basis derived from the eigenmodes of the Hilbert matrix in spectral filtering theory. Motivated by our theoretical finding that the discrete Green's functions of shift-invariant PDE discretizations exhibit spatial Linear Dynamical System (LDS) structure, we prove that these kernels admit compact approximations in the USB. By learning only the spectral coefficients of rapidly decaying eigenvalues, SFO achieves a highly efficient representation. Across six benchmarks, including reaction-diffusion, fluid dynamics, and 3D electromagnetics, SFO achieves state-of-the-art accuracy, reducing error by up to 40% relative to strong baselines while using substantially fewer parameters.</p>"
    },
    {
      "id": "6783704e198c",
      "title": "Dynamic Role Assignment for Multi-Agent Debate",
      "content": "arXiv:2601.17152v1 Announce Type: cross  Abstract: Multi-agent large language model (LLM) and vision-language model (VLM) debate systems employ specialized roles for complex problem-solving, yet model specializations are not leveraged to decide which model should fill which role. We propose dynamic role assignment, a framework that runs a Meta-Debate to select suitable agents before the actual debate. The meta-debate has two stages: (1) proposal, where candidates provide role-tailored arguments, and (2) peer review, where proposals are scored with data and role-specific criteria to choose the best agent for each position. We evaluate our method on LLM problem solving benchmarks. Applied on top of existing debate systems, our approach consistently outperforms uniform assignments (filling all roles with the same model) by up to 74.8% and random assignments (assigning models to roles without considering their suitability) by up to 29.7%, depending on the task and the specific assignment. This work establishes a new paradigm for multi-agent system design, shifting from static agent deployment to dynamic and capability-aware selection.",
      "url": "http://arxiv.org/abs/2601.17152",
      "author": "Miao Zhang, Junsik Kim, Siyuan Xiang, Jian Gao, Cheng Cao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes dynamic role assignment for multi-agent debate through meta-debate with proposal and peer review stages. Consistently outperforms uniform agent assignment.",
      "importance_score": 55,
      "reasoning": "Novel meta-debate mechanism for multi-agent systems. Practical improvement but incremental contribution.",
      "themes": [
        "Multi-Agent Systems",
        "LLM Debate",
        "Role Assignment"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes dynamic role assignment for multi-agent debate through meta-debate with proposal and peer review stages. Consistently outperforms uniform agent assignment.</p>",
      "content_html": "<p>arXiv:2601.17152v1 Announce Type: cross  Abstract: Multi-agent large language model (LLM) and vision-language model (VLM) debate systems employ specialized roles for complex problem-solving, yet model specializations are not leveraged to decide which model should fill which role. We propose dynamic role assignment, a framework that runs a Meta-Debate to select suitable agents before the actual debate. The meta-debate has two stages: (1) proposal, where candidates provide role-tailored arguments, and (2) peer review, where proposals are scored with data and role-specific criteria to choose the best agent for each position. We evaluate our method on LLM problem solving benchmarks. Applied on top of existing debate systems, our approach consistently outperforms uniform assignments (filling all roles with the same model) by up to 74.8% and random assignments (assigning models to roles without considering their suitability) by up to 29.7%, depending on the task and the specific assignment. This work establishes a new paradigm for multi-agent system design, shifting from static agent deployment to dynamic and capability-aware selection.</p>"
    },
    {
      "id": "7c9e7cca542f",
      "title": "Beyond Factual QA: Mentorship-Oriented Question Answering over Long-Form Multilingual Content",
      "content": "arXiv:2601.17173v1 Announce Type: cross  Abstract: Question answering systems are typically evaluated on factual correctness, yet many real-world applications-such as education and career guidance-require mentorship: responses that provide reflection and guidance. Existing QA benchmarks rarely capture this distinction, particularly in multilingual and long-form settings. We introduce MentorQA, the first multilingual dataset and evaluation framework for mentorship-focused question answering from long-form videos, comprising nearly 9,000 QA pairs from 180 hours of content across four languages. We define mentorship-focused evaluation dimensions that go beyond factual accuracy, capturing clarity, alignment, and learning value. Using MentorQA, we compare Single-Agent, Dual-Agent, RAG, and Multi-Agent QA architectures under controlled conditions. Multi-Agent pipelines consistently produce higher-quality mentorship responses, with especially strong gains for complex topics and lower-resource languages. We further analyze the reliability of automated LLM-based evaluation, observing substantial variation in alignment with human judgments. Overall, this work establishes mentorship-focused QA as a distinct research problem and provides a multilingual benchmark for studying agentic architectures and evaluation design in educational AI. The dataset and evaluation framework are released at https://github.com/AIM-SCU/MentorQA.",
      "url": "http://arxiv.org/abs/2601.17173",
      "author": "Parth Bhalerao, Diola Dsouza, Ruiwen Guan, Oana Ignat",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces MentorQA, first multilingual dataset for mentorship-focused QA with 9,000 pairs from 180 hours of video content. Defines evaluation dimensions beyond factual accuracy.",
      "importance_score": 55,
      "reasoning": "Novel benchmark addressing underexplored mentorship dimension in QA. Good scale but narrow focus.",
      "themes": [
        "Question Answering",
        "Multilingual AI",
        "Benchmarks"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces MentorQA, first multilingual dataset for mentorship-focused QA with 9,000 pairs from 180 hours of video content. Defines evaluation dimensions beyond factual accuracy.</p>",
      "content_html": "<p>arXiv:2601.17173v1 Announce Type: cross  Abstract: Question answering systems are typically evaluated on factual correctness, yet many real-world applications-such as education and career guidance-require mentorship: responses that provide reflection and guidance. Existing QA benchmarks rarely capture this distinction, particularly in multilingual and long-form settings. We introduce MentorQA, the first multilingual dataset and evaluation framework for mentorship-focused question answering from long-form videos, comprising nearly 9,000 QA pairs from 180 hours of content across four languages. We define mentorship-focused evaluation dimensions that go beyond factual accuracy, capturing clarity, alignment, and learning value. Using MentorQA, we compare Single-Agent, Dual-Agent, RAG, and Multi-Agent QA architectures under controlled conditions. Multi-Agent pipelines consistently produce higher-quality mentorship responses, with especially strong gains for complex topics and lower-resource languages. We further analyze the reliability of automated LLM-based evaluation, observing substantial variation in alignment with human judgments. Overall, this work establishes mentorship-focused QA as a distinct research problem and provides a multilingual benchmark for studying agentic architectures and evaluation design in educational AI. The dataset and evaluation framework are released at https://github.com/AIM-SCU/MentorQA.</p>"
    },
    {
      "id": "f906de1cc9ac",
      "title": "From Specialist to Generalist: Unlocking SAM's Learning Potential on Unlabeled Medical Images",
      "content": "arXiv:2601.17934v1 Announce Type: cross  Abstract: Foundation models like the Segment Anything Model (SAM) show strong generalization, yet adapting them to medical images remains difficult due to domain shift, scarce labels, and the inability of Parameter-Efficient Fine-Tuning (PEFT) to exploit unlabeled data. While conventional models like U-Net excel in semi-supervised medical learning, their potential to assist a PEFT SAM has been largely overlooked. We introduce SC-SAM, a specialist-generalist framework where U-Net provides point-based prompts and pseudo-labels to guide SAM's adaptation, while SAM serves as a powerful generalist supervisor to regularize U-Net. This reciprocal guidance forms a bidirectional co-training loop that allows both models to effectively exploit the unlabeled data. Across prostate MRI and polyp segmentation benchmarks, our method achieves state-of-the-art results, outperforming other existing semi-supervised SAM variants and even medical foundation models like MedSAM, highlighting the value of specialist-generalist cooperation for label-efficient medical image segmentation. Our code is available at https://github.com/vnlvi2k3/SC-SAM.",
      "url": "http://arxiv.org/abs/2601.17934",
      "author": "Vi Vu, Thanh-Huy Nguyen, Tien-Thinh Nguyen, Ba-Thinh Lam, Hoang-Thien Nguyen, Tianyang Wang, Xingjian Li, Min Xu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "SC-SAM adapts SAM for semi-supervised medical imaging through reciprocal guidance between U-Net (prompts/pseudo-labels) and SAM (regularization).",
      "importance_score": 55,
      "reasoning": "Practical approach for medical image segmentation with limited labels. Leverages both specialist and generalist models.",
      "themes": [
        "Medical Imaging",
        "Semi-supervised Learning",
        "SAM"
      ],
      "continuation": null,
      "summary_html": "<p>SC-SAM adapts SAM for semi-supervised medical imaging through reciprocal guidance between U-Net (prompts/pseudo-labels) and SAM (regularization).</p>",
      "content_html": "<p>arXiv:2601.17934v1 Announce Type: cross  Abstract: Foundation models like the Segment Anything Model (SAM) show strong generalization, yet adapting them to medical images remains difficult due to domain shift, scarce labels, and the inability of Parameter-Efficient Fine-Tuning (PEFT) to exploit unlabeled data. While conventional models like U-Net excel in semi-supervised medical learning, their potential to assist a PEFT SAM has been largely overlooked. We introduce SC-SAM, a specialist-generalist framework where U-Net provides point-based prompts and pseudo-labels to guide SAM's adaptation, while SAM serves as a powerful generalist supervisor to regularize U-Net. This reciprocal guidance forms a bidirectional co-training loop that allows both models to effectively exploit the unlabeled data. Across prostate MRI and polyp segmentation benchmarks, our method achieves state-of-the-art results, outperforming other existing semi-supervised SAM variants and even medical foundation models like MedSAM, highlighting the value of specialist-generalist cooperation for label-efficient medical image segmentation. Our code is available at https://github.com/vnlvi2k3/SC-SAM.</p>"
    },
    {
      "id": "55e704d35e0b",
      "title": "\"Crash Test Dummies\" for AI-Enabled Clinical Assessment: Validating Virtual Patient Scenarios with Virtual Learners",
      "content": "arXiv:2601.18085v1 Announce Type: cross  Abstract: Background: In medical and health professions education (HPE), AI is increasingly used to assess clinical competencies, including via virtual standardized patients. However, most evaluations rely on AI-human interrater reliability and lack a measurement framework for how cases, learners, and raters jointly shape scores. This leaves robustness uncertain and can expose learners to misguidance from unvalidated systems. We address this by using AI \"simulated learners\" to stress-test and psychometrically characterize assessment pipelines before human use.   Objective: Develop an open-source AI virtual patient platform and measurement model for robust competency evaluation across cases and rating conditions.   Methods: We built a platform with virtual patients, virtual learners with tunable ACGME-aligned competency profiles, and multiple independent AI raters scoring encounters with structured Key-Features items. Transcripts were analyzed with a Bayesian HRM-SDT model that treats ratings as decisions under uncertainty and separates learner ability, case performance, and rater behavior; parameters were estimated with MCMC.   Results: The model recovered simulated learners' competencies, with significant correlations to the generating competencies across all ACGME domains despite a non-deterministic pipeline. It estimated case difficulty by competency and showed stable rater detection (sensitivity) and criteria (severity/leniency thresholds) across AI raters using identical models/prompts but different seeds. We also propose a staged \"safety blueprint\" for deploying AI tools with learners, tied to entrustment-based validation milestones.   Conclusions: Combining a purpose-built virtual patient platform with a principled psychometric model enables robust, interpretable, generalizable competency estimates and supports validation of AI-assisted assessment prior to use with human learners.",
      "url": "http://arxiv.org/abs/2601.18085",
      "author": "Brian Gin, Ahreum Lim, Fl\\'avia Silva e Oliveira, Kuan Xing, Xiaomei Song, Gayana Amiyangoda, Thilanka Seneviratne, Alison F. Doubleday, Ananya Gangopadhyaya, Bob Kiser, Lukas Shum-Tim, Dhruva Patel, Kosala Marambe, Lauren Maggio, Ara Tekian, Yoon Soo Park",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.HC"
      ],
      "summary": "Proposes using AI 'simulated learners' to stress-test and validate AI-powered clinical assessment systems before human deployment, creating a novel validation framework. Introduces psychometric measurement models for evaluating virtual patient platforms.",
      "importance_score": 55,
      "reasoning": "Novel validation methodology for medical AI systems. Addresses important safety concern of validating AI assessments before human exposure, but limited to specific medical education domain.",
      "themes": [
        "Medical AI",
        "AI Evaluation",
        "Validation Frameworks"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes using AI 'simulated learners' to stress-test and validate AI-powered clinical assessment systems before human deployment, creating a novel validation framework. Introduces psychometric measurement models for evaluating virtual patient platforms.</p>",
      "content_html": "<p>arXiv:2601.18085v1 Announce Type: cross  Abstract: Background: In medical and health professions education (HPE), AI is increasingly used to assess clinical competencies, including via virtual standardized patients. However, most evaluations rely on AI-human interrater reliability and lack a measurement framework for how cases, learners, and raters jointly shape scores. This leaves robustness uncertain and can expose learners to misguidance from unvalidated systems. We address this by using AI \"simulated learners\" to stress-test and psychometrically characterize assessment pipelines before human use.   Objective: Develop an open-source AI virtual patient platform and measurement model for robust competency evaluation across cases and rating conditions.   Methods: We built a platform with virtual patients, virtual learners with tunable ACGME-aligned competency profiles, and multiple independent AI raters scoring encounters with structured Key-Features items. Transcripts were analyzed with a Bayesian HRM-SDT model that treats ratings as decisions under uncertainty and separates learner ability, case performance, and rater behavior; parameters were estimated with MCMC.   Results: The model recovered simulated learners' competencies, with significant correlations to the generating competencies across all ACGME domains despite a non-deterministic pipeline. It estimated case difficulty by competency and showed stable rater detection (sensitivity) and criteria (severity/leniency thresholds) across AI raters using identical models/prompts but different seeds. We also propose a staged \"safety blueprint\" for deploying AI tools with learners, tied to entrustment-based validation milestones.   Conclusions: Combining a purpose-built virtual patient platform with a principled psychometric model enables robust, interpretable, generalizable competency estimates and supports validation of AI-assisted assessment prior to use with human learners.</p>"
    },
    {
      "id": "5a94bd98ba3f",
      "title": "Beyond Pairwise Comparisons: A Distributional Test of Distinctiveness for Machine-Generated Works in Intellectual Property Law",
      "content": "arXiv:2601.18156v1 Announce Type: cross  Abstract: Key doctrines, including novelty (patent), originality (copyright), and distinctiveness (trademark), turn on a shared empirical question: whether a body of work is meaningfully distinct from a relevant reference class. Yet analyses typically operationalize this set-level inquiry using item-level evidence: pairwise comparisons among exemplars. That unit-of-analysis mismatch may be manageable for finite corpora of human-created works, where it can be bridged by ad hoc aggregations. But it becomes acute for machine-generated works, where the object of evaluation is not a fixed set of works but a generative process with an effectively unbounded output space. We propose a distributional alternative: a two-sample test based on maximum mean discrepancy computed on semantic embeddings to determine if two creative processes-whether human or machine-produce statistically distinguishable output distributions. The test requires no task-specific training-obviating the need for discovery of proprietary training data to characterize the generative process-and is sample-efficient, often detecting differences with as few as 5-10 images and 7-20 texts. We validate the framework across three domains: handwritten digits (controlled images), patent abstracts (text), and AI-generated art (real-world images). We reveal a perceptual paradox: even when human evaluators distinguish AI outputs from human-created art with only about 58% accuracy, our method detects distributional distinctiveness. Our results present evidence contrary to the view that generative models act as mere regurgitators of training data. Rather than producing outputs statistically indistinguishable from a human baseline-as simple regurgitation would predict-they produce outputs that are semantically human-like yet stochastically distinct, suggesting their dominant function is as a semantic interpolator within a learned latent space.",
      "url": "http://arxiv.org/abs/2601.18156",
      "author": "Anirban Mukherjee, Hannah Hanwen Chang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Proposes distributional test using maximum mean discrepancy to assess distinctiveness of machine-generated works for intellectual property law, addressing limitations of pairwise comparisons for generative AI outputs.",
      "importance_score": 55,
      "reasoning": "Novel intersection of ML methodology and IP law. Addresses important emerging legal question about AI-generated content but narrow application domain.",
      "themes": [
        "AI and Law",
        "Generative AI",
        "Statistical Methods"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes distributional test using maximum mean discrepancy to assess distinctiveness of machine-generated works for intellectual property law, addressing limitations of pairwise comparisons for generative AI outputs.</p>",
      "content_html": "<p>arXiv:2601.18156v1 Announce Type: cross  Abstract: Key doctrines, including novelty (patent), originality (copyright), and distinctiveness (trademark), turn on a shared empirical question: whether a body of work is meaningfully distinct from a relevant reference class. Yet analyses typically operationalize this set-level inquiry using item-level evidence: pairwise comparisons among exemplars. That unit-of-analysis mismatch may be manageable for finite corpora of human-created works, where it can be bridged by ad hoc aggregations. But it becomes acute for machine-generated works, where the object of evaluation is not a fixed set of works but a generative process with an effectively unbounded output space. We propose a distributional alternative: a two-sample test based on maximum mean discrepancy computed on semantic embeddings to determine if two creative processes-whether human or machine-produce statistically distinguishable output distributions. The test requires no task-specific training-obviating the need for discovery of proprietary training data to characterize the generative process-and is sample-efficient, often detecting differences with as few as 5-10 images and 7-20 texts. We validate the framework across three domains: handwritten digits (controlled images), patent abstracts (text), and AI-generated art (real-world images). We reveal a perceptual paradox: even when human evaluators distinguish AI outputs from human-created art with only about 58% accuracy, our method detects distributional distinctiveness. Our results present evidence contrary to the view that generative models act as mere regurgitators of training data. Rather than producing outputs statistically indistinguishable from a human baseline-as simple regurgitation would predict-they produce outputs that are semantically human-like yet stochastically distinct, suggesting their dominant function is as a semantic interpolator within a learned latent space.</p>"
    },
    {
      "id": "82b2dc6ecf41",
      "title": "Rethinking Cross-Modal Fine-Tuning: Optimizing the Interaction between Feature Alignment and Target Fitting",
      "content": "arXiv:2601.18231v1 Announce Type: cross  Abstract: Adapting pre-trained models to unseen feature modalities has become increasingly important due to the growing need for cross-disciplinary knowledge integration.~A key challenge here is how to align the representation of new modalities with the most relevant parts of the pre-trained model's representation space to enable accurate knowledge transfer.~This requires combining feature alignment with target fine-tuning, but uncalibrated combinations can exacerbate misalignment between the source and target feature-label structures and reduce target generalization.~Existing work however lacks a theoretical understanding of this critical interaction between feature alignment and target fitting.~To bridge this gap, we develop a principled framework that establishes a provable generalization bound on the target error, which explains the interaction between feature alignment and target fitting through a novel concept of feature-label distortion.~This bound offers actionable insights into how this interaction should be optimized for practical algorithm design. The resulting approach achieves significantly improved performance over state-of-the-art methods across a wide range of benchmark datasets.",
      "url": "http://arxiv.org/abs/2601.18231",
      "author": "Trong Khiem Tran, Manh Cuong Dao, Phi Le Nguyen, Thao Nguyen Truong, Trong Nghia Hoang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Develops theoretical framework for cross-modal fine-tuning, analyzing interaction between feature alignment and target fitting. Shows uncalibrated combinations can exacerbate source-target misalignment.",
      "importance_score": 55,
      "reasoning": "Theoretical contribution addressing important practical problem in transfer learning. Principled framework but abstract lacks empirical validation details.",
      "themes": [
        "Transfer Learning",
        "Cross-Modal Learning",
        "Theoretical ML"
      ],
      "continuation": null,
      "summary_html": "<p>Develops theoretical framework for cross-modal fine-tuning, analyzing interaction between feature alignment and target fitting. Shows uncalibrated combinations can exacerbate source-target misalignment.</p>",
      "content_html": "<p>arXiv:2601.18231v1 Announce Type: cross  Abstract: Adapting pre-trained models to unseen feature modalities has become increasingly important due to the growing need for cross-disciplinary knowledge integration.~A key challenge here is how to align the representation of new modalities with the most relevant parts of the pre-trained model's representation space to enable accurate knowledge transfer.~This requires combining feature alignment with target fine-tuning, but uncalibrated combinations can exacerbate misalignment between the source and target feature-label structures and reduce target generalization.~Existing work however lacks a theoretical understanding of this critical interaction between feature alignment and target fitting.~To bridge this gap, we develop a principled framework that establishes a provable generalization bound on the target error, which explains the interaction between feature alignment and target fitting through a novel concept of feature-label distortion.~This bound offers actionable insights into how this interaction should be optimized for practical algorithm design. The resulting approach achieves significantly improved performance over state-of-the-art methods across a wide range of benchmark datasets.</p>"
    },
    {
      "id": "1798971caf6c",
      "title": "Fair-Eye Net: A Fair, Trustworthy, Multimodal Integrated Glaucoma Full Chain AI System",
      "content": "arXiv:2601.18464v1 Announce Type: cross  Abstract: Glaucoma is a top cause of irreversible blindness globally, making early detection and longitudinal follow-up pivotal to preventing permanent vision loss. Current screening and progression assessment, however, rely on single tests or loosely linked examinations, introducing subjectivity and fragmented care. Limited access to high-quality imaging tools and specialist expertise further compromises consistency and equity in real-world use. To address these gaps, we developed Fair-Eye Net, a fair, reliable multimodal AI system closing the clinical loop from glaucoma screening to follow-up and risk alerting. It integrates fundus photos, OCT structural metrics, VF functional indices, and demographic factors via a dual-stream heterogeneous fusion architecture, with an uncertainty-aware hierarchical gating strategy for selective prediction and safe referral. A fairness constraint reduces missed diagnoses in disadvantaged subgroups. Experimental results show it achieved an AUC of 0.912 (96.7% specificity), cut racial false-negativity disparity by 73.4% (12.31% to 3.28%), maintained stable cross-domain performance, and enabled 3-12 months of early risk alerts (92% sensitivity, 88% specificity). Unlike post hoc fairness adjustments, Fair-Eye Net optimizes fairness as a primary goal with clinical reliability via multitask learning, offering a reproducible path for clinical translation and large-scale deployment to advance global eye health equity.",
      "url": "http://arxiv.org/abs/2601.18464",
      "author": "Wenbin Wei, Suyuan Yao, Cheng Huang, Xiangyu Gao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Develops Fair-Eye Net, multimodal AI system for glaucoma screening and follow-up integrating fundus photos, OCT, visual field indices, and demographics with fairness considerations.",
      "importance_score": 55,
      "reasoning": "Comprehensive medical AI system addressing equity concerns. Full clinical loop approach is practical but domain-specific.",
      "themes": [
        "Medical AI",
        "Fairness",
        "Ophthalmology"
      ],
      "continuation": null,
      "summary_html": "<p>Develops Fair-Eye Net, multimodal AI system for glaucoma screening and follow-up integrating fundus photos, OCT, visual field indices, and demographics with fairness considerations.</p>",
      "content_html": "<p>arXiv:2601.18464v1 Announce Type: cross  Abstract: Glaucoma is a top cause of irreversible blindness globally, making early detection and longitudinal follow-up pivotal to preventing permanent vision loss. Current screening and progression assessment, however, rely on single tests or loosely linked examinations, introducing subjectivity and fragmented care. Limited access to high-quality imaging tools and specialist expertise further compromises consistency and equity in real-world use. To address these gaps, we developed Fair-Eye Net, a fair, reliable multimodal AI system closing the clinical loop from glaucoma screening to follow-up and risk alerting. It integrates fundus photos, OCT structural metrics, VF functional indices, and demographic factors via a dual-stream heterogeneous fusion architecture, with an uncertainty-aware hierarchical gating strategy for selective prediction and safe referral. A fairness constraint reduces missed diagnoses in disadvantaged subgroups. Experimental results show it achieved an AUC of 0.912 (96.7% specificity), cut racial false-negativity disparity by 73.4% (12.31% to 3.28%), maintained stable cross-domain performance, and enabled 3-12 months of early risk alerts (92% sensitivity, 88% specificity). Unlike post hoc fairness adjustments, Fair-Eye Net optimizes fairness as a primary goal with clinical reliability via multitask learning, offering a reproducible path for clinical translation and large-scale deployment to advance global eye health equity.</p>"
    },
    {
      "id": "140334db881a",
      "title": "Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning",
      "content": "arXiv:2601.18626v1 Announce Type: cross  Abstract: Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full inverse-FIM. We theoretically show that under certain conditions, a rank-1 approximation to inverse-FIM converges faster than policy gradients and, under some conditions, enjoys the same sample complexity as stochastic policy gradient methods. We benchmark our method on a diverse set of environments and show that it achieves superior performance to standard actor-critic and trust-region baselines.",
      "url": "http://arxiv.org/abs/2601.18626",
      "author": "Yingxiao Huo, Satya Prakash Dash, Radu Stoican, Samuel Kaski, Mingfei Sun",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Presents efficient natural policy optimization using rank-1 approximation to inverse Fisher Information Matrix, proving faster convergence than policy gradients under certain conditions.",
      "importance_score": 55,
      "reasoning": "Technical contribution to efficient RL optimization. Theoretical guarantees provided but practical improvement magnitude unclear.",
      "themes": [
        "Reinforcement Learning",
        "Natural Gradients",
        "Policy Optimization"
      ],
      "continuation": null,
      "summary_html": "<p>Presents efficient natural policy optimization using rank-1 approximation to inverse Fisher Information Matrix, proving faster convergence than policy gradients under certain conditions.</p>",
      "content_html": "<p>arXiv:2601.18626v1 Announce Type: cross  Abstract: Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full inverse-FIM. We theoretically show that under certain conditions, a rank-1 approximation to inverse-FIM converges faster than policy gradients and, under some conditions, enjoys the same sample complexity as stochastic policy gradient methods. We benchmark our method on a diverse set of environments and show that it achieves superior performance to standard actor-critic and trust-region baselines.</p>"
    },
    {
      "id": "f6a7543d7a46",
      "title": "Advances and Innovations in the Multi-Agent Robotic System (MARS) Challenge",
      "content": "arXiv:2601.18733v1 Announce Type: cross  Abstract: Recent advancements in multimodal large language models and vision-languageaction models have significantly driven progress in Embodied AI. As the field transitions toward more complex task scenarios, multi-agent system frameworks are becoming essential for achieving scalable, efficient, and collaborative solutions. This shift is fueled by three primary factors: increasing agent capabilities, enhancing system efficiency through task delegation, and enabling advanced human-agent interactions. To address the challenges posed by multi-agent collaboration, we propose the Multi-Agent Robotic System (MARS) Challenge, held at the NeurIPS 2025 Workshop on SpaVLE. The competition focuses on two critical areas: planning and control, where participants explore multi-agent embodied planning using vision-language models (VLMs) to coordinate tasks and policy execution to perform robotic manipulation in dynamic environments. By evaluating solutions submitted by participants, the challenge provides valuable insights into the design and coordination of embodied multi-agent systems, contributing to the future development of advanced collaborative AI systems.",
      "url": "http://arxiv.org/abs/2601.18733",
      "author": "Li Kang, Heng Zhou, Xiufeng Song, Rui Li, Bruno N. Y. Chen, Ziye Wang, Ximeng Meng, Stone Tao, Yiran Qin, Xiaohong Liu, Ruimao Zhang, Lei Bai, Yilun Du, Hao Su, Philip Torr, Zhenfei Yin, Ruihao Gong, Yejun Zeng, Fengjun Zhong, Shenghao Jin, Jinyang Guo, Xianglong Liu, Xiaojun Jia, Tianqi Shan, Wenqi Ren, Simeng Qin, Jialing Yang, Xiaoyu Ma, Tianxing Chen, Zixuan Li, Zijian Cai, Yan Qin, Yusen Qin, Qiangyu Chen, Kaixuan Wang, Zhaoming Han, Yao Mu, Ping Luo, Yuanqi Yao, Haoming Song, Jan-Nico Zaech, Fabien Despinoy, Danda Pani Paudel, Luc Van Gool",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents MARS Challenge at NeurIPS 2025 Workshop on SpaVLE for multi-agent robotic systems, focusing on planning and control for embodied AI. Introduces benchmark for multi-agent collaboration.",
      "importance_score": 55,
      "reasoning": "Benchmark and challenge for emerging multi-agent embodied AI. Relevant for field development but primarily organizational contribution.",
      "themes": [
        "Multi-Agent Systems",
        "Embodied AI",
        "Benchmarking",
        "Robotics"
      ],
      "continuation": null,
      "summary_html": "<p>Presents MARS Challenge at NeurIPS 2025 Workshop on SpaVLE for multi-agent robotic systems, focusing on planning and control for embodied AI. Introduces benchmark for multi-agent collaboration.</p>",
      "content_html": "<p>arXiv:2601.18733v1 Announce Type: cross  Abstract: Recent advancements in multimodal large language models and vision-languageaction models have significantly driven progress in Embodied AI. As the field transitions toward more complex task scenarios, multi-agent system frameworks are becoming essential for achieving scalable, efficient, and collaborative solutions. This shift is fueled by three primary factors: increasing agent capabilities, enhancing system efficiency through task delegation, and enabling advanced human-agent interactions. To address the challenges posed by multi-agent collaboration, we propose the Multi-Agent Robotic System (MARS) Challenge, held at the NeurIPS 2025 Workshop on SpaVLE. The competition focuses on two critical areas: planning and control, where participants explore multi-agent embodied planning using vision-language models (VLMs) to coordinate tasks and policy execution to perform robotic manipulation in dynamic environments. By evaluating solutions submitted by participants, the challenge provides valuable insights into the design and coordination of embodied multi-agent systems, contributing to the future development of advanced collaborative AI systems.</p>"
    },
    {
      "id": "a2d33b27688f",
      "title": "Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets",
      "content": "arXiv:2601.18791v1 Announce Type: cross  Abstract: We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing 'glottosets' from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity at scale. Evaluations demonstrate that BPE segmentation aligns with morpheme boundaries 95% better than random baseline across 15 languages (F1 = 0.34 vs 0.15). BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p < 0.001), with Romance languages forming the tightest cluster (mean distance 0.51) and cross-family pairs showing clear separation (0.82). Analysis of 26,939 cross-linguistic homographs reveals that 48.7% receive different segmentations across related languages, with variation correlating to phylogenetic distance. Our results provide quantitative macro-linguistic insights into lexical patterns across typologically diverse languages within a unified analytical framework.",
      "url": "http://arxiv.org/abs/2601.18791",
      "author": "Iaroslav Chelombitko, Mika H\\\"am\\\"al\\\"ainen, Aleksey Komissarov",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Large-scale comparative study of 242 Latin/Cyrillic-script languages using BPE subword analysis of Wikipedia lexicons, showing 95% better morpheme boundary alignment than random baseline.",
      "importance_score": 55,
      "reasoning": "Impressive scale (242 languages). Shows BPE learns linguistic structure. Useful for multilingual NLP research.",
      "themes": [
        "Computational Linguistics",
        "Multilingual NLP",
        "Subword Tokenization"
      ],
      "continuation": null,
      "summary_html": "<p>Large-scale comparative study of 242 Latin/Cyrillic-script languages using BPE subword analysis of Wikipedia lexicons, showing 95% better morpheme boundary alignment than random baseline.</p>",
      "content_html": "<p>arXiv:2601.18791v1 Announce Type: cross  Abstract: We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing 'glottosets' from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity at scale. Evaluations demonstrate that BPE segmentation aligns with morpheme boundaries 95% better than random baseline across 15 languages (F1 = 0.34 vs 0.15). BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p &lt; 0.001), with Romance languages forming the tightest cluster (mean distance 0.51) and cross-family pairs showing clear separation (0.82). Analysis of 26,939 cross-linguistic homographs reveals that 48.7% receive different segmentations across related languages, with variation correlating to phylogenetic distance. Our results provide quantitative macro-linguistic insights into lexical patterns across typologically diverse languages within a unified analytical framework.</p>"
    },
    {
      "id": "bf1650ced0df",
      "title": "ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models",
      "content": "arXiv:2601.18796v1 Announce Type: cross  Abstract: Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical trials from novel vectors. We further show that generated trial abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects. Our public ELM implementation and experimental results will aid the alignment of Large Language Models to embedding spaces in the biomedical domain and beyond.",
      "url": "http://arxiv.org/abs/2601.18796",
      "author": "Brian Ondov, Chia-Hsuan Chang, Yujia Zhou, Mauro Giuffr\\`e, Hua Xu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Develops ctELM applying Embedding Language Model method to clinical trials, training LLMs to decode and manipulate clinical trial embeddings for description, comparison, and generation.",
      "importance_score": 55,
      "reasoning": "Novel application of ELM to clinical domain. Open-source framework contribution. Useful for clinical trial analysis but narrow domain.",
      "themes": [
        "Clinical AI",
        "Embedding Models",
        "Medical NLP"
      ],
      "continuation": null,
      "summary_html": "<p>Develops ctELM applying Embedding Language Model method to clinical trials, training LLMs to decode and manipulate clinical trial embeddings for description, comparison, and generation.</p>",
      "content_html": "<p>arXiv:2601.18796v1 Announce Type: cross  Abstract: Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical trials from novel vectors. We further show that generated trial abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects. Our public ELM implementation and experimental results will aid the alignment of Large Language Models to embedding spaces in the biomedical domain and beyond.</p>"
    },
    {
      "id": "f540df542342",
      "title": "PyHealth 2.0: A Comprehensive Open-Source Toolkit for Accessible and Reproducible Clinical Deep Learning",
      "content": "arXiv:2601.16414v1 Announce Type: new  Abstract: Difficulty replicating baselines, high computational costs, and required domain expertise create persistent barriers to clinical AI research. To address these challenges, we introduce PyHealth 2.0, an enhanced clinical deep learning toolkit that enables predictive modeling in as few as 7 lines of code. PyHealth 2.0 offers three key contributions: (1) a comprehensive toolkit addressing reproducibility and compatibility challenges by unifying 15+ datasets, 20+ clinical tasks, 25+ models, 5+ interpretability methods, and uncertainty quantification including conformal prediction within a single framework that supports diverse clinical data modalities - signals, imaging, and electronic health records - with translation of 5+ medical coding standards; (2) accessibility-focused design accommodating multimodal data and diverse computational resources with up to 39x faster processing and 20x lower memory usage, enabling work from 16GB laptops to production systems; and (3) an active open-source community of 400+ members lowering domain expertise barriers through extensive documentation, reproducible research contributions, and collaborations with academic health systems and industry partners, including multi-language support via RHealth. PyHealth 2.0 establishes an open-source foundation and community advancing accessible, reproducible healthcare AI. Available at pip install pyhealth.",
      "url": "http://arxiv.org/abs/2601.16414",
      "author": "John Wu, Yongda Fan, Zhenbang Wu, Paul Landes, Eric Schrock, Sayeed Sajjad Razin, Arjun Chatterjee, Naveen Baskaran, Joshua Steier, Andrea Fitzpatrick, Bilal Arif, Rian Atri, Jathurshan Pradeepkumar, Siddhartha Laghuvarapu, Junyi Gao, Adam R. Cross, Jimeng Sun",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "PyHealth 2.0 is a comprehensive clinical deep learning toolkit enabling predictive modeling in 7 lines of code. Unifies 15+ datasets, 20+ tasks, 25+ models with interpretability methods and uncertainty quantification.",
      "importance_score": 55,
      "reasoning": "Important infrastructure contribution for clinical AI research; addresses major reproducibility barriers but limited research novelty.",
      "themes": [
        "Healthcare AI",
        "Open Source Tools",
        "Reproducibility",
        "Clinical Deep Learning"
      ],
      "continuation": null,
      "summary_html": "<p>PyHealth 2.0 is a comprehensive clinical deep learning toolkit enabling predictive modeling in 7 lines of code. Unifies 15+ datasets, 20+ tasks, 25+ models with interpretability methods and uncertainty quantification.</p>",
      "content_html": "<p>arXiv:2601.16414v1 Announce Type: new  Abstract: Difficulty replicating baselines, high computational costs, and required domain expertise create persistent barriers to clinical AI research. To address these challenges, we introduce PyHealth 2.0, an enhanced clinical deep learning toolkit that enables predictive modeling in as few as 7 lines of code. PyHealth 2.0 offers three key contributions: (1) a comprehensive toolkit addressing reproducibility and compatibility challenges by unifying 15+ datasets, 20+ clinical tasks, 25+ models, 5+ interpretability methods, and uncertainty quantification including conformal prediction within a single framework that supports diverse clinical data modalities - signals, imaging, and electronic health records - with translation of 5+ medical coding standards; (2) accessibility-focused design accommodating multimodal data and diverse computational resources with up to 39x faster processing and 20x lower memory usage, enabling work from 16GB laptops to production systems; and (3) an active open-source community of 400+ members lowering domain expertise barriers through extensive documentation, reproducible research contributions, and collaborations with academic health systems and industry partners, including multi-language support via RHealth. PyHealth 2.0 establishes an open-source foundation and community advancing accessible, reproducible healthcare AI. Available at pip install pyhealth.</p>"
    },
    {
      "id": "30704758f998",
      "title": "On the Expressive Power of Floating-Point Transformers",
      "content": "arXiv:2601.16450v1 Announce Type: new  Abstract: The study on the expressive power of transformers shows that transformers are permutation equivariant, and they can approximate all permutation-equivariant continuous functions on a compact domain. However, these results are derived under real parameters and exact operations, while real implementations on computers can only use a finite set of numbers and inexact machine operations with round-off errors. In this work, we investigate the representability of floating-point transformers that use floating-point parameters and floating-point operations. Unlike existing results under exact operations, we first show that floating-point transformers can represent a class of non-permutation-equivariant functions even without positional encoding. Furthermore, we prove that floating-point transformers can represent all permutation-equivariant functions when the sequence length is bounded, but they cannot when the sequence length is large. We also found the minimal equivariance structure in floating-point transformers, and show that all non-trivial additive positional encoding can harm the representability of floating-point transformers.",
      "url": "http://arxiv.org/abs/2601.16450",
      "author": "Sejun Park, Yeachan Park, Geonho Hwang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Studies expressiveness of transformers under realistic floating-point parameters and operations. Shows floating-point transformers can represent non-permutation-equivariant functions without positional encoding, challenging existing theory.",
      "importance_score": 55,
      "reasoning": "Important theoretical contribution bridging gap between idealized analysis and practical implementation; reveals surprising properties.",
      "themes": [
        "Transformer Theory",
        "Expressiveness",
        "Numerical Computation"
      ],
      "continuation": null,
      "summary_html": "<p>Studies expressiveness of transformers under realistic floating-point parameters and operations. Shows floating-point transformers can represent non-permutation-equivariant functions without positional encoding, challenging existing theory.</p>",
      "content_html": "<p>arXiv:2601.16450v1 Announce Type: new  Abstract: The study on the expressive power of transformers shows that transformers are permutation equivariant, and they can approximate all permutation-equivariant continuous functions on a compact domain. However, these results are derived under real parameters and exact operations, while real implementations on computers can only use a finite set of numbers and inexact machine operations with round-off errors. In this work, we investigate the representability of floating-point transformers that use floating-point parameters and floating-point operations. Unlike existing results under exact operations, we first show that floating-point transformers can represent a class of non-permutation-equivariant functions even without positional encoding. Furthermore, we prove that floating-point transformers can represent all permutation-equivariant functions when the sequence length is bounded, but they cannot when the sequence length is large. We also found the minimal equivariance structure in floating-point transformers, and show that all non-trivial additive positional encoding can harm the representability of floating-point transformers.</p>"
    },
    {
      "id": "ca709cfc11c2",
      "title": "Rethinking Large Language Models For Irregular Time Series Classification In Critical Care",
      "content": "arXiv:2601.16516v2 Announce Type: new  Abstract: Time series data from the Intensive Care Unit (ICU) provides critical information for patient monitoring. While recent advancements in applying Large Language Models (LLMs) to time series modeling (TSM) have shown great promise, their effectiveness on the irregular ICU data, characterized by particularly high rates of missing values, remains largely unexplored. This work investigates two key components underlying the success of LLMs for TSM: the time series encoder and the multimodal alignment strategy. To this end, we establish a systematic testbed to evaluate their impact across various state-of-the-art LLM-based methods on benchmark ICU datasets against strong supervised and self-supervised baselines. Results reveal that the encoder design is more critical than the alignment strategy. Encoders that explicitly model irregularity achieve substantial performance gains, yielding an average AUPRC increase of $12.8\\%$ over the vanilla Transformer. While less impactful, the alignment strategy is also noteworthy, with the best-performing semantically rich, fusion-based strategy achieving a modest $2.9\\%$ improvement over cross-attention. However, LLM-based methods require at least 10$\\times$ longer training than the best-performing irregular supervised models, while delivering only comparable performance. They also underperform in data-scarce few-shot learning settings. These findings highlight both the promise and current limitations of LLMs for irregular ICU time series. The code is available at https://github.com/mHealthUnimelb/LLMTS.",
      "url": "http://arxiv.org/abs/2601.16516",
      "author": "Feixiang Zheng, Yu Wu, Cecilia Mascolo, Ting Dang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Systematically studies LLM-based methods for irregular ICU time series classification. Finds encoder design choices and alignment strategies are critical; strong baselines often outperform LLM approaches.",
      "importance_score": 55,
      "reasoning": "Important empirical study on LLMs for healthcare; provides practical guidance and challenges hype around LLMs for time series.",
      "themes": [
        "Large Language Models",
        "Healthcare AI",
        "Time Series",
        "ICU"
      ],
      "continuation": null,
      "summary_html": "<p>Systematically studies LLM-based methods for irregular ICU time series classification. Finds encoder design choices and alignment strategies are critical; strong baselines often outperform LLM approaches.</p>",
      "content_html": "<p>arXiv:2601.16516v2 Announce Type: new  Abstract: Time series data from the Intensive Care Unit (ICU) provides critical information for patient monitoring. While recent advancements in applying Large Language Models (LLMs) to time series modeling (TSM) have shown great promise, their effectiveness on the irregular ICU data, characterized by particularly high rates of missing values, remains largely unexplored. This work investigates two key components underlying the success of LLMs for TSM: the time series encoder and the multimodal alignment strategy. To this end, we establish a systematic testbed to evaluate their impact across various state-of-the-art LLM-based methods on benchmark ICU datasets against strong supervised and self-supervised baselines. Results reveal that the encoder design is more critical than the alignment strategy. Encoders that explicitly model irregularity achieve substantial performance gains, yielding an average AUPRC increase of $12.8\\%$ over the vanilla Transformer. While less impactful, the alignment strategy is also noteworthy, with the best-performing semantically rich, fusion-based strategy achieving a modest $2.9\\%$ improvement over cross-attention. However, LLM-based methods require at least 10$\\times$ longer training than the best-performing irregular supervised models, while delivering only comparable performance. They also underperform in data-scarce few-shot learning settings. These findings highlight both the promise and current limitations of LLMs for irregular ICU time series. The code is available at https://github.com/mHealthUnimelb/LLMTS.</p>"
    },
    {
      "id": "4859b9e8d4c5",
      "title": "E2Former-V2: On-the-Fly Equivariant Attention with Linear Activation Memory",
      "content": "arXiv:2601.16622v1 Announce Type: new  Abstract: Equivariant Graph Neural Networks (EGNNs) have become a widely used approach for modeling 3D atomistic systems. However, mainstream architectures face critical scalability bottlenecks due to the explicit construction of geometric features or dense tensor products on \\textit{every} edge. To overcome this, we introduce \\textbf{E2Former-V2}, a scalable architecture that integrates algebraic sparsity with hardware-aware execution. We first propose \\textbf{E}quivariant \\textbf{A}xis-\\textbf{A}ligned \\textbf{S}parsification (EAAS). EAAS builds on Wigner-$6j$ convolution by exploiting an $\\mathrm{SO}(3) \\rightarrow \\mathrm{SO}(2)$ change of basis to transform computationally expensive dense tensor contractions into efficient, sparse parity re-indexing operations. Building on this representation, we introduce \\textbf{On-the-Fly Equivariant Attention}, a fully node-centric mechanism implemented via a custom fused Triton kernel. By eliminating materialized edge tensors and maximizing SRAM utilization, our kernel achieves a \\textbf{20$\\times$ improvement in TFLOPS} compared to standard implementations. Extensive experiments on the SPICE and OMol25 datasets demonstrate that E2Former-V2 maintains comparable predictive performance while notably accelerating inference. This work demonstrates that large equivariant transformers can be trained efficiently using widely accessible GPU platforms. The code is avalible at https://github.com/IQuestLab/UBio-MolFM/tree/e2formerv2.",
      "url": "http://arxiv.org/abs/2601.16622",
      "author": "Lin Huang, Chengxiang Huang, Ziang Wang, Yiyue Du, Chu Wang, Haocheng Lu, Yunyang Li, Xiaoli Liu, Arthur Jiang, Jia Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces E2Former-V2 for scalable equivariant attention in molecular modeling with linear memory. Uses EAAS to exploit SO(3)SO(2) change of basis for efficient tensor contractions.",
      "importance_score": 55,
      "reasoning": "Addresses important scalability bottleneck in equivariant GNNs; enables practical application to larger molecular systems.",
      "themes": [
        "Equivariant GNNs",
        "Molecular Modeling",
        "Efficient Attention",
        "Scalability"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces E2Former-V2 for scalable equivariant attention in molecular modeling with linear memory. Uses EAAS to exploit SO(3)SO(2) change of basis for efficient tensor contractions.</p>",
      "content_html": "<p>arXiv:2601.16622v1 Announce Type: new  Abstract: Equivariant Graph Neural Networks (EGNNs) have become a widely used approach for modeling 3D atomistic systems. However, mainstream architectures face critical scalability bottlenecks due to the explicit construction of geometric features or dense tensor products on \\textit{every} edge. To overcome this, we introduce \\textbf{E2Former-V2}, a scalable architecture that integrates algebraic sparsity with hardware-aware execution. We first propose \\textbf{E}quivariant \\textbf{A}xis-\\textbf{A}ligned \\textbf{S}parsification (EAAS). EAAS builds on Wigner-$6j$ convolution by exploiting an $\\mathrm{SO}(3) \\rightarrow \\mathrm{SO}(2)$ change of basis to transform computationally expensive dense tensor contractions into efficient, sparse parity re-indexing operations. Building on this representation, we introduce \\textbf{On-the-Fly Equivariant Attention}, a fully node-centric mechanism implemented via a custom fused Triton kernel. By eliminating materialized edge tensors and maximizing SRAM utilization, our kernel achieves a \\textbf{20$\\times$ improvement in TFLOPS} compared to standard implementations. Extensive experiments on the SPICE and OMol25 datasets demonstrate that E2Former-V2 maintains comparable predictive performance while notably accelerating inference. This work demonstrates that large equivariant transformers can be trained efficiently using widely accessible GPU platforms. The code is avalible at https://github.com/IQuestLab/UBio-MolFM/tree/e2formerv2.</p>"
    },
    {
      "id": "25331be29b82",
      "title": "The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics",
      "content": "arXiv:2601.16849v1 Announce Type: new  Abstract: We demonstrate the power of human-LLM collaboration in tackling open problems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. Specifically, we target the generation of adversarial instances where these heuristics perform poorly. By iterating on FunSearch's outputs, we identify improved constructions for hierarchical $k$-median clustering, bin packing, the knapsack problem, and a generalization of Lov\\'asz's gasoline problem - some of these have not seen much improvement for over a decade, despite intermittent attention. These results illustrate how expert oversight can effectively extrapolate algorithmic insights from LLM-based evolutionary methods to break long-standing barriers.   Our findings demonstrate that while LLMs provide critical initial patterns, human expertise is essential for transforming these patterns into mathematically rigorous and insightful constructions. This work highlights that LLMs are a strong collaborative tool in mathematics and computer science research.",
      "url": "http://arxiv.org/abs/2601.16849",
      "author": "Henri Nikoleit, Ankit Anand, Anurag Murty Naredla, Heiko R\\\"oglin",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Demonstrates human-LLM collaboration using FunSearch to find adversarial instances where heuristics perform poorly. Achieves state-of-the-art lower bounds for k-median clustering, bin packing, and knapsack problems.",
      "importance_score": 55,
      "reasoning": "Compelling demonstration of human-AI collaboration for open problems; shows expert oversight enhances AI-generated solutions.",
      "themes": [
        "Human-AI Collaboration",
        "Combinatorial Optimization",
        "FunSearch",
        "Adversarial Examples"
      ],
      "continuation": null,
      "summary_html": "<p>Demonstrates human-LLM collaboration using FunSearch to find adversarial instances where heuristics perform poorly. Achieves state-of-the-art lower bounds for k-median clustering, bin packing, and knapsack problems.</p>",
      "content_html": "<p>arXiv:2601.16849v1 Announce Type: new  Abstract: We demonstrate the power of human-LLM collaboration in tackling open problems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. Specifically, we target the generation of adversarial instances where these heuristics perform poorly. By iterating on FunSearch's outputs, we identify improved constructions for hierarchical $k$-median clustering, bin packing, the knapsack problem, and a generalization of Lov\\'asz's gasoline problem - some of these have not seen much improvement for over a decade, despite intermittent attention. These results illustrate how expert oversight can effectively extrapolate algorithmic insights from LLM-based evolutionary methods to break long-standing barriers.   Our findings demonstrate that while LLMs provide critical initial patterns, human expertise is essential for transforming these patterns into mathematically rigorous and insightful constructions. This work highlights that LLMs are a strong collaborative tool in mathematics and computer science research.</p>"
    },
    {
      "id": "405230779807",
      "title": "Latent Causal Diffusions for Single-Cell Perturbation Modeling",
      "content": "arXiv:2601.15341v1 Announce Type: cross  Abstract: Perturbation screens hold the potential to systematically map regulatory processes at single-cell resolution, yet modeling and predicting transcriptome-wide responses to perturbations remains a major computational challenge. Existing methods often underperform simple baselines, fail to disentangle measurement noise from biological signal, and provide limited insight into the causal structure governing cellular responses. Here, we present the latent causal diffusion (LCD), a generative model that frames single-cell gene expression as a stationary diffusion process observed under measurement noise. LCD outperforms established approaches in predicting the distributional shifts of unseen perturbation combinations in single-cell RNA-sequencing screens while simultaneously learning a mechanistic dynamical system of gene regulation. To interpret these learned dynamics, we develop an approach we call causal linearization via perturbation responses (CLIPR), which yields an approximation of the direct causal effects between all genes modeled by the diffusion. CLIPR provably identifies causal effects under a linear drift assumption and recovers causal structure in both simulated systems and a genome-wide perturbation screen, where it clusters genes into coherent functional modules and resolves causal relationships that standard differential expression analysis cannot. The LCD-CLIPR framework bridges generative modeling with causal inference to predict unseen perturbation effects and map the underlying regulatory mechanisms of the transcriptome.",
      "url": "http://arxiv.org/abs/2601.15341",
      "author": "Lars Lorch, Jiaqi Zhang, Charlotte Bunne, Andreas Krause, Bernhard Sch\\\"olkopf, Caroline Uhler",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "q-bio.MN"
      ],
      "summary": "Proposes Latent Causal Diffusion (LCD) for single-cell perturbation modeling, framing gene expression as stationary diffusion under measurement noise. Outperforms existing approaches for predicting unseen perturbation combinations.",
      "importance_score": 55,
      "reasoning": "Novel approach to important computational biology problem; combines causal and diffusion frameworks effectively.",
      "themes": [
        "Single-Cell Analysis",
        "Causal Inference",
        "Diffusion Models",
        "Computational Biology"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Latent Causal Diffusion (LCD) for single-cell perturbation modeling, framing gene expression as stationary diffusion under measurement noise. Outperforms existing approaches for predicting unseen perturbation combinations.</p>",
      "content_html": "<p>arXiv:2601.15341v1 Announce Type: cross  Abstract: Perturbation screens hold the potential to systematically map regulatory processes at single-cell resolution, yet modeling and predicting transcriptome-wide responses to perturbations remains a major computational challenge. Existing methods often underperform simple baselines, fail to disentangle measurement noise from biological signal, and provide limited insight into the causal structure governing cellular responses. Here, we present the latent causal diffusion (LCD), a generative model that frames single-cell gene expression as a stationary diffusion process observed under measurement noise. LCD outperforms established approaches in predicting the distributional shifts of unseen perturbation combinations in single-cell RNA-sequencing screens while simultaneously learning a mechanistic dynamical system of gene regulation. To interpret these learned dynamics, we develop an approach we call causal linearization via perturbation responses (CLIPR), which yields an approximation of the direct causal effects between all genes modeled by the diffusion. CLIPR provably identifies causal effects under a linear drift assumption and recovers causal structure in both simulated systems and a genome-wide perturbation screen, where it clusters genes into coherent functional modules and resolves causal relationships that standard differential expression analysis cannot. The LCD-CLIPR framework bridges generative modeling with causal inference to predict unseen perturbation effects and map the underlying regulatory mechanisms of the transcriptome.</p>"
    },
    {
      "id": "58542de9fc7c",
      "title": "Towards Latent Diffusion Suitable For Text",
      "content": "arXiv:2601.16220v1 Announce Type: cross  Abstract: Language diffusion models aim to improve sampling speed and coherence over autoregressive LLMs. We introduce Neural Flow Diffusion Models for language generation, an extension of NFDM that enables the straightforward application of continuous diffusion models to discrete state spaces. NFDM learns a multivariate forward process from the data, ensuring that the forward process and generative trajectory are a good fit for language modeling. Our model substantially reduces the likelihood gap with autoregressive models of the same size, while achieving sample quality comparable to that of previous latent diffusion models.",
      "url": "http://arxiv.org/abs/2601.16220",
      "author": "Nesta Midavaine, Christian A. Naesseth, Grigory Bartosh",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces Neural Flow Diffusion Models for language generation that learns multivariate forward process from data. Substantially reduces likelihood gap with autoregressive models of same size.",
      "importance_score": 55,
      "reasoning": "Important progress on text diffusion models; addresses key challenge of fitting continuous diffusion to discrete text.",
      "themes": [
        "Diffusion Models",
        "Language Generation",
        "Text Generation"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Neural Flow Diffusion Models for language generation that learns multivariate forward process from data. Substantially reduces likelihood gap with autoregressive models of same size.</p>",
      "content_html": "<p>arXiv:2601.16220v1 Announce Type: cross  Abstract: Language diffusion models aim to improve sampling speed and coherence over autoregressive LLMs. We introduce Neural Flow Diffusion Models for language generation, an extension of NFDM that enables the straightforward application of continuous diffusion models to discrete state spaces. NFDM learns a multivariate forward process from the data, ensuring that the forward process and generative trajectory are a good fit for language modeling. Our model substantially reduces the likelihood gap with autoregressive models of the same size, while achieving sample quality comparable to that of previous latent diffusion models.</p>"
    },
    {
      "id": "d9fbb20a960e",
      "title": "SoundBreak: A Systematic Study of Audio-Only Adversarial Attacks on Trimodal Models",
      "content": "arXiv:2601.16231v1 Announce Type: cross  Abstract: Multimodal foundation models that integrate audio, vision, and language achieve strong performance on reasoning and generation tasks, yet their robustness to adversarial manipulation remains poorly understood. We study a realistic and underexplored threat model: untargeted, audio-only adversarial attacks on trimodal audio-video-language models. We analyze six complementary attack objectives that target different stages of multimodal processing, including audio encoder representations, cross-modal attention, hidden states, and output likelihoods. Across three state-of-the-art models and multiple benchmarks, we show that audio-only perturbations can induce severe multimodal failures, achieving up to 96% attack success rate. We further show that attacks can be successful at low perceptual distortions (LPIPS <= 0.08, SI-SNR >= 0) and benefit more from extended optimization than increased data scale. Transferability across models and encoders remains limited, while speech recognition systems such as Whisper primarily respond to perturbation magnitude, achieving >97% attack success under severe distortion. These results expose a previously overlooked single-modality attack surface in multimodal systems and motivate defenses that enforce cross-modal consistency.",
      "url": "http://arxiv.org/abs/2601.16231",
      "author": "Aafiya Hussain, Gaurav Srivastava, Alvi Ishmam, Zaber Hakim, Chris Thomas",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.SD"
      ],
      "summary": "First systematic study of audio-only adversarial attacks on trimodal audio-video-language models. Analyzes six attack objectives achieving up to 96% success rate, revealing severe multimodal vulnerabilities.",
      "importance_score": 55,
      "reasoning": "Important security research revealing vulnerabilities in multimodal models; practical threat model with comprehensive evaluation.",
      "themes": [
        "Adversarial Attacks",
        "Multimodal Models",
        "AI Security",
        "Audio Processing"
      ],
      "continuation": null,
      "summary_html": "<p>First systematic study of audio-only adversarial attacks on trimodal audio-video-language models. Analyzes six attack objectives achieving up to 96% success rate, revealing severe multimodal vulnerabilities.</p>",
      "content_html": "<p>arXiv:2601.16231v1 Announce Type: cross  Abstract: Multimodal foundation models that integrate audio, vision, and language achieve strong performance on reasoning and generation tasks, yet their robustness to adversarial manipulation remains poorly understood. We study a realistic and underexplored threat model: untargeted, audio-only adversarial attacks on trimodal audio-video-language models. We analyze six complementary attack objectives that target different stages of multimodal processing, including audio encoder representations, cross-modal attention, hidden states, and output likelihoods. Across three state-of-the-art models and multiple benchmarks, we show that audio-only perturbations can induce severe multimodal failures, achieving up to 96% attack success rate. We further show that attacks can be successful at low perceptual distortions (LPIPS &lt;= 0.08, SI-SNR &gt;= 0) and benefit more from extended optimization than increased data scale. Transferability across models and encoders remains limited, while speech recognition systems such as Whisper primarily respond to perturbation magnitude, achieving &gt;97% attack success under severe distortion. These results expose a previously overlooked single-modality attack surface in multimodal systems and motivate defenses that enforce cross-modal consistency.</p>"
    },
    {
      "id": "b5e593d74c58",
      "title": "GameTalk: Training LLMs for Strategic Conversation",
      "content": "arXiv:2601.16276v1 Announce Type: cross  Abstract: Strategic decision-making in multi-agent settings is a key challenge for large language models (LLMs), particularly when coordination and negotiation must unfold over extended conversations. While recent work has explored the use of LLMs in isolated decision tasks, little attention has been given to optimizing long-term objectives through dialogue. We introduce \\textbf{GameTalk}, a framework for training LLMs to make strategic decisions via multi-turn interactions. Unlike prior work that focuses on single-turn objectives or static action prediction, we train LLMs to optimize a global objective across full conversations. We achieve this by adapting fine-tuning methods like GRPO, DPO, and STaR to incorporate reward signals that depend on the entire interaction. We evaluate this approach on a suite of increasingly complex games, designed to stress different aspects of reasoning, coordination, and opponent modeling. Our results show that GameTalk significantly outperforms untrained models, especially under reward shaping, with DPO consistently yielding the strongest gains. These findings position conversational fine-tuning as a promising path for LLMs to reason, negotiate, and act in interactive environments.",
      "url": "http://arxiv.org/abs/2601.16276",
      "author": "Victor Conchello Vendrell, Max Ruiz Luyten, Mihaela van der Schaar",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces GameTalk framework for training LLMs to make strategic decisions via multi-turn dialogue. Adapts fine-tuning methods to optimize global objectives across full conversations.",
      "importance_score": 55,
      "reasoning": "Important for developing strategic reasoning in LLMs; addresses gap between single-turn and conversation-level objectives.",
      "themes": [
        "Large Language Models",
        "Strategic Reasoning",
        "Multi-Agent Systems",
        "Dialogue Systems"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces GameTalk framework for training LLMs to make strategic decisions via multi-turn dialogue. Adapts fine-tuning methods to optimize global objectives across full conversations.</p>",
      "content_html": "<p>arXiv:2601.16276v1 Announce Type: cross  Abstract: Strategic decision-making in multi-agent settings is a key challenge for large language models (LLMs), particularly when coordination and negotiation must unfold over extended conversations. While recent work has explored the use of LLMs in isolated decision tasks, little attention has been given to optimizing long-term objectives through dialogue. We introduce \\textbf{GameTalk}, a framework for training LLMs to make strategic decisions via multi-turn interactions. Unlike prior work that focuses on single-turn objectives or static action prediction, we train LLMs to optimize a global objective across full conversations. We achieve this by adapting fine-tuning methods like GRPO, DPO, and STaR to incorporate reward signals that depend on the entire interaction. We evaluate this approach on a suite of increasingly complex games, designed to stress different aspects of reasoning, coordination, and opponent modeling. Our results show that GameTalk significantly outperforms untrained models, especially under reward shaping, with DPO consistently yielding the strongest gains. These findings position conversational fine-tuning as a promising path for LLMs to reason, negotiate, and act in interactive environments.</p>"
    },
    {
      "id": "ceddf1d21d9c",
      "title": "Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis",
      "content": "arXiv:2601.17203v1 Announce Type: new  Abstract: Modern models for common NLP tasks often employ machine learning techniques and train on journalistic, social media, or other culturally-derived text. These have recently been scrutinized for racial and gender biases, rooting from inherent bias in their training text. These biases are often sub-optimal and recent work poses methods to rectify them; however, these biases may shed light on actual racial or gender gaps in the culture(s) that produced the training text, thereby helping us understand cultural context through big data. This paper presents an approach for quantifying gender bias in word embeddings, and then using them to characterize statistical gender gaps in education, politics, economics, and health. We validate these metrics on 2018 Twitter data spanning 51 U.S. regions and 99 countries. We correlate state and country word embedding biases with 18 international and 5 U.S.-based statistical gender gaps, characterizing regularities and predictive strength.",
      "url": "http://arxiv.org/abs/2601.17203",
      "author": "Scott Friedman, Sonja Schmer-Galunder, Anthony Chen, Jeffrey Rye",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents approach for quantifying gender bias in word embeddings and correlating them with real-world gender gaps in education, politics, economics, and health across cultures.",
      "importance_score": 55,
      "reasoning": "Useful methodology for bias analysis but builds on well-established techniques. Cross-cultural validation adds value.",
      "themes": [
        "Bias and Fairness",
        "Word Embeddings",
        "Cross-Cultural NLP"
      ],
      "continuation": null,
      "summary_html": "<p>Presents approach for quantifying gender bias in word embeddings and correlating them with real-world gender gaps in education, politics, economics, and health across cultures.</p>",
      "content_html": "<p>arXiv:2601.17203v1 Announce Type: new  Abstract: Modern models for common NLP tasks often employ machine learning techniques and train on journalistic, social media, or other culturally-derived text. These have recently been scrutinized for racial and gender biases, rooting from inherent bias in their training text. These biases are often sub-optimal and recent work poses methods to rectify them; however, these biases may shed light on actual racial or gender gaps in the culture(s) that produced the training text, thereby helping us understand cultural context through big data. This paper presents an approach for quantifying gender bias in word embeddings, and then using them to characterize statistical gender gaps in education, politics, economics, and health. We validate these metrics on 2018 Twitter data spanning 51 U.S. regions and 99 countries. We correlate state and country word embedding biases with 18 international and 5 U.S.-based statistical gender gaps, characterizing regularities and predictive strength.</p>"
    },
    {
      "id": "d6f5b1738851",
      "title": "Beyond the Rabbit Hole: Mapping the Relational Harms of QAnon Radicalization",
      "content": "arXiv:2601.17658v1 Announce Type: new  Abstract: The rise of conspiracy theories has created far-reaching societal harm in the public discourse by eroding trust and fueling polarization. Beyond this public impact lies a deeply personal toll on the friends and families of conspiracy believers, a dimension often overlooked in large-scale computational research. This study fills this gap by systematically mapping radicalization journeys and quantifying the associated emotional toll inflicted on loved ones. We use the prominent case of QAnon as a case study, analyzing 12747 narratives from the r/QAnonCasualties support community through a novel mixed-methods approach. First, we use topic modeling (BERTopic) to map the radicalization trajectories, identifying key pre-existing conditions, triggers, and post-radicalization characteristics. From this, we apply an LDA-based graphical model to uncover six recurring archetypes of QAnon adherents, which we term \"radicalization personas.\" Finally, using LLM-assisted emotion detection and regression modeling, we link these personas to the specific emotional toll reported by narrators. Our findings reveal that these personas are not just descriptive; they are powerful predictors of the specific emotional harms experienced by narrators. Radicalization perceived as a deliberate ideological choice is associated with narrator anger and disgust, while those marked by personal and cognitive collapse are linked to fear and sadness. This work provides the first empirical framework for understanding radicalization as a relational phenomenon, offering a vital roadmap for researchers and practitioners to navigate its interpersonal fallout.",
      "url": "http://arxiv.org/abs/2601.17658",
      "author": "Bich Ngoc (Rubi), Doan, Giuseppe Russo, Gianmarco De Francisci Morales, Robert West",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Maps QAnon radicalization journeys and emotional toll on families using BERTopic analysis of 12,747 narratives from r/QAnonCasualties. Identifies pre-existing conditions, triggers, and escalation patterns.",
      "importance_score": 55,
      "reasoning": "Important social science application of NLP methods. Valuable for understanding radicalization but limited ML novelty.",
      "themes": [
        "Computational Social Science",
        "Topic Modeling",
        "Misinformation"
      ],
      "continuation": null,
      "summary_html": "<p>Maps QAnon radicalization journeys and emotional toll on families using BERTopic analysis of 12,747 narratives from r/QAnonCasualties. Identifies pre-existing conditions, triggers, and escalation patterns.</p>",
      "content_html": "<p>arXiv:2601.17658v1 Announce Type: new  Abstract: The rise of conspiracy theories has created far-reaching societal harm in the public discourse by eroding trust and fueling polarization. Beyond this public impact lies a deeply personal toll on the friends and families of conspiracy believers, a dimension often overlooked in large-scale computational research. This study fills this gap by systematically mapping radicalization journeys and quantifying the associated emotional toll inflicted on loved ones. We use the prominent case of QAnon as a case study, analyzing 12747 narratives from the r/QAnonCasualties support community through a novel mixed-methods approach. First, we use topic modeling (BERTopic) to map the radicalization trajectories, identifying key pre-existing conditions, triggers, and post-radicalization characteristics. From this, we apply an LDA-based graphical model to uncover six recurring archetypes of QAnon adherents, which we term \"radicalization personas.\" Finally, using LLM-assisted emotion detection and regression modeling, we link these personas to the specific emotional toll reported by narrators. Our findings reveal that these personas are not just descriptive; they are powerful predictors of the specific emotional harms experienced by narrators. Radicalization perceived as a deliberate ideological choice is associated with narrator anger and disgust, while those marked by personal and cognitive collapse are linked to fear and sadness. This work provides the first empirical framework for understanding radicalization as a relational phenomenon, offering a vital roadmap for researchers and practitioners to navigate its interpersonal fallout.</p>"
    },
    {
      "id": "d86d314610c7",
      "title": "Using Large Language Models to Construct Virtual Top Managers: A Method for Organizational Research",
      "content": "arXiv:2601.18512v1 Announce Type: new  Abstract: This study introduces a methodological framework that uses large language models to create virtual personas of real top managers. Drawing on real CEO communications and Moral Foundations Theory, we construct LLM-based participants that simulate the decision-making of individual leaders. Across three phases, we assess construct validity, reliability, and behavioral fidelity by benchmarking these virtual CEOs against human participants. Our results indicate that theoretically scaffolded personas approximate the moral judgements observed in human samples, suggesting that LLM-based personas can serve as credible and complementary tools for organizational research in contexts where direct access to executives is limited. We conclude by outlining implications for future research using LLM-based personas in organizational settings.",
      "url": "http://arxiv.org/abs/2601.18512",
      "author": "Antonio Garzon-Vico, Krithika Sharon Komalapati, Arsalan Shahid, Jan Rosier",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces framework using LLMs to create virtual personas of real CEOs based on their communications and Moral Foundations Theory. Validates against human participants for organizational research.",
      "importance_score": 55,
      "reasoning": "Novel methodology for organizational research with careful validation. Limited technical contribution but interesting application.",
      "themes": [
        "LLM Applications",
        "Organizational Research",
        "Persona Modeling"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces framework using LLMs to create virtual personas of real CEOs based on their communications and Moral Foundations Theory. Validates against human participants for organizational research.</p>",
      "content_html": "<p>arXiv:2601.18512v1 Announce Type: new  Abstract: This study introduces a methodological framework that uses large language models to create virtual personas of real top managers. Drawing on real CEO communications and Moral Foundations Theory, we construct LLM-based participants that simulate the decision-making of individual leaders. Across three phases, we assess construct validity, reliability, and behavioral fidelity by benchmarking these virtual CEOs against human participants. Our results indicate that theoretically scaffolded personas approximate the moral judgements observed in human samples, suggesting that LLM-based personas can serve as credible and complementary tools for organizational research in contexts where direct access to executives is limited. We conclude by outlining implications for future research using LLM-based personas in organizational settings.</p>"
    },
    {
      "id": "d84af492c81e",
      "title": "Integrating Fine-Grained Audio-Visual Evidence for Robust Multimodal Emotion Reasoning",
      "content": "arXiv:2601.18321v1 Announce Type: cross  Abstract: Multimodal emotion analysis is shifting from static classification to generative reasoning. Beyond simple label prediction, robust affective reasoning must synthesize fine-grained signals such as facial micro-expressions and prosodic which shifts to decode the latent causality within complex social contexts. However, current Multimodal Large Language Models (MLLMs) face significant limitations in fine-grained perception, primarily due to data scarcity and insufficient cross-modal fusion. As a result, these models often exhibit unimodal dominance which leads to hallucinations in complex multimodal interactions, particularly when visual and acoustic cues are subtle, ambiguous, or even contradictory (e.g., in sarcastic scenery). To address this, we introduce SABER-LLM, a framework designed for robust multimodal reasoning. First, we construct SABER, a large-scale emotion reasoning dataset comprising 600K video clips, annotated with a novel six-dimensional schema that jointly captures audiovisual cues and causal logic. Second, we propose the structured evidence decomposition paradigm, which enforces a \"perceive-then-reason\" separation between evidence extraction and reasoning to alleviate unimodal dominance. The ability to perceive complex scenes is further reinforced by consistency-aware direct preference optimization, which explicitly encourages alignment among modalities under ambiguous or conflicting perceptual conditions. Experiments on EMER, EmoBench-M, and SABER-Test demonstrate that SABER-LLM significantly outperforms open-source baselines and achieves robustness competitive with closed-source models in decoding complex emotional dynamics. The dataset and model are available at https://github.com/zxzhao0/SABER-LLM.",
      "url": "http://arxiv.org/abs/2601.18321",
      "author": "Zhixian Zhao, Wenjie Tian, Xiaohai Tian, Jun Zhang, Lei Xie",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.MM"
      ],
      "summary": "Proposes framework for multimodal emotion reasoning integrating fine-grained audio-visual evidence. Addresses MLLM limitations in perceiving subtle cues and unimodal dominance leading to hallucinations.",
      "importance_score": 55,
      "reasoning": "Addresses important challenge in affective computing but incremental contribution to multimodal understanding.",
      "themes": [
        "Emotion AI",
        "Multimodal Learning",
        "Affective Computing"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes framework for multimodal emotion reasoning integrating fine-grained audio-visual evidence. Addresses MLLM limitations in perceiving subtle cues and unimodal dominance leading to hallucinations.</p>",
      "content_html": "<p>arXiv:2601.18321v1 Announce Type: cross  Abstract: Multimodal emotion analysis is shifting from static classification to generative reasoning. Beyond simple label prediction, robust affective reasoning must synthesize fine-grained signals such as facial micro-expressions and prosodic which shifts to decode the latent causality within complex social contexts. However, current Multimodal Large Language Models (MLLMs) face significant limitations in fine-grained perception, primarily due to data scarcity and insufficient cross-modal fusion. As a result, these models often exhibit unimodal dominance which leads to hallucinations in complex multimodal interactions, particularly when visual and acoustic cues are subtle, ambiguous, or even contradictory (e.g., in sarcastic scenery). To address this, we introduce SABER-LLM, a framework designed for robust multimodal reasoning. First, we construct SABER, a large-scale emotion reasoning dataset comprising 600K video clips, annotated with a novel six-dimensional schema that jointly captures audiovisual cues and causal logic. Second, we propose the structured evidence decomposition paradigm, which enforces a \"perceive-then-reason\" separation between evidence extraction and reasoning to alleviate unimodal dominance. The ability to perceive complex scenes is further reinforced by consistency-aware direct preference optimization, which explicitly encourages alignment among modalities under ambiguous or conflicting perceptual conditions. Experiments on EMER, EmoBench-M, and SABER-Test demonstrate that SABER-LLM significantly outperforms open-source baselines and achieves robustness competitive with closed-source models in decoding complex emotional dynamics. The dataset and model are available at https://github.com/zxzhao0/SABER-LLM.</p>"
    },
    {
      "id": "4b2164e83f26",
      "title": "OCR-Enhanced Multimodal ASR Can Read While Listening",
      "content": "arXiv:2601.18393v1 Announce Type: cross  Abstract: Visual information, such as subtitles in a movie, often helps automatic speech recognition. In this paper, we propose Donut-Whisper, an audio-visual ASR model with dual encoder to leverage visual information to improve speech recognition performance in both English and Chinese. Donut-Whisper combines the advantage of the linear and the Q-Former-based modality alignment structures via a cross-attention module, generating more powerful audio-visual features. Meanwhile, we propose a lightweight knowledge distillation scheme showcasing the potential of using audio-visual models to teach audio-only models to achieve better performance. Moreover, we propose a new multilingual audio-visual speech recognition dataset based on movie clips containing both Chinese and English partitions. As a result, Donut-Whisper achieved significantly better performance on both English and Chinese partition of the dataset compared to both Donut and Whisper large V3 baselines. In particular, an absolute 5.75% WER reduction and a 16.5% absolute CER reduction were achieved on the English and Chinese sets respectively compared to the Whisper ASR baseline.",
      "url": "http://arxiv.org/abs/2601.18393",
      "author": "Junli Chen, Changli Tang, Yixuan Li, Guangzhi Sun, Chao Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.SD"
      ],
      "summary": "Proposes Donut-Whisper, an audio-visual ASR model combining linear and Q-Former alignment structures via cross-attention. Introduces new multilingual AV-ASR dataset from movie clips with subtitles.",
      "importance_score": 55,
      "reasoning": "Practical multimodal ASR improvement with new dataset contribution. Solid but incremental advancement.",
      "themes": [
        "Speech Recognition",
        "Multimodal Learning",
        "Dataset"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Donut-Whisper, an audio-visual ASR model combining linear and Q-Former alignment structures via cross-attention. Introduces new multilingual AV-ASR dataset from movie clips with subtitles.</p>",
      "content_html": "<p>arXiv:2601.18393v1 Announce Type: cross  Abstract: Visual information, such as subtitles in a movie, often helps automatic speech recognition. In this paper, we propose Donut-Whisper, an audio-visual ASR model with dual encoder to leverage visual information to improve speech recognition performance in both English and Chinese. Donut-Whisper combines the advantage of the linear and the Q-Former-based modality alignment structures via a cross-attention module, generating more powerful audio-visual features. Meanwhile, we propose a lightweight knowledge distillation scheme showcasing the potential of using audio-visual models to teach audio-only models to achieve better performance. Moreover, we propose a new multilingual audio-visual speech recognition dataset based on movie clips containing both Chinese and English partitions. As a result, Donut-Whisper achieved significantly better performance on both English and Chinese partition of the dataset compared to both Donut and Whisper large V3 baselines. In particular, an absolute 5.75% WER reduction and a 16.5% absolute CER reduction were achieved on the English and Chinese sets respectively compared to the Whisper ASR baseline.</p>"
    },
    {
      "id": "f932d668b525",
      "title": "Atomic Depth Estimation From Noisy Electron Microscopy Data Via Deep Learning",
      "content": "arXiv:2601.17046v1 Announce Type: new  Abstract: We present a novel approach for extracting 3D atomic-level information from transmission electron microscopy (TEM) images affected by significant noise. The approach is based on formulating depth estimation as a semantic segmentation problem. We address the resulting segmentation problem by training a deep convolutional neural network to generate pixel-wise depth segmentation maps using simulated data corrupted by synthetic noise. The proposed method was applied to estimate the depth of atomic columns in CeO2 nanoparticles from simulated images and real-world TEM data. Our experiments show that the resulting depth estimates are accurate, calibrated and robust to noise.",
      "url": "http://arxiv.org/abs/2601.17046",
      "author": "Matan Leibovich, Mai Tan, Adria Marcos-Morales, Sreyas Mohan, Peter A. Crozier, Carlos Fernandez-Granda",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes deep learning approach for estimating 3D atomic depth from noisy TEM images by formulating depth estimation as semantic segmentation, trained on simulated data with synthetic noise.",
      "importance_score": 55,
      "reasoning": "Specialized scientific application with novel framing of depth estimation problem for electron microscopy.",
      "themes": [
        "Scientific Imaging",
        "Deep Learning",
        "3D Reconstruction"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes deep learning approach for estimating 3D atomic depth from noisy TEM images by formulating depth estimation as semantic segmentation, trained on simulated data with synthetic noise.</p>",
      "content_html": "<p>arXiv:2601.17046v1 Announce Type: new  Abstract: We present a novel approach for extracting 3D atomic-level information from transmission electron microscopy (TEM) images affected by significant noise. The approach is based on formulating depth estimation as a semantic segmentation problem. We address the resulting segmentation problem by training a deep convolutional neural network to generate pixel-wise depth segmentation maps using simulated data corrupted by synthetic noise. The proposed method was applied to estimate the depth of atomic columns in CeO2 nanoparticles from simulated images and real-world TEM data. Our experiments show that the resulting depth estimates are accurate, calibrated and robust to noise.</p>"
    },
    {
      "id": "f03d7a1e0658",
      "title": "GRASP: Guided Region-Aware Sparse Prompting for Adapting MLLMs to Remote Sensing",
      "content": "arXiv:2601.17089v1 Announce Type: new  Abstract: In recent years, Multimodal Large Language Models (MLLMs) have made significant progress in visual question answering tasks. However, directly applying existing fine-tuning methods to remote sensing (RS) images often leads to issues such as overfitting on background noise or neglecting target details. This is primarily due to the large-scale variations, sparse target distributions, and complex regional semantic features inherent in RS images. These challenges limit the effectiveness of MLLMs in RS tasks. To address these challenges, we propose a parameter-efficient fine-tuning (PEFT) strategy called Guided Region-Aware Sparse Prompting (GRASP). GRASP introduces spatially structured soft prompts associated with spatial blocks extracted from a frozen visual token grid. Through a question-guided sparse fusion mechanism, GRASP dynamically aggregates task-specific context into a compact global prompt, enabling the model to focus on relevant regions while filtering out background noise. Extensive experiments on multiple RSVQA benchmarks show that GRASP achieves competitive performance compared to existing fine-tuning and prompt-based methods while maintaining high parameter efficiency.",
      "url": "http://arxiv.org/abs/2601.17089",
      "author": "Qigan Sun, Chaoning Zhang, Jianwei Zhang, Xudong Wang, Jiehui Xie, Pengcheng Zheng, Haoyu Wang, Sungyoung Lee, Chi-lok Andy Tai, Yang Yang, Heng Tao Shen",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes GRASP, a parameter-efficient fine-tuning strategy for adapting MLLMs to remote sensing using spatially structured soft prompts to address large-scale variations and sparse target distributions.",
      "importance_score": 55,
      "reasoning": "Addresses specific challenges in remote sensing MLLM adaptation with practical PEFT approach.",
      "themes": [
        "Remote Sensing",
        "PEFT",
        "Vision-Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes GRASP, a parameter-efficient fine-tuning strategy for adapting MLLMs to remote sensing using spatially structured soft prompts to address large-scale variations and sparse target distributions.</p>",
      "content_html": "<p>arXiv:2601.17089v1 Announce Type: new  Abstract: In recent years, Multimodal Large Language Models (MLLMs) have made significant progress in visual question answering tasks. However, directly applying existing fine-tuning methods to remote sensing (RS) images often leads to issues such as overfitting on background noise or neglecting target details. This is primarily due to the large-scale variations, sparse target distributions, and complex regional semantic features inherent in RS images. These challenges limit the effectiveness of MLLMs in RS tasks. To address these challenges, we propose a parameter-efficient fine-tuning (PEFT) strategy called Guided Region-Aware Sparse Prompting (GRASP). GRASP introduces spatially structured soft prompts associated with spatial blocks extracted from a frozen visual token grid. Through a question-guided sparse fusion mechanism, GRASP dynamically aggregates task-specific context into a compact global prompt, enabling the model to focus on relevant regions while filtering out background noise. Extensive experiments on multiple RSVQA benchmarks show that GRASP achieves competitive performance compared to existing fine-tuning and prompt-based methods while maintaining high parameter efficiency.</p>"
    },
    {
      "id": "29a0ec6c0507",
      "title": "FineVAU: A Novel Human-Aligned Benchmark for Fine-Grained Video Anomaly Understanding",
      "content": "arXiv:2601.17258v1 Announce Type: new  Abstract: Video Anomaly Understanding (VAU) is a novel task focused on describing unusual occurrences in videos. Despite growing interest, the evaluation of VAU remains an open challenge. Existing benchmarks rely on n-gram-based metrics (e.g., BLEU, ROUGE-L) or LLM-based evaluation. The first fails to capture the rich, free-form, and visually grounded nature of LVLM responses, while the latter focuses on assessing language quality over factual relevance, often resulting in subjective judgments that are misaligned with human perception. In this work, we address this issue by proposing FineVAU, a new benchmark for VAU that shifts the focus towards rich, fine-grained and domain-specific understanding of anomalous videos. We formulate VAU as a three-fold problem, with the goal of comprehensively understanding key descriptive elements of anomalies in video: events (What), participating entities (Who) and location (Where). Our benchmark introduces a) FVScore, a novel, human-aligned evaluation metric that assesses the presence of critical visual elements in LVLM answers, providing interpretable, fine-grained feedback; and b) FineW3, a novel, comprehensive dataset curated through a structured and fully automatic procedure that augments existing human annotations with high quality, fine-grained visual information. Human evaluation reveals that our proposed metric has a superior alignment with human perception of anomalies in comparison to current approaches. Detailed experiments on FineVAU unveil critical limitations in LVLM's ability to perceive anomalous events that require spatial and fine-grained temporal understanding, despite strong performance on coarse grain, static information, and events with strong visual cues.",
      "url": "http://arxiv.org/abs/2601.17258",
      "author": "Jo\\~ao Pereira, Vasco Lopes, Jo\\~ao Neves, David Semedo",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes FineVAU benchmark for Video Anomaly Understanding with fine-grained, domain-specific evaluation focusing on factual relevance over language quality, addressing misalignment with human perception.",
      "importance_score": 55,
      "reasoning": "Addresses important evaluation gap for video anomaly understanding with more rigorous benchmark.",
      "themes": [
        "Video Understanding",
        "Benchmarks",
        "Anomaly Detection"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes FineVAU benchmark for Video Anomaly Understanding with fine-grained, domain-specific evaluation focusing on factual relevance over language quality, addressing misalignment with human perception.</p>",
      "content_html": "<p>arXiv:2601.17258v1 Announce Type: new  Abstract: Video Anomaly Understanding (VAU) is a novel task focused on describing unusual occurrences in videos. Despite growing interest, the evaluation of VAU remains an open challenge. Existing benchmarks rely on n-gram-based metrics (e.g., BLEU, ROUGE-L) or LLM-based evaluation. The first fails to capture the rich, free-form, and visually grounded nature of LVLM responses, while the latter focuses on assessing language quality over factual relevance, often resulting in subjective judgments that are misaligned with human perception. In this work, we address this issue by proposing FineVAU, a new benchmark for VAU that shifts the focus towards rich, fine-grained and domain-specific understanding of anomalous videos. We formulate VAU as a three-fold problem, with the goal of comprehensively understanding key descriptive elements of anomalies in video: events (What), participating entities (Who) and location (Where). Our benchmark introduces a) FVScore, a novel, human-aligned evaluation metric that assesses the presence of critical visual elements in LVLM answers, providing interpretable, fine-grained feedback; and b) FineW3, a novel, comprehensive dataset curated through a structured and fully automatic procedure that augments existing human annotations with high quality, fine-grained visual information. Human evaluation reveals that our proposed metric has a superior alignment with human perception of anomalies in comparison to current approaches. Detailed experiments on FineVAU unveil critical limitations in LVLM's ability to perceive anomalous events that require spatial and fine-grained temporal understanding, despite strong performance on coarse grain, static information, and events with strong visual cues.</p>"
    },
    {
      "id": "c6b479ed7904",
      "title": "TEXTS-Diff: TEXTS-Aware Diffusion Model for Real-World Text Image Super-Resolution",
      "content": "arXiv:2601.17340v1 Announce Type: new  Abstract: Real-world text image super-resolution aims to restore overall visual quality and text legibility in images suffering from diverse degradations and text distortions. However, the scarcity of text image data in existing datasets results in poor performance on text regions. In addition, datasets consisting of isolated text samples limit the quality of background reconstruction. To address these limitations, we construct Real-Texts, a large-scale, high-quality dataset collected from real-world images, which covers diverse scenarios and contains natural text instances in both Chinese and English. Additionally, we propose the TEXTS-Aware Diffusion Model (TEXTS-Diff) to achieve high-quality generation in both background and textual regions. This approach leverages abstract concepts to improve the understanding of textual elements within visual scenes and concrete text regions to enhance textual details. It mitigates distortions and hallucination artifacts commonly observed in text regions, while preserving high-quality visual scene fidelity. Extensive experiments demonstrate that our method achieves state-of-the-art performance across multiple evaluation metrics, exhibiting superior generalization ability and text restoration accuracy in complex scenarios. All the code, model, and dataset will be released.",
      "url": "http://arxiv.org/abs/2601.17340",
      "author": "Haodong He, Xin Zhan, Yancheng Bai, Rui Lan, Lei Sun, Xiangxiang Chu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes TEXTS-Diff for real-world text image super-resolution with new Real-Texts dataset and TEXTS-aware diffusion model achieving high quality in both background and textual regions.",
      "importance_score": 55,
      "reasoning": "Addresses real challenge in text image SR with substantial dataset contribution.",
      "themes": [
        "Image Super-Resolution",
        "Text Recognition",
        "Dataset"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes TEXTS-Diff for real-world text image super-resolution with new Real-Texts dataset and TEXTS-aware diffusion model achieving high quality in both background and textual regions.</p>",
      "content_html": "<p>arXiv:2601.17340v1 Announce Type: new  Abstract: Real-world text image super-resolution aims to restore overall visual quality and text legibility in images suffering from diverse degradations and text distortions. However, the scarcity of text image data in existing datasets results in poor performance on text regions. In addition, datasets consisting of isolated text samples limit the quality of background reconstruction. To address these limitations, we construct Real-Texts, a large-scale, high-quality dataset collected from real-world images, which covers diverse scenarios and contains natural text instances in both Chinese and English. Additionally, we propose the TEXTS-Aware Diffusion Model (TEXTS-Diff) to achieve high-quality generation in both background and textual regions. This approach leverages abstract concepts to improve the understanding of textual elements within visual scenes and concrete text regions to enhance textual details. It mitigates distortions and hallucination artifacts commonly observed in text regions, while preserving high-quality visual scene fidelity. Extensive experiments demonstrate that our method achieves state-of-the-art performance across multiple evaluation metrics, exhibiting superior generalization ability and text restoration accuracy in complex scenarios. All the code, model, and dataset will be released.</p>"
    },
    {
      "id": "5b704320a618",
      "title": "UCAD: Uncertainty-guided Contour-aware Displacement for semi-supervised medical image segmentation",
      "content": "arXiv:2601.17366v1 Announce Type: new  Abstract: Existing displacement strategies in semi-supervised segmentation only operate on rectangular regions, ignoring anatomical structures and resulting in boundary distortions and semantic inconsistency. To address these issues, we propose UCAD, an Uncertainty-Guided Contour-Aware Displacement framework for semi-supervised medical image segmentation that preserves contour-aware semantics while enhancing consistency learning. Our UCAD leverages superpixels to generate anatomically coherent regions aligned with anatomy boundaries, and an uncertainty-guided selection mechanism to selectively displace challenging regions for better consistency learning. We further propose a dynamic uncertainty-weighted consistency loss, which adaptively stabilizes training and effectively regularizes the model on unlabeled regions. Extensive experiments demonstrate that UCAD consistently outperforms state-of-the-art semi-supervised segmentation methods, achieving superior segmentation accuracy under limited annotation. The code is available at:https://github.com/dcb937/UCAD.",
      "url": "http://arxiv.org/abs/2601.17366",
      "author": "Chengbo Ding, Fenghe Tang, Shaohua Kevin Zhou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes UCAD framework for semi-supervised medical segmentation using uncertainty-guided contour-aware displacement that preserves anatomical structures unlike rectangular region approaches.",
      "importance_score": 55,
      "reasoning": "Addresses real limitation in semi-supervised medical segmentation with principled approach.",
      "themes": [
        "Medical Image Segmentation",
        "Semi-supervised Learning",
        "Uncertainty"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes UCAD framework for semi-supervised medical segmentation using uncertainty-guided contour-aware displacement that preserves anatomical structures unlike rectangular region approaches.</p>",
      "content_html": "<p>arXiv:2601.17366v1 Announce Type: new  Abstract: Existing displacement strategies in semi-supervised segmentation only operate on rectangular regions, ignoring anatomical structures and resulting in boundary distortions and semantic inconsistency. To address these issues, we propose UCAD, an Uncertainty-Guided Contour-Aware Displacement framework for semi-supervised medical image segmentation that preserves contour-aware semantics while enhancing consistency learning. Our UCAD leverages superpixels to generate anatomically coherent regions aligned with anatomy boundaries, and an uncertainty-guided selection mechanism to selectively displace challenging regions for better consistency learning. We further propose a dynamic uncertainty-weighted consistency loss, which adaptively stabilizes training and effectively regularizes the model on unlabeled regions. Extensive experiments demonstrate that UCAD consistently outperforms state-of-the-art semi-supervised segmentation methods, achieving superior segmentation accuracy under limited annotation. The code is available at:https://github.com/dcb937/UCAD.</p>"
    },
    {
      "id": "5a547df79285",
      "title": "Will It Zero-Shot?: Will It Zero-Shot?: Predicting Zero-Shot Classification Performance For Arbitrary Queries",
      "content": "arXiv:2601.17535v1 Announce Type: new  Abstract: Vision-Language Models like CLIP create aligned embedding spaces for text and images, making it possible for anyone to build a visual classifier by simply naming the classes they want to distinguish. However, a model that works well in one domain may fail in another, and non-expert users have no straightforward way to assess whether their chosen VLM will work on their problem. We build on prior work using text-only comparisons to evaluate how well a model works for a given natural language task, and explore approaches that also generate synthetic images relevant to that task to evaluate and refine the prediction of zero-shot accuracy. We show that generated imagery to the baseline text-only scores substantially improves the quality of these predictions. Additionally, it gives a user feedback on the kinds of images that were used to make the assessment. Experiments on standard CLIP benchmark datasets demonstrate that the image-based approach helps users predict, without any labeled examples, whether a VLM will be effective for their application.",
      "url": "http://arxiv.org/abs/2601.17535",
      "author": "Kevin Robbins, Xiaotong Liu, Yu Wu, Le Sun, Grady McPeak, Abby Stylianou, Robert Pless",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes method to predict zero-shot classification performance for arbitrary queries using text-only comparisons and synthetic image generation to evaluate VLM task suitability without real data.",
      "importance_score": 55,
      "reasoning": "Practical contribution for assessing VLM applicability to new tasks without domain data.",
      "themes": [
        "Vision-Language Models",
        "Zero-shot Learning",
        "Evaluation"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes method to predict zero-shot classification performance for arbitrary queries using text-only comparisons and synthetic image generation to evaluate VLM task suitability without real data.</p>",
      "content_html": "<p>arXiv:2601.17535v1 Announce Type: new  Abstract: Vision-Language Models like CLIP create aligned embedding spaces for text and images, making it possible for anyone to build a visual classifier by simply naming the classes they want to distinguish. However, a model that works well in one domain may fail in another, and non-expert users have no straightforward way to assess whether their chosen VLM will work on their problem. We build on prior work using text-only comparisons to evaluate how well a model works for a given natural language task, and explore approaches that also generate synthetic images relevant to that task to evaluate and refine the prediction of zero-shot accuracy. We show that generated imagery to the baseline text-only scores substantially improves the quality of these predictions. Additionally, it gives a user feedback on the kinds of images that were used to make the assessment. Experiments on standard CLIP benchmark datasets demonstrate that the image-based approach helps users predict, without any labeled examples, whether a VLM will be effective for their application.</p>"
    },
    {
      "id": "b92168d0d0fb",
      "title": "Implicit Neural Representation-Based Continuous Single Image Super Resolution: An Empirical Study",
      "content": "arXiv:2601.17723v1 Announce Type: new  Abstract: Implicit neural representation (INR) has become the standard approach for arbitrary-scale image super-resolution (ASSR). To date, no empirical study has systematically examined the effectiveness of existing methods, nor investigated the effects of different training recipes, such as scaling laws, objective design, and optimization strategies. A rigorous empirical analysis is essential not only for benchmarking performance and revealing true gains but also for establishing the current state of ASSR, identifying saturation limits, and highlighting promising directions. We fill this gap by comparing existing techniques across diverse settings and presenting aggregated performance results on multiple image quality metrics. We contribute a unified framework and code repository to facilitate reproducible comparisons. Furthermore, we investigate the impact of carefully controlled training configurations on perceptual image quality and examine a new loss function that penalizes intensity variations while preserving edges, textures, and finer details during training. We conclude the following key insights that have been previously overlooked: (1) Recent, more complex INR methods provide only marginal improvements over earlier methods. (2) Model performance is strongly correlated to training configurations, a factor overlooked in prior works. (3) The proposed loss enhances texture fidelity across architectures, emphasizing the role of objective design for targeted perceptual gains. (4) Scaling laws apply to INR-based ASSR, confirming predictable gains with increased model complexity and data diversity.",
      "url": "http://arxiv.org/abs/2601.17723",
      "author": "Tayyab Nasir, Daochang Liu, Ajmal Mian",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Provides a comprehensive empirical study of implicit neural representation methods for arbitrary-scale image super-resolution, examining training recipes, scaling laws, and optimization strategies across multiple quality metrics.",
      "importance_score": 55,
      "reasoning": "Valuable meta-analysis establishing benchmarks and revealing saturation limits for INR-based super-resolution. Helps identify promising research directions.",
      "themes": [
        "Neural Representations",
        "Super Resolution",
        "Empirical Study"
      ],
      "continuation": null,
      "summary_html": "<p>Provides a comprehensive empirical study of implicit neural representation methods for arbitrary-scale image super-resolution, examining training recipes, scaling laws, and optimization strategies across multiple quality metrics.</p>",
      "content_html": "<p>arXiv:2601.17723v1 Announce Type: new  Abstract: Implicit neural representation (INR) has become the standard approach for arbitrary-scale image super-resolution (ASSR). To date, no empirical study has systematically examined the effectiveness of existing methods, nor investigated the effects of different training recipes, such as scaling laws, objective design, and optimization strategies. A rigorous empirical analysis is essential not only for benchmarking performance and revealing true gains but also for establishing the current state of ASSR, identifying saturation limits, and highlighting promising directions. We fill this gap by comparing existing techniques across diverse settings and presenting aggregated performance results on multiple image quality metrics. We contribute a unified framework and code repository to facilitate reproducible comparisons. Furthermore, we investigate the impact of carefully controlled training configurations on perceptual image quality and examine a new loss function that penalizes intensity variations while preserving edges, textures, and finer details during training. We conclude the following key insights that have been previously overlooked: (1) Recent, more complex INR methods provide only marginal improvements over earlier methods. (2) Model performance is strongly correlated to training configurations, a factor overlooked in prior works. (3) The proposed loss enhances texture fidelity across architectures, emphasizing the role of objective design for targeted perceptual gains. (4) Scaling laws apply to INR-based ASSR, confirming predictable gains with increased model complexity and data diversity.</p>"
    },
    {
      "id": "257c7660460d",
      "title": "SynMind: Reducing Semantic Hallucination in fMRI-Based Image Reconstruction",
      "content": "arXiv:2601.17857v1 Announce Type: new  Abstract: Recent advances in fMRI-based image reconstruction have achieved remarkable photo-realistic fidelity. Yet, a persistent limitation remains: while reconstructed images often appear naturalistic and holistically similar to the target stimuli, they frequently suffer from severe semantic misalignment -- salient objects are often replaced or hallucinated despite high visual quality. In this work, we address this limitation by rethinking the role of explicit semantic interpretation in fMRI decoding. We argue that existing methods rely too heavily on entangled visual embeddings which prioritize low-level appearance cues -- such as texture and global gist -- over explicit semantic identity. To overcome this, we parse fMRI signals into rich, sentence-level semantic descriptions that mirror the hierarchical and compositional nature of human visual understanding. We achieve this by leveraging grounded VLMs to generate synthetic, human-like, multi-granularity textual representations that capture object identities and spatial organization. Built upon this foundation, we propose SynMind, a framework that integrates these explicit semantic encodings with visual priors to condition a pretrained diffusion model. Extensive experiments demonstrate that SynMind outperforms state-of-the-art methods across most quantitative metrics. Notably, by offloading semantic reasoning to our text-alignment module, SynMind surpasses competing methods based on SDXL while using the much smaller Stable Diffusion 1.4 and a single consumer GPU. Large-scale human evaluations further confirm that SynMind produces reconstructions more consistent with human visual perception. Neurovisualization analyses reveal that SynMind engages broader and more semantically relevant brain regions, mitigating the over-reliance on high-level visual areas.",
      "url": "http://arxiv.org/abs/2601.17857",
      "author": "Lan Yang, Minghan Yang, Ke Li, Honggang Zhang, Kaiyue Pang, Yi-Zhe Song",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "SynMind addresses semantic hallucination in fMRI-based image reconstruction by parsing fMRI signals into rich sentence-level semantic descriptions rather than relying solely on entangled visual embeddings.",
      "importance_score": 55,
      "reasoning": "Interesting approach to brain-to-image generation addressing known hallucination problem. Novel angle on semantic grounding.",
      "themes": [
        "Brain-Computer Interfaces",
        "Neural Decoding",
        "Semantic Alignment"
      ],
      "continuation": null,
      "summary_html": "<p>SynMind addresses semantic hallucination in fMRI-based image reconstruction by parsing fMRI signals into rich sentence-level semantic descriptions rather than relying solely on entangled visual embeddings.</p>",
      "content_html": "<p>arXiv:2601.17857v1 Announce Type: new  Abstract: Recent advances in fMRI-based image reconstruction have achieved remarkable photo-realistic fidelity. Yet, a persistent limitation remains: while reconstructed images often appear naturalistic and holistically similar to the target stimuli, they frequently suffer from severe semantic misalignment -- salient objects are often replaced or hallucinated despite high visual quality. In this work, we address this limitation by rethinking the role of explicit semantic interpretation in fMRI decoding. We argue that existing methods rely too heavily on entangled visual embeddings which prioritize low-level appearance cues -- such as texture and global gist -- over explicit semantic identity. To overcome this, we parse fMRI signals into rich, sentence-level semantic descriptions that mirror the hierarchical and compositional nature of human visual understanding. We achieve this by leveraging grounded VLMs to generate synthetic, human-like, multi-granularity textual representations that capture object identities and spatial organization. Built upon this foundation, we propose SynMind, a framework that integrates these explicit semantic encodings with visual priors to condition a pretrained diffusion model. Extensive experiments demonstrate that SynMind outperforms state-of-the-art methods across most quantitative metrics. Notably, by offloading semantic reasoning to our text-alignment module, SynMind surpasses competing methods based on SDXL while using the much smaller Stable Diffusion 1.4 and a single consumer GPU. Large-scale human evaluations further confirm that SynMind produces reconstructions more consistent with human visual perception. Neurovisualization analyses reveal that SynMind engages broader and more semantically relevant brain regions, mitigating the over-reliance on high-level visual areas.</p>"
    },
    {
      "id": "7d01412a3293",
      "title": "RemEdit: Efficient Diffusion Editing with Riemannian Geometry",
      "content": "arXiv:2601.17927v1 Announce Type: new  Abstract: Controllable image generation is fundamental to the success of modern generative AI, yet it faces a critical trade-off between semantic fidelity and inference speed. The RemEdit diffusion-based framework addresses this trade-off with two synergistic innovations. First, for editing fidelity, we navigate the latent space as a Riemannian manifold. A mamba-based module efficiently learns the manifold's structure, enabling direct and accurate geodesic path computation for smooth semantic edits. This control is further refined by a dual-SLERP blending technique and a goal-aware prompt enrichment pass from a Vision-Language Model. Second, for additional acceleration, we introduce a novel task-specific attention pruning mechanism. A lightweight pruning head learns to retain tokens essential to the edit, enabling effective optimization without the semantic degradation common in content-agnostic approaches. RemEdit surpasses prior state-of-the-art editing frameworks while maintaining real-time performance under 50% pruning. Consequently, RemEdit establishes a new benchmark for practical and powerful image editing. Source code: https://www.github.com/eashanadhikarla/RemEdit.",
      "url": "http://arxiv.org/abs/2601.17927",
      "author": "Eashan Adhikarla, Brian D. Davison",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "RemEdit combines Riemannian manifold geometry for semantic diffusion editing with task-specific attention pruning and VLM-guided prompt enrichment for efficient controllable image generation.",
      "importance_score": 55,
      "reasoning": "Multiple innovations combined (Riemannian geometry, attention pruning, VLM guidance) but each component is incremental.",
      "themes": [
        "Diffusion Models",
        "Image Editing",
        "Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>RemEdit combines Riemannian manifold geometry for semantic diffusion editing with task-specific attention pruning and VLM-guided prompt enrichment for efficient controllable image generation.</p>",
      "content_html": "<p>arXiv:2601.17927v1 Announce Type: new  Abstract: Controllable image generation is fundamental to the success of modern generative AI, yet it faces a critical trade-off between semantic fidelity and inference speed. The RemEdit diffusion-based framework addresses this trade-off with two synergistic innovations. First, for editing fidelity, we navigate the latent space as a Riemannian manifold. A mamba-based module efficiently learns the manifold's structure, enabling direct and accurate geodesic path computation for smooth semantic edits. This control is further refined by a dual-SLERP blending technique and a goal-aware prompt enrichment pass from a Vision-Language Model. Second, for additional acceleration, we introduce a novel task-specific attention pruning mechanism. A lightweight pruning head learns to retain tokens essential to the edit, enabling effective optimization without the semantic degradation common in content-agnostic approaches. RemEdit surpasses prior state-of-the-art editing frameworks while maintaining real-time performance under 50% pruning. Consequently, RemEdit establishes a new benchmark for practical and powerful image editing. Source code: https://www.github.com/eashanadhikarla/RemEdit.</p>"
    },
    {
      "id": "b656d4ec3cf9",
      "title": "Domain-Expert-Guided Hybrid Mixture-of-Experts for Medical AI: Integrating Data-Driven Learning with Clinical Priors",
      "content": "arXiv:2601.17977v1 Announce Type: new  Abstract: Mixture-of-Experts (MoE) models increase representational capacity with modest computational cost, but their effectiveness in specialized domains such as medicine is limited by small datasets. In contrast, clinical practice offers rich expert knowledge, such as physician gaze patterns and diagnostic heuristics, that models cannot reliably learn from limited data. Combining data-driven experts, which capture novel patterns, with domain-expert-guided experts, which encode accumulated clinical insights, provides complementary strengths for robust and clinically meaningful learning. To this end, we propose Domain-Knowledge-Guided Hybrid MoE (DKGH-MoE), a plug-and-play and interpretable module that unifies data-driven learning with domain expertise. DKGH-MoE integrates a data-driven MoE to extract novel features from raw imaging data, and a domain-expert-guided MoE incorporates clinical priors, specifically clinician eye-gaze cues, to emphasize regions of high diagnostic relevance. By integrating domain expert insights with data-driven features, DKGH-MoE improves both performance and interpretability.",
      "url": "http://arxiv.org/abs/2601.17977",
      "author": "Jinchen Gu, Nan Zhao, Lei Qiu, Lu Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "DKGH-MoE unifies data-driven experts with domain-expert-guided experts that encode clinical knowledge like physician gaze patterns, providing a plug-and-play interpretable module for medical AI.",
      "importance_score": 55,
      "reasoning": "Interesting hybrid approach integrating clinical knowledge into MoE. Addresses data scarcity in medical domains.",
      "themes": [
        "Mixture of Experts",
        "Medical AI",
        "Domain Knowledge"
      ],
      "continuation": null,
      "summary_html": "<p>DKGH-MoE unifies data-driven experts with domain-expert-guided experts that encode clinical knowledge like physician gaze patterns, providing a plug-and-play interpretable module for medical AI.</p>",
      "content_html": "<p>arXiv:2601.17977v1 Announce Type: new  Abstract: Mixture-of-Experts (MoE) models increase representational capacity with modest computational cost, but their effectiveness in specialized domains such as medicine is limited by small datasets. In contrast, clinical practice offers rich expert knowledge, such as physician gaze patterns and diagnostic heuristics, that models cannot reliably learn from limited data. Combining data-driven experts, which capture novel patterns, with domain-expert-guided experts, which encode accumulated clinical insights, provides complementary strengths for robust and clinically meaningful learning. To this end, we propose Domain-Knowledge-Guided Hybrid MoE (DKGH-MoE), a plug-and-play and interpretable module that unifies data-driven learning with domain expertise. DKGH-MoE integrates a data-driven MoE to extract novel features from raw imaging data, and a domain-expert-guided MoE incorporates clinical priors, specifically clinician eye-gaze cues, to emphasize regions of high diagnostic relevance. By integrating domain expert insights with data-driven features, DKGH-MoE improves both performance and interpretability.</p>"
    },
    {
      "id": "ee1344deb121",
      "title": "HomoFM: Deep Homography Estimation with Flow Matching",
      "content": "arXiv:2601.18222v1 Announce Type: new  Abstract: Deep homography estimation has broad applications in computer vision and robotics. Remarkable progresses have been achieved while the existing methods typically treat it as a direct regression or iterative refinement problem and often struggling to capture complex geometric transformations or generalize across different domains. In this work, we propose HomoFM, a new framework that introduces the flow matching technique from generative modeling into the homography estimation task for the first time. Unlike the existing methods, we formulate homography estimation problem as a velocity field learning problem. By modeling a continuous and point-wise velocity field that transforms noisy distributions into registered coordinates, the proposed network recovers high-precision transformations through a conditional flow trajectory. Furthermore, to address the challenge of domain shifts issue, e.g., the cases of multimodal matching or varying illumination scenarios, we integrate a gradient reversal layer (GRL) into the feature extraction backbone. This domain adaptation strategy explicitly constrains the encoder to learn domain-invariant representations, significantly enhancing the network's robustness. Extensive experiments demonstrate the effectiveness of the proposed method, showing that HomoFM outperforms state-of-the-art methods in both estimation accuracy and robustness on standard benchmarks. Code and data resource are available at https://github.com/hmf21/HomoFM.",
      "url": "http://arxiv.org/abs/2601.18222",
      "author": "Mengfan He, Liangzheng Sun, Chunyu Li, Ziyang Meng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "HomoFM applies flow matching from generative modeling to homography estimation for the first time, formulating it as velocity field learning for continuous point-wise transformation.",
      "importance_score": 55,
      "reasoning": "Novel application of flow matching to geometric estimation. Interesting cross-pollination of techniques.",
      "themes": [
        "Homography Estimation",
        "Flow Matching",
        "Geometric Vision"
      ],
      "continuation": null,
      "summary_html": "<p>HomoFM applies flow matching from generative modeling to homography estimation for the first time, formulating it as velocity field learning for continuous point-wise transformation.</p>",
      "content_html": "<p>arXiv:2601.18222v1 Announce Type: new  Abstract: Deep homography estimation has broad applications in computer vision and robotics. Remarkable progresses have been achieved while the existing methods typically treat it as a direct regression or iterative refinement problem and often struggling to capture complex geometric transformations or generalize across different domains. In this work, we propose HomoFM, a new framework that introduces the flow matching technique from generative modeling into the homography estimation task for the first time. Unlike the existing methods, we formulate homography estimation problem as a velocity field learning problem. By modeling a continuous and point-wise velocity field that transforms noisy distributions into registered coordinates, the proposed network recovers high-precision transformations through a conditional flow trajectory. Furthermore, to address the challenge of domain shifts issue, e.g., the cases of multimodal matching or varying illumination scenarios, we integrate a gradient reversal layer (GRL) into the feature extraction backbone. This domain adaptation strategy explicitly constrains the encoder to learn domain-invariant representations, significantly enhancing the network's robustness. Extensive experiments demonstrate the effectiveness of the proposed method, showing that HomoFM outperforms state-of-the-art methods in both estimation accuracy and robustness on standard benchmarks. Code and data resource are available at https://github.com/hmf21/HomoFM.</p>"
    },
    {
      "id": "aece943c351c",
      "title": "SwipeGen: Bridging the Execution Gap in GUI Agents via Human-like Swipe Synthesis",
      "content": "arXiv:2601.18305v1 Announce Type: new  Abstract: With the widespread adoption of Graphical User Interface (GUI) agents for automating GUI interaction tasks, substantial research focused on improving GUI perception to ground task instructions into concrete action steps. However, the step execution capability of these agents has gradually emerged as a new bottleneck for task completion. In particular, existing GUI agents often adopt overly simplified strategies for handling swipe interactions, preventing them from accurately replicating human-like behavior. To address this limitation, we decompose human swipe gestures into multiple quantifiable dimensions and propose an automated pipeline SwipeGen to synthesize human-like swipe interactions through GUI exploration. Based on this pipeline, we construct and release the first benchmark for evaluating the swipe execution capability of GUI agents. Furthermore, leveraging the synthesized data, we propose GUISwiper, a GUI agent with enhanced interaction execution capabilities. Experimental results demonstrate that GUISwiper achieves a swipe execution accuracy of 69.07%, representing a 214% improvement over existing VLM baselines.",
      "url": "http://arxiv.org/abs/2601.18305",
      "author": "Xuan Wang, Siyuan Su, Quantong Fu, Yongxiang Hu, Yangfan Zhou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "SwipeGen addresses GUI agent execution capability by decomposing human swipe gestures into quantifiable dimensions and synthesizing human-like swipe interactions through automated GUI exploration.",
      "importance_score": 55,
      "reasoning": "Addresses overlooked bottleneck in GUI agents. Practical contribution for agent systems.",
      "themes": [
        "GUI Agents",
        "Human-Computer Interaction",
        "Gesture Synthesis"
      ],
      "continuation": null,
      "summary_html": "<p>SwipeGen addresses GUI agent execution capability by decomposing human swipe gestures into quantifiable dimensions and synthesizing human-like swipe interactions through automated GUI exploration.</p>",
      "content_html": "<p>arXiv:2601.18305v1 Announce Type: new  Abstract: With the widespread adoption of Graphical User Interface (GUI) agents for automating GUI interaction tasks, substantial research focused on improving GUI perception to ground task instructions into concrete action steps. However, the step execution capability of these agents has gradually emerged as a new bottleneck for task completion. In particular, existing GUI agents often adopt overly simplified strategies for handling swipe interactions, preventing them from accurately replicating human-like behavior. To address this limitation, we decompose human swipe gestures into multiple quantifiable dimensions and propose an automated pipeline SwipeGen to synthesize human-like swipe interactions through GUI exploration. Based on this pipeline, we construct and release the first benchmark for evaluating the swipe execution capability of GUI agents. Furthermore, leveraging the synthesized data, we propose GUISwiper, a GUI agent with enhanced interaction execution capabilities. Experimental results demonstrate that GUISwiper achieves a swipe execution accuracy of 69.07%, representing a 214% improvement over existing VLM baselines.</p>"
    },
    {
      "id": "11bf9ef8a143",
      "title": "PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction",
      "content": "arXiv:2601.18336v1 Announce Type: new  Abstract: Multi-view 3D reconstruction methods remain highly sensitive to photometric inconsistencies arising from camera optical characteristics and variations in image signal processing (ISP). Existing mitigation strategies such as per-frame latent variables or affine color corrections lack physical grounding and generalize poorly to novel views. We propose the Physically-Plausible ISP (PPISP) correction module, which disentangles camera-intrinsic and capture-dependent effects through physically based and interpretable transformations. A dedicated PPISP controller, trained on the input views, predicts ISP parameters for novel viewpoints, analogous to auto exposure and auto white balance in real cameras. This design enables realistic and fair evaluation on novel views without access to ground-truth images. PPISP achieves SoTA performance on standard benchmarks, while providing intuitive control and supporting the integration of metadata when available. The source code is available at: https://github.com/nv-tlabs/ppisp",
      "url": "http://arxiv.org/abs/2601.18336",
      "author": "Isaac Deutsch, Nicolas Mo\\\"enne-Loccoz, Gavriel State, Zan Gojcic",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "PPISP proposes physically-plausible ISP correction for radiance field reconstruction, disentangling camera-intrinsic and capture-dependent effects through interpretable transformations with a controller for novel views.",
      "importance_score": 55,
      "reasoning": "Addresses practical photometric inconsistency problem in 3D reconstruction. Principled physics-based approach.",
      "themes": [
        "Neural Rendering",
        "Image Signal Processing",
        "3D Reconstruction"
      ],
      "continuation": null,
      "summary_html": "<p>PPISP proposes physically-plausible ISP correction for radiance field reconstruction, disentangling camera-intrinsic and capture-dependent effects through interpretable transformations with a controller for novel views.</p>",
      "content_html": "<p>arXiv:2601.18336v1 Announce Type: new  Abstract: Multi-view 3D reconstruction methods remain highly sensitive to photometric inconsistencies arising from camera optical characteristics and variations in image signal processing (ISP). Existing mitigation strategies such as per-frame latent variables or affine color corrections lack physical grounding and generalize poorly to novel views. We propose the Physically-Plausible ISP (PPISP) correction module, which disentangles camera-intrinsic and capture-dependent effects through physically based and interpretable transformations. A dedicated PPISP controller, trained on the input views, predicts ISP parameters for novel viewpoints, analogous to auto exposure and auto white balance in real cameras. This design enables realistic and fair evaluation on novel views without access to ground-truth images. PPISP achieves SoTA performance on standard benchmarks, while providing intuitive control and supporting the integration of metadata when available. The source code is available at: https://github.com/nv-tlabs/ppisp</p>"
    },
    {
      "id": "ab8f4699a4c7",
      "title": "Q-Bench-Portrait: Benchmarking Multimodal Large Language Models on Portrait Image Quality Perception",
      "content": "arXiv:2601.18346v1 Announce Type: new  Abstract: Recent advances in multimodal large language models (MLLMs) have demonstrated impressive performance on existing low-level vision benchmarks, which primarily focus on generic images. However, their capabilities to perceive and assess portrait images, a domain characterized by distinct structural and perceptual properties, remain largely underexplored. To this end, we introduce Q-Bench-Portrait, the first holistic benchmark specifically designed for portrait image quality perception, comprising 2,765 image-question-answer triplets and featuring (1) diverse portrait image sources, including natural, synthetic distortion, AI-generated, artistic, and computer graphics images; (2) comprehensive quality dimensions, covering technical distortions, AIGC-specific distortions, and aesthetics; and (3) a range of question formats, including single-choice, multiple-choice, true/false, and open-ended questions, at both global and local levels. Based on Q-Bench-Portrait, we evaluate 20 open-source and 5 closed-source MLLMs, revealing that although current models demonstrate some competence in portrait image perception, their performance remains limited and imprecise, with a clear gap relative to human judgments. We hope that the proposed benchmark will foster further research into enhancing the portrait image perception capabilities of both general-purpose and domain-specific MLLMs.",
      "url": "http://arxiv.org/abs/2601.18346",
      "author": "Sijing Wu, Yunhao Li, Zicheng Zhang, Qi Jia, Xinyue Li, Huiyu Duan, Xiongkuo Min, Guangtao Zhai",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Q-Bench-Portrait introduces first holistic benchmark for MLLM portrait image quality perception with 2,765 triplets covering diverse sources including AI-generated and artistic portraits.",
      "importance_score": 55,
      "reasoning": "Fills evaluation gap for portrait-specific quality assessment. Important as portrait generation grows.",
      "themes": [
        "Benchmarks",
        "Image Quality",
        "Vision-Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>Q-Bench-Portrait introduces first holistic benchmark for MLLM portrait image quality perception with 2,765 triplets covering diverse sources including AI-generated and artistic portraits.</p>",
      "content_html": "<p>arXiv:2601.18346v1 Announce Type: new  Abstract: Recent advances in multimodal large language models (MLLMs) have demonstrated impressive performance on existing low-level vision benchmarks, which primarily focus on generic images. However, their capabilities to perceive and assess portrait images, a domain characterized by distinct structural and perceptual properties, remain largely underexplored. To this end, we introduce Q-Bench-Portrait, the first holistic benchmark specifically designed for portrait image quality perception, comprising 2,765 image-question-answer triplets and featuring (1) diverse portrait image sources, including natural, synthetic distortion, AI-generated, artistic, and computer graphics images; (2) comprehensive quality dimensions, covering technical distortions, AIGC-specific distortions, and aesthetics; and (3) a range of question formats, including single-choice, multiple-choice, true/false, and open-ended questions, at both global and local levels. Based on Q-Bench-Portrait, we evaluate 20 open-source and 5 closed-source MLLMs, revealing that although current models demonstrate some competence in portrait image perception, their performance remains limited and imprecise, with a clear gap relative to human judgments. We hope that the proposed benchmark will foster further research into enhancing the portrait image perception capabilities of both general-purpose and domain-specific MLLMs.</p>"
    },
    {
      "id": "247b1e6cc532",
      "title": "Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation",
      "content": "arXiv:2601.18623v1 Announce Type: new  Abstract: Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model's role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps.",
      "url": "http://arxiv.org/abs/2601.18623",
      "author": "Zihao Wang, Yuzhou Chen, Shaogang Ren",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes adaptive domain shift dynamics embedded in diffusion generative process for cross-modal image translation, with spatially varying mixing field and target-consistent restoration at each step.",
      "importance_score": 55,
      "reasoning": "Addresses fundamental limitation of fixed-schedule domain transfer. Principled approach to cross-modal translation.",
      "themes": [
        "Diffusion Models",
        "Domain Adaptation",
        "Image Translation"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes adaptive domain shift dynamics embedded in diffusion generative process for cross-modal image translation, with spatially varying mixing field and target-consistent restoration at each step.</p>",
      "content_html": "<p>arXiv:2601.18623v1 Announce Type: new  Abstract: Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model's role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps.</p>"
    },
    {
      "id": "1e492904977c",
      "title": "Thermodynamically Optimal Regularization under Information-Geometric Constraints",
      "content": "arXiv:2601.17330v1 Announce Type: cross  Abstract: Modern machine learning relies on a collection of empirically successful but theoretically heterogeneous regularization techniques, such as weight decay, dropout, and exponential moving averages. At the same time, the rapidly increasing energetic cost of training large models raises the question of whether learning algorithms approach any fundamental efficiency bound. In this work, we propose a unifying theoretical framework connecting thermodynamic optimality, information geometry, and regularization.   Under three explicit assumptions -- (A1) that optimality requires an intrinsic, parametrization-invariant measure of information, (A2) that belief states are modeled by maximum-entropy distributions under known constraints, and (A3) that optimal processes are quasi-static -- we prove a conditional optimality theorem. Specifically, the Fisher--Rao metric is the unique admissible geometry on belief space, and thermodynamically optimal regularization corresponds to minimizing squared Fisher--Rao distance to a reference state.   We derive the induced geometries for Gaussian and circular belief models, yielding hyperbolic and von Mises manifolds, respectively, and show that classical regularization schemes are structurally incapable of guaranteeing thermodynamic optimality. We introduce a notion of thermodynamic efficiency of learning and propose experimentally testable predictions. This work provides a principled geometric and thermodynamic foundation for regularization in machine learning.",
      "url": "http://arxiv.org/abs/2601.17330",
      "author": "Laurent Caraffa",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes a theoretical framework connecting thermodynamic optimality with information geometry, showing that Fisher-Rao regularization is the unique thermodynamically optimal regularization strategy.",
      "importance_score": 55,
      "reasoning": "Interesting theoretical unification of regularization techniques through thermodynamics, but practical impact remains to be demonstrated.",
      "themes": [
        "Machine Learning Theory",
        "Information Geometry",
        "Regularization"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes a theoretical framework connecting thermodynamic optimality with information geometry, showing that Fisher-Rao regularization is the unique thermodynamically optimal regularization strategy.</p>",
      "content_html": "<p>arXiv:2601.17330v1 Announce Type: cross  Abstract: Modern machine learning relies on a collection of empirically successful but theoretically heterogeneous regularization techniques, such as weight decay, dropout, and exponential moving averages. At the same time, the rapidly increasing energetic cost of training large models raises the question of whether learning algorithms approach any fundamental efficiency bound. In this work, we propose a unifying theoretical framework connecting thermodynamic optimality, information geometry, and regularization.   Under three explicit assumptions -- (A1) that optimality requires an intrinsic, parametrization-invariant measure of information, (A2) that belief states are modeled by maximum-entropy distributions under known constraints, and (A3) that optimal processes are quasi-static -- we prove a conditional optimality theorem. Specifically, the Fisher--Rao metric is the unique admissible geometry on belief space, and thermodynamically optimal regularization corresponds to minimizing squared Fisher--Rao distance to a reference state.   We derive the induced geometries for Gaussian and circular belief models, yielding hyperbolic and von Mises manifolds, respectively, and show that classical regularization schemes are structurally incapable of guaranteeing thermodynamic optimality. We introduce a notion of thermodynamic efficiency of learning and propose experimentally testable predictions. This work provides a principled geometric and thermodynamic foundation for regularization in machine learning.</p>"
    },
    {
      "id": "2766f4b51bba",
      "title": "Counterfactual Explanations on Robust Perceptual Geodesics",
      "content": "arXiv:2601.18678v1 Announce Type: cross  Abstract: Latent-space optimization methods for counterfactual explanations - framed as minimal semantic perturbations that change model predictions - inherit the ambiguity of Wachter et al.'s objective: the choice of distance metric dictates whether perturbations are meaningful or adversarial. Existing approaches adopt flat or misaligned geometries, leading to off-manifold artifacts, semantic drift, or adversarial collapse. We introduce Perceptual Counterfactual Geodesics (PCG), a method that constructs counterfactuals by tracing geodesics under a perceptually Riemannian metric induced from robust vision features. This geometry aligns with human perception and penalizes brittle directions, enabling smooth, on-manifold, semantically valid transitions. Experiments on three vision datasets show that PCG outperforms baselines and reveals failure modes hidden under standard metrics.",
      "url": "http://arxiv.org/abs/2601.18678",
      "author": "Eslam Zaher, Maciej Trzaskowski, Quan Nguyen, Fred Roosta",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Presents Perceptual Counterfactual Geodesics (PCG), constructing counterfactual explanations by tracing geodesics under perceptually-aligned Riemannian metric from robust vision features.",
      "importance_score": 55,
      "reasoning": "Novel approach to counterfactual explanations with perceptual alignment, contributes to explainable AI.",
      "themes": [
        "Explainability",
        "Counterfactual Explanations",
        "Computer Vision"
      ],
      "continuation": null,
      "summary_html": "<p>Presents Perceptual Counterfactual Geodesics (PCG), constructing counterfactual explanations by tracing geodesics under perceptually-aligned Riemannian metric from robust vision features.</p>",
      "content_html": "<p>arXiv:2601.18678v1 Announce Type: cross  Abstract: Latent-space optimization methods for counterfactual explanations - framed as minimal semantic perturbations that change model predictions - inherit the ambiguity of Wachter et al.'s objective: the choice of distance metric dictates whether perturbations are meaningful or adversarial. Existing approaches adopt flat or misaligned geometries, leading to off-manifold artifacts, semantic drift, or adversarial collapse. We introduce Perceptual Counterfactual Geodesics (PCG), a method that constructs counterfactuals by tracing geodesics under a perceptually Riemannian metric induced from robust vision features. This geometry aligns with human perception and penalizes brittle directions, enabling smooth, on-manifold, semantically valid transitions. Experiments on three vision datasets show that PCG outperforms baselines and reveals failure modes hidden under standard metrics.</p>"
    },
    {
      "id": "27b461947d54",
      "title": "Scaling Rough Terrain Locomotion with Automatic Curriculum Reinforcement Learning",
      "content": "arXiv:2601.17428v1 Announce Type: new  Abstract: Curriculum learning has demonstrated substantial effectiveness in robot learning. However, it still faces limitations when scaling to complex, wide-ranging task spaces. Such task spaces often lack a well-defined difficulty structure, making the difficulty ordering required by previous methods challenging to define. We propose a Learning Progress-based Automatic Curriculum Reinforcement Learning (LP-ACRL) framework, which estimates the agent's learning progress online and adaptively adjusts the task-sampling distribution, thereby enabling automatic curriculum generation without prior knowledge of the difficulty distribution over the task space. Policies trained with LP-ACRL enable the ANYmal D quadruped to achieve and maintain stable, high-speed locomotion at 2.5 m/s linear velocity and 3.0 rad/s angular velocity across diverse terrains, including stairs, slopes, gravel, and low-friction flat surfaces--whereas previous methods have generally been limited to high speeds on flat terrain or low speeds on complex terrain. Experimental results demonstrate that LP-ACRL exhibits strong scalability and real-world applicability, providing a robust baseline for future research on curriculum generation in complex, wide-ranging robotic learning task spaces.",
      "url": "http://arxiv.org/abs/2601.17428",
      "author": "Ziming Li, Chenhao Li, Marco Hutter",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes LP-ACRL framework for automatic curriculum generation in reinforcement learning, achieving stable high-speed quadruped locomotion on challenging terrain.",
      "importance_score": 55,
      "reasoning": "Solid contribution to curriculum learning for robot locomotion, practical results on ANYmal.",
      "themes": [
        "Curriculum Learning",
        "Quadruped Locomotion",
        "Reinforcement Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes LP-ACRL framework for automatic curriculum generation in reinforcement learning, achieving stable high-speed quadruped locomotion on challenging terrain.</p>",
      "content_html": "<p>arXiv:2601.17428v1 Announce Type: new  Abstract: Curriculum learning has demonstrated substantial effectiveness in robot learning. However, it still faces limitations when scaling to complex, wide-ranging task spaces. Such task spaces often lack a well-defined difficulty structure, making the difficulty ordering required by previous methods challenging to define. We propose a Learning Progress-based Automatic Curriculum Reinforcement Learning (LP-ACRL) framework, which estimates the agent's learning progress online and adaptively adjusts the task-sampling distribution, thereby enabling automatic curriculum generation without prior knowledge of the difficulty distribution over the task space. Policies trained with LP-ACRL enable the ANYmal D quadruped to achieve and maintain stable, high-speed locomotion at 2.5 m/s linear velocity and 3.0 rad/s angular velocity across diverse terrains, including stairs, slopes, gravel, and low-friction flat surfaces--whereas previous methods have generally been limited to high speeds on flat terrain or low speeds on complex terrain. Experimental results demonstrate that LP-ACRL exhibits strong scalability and real-world applicability, providing a robust baseline for future research on curriculum generation in complex, wide-ranging robotic learning task spaces.</p>"
    },
    {
      "id": "f8b589463655",
      "title": "ConceptACT: Episode-Level Concepts for Sample-Efficient Robotic Imitation Learning",
      "content": "arXiv:2601.17135v1 Announce Type: cross  Abstract: Imitation learning enables robots to acquire complex manipulation skills from human demonstrations, but current methods rely solely on low-level sensorimotor data while ignoring the rich semantic knowledge humans naturally possess about tasks. We present ConceptACT, an extension of Action Chunking with Transformers that leverages episode-level semantic concept annotations during training to improve learning efficiency. Unlike language-conditioned approaches that require semantic input at deployment, ConceptACT uses human-provided concepts (object properties, spatial relationships, task constraints) exclusively during demonstration collection, adding minimal annotation burden. We integrate concepts using a modified transformer architecture in which the final encoder layer implements concept-aware cross-attention, supervised to align with human annotations. Through experiments on two robotic manipulation tasks with logical constraints, we demonstrate that ConceptACT converges faster and achieves superior sample efficiency compared to standard ACT. Crucially, we show that architectural integration through attention mechanisms significantly outperforms naive auxiliary prediction losses or language-conditioned models. These results demonstrate that properly integrated semantic supervision provides powerful inductive biases for more efficient robot learning.",
      "url": "http://arxiv.org/abs/2601.17135",
      "author": "Jakob Karalus, Friedhelm Schwenker",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces ConceptACT extending Action Chunking with Transformers to leverage episode-level semantic concepts during training for improved sample efficiency without requiring concepts at deployment.",
      "importance_score": 55,
      "reasoning": "Practical approach to incorporating semantic knowledge in imitation learning with minimal annotation overhead.",
      "themes": [
        "Imitation Learning",
        "Sample Efficiency",
        "Semantic Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces ConceptACT extending Action Chunking with Transformers to leverage episode-level semantic concepts during training for improved sample efficiency without requiring concepts at deployment.</p>",
      "content_html": "<p>arXiv:2601.17135v1 Announce Type: cross  Abstract: Imitation learning enables robots to acquire complex manipulation skills from human demonstrations, but current methods rely solely on low-level sensorimotor data while ignoring the rich semantic knowledge humans naturally possess about tasks. We present ConceptACT, an extension of Action Chunking with Transformers that leverages episode-level semantic concept annotations during training to improve learning efficiency. Unlike language-conditioned approaches that require semantic input at deployment, ConceptACT uses human-provided concepts (object properties, spatial relationships, task constraints) exclusively during demonstration collection, adding minimal annotation burden. We integrate concepts using a modified transformer architecture in which the final encoder layer implements concept-aware cross-attention, supervised to align with human annotations. Through experiments on two robotic manipulation tasks with logical constraints, we demonstrate that ConceptACT converges faster and achieves superior sample efficiency compared to standard ACT. Crucially, we show that architectural integration through attention mechanisms significantly outperforms naive auxiliary prediction losses or language-conditioned models. These results demonstrate that properly integrated semantic supervision provides powerful inductive biases for more efficient robot learning.</p>"
    },
    {
      "id": "653302ee3d3f",
      "title": "Listing the virtues from Claudes Constitution",
      "content": "Anthropic has released the Constitution document (formerly known as the Soul document) that guides the characteristics of Claude.As others have noted,[1]&nbsp;this document is strikingly virtue-ethics-like, in contrast with the sorts of utilitarian (e.g. maximize human welfare) or deontological (e.g. Asimov's Three Laws of Robotics) guidance that are sometimes expected in this context.Ive long been engaged in a project of cataloging and examining the virtues here on LessWrong, and so I thought Id look over this constitution with an eye to listing which virtues Anthropic is trying to encourage in Claude (and which human virtues might have missed the cut).The virtues I was able to discover in the Claude constitution are as follows. First, the main ones that are especially emphasized:caution / harmlessnessbenevolence / ethicshelpfulness / beneficenceobedience / deference / corrigibilityThen, several social virtues particular to Claude's interactions with people:honesty[2]forthrightness / candortransparency / opennessreliability / trustworthinesscare / concernrespect (of people, e.g. their autonomy &amp; maturity)friendlinessunderstandingnurturancecharity (in the sense of interpreting what people say)propriety (e.g. no playacting as Hitler, pirating intellectual property, telling racist jokes)being nonjudgmentalempathy[3]rhetoric[4]tact / diplomacycompassiongracesocial responsibilityfairnesscultural awareness / ability to code-switchcollegiality / cooperationplayfulness (when context-appropriate)graciousness (e.g. acknowledging errors, faults, etc.)Then, several intellectual virtues:phronesis / good judgementwisdomjudiciousnessthoughtfulness / epistemic rigorawarenessreason / rationalityinsightcuriosityimagination (e.g. perspective-taking)parrhesia (occasionally telling unwelcome truths)[5]emotional intelligence (including, explicitly, its own emotions)Finally, some more general character virtues:self-awareness / introspectionconsistency / integrity / self-confide...",
      "url": "https://www.lesswrong.com/posts/Deko7pzwQRjvCSLs9/listing-the-virtues-from-claude-s-constitution",
      "author": "David Gross",
      "published": "2026-01-26T17:16:37.748000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Catalogs the virtues embedded in Anthropic's newly released Claude constitution, noting its surprisingly virtue-ethics approach rather than utilitarian or deontological frameworks. Identifies primary virtues (harmlessness, helpfulness, honesty) and secondary social virtues.",
      "importance_score": 55,
      "reasoning": "Useful systematic analysis of Anthropic's public approach to AI values. Provides a structured reference for understanding Claude's design philosophy but is primarily analytical rather than novel research.",
      "themes": [
        "AI Alignment",
        "Anthropic",
        "Virtue Ethics",
        "Constitutional AI"
      ],
      "continuation": null,
      "summary_html": "<p>Catalogs the virtues embedded in Anthropic's newly released Claude constitution, noting its surprisingly virtue-ethics approach rather than utilitarian or deontological frameworks. Identifies primary virtues (harmlessness, helpfulness, honesty) and secondary social virtues.</p>",
      "content_html": "<p>Anthropic has released the Constitution document (formerly known as the Soul document) that guides the characteristics of Claude.As others have noted,[1]&nbsp;this document is strikingly virtue-ethics-like, in contrast with the sorts of utilitarian (e.g. maximize human welfare) or deontological (e.g. Asimov's Three Laws of Robotics) guidance that are sometimes expected in this context.Ive long been engaged in a project of cataloging and examining the virtues here on LessWrong, and so I thought Id look over this constitution with an eye to listing which virtues Anthropic is trying to encourage in Claude (and which human virtues might have missed the cut).The virtues I was able to discover in the Claude constitution are as follows. First, the main ones that are especially emphasized:caution / harmlessnessbenevolence / ethicshelpfulness / beneficenceobedience / deference / corrigibilityThen, several social virtues particular to Claude's interactions with people:honesty[2]forthrightness / candortransparency / opennessreliability / trustworthinesscare / concernrespect (of people, e.g. their autonomy &amp; maturity)friendlinessunderstandingnurturancecharity (in the sense of interpreting what people say)propriety (e.g. no playacting as Hitler, pirating intellectual property, telling racist jokes)being nonjudgmentalempathy[3]rhetoric[4]tact / diplomacycompassiongracesocial responsibilityfairnesscultural awareness / ability to code-switchcollegiality / cooperationplayfulness (when context-appropriate)graciousness (e.g. acknowledging errors, faults, etc.)Then, several intellectual virtues:phronesis / good judgementwisdomjudiciousnessthoughtfulness / epistemic rigorawarenessreason / rationalityinsightcuriosityimagination (e.g. perspective-taking)parrhesia (occasionally telling unwelcome truths)[5]emotional intelligence (including, explicitly, its own emotions)Finally, some more general character virtues:self-awareness / introspectionconsistency / integrity / self-confide...</p>"
    },
    {
      "id": "cada31aba58c",
      "title": "ReFuGe: Feature Generation for Prediction Tasks on Relational Databases with LLM Agents",
      "content": "arXiv:2601.17735v1 Announce Type: new  Abstract: Relational databases (RDBs) play a crucial role in many real-world web applications, supporting data management across multiple interconnected tables. Beyond typical retrieval-oriented tasks, prediction tasks on RDBs have recently gained attention. In this work, we address this problem by generating informative relational features that enhance predictive performance. However, generating such features is challenging: it requires reasoning over complex schemas and exploring a combinatorially large feature space, all without explicit supervision. To address these challenges, we propose ReFuGe, an agentic framework that leverages specialized large language model agents: (1) a schema selection agent identifies the tables and columns relevant to the task, (2) a feature generation agent produces diverse candidate features from the selected schema, and (3) a feature filtering agent evaluates and retains promising features through reasoning-based and validation-based filtering. It operates within an iterative feedback loop until performance converges. Experiments on RDB benchmarks demonstrate that ReFuGe substantially improves performance on various RDB prediction tasks. Our code and datasets are available at https://github.com/K-Kyungho/REFUGE.",
      "url": "http://arxiv.org/abs/2601.17735",
      "author": "Kyungho Kim, Geon Lee, Juyeon Kim, Dongwon Choi, Shinhwan Kang, Kijung Shin",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes ReFuGe, an agentic framework using specialized LLM agents for schema selection, feature synthesis, and verification to generate informative features for prediction tasks on relational databases.",
      "importance_score": 54,
      "reasoning": "Practical application of LLM agents to database feature engineering; incremental contribution to automated ML.",
      "themes": [
        "AutoML",
        "Databases",
        "Agentic AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes ReFuGe, an agentic framework using specialized LLM agents for schema selection, feature synthesis, and verification to generate informative features for prediction tasks on relational databases.</p>",
      "content_html": "<p>arXiv:2601.17735v1 Announce Type: new  Abstract: Relational databases (RDBs) play a crucial role in many real-world web applications, supporting data management across multiple interconnected tables. Beyond typical retrieval-oriented tasks, prediction tasks on RDBs have recently gained attention. In this work, we address this problem by generating informative relational features that enhance predictive performance. However, generating such features is challenging: it requires reasoning over complex schemas and exploring a combinatorially large feature space, all without explicit supervision. To address these challenges, we propose ReFuGe, an agentic framework that leverages specialized large language model agents: (1) a schema selection agent identifies the tables and columns relevant to the task, (2) a feature generation agent produces diverse candidate features from the selected schema, and (3) a feature filtering agent evaluates and retains promising features through reasoning-based and validation-based filtering. It operates within an iterative feedback loop until performance converges. Experiments on RDB benchmarks demonstrate that ReFuGe substantially improves performance on various RDB prediction tasks. Our code and datasets are available at https://github.com/K-Kyungho/REFUGE.</p>"
    },
    {
      "id": "26313dd3c033",
      "title": "Clustering-driven Memory Compression for On-device Large Language Models",
      "content": "arXiv:2601.17443v1 Announce Type: cross  Abstract: Large language models (LLMs) often rely on user-specific memories distilled from past interactions to enable personalized generation. A common practice is to concatenate these memories with the input prompt, but this approach quickly exhausts the limited context available in on-device LLMs. Compressing memories by averaging can mitigate context growth, yet it frequently harms performance due to semantic conflicts across heterogeneous memories. In this work, we introduce a clustering-based memory compression strategy that balances context efficiency and personalization quality. Our method groups memories by similarity and merges them within clusters prior to concatenation, thereby preserving coherence while reducing redundancy. Experiments demonstrate that our approach substantially lowers the number of memory tokens while outperforming baseline strategies such as naive averaging or direct concatenation. Furthermore, for a fixed context budget, clustering-driven merging yields more compact memory representations and consistently enhances generation quality.",
      "url": "http://arxiv.org/abs/2601.17443",
      "author": "Ondrej Bohdal, Pramit Saha, Umberto Michieli, Mete Ozay, Taha Ceritli",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Clustering-based memory compression for on-device LLMs that groups memories by similarity before merging, balancing context efficiency and personalization quality.",
      "importance_score": 54,
      "reasoning": "Practical on-device optimization. Addresses semantic conflicts in memory compression.",
      "themes": [
        "On-device AI",
        "Memory Compression",
        "Personalization"
      ],
      "continuation": null,
      "summary_html": "<p>Clustering-based memory compression for on-device LLMs that groups memories by similarity before merging, balancing context efficiency and personalization quality.</p>",
      "content_html": "<p>arXiv:2601.17443v1 Announce Type: cross  Abstract: Large language models (LLMs) often rely on user-specific memories distilled from past interactions to enable personalized generation. A common practice is to concatenate these memories with the input prompt, but this approach quickly exhausts the limited context available in on-device LLMs. Compressing memories by averaging can mitigate context growth, yet it frequently harms performance due to semantic conflicts across heterogeneous memories. In this work, we introduce a clustering-based memory compression strategy that balances context efficiency and personalization quality. Our method groups memories by similarity and merges them within clusters prior to concatenation, thereby preserving coherence while reducing redundancy. Experiments demonstrate that our approach substantially lowers the number of memory tokens while outperforming baseline strategies such as naive averaging or direct concatenation. Furthermore, for a fixed context budget, clustering-driven merging yields more compact memory representations and consistently enhances generation quality.</p>"
    },
    {
      "id": "f23bfd321902",
      "title": "Beyond a Single Perspective: Text Anomaly Detection with Multi-View Language Representations",
      "content": "arXiv:2601.17786v1 Announce Type: new  Abstract: Text anomaly detection (TAD) plays a critical role in various language-driven real-world applications, including harmful content moderation, phishing detection, and spam review filtering. While two-step \"embedding-detector\" TAD methods have shown state-of-the-art performance, their effectiveness is often limited by the use of a single embedding model and the lack of adaptability across diverse datasets and anomaly types. To address these limitations, we propose to exploit the embeddings from multiple pretrained language models and integrate them into $MCA^2$, a multi-view TAD framework. $MCA^2$ adopts a multi-view reconstruction model to effectively extract normal textual patterns from multiple embedding perspectives. To exploit inter-view complementarity, a contrastive collaboration module is designed to leverage and strengthen the interactions across different views. Moreover, an adaptive allocation module is developed to automatically assign the contribution weight of each view, thereby improving the adaptability to diverse datasets. Extensive experiments on 10 benchmark datasets verify the effectiveness of $MCA^2$ against strong baselines. The source code of $MCA^2$ is available at https://github.com/yankehan/MCA2.",
      "url": "http://arxiv.org/abs/2601.17786",
      "author": "Yixin Liu, Kehan Yan, Shiyuan Li, Qingfeng Chen, Shirui Pan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes MCA framework for text anomaly detection using embeddings from multiple pretrained language models. Employs multi-view reconstruction with inter-view correlation exploitation.",
      "importance_score": 54,
      "reasoning": "Practical improvement to text anomaly detection through ensemble approach. Standard methodology with demonstrated effectiveness.",
      "themes": [
        "Anomaly Detection",
        "Text Classification",
        "Ensemble Methods"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes MCA framework for text anomaly detection using embeddings from multiple pretrained language models. Employs multi-view reconstruction with inter-view correlation exploitation.</p>",
      "content_html": "<p>arXiv:2601.17786v1 Announce Type: new  Abstract: Text anomaly detection (TAD) plays a critical role in various language-driven real-world applications, including harmful content moderation, phishing detection, and spam review filtering. While two-step \"embedding-detector\" TAD methods have shown state-of-the-art performance, their effectiveness is often limited by the use of a single embedding model and the lack of adaptability across diverse datasets and anomaly types. To address these limitations, we propose to exploit the embeddings from multiple pretrained language models and integrate them into $MCA^2$, a multi-view TAD framework. $MCA^2$ adopts a multi-view reconstruction model to effectively extract normal textual patterns from multiple embedding perspectives. To exploit inter-view complementarity, a contrastive collaboration module is designed to leverage and strengthen the interactions across different views. Moreover, an adaptive allocation module is developed to automatically assign the contribution weight of each view, thereby improving the adaptability to diverse datasets. Extensive experiments on 10 benchmark datasets verify the effectiveness of $MCA^2$ against strong baselines. The source code of $MCA^2$ is available at https://github.com/yankehan/MCA2.</p>"
    },
    {
      "id": "e1c9f280907d",
      "title": "LoD-Structured 3D Gaussian Splatting for Streaming Video Reconstruction",
      "content": "arXiv:2601.18475v1 Announce Type: cross  Abstract: Free-Viewpoint Video (FVV) reconstruction enables photorealistic and interactive 3D scene visualization; however, real-time streaming is often bottlenecked by sparse-view inputs, prohibitive training costs, and bandwidth constraints. While recent 3D Gaussian Splatting (3DGS) has advanced FVV due to its superior rendering speed, Streaming Free-Viewpoint Video (SFVV) introduces additional demands for rapid optimization, high-fidelity reconstruction under sparse constraints, and minimal storage footprints. To bridge this gap, we propose StreamLoD-GS, an LoD-based Gaussian Splatting framework designed specifically for SFVV. Our approach integrates three core innovations: 1) an Anchor- and Octree-based LoD-structured 3DGS with a hierarchical Gaussian dropout technique to ensure efficient and stable optimization while maintaining high-quality rendering; 2) a GMM-based motion partitioning mechanism that separates dynamic and static content, refining dynamic regions while preserving background stability; and 3) a quantized residual refinement framework that significantly reduces storage requirements without compromising visual fidelity. Extensive experiments demonstrate that StreamLoD-GS achieves competitive or state-of-the-art performance in terms of quality, efficiency, and storage.",
      "url": "http://arxiv.org/abs/2601.18475",
      "author": "Xinhui Liu, Can Wang, Lei Liu, Zhenghao Chen, Wei Jiang, Wei Wang, Dong Xu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.GR"
      ],
      "summary": "Proposes StreamLoD-GS, an LoD-based Gaussian Splatting framework for streaming free-viewpoint video with anchor-based LoD structure and hierarchical Gaussian representation.",
      "importance_score": 54,
      "reasoning": "Technical contribution to real-time 3DGS streaming with practical applications, extends active research area.",
      "themes": [
        "3D Gaussian Splatting",
        "Video Streaming",
        "3D Reconstruction"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes StreamLoD-GS, an LoD-based Gaussian Splatting framework for streaming free-viewpoint video with anchor-based LoD structure and hierarchical Gaussian representation.</p>",
      "content_html": "<p>arXiv:2601.18475v1 Announce Type: cross  Abstract: Free-Viewpoint Video (FVV) reconstruction enables photorealistic and interactive 3D scene visualization; however, real-time streaming is often bottlenecked by sparse-view inputs, prohibitive training costs, and bandwidth constraints. While recent 3D Gaussian Splatting (3DGS) has advanced FVV due to its superior rendering speed, Streaming Free-Viewpoint Video (SFVV) introduces additional demands for rapid optimization, high-fidelity reconstruction under sparse constraints, and minimal storage footprints. To bridge this gap, we propose StreamLoD-GS, an LoD-based Gaussian Splatting framework designed specifically for SFVV. Our approach integrates three core innovations: 1) an Anchor- and Octree-based LoD-structured 3DGS with a hierarchical Gaussian dropout technique to ensure efficient and stable optimization while maintaining high-quality rendering; 2) a GMM-based motion partitioning mechanism that separates dynamic and static content, refining dynamic regions while preserving background stability; and 3) a quantized residual refinement framework that significantly reduces storage requirements without compromising visual fidelity. Extensive experiments demonstrate that StreamLoD-GS achieves competitive or state-of-the-art performance in terms of quality, efficiency, and storage.</p>"
    },
    {
      "id": "994de845cf38",
      "title": "Advancing Improvisation in Human-Robot Construction Collaboration: Taxonomy and Research Roadmap",
      "content": "arXiv:2601.17219v1 Announce Type: new  Abstract: The construction industry faces productivity stagnation, skilled labor shortages, and safety concerns. While robotic automation offers solutions, construction robots struggle to adapt to unstructured, dynamic sites. Central to this is improvisation, adapting to unexpected situations through creative problem-solving, which remains predominantly human. In construction's unpredictable environments, collaborative human-robot improvisation is essential for workflow continuity. This research develops a six-level taxonomy classifying human-robot collaboration (HRC) based on improvisation capabilities. Through systematic review of 214 articles (2010-2025), we categorize construction robotics across: Manual Work (Level 0), Human-Controlled Execution (Level 1), Adaptive Manipulation (Level 2), Imitation Learning (Level 3), Human-in-Loop BIM Workflow (Level 4), Cloud-Based Knowledge Integration (Level 5), and True Collaborative Improvisation (Level 6). Analysis reveals current research concentrates at lower levels, with critical gaps in experiential learning and limited progression toward collaborative improvisation. A five-dimensional radar framework illustrates progressive evolution of Planning, Cognitive Role, Physical Execution, Learning Capability, and Improvisation, demonstrating how complementary human-robot capabilities create team performance exceeding individual contributions. The research identifies three fundamental barriers: technical limitations in grounding and dialogic reasoning, conceptual gaps between human improvisation and robotics research, and methodological challenges. We recommend future research emphasizing improved human-robot communication via Augmented/Virtual Reality interfaces, large language model integration, and cloud-based knowledge systems to advance toward true collaborative improvisation.",
      "url": "http://arxiv.org/abs/2601.17219",
      "author": "David Wireko Atibila, Vineet R. Kamat, Carol C. Menassa",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Develops six-level taxonomy classifying human-robot collaboration based on improvisation capabilities, with systematic review of 214 construction robotics articles from 2010-2025.",
      "importance_score": 54,
      "reasoning": "Useful framework and comprehensive survey for construction robotics, identifies key capability gaps.",
      "themes": [
        "Human-Robot Collaboration",
        "Construction Robotics",
        "Taxonomy"
      ],
      "continuation": null,
      "summary_html": "<p>Develops six-level taxonomy classifying human-robot collaboration based on improvisation capabilities, with systematic review of 214 construction robotics articles from 2010-2025.</p>",
      "content_html": "<p>arXiv:2601.17219v1 Announce Type: new  Abstract: The construction industry faces productivity stagnation, skilled labor shortages, and safety concerns. While robotic automation offers solutions, construction robots struggle to adapt to unstructured, dynamic sites. Central to this is improvisation, adapting to unexpected situations through creative problem-solving, which remains predominantly human. In construction's unpredictable environments, collaborative human-robot improvisation is essential for workflow continuity. This research develops a six-level taxonomy classifying human-robot collaboration (HRC) based on improvisation capabilities. Through systematic review of 214 articles (2010-2025), we categorize construction robotics across: Manual Work (Level 0), Human-Controlled Execution (Level 1), Adaptive Manipulation (Level 2), Imitation Learning (Level 3), Human-in-Loop BIM Workflow (Level 4), Cloud-Based Knowledge Integration (Level 5), and True Collaborative Improvisation (Level 6). Analysis reveals current research concentrates at lower levels, with critical gaps in experiential learning and limited progression toward collaborative improvisation. A five-dimensional radar framework illustrates progressive evolution of Planning, Cognitive Role, Physical Execution, Learning Capability, and Improvisation, demonstrating how complementary human-robot capabilities create team performance exceeding individual contributions. The research identifies three fundamental barriers: technical limitations in grounding and dialogic reasoning, conceptual gaps between human improvisation and robotics research, and methodological challenges. We recommend future research emphasizing improved human-robot communication via Augmented/Virtual Reality interfaces, large language model integration, and cloud-based knowledge systems to advance toward true collaborative improvisation.</p>"
    },
    {
      "id": "6da85de02081",
      "title": "Fast and Safe Trajectory Optimization for Mobile Manipulators With Neural Configuration Space Distance Field",
      "content": "arXiv:2601.18548v1 Announce Type: new  Abstract: Mobile manipulators promise agile, long-horizon behavior by coordinating base and arm motion, yet whole-body trajectory optimization in cluttered, confined spaces remains difficult due to high-dimensional nonconvexity and the need for fast, accurate collision reasoning. Configuration Space Distance Fields (CDF) enable fixed-base manipulators to model collisions directly in configuration space via smooth, implicit distances. This representation holds strong potential to bypass the nonlinear configuration-to-workspace mapping while preserving accurate whole-body geometry and providing optimization-friendly collision costs. Yet, extending this capability to mobile manipulators is hindered by unbounded workspaces and tighter base-arm coupling. We lift this promise to mobile manipulation with Generalized Configuration Space Distance Fields (GCDF), extending CDF to robots with both translational and rotational joints in unbounded workspaces with tighter base-arm coupling. We prove that GCDF preserves Euclidean-like local distance structure and accurately encodes whole-body geometry in configuration space, and develop a data generation and training pipeline that yields continuous neural GCDFs with accurate values and gradients, supporting efficient GPU-batched queries. Building on this representation, we develop a high-performance sequential convex optimization framework centered on GCDF-based collision reasoning. The solver scales to large numbers of implicit constraints through (i) online specification of neural constraints, (ii) sparsity-aware active-set detection with parallel batched evaluation across thousands of constraints, and (iii) incremental constraint management for rapid replanning under scene changes.",
      "url": "http://arxiv.org/abs/2601.18548",
      "author": "Yulin Li, Zhiyuan Song, Yiming Li, Zhicheng Song, Kai Chen, Chunxin Zheng, Zhihai Bi, Jiahang Cao, Sylvain Calinon, Fan Shi, Jun Ma",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes neural configuration space distance field for fast trajectory optimization of mobile manipulators, extending CDF approach to handle unbounded workspaces.",
      "importance_score": 54,
      "reasoning": "Solid motion planning contribution extending CDF to mobile manipulators, practical optimization approach.",
      "themes": [
        "Motion Planning",
        "Mobile Manipulation",
        "Neural Networks"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes neural configuration space distance field for fast trajectory optimization of mobile manipulators, extending CDF approach to handle unbounded workspaces.</p>",
      "content_html": "<p>arXiv:2601.18548v1 Announce Type: new  Abstract: Mobile manipulators promise agile, long-horizon behavior by coordinating base and arm motion, yet whole-body trajectory optimization in cluttered, confined spaces remains difficult due to high-dimensional nonconvexity and the need for fast, accurate collision reasoning. Configuration Space Distance Fields (CDF) enable fixed-base manipulators to model collisions directly in configuration space via smooth, implicit distances. This representation holds strong potential to bypass the nonlinear configuration-to-workspace mapping while preserving accurate whole-body geometry and providing optimization-friendly collision costs. Yet, extending this capability to mobile manipulators is hindered by unbounded workspaces and tighter base-arm coupling. We lift this promise to mobile manipulation with Generalized Configuration Space Distance Fields (GCDF), extending CDF to robots with both translational and rotational joints in unbounded workspaces with tighter base-arm coupling. We prove that GCDF preserves Euclidean-like local distance structure and accurately encodes whole-body geometry in configuration space, and develop a data generation and training pipeline that yields continuous neural GCDFs with accurate values and gradients, supporting efficient GPU-batched queries. Building on this representation, we develop a high-performance sequential convex optimization framework centered on GCDF-based collision reasoning. The solver scales to large numbers of implicit constraints through (i) online specification of neural constraints, (ii) sparsity-aware active-set detection with parallel batched evaluation across thousands of constraints, and (iii) incremental constraint management for rapid replanning under scene changes.</p>"
    },
    {
      "id": "0dbe30a6bda4",
      "title": "Resonant Sparse Geometry Networks",
      "content": "arXiv:2601.18064v1 Announce Type: cross  Abstract: We introduce Resonant Sparse Geometry Networks (RSGN), a brain-inspired architecture with self-organizing sparse   hierarchical input-dependent connectivity. Unlike Transformer architectures that employ dense attention mechanisms with   O(n^2) computational complexity, RSGN embeds computational nodes in learned hyperbolic space where connection strength   decays with geodesic distance, achieving dynamic sparsity that adapts to each input. The architecture operates on two   distinct timescales: fast differentiable activation propagation optimized through gradient descent, and slow   Hebbian-inspired structural learning for connectivity adaptation through local correlation rules. We provide rigorous   mathematical analysis demonstrating that RSGN achieves O(n*k) computational complexity, where k << n represents the average   active neighborhood size. Experimental evaluation on hierarchical classification and long-range dependency tasks   demonstrates that RSGN achieves 96.5% accuracy on long-range dependency tasks while using approximately 15x fewer   parameters than standard Transformers. On challenging hierarchical classification with 20 classes, RSGN achieves 23.8%   accuracy (compared to 5% random baseline) with only 41,672 parameters, nearly 10x fewer than the Transformer baselines   which require 403,348 parameters to achieve 30.1% accuracy. Our ablation studies confirm the contribution of each architectural   component, with Hebbian learning providing consistent improvements. These results suggest that brain-inspired principles   of sparse, geometrically-organized computation offer a promising direction toward more efficient and biologically plausible   neural architectures.",
      "url": "http://arxiv.org/abs/2601.18064",
      "author": "Hasi Hays",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Resonant Sparse Geometry Networks use learned hyperbolic space for input-dependent sparse connectivity, combining fast gradient descent with slow Hebbian structural learning.",
      "importance_score": 53,
      "reasoning": "Novel brain-inspired architecture. Hyperbolic embedding for connectivity is interesting. Claims O(n) improvement over transformers.",
      "themes": [
        "Neural Architecture",
        "Brain-inspired AI",
        "Sparse Networks"
      ],
      "continuation": null,
      "summary_html": "<p>Resonant Sparse Geometry Networks use learned hyperbolic space for input-dependent sparse connectivity, combining fast gradient descent with slow Hebbian structural learning.</p>",
      "content_html": "<p>arXiv:2601.18064v1 Announce Type: cross  Abstract: We introduce Resonant Sparse Geometry Networks (RSGN), a brain-inspired architecture with self-organizing sparse   hierarchical input-dependent connectivity. Unlike Transformer architectures that employ dense attention mechanisms with   O(n^2) computational complexity, RSGN embeds computational nodes in learned hyperbolic space where connection strength   decays with geodesic distance, achieving dynamic sparsity that adapts to each input. The architecture operates on two   distinct timescales: fast differentiable activation propagation optimized through gradient descent, and slow   Hebbian-inspired structural learning for connectivity adaptation through local correlation rules. We provide rigorous   mathematical analysis demonstrating that RSGN achieves O(n*k) computational complexity, where k &lt;&lt; n represents the average   active neighborhood size. Experimental evaluation on hierarchical classification and long-range dependency tasks   demonstrates that RSGN achieves 96.5% accuracy on long-range dependency tasks while using approximately 15x fewer   parameters than standard Transformers. On challenging hierarchical classification with 20 classes, RSGN achieves 23.8%   accuracy (compared to 5% random baseline) with only 41,672 parameters, nearly 10x fewer than the Transformer baselines   which require 403,348 parameters to achieve 30.1% accuracy. Our ablation studies confirm the contribution of each architectural   component, with Hebbian learning providing consistent improvements. These results suggest that brain-inspired principles   of sparse, geometrically-organized computation offer a promising direction toward more efficient and biologically plausible   neural architectures.</p>"
    },
    {
      "id": "4dc580b5854c",
      "title": "Dissipative Learning: A Framework for Viable Adaptive Systems",
      "content": "arXiv:2601.17933v1 Announce Type: cross  Abstract: We propose a perspective in which learning is an intrinsically dissipative process. Forgetting and regularization are not heuristic add-ons but structural requirements for adaptive systems. Drawing on information theory, thermodynamics, and information geometry, we introduce the BEDS (Bayesian Emergent Dissipative Structures) framework, modeling learning as the evolution of compressed belief states under dissipation constraints.   A central contribution is the Conditional Optimality Theorem, showing that Fisher-Rao regularization measuring change via information divergence rather than Euclidean distance is the unique thermodynamically optimal regularization strategy, achieving minimal dissipation. Euclidean regularization is shown to be structurally suboptimal. The framework unifies existing methods (Ridge, SIGReg, EMA, SAC) as special cases of a single governing equation.   Within this view, overfitting corresponds to over-crystallization, while catastrophic forgetting reflects insufficient dissipation control. The framework distinguishes BEDS-crystallizable problems, where beliefs converge to stable equilibria, from BEDS-maintainable problems, which require continual adaptation. It extends naturally to continual and multi-agent systems, where viability, stability under adaptation and finite resources replaces asymptotic optimality as the primary criterion. Overall, this work reframes learning as maintaining viable belief states under dissipation constraints, providing a principled lens on forgetting, regularization, and stability.",
      "url": "http://arxiv.org/abs/2601.17933",
      "author": "Laurent Caraffa",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes BEDS framework modeling learning as evolution of compressed belief states under dissipation constraints, proving Fisher-Rao regularization achieves minimal dissipation compared to Euclidean.",
      "importance_score": 53,
      "reasoning": "Theoretical contribution connecting learning theory to thermodynamics, companion to item 7 with similar ideas.",
      "themes": [
        "Machine Learning Theory",
        "Information Theory",
        "Regularization"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes BEDS framework modeling learning as evolution of compressed belief states under dissipation constraints, proving Fisher-Rao regularization achieves minimal dissipation compared to Euclidean.</p>",
      "content_html": "<p>arXiv:2601.17933v1 Announce Type: cross  Abstract: We propose a perspective in which learning is an intrinsically dissipative process. Forgetting and regularization are not heuristic add-ons but structural requirements for adaptive systems. Drawing on information theory, thermodynamics, and information geometry, we introduce the BEDS (Bayesian Emergent Dissipative Structures) framework, modeling learning as the evolution of compressed belief states under dissipation constraints.   A central contribution is the Conditional Optimality Theorem, showing that Fisher-Rao regularization measuring change via information divergence rather than Euclidean distance is the unique thermodynamically optimal regularization strategy, achieving minimal dissipation. Euclidean regularization is shown to be structurally suboptimal. The framework unifies existing methods (Ridge, SIGReg, EMA, SAC) as special cases of a single governing equation.   Within this view, overfitting corresponds to over-crystallization, while catastrophic forgetting reflects insufficient dissipation control. The framework distinguishes BEDS-crystallizable problems, where beliefs converge to stable equilibria, from BEDS-maintainable problems, which require continual adaptation. It extends naturally to continual and multi-agent systems, where viability, stability under adaptation and finite resources replaces asymptotic optimality as the primary criterion. Overall, this work reframes learning as maintaining viable belief states under dissipation constraints, providing a principled lens on forgetting, regularization, and stability.</p>"
    },
    {
      "id": "23980b1f6fd4",
      "title": "TEFormer: Structured Bidirectional Temporal Enhancement Modeling in Spiking Transformers",
      "content": "arXiv:2601.18274v1 Announce Type: new  Abstract: In recent years, Spiking Neural Networks (SNNs) have achieved remarkable progress, with Spiking Transformers emerging as a promising architecture for energy-efficient sequence modeling. However, existing Spiking Transformers still lack a principled mechanism for effective temporal fusion, limiting their ability to fully exploit spatiotemporal dependencies. Inspired by feedforward-feedback modulation in the human visual pathway, we propose TEFormer, the first Spiking Transformer framework that achieves bidirectional temporal fusion by decoupling temporal modeling across its core components. Specifically, TEFormer employs a lightweight and hyperparameter-free forward temporal fusion mechanism in the attention module, enabling fully parallel computation, while incorporating a backward gated recurrent structure in the MLP to aggregate temporal information in reverse order and reinforce temporal consistency. Extensive experiments across a wide range of benchmarks demonstrate that TEFormer consistently and significantly outperforms strong SNN and Spiking Transformer baselines under diverse datasets. Moreover, through the first systematic evaluation of Spiking Transformers under different neural encoding schemes, we show that the performance gains of TEFormer remain stable across encoding choices, indicating that the improved temporal modeling directly translates into reliable accuracy improvements across varied spiking representations. These results collectively establish TEFormer as an effective and general framework for temporal modeling in Spiking Transformers.",
      "url": "http://arxiv.org/abs/2601.18274",
      "author": "Sicheng Shen, Mingyang Lv, Bing Han, Dongcheng Zhao, Guobin Shen, Feifei Zhao, Yi Zeng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "cs.NE"
      ],
      "summary": "Introduces TEFormer, a spiking transformer with bidirectional temporal fusion inspired by feedforward-feedback modulation in human visual pathway.",
      "importance_score": 53,
      "reasoning": "Advances spiking neural network architectures with neurobiologically-inspired design, contributes to neuromorphic computing.",
      "themes": [
        "Spiking Neural Networks",
        "Transformers",
        "Neuromorphic Computing"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces TEFormer, a spiking transformer with bidirectional temporal fusion inspired by feedforward-feedback modulation in human visual pathway.</p>",
      "content_html": "<p>arXiv:2601.18274v1 Announce Type: new  Abstract: In recent years, Spiking Neural Networks (SNNs) have achieved remarkable progress, with Spiking Transformers emerging as a promising architecture for energy-efficient sequence modeling. However, existing Spiking Transformers still lack a principled mechanism for effective temporal fusion, limiting their ability to fully exploit spatiotemporal dependencies. Inspired by feedforward-feedback modulation in the human visual pathway, we propose TEFormer, the first Spiking Transformer framework that achieves bidirectional temporal fusion by decoupling temporal modeling across its core components. Specifically, TEFormer employs a lightweight and hyperparameter-free forward temporal fusion mechanism in the attention module, enabling fully parallel computation, while incorporating a backward gated recurrent structure in the MLP to aggregate temporal information in reverse order and reinforce temporal consistency. Extensive experiments across a wide range of benchmarks demonstrate that TEFormer consistently and significantly outperforms strong SNN and Spiking Transformer baselines under diverse datasets. Moreover, through the first systematic evaluation of Spiking Transformers under different neural encoding schemes, we show that the performance gains of TEFormer remain stable across encoding choices, indicating that the improved temporal modeling directly translates into reliable accuracy improvements across varied spiking representations. These results collectively establish TEFormer as an effective and general framework for temporal modeling in Spiking Transformers.</p>"
    },
    {
      "id": "a281b161922c",
      "title": "AsterNav: Autonomous Aerial Robot Navigation In Darkness Using Passive Computation",
      "content": "arXiv:2601.17550v1 Announce Type: new  Abstract: Autonomous aerial navigation in absolute darkness is crucial for post-disaster search and rescue operations, which often occur from disaster-zone power outages. Yet, due to resource constraints, tiny aerial robots, perfectly suited for these operations, are unable to navigate in the darkness to find survivors safely. In this paper, we present an autonomous aerial robot for navigation in the dark by combining an Infra-Red (IR) monocular camera with a large-aperture coded lens and structured light without external infrastructure like GPS or motion-capture. Our approach obtains depth-dependent defocus cues (each structured light point appears as a pattern that is depth dependent), which acts as a strong prior for our AsterNet deep depth estimation model. The model is trained in simulation by generating data using a simple optical model and transfers directly to the real world without any fine-tuning or retraining. AsterNet runs onboard the robot at 20 Hz on an NVIDIA Jetson Orin$^\\text{TM}$ Nano. Furthermore, our network is robust to changes in the structured light pattern and relative placement of the pattern emitter and IR camera, leading to simplified and cost-effective construction. We successfully evaluate and demonstrate our proposed depth navigation approach AsterNav using depth from AsterNet in many real-world experiments using only onboard sensing and computation, including dark matte obstacles and thin ropes (diameter 6.25mm), achieving an overall success rate of 95.5% with unknown object shapes, locations and materials. To the best of our knowledge, this is the first work on monocular, structured-light-based quadrotor navigation in absolute darkness.",
      "url": "http://arxiv.org/abs/2601.17550",
      "author": "Deepak Singh, Shreyas Khobragade, Nitin J. Sanket",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents AsterNav for autonomous aerial navigation in darkness using IR camera with coded lens and structured light for depth-dependent defocus cues.",
      "importance_score": 53,
      "reasoning": "Novel sensing approach for challenging navigation scenario, practical for search and rescue.",
      "themes": [
        "Aerial Robotics",
        "Depth Estimation",
        "Low-Light Navigation"
      ],
      "continuation": null,
      "summary_html": "<p>Presents AsterNav for autonomous aerial navigation in darkness using IR camera with coded lens and structured light for depth-dependent defocus cues.</p>",
      "content_html": "<p>arXiv:2601.17550v1 Announce Type: new  Abstract: Autonomous aerial navigation in absolute darkness is crucial for post-disaster search and rescue operations, which often occur from disaster-zone power outages. Yet, due to resource constraints, tiny aerial robots, perfectly suited for these operations, are unable to navigate in the darkness to find survivors safely. In this paper, we present an autonomous aerial robot for navigation in the dark by combining an Infra-Red (IR) monocular camera with a large-aperture coded lens and structured light without external infrastructure like GPS or motion-capture. Our approach obtains depth-dependent defocus cues (each structured light point appears as a pattern that is depth dependent), which acts as a strong prior for our AsterNet deep depth estimation model. The model is trained in simulation by generating data using a simple optical model and transfers directly to the real world without any fine-tuning or retraining. AsterNet runs onboard the robot at 20 Hz on an NVIDIA Jetson Orin$^\\text{TM}$ Nano. Furthermore, our network is robust to changes in the structured light pattern and relative placement of the pattern emitter and IR camera, leading to simplified and cost-effective construction. We successfully evaluate and demonstrate our proposed depth navigation approach AsterNav using depth from AsterNet in many real-world experiments using only onboard sensing and computation, including dark matte obstacles and thin ropes (diameter 6.25mm), achieving an overall success rate of 95.5% with unknown object shapes, locations and materials. To the best of our knowledge, this is the first work on monocular, structured-light-based quadrotor navigation in absolute darkness.</p>"
    },
    {
      "id": "326188bbdbdf",
      "title": "A Cherry-Picking Approach to Large Load Shaping for More Effective Carbon Reduction",
      "content": "arXiv:2601.17990v1 Announce Type: new  Abstract: Shaping multi-megawatt loads, such as data centers, impacts generator dispatch on the electric grid, which in turn affects system CO2 emissions and energy cost. Substantiating the effectiveness of prevalent load shaping strategies, such as those based on grid-level average carbon intensity, locational marginal price, or marginal emissions, is challenging due to the lack of detailed counterfactual data required for accurate attribution. This study uses a series of calibrated granular ERCOT day-ahead direct current optimal power flow (DC-OPF) simulations for counterfactual analysis of a broad set of load shaping strategies on grid CO2 emissions and cost of electricity. In terms of annual grid level CO2 emissions reductions, LMP-based shaping outperforms other common strategies, but can be significantly improved upon. Examining the performance of practicable strategies under different grid conditions motivates a more effective load shaping approach: one that \"cherry-picks\" a daily strategy based on observable grid signals and historical data. The cherry-picking approach to power load shaping is applicable to any large flexible consumer on the electricity grid, such as data centers, distributed energy resources and Virtual Power Plants (VPPs).",
      "url": "http://arxiv.org/abs/2601.17990",
      "author": "Bokan Chen, Raiden Hasegawa, Adriaan Hilbers, Ross Koningstein, Ana Radovanovi\\'c, Utkarsh Shah, Gabriela Volpato, Mohamed Ahmed, Tim Cary, Rod Frowd",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "stat.ML"
      ],
      "summary": "Studies load shaping strategies for data centers on CO2 emissions using calibrated DC-OPF simulations of ERCOT grid, finding LMP-based shaping underperforms other strategies.",
      "importance_score": 53,
      "reasoning": "Practical sustainability contribution with rigorous counterfactual analysis, relevant to data center operations.",
      "themes": [
        "Sustainability",
        "Data Centers",
        "Grid Optimization",
        "Carbon Reduction"
      ],
      "continuation": null,
      "summary_html": "<p>Studies load shaping strategies for data centers on CO2 emissions using calibrated DC-OPF simulations of ERCOT grid, finding LMP-based shaping underperforms other strategies.</p>",
      "content_html": "<p>arXiv:2601.17990v1 Announce Type: new  Abstract: Shaping multi-megawatt loads, such as data centers, impacts generator dispatch on the electric grid, which in turn affects system CO2 emissions and energy cost. Substantiating the effectiveness of prevalent load shaping strategies, such as those based on grid-level average carbon intensity, locational marginal price, or marginal emissions, is challenging due to the lack of detailed counterfactual data required for accurate attribution. This study uses a series of calibrated granular ERCOT day-ahead direct current optimal power flow (DC-OPF) simulations for counterfactual analysis of a broad set of load shaping strategies on grid CO2 emissions and cost of electricity. In terms of annual grid level CO2 emissions reductions, LMP-based shaping outperforms other common strategies, but can be significantly improved upon. Examining the performance of practicable strategies under different grid conditions motivates a more effective load shaping approach: one that \"cherry-picks\" a daily strategy based on observable grid signals and historical data. The cherry-picking approach to power load shaping is applicable to any large flexible consumer on the electricity grid, such as data centers, distributed energy resources and Virtual Power Plants (VPPs).</p>"
    },
    {
      "id": "8284ea914ed3",
      "title": "A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience",
      "content": "arXiv:2601.18308v1 Announce Type: new  Abstract: As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures.",
      "url": "http://arxiv.org/abs/2601.18308",
      "author": "Geunsik Lim",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces Climate RADAR, an AI-based disaster communication system reframing alerts as action recommendations using guardrail-embedded LLMs with personalized guidance across multiple interfaces.",
      "importance_score": 52,
      "reasoning": "Important application domain; practical approach but limited AI research novelty.",
      "themes": [
        "Disaster Response",
        "Applied AI",
        "Guardrails"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Climate RADAR, an AI-based disaster communication system reframing alerts as action recommendations using guardrail-embedded LLMs with personalized guidance across multiple interfaces.</p>",
      "content_html": "<p>arXiv:2601.18308v1 Announce Type: new  Abstract: As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures.</p>"
    },
    {
      "id": "c0a7ea509640",
      "title": "TelcoAI: Advancing 3GPP Technical Specification Search through Agentic Multi-Modal Retrieval-Augmented Generation",
      "content": "arXiv:2601.16984v1 Announce Type: cross  Abstract: The 3rd Generation Partnership Project (3GPP) produces complex technical specifications essential to global telecommunications, yet their hierarchical structure, dense formatting, and multi-modal content make them difficult to process. While Large Language Models (LLMs) show promise, existing approaches fall short in handling complex queries, visual information, and document interdependencies. We present TelcoAI, an agentic, multi-modal Retrieval-Augmented Generation (RAG) system tailored for 3GPP documentation. TelcoAI introduces section-aware chunking, structured query planning, metadata-guided retrieval, and multi-modal fusion of text and diagrams. Evaluated on multiple benchmarks-including expert-curated queries-our system achieves $87\\%$ recall, $83\\%$ claim recall, and $92\\%$ faithfulness, representing a $16\\%$ improvement over state-of-the-art baselines. These results demonstrate the effectiveness of agentic and multi-modal reasoning in technical document understanding, advancing practical solutions for real-world telecommunications research and engineering.",
      "url": "http://arxiv.org/abs/2601.16984",
      "author": "Rahul Ghosh, Chun-Hao Liu, Gaurav Rele, Vidya Sagar Ravipati, Hazar Aouad",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Presents TelcoAI, agentic multi-modal RAG system for 3GPP documentation with section-aware chunking, structured query planning, and multi-modal fusion achieving 87% accuracy.",
      "importance_score": 52,
      "reasoning": "Domain-specific RAG application; practical but specialized to telecommunications standards.",
      "themes": [
        "RAG",
        "Telecommunications",
        "Multi-Modal AI"
      ],
      "continuation": null,
      "summary_html": "<p>Presents TelcoAI, agentic multi-modal RAG system for 3GPP documentation with section-aware chunking, structured query planning, and multi-modal fusion achieving 87% accuracy.</p>",
      "content_html": "<p>arXiv:2601.16984v1 Announce Type: cross  Abstract: The 3rd Generation Partnership Project (3GPP) produces complex technical specifications essential to global telecommunications, yet their hierarchical structure, dense formatting, and multi-modal content make them difficult to process. While Large Language Models (LLMs) show promise, existing approaches fall short in handling complex queries, visual information, and document interdependencies. We present TelcoAI, an agentic, multi-modal Retrieval-Augmented Generation (RAG) system tailored for 3GPP documentation. TelcoAI introduces section-aware chunking, structured query planning, metadata-guided retrieval, and multi-modal fusion of text and diagrams. Evaluated on multiple benchmarks-including expert-curated queries-our system achieves $87\\%$ recall, $83\\%$ claim recall, and $92\\%$ faithfulness, representing a $16\\%$ improvement over state-of-the-art baselines. These results demonstrate the effectiveness of agentic and multi-modal reasoning in technical document understanding, advancing practical solutions for real-world telecommunications research and engineering.</p>"
    },
    {
      "id": "c9e83ea0d988",
      "title": "Single-Pixel Vision-Language Model for Intrinsic Privacy-Preserving Behavioral Intelligence",
      "content": "arXiv:2601.17050v1 Announce Type: cross  Abstract: Adverse social interactions, such as bullying, harassment, and other illicit activities, pose significant threats to individual well-being and public safety, leaving profound impacts on physical and mental health. However, these critical events frequently occur in privacy-sensitive environments like restrooms, and changing rooms, where conventional surveillance is prohibited or severely restricted by stringent privacy regulations and ethical concerns. Here, we propose the Single-Pixel Vision-Language Model (SP-VLM), a novel framework that reimagines secure environmental monitoring. It achieves intrinsic privacy-by-design by capturing human dynamics through inherently low-dimensional single-pixel modalities and inferring complex behavioral patterns via seamless vision-language integration. Building on this framework, we demonstrate that single-pixel sensing intrinsically suppresses identity recoverability, rendering state-of-the-art face recognition systems ineffective below a critical sampling rate. We further show that SP-VLM can nonetheless extract meaningful behavioral semantics, enabling robust anomaly detection, people counting, and activity understanding from severely degraded single-pixel observations. Combining these findings, we identify a practical sampling-rate regime in which behavioral intelligence emerges while personal identity remains strongly protected. Together, these results point to a human-rights-aligned pathway for safety monitoring that can support timely intervention without normalizing intrusive surveillance in privacy-sensitive spaces.",
      "url": "http://arxiv.org/abs/2601.17050",
      "author": "Hongjun An, Yiliang Song, Jiawei Shao, Zhe Sun, Xuelong Li",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes Single-Pixel Vision-Language Model (SP-VLM) for privacy-preserving behavioral monitoring using inherently low-dimensional single-pixel modalities to detect adverse social interactions.",
      "importance_score": 52,
      "reasoning": "Novel privacy-by-design approach for sensitive environments. Creative use of single-pixel sensing with VLM but limited evaluation scope.",
      "themes": [
        "Privacy-Preserving AI",
        "Vision-Language Models",
        "Behavioral Monitoring"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Single-Pixel Vision-Language Model (SP-VLM) for privacy-preserving behavioral monitoring using inherently low-dimensional single-pixel modalities to detect adverse social interactions.</p>",
      "content_html": "<p>arXiv:2601.17050v1 Announce Type: cross  Abstract: Adverse social interactions, such as bullying, harassment, and other illicit activities, pose significant threats to individual well-being and public safety, leaving profound impacts on physical and mental health. However, these critical events frequently occur in privacy-sensitive environments like restrooms, and changing rooms, where conventional surveillance is prohibited or severely restricted by stringent privacy regulations and ethical concerns. Here, we propose the Single-Pixel Vision-Language Model (SP-VLM), a novel framework that reimagines secure environmental monitoring. It achieves intrinsic privacy-by-design by capturing human dynamics through inherently low-dimensional single-pixel modalities and inferring complex behavioral patterns via seamless vision-language integration. Building on this framework, we demonstrate that single-pixel sensing intrinsically suppresses identity recoverability, rendering state-of-the-art face recognition systems ineffective below a critical sampling rate. We further show that SP-VLM can nonetheless extract meaningful behavioral semantics, enabling robust anomaly detection, people counting, and activity understanding from severely degraded single-pixel observations. Combining these findings, we identify a practical sampling-rate regime in which behavioral intelligence emerges while personal identity remains strongly protected. Together, these results point to a human-rights-aligned pathway for safety monitoring that can support timely intervention without normalizing intrusive surveillance in privacy-sensitive spaces.</p>"
    },
    {
      "id": "c547bafb4d98",
      "title": "ThinkTank-ME: A Multi-Expert Framework for Middle East Event Forecasting",
      "content": "arXiv:2601.17065v1 Announce Type: cross  Abstract: Event forecasting is inherently influenced by multifaceted considerations, including international relations, regional historical dynamics, and cultural contexts. However, existing LLM-based approaches employ single-model architectures that generate predictions along a singular explicit trajectory, constraining their ability to capture diverse geopolitical nuances across complex regional contexts. To address this limitation, we introduce ThinkTank-ME, a novel Think Tank framework for Middle East event forecasting that emulates collaborative expert analysis in real-world strategic decision-making. To facilitate expert specialization and rigorous evaluation, we construct POLECAT-FOR-ME, a Middle East-focused event forecasting benchmark. Experimental results demonstrate the superiority of multi-expert collaboration in handling complex temporal geopolitical forecasting tasks. The code is available at https://github.com/LuminosityX/ThinkTank-ME.",
      "url": "http://arxiv.org/abs/2601.17065",
      "author": "Haoxuan Li, He Chang, Yunshan Ma, Yi Bin, Yang Yang, See-Kiong Ng, Tat-Seng Chua",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes ThinkTank-ME, a multi-expert LLM framework emulating collaborative expert analysis for Middle East event forecasting. Constructs POLECAT-FOR-ME benchmark for evaluation.",
      "importance_score": 52,
      "reasoning": "Novel multi-expert architecture for domain-specific reasoning. Interesting benchmark but narrow application domain.",
      "themes": [
        "Multi-Agent Systems",
        "Event Forecasting",
        "LLM Applications"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes ThinkTank-ME, a multi-expert LLM framework emulating collaborative expert analysis for Middle East event forecasting. Constructs POLECAT-FOR-ME benchmark for evaluation.</p>",
      "content_html": "<p>arXiv:2601.17065v1 Announce Type: cross  Abstract: Event forecasting is inherently influenced by multifaceted considerations, including international relations, regional historical dynamics, and cultural contexts. However, existing LLM-based approaches employ single-model architectures that generate predictions along a singular explicit trajectory, constraining their ability to capture diverse geopolitical nuances across complex regional contexts. To address this limitation, we introduce ThinkTank-ME, a novel Think Tank framework for Middle East event forecasting that emulates collaborative expert analysis in real-world strategic decision-making. To facilitate expert specialization and rigorous evaluation, we construct POLECAT-FOR-ME, a Middle East-focused event forecasting benchmark. Experimental results demonstrate the superiority of multi-expert collaboration in handling complex temporal geopolitical forecasting tasks. The code is available at https://github.com/LuminosityX/ThinkTank-ME.</p>"
    },
    {
      "id": "31865d33fb51",
      "title": "The Triangle of Similarity: A Multi-Faceted Framework for Comparing Neural Network Representations",
      "content": "arXiv:2601.17093v1 Announce Type: cross  Abstract: Comparing neural network representations is essential for understanding and validating models in scientific applications. Existing methods, however, often provide a limited view. We propose the Triangle of Similarity, a framework that combines three complementary perspectives: static representational similarity (CKA/Procrustes), functional similarity (Linear Mode Connectivity or Predictive Similarity), and sparsity similarity (robustness under pruning). Analyzing a range of CNNs, Vision Transformers, and Vision-Language Models using both in-distribution (ImageNetV2) and out-of-distribution (CIFAR-10) testbeds, our initial findings suggest that: (1) architectural family is a primary determinant of representational similarity, forming distinct clusters; (2) CKA self-similarity and task accuracy are strongly correlated during pruning, though accuracy often degrades more sharply; and (3) for some model pairs, pruning appears to regularize representations, exposing a shared computational core. This framework offers a more holistic approach for assessing whether models have converged on similar internal mechanisms, providing a useful tool for model selection and analysis in scientific research.",
      "url": "http://arxiv.org/abs/2601.17093",
      "author": "Olha Sirikova, Alvin Chan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes Triangle of Similarity framework combining CKA/Procrustes, functional similarity, and sparsity similarity for comparing neural network representations across architectures.",
      "importance_score": 52,
      "reasoning": "Methodological contribution to representation comparison. Multi-faceted approach but primarily synthesis of existing metrics.",
      "themes": [
        "Representation Learning",
        "Model Analysis",
        "Interpretability"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Triangle of Similarity framework combining CKA/Procrustes, functional similarity, and sparsity similarity for comparing neural network representations across architectures.</p>",
      "content_html": "<p>arXiv:2601.17093v1 Announce Type: cross  Abstract: Comparing neural network representations is essential for understanding and validating models in scientific applications. Existing methods, however, often provide a limited view. We propose the Triangle of Similarity, a framework that combines three complementary perspectives: static representational similarity (CKA/Procrustes), functional similarity (Linear Mode Connectivity or Predictive Similarity), and sparsity similarity (robustness under pruning). Analyzing a range of CNNs, Vision Transformers, and Vision-Language Models using both in-distribution (ImageNetV2) and out-of-distribution (CIFAR-10) testbeds, our initial findings suggest that: (1) architectural family is a primary determinant of representational similarity, forming distinct clusters; (2) CKA self-similarity and task accuracy are strongly correlated during pruning, though accuracy often degrades more sharply; and (3) for some model pairs, pruning appears to regularize representations, exposing a shared computational core. This framework offers a more holistic approach for assessing whether models have converged on similar internal mechanisms, providing a useful tool for model selection and analysis in scientific research.</p>"
    },
    {
      "id": "68aa285f5fbe",
      "title": "Interpretability of the Intent Detection Problem: A New Approach",
      "content": "arXiv:2601.17156v1 Announce Type: cross  Abstract: Intent detection, a fundamental text classification task, aims to identify and label the semantics of user queries, playing a vital role in numerous business applications. Despite the dominance of deep learning techniques in this field, the internal mechanisms enabling Recurrent Neural Networks (RNNs) to solve intent detection tasks are poorly understood. In this work, we apply dynamical systems theory to analyze how RNN architectures address this problem, using both the balanced SNIPS and the imbalanced ATIS datasets. By interpreting sentences as trajectories in the hidden state space, we first show that on the balanced SNIPS dataset, the network learns an ideal solution: the state space, constrained to a low-dimensional manifold, is partitioned into distinct clusters corresponding to each intent. The application of this framework to the imbalanced ATIS dataset then reveals how this ideal geometric solution is distorted by class imbalance, causing the clusters for low-frequency intents to degrade. Our framework decouples geometric separation from readout alignment, providing a novel, mechanistic explanation for real world performance disparities. These findings provide new insights into RNN dynamics, offering a geometric interpretation of how dataset properties directly shape a network's computational solution.",
      "url": "http://arxiv.org/abs/2601.17156",
      "author": "Eduardo Sanchez-Karhunen, Jose F. Quesada-Moreno, Miguel A. Guti\\'errez-Naranjo",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Applies dynamical systems theory to understand RNN intent detection, interpreting sentences as trajectories in hidden state space. Reveals distinct solution structures for balanced vs imbalanced datasets.",
      "importance_score": 52,
      "reasoning": "Interesting interpretability approach using dynamical systems. Provides insight into RNN behavior but limited to specific architecture.",
      "themes": [
        "Interpretability",
        "RNNs",
        "Natural Language Understanding"
      ],
      "continuation": null,
      "summary_html": "<p>Applies dynamical systems theory to understand RNN intent detection, interpreting sentences as trajectories in hidden state space. Reveals distinct solution structures for balanced vs imbalanced datasets.</p>",
      "content_html": "<p>arXiv:2601.17156v1 Announce Type: cross  Abstract: Intent detection, a fundamental text classification task, aims to identify and label the semantics of user queries, playing a vital role in numerous business applications. Despite the dominance of deep learning techniques in this field, the internal mechanisms enabling Recurrent Neural Networks (RNNs) to solve intent detection tasks are poorly understood. In this work, we apply dynamical systems theory to analyze how RNN architectures address this problem, using both the balanced SNIPS and the imbalanced ATIS datasets. By interpreting sentences as trajectories in the hidden state space, we first show that on the balanced SNIPS dataset, the network learns an ideal solution: the state space, constrained to a low-dimensional manifold, is partitioned into distinct clusters corresponding to each intent. The application of this framework to the imbalanced ATIS dataset then reveals how this ideal geometric solution is distorted by class imbalance, causing the clusters for low-frequency intents to degrade. Our framework decouples geometric separation from readout alignment, providing a novel, mechanistic explanation for real world performance disparities. These findings provide new insights into RNN dynamics, offering a geometric interpretation of how dataset properties directly shape a network's computational solution.</p>"
    },
    {
      "id": "b4327da7a52e",
      "title": "Conservative & Aggressive NaNs Accelerate U-Nets for Neuroimaging",
      "content": "arXiv:2601.17180v1 Announce Type: cross  Abstract: Deep learning models for neuroimaging increasingly rely on large architectures, making efficiency a persistent concern despite advances in hardware. Through an analysis of numerical uncertainty of convolutional neural networks (CNNs), we observe that many operations are applied to values dominated by numerical noise and have negligible influence on model outputs. In some models, up to two-thirds of convolution operations appear redundant. We introduce Conservative & Aggressive NaNs, two novel variants of max pooling and unpooling that identify numerically unstable voxels and replace them with NaNs, allowing subsequent layers to skip computations on irrelevant data. Both methods are implemented within PyTorch and require no architectural changes. We evaluate these approaches on four CNN models spanning neuroimaging and image classification tasks. For inputs containing at least 50% NaNs, we observe consistent runtime improvements; for data with more than two-thirds NaNs )common in several neuroimaging settings) we achieve an average inference speedup of 1.67x. Conservative NaNs reduces convolution operations by an average of 30% across models and datasets, with no measurable performance degradation, and can skip up to 64.64% of convolutions in specific layers. Aggressive NaNs can skip up to 69.30% of convolutions but may occasionally affect performance. Overall, these methods demonstrate that numerical uncertainty can be exploited to reduce redundant computation and improve inference efficiency in CNNs.",
      "url": "http://arxiv.org/abs/2601.17180",
      "author": "In\\'es Gonzalez-Pepe, Vinuyan Sivakolunthu, Jacob Fortin, Yohan Chatelain, Tristan Glatard",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces Conservative & Aggressive NaNs, novel max pooling variants that identify numerically unstable voxels and skip computations on irrelevant data, achieving 2x speedup in neuroimaging CNNs.",
      "importance_score": 52,
      "reasoning": "Creative efficiency technique exploiting numerical instability. Practical speedup but narrow application domain.",
      "themes": [
        "Efficient Inference",
        "Medical Imaging",
        "CNN Optimization"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Conservative &amp; Aggressive NaNs, novel max pooling variants that identify numerically unstable voxels and skip computations on irrelevant data, achieving 2x speedup in neuroimaging CNNs.</p>",
      "content_html": "<p>arXiv:2601.17180v1 Announce Type: cross  Abstract: Deep learning models for neuroimaging increasingly rely on large architectures, making efficiency a persistent concern despite advances in hardware. Through an analysis of numerical uncertainty of convolutional neural networks (CNNs), we observe that many operations are applied to values dominated by numerical noise and have negligible influence on model outputs. In some models, up to two-thirds of convolution operations appear redundant. We introduce Conservative &amp; Aggressive NaNs, two novel variants of max pooling and unpooling that identify numerically unstable voxels and replace them with NaNs, allowing subsequent layers to skip computations on irrelevant data. Both methods are implemented within PyTorch and require no architectural changes. We evaluate these approaches on four CNN models spanning neuroimaging and image classification tasks. For inputs containing at least 50% NaNs, we observe consistent runtime improvements; for data with more than two-thirds NaNs )common in several neuroimaging settings) we achieve an average inference speedup of 1.67x. Conservative NaNs reduces convolution operations by an average of 30% across models and datasets, with no measurable performance degradation, and can skip up to 64.64% of convolutions in specific layers. Aggressive NaNs can skip up to 69.30% of convolutions but may occasionally affect performance. Overall, these methods demonstrate that numerical uncertainty can be exploited to reduce redundant computation and improve inference efficiency in CNNs.</p>"
    },
    {
      "id": "622714ef78f5",
      "title": "Human-Aligned Enhancement of Programming Answers with LLMs Guided by User Feedback",
      "content": "arXiv:2601.17604v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are widely used to support software developers in tasks such as code generation, optimization, and documentation. However, their ability to improve existing programming answers in a human-like manner remains underexplored. On technical question-and-answer platforms such as Stack Overflow (SO), contributors often revise answers based on user comments that identify errors, inefficiencies, or missing explanations. Yet roughly one-third of this feedback is never addressed due to limited time, expertise, or visibility, leaving many answers incomplete or outdated. This study investigates whether LLMs can enhance programming answers by interpreting and incorporating comment-based feedback. We make four main contributions. First, we introduce ReSOlve, a benchmark consisting of 790 SO answers with associated comment threads, annotated for improvement-related and general feedback. Second, we evaluate four state-of-the-art LLMs on their ability to identify actionable concerns, finding that DeepSeek achieves the best balance between precision and recall. Third, we present AUTOCOMBAT, an LLM-powered tool that improves programming answers by jointly leveraging user comments and question context. Compared to human revised references, AUTOCOMBAT produces near-human quality improvements while preserving the original intent and significantly outperforming the baseline. Finally, a user study with 58 practitioners shows strong practical value, with 84.5 percent indicating they would adopt or recommend the tool. Overall, AUTOCOMBAT demonstrates the potential of scalable, feedback-driven answer refinement to improve the reliability and trustworthiness of technical knowledge platforms.",
      "url": "http://arxiv.org/abs/2601.17604",
      "author": "Suborno Deb Bappon, Saikat Mondal, Chanchal K. Roy, Kevin Schneider",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.SE"
      ],
      "summary": "Studies whether LLMs can improve Stack Overflow answers by incorporating user feedback from comments, finding one-third of feedback is never addressed.",
      "importance_score": 52,
      "reasoning": "Practical application of LLMs to knowledge maintenance. Identifies real problem in community platforms.",
      "themes": [
        "Code QA",
        "LLM Applications",
        "Knowledge Maintenance"
      ],
      "continuation": null,
      "summary_html": "<p>Studies whether LLMs can improve Stack Overflow answers by incorporating user feedback from comments, finding one-third of feedback is never addressed.</p>",
      "content_html": "<p>arXiv:2601.17604v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are widely used to support software developers in tasks such as code generation, optimization, and documentation. However, their ability to improve existing programming answers in a human-like manner remains underexplored. On technical question-and-answer platforms such as Stack Overflow (SO), contributors often revise answers based on user comments that identify errors, inefficiencies, or missing explanations. Yet roughly one-third of this feedback is never addressed due to limited time, expertise, or visibility, leaving many answers incomplete or outdated. This study investigates whether LLMs can enhance programming answers by interpreting and incorporating comment-based feedback. We make four main contributions. First, we introduce ReSOlve, a benchmark consisting of 790 SO answers with associated comment threads, annotated for improvement-related and general feedback. Second, we evaluate four state-of-the-art LLMs on their ability to identify actionable concerns, finding that DeepSeek achieves the best balance between precision and recall. Third, we present AUTOCOMBAT, an LLM-powered tool that improves programming answers by jointly leveraging user comments and question context. Compared to human revised references, AUTOCOMBAT produces near-human quality improvements while preserving the original intent and significantly outperforming the baseline. Finally, a user study with 58 practitioners shows strong practical value, with 84.5 percent indicating they would adopt or recommend the tool. Overall, AUTOCOMBAT demonstrates the potential of scalable, feedback-driven answer refinement to improve the reliability and trustworthiness of technical knowledge platforms.</p>"
    },
    {
      "id": "bace89e2b032",
      "title": "What Do Learned Models Measure?",
      "content": "arXiv:2601.18278v1 Announce Type: cross  Abstract: In many scientific and data-driven applications, machine learning models are increasingly used as measurement instruments, rather than merely as predictors of predefined labels. When the measurement function is learned from data, the mapping from observations to quantities is determined implicitly by the training distribution and inductive biases, allowing multiple inequivalent mappings to satisfy standard predictive evaluation criteria. We formalize learned measurement functions as a distinct focus of evaluation and introduce measurement stability, a property capturing invariance of the measured quantity across admissible realizations of the learning process and across contexts. We show that standard evaluation criteria in machine learning, including generalization error, calibration, and robustness, do not guarantee measurement stability. Through a real-world case study, we show that models with comparable predictive performance can implement systematically inequivalent measurement functions, with distribution shift providing a concrete illustration of this failure. Taken together, our results highlight a limitation of existing evaluation frameworks in settings where learned model outputs are identified as measurements, motivating the need for an additional evaluative dimension.",
      "url": "http://arxiv.org/abs/2601.18278",
      "author": "Indr\\.e \\v{Z}liobait\\.e",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Formalizes learned measurement functions as distinct evaluation focus, introducing measurement stability concept capturing invariance across learning realizations and contexts. Shows standard ML criteria insufficient.",
      "importance_score": 52,
      "reasoning": "Thoughtful theoretical work on what ML models actually measure. Important conceptual contribution but abstract framework.",
      "themes": [
        "Measurement Theory",
        "ML Evaluation",
        "Theoretical ML"
      ],
      "continuation": null,
      "summary_html": "<p>Formalizes learned measurement functions as distinct evaluation focus, introducing measurement stability concept capturing invariance across learning realizations and contexts. Shows standard ML criteria insufficient.</p>",
      "content_html": "<p>arXiv:2601.18278v1 Announce Type: cross  Abstract: In many scientific and data-driven applications, machine learning models are increasingly used as measurement instruments, rather than merely as predictors of predefined labels. When the measurement function is learned from data, the mapping from observations to quantities is determined implicitly by the training distribution and inductive biases, allowing multiple inequivalent mappings to satisfy standard predictive evaluation criteria. We formalize learned measurement functions as a distinct focus of evaluation and introduce measurement stability, a property capturing invariance of the measured quantity across admissible realizations of the learning process and across contexts. We show that standard evaluation criteria in machine learning, including generalization error, calibration, and robustness, do not guarantee measurement stability. Through a real-world case study, we show that models with comparable predictive performance can implement systematically inequivalent measurement functions, with distribution shift providing a concrete illustration of this failure. Taken together, our results highlight a limitation of existing evaluation frameworks in settings where learned model outputs are identified as measurements, motivating the need for an additional evaluative dimension.</p>"
    },
    {
      "id": "045711dbf1e8",
      "title": "Gradient Regularized Natural Gradients",
      "content": "arXiv:2601.18420v1 Announce Type: cross  Abstract: Gradient regularization (GR) has been shown to improve the generalizability of trained models. While Natural Gradient Descent has been shown to accelerate optimization in the initial phase of training, little attention has been paid to how the training dynamics of second-order optimizers can benefit from GR. In this work, we propose Gradient-Regularized Natural Gradients (GRNG), a family of scalable second-order optimizers that integrate explicit gradient regularization with natural gradient updates. Our framework provides two complementary algorithms: a frequentist variant that avoids explicit inversion of the Fisher Information Matrix (FIM) via structured approximations, and a Bayesian variant based on a Regularized-Kalman formulation that eliminates the need for FIM inversion entirely. We establish convergence guarantees for GRNG, showing that gradient regularization improves stability and enables convergence to global minima. Empirically, we demonstrate that GRNG consistently enhances both optimization speed and generalization compared to first-order methods (SGD, AdamW) and second-order baselines (K-FAC, Sophia), with strong results on vision and language benchmarks. Our findings highlight gradient regularization as a principled and practical tool to unlock the robustness of natural gradient methods for large-scale deep learning.",
      "url": "http://arxiv.org/abs/2601.18420",
      "author": "Satya Prakash Dash, Hossein Abdi, Wei Pan, Samuel Kaski, Mingfei Sun",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes Gradient-Regularized Natural Gradients (GRNG), integrating gradient regularization with natural gradient updates via frequentist and Bayesian variants avoiding explicit Fisher matrix inversion.",
      "importance_score": 52,
      "reasoning": "Technical optimization contribution. Combines two established ideas (GR and natural gradients) but unclear practical advantage magnitude.",
      "themes": [
        "Optimization",
        "Natural Gradients",
        "Regularization"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Gradient-Regularized Natural Gradients (GRNG), integrating gradient regularization with natural gradient updates via frequentist and Bayesian variants avoiding explicit Fisher matrix inversion.</p>",
      "content_html": "<p>arXiv:2601.18420v1 Announce Type: cross  Abstract: Gradient regularization (GR) has been shown to improve the generalizability of trained models. While Natural Gradient Descent has been shown to accelerate optimization in the initial phase of training, little attention has been paid to how the training dynamics of second-order optimizers can benefit from GR. In this work, we propose Gradient-Regularized Natural Gradients (GRNG), a family of scalable second-order optimizers that integrate explicit gradient regularization with natural gradient updates. Our framework provides two complementary algorithms: a frequentist variant that avoids explicit inversion of the Fisher Information Matrix (FIM) via structured approximations, and a Bayesian variant based on a Regularized-Kalman formulation that eliminates the need for FIM inversion entirely. We establish convergence guarantees for GRNG, showing that gradient regularization improves stability and enables convergence to global minima. Empirically, we demonstrate that GRNG consistently enhances both optimization speed and generalization compared to first-order methods (SGD, AdamW) and second-order baselines (K-FAC, Sophia), with strong results on vision and language benchmarks. Our findings highlight gradient regularization as a principled and practical tool to unlock the robustness of natural gradient methods for large-scale deep learning.</p>"
    },
    {
      "id": "f9cfd71ffc2a",
      "title": "Learning long term climate-resilient transport adaptation pathways under direct and indirect flood impacts using reinforcement learning",
      "content": "arXiv:2601.18586v1 Announce Type: cross  Abstract: Climate change is expected to intensify rainfall and other hazards, increasing disruptions in urban transportation systems. Designing effective adaptation strategies is challenging due to the long-term, sequential nature of infrastructure investments, deep uncertainty, and complex cross-sector interactions. We propose a generic decision-support framework that couples an integrated assessment model (IAM) with reinforcement learning (RL) to learn adaptive, multi-decade investment pathways under uncertainty. The framework combines long-term climate projections (e.g., IPCC scenario pathways) with models that map projected extreme-weather drivers (e.g. rain) into hazard likelihoods (e.g. flooding), propagate hazards into urban infrastructure impacts (e.g. transport disruption), and value direct and indirect consequences for service performance and societal costs. Embedded in a reinforcement-learning loop, it learns adaptive climate adaptation policies that trade off investment and maintenance expenditures against avoided impacts. In collaboration with Copenhagen Municipality, we demonstrate the approach on pluvial flooding in the inner city for the horizon of 2024 to 2100. The learned strategies yield coordinated spatial-temporal pathways and improved robustness relative to conventional optimization baselines, namely inaction and random action, illustrating the framework's transferability to other hazards and cities.",
      "url": "http://arxiv.org/abs/2601.18586",
      "author": "Miguel Costa, Arthur Vandervoort, Carolin Schmidt, Morten W. Petersen, Martin Drews, Karyn Morrissey, Francisco C. Pereira",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes RL framework coupled with integrated assessment model for learning climate-resilient transport adaptation pathways under uncertainty, considering direct and indirect flood impacts.",
      "importance_score": 52,
      "reasoning": "Novel application of RL to long-term infrastructure planning under climate uncertainty. Important domain but specialized application.",
      "themes": [
        "Climate Adaptation",
        "Reinforcement Learning",
        "Infrastructure Planning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes RL framework coupled with integrated assessment model for learning climate-resilient transport adaptation pathways under uncertainty, considering direct and indirect flood impacts.</p>",
      "content_html": "<p>arXiv:2601.18586v1 Announce Type: cross  Abstract: Climate change is expected to intensify rainfall and other hazards, increasing disruptions in urban transportation systems. Designing effective adaptation strategies is challenging due to the long-term, sequential nature of infrastructure investments, deep uncertainty, and complex cross-sector interactions. We propose a generic decision-support framework that couples an integrated assessment model (IAM) with reinforcement learning (RL) to learn adaptive, multi-decade investment pathways under uncertainty. The framework combines long-term climate projections (e.g., IPCC scenario pathways) with models that map projected extreme-weather drivers (e.g. rain) into hazard likelihoods (e.g. flooding), propagate hazards into urban infrastructure impacts (e.g. transport disruption), and value direct and indirect consequences for service performance and societal costs. Embedded in a reinforcement-learning loop, it learns adaptive climate adaptation policies that trade off investment and maintenance expenditures against avoided impacts. In collaboration with Copenhagen Municipality, we demonstrate the approach on pluvial flooding in the inner city for the horizon of 2024 to 2100. The learned strategies yield coordinated spatial-temporal pathways and improved robustness relative to conventional optimization baselines, namely inaction and random action, illustrating the framework's transferability to other hazards and cities.</p>"
    },
    {
      "id": "9d9b1e8bc927",
      "title": "Point transformer for protein structural heterogeneity analysis using CryoEM",
      "content": "arXiv:2601.18713v1 Announce Type: cross  Abstract: Structural dynamics of macromolecules is critical to their structural-function relationship. Cryogenic electron microscopy (CryoEM) provides snapshots of vitrified protein at different compositional and conformational states, and the structural heterogeneity of proteins can be characterized through computational analysis of the images. For protein systems with multiple degrees of freedom, it is still challenging to disentangle and interpret the different modes of dynamics. Here, by implementing Point Transformer, a self-attention network designed for point cloud analysis, we are able to improve the performance of heterogeneity analysis on CryoEM data, and characterize the dynamics of highly complex protein systems in a more human-interpretable way.",
      "url": "http://arxiv.org/abs/2601.18713",
      "author": "Muyuan Chen, Muchen Li, Renjie Liao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "q-bio.QM"
      ],
      "summary": "Implements Point Transformer for CryoEM structural heterogeneity analysis, improving characterization of protein dynamics in complex systems with better human interpretability.",
      "importance_score": 52,
      "reasoning": "Application of point transformers to important structural biology problem. Practical advance for protein structure analysis.",
      "themes": [
        "Structural Biology",
        "Point Transformers",
        "CryoEM"
      ],
      "continuation": null,
      "summary_html": "<p>Implements Point Transformer for CryoEM structural heterogeneity analysis, improving characterization of protein dynamics in complex systems with better human interpretability.</p>",
      "content_html": "<p>arXiv:2601.18713v1 Announce Type: cross  Abstract: Structural dynamics of macromolecules is critical to their structural-function relationship. Cryogenic electron microscopy (CryoEM) provides snapshots of vitrified protein at different compositional and conformational states, and the structural heterogeneity of proteins can be characterized through computational analysis of the images. For protein systems with multiple degrees of freedom, it is still challenging to disentangle and interpret the different modes of dynamics. Here, by implementing Point Transformer, a self-attention network designed for point cloud analysis, we are able to improve the performance of heterogeneity analysis on CryoEM data, and characterize the dynamics of highly complex protein systems in a more human-interpretable way.</p>"
    },
    {
      "id": "9bd907564d93",
      "title": "SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification",
      "content": "arXiv:2601.18739v1 Announce Type: cross  Abstract: Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion. This framework decomposes the detection task into a hierarchical structure of binary fusion nodes, where each layer is designed to integrate decision boundaries aligned with specific levels of semantic abstraction. To validate the proposed framework, we present a comprehensive case study using MonuMAI, a real-world architectural style recognition system exposed to an open environment. This application faces a diverse range of inputs, including non-monument images, unknown architectural styles, and adversarial attacks, making it an ideal testbed for our proposal. Through extensive experimental evaluation in this domain, results demonstrate that our hierarchical fusion methodology significantly outperforms traditional baselines, effectively filtering these diverse OOD categories while preserving in-distribution performance.",
      "url": "http://arxiv.org/abs/2601.18739",
      "author": "Ignacio Antequera-S\\'anchez, Juan Luis Su\\'arez-D\\'iaz, Rosana Montes, Francisco Herrera",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes SeNeDiF-OOD using Semantic Nested Dichotomy Fusion for out-of-distribution detection, creating hierarchical binary fusion nodes aligned with semantic abstraction levels.",
      "importance_score": 52,
      "reasoning": "Novel hierarchical approach to OOD detection. Addresses heterogeneous OOD challenge but validated only on monument classification.",
      "themes": [
        "OOD Detection",
        "Hierarchical Classification",
        "Computer Vision"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes SeNeDiF-OOD using Semantic Nested Dichotomy Fusion for out-of-distribution detection, creating hierarchical binary fusion nodes aligned with semantic abstraction levels.</p>",
      "content_html": "<p>arXiv:2601.18739v1 Announce Type: cross  Abstract: Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion. This framework decomposes the detection task into a hierarchical structure of binary fusion nodes, where each layer is designed to integrate decision boundaries aligned with specific levels of semantic abstraction. To validate the proposed framework, we present a comprehensive case study using MonuMAI, a real-world architectural style recognition system exposed to an open environment. This application faces a diverse range of inputs, including non-monument images, unknown architectural styles, and adversarial attacks, making it an ideal testbed for our proposal. Through extensive experimental evaluation in this domain, results demonstrate that our hierarchical fusion methodology significantly outperforms traditional baselines, effectively filtering these diverse OOD categories while preserving in-distribution performance.</p>"
    },
    {
      "id": "5d2137e432f7",
      "title": "AutoRegressive Generation with B-rep Holistic Token Sequence Representation",
      "content": "arXiv:2601.16771v1 Announce Type: cross  Abstract: Previous representation and generation approaches for the B-rep relied on graph-based representations that disentangle geometric and topological features through decoupled computational pipelines, thereby precluding the application of sequence-based generative frameworks, such as transformer architectures that have demonstrated remarkable performance. In this paper, we propose BrepARG, the first attempt to encode B-rep's geometry and topology into a holistic token sequence representation, enabling sequence-based B-rep generation with an autoregressive architecture. Specifically, BrepARG encodes B-rep into 3 types of tokens: geometry and position tokens representing geometric features, and face index tokens representing topology. Then the holistic token sequence is constructed hierarchically, starting with constructing the geometry blocks (i.e., faces and edges) using the above tokens, followed by geometry block sequencing. Finally, we assemble the holistic sequence representation for the entire B-rep. We also construct a transformer-based autoregressive model that learns the distribution over holistic token sequences via next-token prediction, using a multi-layer decoder-only architecture with causal masking. Experiments demonstrate that BrepARG achieves state-of-the-art (SOTA) performance. BrepARG validates the feasibility of representing B-rep as holistic token sequences, opening new directions for B-rep generation.",
      "url": "http://arxiv.org/abs/2601.16771",
      "author": "Jiahao Li, Yunpeng Bai, Yongkang Dai, Hao Guo, Hongping Gan, Yilei Shi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "First approach to encode B-rep (boundary representation) geometry and topology into a holistic token sequence for autoregressive generation using transformers. Enables sequence-based CAD model generation, bringing transformer architectures to 3D manufacturing design.",
      "importance_score": 52,
      "reasoning": "Novel application of transformers to CAD/manufacturing domain, but niche application area with limited broader AI impact.",
      "themes": [
        "Generative Models",
        "3D Generation",
        "Transformer Architectures"
      ],
      "continuation": null,
      "summary_html": "<p>First approach to encode B-rep (boundary representation) geometry and topology into a holistic token sequence for autoregressive generation using transformers. Enables sequence-based CAD model generation, bringing transformer architectures to 3D manufacturing design.</p>",
      "content_html": "<p>arXiv:2601.16771v1 Announce Type: cross  Abstract: Previous representation and generation approaches for the B-rep relied on graph-based representations that disentangle geometric and topological features through decoupled computational pipelines, thereby precluding the application of sequence-based generative frameworks, such as transformer architectures that have demonstrated remarkable performance. In this paper, we propose BrepARG, the first attempt to encode B-rep's geometry and topology into a holistic token sequence representation, enabling sequence-based B-rep generation with an autoregressive architecture. Specifically, BrepARG encodes B-rep into 3 types of tokens: geometry and position tokens representing geometric features, and face index tokens representing topology. Then the holistic token sequence is constructed hierarchically, starting with constructing the geometry blocks (i.e., faces and edges) using the above tokens, followed by geometry block sequencing. Finally, we assemble the holistic sequence representation for the entire B-rep. We also construct a transformer-based autoregressive model that learns the distribution over holistic token sequences via next-token prediction, using a multi-layer decoder-only architecture with causal masking. Experiments demonstrate that BrepARG achieves state-of-the-art (SOTA) performance. BrepARG validates the feasibility of representing B-rep as holistic token sequences, opening new directions for B-rep generation.</p>"
    },
    {
      "id": "eb88b956453b",
      "title": "WarrantScore: Modeling Warrants between Claims and Evidence for Substantiation Evaluation in Peer Reviews",
      "content": "arXiv:2601.17377v1 Announce Type: new  Abstract: The scientific peer-review process is facing a shortage of human resources due to the rapid growth in the number of submitted papers. The use of language models to reduce the human cost of peer review has been actively explored as a potential solution to this challenge. A method has been proposed to evaluate the level of substantiation in scientific reviews in a manner that is interpretable by humans. This method extracts the core components of an argument, claims and evidence, and assesses the level of substantiation based on the proportion of claims supported by evidence. The level of substantiation refers to the extent to which claims are based on objective facts. However, when assessing the level of substantiation, simply detecting the presence or absence of supporting evidence for a claim is insufficient; it is also necessary to accurately assess the logical inference between a claim and its evidence. We propose a new evaluation metric for scientific review comments that assesses the logical inference between claims and evidence. Experimental results show that the proposed method achieves a higher correlation with human scores than conventional methods, indicating its potential to better support the efficiency of the peer-review process.",
      "url": "http://arxiv.org/abs/2601.17377",
      "author": "Kiyotada Mori, Shohei Tanaka, Tosho Hirasawa, Tadashi Kozuno, Koichiro Yoshino, Yoshitaka Ushiku",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes WarrantScore for evaluating substantiation in peer reviews by modeling warrants (logical connections) between claims and evidence, going beyond simple claim-evidence detection.",
      "importance_score": 52,
      "reasoning": "Niche application to scientific peer review. Useful refinement but limited broader impact.",
      "themes": [
        "Scientific NLP",
        "Argumentation Mining",
        "Peer Review"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes WarrantScore for evaluating substantiation in peer reviews by modeling warrants (logical connections) between claims and evidence, going beyond simple claim-evidence detection.</p>",
      "content_html": "<p>arXiv:2601.17377v1 Announce Type: new  Abstract: The scientific peer-review process is facing a shortage of human resources due to the rapid growth in the number of submitted papers. The use of language models to reduce the human cost of peer review has been actively explored as a potential solution to this challenge. A method has been proposed to evaluate the level of substantiation in scientific reviews in a manner that is interpretable by humans. This method extracts the core components of an argument, claims and evidence, and assesses the level of substantiation based on the proportion of claims supported by evidence. The level of substantiation refers to the extent to which claims are based on objective facts. However, when assessing the level of substantiation, simply detecting the presence or absence of supporting evidence for a claim is insufficient; it is also necessary to accurately assess the logical inference between a claim and its evidence. We propose a new evaluation metric for scientific review comments that assesses the logical inference between claims and evidence. Experimental results show that the proposed method achieves a higher correlation with human scores than conventional methods, indicating its potential to better support the efficiency of the peer-review process.</p>"
    },
    {
      "id": "5ddae39f96ff",
      "title": "Unsupervised Text Segmentation via Kernel Change-Point Detection on Sentence Embeddings",
      "content": "arXiv:2601.18788v1 Announce Type: new  Abstract: Unsupervised text segmentation is crucial because boundary labels are expensive, subjective, and often fail to transfer across domains and granularity choices. We propose Embed-KCPD, a training-free method that represents sentences as embedding vectors and estimates boundaries by minimizing a penalized KCPD objective. Beyond the algorithmic instantiation, we develop, to our knowledge, the first dependence-aware theory for KCPD under $m$-dependent sequences, a finite-memory abstraction of short-range dependence common in language. We prove an oracle inequality for the population penalized risk and a localization guarantee showing that each true change point is recovered within a window that is small relative to segment length. To connect theory to practice, we introduce an LLM-based simulation framework that generates synthetic documents with controlled finite-memory dependence and known boundaries, validating the predicted scaling behavior. Across standard segmentation benchmarks, Embed-KCPD often outperforms strong unsupervised baselines. A case study on Taylor Swift's tweets illustrates that Embed-KCPD combines strong theoretical guarantees, simulated reliability, and practical effectiveness for text segmentation.",
      "url": "http://arxiv.org/abs/2601.18788",
      "author": "Mumin Jia, Jairo Diaz-Rodriguez",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces Embed-KCPD, a training-free text segmentation method using sentence embeddings and kernel change-point detection. Provides first dependence-aware theoretical guarantees for KCPD under finite-memory sequences common in language.",
      "importance_score": 52,
      "reasoning": "Solid theoretical contribution for text segmentation, but relatively niche application area with limited broader impact.",
      "themes": [
        "NLP",
        "Text Segmentation",
        "Theoretical ML"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Embed-KCPD, a training-free text segmentation method using sentence embeddings and kernel change-point detection. Provides first dependence-aware theoretical guarantees for KCPD under finite-memory sequences common in language.</p>",
      "content_html": "<p>arXiv:2601.18788v1 Announce Type: new  Abstract: Unsupervised text segmentation is crucial because boundary labels are expensive, subjective, and often fail to transfer across domains and granularity choices. We propose Embed-KCPD, a training-free method that represents sentences as embedding vectors and estimates boundaries by minimizing a penalized KCPD objective. Beyond the algorithmic instantiation, we develop, to our knowledge, the first dependence-aware theory for KCPD under $m$-dependent sequences, a finite-memory abstraction of short-range dependence common in language. We prove an oracle inequality for the population penalized risk and a localization guarantee showing that each true change point is recovered within a window that is small relative to segment length. To connect theory to practice, we introduce an LLM-based simulation framework that generates synthetic documents with controlled finite-memory dependence and known boundaries, validating the predicted scaling behavior. Across standard segmentation benchmarks, Embed-KCPD often outperforms strong unsupervised baselines. A case study on Taylor Swift's tweets illustrates that Embed-KCPD combines strong theoretical guarantees, simulated reliability, and practical effectiveness for text segmentation.</p>"
    },
    {
      "id": "8b75e5460f1c",
      "title": "LegalMALR:Multi-Agent Query Understanding and LLM-Based Reranking for Chinese Statute Retrieval",
      "content": "arXiv:2601.17692v1 Announce Type: cross  Abstract: Statute retrieval is essential for legal assistance and judicial decision support, yet real-world legal queries are often implicit, multi-issue, and expressed in colloquial or underspecified forms. These characteristics make it difficult for conventional retrieval-augmented generation pipelines to recover the statutory elements required for accurate retrieval. Dense retrievers focus primarily on the literal surface form of the query, whereas lightweight rerankers lack the legal-reasoning capacity needed to assess statutory applicability. We present LegalMALR, a retrieval framework that integrates a Multi-Agent Query Understanding System (MAS) with a zero-shot large-language-model-based reranking module (LLM Reranker). MAS generates diverse, legally grounded reformulations and conducts iterative dense retrieval to broaden candidate coverage. To stabilise the stochastic behaviour of LLM-generated rewrites, we optimise a unified MAS policy using Generalized Reinforcement Policy Optimization(GRPO). The accumulated candidate set is subsequently evaluated by the LLM Reranker, which performs natural-language legal reasoning to produce the final ranking. We further construct CSAID, a dataset of 118 difficult Chinese legal queries annotated with multiple statutory labels, and evaluate LegalMALR on both CSAID and the public STARD benchmark. Experiments show that LegalMALR substantially outperforms strong Retrieval-augmented generation(RAG) baselines in both in-distribution and out-of-distribution settings, demonstrating the effectiveness of combining multi-perspective query interpretation, reinforcement-based policy optimisation, and large-model reranking for statute retrieval.",
      "url": "http://arxiv.org/abs/2601.17692",
      "author": "Yunhan Li, Mingjie Xie, Gaoli Kang, Zihan Gong, Gengshen Wu, Min Yang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.IR"
      ],
      "summary": "Introduces LegalMALR, a retrieval framework combining multi-agent query understanding with LLM-based reranking for Chinese statute retrieval, addressing implicit, multi-issue legal queries.",
      "importance_score": 52,
      "reasoning": "Practical legal AI application with multi-agent approach. Domain-specific contribution with limited broader applicability.",
      "themes": [
        "Legal AI",
        "Multi-agent Systems",
        "Information Retrieval"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces LegalMALR, a retrieval framework combining multi-agent query understanding with LLM-based reranking for Chinese statute retrieval, addressing implicit, multi-issue legal queries.</p>",
      "content_html": "<p>arXiv:2601.17692v1 Announce Type: cross  Abstract: Statute retrieval is essential for legal assistance and judicial decision support, yet real-world legal queries are often implicit, multi-issue, and expressed in colloquial or underspecified forms. These characteristics make it difficult for conventional retrieval-augmented generation pipelines to recover the statutory elements required for accurate retrieval. Dense retrievers focus primarily on the literal surface form of the query, whereas lightweight rerankers lack the legal-reasoning capacity needed to assess statutory applicability. We present LegalMALR, a retrieval framework that integrates a Multi-Agent Query Understanding System (MAS) with a zero-shot large-language-model-based reranking module (LLM Reranker). MAS generates diverse, legally grounded reformulations and conducts iterative dense retrieval to broaden candidate coverage. To stabilise the stochastic behaviour of LLM-generated rewrites, we optimise a unified MAS policy using Generalized Reinforcement Policy Optimization(GRPO). The accumulated candidate set is subsequently evaluated by the LLM Reranker, which performs natural-language legal reasoning to produce the final ranking. We further construct CSAID, a dataset of 118 difficult Chinese legal queries annotated with multiple statutory labels, and evaluate LegalMALR on both CSAID and the public STARD benchmark. Experiments show that LegalMALR substantially outperforms strong Retrieval-augmented generation(RAG) baselines in both in-distribution and out-of-distribution settings, demonstrating the effectiveness of combining multi-perspective query interpretation, reinforcement-based policy optimisation, and large-model reranking for statute retrieval.</p>"
    },
    {
      "id": "6377b971b901",
      "title": "Superpixel-Based Image Segmentation Using Squared 2-Wasserstein Distances",
      "content": "arXiv:2601.17071v1 Announce Type: new  Abstract: We present an efficient method for image segmentation in the presence of strong inhomogeneities. The approach can be interpreted as a two-level clustering procedure: pixels are first grouped into superpixels via a linear least-squares assignment problem, which can be viewed as a special case of a discrete optimal transport (OT) problem, and these superpixels are subsequently greedily merged into object-level segments using the squared 2-Wasserstein distance between their empirical distributions. In contrast to conventional superpixel merging strategies based on mean-color distances, our framework employs a distributional OT distance, yielding a mathematically unified formulation across both clustering levels. Numerical experiments demonstrate that this perspective leads to improved segmentation accuracy on challenging images while retaining high computational efficiency.",
      "url": "http://arxiv.org/abs/2601.17071",
      "author": "Jisui Huang, Andreas Alpers, Ke Chen, Na Lei",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes image segmentation method using squared 2-Wasserstein distances, combining superpixel generation via optimal transport with distributional distance-based merging for handling strong inhomogeneities.",
      "importance_score": 52,
      "reasoning": "Mathematically principled approach to segmentation with solid theoretical grounding but incremental practical impact.",
      "themes": [
        "Image Segmentation",
        "Optimal Transport",
        "Computer Vision"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes image segmentation method using squared 2-Wasserstein distances, combining superpixel generation via optimal transport with distributional distance-based merging for handling strong inhomogeneities.</p>",
      "content_html": "<p>arXiv:2601.17071v1 Announce Type: new  Abstract: We present an efficient method for image segmentation in the presence of strong inhomogeneities. The approach can be interpreted as a two-level clustering procedure: pixels are first grouped into superpixels via a linear least-squares assignment problem, which can be viewed as a special case of a discrete optimal transport (OT) problem, and these superpixels are subsequently greedily merged into object-level segments using the squared 2-Wasserstein distance between their empirical distributions. In contrast to conventional superpixel merging strategies based on mean-color distances, our framework employs a distributional OT distance, yielding a mathematically unified formulation across both clustering levels. Numerical experiments demonstrate that this perspective leads to improved segmentation accuracy on challenging images while retaining high computational efficiency.</p>"
    },
    {
      "id": "d2d752410aaa",
      "title": "StealthMark: Harmless and Stealthy Ownership Verification for Medical Segmentation via Uncertainty-Guided Backdoors",
      "content": "arXiv:2601.17107v1 Announce Type: new  Abstract: Annotating medical data for training AI models is often costly and limited due to the shortage of specialists with relevant clinical expertise. This challenge is further compounded by privacy and ethical concerns associated with sensitive patient information. As a result, well-trained medical segmentation models on private datasets constitute valuable intellectual property requiring robust protection mechanisms. Existing model protection techniques primarily focus on classification and generative tasks, while segmentation models-crucial to medical image analysis-remain largely underexplored. In this paper, we propose a novel, stealthy, and harmless method, StealthMark, for verifying the ownership of medical segmentation models under black-box conditions. Our approach subtly modulates model uncertainty without altering the final segmentation outputs, thereby preserving the model's performance. To enable ownership verification, we incorporate model-agnostic explanation methods, e.g. LIME, to extract feature attributions from the model outputs. Under specific triggering conditions, these explanations reveal a distinct and verifiable watermark. We further design the watermark as a QR code to facilitate robust and recognizable ownership claims. We conducted extensive experiments across four medical imaging datasets and five mainstream segmentation models. The results demonstrate the effectiveness, stealthiness, and harmlessness of our method on the original model's segmentation performance. For example, when applied to the SAM model, StealthMark consistently achieved ASR above 95% across various datasets while maintaining less than a 1% drop in Dice and AUC scores, significantly outperforming backdoor-based watermarking methods and highlighting its strong potential for practical deployment. Our implementation code is made available at: https://github.com/Qinkaiyu/StealthMark.",
      "url": "http://arxiv.org/abs/2601.17107",
      "author": "Qinkai Yu, Chong Zhang, Gaojie Jin, Tianjin Huang, Wei Zhou, Wenhui Li, Xiaobo Jin, Bo Huang, Yitian Zhao, Guang Yang, Gregory Y. H. Lip, Yalin Zheng, Aline Villavicencio, Yanda Meng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes StealthMark for verifying ownership of medical segmentation models using uncertainty-guided backdoors that are harmless and stealthy under black-box access.",
      "importance_score": 52,
      "reasoning": "Addresses important IP protection problem for medical AI models with novel approach.",
      "themes": [
        "Model Protection",
        "Medical AI",
        "Security"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes StealthMark for verifying ownership of medical segmentation models using uncertainty-guided backdoors that are harmless and stealthy under black-box access.</p>",
      "content_html": "<p>arXiv:2601.17107v1 Announce Type: new  Abstract: Annotating medical data for training AI models is often costly and limited due to the shortage of specialists with relevant clinical expertise. This challenge is further compounded by privacy and ethical concerns associated with sensitive patient information. As a result, well-trained medical segmentation models on private datasets constitute valuable intellectual property requiring robust protection mechanisms. Existing model protection techniques primarily focus on classification and generative tasks, while segmentation models-crucial to medical image analysis-remain largely underexplored. In this paper, we propose a novel, stealthy, and harmless method, StealthMark, for verifying the ownership of medical segmentation models under black-box conditions. Our approach subtly modulates model uncertainty without altering the final segmentation outputs, thereby preserving the model's performance. To enable ownership verification, we incorporate model-agnostic explanation methods, e.g. LIME, to extract feature attributions from the model outputs. Under specific triggering conditions, these explanations reveal a distinct and verifiable watermark. We further design the watermark as a QR code to facilitate robust and recognizable ownership claims. We conducted extensive experiments across four medical imaging datasets and five mainstream segmentation models. The results demonstrate the effectiveness, stealthiness, and harmlessness of our method on the original model's segmentation performance. For example, when applied to the SAM model, StealthMark consistently achieved ASR above 95% across various datasets while maintaining less than a 1% drop in Dice and AUC scores, significantly outperforming backdoor-based watermarking methods and highlighting its strong potential for practical deployment. Our implementation code is made available at: https://github.com/Qinkaiyu/StealthMark.</p>"
    },
    {
      "id": "9a977e83b959",
      "title": "LGDWT-GS: Local and Global Discrete Wavelet-Regularized 3D Gaussian Splatting for Sparse-View Scene Reconstruction",
      "content": "arXiv:2601.17185v1 Announce Type: new  Abstract: We propose a new method for few-shot 3D reconstruction that integrates global and local frequency regularization to stabilize geometry and preserve fine details under sparse-view conditions, addressing a key limitation of existing 3D Gaussian Splatting (3DGS) models. We also introduce a new multispectral greenhouse dataset containing four spectral bands captured from diverse plant species under controlled conditions. Alongside the dataset, we release an open-source benchmarking package that defines standardized few-shot reconstruction protocols for evaluating 3DGS-based methods. Experiments on our multispectral dataset, as well as standard benchmarks, demonstrate that the proposed method achieves sharper, more stable, and spectrally consistent reconstructions than existing baselines. The dataset and code for this work are publicly available",
      "url": "http://arxiv.org/abs/2601.17185",
      "author": "Shima Salehi, Atharva Agashe, Andrew J. McFarland, Joshua Peeples",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes LGDWT-GS for few-shot 3D reconstruction integrating global and local frequency regularization via discrete wavelet transforms. Introduces new multispectral greenhouse dataset.",
      "importance_score": 52,
      "reasoning": "Solid 3DGS improvement with novel dataset contribution but incremental methodological advance.",
      "themes": [
        "3D Reconstruction",
        "Few-shot Learning",
        "Dataset"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes LGDWT-GS for few-shot 3D reconstruction integrating global and local frequency regularization via discrete wavelet transforms. Introduces new multispectral greenhouse dataset.</p>",
      "content_html": "<p>arXiv:2601.17185v1 Announce Type: new  Abstract: We propose a new method for few-shot 3D reconstruction that integrates global and local frequency regularization to stabilize geometry and preserve fine details under sparse-view conditions, addressing a key limitation of existing 3D Gaussian Splatting (3DGS) models. We also introduce a new multispectral greenhouse dataset containing four spectral bands captured from diverse plant species under controlled conditions. Alongside the dataset, we release an open-source benchmarking package that defines standardized few-shot reconstruction protocols for evaluating 3DGS-based methods. Experiments on our multispectral dataset, as well as standard benchmarks, demonstrate that the proposed method achieves sharper, more stable, and spectrally consistent reconstructions than existing baselines. The dataset and code for this work are publicly available</p>"
    },
    {
      "id": "a4c6d84f6f1c",
      "title": "Cross360: 360{\\deg} Monocular Depth Estimation via Cross Projections Across Scales",
      "content": "arXiv:2601.17271v1 Announce Type: new  Abstract: 360{\\deg} depth estimation is a challenging research problem due to the difficulty of finding a representation that both preserves global continuity and avoids distortion in spherical images. Existing methods attempt to leverage complementary information from multiple projections, but struggle with balancing global and local consistency. Their local patch features have limited global perception, and the combined global representation does not address discrepancies in feature extraction at the boundaries between patches. To address these issues, we propose Cross360, a novel cross-attention-based architecture integrating local and global information using less-distorted tangent patches along with equirectangular features. Our Cross Projection Feature Alignment module employs cross-attention to align local tangent projection features with the equirectangular projection's 360{\\deg} field of view, ensuring each tangent projection patch is aware of the global context. Additionally, our Progressive Feature Aggregation with Attention module refines multi-scaled features progressively, enhancing depth estimation accuracy. Cross360 significantly outperforms existing methods across most benchmark datasets, especially those in which the entire 360{\\deg} image is available, demonstrating its effectiveness in accurate and globally consistent depth estimation. The code and model are available at https://github.com/huangkun101230/Cross360.",
      "url": "http://arxiv.org/abs/2601.17271",
      "author": "Kun Huang, Fang-Lue Zhang, Neil Dodgson",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes Cross360 for 360 depth estimation using cross-attention to integrate less-distorted tangent patches with equirectangular features, addressing global-local consistency.",
      "importance_score": 52,
      "reasoning": "Addresses known challenges in 360 depth estimation with reasonable approach.",
      "themes": [
        "Depth Estimation",
        "360 Vision",
        "Computer Vision"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Cross360 for 360 depth estimation using cross-attention to integrate less-distorted tangent patches with equirectangular features, addressing global-local consistency.</p>",
      "content_html": "<p>arXiv:2601.17271v1 Announce Type: new  Abstract: 360{\\deg} depth estimation is a challenging research problem due to the difficulty of finding a representation that both preserves global continuity and avoids distortion in spherical images. Existing methods attempt to leverage complementary information from multiple projections, but struggle with balancing global and local consistency. Their local patch features have limited global perception, and the combined global representation does not address discrepancies in feature extraction at the boundaries between patches. To address these issues, we propose Cross360, a novel cross-attention-based architecture integrating local and global information using less-distorted tangent patches along with equirectangular features. Our Cross Projection Feature Alignment module employs cross-attention to align local tangent projection features with the equirectangular projection's 360{\\deg} field of view, ensuring each tangent projection patch is aware of the global context. Additionally, our Progressive Feature Aggregation with Attention module refines multi-scaled features progressively, enhancing depth estimation accuracy. Cross360 significantly outperforms existing methods across most benchmark datasets, especially those in which the entire 360{\\deg} image is available, demonstrating its effectiveness in accurate and globally consistent depth estimation. The code and model are available at https://github.com/huangkun101230/Cross360.</p>"
    },
    {
      "id": "2644b919baa6",
      "title": "AGE-Net: Spectral--Spatial Fusion and Anatomical Graph Reasoning with Evidential Ordinal Regression for Knee Osteoarthritis Grading",
      "content": "arXiv:2601.17336v1 Announce Type: new  Abstract: Automated Kellgren--Lawrence (KL) grading from knee radiographs is challenging due to subtle structural changes, long-range anatomical dependencies, and ambiguity near grade boundaries. We propose AGE-Net, a ConvNeXt-based framework that integrates Spectral--Spatial Fusion (SSF), Anatomical Graph Reasoning (AGR), and Differential Refinement (DFR). To capture predictive uncertainty and preserve label ordinality, AGE-Net employs a Normal-Inverse-Gamma (NIG) evidential regression head and a pairwise ordinal ranking constraint. On a knee KL dataset, AGE-Net achieves a quadratic weighted kappa (QWK) of 0.9017 +/- 0.0045 and a mean squared error (MSE) of 0.2349 +/- 0.0028 over three random seeds, outperforming strong CNN baselines and showing consistent gains in ablation studies. We further outline evaluations of uncertainty quality, robustness, and explainability, with additional experimental figures to be included in the full manuscript.",
      "url": "http://arxiv.org/abs/2601.17336",
      "author": "Xiaoyang Li, Runni Zhou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes AGE-Net for knee osteoarthritis KL grading combining spectral-spatial fusion, anatomical graph reasoning, and evidential ordinal regression for uncertainty-aware predictions.",
      "importance_score": 52,
      "reasoning": "Solid medical imaging work with uncertainty quantification but limited novelty in individual components.",
      "themes": [
        "Medical Image Analysis",
        "Osteoarthritis",
        "Uncertainty Quantification"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes AGE-Net for knee osteoarthritis KL grading combining spectral-spatial fusion, anatomical graph reasoning, and evidential ordinal regression for uncertainty-aware predictions.</p>",
      "content_html": "<p>arXiv:2601.17336v1 Announce Type: new  Abstract: Automated Kellgren--Lawrence (KL) grading from knee radiographs is challenging due to subtle structural changes, long-range anatomical dependencies, and ambiguity near grade boundaries. We propose AGE-Net, a ConvNeXt-based framework that integrates Spectral--Spatial Fusion (SSF), Anatomical Graph Reasoning (AGR), and Differential Refinement (DFR). To capture predictive uncertainty and preserve label ordinality, AGE-Net employs a Normal-Inverse-Gamma (NIG) evidential regression head and a pairwise ordinal ranking constraint. On a knee KL dataset, AGE-Net achieves a quadratic weighted kappa (QWK) of 0.9017 +/- 0.0045 and a mean squared error (MSE) of 0.2349 +/- 0.0028 over three random seeds, outperforming strong CNN baselines and showing consistent gains in ablation studies. We further outline evaluations of uncertainty quality, robustness, and explainability, with additional experimental figures to be included in the full manuscript.</p>"
    },
    {
      "id": "61568a60ea28",
      "title": "STARS: Shared-specific Translation and Alignment for missing-modality Remote Sensing Semantic Segmentation",
      "content": "arXiv:2601.17342v1 Announce Type: new  Abstract: Multimodal remote sensing technology significantly enhances the understanding of surface semantics by integrating heterogeneous data such as optical images, Synthetic Aperture Radar (SAR), and Digital Surface Models (DSM). However, in practical applications, the missing of modality data (e.g., optical or DSM) is a common and severe challenge, which leads to performance decline in traditional multimodal fusion models. Existing methods for addressing missing modalities still face limitations, including feature collapse and overly generalized recovered features. To address these issues, we propose \\textbf{STARS} (\\textbf{S}hared-specific \\textbf{T}ranslation and \\textbf{A}lignment for missing-modality \\textbf{R}emote \\textbf{S}ensing), a robust semantic segmentation framework for incomplete multimodal inputs. STARS is built on two key designs. First, we introduce an asymmetric alignment mechanism with bidirectional translation and stop-gradient, which effectively prevents feature collapse and reduces sensitivity to hyperparameters. Second, we propose a Pixel-level Semantic sampling Alignment (PSA) strategy that combines class-balanced pixel sampling with cross-modality semantic alignment loss, to mitigate alignment failures caused by severe class imbalance and improve minority-class recognition.",
      "url": "http://arxiv.org/abs/2601.17342",
      "author": "Tong Wang, Xiaodong Zhang, Guanzhou Chen, Jiaqi Wang, Chenxi Liu, Xiaoliang Tan, Wenchao Guo, Xuyang Li, Xuanrui Wang, Zifan Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes STARS for missing-modality remote sensing semantic segmentation using shared-specific translation and alignment to address feature collapse and overly generalized recovery.",
      "importance_score": 52,
      "reasoning": "Addresses practical challenge in multimodal remote sensing with reasonable approach.",
      "themes": [
        "Remote Sensing",
        "Missing Modality",
        "Semantic Segmentation"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes STARS for missing-modality remote sensing semantic segmentation using shared-specific translation and alignment to address feature collapse and overly generalized recovery.</p>",
      "content_html": "<p>arXiv:2601.17342v1 Announce Type: new  Abstract: Multimodal remote sensing technology significantly enhances the understanding of surface semantics by integrating heterogeneous data such as optical images, Synthetic Aperture Radar (SAR), and Digital Surface Models (DSM). However, in practical applications, the missing of modality data (e.g., optical or DSM) is a common and severe challenge, which leads to performance decline in traditional multimodal fusion models. Existing methods for addressing missing modalities still face limitations, including feature collapse and overly generalized recovered features. To address these issues, we propose \\textbf{STARS} (\\textbf{S}hared-specific \\textbf{T}ranslation and \\textbf{A}lignment for missing-modality \\textbf{R}emote \\textbf{S}ensing), a robust semantic segmentation framework for incomplete multimodal inputs. STARS is built on two key designs. First, we introduce an asymmetric alignment mechanism with bidirectional translation and stop-gradient, which effectively prevents feature collapse and reduces sensitivity to hyperparameters. Second, we propose a Pixel-level Semantic sampling Alignment (PSA) strategy that combines class-balanced pixel sampling with cross-modality semantic alignment loss, to mitigate alignment failures caused by severe class imbalance and improve minority-class recognition.</p>"
    },
    {
      "id": "02a387a212f3",
      "title": "Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity",
      "content": "arXiv:2601.17408v1 Announce Type: new  Abstract: Source-Free Domain Adaptation (SFDA) is an emerging area of research that aims to adapt a model trained on a labeled source domain to an unlabeled target domain without accessing the source data. Most of the successful methods in this area rely on the concept of neighborhood consistency but are prone to errors due to misleading neighborhood information. In this paper, we explore this approach from the point of view of learning more informative clusters and mitigating the effect of noisy neighbors using a concept called neighborhood signature, and demonstrate that adaptation can be achieved using just a single loss term tailored to optimize the similarity and dissimilarity of predictions of samples in the target domain. In particular, our proposed method outperforms existing methods in the challenging VisDA dataset while also yielding competitive results on other benchmark datasets.",
      "url": "http://arxiv.org/abs/2601.17408",
      "author": "Harsharaj Pathak, Vineeth N Balasubramanian",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes source-free domain adaptation via optimizing batch-wise cosine similarity using neighborhood signatures to mitigate noisy neighbor effects without source data access.",
      "importance_score": 52,
      "reasoning": "Simplified approach to SFDA with single loss term. Reasonable contribution to domain adaptation.",
      "themes": [
        "Domain Adaptation",
        "Transfer Learning",
        "Computer Vision"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes source-free domain adaptation via optimizing batch-wise cosine similarity using neighborhood signatures to mitigate noisy neighbor effects without source data access.</p>",
      "content_html": "<p>arXiv:2601.17408v1 Announce Type: new  Abstract: Source-Free Domain Adaptation (SFDA) is an emerging area of research that aims to adapt a model trained on a labeled source domain to an unlabeled target domain without accessing the source data. Most of the successful methods in this area rely on the concept of neighborhood consistency but are prone to errors due to misleading neighborhood information. In this paper, we explore this approach from the point of view of learning more informative clusters and mitigating the effect of noisy neighbors using a concept called neighborhood signature, and demonstrate that adaptation can be achieved using just a single loss term tailored to optimize the similarity and dissimilarity of predictions of samples in the target domain. In particular, our proposed method outperforms existing methods in the challenging VisDA dataset while also yielding competitive results on other benchmark datasets.</p>"
    },
    {
      "id": "645c1ed540d7",
      "title": "OTI: A Model-free and Visually Interpretable Measure of Image Attackability",
      "content": "arXiv:2601.17536v1 Announce Type: new  Abstract: Despite the tremendous success of neural networks, benign images can be corrupted by adversarial perturbations to deceive these models. Intriguingly, images differ in their attackability. Specifically, given an attack configuration, some images are easily corrupted, whereas others are more resistant. Evaluating image attackability has important applications in active learning, adversarial training, and attack enhancement. This prompts a growing interest in developing attackability measures. However, existing methods are scarce and suffer from two major limitations: (1) They rely on a model proxy to provide prior knowledge (e.g., gradients or minimal perturbation) to extract model-dependent image features. Unfortunately, in practice, many task-specific models are not readily accessible. (2) Extracted features characterizing image attackability lack visual interpretability, obscuring their direct relationship with the images. To address these, we propose a novel Object Texture Intensity (OTI), a model-free and visually interpretable measure of image attackability, which measures image attackability as the texture intensity of the image's semantic object. Theoretically, we describe the principles of OTI from the perspectives of decision boundaries as well as the mid- and high-frequency characteristics of adversarial perturbations. Comprehensive experiments demonstrate that OTI is effective and computationally efficient. In addition, our OTI provides the adversarial machine learning community with a visual understanding of attackability.",
      "url": "http://arxiv.org/abs/2601.17536",
      "author": "Jiaming Liang, Haowei Liu, Chi-Man Pun",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes OTI, a model-free visually interpretable measure of image attackability based on intrinsic image properties rather than model-dependent gradients or perturbations.",
      "importance_score": 52,
      "reasoning": "Novel approach to measuring adversarial vulnerability without model access. Useful for understanding attack susceptibility.",
      "themes": [
        "Adversarial ML",
        "Image Analysis",
        "Security"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes OTI, a model-free visually interpretable measure of image attackability based on intrinsic image properties rather than model-dependent gradients or perturbations.</p>",
      "content_html": "<p>arXiv:2601.17536v1 Announce Type: new  Abstract: Despite the tremendous success of neural networks, benign images can be corrupted by adversarial perturbations to deceive these models. Intriguingly, images differ in their attackability. Specifically, given an attack configuration, some images are easily corrupted, whereas others are more resistant. Evaluating image attackability has important applications in active learning, adversarial training, and attack enhancement. This prompts a growing interest in developing attackability measures. However, existing methods are scarce and suffer from two major limitations: (1) They rely on a model proxy to provide prior knowledge (e.g., gradients or minimal perturbation) to extract model-dependent image features. Unfortunately, in practice, many task-specific models are not readily accessible. (2) Extracted features characterizing image attackability lack visual interpretability, obscuring their direct relationship with the images. To address these, we propose a novel Object Texture Intensity (OTI), a model-free and visually interpretable measure of image attackability, which measures image attackability as the texture intensity of the image's semantic object. Theoretically, we describe the principles of OTI from the perspectives of decision boundaries as well as the mid- and high-frequency characteristics of adversarial perturbations. Comprehensive experiments demonstrate that OTI is effective and computationally efficient. In addition, our OTI provides the adversarial machine learning community with a visual understanding of attackability.</p>"
    },
    {
      "id": "6a703798d7d9",
      "title": "Advancing Structured Priors for Sparse-Voxel Surface Reconstruction",
      "content": "arXiv:2601.17720v1 Announce Type: new  Abstract: Reconstructing accurate surfaces with radiance fields has progressed rapidly, yet two promising explicit representations, 3D Gaussian Splatting and sparse-voxel rasterization, exhibit complementary strengths and weaknesses. 3D Gaussian Splatting converges quickly and carries useful geometric priors, but surface fidelity is limited by its point-like parameterization. Sparse-voxel rasterization provides continuous opacity fields and crisp geometry, but its typical uniform dense-grid initialization slows convergence and underutilizes scene structure. We combine the advantages of both by introducing a voxel initialization method that places voxels at plausible locations and with appropriate levels of detail, yielding a strong starting point for per-scene optimization. To further enhance depth consistency without blurring edges, we propose refined depth geometry supervision that converts multi-view cues into direct per-ray depth regularization. Experiments on standard benchmarks demonstrate improvements over prior methods in geometric accuracy, better fine-structure recovery, and more complete surfaces, while maintaining fast convergence.",
      "url": "http://arxiv.org/abs/2601.17720",
      "author": "Ting-Hsun Chi, Chu-Rong Chen, Chi-Tun Hsu, Hsuan-Ting Lin, Sheng-Yu Huang, Cheng Sun, Yu-Chiang Frank Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Combines advantages of 3D Gaussian Splatting and sparse-voxel rasterization by introducing a voxel initialization method that leverages Gaussian priors to place voxels at plausible locations with appropriate level of detail.",
      "importance_score": 52,
      "reasoning": "Practical combination of two popular 3D reconstruction methods. Addresses known limitations but incremental contribution.",
      "themes": [
        "3D Reconstruction",
        "Gaussian Splatting",
        "Neural Rendering"
      ],
      "continuation": null,
      "summary_html": "<p>Combines advantages of 3D Gaussian Splatting and sparse-voxel rasterization by introducing a voxel initialization method that leverages Gaussian priors to place voxels at plausible locations with appropriate level of detail.</p>",
      "content_html": "<p>arXiv:2601.17720v1 Announce Type: new  Abstract: Reconstructing accurate surfaces with radiance fields has progressed rapidly, yet two promising explicit representations, 3D Gaussian Splatting and sparse-voxel rasterization, exhibit complementary strengths and weaknesses. 3D Gaussian Splatting converges quickly and carries useful geometric priors, but surface fidelity is limited by its point-like parameterization. Sparse-voxel rasterization provides continuous opacity fields and crisp geometry, but its typical uniform dense-grid initialization slows convergence and underutilizes scene structure. We combine the advantages of both by introducing a voxel initialization method that places voxels at plausible locations and with appropriate levels of detail, yielding a strong starting point for per-scene optimization. To further enhance depth consistency without blurring edges, we propose refined depth geometry supervision that converts multi-view cues into direct per-ray depth regularization. Experiments on standard benchmarks demonstrate improvements over prior methods in geometric accuracy, better fine-structure recovery, and more complete surfaces, while maintaining fast convergence.</p>"
    },
    {
      "id": "8820e8883e49",
      "title": "Bridging Supervision Gaps: A Unified Framework for Remote Sensing Change Detection",
      "content": "arXiv:2601.17747v1 Announce Type: new  Abstract: Change detection (CD) aims to identify surface changes from multi-temporal remote sensing imagery. In real-world scenarios, Pixel-level change labels are expensive to acquire, and existing models struggle to adapt to scenarios with diverse annotation availability. To tackle this challenge, we propose a unified change detection framework (UniCD), which collaboratively handles supervised, weakly-supervised, and unsupervised tasks through a coupled architecture. UniCD eliminates architectural barriers through a shared encoder and multi-branch collaborative learning mechanism, achieving deep coupling of heterogeneous supervision signals. Specifically, UniCD consists of three supervision-specific branches. In the supervision branch, UniCD introduces the spatial-temporal awareness module (STAM), achieving efficient synergistic fusion of bi-temporal features. In the weakly-supervised branch, we construct change representation regularization (CRR), which steers model convergence from coarse-grained activations toward coherent and separable change modeling. In the unsupervised branch, we propose semantic prior-driven change inference (SPCI), which transforms unsupervised tasks into controlled weakly-supervised path optimization. Experiments on mainstream datasets demonstrate that UniCD achieves optimal performance across three tasks. It exhibits significant accuracy improvements in weakly and unsupervised scenarios, surpassing current state-of-the-art by 12.72% and 12.37% on LEVIR-CD, respectively.",
      "url": "http://arxiv.org/abs/2601.17747",
      "author": "Kaixuan Jiang, Chen Wu, Zhenghui Zhao, Chengxi Han",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "UniCD is a unified change detection framework that handles supervised, weakly-supervised, and unsupervised tasks through a shared encoder and multi-branch collaborative learning mechanism for remote sensing imagery.",
      "importance_score": 52,
      "reasoning": "Practical framework addressing real-world annotation constraints in remote sensing. Good unified approach.",
      "themes": [
        "Remote Sensing",
        "Change Detection",
        "Multi-task Learning"
      ],
      "continuation": null,
      "summary_html": "<p>UniCD is a unified change detection framework that handles supervised, weakly-supervised, and unsupervised tasks through a shared encoder and multi-branch collaborative learning mechanism for remote sensing imagery.</p>",
      "content_html": "<p>arXiv:2601.17747v1 Announce Type: new  Abstract: Change detection (CD) aims to identify surface changes from multi-temporal remote sensing imagery. In real-world scenarios, Pixel-level change labels are expensive to acquire, and existing models struggle to adapt to scenarios with diverse annotation availability. To tackle this challenge, we propose a unified change detection framework (UniCD), which collaboratively handles supervised, weakly-supervised, and unsupervised tasks through a coupled architecture. UniCD eliminates architectural barriers through a shared encoder and multi-branch collaborative learning mechanism, achieving deep coupling of heterogeneous supervision signals. Specifically, UniCD consists of three supervision-specific branches. In the supervision branch, UniCD introduces the spatial-temporal awareness module (STAM), achieving efficient synergistic fusion of bi-temporal features. In the weakly-supervised branch, we construct change representation regularization (CRR), which steers model convergence from coarse-grained activations toward coherent and separable change modeling. In the unsupervised branch, we propose semantic prior-driven change inference (SPCI), which transforms unsupervised tasks into controlled weakly-supervised path optimization. Experiments on mainstream datasets demonstrate that UniCD achieves optimal performance across three tasks. It exhibits significant accuracy improvements in weakly and unsupervised scenarios, surpassing current state-of-the-art by 12.72% and 12.37% on LEVIR-CD, respectively.</p>"
    },
    {
      "id": "5dea5ed30b1c",
      "title": "Masked Depth Modeling for Spatial Perception",
      "content": "arXiv:2601.17895v1 Announce Type: new  Abstract: Spatial visual perception is a fundamental requirement in physical-world applications like autonomous driving and robotic manipulation, driven by the need to interact with 3D environments. Capturing pixel-aligned metric depth using RGB-D cameras would be the most viable way, yet it usually faces obstacles posed by hardware limitations and challenging imaging conditions, especially in the presence of specular or texture-less surfaces. In this work, we argue that the inaccuracies from depth sensors can be viewed as \"masked\" signals that inherently reflect underlying geometric ambiguities. Building on this motivation, we present LingBot-Depth, a depth completion model which leverages visual context to refine depth maps through masked depth modeling and incorporates an automated data curation pipeline for scalable training. It is encouraging to see that our model outperforms top-tier RGB-D cameras in terms of both depth precision and pixel coverage. Experimental results on a range of downstream tasks further suggest that LingBot-Depth offers an aligned latent representation across RGB and depth modalities. We release the code, checkpoint, and 3M RGB-depth pairs (including 2M real data and 1M simulated data) to the community of spatial perception.",
      "url": "http://arxiv.org/abs/2601.17895",
      "author": "Bin Tan, Changjiang Sun, Xiage Qin, Hanat Adai, Zelin Fu, Tianxiang Zhou, Han Zhang, Yinghao Xu, Xing Zhu, Yujun Shen, Nan Xue",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "LingBot-Depth treats depth sensor inaccuracies as 'masked' signals and uses masked depth modeling with visual context to refine depth maps, addressing geometric ambiguities from hardware limitations.",
      "importance_score": 52,
      "reasoning": "Practical approach to depth completion with nice conceptual framing of sensor errors as masking.",
      "themes": [
        "Depth Estimation",
        "Masked Modeling",
        "Robotics"
      ],
      "continuation": null,
      "summary_html": "<p>LingBot-Depth treats depth sensor inaccuracies as 'masked' signals and uses masked depth modeling with visual context to refine depth maps, addressing geometric ambiguities from hardware limitations.</p>",
      "content_html": "<p>arXiv:2601.17895v1 Announce Type: new  Abstract: Spatial visual perception is a fundamental requirement in physical-world applications like autonomous driving and robotic manipulation, driven by the need to interact with 3D environments. Capturing pixel-aligned metric depth using RGB-D cameras would be the most viable way, yet it usually faces obstacles posed by hardware limitations and challenging imaging conditions, especially in the presence of specular or texture-less surfaces. In this work, we argue that the inaccuracies from depth sensors can be viewed as \"masked\" signals that inherently reflect underlying geometric ambiguities. Building on this motivation, we present LingBot-Depth, a depth completion model which leverages visual context to refine depth maps through masked depth modeling and incorporates an automated data curation pipeline for scalable training. It is encouraging to see that our model outperforms top-tier RGB-D cameras in terms of both depth precision and pixel coverage. Experimental results on a range of downstream tasks further suggest that LingBot-Depth offers an aligned latent representation across RGB and depth modalities. We release the code, checkpoint, and 3M RGB-depth pairs (including 2M real data and 1M simulated data) to the community of spatial perception.</p>"
    },
    {
      "id": "f483b92a5049",
      "title": "UPLiFT: Efficient Pixel-Dense Feature Upsampling with Local Attenders",
      "content": "arXiv:2601.17950v1 Announce Type: new  Abstract: The space of task-agnostic feature upsampling has emerged as a promising area of research to efficiently create denser features from pre-trained visual backbones. These methods act as a shortcut to achieve dense features for a fraction of the cost by learning to map low-resolution features to high-resolution versions. While early works in this space used iterative upsampling approaches, more recent works have switched to cross-attention-based methods, which risk falling into the same efficiency scaling problems of the backbones they are upsampling. In this work, we demonstrate that iterative upsampling methods can still compete with cross-attention-based methods; moreover, they can achieve state-of-the-art performance with lower inference costs. We propose UPLiFT, an architecture for Universal Pixel-dense Lightweight Feature Transforms. We also propose an efficient Local Attender operator to overcome the limitations of prior iterative feature upsampling methods. This operator uses an alternative attentional pooling formulation defined fully locally. We show that our Local Attender allows UPLiFT to maintain stable features throughout upsampling, enabling state-of-the-art performance with lower inference costs than existing pixel-dense feature upsamplers. In addition, we apply UPLiFT to generative downstream tasks and show that it achieves competitive performance with state-of-the-art Coupled Flow Matching models for VAE feature upsampling. Altogether, UPLiFT offers a versatile and efficient approach to creating denser features.",
      "url": "http://arxiv.org/abs/2601.17950",
      "author": "Matthew Walmer, Saksham Suri, Anirud Aggarwal, Abhinav Shrivastava",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "UPLiFT demonstrates that iterative upsampling methods can achieve state-of-the-art dense feature upsampling with lower inference cost than cross-attention-based approaches, using local attenders.",
      "importance_score": 52,
      "reasoning": "Practical efficiency improvement for feature upsampling. Useful finding that simpler methods can compete.",
      "themes": [
        "Feature Upsampling",
        "Efficiency",
        "Vision Backbones"
      ],
      "continuation": null,
      "summary_html": "<p>UPLiFT demonstrates that iterative upsampling methods can achieve state-of-the-art dense feature upsampling with lower inference cost than cross-attention-based approaches, using local attenders.</p>",
      "content_html": "<p>arXiv:2601.17950v1 Announce Type: new  Abstract: The space of task-agnostic feature upsampling has emerged as a promising area of research to efficiently create denser features from pre-trained visual backbones. These methods act as a shortcut to achieve dense features for a fraction of the cost by learning to map low-resolution features to high-resolution versions. While early works in this space used iterative upsampling approaches, more recent works have switched to cross-attention-based methods, which risk falling into the same efficiency scaling problems of the backbones they are upsampling. In this work, we demonstrate that iterative upsampling methods can still compete with cross-attention-based methods; moreover, they can achieve state-of-the-art performance with lower inference costs. We propose UPLiFT, an architecture for Universal Pixel-dense Lightweight Feature Transforms. We also propose an efficient Local Attender operator to overcome the limitations of prior iterative feature upsampling methods. This operator uses an alternative attentional pooling formulation defined fully locally. We show that our Local Attender allows UPLiFT to maintain stable features throughout upsampling, enabling state-of-the-art performance with lower inference costs than existing pixel-dense feature upsamplers. In addition, we apply UPLiFT to generative downstream tasks and show that it achieves competitive performance with state-of-the-art Coupled Flow Matching models for VAE feature upsampling. Altogether, UPLiFT offers a versatile and efficient approach to creating denser features.</p>"
    },
    {
      "id": "9f9dfea3ec9c",
      "title": "Spatial-Conditioned Reasoning in Long-Egocentric Videos",
      "content": "arXiv:2601.18100v1 Announce Type: new  Abstract: Long-horizon egocentric video presents significant challenges for visual navigation due to viewpoint drift and the absence of persistent geometric context. Although recent vision-language models perform well on image and short-video reasoning, their spatial reasoning capability in long egocentric sequences remains limited. In this work, we study how explicit spatial signals influence VLM-based video understanding without modifying model architectures or inference procedures. We introduce Sanpo-D, a fine-grained re-annotation of the Google Sanpo dataset, and benchmark multiple VLMs on navigation-oriented spatial queries. To examine input-level inductive bias, we further fuse depth maps with RGB frames and evaluate their impact on spatial reasoning. Our results reveal a trade-off between general-purpose accuracy and spatial specialization, showing that depth-aware and spatially grounded representations can improve performance on safety-critical tasks such as pedestrian and obstruction detection.",
      "url": "http://arxiv.org/abs/2601.18100",
      "author": "James Tribble, Hao Wang, Si-En Hong, Chaoyi Zhou, Ashish Bastola, Siyu Huang, Abolfazl Razi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Studies how explicit spatial signals influence VLM-based video understanding in long egocentric sequences, introducing Sanpo-D dataset and evaluating depth fusion impact on spatial reasoning.",
      "importance_score": 52,
      "reasoning": "Addresses important limitation of VLMs in spatial reasoning. New dataset and evaluation protocol contribution.",
      "themes": [
        "Vision-Language Models",
        "Spatial Reasoning",
        "Egocentric Vision"
      ],
      "continuation": null,
      "summary_html": "<p>Studies how explicit spatial signals influence VLM-based video understanding in long egocentric sequences, introducing Sanpo-D dataset and evaluating depth fusion impact on spatial reasoning.</p>",
      "content_html": "<p>arXiv:2601.18100v1 Announce Type: new  Abstract: Long-horizon egocentric video presents significant challenges for visual navigation due to viewpoint drift and the absence of persistent geometric context. Although recent vision-language models perform well on image and short-video reasoning, their spatial reasoning capability in long egocentric sequences remains limited. In this work, we study how explicit spatial signals influence VLM-based video understanding without modifying model architectures or inference procedures. We introduce Sanpo-D, a fine-grained re-annotation of the Google Sanpo dataset, and benchmark multiple VLMs on navigation-oriented spatial queries. To examine input-level inductive bias, we further fuse depth maps with RGB frames and evaluate their impact on spatial reasoning. Our results reveal a trade-off between general-purpose accuracy and spatial specialization, showing that depth-aware and spatially grounded representations can improve performance on safety-critical tasks such as pedestrian and obstruction detection.</p>"
    },
    {
      "id": "4c00e7f02512",
      "title": "QualiRAG: Retrieval-Augmented Generation for Visual Quality Understanding",
      "content": "arXiv:2601.18195v1 Announce Type: new  Abstract: Visual quality assessment (VQA) is increasingly shifting from scalar score prediction toward interpretable quality understanding -- a paradigm that demands \\textit{fine-grained spatiotemporal perception} and \\textit{auxiliary contextual information}. Current approaches rely on supervised fine-tuning or reinforcement learning on curated instruction datasets, which involve labor-intensive annotation and are prone to dataset-specific biases. To address these challenges, we propose \\textbf{QualiRAG}, a \\textit{training-free} \\textbf{R}etrieval-\\textbf{A}ugmented \\textbf{G}eneration \\textbf{(RAG)} framework that systematically leverages the latent perceptual knowledge of large multimodal models (LMMs) for visual quality perception. Unlike conventional RAG that retrieves from static corpora, QualiRAG dynamically generates auxiliary knowledge by decomposing questions into structured requests and constructing four complementary knowledge sources: \\textit{visual metadata}, \\textit{subject localization}, \\textit{global quality summaries}, and \\textit{local quality descriptions}, followed by relevance-aware retrieval for evidence-grounded reasoning. Extensive experiments show that QualiRAG achieves substantial improvements over open-source general-purpose LMMs and VQA-finetuned LMMs on visual quality understanding tasks, and delivers competitive performance on visual quality comparison tasks, demonstrating robust quality assessment capabilities without any task-specific training. The code will be publicly available at https://github.com/clh124/QualiRAG.",
      "url": "http://arxiv.org/abs/2601.18195",
      "author": "Linhan Cao, Wei Sun, Weixia Zhang, Xiangyang Zhu, Kaiwei Zhang, Jun Jia, Dandan Zhu, Guangtao Zhai, Xiongkuo Min",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "QualiRAG introduces training-free RAG framework for visual quality assessment that leverages latent perceptual knowledge of multimodal models for fine-grained spatiotemporal quality understanding.",
      "importance_score": 52,
      "reasoning": "Novel application of RAG to visual quality. Training-free approach is practical.",
      "themes": [
        "Visual Quality Assessment",
        "RAG",
        "Vision-Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>QualiRAG introduces training-free RAG framework for visual quality assessment that leverages latent perceptual knowledge of multimodal models for fine-grained spatiotemporal quality understanding.</p>",
      "content_html": "<p>arXiv:2601.18195v1 Announce Type: new  Abstract: Visual quality assessment (VQA) is increasingly shifting from scalar score prediction toward interpretable quality understanding -- a paradigm that demands \\textit{fine-grained spatiotemporal perception} and \\textit{auxiliary contextual information}. Current approaches rely on supervised fine-tuning or reinforcement learning on curated instruction datasets, which involve labor-intensive annotation and are prone to dataset-specific biases. To address these challenges, we propose \\textbf{QualiRAG}, a \\textit{training-free} \\textbf{R}etrieval-\\textbf{A}ugmented \\textbf{G}eneration \\textbf{(RAG)} framework that systematically leverages the latent perceptual knowledge of large multimodal models (LMMs) for visual quality perception. Unlike conventional RAG that retrieves from static corpora, QualiRAG dynamically generates auxiliary knowledge by decomposing questions into structured requests and constructing four complementary knowledge sources: \\textit{visual metadata}, \\textit{subject localization}, \\textit{global quality summaries}, and \\textit{local quality descriptions}, followed by relevance-aware retrieval for evidence-grounded reasoning. Extensive experiments show that QualiRAG achieves substantial improvements over open-source general-purpose LMMs and VQA-finetuned LMMs on visual quality understanding tasks, and delivers competitive performance on visual quality comparison tasks, demonstrating robust quality assessment capabilities without any task-specific training. The code will be publicly available at https://github.com/clh124/QualiRAG.</p>"
    },
    {
      "id": "2f4ba55b8f33",
      "title": "Depth to Anatomy: Learning Internal Organ Locations from Surface Depth Images",
      "content": "arXiv:2601.18260v1 Announce Type: new  Abstract: Automated patient positioning plays an important role in optimizing scanning procedure and improving patient throughput. Leveraging depth information captured by RGB-D cameras presents a promising approach for estimating internal organ positions, thereby enabling more accurate and efficient positioning. In this work, we propose a learning-based framework that directly predicts the 3D locations and shapes of multiple internal organs from single 2D depth images of the body surface. Utilizing a large-scale dataset of full-body MRI scans, we synthesize depth images paired with corresponding anatomical segmentations to train a unified convolutional neural network architecture. Our method accurately localizes a diverse set of anatomical structures, including bones and soft tissues, without requiring explicit surface reconstruction. Experimental results demonstrate the potential of integrating depth sensors into radiology workflows to streamline scanning procedures and enhance patient experience through automated patient positioning.",
      "url": "http://arxiv.org/abs/2601.18260",
      "author": "Eytan Kats, Kai Geissler, Daniel Mensing, Jochen G. Hirsch, Stefan Heldman, Mattias P. Heinrich",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes learning framework to predict 3D locations and shapes of internal organs from single 2D depth images of body surface, trained on synthetic data from full-body MRI scans.",
      "importance_score": 52,
      "reasoning": "Practical medical application for patient positioning. Novel surface-to-internal mapping.",
      "themes": [
        "Medical Imaging",
        "Depth Estimation",
        "Patient Positioning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes learning framework to predict 3D locations and shapes of internal organs from single 2D depth images of body surface, trained on synthetic data from full-body MRI scans.</p>",
      "content_html": "<p>arXiv:2601.18260v1 Announce Type: new  Abstract: Automated patient positioning plays an important role in optimizing scanning procedure and improving patient throughput. Leveraging depth information captured by RGB-D cameras presents a promising approach for estimating internal organ positions, thereby enabling more accurate and efficient positioning. In this work, we propose a learning-based framework that directly predicts the 3D locations and shapes of multiple internal organs from single 2D depth images of the body surface. Utilizing a large-scale dataset of full-body MRI scans, we synthesize depth images paired with corresponding anatomical segmentations to train a unified convolutional neural network architecture. Our method accurately localizes a diverse set of anatomical structures, including bones and soft tissues, without requiring explicit surface reconstruction. Experimental results demonstrate the potential of integrating depth sensors into radiology workflows to streamline scanning procedures and enhance patient experience through automated patient positioning.</p>"
    },
    {
      "id": "b90f91719bd1",
      "title": "Larger than memory image processing",
      "content": "arXiv:2601.18407v1 Announce Type: new  Abstract: This report addresses larger-than-memory image analysis for petascale datasets such as 1.4 PB electron-microscopy volumes and 150 TB human-organ atlases. We argue that performance is fundamentally I/O-bound. We show that structuring analysis as streaming passes over data is crucial. For 3D volumes, two representations are popular: stacks of 2D slices (e.g., directories or multi-page TIFF) and 3D chunked layouts (e.g., Zarr/HDF5). While for a few algorithms, chunked layout on disk is crucial to keep disk I/O at a minimum, we show how the slice-based streaming architecture can be built on top of either image representation in a manner that minimizes disk I/O. This is in particular advantageous for algorithms relying on neighbouring values, since the slicing streaming architecture is 1D, which implies that there are only 2 possible sweeping orders, both of which are aligned with the order in which images are read from the disk. This is in contrast to 3D chunks, in which any sweep cannot be done without accessing each chunk at least 9 times. We formalize this with sweep-based execution (natural 2D/3D orders), windowed operations, and overlap-aware tiling to minimize redundant access. Building on these principles, we introduce a domain-specific language (DSL) that encodes algorithms with intrinsic knowledge of their optimal streaming and memory use; the DSL performs compile-time and run-time pipeline analyses to automatically select window sizes, fuse stages, tee and zip streams, and schedule passes for limited-RAM machines, yielding near-linear I/O scans and predictable memory footprints. The approach integrates with existing tooling for segmentation and morphology but reframes pre/post-processing as pipelines that privilege sequential read/write patterns, delivering substantial throughput gains for extremely large images without requiring full-volume residency in memory.",
      "url": "http://arxiv.org/abs/2601.18407",
      "author": "Jon Sporring, David Stansby",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Addresses larger-than-memory image analysis for petascale datasets, showing that performance is I/O-bound and proposing streaming architectures that work with both slice-based and chunked representations.",
      "importance_score": 52,
      "reasoning": "Practical systems contribution for large-scale imaging. Important infrastructure work.",
      "themes": [
        "Large-Scale Computing",
        "Medical Imaging",
        "Systems"
      ],
      "continuation": null,
      "summary_html": "<p>Addresses larger-than-memory image analysis for petascale datasets, showing that performance is I/O-bound and proposing streaming architectures that work with both slice-based and chunked representations.</p>",
      "content_html": "<p>arXiv:2601.18407v1 Announce Type: new  Abstract: This report addresses larger-than-memory image analysis for petascale datasets such as 1.4 PB electron-microscopy volumes and 150 TB human-organ atlases. We argue that performance is fundamentally I/O-bound. We show that structuring analysis as streaming passes over data is crucial. For 3D volumes, two representations are popular: stacks of 2D slices (e.g., directories or multi-page TIFF) and 3D chunked layouts (e.g., Zarr/HDF5). While for a few algorithms, chunked layout on disk is crucial to keep disk I/O at a minimum, we show how the slice-based streaming architecture can be built on top of either image representation in a manner that minimizes disk I/O. This is in particular advantageous for algorithms relying on neighbouring values, since the slicing streaming architecture is 1D, which implies that there are only 2 possible sweeping orders, both of which are aligned with the order in which images are read from the disk. This is in contrast to 3D chunks, in which any sweep cannot be done without accessing each chunk at least 9 times. We formalize this with sweep-based execution (natural 2D/3D orders), windowed operations, and overlap-aware tiling to minimize redundant access. Building on these principles, we introduce a domain-specific language (DSL) that encodes algorithms with intrinsic knowledge of their optimal streaming and memory use; the DSL performs compile-time and run-time pipeline analyses to automatically select window sizes, fuse stages, tee and zip streams, and schedule passes for limited-RAM machines, yielding near-linear I/O scans and predictable memory footprints. The approach integrates with existing tooling for segmentation and morphology but reframes pre/post-processing as pipelines that privilege sequential read/write patterns, delivering substantial throughput gains for extremely large images without requiring full-volume residency in memory.</p>"
    },
    {
      "id": "dfa84ed8896e",
      "title": "From Cold Start to Active Learning: Embedding-Based Scan Selection for Medical Image Segmentation",
      "content": "arXiv:2601.18532v1 Announce Type: new  Abstract: Accurate segmentation annotations are critical for disease monitoring, yet manual labeling remains a major bottleneck due to the time and expertise required. Active learning (AL) alleviates this burden by prioritizing informative samples for annotation, typically through a diversity-based cold-start phase followed by uncertainty-driven selection. We propose a novel cold-start sampling strategy that combines foundation-model embeddings with clustering, including automatic selection of the number of clusters and proportional sampling across clusters, to construct a diverse and representative initial training. This is followed by an uncertainty-based AL framework that integrates spatial diversity to guide sample selection. The proposed method is intuitive and interpretable, enabling visualization of the feature-space distribution of candidate samples. We evaluate our approach on three datasets spanning X-ray and MRI modalities. On the CheXmask dataset, the cold-start strategy outperforms random selection, improving Dice from 0.918 to 0.929 and reducing the Hausdorff distance from 32.41 to 27.66 mm. In the AL setting, combined entropy and diversity selection improves Dice from 0.919 to 0.939 and reduces the Hausdorff distance from 30.10 to 19.16 mm. On the Montgomery dataset, cold-start gains are substantial, with Dice improving from 0.928 to 0.950 and Hausdorff distance decreasing from 14.22 to 9.38 mm. On the SynthStrip dataset, cold-start selection slightly affects Dice but reduces the Hausdorff distance from 9.43 to 8.69 mm, while active learning improves Dice from 0.816 to 0.826 and reduces the Hausdorff distance from 7.76 to 6.38 mm. Overall, the proposed framework consistently outperforms baseline methods in low-data regimes, improving segmentation accuracy.",
      "url": "http://arxiv.org/abs/2601.18532",
      "author": "Devon Levy, Bar Assayag, Laura Gaspar, Ilan Shimshoni, Bella Specktor-Fadida",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes cold-start sampling strategy for medical image segmentation active learning that combines foundation model embeddings with clustering and proportional sampling for diverse initial training.",
      "importance_score": 52,
      "reasoning": "Practical active learning improvement using foundation models. Addresses annotation bottleneck.",
      "themes": [
        "Active Learning",
        "Medical Imaging",
        "Foundation Models"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes cold-start sampling strategy for medical image segmentation active learning that combines foundation model embeddings with clustering and proportional sampling for diverse initial training.</p>",
      "content_html": "<p>arXiv:2601.18532v1 Announce Type: new  Abstract: Accurate segmentation annotations are critical for disease monitoring, yet manual labeling remains a major bottleneck due to the time and expertise required. Active learning (AL) alleviates this burden by prioritizing informative samples for annotation, typically through a diversity-based cold-start phase followed by uncertainty-driven selection. We propose a novel cold-start sampling strategy that combines foundation-model embeddings with clustering, including automatic selection of the number of clusters and proportional sampling across clusters, to construct a diverse and representative initial training. This is followed by an uncertainty-based AL framework that integrates spatial diversity to guide sample selection. The proposed method is intuitive and interpretable, enabling visualization of the feature-space distribution of candidate samples. We evaluate our approach on three datasets spanning X-ray and MRI modalities. On the CheXmask dataset, the cold-start strategy outperforms random selection, improving Dice from 0.918 to 0.929 and reducing the Hausdorff distance from 32.41 to 27.66 mm. In the AL setting, combined entropy and diversity selection improves Dice from 0.919 to 0.939 and reduces the Hausdorff distance from 30.10 to 19.16 mm. On the Montgomery dataset, cold-start gains are substantial, with Dice improving from 0.928 to 0.950 and Hausdorff distance decreasing from 14.22 to 9.38 mm. On the SynthStrip dataset, cold-start selection slightly affects Dice but reduces the Hausdorff distance from 9.43 to 8.69 mm, while active learning improves Dice from 0.816 to 0.826 and reduces the Hausdorff distance from 7.76 to 6.38 mm. Overall, the proposed framework consistently outperforms baseline methods in low-data regimes, improving segmentation accuracy.</p>"
    },
    {
      "id": "66de19ea10b0",
      "title": "Scale-Aware Self-Supervised Learning for Segmentation of Small and Sparse Structures",
      "content": "arXiv:2601.18619v1 Announce Type: new  Abstract: Self-supervised learning (SSL) has emerged as a powerful strategy for representation learning under limited annotation regimes, yet its effectiveness remains highly sensitive to many factors, especially the nature of the target task. In segmentation, existing pipelines are typically tuned to large, homogeneous regions, but their performance drops when objects are small, sparse, or locally irregular. In this work, we propose a scale-aware SSL adaptation that integrates small-window cropping into the augmentation pipeline, zooming in on fine-scale structures during pretraining. We evaluate this approach across two domains with markedly different data modalities: seismic imaging, where the goal is to segment sparse faults, and neuroimaging, where the task is to delineate small cellular structures. In both settings, our method yields consistent improvements over standard and state-of-the-art baselines under label constraints, improving accuracy by up to 13% for fault segmentation and 5% for cell delineation. In contrast, large-scale features such as seismic facies or tissue regions see little benefit, underscoring that the value of SSL depends critically on the scale of the target objects. Our findings highlight the need to align SSL design with object size and sparsity, offering a general principle for buil ding more effective representation learning pipelines across scientific imaging domains.",
      "url": "http://arxiv.org/abs/2601.18619",
      "author": "Jorge Quesada, Ghassan AlRegib",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes scale-aware SSL adaptation integrating small-window cropping for fine-scale structures, demonstrating improvements in seismic fault segmentation and neuroimaging applications.",
      "importance_score": 52,
      "reasoning": "Addresses overlooked failure mode of SSL for small structures. Applicable across diverse domains.",
      "themes": [
        "Self-Supervised Learning",
        "Segmentation",
        "Multi-Scale"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes scale-aware SSL adaptation integrating small-window cropping for fine-scale structures, demonstrating improvements in seismic fault segmentation and neuroimaging applications.</p>",
      "content_html": "<p>arXiv:2601.18619v1 Announce Type: new  Abstract: Self-supervised learning (SSL) has emerged as a powerful strategy for representation learning under limited annotation regimes, yet its effectiveness remains highly sensitive to many factors, especially the nature of the target task. In segmentation, existing pipelines are typically tuned to large, homogeneous regions, but their performance drops when objects are small, sparse, or locally irregular. In this work, we propose a scale-aware SSL adaptation that integrates small-window cropping into the augmentation pipeline, zooming in on fine-scale structures during pretraining. We evaluate this approach across two domains with markedly different data modalities: seismic imaging, where the goal is to segment sparse faults, and neuroimaging, where the task is to delineate small cellular structures. In both settings, our method yields consistent improvements over standard and state-of-the-art baselines under label constraints, improving accuracy by up to 13% for fault segmentation and 5% for cell delineation. In contrast, large-scale features such as seismic facies or tissue regions see little benefit, underscoring that the value of SSL depends critically on the scale of the target objects. Our findings highlight the need to align SSL design with object size and sparsity, offering a general principle for buil ding more effective representation learning pipelines across scientific imaging domains.</p>"
    },
    {
      "id": "dba29968714b",
      "title": "Splat-Portrait: Generalizing Talking Heads with Gaussian Splatting",
      "content": "arXiv:2601.18633v1 Announce Type: new  Abstract: Talking Head Generation aims at synthesizing natural-looking talking videos from speech and a single portrait image. Previous 3D talking head generation methods have relied on domain-specific heuristics such as warping-based facial motion representation priors to animate talking motions, yet still produce inaccurate 3D avatar reconstructions, thus undermining the realism of generated animations. We introduce Splat-Portrait, a Gaussian-splatting-based method that addresses the challenges of 3D head reconstruction and lip motion synthesis. Our approach automatically learns to disentangle a single portrait image into a static 3D reconstruction represented as static Gaussian Splatting, and a predicted whole-image 2D background. It then generates natural lip motion conditioned on input audio, without any motion driven priors. Training is driven purely by 2D reconstruction and score-distillation losses, without 3D supervision nor landmarks. Experimental results demonstrate that Splat-Portrait exhibits superior performance on talking head generation and novel view synthesis, achieving better visual quality compared to previous works. Our project code and supplementary documents are public available at https://github.com/stonewalking/Splat-portrait.",
      "url": "http://arxiv.org/abs/2601.18633",
      "author": "Tong Shi, Melonie de Almeida, Daniela Ivanova, Nicolas Pugeault, Paul Henderson",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents Splat-Portrait, a Gaussian splatting method for talking head generation that disentangles static 3D reconstruction from dynamic lip motion synthesis for more realistic animations.",
      "importance_score": 52,
      "reasoning": "Applies popular 3DGS technique to talking heads with improved reconstruction quality, but follows established research directions.",
      "themes": [
        "3D Gaussian Splatting",
        "Face Generation",
        "Computer Vision"
      ],
      "continuation": null,
      "summary_html": "<p>Presents Splat-Portrait, a Gaussian splatting method for talking head generation that disentangles static 3D reconstruction from dynamic lip motion synthesis for more realistic animations.</p>",
      "content_html": "<p>arXiv:2601.18633v1 Announce Type: new  Abstract: Talking Head Generation aims at synthesizing natural-looking talking videos from speech and a single portrait image. Previous 3D talking head generation methods have relied on domain-specific heuristics such as warping-based facial motion representation priors to animate talking motions, yet still produce inaccurate 3D avatar reconstructions, thus undermining the realism of generated animations. We introduce Splat-Portrait, a Gaussian-splatting-based method that addresses the challenges of 3D head reconstruction and lip motion synthesis. Our approach automatically learns to disentangle a single portrait image into a static 3D reconstruction represented as static Gaussian Splatting, and a predicted whole-image 2D background. It then generates natural lip motion conditioned on input audio, without any motion driven priors. Training is driven purely by 2D reconstruction and score-distillation losses, without 3D supervision nor landmarks. Experimental results demonstrate that Splat-Portrait exhibits superior performance on talking head generation and novel view synthesis, achieving better visual quality compared to previous works. Our project code and supplementary documents are public available at https://github.com/stonewalking/Splat-portrait.</p>"
    },
    {
      "id": "8662916164a7",
      "title": "Multimodal Privacy-Preserving Entity Resolution with Fully Homomorphic Encryption",
      "content": "arXiv:2601.18612v1 Announce Type: cross  Abstract: The canonical challenge of entity resolution within high-compliance sectors, where secure identity reconciliation is frequently confounded by significant data heterogeneity, including syntactic variations in personal identifiers, is a longstanding and complex problem. To this end, we introduce a novel multimodal framework operating with the voluminous data sets typical of government and financial institutions. Specifically, our methodology is designed to address the tripartite challenge of data volume, matching fidelity, and privacy. Consequently, the underlying plaintext of personally identifiable information remains computationally inaccessible throughout the matching lifecycle, empowering institutions to rigorously satisfy stringent regulatory mandates with cryptographic assurances of client confidentiality while achieving a demonstrably low equal error rate and maintaining computational tractability at scale.",
      "url": "http://arxiv.org/abs/2601.18612",
      "author": "Susim Roy, Nalini Ratha",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Introduces multimodal framework for privacy-preserving entity resolution using fully homomorphic encryption for government and financial institution data matching.",
      "importance_score": 52,
      "reasoning": "Addresses important privacy challenge in entity resolution but practical FHE limitations remain significant.",
      "themes": [
        "Privacy-Preserving ML",
        "Entity Resolution",
        "Homomorphic Encryption"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces multimodal framework for privacy-preserving entity resolution using fully homomorphic encryption for government and financial institution data matching.</p>",
      "content_html": "<p>arXiv:2601.18612v1 Announce Type: cross  Abstract: The canonical challenge of entity resolution within high-compliance sectors, where secure identity reconciliation is frequently confounded by significant data heterogeneity, including syntactic variations in personal identifiers, is a longstanding and complex problem. To this end, we introduce a novel multimodal framework operating with the voluminous data sets typical of government and financial institutions. Specifically, our methodology is designed to address the tripartite challenge of data volume, matching fidelity, and privacy. Consequently, the underlying plaintext of personally identifiable information remains computationally inaccessible throughout the matching lifecycle, empowering institutions to rigorously satisfy stringent regulatory mandates with cryptographic assurances of client confidentiality while achieving a demonstrably low equal error rate and maintaining computational tractability at scale.</p>"
    },
    {
      "id": "2b4cf3cba495",
      "title": "Real-Time, Energy-Efficient, Sampling-Based Optimal Control via FPGA Acceleration",
      "content": "arXiv:2601.17231v1 Announce Type: new  Abstract: Autonomous mobile robots (AMRs), used for search-and-rescue and remote exploration, require fast and robust planning and control schemes. Sampling-based approaches for Model Predictive Control, especially approaches based on the Model Predictive Path Integral Control (MPPI) algorithm, have recently proven both to be highly effective for such applications and to map naturally to GPUs for hardware acceleration. However, both GPU and CPU implementations of such algorithms can struggle to meet tight energy and latency budgets on battery-constrained AMR platforms that leverage embedded compute. To address this issue, we present an FPGA-optimized MPPI design that exposes fine-grained parallelism and eliminates synchronization bottlenecks via deep pipelining and parallelism across algorithmic stages. This results in an average 3.1x to 7.5x speedup over optimized implementations on an embedded GPU and CPU, respectively, while simultaneously achieving a 2.5x to 5.4x reduction in energy usage. These results demonstrate that FPGA architectures are a promising direction for energy-efficient and high-performance edge robotics.",
      "url": "http://arxiv.org/abs/2601.17231",
      "author": "Tanmay Desai, Brian Plancher, R. Iris Bahar",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents FPGA-optimized MPPI implementation for real-time sampling-based model predictive control, addressing energy and latency constraints on battery-constrained autonomous mobile robots.",
      "importance_score": 52,
      "reasoning": "Practical contribution for efficient robot control, addresses real deployment constraints.",
      "themes": [
        "FPGA Acceleration",
        "Model Predictive Control",
        "Embedded Robotics"
      ],
      "continuation": null,
      "summary_html": "<p>Presents FPGA-optimized MPPI implementation for real-time sampling-based model predictive control, addressing energy and latency constraints on battery-constrained autonomous mobile robots.</p>",
      "content_html": "<p>arXiv:2601.17231v1 Announce Type: new  Abstract: Autonomous mobile robots (AMRs), used for search-and-rescue and remote exploration, require fast and robust planning and control schemes. Sampling-based approaches for Model Predictive Control, especially approaches based on the Model Predictive Path Integral Control (MPPI) algorithm, have recently proven both to be highly effective for such applications and to map naturally to GPUs for hardware acceleration. However, both GPU and CPU implementations of such algorithms can struggle to meet tight energy and latency budgets on battery-constrained AMR platforms that leverage embedded compute. To address this issue, we present an FPGA-optimized MPPI design that exposes fine-grained parallelism and eliminates synchronization bottlenecks via deep pipelining and parallelism across algorithmic stages. This results in an average 3.1x to 7.5x speedup over optimized implementations on an embedded GPU and CPU, respectively, while simultaneously achieving a 2.5x to 5.4x reduction in energy usage. These results demonstrate that FPGA architectures are a promising direction for energy-efficient and high-performance edge robotics.</p>"
    },
    {
      "id": "24c2f23b5e8f",
      "title": "Quantum-Inspired Episode Selection for Monte Carlo Reinforcement Learning via QUBO Optimization",
      "content": "arXiv:2601.17570v1 Announce Type: cross  Abstract: Monte Carlo (MC) reinforcement learning suffers from high sample complexity, especially in environments with sparse rewards, large state spaces, and correlated trajectories. We address these limitations by reformulating episode selection as a Quadratic Unconstrained Binary Optimization (QUBO) problem and solving it with quantum-inspired samplers. Our method, MC+QUBO, integrates a combinatorial filtering step into standard MC policy evaluation: from each batch of trajectories, we select a subset that maximizes cumulative reward while promoting state-space coverage. This selection is encoded as a QUBO, where linear terms favor high-reward episodes and quadratic terms penalize redundancy. We explore both Simulated Quantum Annealing (SQA) and Simulated Bifurcation (SB) as black-box solvers within this framework. Experiments in a finite-horizon GridWorld demonstrate that MC+QUBO outperforms vanilla MC in convergence speed and final policy quality, highlighting the potential of quantum-inspired optimization as a decision-making subroutine in reinforcement learning.",
      "url": "http://arxiv.org/abs/2601.17570",
      "author": "Hadi Salloum, Ali Jnadi, Yaroslav Kholodov, Alexander Gasnikov",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Reformulates episode selection in Monte Carlo RL as QUBO problem solvable by quantum-inspired samplers, selecting episodes maximizing reward while promoting state-space coverage.",
      "importance_score": 52,
      "reasoning": "Novel formulation connecting QUBO optimization to RL sample selection, interesting quantum-inspired approach.",
      "themes": [
        "Quantum-Inspired Computing",
        "Reinforcement Learning",
        "Sample Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>Reformulates episode selection in Monte Carlo RL as QUBO problem solvable by quantum-inspired samplers, selecting episodes maximizing reward while promoting state-space coverage.</p>",
      "content_html": "<p>arXiv:2601.17570v1 Announce Type: cross  Abstract: Monte Carlo (MC) reinforcement learning suffers from high sample complexity, especially in environments with sparse rewards, large state spaces, and correlated trajectories. We address these limitations by reformulating episode selection as a Quadratic Unconstrained Binary Optimization (QUBO) problem and solving it with quantum-inspired samplers. Our method, MC+QUBO, integrates a combinatorial filtering step into standard MC policy evaluation: from each batch of trajectories, we select a subset that maximizes cumulative reward while promoting state-space coverage. This selection is encoded as a QUBO, where linear terms favor high-reward episodes and quadratic terms penalize redundancy. We explore both Simulated Quantum Annealing (SQA) and Simulated Bifurcation (SB) as black-box solvers within this framework. Experiments in a finite-horizon GridWorld demonstrate that MC+QUBO outperforms vanilla MC in convergence speed and final policy quality, highlighting the potential of quantum-inspired optimization as a decision-making subroutine in reinforcement learning.</p>"
    },
    {
      "id": "8a56947c2d40",
      "title": "PEAfowl: Perception-Enhanced Multi-View Vision-Language-Action for Bimanual Manipulation",
      "content": "arXiv:2601.17885v1 Announce Type: cross  Abstract: Bimanual manipulation in cluttered scenes requires policies that remain stable under occlusions, viewpoint and scene variations. Existing vision-language-action models often fail to generalize because (i) multi-view features are fused via view-agnostic token concatenation, yielding weak 3D-consistent spatial understanding, and (ii) language is injected as global conditioning, resulting in coarse instruction grounding.   In this paper, we introduce PEAfowl, a perception-enhanced multi-view VLA policy for bimanual manipulation. For spatial reasoning, PEAfowl predicts per-token depth distributions, performs differentiable 3D lifting, and aggregates local cross-view neighbors to form geometrically grounded, cross-view consistent representations. For instruction grounding, we propose to replace global conditioning with a Perceiver-style text-aware readout over frozen CLIP visual features, enabling iterative evidence accumulation. To overcome noisy and incomplete commodity depth without adding inference overhead, we apply training-only depth distillation from a pretrained depth teacher to supervise the depth-distribution head, providing perception front-end with geometry-aware priors.   On RoboTwin 2.0 under domain-randomized setting, PEAfowl improves the strongest baseline by 23.0 pp in success rate, and real-robot experiments further demonstrate reliable sim-to-real transfer and consistent improvements from depth distillation.   Project website: https://peafowlvla.github.io/.",
      "url": "http://arxiv.org/abs/2601.17885",
      "author": "Qingyu Fan, Zhaoxiang Li, Yi Lu, Wang Chen, Qiu Shen, Xiao-xiao Long, Yinghao Cai, Tao Lu, Shuo Wang, Xun Cao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "PEAfowl improves bimanual manipulation through multi-view VLA with explicit depth prediction and spatial-aware query injection for 3D-consistent representations.",
      "importance_score": 51,
      "reasoning": "Addresses key limitations in VLA for robotics. Multi-view fusion with geometric grounding.",
      "themes": [
        "Robotics",
        "Vision-Language-Action",
        "Manipulation"
      ],
      "continuation": null,
      "summary_html": "<p>PEAfowl improves bimanual manipulation through multi-view VLA with explicit depth prediction and spatial-aware query injection for 3D-consistent representations.</p>",
      "content_html": "<p>arXiv:2601.17885v1 Announce Type: cross  Abstract: Bimanual manipulation in cluttered scenes requires policies that remain stable under occlusions, viewpoint and scene variations. Existing vision-language-action models often fail to generalize because (i) multi-view features are fused via view-agnostic token concatenation, yielding weak 3D-consistent spatial understanding, and (ii) language is injected as global conditioning, resulting in coarse instruction grounding.   In this paper, we introduce PEAfowl, a perception-enhanced multi-view VLA policy for bimanual manipulation. For spatial reasoning, PEAfowl predicts per-token depth distributions, performs differentiable 3D lifting, and aggregates local cross-view neighbors to form geometrically grounded, cross-view consistent representations. For instruction grounding, we propose to replace global conditioning with a Perceiver-style text-aware readout over frozen CLIP visual features, enabling iterative evidence accumulation. To overcome noisy and incomplete commodity depth without adding inference overhead, we apply training-only depth distillation from a pretrained depth teacher to supervise the depth-distribution head, providing perception front-end with geometry-aware priors.   On RoboTwin 2.0 under domain-randomized setting, PEAfowl improves the strongest baseline by 23.0 pp in success rate, and real-robot experiments further demonstrate reliable sim-to-real transfer and consistent improvements from depth distillation.   Project website: https://peafowlvla.github.io/.</p>"
    },
    {
      "id": "03993b295c8c",
      "title": "How Information Evolves: Stability-Driven Assembly and the Emergence of a Natural Genetic Algorithm",
      "content": "arXiv:2601.17061v1 Announce Type: cross  Abstract: Information can evolve as a physical consequence of non-equilibrium dynamics, even in the absence of genes, replication, or predefined fitness functions. We present Stability-Driven Assembly (SDA), a framework in which stochastic assembly combined with differential persistence biases populations toward longer-lived motifs. Assemblies that persist longer become more frequent and are therefore more likely to participate in subsequent interactions, generating feedback that reshapes the population distribution and implements fitness-proportional sampling, realizing evolution as a natural, emergent genetic algorithm (SDA/GA) driven solely by stability. We apply SDA/GA to chemical symbol space using SMILES fragments with recombination, mutation, and a heuristic stability function. Simulations show hallmark features of evolutionary search, including scaffold-level dominance, sustained novelty, and entropy reduction, yielding open-ended dynamics absent from equilibrium models with fixed transition rates. These results motivate an evolutionary ladder hypothesis where persistence-driven selection precedes genetic replication.",
      "url": "http://arxiv.org/abs/2601.17061",
      "author": "Dan Adler",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "q-bio.PE"
      ],
      "summary": "Presents Stability-Driven Assembly framework showing information can evolve through differential persistence alone, implementing evolution as emergent genetic algorithm without predefined fitness.",
      "importance_score": 51,
      "reasoning": "Interesting theoretical framework connecting physics-driven assembly to evolution, interdisciplinary contribution.",
      "themes": [
        "Artificial Life",
        "Evolutionary Theory",
        "Chemical Computing"
      ],
      "continuation": null,
      "summary_html": "<p>Presents Stability-Driven Assembly framework showing information can evolve through differential persistence alone, implementing evolution as emergent genetic algorithm without predefined fitness.</p>",
      "content_html": "<p>arXiv:2601.17061v1 Announce Type: cross  Abstract: Information can evolve as a physical consequence of non-equilibrium dynamics, even in the absence of genes, replication, or predefined fitness functions. We present Stability-Driven Assembly (SDA), a framework in which stochastic assembly combined with differential persistence biases populations toward longer-lived motifs. Assemblies that persist longer become more frequent and are therefore more likely to participate in subsequent interactions, generating feedback that reshapes the population distribution and implements fitness-proportional sampling, realizing evolution as a natural, emergent genetic algorithm (SDA/GA) driven solely by stability. We apply SDA/GA to chemical symbol space using SMILES fragments with recombination, mutation, and a heuristic stability function. Simulations show hallmark features of evolutionary search, including scaffold-level dominance, sustained novelty, and entropy reduction, yielding open-ended dynamics absent from equilibrium models with fixed transition rates. These results motivate an evolutionary ladder hypothesis where persistence-driven selection precedes genetic replication.</p>"
    },
    {
      "id": "1af25a8eeb20",
      "title": "DiffusionCinema: Text-to-Aerial Cinematography",
      "content": "arXiv:2601.17412v1 Announce Type: new  Abstract: We propose a novel Unmanned Aerial Vehicles (UAV) assisted creative capture system that leverages diffusion models to interpret high-level natural language prompts and automatically generate optimal flight trajectories for cinematic video recording. Instead of manually piloting the drone, the user simply describes the desired shot (e.g., \"orbit around me slowly from the right and reveal the background waterfall\"). Our system encodes the prompt along with an initial visual snapshot from the onboard camera, and a diffusion model samples plausible spatio-temporal motion plans that satisfy both the scene geometry and shot semantics. The generated flight trajectory is then executed autonomously by the UAV to record smooth, repeatable video clips that match the prompt. User evaluation using NASA-TLX showed a significantly lower overall workload with our interface (M = 21.6) compared to a traditional remote controller (M = 58.1), demonstrating a substantial reduction in perceived effort. Mental demand (M = 11.5 vs. 60.5) and frustration (M = 14.0 vs. 54.5) were also markedly lower for our system, confirming clear usability advantages in autonomous text-driven flight control. This project demonstrates a new interaction paradigm: text-to-cinema flight, where diffusion models act as the \"creative operator\" converting story intentions directly into aerial motion.",
      "url": "http://arxiv.org/abs/2601.17412",
      "author": "Valerii Serpiva, Artem Lykov, Jeffrin Sam, Aleksey Fedoseev, Dzmitry Tsetserukou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes DiffusionCinema, using diffusion models to interpret natural language prompts and generate UAV flight trajectories for cinematic video recording.",
      "importance_score": 51,
      "reasoning": "Creative application of diffusion models to robotics, addresses interesting use case but narrow scope.",
      "themes": [
        "Diffusion Models",
        "UAV Navigation",
        "Creative AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes DiffusionCinema, using diffusion models to interpret natural language prompts and generate UAV flight trajectories for cinematic video recording.</p>",
      "content_html": "<p>arXiv:2601.17412v1 Announce Type: new  Abstract: We propose a novel Unmanned Aerial Vehicles (UAV) assisted creative capture system that leverages diffusion models to interpret high-level natural language prompts and automatically generate optimal flight trajectories for cinematic video recording. Instead of manually piloting the drone, the user simply describes the desired shot (e.g., \"orbit around me slowly from the right and reveal the background waterfall\"). Our system encodes the prompt along with an initial visual snapshot from the onboard camera, and a diffusion model samples plausible spatio-temporal motion plans that satisfy both the scene geometry and shot semantics. The generated flight trajectory is then executed autonomously by the UAV to record smooth, repeatable video clips that match the prompt. User evaluation using NASA-TLX showed a significantly lower overall workload with our interface (M = 21.6) compared to a traditional remote controller (M = 58.1), demonstrating a substantial reduction in perceived effort. Mental demand (M = 11.5 vs. 60.5) and frustration (M = 14.0 vs. 54.5) were also markedly lower for our system, confirming clear usability advantages in autonomous text-driven flight control. This project demonstrates a new interaction paradigm: text-to-cinema flight, where diffusion models act as the \"creative operator\" converting story intentions directly into aerial motion.</p>"
    },
    {
      "id": "bf615501ce55",
      "title": "Universality of Many-body Projected Ensemble for Learning Quantum Data Distribution",
      "content": "arXiv:2601.18637v1 Announce Type: cross  Abstract: Generating quantum data by learning the underlying quantum distribution poses challenges in both theoretical and practical scenarios, yet it is a critical task for understanding quantum systems. A fundamental question in quantum machine learning (QML) is the universality of approximation: whether a parameterized QML model can approximate any quantum distribution. We address this question by proving a universality theorem for the Many-body Projected Ensemble (MPE) framework, a method for quantum state design that uses a single many-body wave function to prepare random states. This demonstrates that MPE can approximate any distribution of pure states within a 1-Wasserstein distance error. This theorem provides a rigorous guarantee of universal expressivity, addressing key theoretical gaps in QML. For practicality, we propose an Incremental MPE variant with layer-wise training to improve the trainability. Numerical experiments on clustered quantum states and quantum chemistry datasets validate MPE's efficacy in learning complex quantum data distributions.",
      "url": "http://arxiv.org/abs/2601.18637",
      "author": "Quoc Hoan Tran, Koki Chinzei, Yasuhiro Endo, Hirotaka Oshima",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "quant-ph"
      ],
      "summary": "Proves universality theorem for Many-body Projected Ensemble framework, showing it can approximate any distribution of pure states within Wasserstein-1 error.",
      "importance_score": 51,
      "reasoning": "Important theoretical result for quantum ML but limited practical implications currently.",
      "themes": [
        "Quantum Machine Learning",
        "Universality",
        "Theory"
      ],
      "continuation": null,
      "summary_html": "<p>Proves universality theorem for Many-body Projected Ensemble framework, showing it can approximate any distribution of pure states within Wasserstein-1 error.</p>",
      "content_html": "<p>arXiv:2601.18637v1 Announce Type: cross  Abstract: Generating quantum data by learning the underlying quantum distribution poses challenges in both theoretical and practical scenarios, yet it is a critical task for understanding quantum systems. A fundamental question in quantum machine learning (QML) is the universality of approximation: whether a parameterized QML model can approximate any quantum distribution. We address this question by proving a universality theorem for the Many-body Projected Ensemble (MPE) framework, a method for quantum state design that uses a single many-body wave function to prepare random states. This demonstrates that MPE can approximate any distribution of pure states within a 1-Wasserstein distance error. This theorem provides a rigorous guarantee of universal expressivity, addressing key theoretical gaps in QML. For practicality, we propose an Incremental MPE variant with layer-wise training to improve the trainability. Numerical experiments on clustered quantum states and quantum chemistry datasets validate MPE's efficacy in learning complex quantum data distributions.</p>"
    },
    {
      "id": "88aadc9424c5",
      "title": "Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules",
      "content": "arXiv:2601.18716v1 Announce Type: new  Abstract: Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases.",
      "url": "http://arxiv.org/abs/2601.18716",
      "author": "Naeyma N. Islam, Thomas R. Caulfield",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Presents AI-assisted drug design for Alzheimer's using ligase-conditioned generative models to design molecular glues promoting targeted degradation of amyloid beta-42.",
      "importance_score": 50,
      "reasoning": "Specialized drug discovery application; interesting use of generative AI but narrow scope.",
      "themes": [
        "Drug Discovery",
        "Generative Models",
        "Healthcare AI"
      ],
      "continuation": null,
      "summary_html": "<p>Presents AI-assisted drug design for Alzheimer's using ligase-conditioned generative models to design molecular glues promoting targeted degradation of amyloid beta-42.</p>",
      "content_html": "<p>arXiv:2601.18716v1 Announce Type: new  Abstract: Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases.</p>"
    },
    {
      "id": "fd15ea65fa0b",
      "title": "E2PL: Effective and Efficient Prompt Learning for Incomplete Multi-view Multi-Label Class Incremental Learning",
      "content": "arXiv:2601.17076v1 Announce Type: cross  Abstract: Multi-view multi-label classification (MvMLC) is indispensable for modern web applications aggregating information from diverse sources. However, real-world web-scale settings are rife with missing views and continuously emerging classes, which pose significant obstacles to robust learning. Prevailing methods are ill-equipped for this reality, as they either lack adaptability to new classes or incur exponential parameter growth when handling all possible missing-view patterns, severely limiting their scalability in web environments. To systematically address this gap, we formally introduce a novel task, termed \\emph{incomplete multi-view multi-label class incremental learning} (IMvMLCIL), which requires models to simultaneously address heterogeneous missing views and dynamic class expansion. To tackle this task, we propose \\textsf{E2PL}, an Effective and Efficient Prompt Learning framework for IMvMLCIL. \\textsf{E2PL} unifies two novel prompt designs: \\emph{task-tailored prompts} for class-incremental adaptation and \\emph{missing-aware prompts} for the flexible integration of arbitrary view-missing scenarios. To fundamentally address the exponential parameter explosion inherent in missing-aware prompts, we devise an \\emph{efficient prototype tensorization} module, which leverages atomic tensor decomposition to elegantly reduce the prompt parameter complexity from exponential to linear w.r.t. the number of views. We further incorporate a \\emph{dynamic contrastive learning} strategy explicitly model the complex dependencies among diverse missing-view patterns, thus enhancing the model's robustness. Extensive experiments on three benchmarks demonstrate that \\textsf{E2PL} consistently outperforms state-of-the-art methods in both effectiveness and efficiency. The codes and datasets are available at https://anonymous.4open.science/r/code-for-E2PL.",
      "url": "http://arxiv.org/abs/2601.17076",
      "author": "Jiajun Chen, Yue Wu, Kai Huang, Wen Xi, Yangyang Wu, Xiaoye Miao, Mengying Zhu, Meng Xi, Guanjie Cheng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Defines new task of incomplete multi-view multi-label class incremental learning (IMvMLCIL) and proposes E2PL using prompt learning to handle missing views and emerging classes.",
      "importance_score": 50,
      "reasoning": "Novel task formulation addressing realistic web-scale challenges. Technical contribution but complex problem setup may limit adoption.",
      "themes": [
        "Continual Learning",
        "Multi-View Learning",
        "Prompt Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Defines new task of incomplete multi-view multi-label class incremental learning (IMvMLCIL) and proposes E2PL using prompt learning to handle missing views and emerging classes.</p>",
      "content_html": "<p>arXiv:2601.17076v1 Announce Type: cross  Abstract: Multi-view multi-label classification (MvMLC) is indispensable for modern web applications aggregating information from diverse sources. However, real-world web-scale settings are rife with missing views and continuously emerging classes, which pose significant obstacles to robust learning. Prevailing methods are ill-equipped for this reality, as they either lack adaptability to new classes or incur exponential parameter growth when handling all possible missing-view patterns, severely limiting their scalability in web environments. To systematically address this gap, we formally introduce a novel task, termed \\emph{incomplete multi-view multi-label class incremental learning} (IMvMLCIL), which requires models to simultaneously address heterogeneous missing views and dynamic class expansion. To tackle this task, we propose \\textsf{E2PL}, an Effective and Efficient Prompt Learning framework for IMvMLCIL. \\textsf{E2PL} unifies two novel prompt designs: \\emph{task-tailored prompts} for class-incremental adaptation and \\emph{missing-aware prompts} for the flexible integration of arbitrary view-missing scenarios. To fundamentally address the exponential parameter explosion inherent in missing-aware prompts, we devise an \\emph{efficient prototype tensorization} module, which leverages atomic tensor decomposition to elegantly reduce the prompt parameter complexity from exponential to linear w.r.t. the number of views. We further incorporate a \\emph{dynamic contrastive learning} strategy explicitly model the complex dependencies among diverse missing-view patterns, thus enhancing the model's robustness. Extensive experiments on three benchmarks demonstrate that \\textsf{E2PL} consistently outperforms state-of-the-art methods in both effectiveness and efficiency. The codes and datasets are available at https://anonymous.4open.science/r/code-for-E2PL.</p>"
    },
    {
      "id": "309a869cbf9f",
      "title": "Authority Signals in AI Cited Health Sources: A Framework for Evaluating Source Credibility in ChatGPT Responses",
      "content": "arXiv:2601.17109v1 Announce Type: cross  Abstract: Health information seeking has fundamentally changed since the onset of Large Language Models (LLM), with nearly one third of ChatGPT's 800 million users asking health questions weekly. Understanding the sources of those AI generated responses is vital, as health organizations and providers are also investing in digital strategies to organically improve their ranking, reach and visibility in LLM systems like ChatGPT. As AI search optimization strategies are gaining maturity, this study introduces an Authority Signals Framework, organized in four domains that reflect key components to health information seeking, starting with \"Who wrote it?\" (Author Credentials), followed by \"Who published it?\" (Institutional Affiliation), \"How was it vetted?\" (Quality Assurance), and \"How does AI find it?\" (Digital Authority). This descriptive cross-sectional study randomly selected 100 questions from HealthSearchQA which contains 3,173 consumer health questions curated by Google Research from publicly available search engine suggestions. Those questions were entered into ChatGPT 5.2 Pro to record and code the cited sources through the lens of the Authority Signals Framework's four domains. Descriptive statistics were calculated for all cited sources (n=615), and cross tabulations were conducted to examine distinction among organization types. Over 75% of the sources cited in ChatGPT's health generated responses were from established institutional sources, such as Mayo Clinic, Cleveland Clinic, Wikipedia, National Health Service, PubMed with the remaining citations sourced from alternative health information sources that lacked established institutional backing.",
      "url": "http://arxiv.org/abs/2601.17109",
      "author": "Erin Jacques (York College, CUNY), Erela Datuowei (Teachers College, Columbia University), Vincent Jones II (York College, CUNY), Corey Basch (William Paterson University), Celeta Vanderpool (Teachers College, Columbia University), Nkechi Udeozo (CUNY School of Public Health), Griselda Chapa (York College, CUNY)",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.DL"
      ],
      "summary": "Introduces Authority Signals Framework for evaluating source credibility in ChatGPT health responses across four domains: author credentials, institutional affiliation, vetting process, and reach.",
      "importance_score": 50,
      "reasoning": "Practical framework for health information quality assessment. Important for safe AI deployment in healthcare.",
      "themes": [
        "Health AI",
        "Source Credibility",
        "Information Quality"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Authority Signals Framework for evaluating source credibility in ChatGPT health responses across four domains: author credentials, institutional affiliation, vetting process, and reach.</p>",
      "content_html": "<p>arXiv:2601.17109v1 Announce Type: cross  Abstract: Health information seeking has fundamentally changed since the onset of Large Language Models (LLM), with nearly one third of ChatGPT's 800 million users asking health questions weekly. Understanding the sources of those AI generated responses is vital, as health organizations and providers are also investing in digital strategies to organically improve their ranking, reach and visibility in LLM systems like ChatGPT. As AI search optimization strategies are gaining maturity, this study introduces an Authority Signals Framework, organized in four domains that reflect key components to health information seeking, starting with \"Who wrote it?\" (Author Credentials), followed by \"Who published it?\" (Institutional Affiliation), \"How was it vetted?\" (Quality Assurance), and \"How does AI find it?\" (Digital Authority). This descriptive cross-sectional study randomly selected 100 questions from HealthSearchQA which contains 3,173 consumer health questions curated by Google Research from publicly available search engine suggestions. Those questions were entered into ChatGPT 5.2 Pro to record and code the cited sources through the lens of the Authority Signals Framework's four domains. Descriptive statistics were calculated for all cited sources (n=615), and cross tabulations were conducted to examine distinction among organization types. Over 75% of the sources cited in ChatGPT's health generated responses were from established institutional sources, such as Mayo Clinic, Cleveland Clinic, Wikipedia, National Health Service, PubMed with the remaining citations sourced from alternative health information sources that lacked established institutional backing.</p>"
    },
    {
      "id": "e87d06411ea2",
      "title": "RAICL: Retrieval-Augmented In-Context Learning for Vision-Language-Model Based EEG Seizure Detection",
      "content": "arXiv:2601.17844v1 Announce Type: cross  Abstract: Electroencephalogram (EEG) decoding is a critical component of medical diagnostics, rehabilitation engineering, and brain-computer interfaces. However, contemporary decoding methodologies remain heavily dependent on task-specific datasets to train specialized neural network architectures. Consequently, limited data availability impedes the development of generalizable large brain decoding models. In this work, we propose a paradigm shift from conventional signal-based decoding by leveraging large-scale vision-language models (VLMs) to analyze EEG waveform plots. By converting multivariate EEG signals into stacked waveform images and integrating neuroscience domain expertise into textual prompts, we demonstrate that foundational VLMs can effectively differentiate between different patterns in the human brain. To address the inherent non-stationarity of EEG signals, we introduce a Retrieval-Augmented In-Context Learning (RAICL) approach, which dynamically selects the most representative and relevant few-shot examples to condition the autoregressive outputs of the VLM. Experiments on EEG-based seizure detection indicate that state-of-the-art VLMs under RAICL achieved better or comparable performance with traditional time series based approaches. These findings suggest a new direction in physiological signal processing that effectively bridges the modalities of vision, language, and neural activities. Furthermore, the utilization of off-the-shelf VLMs, without the need for retraining or downstream architecture construction, offers a readily deployable solution for clinical applications.",
      "url": "http://arxiv.org/abs/2601.17844",
      "author": "Siyang Li, Zhuoya Wang, Xiyan Gui, Xiaoqing Chen, Ziwei Wang, Yaozhi Wen, Dongrui Wu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.HC"
      ],
      "summary": "RAICL converts EEG signals into waveform images and uses vision-language models with retrieval-augmented in-context learning for seizure detection.",
      "importance_score": 50,
      "reasoning": "Novel modality conversion approach for EEG. Leverages pretrained VLMs for medical application.",
      "themes": [
        "Medical AI",
        "EEG Analysis",
        "Vision-Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>RAICL converts EEG signals into waveform images and uses vision-language models with retrieval-augmented in-context learning for seizure detection.</p>",
      "content_html": "<p>arXiv:2601.17844v1 Announce Type: cross  Abstract: Electroencephalogram (EEG) decoding is a critical component of medical diagnostics, rehabilitation engineering, and brain-computer interfaces. However, contemporary decoding methodologies remain heavily dependent on task-specific datasets to train specialized neural network architectures. Consequently, limited data availability impedes the development of generalizable large brain decoding models. In this work, we propose a paradigm shift from conventional signal-based decoding by leveraging large-scale vision-language models (VLMs) to analyze EEG waveform plots. By converting multivariate EEG signals into stacked waveform images and integrating neuroscience domain expertise into textual prompts, we demonstrate that foundational VLMs can effectively differentiate between different patterns in the human brain. To address the inherent non-stationarity of EEG signals, we introduce a Retrieval-Augmented In-Context Learning (RAICL) approach, which dynamically selects the most representative and relevant few-shot examples to condition the autoregressive outputs of the VLM. Experiments on EEG-based seizure detection indicate that state-of-the-art VLMs under RAICL achieved better or comparable performance with traditional time series based approaches. These findings suggest a new direction in physiological signal processing that effectively bridges the modalities of vision, language, and neural activities. Furthermore, the utilization of off-the-shelf VLMs, without the need for retraining or downstream architecture construction, offers a readily deployable solution for clinical applications.</p>"
    },
    {
      "id": "08e26b572c45",
      "title": "Explaining Synergistic Effects in Social Recommendations",
      "content": "arXiv:2601.18151v1 Announce Type: cross  Abstract: In social recommenders, the inherent nonlinearity and opacity of synergistic effects across multiple social networks hinders users from understanding how diverse information is leveraged for recommendations, consequently diminishing explainability. However, existing explainers can only identify the topological information in social networks that significantly influences recommendations, failing to further explain the synergistic effects among this information. Inspired by existing findings that synergistic effects enhance mutual information between inputs and predictions to generate information gain, we extend this discovery to graph data. We quantify graph information gain to identify subgraphs embodying synergistic effects. Based on the theoretical insights, we propose SemExplainer, which explains synergistic effects by identifying subgraphs that embody them. SemExplainer first extracts explanatory subgraphs from multi-view social networks to generate preliminary importance explanations for recommendations. A conditional entropy optimization strategy to maximize information gain is developed, thereby further identifying subgraphs that embody synergistic effects from explanatory subgraphs. Finally, SemExplainer searches for paths from users to recommended items within the synergistic subgraphs to generate explanations for the recommendations. Extensive experiments on three datasets demonstrate the superiority of SemExplainer over baseline methods, providing superior explanations of synergistic effects.",
      "url": "http://arxiv.org/abs/2601.18151",
      "author": "Yicong Li, Shan Jin, Qi Liu, Shuo Wang, Jiaying Liu, Shuo Yu, Qiang Zhang, Kuanjiu Zhou, Feng Xia",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.SI"
      ],
      "summary": "Addresses explainability in social recommender systems by quantifying synergistic effects across multiple social networks using graph information gain. Identifies subgraphs embodying synergistic effects.",
      "importance_score": 50,
      "reasoning": "Contributes to recommender system explainability but specialized application. Novel use of information gain for graph explanation.",
      "themes": [
        "Explainability",
        "Recommender Systems",
        "Graph Neural Networks"
      ],
      "continuation": null,
      "summary_html": "<p>Addresses explainability in social recommender systems by quantifying synergistic effects across multiple social networks using graph information gain. Identifies subgraphs embodying synergistic effects.</p>",
      "content_html": "<p>arXiv:2601.18151v1 Announce Type: cross  Abstract: In social recommenders, the inherent nonlinearity and opacity of synergistic effects across multiple social networks hinders users from understanding how diverse information is leveraged for recommendations, consequently diminishing explainability. However, existing explainers can only identify the topological information in social networks that significantly influences recommendations, failing to further explain the synergistic effects among this information. Inspired by existing findings that synergistic effects enhance mutual information between inputs and predictions to generate information gain, we extend this discovery to graph data. We quantify graph information gain to identify subgraphs embodying synergistic effects. Based on the theoretical insights, we propose SemExplainer, which explains synergistic effects by identifying subgraphs that embody them. SemExplainer first extracts explanatory subgraphs from multi-view social networks to generate preliminary importance explanations for recommendations. A conditional entropy optimization strategy to maximize information gain is developed, thereby further identifying subgraphs that embody synergistic effects from explanatory subgraphs. Finally, SemExplainer searches for paths from users to recommended items within the synergistic subgraphs to generate explanations for the recommendations. Extensive experiments on three datasets demonstrate the superiority of SemExplainer over baseline methods, providing superior explanations of synergistic effects.</p>"
    },
    {
      "id": "7ab74eaf7f7c",
      "title": "MultiVis-Agent: A Multi-Agent Framework with Logic Rules for Reliable and Comprehensive Cross-Modal Data Visualization",
      "content": "arXiv:2601.18320v1 Announce Type: cross  Abstract: Real-world visualization tasks involve complex, multi-modal requirements that extend beyond simple text-to-chart generation, requiring reference images, code examples, and iterative refinement. Current systems exhibit fundamental limitations: single-modality input, one-shot generation, and rigid workflows. While LLM-based approaches show potential for these complex requirements, they introduce reliability challenges including catastrophic failures and infinite loop susceptibility. To address this gap, we propose MultiVis-Agent, a logic rule-enhanced multi-agent framework for reliable multi-modal and multi-scenario visualization generation. Our approach introduces a four-layer logic rule framework that provides mathematical guarantees for system reliability while maintaining flexibility. Unlike traditional rule-based systems, our logic rules are mathematical constraints that guide LLM reasoning rather than replacing it. We formalize the MultiVis task spanning four scenarios from basic generation to iterative refinement, and develop MultiVis-Bench, a benchmark with over 1,000 cases for multi-modal visualization evaluation. Extensive experiments demonstrate that our approach achieves 75.63% visualization score on challenging tasks, significantly outperforming baselines (57.54-62.79%), with task completion rates of 99.58% and code execution success rates of 94.56% (vs. 74.48% and 65.10% without logic rules), successfully addressing both complexity and reliability challenges in automated visualization generation.",
      "url": "http://arxiv.org/abs/2601.18320",
      "author": "Jinwei Lu, Yuanfeng Song, Chen Zhang, Raymond Chi-Wing Wong",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes MultiVis-Agent, logic rule-enhanced multi-agent framework for reliable multi-modal visualization generation with mathematical guarantees for system reliability.",
      "importance_score": 50,
      "reasoning": "Addresses real problem of LLM reliability in structured output tasks. Four-layer logic framework provides theoretical grounding but narrow application.",
      "themes": [
        "Multi-Agent Systems",
        "Data Visualization",
        "LLM Reliability"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes MultiVis-Agent, logic rule-enhanced multi-agent framework for reliable multi-modal visualization generation with mathematical guarantees for system reliability.</p>",
      "content_html": "<p>arXiv:2601.18320v1 Announce Type: cross  Abstract: Real-world visualization tasks involve complex, multi-modal requirements that extend beyond simple text-to-chart generation, requiring reference images, code examples, and iterative refinement. Current systems exhibit fundamental limitations: single-modality input, one-shot generation, and rigid workflows. While LLM-based approaches show potential for these complex requirements, they introduce reliability challenges including catastrophic failures and infinite loop susceptibility. To address this gap, we propose MultiVis-Agent, a logic rule-enhanced multi-agent framework for reliable multi-modal and multi-scenario visualization generation. Our approach introduces a four-layer logic rule framework that provides mathematical guarantees for system reliability while maintaining flexibility. Unlike traditional rule-based systems, our logic rules are mathematical constraints that guide LLM reasoning rather than replacing it. We formalize the MultiVis task spanning four scenarios from basic generation to iterative refinement, and develop MultiVis-Bench, a benchmark with over 1,000 cases for multi-modal visualization evaluation. Extensive experiments demonstrate that our approach achieves 75.63% visualization score on challenging tasks, significantly outperforming baselines (57.54-62.79%), with task completion rates of 99.58% and code execution success rates of 94.56% (vs. 74.48% and 65.10% without logic rules), successfully addressing both complexity and reliability challenges in automated visualization generation.</p>"
    },
    {
      "id": "e83c6fe1edef",
      "title": "GCFX: Generative Counterfactual Explanations for Deep Graph Models at the Model Level",
      "content": "arXiv:2601.18447v1 Announce Type: cross  Abstract: Deep graph learning models have demonstrated remarkable capabilities in processing graph-structured data and have been widely applied across various fields. However, their complex internal architectures and lack of transparency make it difficult to explain their decisions, resulting in opaque models that users find hard to understand and trust. In this paper, we explore model-level explanation techniques for deep graph learning models, aiming to provide users with a comprehensive understanding of the models' overall decision-making processes and underlying mechanisms. Specifically, we address the problem of counterfactual explanations for deep graph learning models by introducing a generative model-level counterfactual explanation approach called GCFX, which is based on deep graph generation. This approach generates a set of high-quality counterfactual explanations that reflect the model's global predictive behavior by leveraging an enhanced deep graph generation framework and a global summarization algorithm. GCFX features an architecture that combines dual encoders, structure-aware taggers, and Message Passing Neural Network decoders, enabling it to accurately learn the true latent distribution of input data and generate high-quality, closely related counterfactual examples. Subsequently, a global counterfactual summarization algorithm selects the most representative and comprehensive explanations from numerous candidate counterfactuals, providing broad insights into the model's global predictive patterns. Experiments on a synthetic dataset and several real-world datasets demonstrate that GCFX outperforms existing methods in terms of counterfactual validity and coverage while maintaining low explanation costs, thereby offering crucial support for enhancing the practicality and trustworthiness of global counterfactual explanations.",
      "url": "http://arxiv.org/abs/2601.18447",
      "author": "Jinlong Hu, Jiacheng Liu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces GCFX, generative approach for model-level counterfactual explanations of deep graph learning models, providing comprehensive understanding of overall decision-making processes.",
      "importance_score": 50,
      "reasoning": "Novel model-level (vs instance-level) explainability for graph models. Interesting direction but abstract lacks concrete evaluation details.",
      "themes": [
        "Explainability",
        "Graph Neural Networks",
        "Counterfactual Explanations"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces GCFX, generative approach for model-level counterfactual explanations of deep graph learning models, providing comprehensive understanding of overall decision-making processes.</p>",
      "content_html": "<p>arXiv:2601.18447v1 Announce Type: cross  Abstract: Deep graph learning models have demonstrated remarkable capabilities in processing graph-structured data and have been widely applied across various fields. However, their complex internal architectures and lack of transparency make it difficult to explain their decisions, resulting in opaque models that users find hard to understand and trust. In this paper, we explore model-level explanation techniques for deep graph learning models, aiming to provide users with a comprehensive understanding of the models' overall decision-making processes and underlying mechanisms. Specifically, we address the problem of counterfactual explanations for deep graph learning models by introducing a generative model-level counterfactual explanation approach called GCFX, which is based on deep graph generation. This approach generates a set of high-quality counterfactual explanations that reflect the model's global predictive behavior by leveraging an enhanced deep graph generation framework and a global summarization algorithm. GCFX features an architecture that combines dual encoders, structure-aware taggers, and Message Passing Neural Network decoders, enabling it to accurately learn the true latent distribution of input data and generate high-quality, closely related counterfactual examples. Subsequently, a global counterfactual summarization algorithm selects the most representative and comprehensive explanations from numerous candidate counterfactuals, providing broad insights into the model's global predictive patterns. Experiments on a synthetic dataset and several real-world datasets demonstrate that GCFX outperforms existing methods in terms of counterfactual validity and coverage while maintaining low explanation costs, thereby offering crucial support for enhancing the practicality and trustworthiness of global counterfactual explanations.</p>"
    },
    {
      "id": "50bbdb3b2743",
      "title": "Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation",
      "content": "arXiv:2601.18569v1 Announce Type: cross  Abstract: In this letter, we propose an Attention-Based Neural-Augmented Kalman Filter (AttenNKF) for state estimation in legged robots. Foot slip is a major source of estimation error: when slip occurs, kinematic measurements violate the no-slip assumption and inject bias during the update step. Our objective is to estimate this slip-induced error and compensate for it. To this end, we augment an Invariant Extended Kalman Filter (InEKF) with a neural compensator that uses an attention mechanism to infer error conditioned on foot-slip severity and then applies this estimate as a post-update compensation to the InEKF state (i.e., after the filter update). The compensator is trained in a latent space, which aims to reduce sensitivity to raw input scales and encourages structured slip-conditioned compensations, while preserving the InEKF recursion. Experiments demonstrate improved performance compared to existing legged-robot state estimators, particularly under slip-prone conditions.",
      "url": "http://arxiv.org/abs/2601.18569",
      "author": "Seokju Lee, Kyung-Soo Kim",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes AttenNKF, attention-based neural-augmented Kalman filter for legged robot state estimation that compensates for slip-induced errors through learned attention mechanism.",
      "importance_score": 50,
      "reasoning": "Practical robotics contribution combining classical estimation with neural networks. Addresses real problem but incremental advance.",
      "themes": [
        "Robotics",
        "State Estimation",
        "Neural-Augmented Methods"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes AttenNKF, attention-based neural-augmented Kalman filter for legged robot state estimation that compensates for slip-induced errors through learned attention mechanism.</p>",
      "content_html": "<p>arXiv:2601.18569v1 Announce Type: cross  Abstract: In this letter, we propose an Attention-Based Neural-Augmented Kalman Filter (AttenNKF) for state estimation in legged robots. Foot slip is a major source of estimation error: when slip occurs, kinematic measurements violate the no-slip assumption and inject bias during the update step. Our objective is to estimate this slip-induced error and compensate for it. To this end, we augment an Invariant Extended Kalman Filter (InEKF) with a neural compensator that uses an attention mechanism to infer error conditioned on foot-slip severity and then applies this estimate as a post-update compensation to the InEKF state (i.e., after the filter update). The compensator is trained in a latent space, which aims to reduce sensitivity to raw input scales and encourages structured slip-conditioned compensations, while preserving the InEKF recursion. Experiments demonstrate improved performance compared to existing legged-robot state estimators, particularly under slip-prone conditions.</p>"
    },
    {
      "id": "4c6d82f5dba7",
      "title": "Unheard in the Digital Age: Rethinking AI Bias and Speech Diversity",
      "content": "arXiv:2601.18641v1 Announce Type: cross  Abstract: Speech remains one of the most visible yet overlooked vectors of inclusion and exclusion in contemporary society. While fluency is often equated with credibility and competence, individuals with atypical speech patterns are routinely marginalized. Given the current state of the debate, this article focuses on the structural biases that shape perceptions of atypical speech and are now being encoded into artificial intelligence. Automated speech recognition (ASR) systems and voice interfaces, trained predominantly on standardized speech, routinely fail to recognize or respond to diverse voices, compounding digital exclusion. As AI technologies increasingly mediate access to opportunity, the study calls for inclusive technological design, anti-bias training to minimize the impact of discriminatory algorithmic decisions, and enforceable policy reform that explicitly recognize speech diversity as a matter of equity, not merely accessibility. Drawing on interdisciplinary research, the article advocates for a cultural and institutional shift in how we value voice, urging co-created solutions that elevate the rights, representation, and realities of atypical speakers in the digital age. Ultimately, the article reframes speech inclusion as a matter of equity (not accommodation) and advocates for co-created AI systems that reflect the full spectrum of human voices.",
      "url": "http://arxiv.org/abs/2601.18641",
      "author": "Onyedikachi Hope Amaechi-Okorie, Branislav Radeljic",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.HC"
      ],
      "summary": "Analyzes structural biases against atypical speech patterns being encoded into ASR systems, arguing that AI mediating access to opportunity compounds exclusion of diverse voices.",
      "importance_score": 50,
      "reasoning": "Important social issue but primarily commentary/position paper rather than technical research. Calls for inclusive design.",
      "themes": [
        "AI Bias",
        "Speech Recognition",
        "Accessibility",
        "AI Ethics"
      ],
      "continuation": null,
      "summary_html": "<p>Analyzes structural biases against atypical speech patterns being encoded into ASR systems, arguing that AI mediating access to opportunity compounds exclusion of diverse voices.</p>",
      "content_html": "<p>arXiv:2601.18641v1 Announce Type: cross  Abstract: Speech remains one of the most visible yet overlooked vectors of inclusion and exclusion in contemporary society. While fluency is often equated with credibility and competence, individuals with atypical speech patterns are routinely marginalized. Given the current state of the debate, this article focuses on the structural biases that shape perceptions of atypical speech and are now being encoded into artificial intelligence. Automated speech recognition (ASR) systems and voice interfaces, trained predominantly on standardized speech, routinely fail to recognize or respond to diverse voices, compounding digital exclusion. As AI technologies increasingly mediate access to opportunity, the study calls for inclusive technological design, anti-bias training to minimize the impact of discriminatory algorithmic decisions, and enforceable policy reform that explicitly recognize speech diversity as a matter of equity, not merely accessibility. Drawing on interdisciplinary research, the article advocates for a cultural and institutional shift in how we value voice, urging co-created solutions that elevate the rights, representation, and realities of atypical speakers in the digital age. Ultimately, the article reframes speech inclusion as a matter of equity (not accommodation) and advocates for co-created AI systems that reflect the full spectrum of human voices.</p>"
    },
    {
      "id": "1f1a148ae424",
      "title": "Optimal Use of Preferences in Artificial Intelligence Algorithms",
      "content": "arXiv:2601.18732v1 Announce Type: cross  Abstract: Machine learning systems embed preferences either in training losses or through post-processing of calibrated predictions. Applying information design methods from Strack and Yang (2024), this paper provides decision problem agnostic conditions under which separation training preference free and applying preferences ex post is optimal. Unlike prior work that requires specifying downstream objectives, the welfare results here apply uniformly across decision problems. The key primitive is a diminishing-value-of-information condition: relative to a fixed (normalised) preference-free loss, preference embedding makes informativeness less valuable at the margin, inducing a mean-preserving contraction of learned posteriors. Because the value of information is convex in beliefs, preference-free training weakly dominates for any expected utility decision problem. This provides theoretical foundations for modular AI pipelines that learn calibrated probabilities and implement asymmetric costs through downstream decision rules. However, separation requires users to implement optimal decision rules. When cognitive constraints bind, as documented in human AI decision-making, preference embedding can dominate by automating threshold computation. These results provide design guidance: preserve optionality through post-processing when objectives may shift; embed preferences when decision-stage frictions dominate.",
      "url": "http://arxiv.org/abs/2601.18732",
      "author": "Joshua S. Gans",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "econ.TH"
      ],
      "summary": "Applies information design methods to determine when separating preference-free training from post-processing preference application is optimal, introducing diminishing-value-of-information condition.",
      "importance_score": 50,
      "reasoning": "Theoretical framework for preference embedding in ML. Elegant connection to information design but practical implications unclear.",
      "themes": [
        "Preference Learning",
        "Information Design",
        "Theoretical ML"
      ],
      "continuation": null,
      "summary_html": "<p>Applies information design methods to determine when separating preference-free training from post-processing preference application is optimal, introducing diminishing-value-of-information condition.</p>",
      "content_html": "<p>arXiv:2601.18732v1 Announce Type: cross  Abstract: Machine learning systems embed preferences either in training losses or through post-processing of calibrated predictions. Applying information design methods from Strack and Yang (2024), this paper provides decision problem agnostic conditions under which separation training preference free and applying preferences ex post is optimal. Unlike prior work that requires specifying downstream objectives, the welfare results here apply uniformly across decision problems. The key primitive is a diminishing-value-of-information condition: relative to a fixed (normalised) preference-free loss, preference embedding makes informativeness less valuable at the margin, inducing a mean-preserving contraction of learned posteriors. Because the value of information is convex in beliefs, preference-free training weakly dominates for any expected utility decision problem. This provides theoretical foundations for modular AI pipelines that learn calibrated probabilities and implement asymmetric costs through downstream decision rules. However, separation requires users to implement optimal decision rules. When cognitive constraints bind, as documented in human AI decision-making, preference embedding can dominate by automating threshold computation. These results provide design guidance: preserve optionality through post-processing when objectives may shift; embed preferences when decision-stage frictions dominate.</p>"
    },
    {
      "id": "b626bf7271ce",
      "title": "A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning",
      "content": "arXiv:2601.16399v2 Announce Type: new  Abstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).",
      "url": "http://arxiv.org/abs/2601.16399",
      "author": "Sihan Zeng, Sujay Bhatt, Sumitra Ganesh, Alec Koppel",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Develops a single-loop, first-order actor-critic algorithm for bi-level optimization where the lower level is MDP policy optimization. Avoids expensive second-order methods and nested loops through penalty-based reformulation.",
      "importance_score": 50,
      "reasoning": "Addresses practical limitations of existing bi-level RL methods; solid theoretical contribution with practical algorithmic improvements.",
      "themes": [
        "Reinforcement Learning",
        "Bi-level Optimization",
        "Actor-Critic Methods"
      ],
      "continuation": null,
      "summary_html": "<p>Develops a single-loop, first-order actor-critic algorithm for bi-level optimization where the lower level is MDP policy optimization. Avoids expensive second-order methods and nested loops through penalty-based reformulation.</p>",
      "content_html": "<p>arXiv:2601.16399v2 Announce Type: new  Abstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).</p>"
    },
    {
      "id": "e8d0fd729933",
      "title": "On the Effects of Adversarial Perturbations on Distribution Robustness",
      "content": "arXiv:2601.16464v1 Announce Type: new  Abstract: Adversarial robustness refers to a model's ability to resist perturbation of inputs, while distribution robustness evaluates the performance of the model under data shifts. Although both aim to ensure reliable performance, prior work has revealed a tradeoff in distribution and adversarial robustness. Specifically, adversarial training might increase reliance on spurious features, which can harm distribution robustness, especially the performance on some underrepresented subgroups. We present a theoretical analysis of adversarial and distribution robustness that provides a tractable surrogate for per-step adversarial training by studying models trained on perturbed data. In addition to the tradeoff, our work further identified a nuanced phenomenon that $\\ell_\\infty$ perturbations on data with moderate bias can yield an increase in distribution robustness. Moreover, the gain in distribution robustness remains on highly skewed data when simplicity bias induces reliance on the core feature, characterized as greater feature separability. Our theoretical analysis extends the understanding of the tradeoff by highlighting the interplay of the tradeoff and the feature separability. Despite the tradeoff that persists in many cases, overlooking the role of feature separability may lead to misleading conclusions about robustness.",
      "url": "http://arxiv.org/abs/2601.16464",
      "author": "Yipei Wang, Zhaoying Pan, Xiaoqian Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Analyzes the tradeoff between adversarial robustness and distribution robustness. Shows adversarial training can increase reliance on spurious features but also identifies conditions where both types of robustness improve.",
      "importance_score": 50,
      "reasoning": "Addresses important tension in robustness research; provides both theoretical analysis and nuanced practical insights.",
      "themes": [
        "Adversarial Robustness",
        "Distribution Shift",
        "Robust Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Analyzes the tradeoff between adversarial robustness and distribution robustness. Shows adversarial training can increase reliance on spurious features but also identifies conditions where both types of robustness improve.</p>",
      "content_html": "<p>arXiv:2601.16464v1 Announce Type: new  Abstract: Adversarial robustness refers to a model's ability to resist perturbation of inputs, while distribution robustness evaluates the performance of the model under data shifts. Although both aim to ensure reliable performance, prior work has revealed a tradeoff in distribution and adversarial robustness. Specifically, adversarial training might increase reliance on spurious features, which can harm distribution robustness, especially the performance on some underrepresented subgroups. We present a theoretical analysis of adversarial and distribution robustness that provides a tractable surrogate for per-step adversarial training by studying models trained on perturbed data. In addition to the tradeoff, our work further identified a nuanced phenomenon that $\\ell_\\infty$ perturbations on data with moderate bias can yield an increase in distribution robustness. Moreover, the gain in distribution robustness remains on highly skewed data when simplicity bias induces reliance on the core feature, characterized as greater feature separability. Our theoretical analysis extends the understanding of the tradeoff by highlighting the interplay of the tradeoff and the feature separability. Despite the tradeoff that persists in many cases, overlooking the role of feature separability may lead to misleading conclusions about robustness.</p>"
    },
    {
      "id": "95353bdf17c7",
      "title": "A Cautionary Tale of Self-Supervised Learning for Imaging Biomarkers: Alzheimer's Disease Case Study",
      "content": "arXiv:2601.16467v1 Announce Type: new  Abstract: Discovery of sensitive and biologically grounded biomarkers is essential for early detection and monitoring of Alzheimer's disease (AD). Structural MRI is widely available but typically relies on hand-crafted features such as cortical thickness or volume. We ask whether self-supervised learning (SSL) can uncover more powerful biomarkers from the same data. Existing SSL methods underperform FreeSurfer-derived features in disease classification, conversion prediction, and amyloid status prediction. We introduce Residual Noise Contrastive Estimation (R-NCE), a new SSL framework that integrates auxiliary FreeSurfer features while maximizing additional augmentation-invariant information. R-NCE outperforms traditional features and existing SSL methods across multiple benchmarks, including AD conversion prediction. To assess biological relevance, we derive Brain Age Gap (BAG) measures and perform genome-wide association studies. R-NCE-BAG shows high heritability and associations with MAPT and IRAG1, with enrichment in astrocytes and oligodendrocytes, indicating sensitivity to neurodegenerative and cerebrovascular processes.",
      "url": "http://arxiv.org/abs/2601.16467",
      "author": "Maxwell Reynolds, Chaitanya Srinivasan, Vijay Cherupally, Michael Leone, Ke Yu, Li Sun, Tigmanshu Chaudhary, Andreas Pfenning, Kayhan Batmanghelich",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Finds that existing SSL methods underperform hand-crafted FreeSurfer features for Alzheimer's biomarkers. Introduces R-NCE framework that integrates FreeSurfer features while learning additional augmentation-invariant information.",
      "importance_score": 50,
      "reasoning": "Important cautionary finding about SSL in medical imaging; demonstrates value of domain knowledge integration.",
      "themes": [
        "Self-Supervised Learning",
        "Medical Imaging",
        "Alzheimer's Disease",
        "Biomarkers"
      ],
      "continuation": null,
      "summary_html": "<p>Finds that existing SSL methods underperform hand-crafted FreeSurfer features for Alzheimer's biomarkers. Introduces R-NCE framework that integrates FreeSurfer features while learning additional augmentation-invariant information.</p>",
      "content_html": "<p>arXiv:2601.16467v1 Announce Type: new  Abstract: Discovery of sensitive and biologically grounded biomarkers is essential for early detection and monitoring of Alzheimer's disease (AD). Structural MRI is widely available but typically relies on hand-crafted features such as cortical thickness or volume. We ask whether self-supervised learning (SSL) can uncover more powerful biomarkers from the same data. Existing SSL methods underperform FreeSurfer-derived features in disease classification, conversion prediction, and amyloid status prediction. We introduce Residual Noise Contrastive Estimation (R-NCE), a new SSL framework that integrates auxiliary FreeSurfer features while maximizing additional augmentation-invariant information. R-NCE outperforms traditional features and existing SSL methods across multiple benchmarks, including AD conversion prediction. To assess biological relevance, we derive Brain Age Gap (BAG) measures and perform genome-wide association studies. R-NCE-BAG shows high heritability and associations with MAPT and IRAG1, with enrichment in astrocytes and oligodendrocytes, indicating sensitivity to neurodegenerative and cerebrovascular processes.</p>"
    },
    {
      "id": "1af218c8783e",
      "title": "BoostFGL: Boosting Fairness in Federated Graph Learning",
      "content": "arXiv:2601.16496v1 Announce Type: new  Abstract: Federated graph learning (FGL) enables collaborative training of graph neural networks (GNNs) across decentralized subgraphs without exposing raw data. While existing FGL methods often achieve high overall accuracy, we show that this average performance can conceal severe degradation on disadvantaged node groups. From a fairness perspective, these disparities arise systematically from three coupled sources: label skew toward majority patterns, topology confounding in message propagation, and aggregation dilution of updates from hard clients. To address this, we propose \\textbf{BoostFGL}, a boosting-style framework for fairness-aware FGL. BoostFGL introduces three coordinated mechanisms: \\ding{182} \\emph{Client-side node boosting}, which reshapes local training signals to emphasize systematically under-served nodes; \\ding{183} \\emph{Client-side topology boosting}, which reallocates propagation emphasis toward reliable yet underused structures and attenuates misleading neighborhoods; and \\ding{184} \\emph{Server-side model boosting}, which performs difficulty- and reliability-aware aggregation to preserve informative updates from hard clients while stabilizing the global model. Extensive experiments on 9 datasets show that BoostFGL delivers substantial fairness gains, improving Overall-F1 by 8.43\\%, while preserving competitive overall performance against strong FGL baselines.",
      "url": "http://arxiv.org/abs/2601.16496",
      "author": "Zekai Chen, Kairui Yang, Xunkai Li, Henan Sun, Zhihan Zhang, Jia Li, Qiangqiang Dai, Rong-Hua Li, Guoren Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Addresses fairness in federated graph learning through BoostFGL framework. Identifies three sources of disparity: label skew, topology confounding, and aggregation dilution; proposes boosting-style mechanisms to address each.",
      "importance_score": 50,
      "reasoning": "Important intersection of federated learning and fairness; systematic analysis of disparity sources is valuable.",
      "themes": [
        "Federated Learning",
        "Graph Neural Networks",
        "Fairness",
        "Responsible AI"
      ],
      "continuation": null,
      "summary_html": "<p>Addresses fairness in federated graph learning through BoostFGL framework. Identifies three sources of disparity: label skew, topology confounding, and aggregation dilution; proposes boosting-style mechanisms to address each.</p>",
      "content_html": "<p>arXiv:2601.16496v1 Announce Type: new  Abstract: Federated graph learning (FGL) enables collaborative training of graph neural networks (GNNs) across decentralized subgraphs without exposing raw data. While existing FGL methods often achieve high overall accuracy, we show that this average performance can conceal severe degradation on disadvantaged node groups. From a fairness perspective, these disparities arise systematically from three coupled sources: label skew toward majority patterns, topology confounding in message propagation, and aggregation dilution of updates from hard clients. To address this, we propose \\textbf{BoostFGL}, a boosting-style framework for fairness-aware FGL. BoostFGL introduces three coordinated mechanisms: \\ding{182} \\emph{Client-side node boosting}, which reshapes local training signals to emphasize systematically under-served nodes; \\ding{183} \\emph{Client-side topology boosting}, which reallocates propagation emphasis toward reliable yet underused structures and attenuates misleading neighborhoods; and \\ding{184} \\emph{Server-side model boosting}, which performs difficulty- and reliability-aware aggregation to preserve informative updates from hard clients while stabilizing the global model. Extensive experiments on 9 datasets show that BoostFGL delivers substantial fairness gains, improving Overall-F1 by 8.43\\%, while preserving competitive overall performance against strong FGL baselines.</p>"
    },
    {
      "id": "0f948093fa49",
      "title": "Finite-Time Analysis of Gradient Descent for Shallow Transformers",
      "content": "arXiv:2601.16514v1 Announce Type: new  Abstract: Understanding why Transformers perform so well remains challenging due to their non-convex optimization landscape. In this work, we analyze a shallow Transformer with $m$ independent heads trained by projected gradient descent in the kernel regime. Our analysis reveals two main findings: (i) the width required for nonasymptotic guarantees scales only logarithmically with the sample size $n$, and (ii) the optimization error is independent of the sequence length $T$. This contrasts sharply with recurrent architectures, where the optimization error can grow exponentially with $T$. The trade-off is memory: to keep the full context, the Transformer's memory requirement grows with the sequence length. We validate our theoretical results numerically in a teacher-student setting and confirm the predicted scaling laws for Transformers.",
      "url": "http://arxiv.org/abs/2601.16514",
      "author": "Enes Arda, Semih Cayci, Atilla Eryilmaz",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Provides finite-time convergence analysis for shallow transformers trained with projected gradient descent. Shows width scales only logarithmically with sample size and optimization error is independent of sequence length.",
      "importance_score": 50,
      "reasoning": "Good theoretical contribution contrasting transformers with RNNs; provides non-asymptotic guarantees but limited to shallow case.",
      "themes": [
        "Transformer Theory",
        "Optimization",
        "Convergence Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Provides finite-time convergence analysis for shallow transformers trained with projected gradient descent. Shows width scales only logarithmically with sample size and optimization error is independent of sequence length.</p>",
      "content_html": "<p>arXiv:2601.16514v1 Announce Type: new  Abstract: Understanding why Transformers perform so well remains challenging due to their non-convex optimization landscape. In this work, we analyze a shallow Transformer with $m$ independent heads trained by projected gradient descent in the kernel regime. Our analysis reveals two main findings: (i) the width required for nonasymptotic guarantees scales only logarithmically with the sample size $n$, and (ii) the optimization error is independent of the sequence length $T$. This contrasts sharply with recurrent architectures, where the optimization error can grow exponentially with $T$. The trade-off is memory: to keep the full context, the Transformer's memory requirement grows with the sequence length. We validate our theoretical results numerically in a teacher-student setting and confirm the predicted scaling laws for Transformers.</p>"
    },
    {
      "id": "7c0ac8b01f35",
      "title": "Provably Robust Bayesian Counterfactual Explanations under Model Changes",
      "content": "arXiv:2601.16659v1 Announce Type: new  Abstract: Counterfactual explanations (CEs) offer interpretable insights into machine learning predictions by answering ``what if?\" questions. However, in real-world settings where models are frequently updated, existing counterfactual explanations can quickly become invalid or unreliable. In this paper, we introduce Probabilistically Safe CEs (PSCE), a method for generating counterfactual explanations that are $\\delta$-safe, to ensure high predictive confidence, and $\\epsilon$-robust to ensure low predictive variance. Based on Bayesian principles, PSCE provides formal probabilistic guarantees for CEs under model changes which are adhered to in what we refer to as the $\\langle \\delta, \\epsilon \\rangle$-set. Uncertainty-aware constraints are integrated into our optimization framework and we validate our method empirically across diverse datasets. We compare our approach against state-of-the-art Bayesian CE methods, where PSCE produces counterfactual explanations that are not only more plausible and discriminative, but also provably robust under model change.",
      "url": "http://arxiv.org/abs/2601.16659",
      "author": "Jamie Duell, Xiuyi Fan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces Probabilistically Safe Counterfactual Explanations (PSCE) with formal guarantees under model changes. Uses Bayesian principles to ensure CEs remain valid with -safety and -robustness.",
      "importance_score": 50,
      "reasoning": "Important for practical XAI deployment where models are frequently updated; provides formal guarantees lacking in prior work.",
      "themes": [
        "Explainability",
        "Counterfactual Explanations",
        "Bayesian Methods",
        "Robustness"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Probabilistically Safe Counterfactual Explanations (PSCE) with formal guarantees under model changes. Uses Bayesian principles to ensure CEs remain valid with -safety and -robustness.</p>",
      "content_html": "<p>arXiv:2601.16659v1 Announce Type: new  Abstract: Counterfactual explanations (CEs) offer interpretable insights into machine learning predictions by answering ``what if?\" questions. However, in real-world settings where models are frequently updated, existing counterfactual explanations can quickly become invalid or unreliable. In this paper, we introduce Probabilistically Safe CEs (PSCE), a method for generating counterfactual explanations that are $\\delta$-safe, to ensure high predictive confidence, and $\\epsilon$-robust to ensure low predictive variance. Based on Bayesian principles, PSCE provides formal probabilistic guarantees for CEs under model changes which are adhered to in what we refer to as the $\\langle \\delta, \\epsilon \\rangle$-set. Uncertainty-aware constraints are integrated into our optimization framework and we validate our method empirically across diverse datasets. We compare our approach against state-of-the-art Bayesian CE methods, where PSCE produces counterfactual explanations that are not only more plausible and discriminative, but also provably robust under model change.</p>"
    },
    {
      "id": "c7e9c324195a",
      "title": "Provably Learning Attention with Queries",
      "content": "arXiv:2601.16873v1 Announce Type: new  Abstract: We study the problem of learning Transformer-based sequence models with black-box access to their outputs. In this setting, a learner may adaptively query the oracle with any sequence of vectors and observe the corresponding real-valued output. We begin with the simplest case, a single-head softmax-attention regressor. We show that for a model with width $d$, there is an elementary algorithm to learn the parameters of single-head attention exactly with $O(d^2)$ queries. Further, we show that if there exists an algorithm to learn ReLU feedforward networks (FFNs), then the single-head algorithm can be easily adapted to learn one-layer Transformers with single-head attention. Next, motivated by the regime where the head dimension $r \\ll d$, we provide a randomised algorithm that learns single-head attention-based models with $O(rd)$ queries via compressed sensing arguments. We also study robustness to noisy oracle access, proving that under mild norm and margin conditions, the parameters can be estimated to $\\varepsilon$ accuracy with a polynomial number of queries even when outputs are only provided up to additive tolerance. Finally, we show that multi-head attention parameters are not identifiable from value queries in general -- distinct parameterisations can induce the same input-output map. Hence, guarantees analogous to the single-head setting are impossible without additional structural assumptions.",
      "url": "http://arxiv.org/abs/2601.16873",
      "author": "Satwik Bhattamishra, Kulin Shah, Michael Hahn, Varun Kanade",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Studies learning transformer parameters with black-box query access. Shows O(d) queries suffice for single-head attention; extends to multi-head with head dimension r << d.",
      "importance_score": 50,
      "reasoning": "Good theoretical contribution to understanding transformer learnability; practical implications for model extraction.",
      "themes": [
        "Transformer Theory",
        "Query Learning",
        "Model Extraction"
      ],
      "continuation": null,
      "summary_html": "<p>Studies learning transformer parameters with black-box query access. Shows O(d) queries suffice for single-head attention; extends to multi-head with head dimension r &lt;&lt; d.</p>",
      "content_html": "<p>arXiv:2601.16873v1 Announce Type: new  Abstract: We study the problem of learning Transformer-based sequence models with black-box access to their outputs. In this setting, a learner may adaptively query the oracle with any sequence of vectors and observe the corresponding real-valued output. We begin with the simplest case, a single-head softmax-attention regressor. We show that for a model with width $d$, there is an elementary algorithm to learn the parameters of single-head attention exactly with $O(d^2)$ queries. Further, we show that if there exists an algorithm to learn ReLU feedforward networks (FFNs), then the single-head algorithm can be easily adapted to learn one-layer Transformers with single-head attention. Next, motivated by the regime where the head dimension $r \\ll d$, we provide a randomised algorithm that learns single-head attention-based models with $O(rd)$ queries via compressed sensing arguments. We also study robustness to noisy oracle access, proving that under mild norm and margin conditions, the parameters can be estimated to $\\varepsilon$ accuracy with a polynomial number of queries even when outputs are only provided up to additive tolerance. Finally, we show that multi-head attention parameters are not identifiable from value queries in general -- distinct parameterisations can induce the same input-output map. Hence, guarantees analogous to the single-head setting are impossible without additional structural assumptions.</p>"
    },
    {
      "id": "8417c50bc5d4",
      "title": "Theory of Minimal Weight Perturbations in Deep Networks and its Applications for Low-Rank Activated Backdoor Attacks",
      "content": "arXiv:2601.16880v1 Announce Type: new  Abstract: The minimal norm weight perturbations of DNNs required to achieve a specified change in output are derived and the factors determining its size are discussed. These single-layer exact formulae are contrasted with more generic multi-layer Lipschitz constant based robustness guarantees; both are observed to be of the same order which indicates similar efficacy in their guarantees. These results are applied to precision-modification-activated backdoor attacks, establishing provable compression thresholds below which such attacks cannot succeed, and show empirically that low-rank compression can reliably activate latent backdoors while preserving full-precision accuracy. These expressions reveal how back-propagated margins govern layer-wise sensitivity and provide certifiable guarantees on the smallest parameter updates consistent with a desired output shift.",
      "url": "http://arxiv.org/abs/2601.16880",
      "author": "Bethan Evans, Jared Tanner",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Derives minimal norm weight perturbations needed to change DNN outputs; applies to backdoor attacks. Establishes provable compression thresholds below which precision-modification backdoors fail.",
      "importance_score": 50,
      "reasoning": "Important for AI security; provides theoretical foundations for both attacks and defenses against backdoors.",
      "themes": [
        "AI Security",
        "Backdoor Attacks",
        "Neural Network Robustness",
        "Model Compression"
      ],
      "continuation": null,
      "summary_html": "<p>Derives minimal norm weight perturbations needed to change DNN outputs; applies to backdoor attacks. Establishes provable compression thresholds below which precision-modification backdoors fail.</p>",
      "content_html": "<p>arXiv:2601.16880v1 Announce Type: new  Abstract: The minimal norm weight perturbations of DNNs required to achieve a specified change in output are derived and the factors determining its size are discussed. These single-layer exact formulae are contrasted with more generic multi-layer Lipschitz constant based robustness guarantees; both are observed to be of the same order which indicates similar efficacy in their guarantees. These results are applied to precision-modification-activated backdoor attacks, establishing provable compression thresholds below which such attacks cannot succeed, and show empirically that low-rank compression can reliably activate latent backdoors while preserving full-precision accuracy. These expressions reveal how back-propagated margins govern layer-wise sensitivity and provide certifiable guarantees on the smallest parameter updates consistent with a desired output shift.</p>"
    },
    {
      "id": "d7081c64ee9c",
      "title": "FedSGM: A Unified Framework for Constraint Aware, Bidirectionally Compressed, Multi-Step Federated Optimization",
      "content": "arXiv:2601.16897v1 Announce Type: new  Abstract: We introduce FedSGM, a unified framework for federated constrained optimization that addresses four major challenges in federated learning (FL): functional constraints, communication bottlenecks, local updates, and partial client participation. Building on the switching gradient method, FedSGM provides projection-free, primal-only updates, avoiding expensive dual-variable tuning or inner solvers. To handle communication limits, FedSGM incorporates bi-directional error feedback, correcting the bias introduced by compression while explicitly understanding the interaction between compression noise and multi-step local updates. We derive convergence guarantees showing that the averaged iterate achieves the canonical $\\boldsymbol{\\mathcal{O}}(1/\\sqrt{T})$ rate, with additional high-probability bounds that decouple optimization progress from sampling noise due to partial participation. Additionally, we introduce a soft switching version of FedSGM to stabilize updates near the feasibility boundary. To our knowledge, FedSGM is the first framework to unify functional constraints, compression, multiple local updates, and partial client participation, establishing a theoretically grounded foundation for constrained federated learning. Finally, we validate the theoretical guarantees of FedSGM via experimentation on Neyman-Pearson classification and constrained Markov decision process (CMDP) tasks.",
      "url": "http://arxiv.org/abs/2601.16897",
      "author": "Antesh Upadhyay, Sang Bin Moon, Abolfazl Hashemi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces FedSGM, a unified federated optimization framework addressing functional constraints, bidirectional compression, local updates, and partial participation. Provides convergence guarantees.",
      "importance_score": 50,
      "reasoning": "Comprehensive FL framework addressing multiple practical challenges simultaneously; strong theoretical analysis.",
      "themes": [
        "Federated Learning",
        "Constrained Optimization",
        "Communication Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces FedSGM, a unified federated optimization framework addressing functional constraints, bidirectional compression, local updates, and partial participation. Provides convergence guarantees.</p>",
      "content_html": "<p>arXiv:2601.16897v1 Announce Type: new  Abstract: We introduce FedSGM, a unified framework for federated constrained optimization that addresses four major challenges in federated learning (FL): functional constraints, communication bottlenecks, local updates, and partial client participation. Building on the switching gradient method, FedSGM provides projection-free, primal-only updates, avoiding expensive dual-variable tuning or inner solvers. To handle communication limits, FedSGM incorporates bi-directional error feedback, correcting the bias introduced by compression while explicitly understanding the interaction between compression noise and multi-step local updates. We derive convergence guarantees showing that the averaged iterate achieves the canonical $\\boldsymbol{\\mathcal{O}}(1/\\sqrt{T})$ rate, with additional high-probability bounds that decouple optimization progress from sampling noise due to partial participation. Additionally, we introduce a soft switching version of FedSGM to stabilize updates near the feasibility boundary. To our knowledge, FedSGM is the first framework to unify functional constraints, compression, multiple local updates, and partial client participation, establishing a theoretically grounded foundation for constrained federated learning. Finally, we validate the theoretical guarantees of FedSGM via experimentation on Neyman-Pearson classification and constrained Markov decision process (CMDP) tasks.</p>"
    },
    {
      "id": "9b7458739b4a",
      "title": "Is BatchEnsemble a Single Model? On Calibration and Diversity of Efficient Ensembles",
      "content": "arXiv:2601.16936v1 Announce Type: new  Abstract: In resource-constrained and low-latency settings, uncertainty estimates must be efficiently obtained. Deep Ensembles provide robust epistemic uncertainty (EU) but require training multiple full-size models. BatchEnsemble aims to deliver ensemble-like EU at far lower parameter and memory cost by applying learned rank-1 perturbations to a shared base network. We show that BatchEnsemble not only underperforms Deep Ensembles but closely tracks a single model baseline in terms of accuracy, calibration and out-of-distribution (OOD) detection on CIFAR10/10C/SVHN. A controlled study on MNIST finds members are near-identical in function and parameter space, indicating limited capacity to realize distinct predictive modes. Thus, BatchEnsemble behaves more like a single model than a true ensemble.",
      "url": "http://arxiv.org/abs/2601.16936",
      "author": "Anton Zamyatin, Patrick Indri, Sagar Malhotra, Thomas G\\\"artner",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Shows BatchEnsemble tracks single model baselines in accuracy, calibration, and OOD detection. Members are near-identical in function and parameter space, indicating limited capacity for diverse predictions.",
      "importance_score": 50,
      "reasoning": "Important negative result challenging assumptions about efficient ensembles; high practical relevance.",
      "themes": [
        "Uncertainty Quantification",
        "Ensemble Methods",
        "BatchEnsemble",
        "OOD Detection"
      ],
      "continuation": null,
      "summary_html": "<p>Shows BatchEnsemble tracks single model baselines in accuracy, calibration, and OOD detection. Members are near-identical in function and parameter space, indicating limited capacity for diverse predictions.</p>",
      "content_html": "<p>arXiv:2601.16936v1 Announce Type: new  Abstract: In resource-constrained and low-latency settings, uncertainty estimates must be efficiently obtained. Deep Ensembles provide robust epistemic uncertainty (EU) but require training multiple full-size models. BatchEnsemble aims to deliver ensemble-like EU at far lower parameter and memory cost by applying learned rank-1 perturbations to a shared base network. We show that BatchEnsemble not only underperforms Deep Ensembles but closely tracks a single model baseline in terms of accuracy, calibration and out-of-distribution (OOD) detection on CIFAR10/10C/SVHN. A controlled study on MNIST finds members are near-identical in function and parameter space, indicating limited capacity to realize distinct predictive modes. Thus, BatchEnsemble behaves more like a single model than a true ensemble.</p>"
    },
    {
      "id": "800139cd919c",
      "title": "3D Molecule Generation from Rigid Motifs via SE(3) Flows",
      "content": "arXiv:2601.16955v1 Announce Type: new  Abstract: Three-dimensional molecular structure generation is typically performed at the level of individual atoms, yet molecular graph generation techniques often consider fragments as their structural units. Building on the advances in frame-based protein structure generation, we extend these fragmentation ideas to 3D, treating general molecules as sets of rigid-body motifs. Utilising this representation, we employ SE(3)-equivariant generative modelling for de novo 3D molecule generation from rigid motifs. In our evaluations, we observe comparable or superior results to state-of-the-art across benchmarks, surpassing it in atom stability on GEOM-Drugs, while yielding a 2x to 10x reduction in generation steps and offering 3.5x compression in molecular representations compared to the standard atom-based methods.",
      "url": "http://arxiv.org/abs/2601.16955",
      "author": "Roman Poletukhin, Marcel Kollovieh, Eike Eberhard, Stephan G\\\"unnemann",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes SE(3)-equivariant flow-based generation for 3D molecules treating them as rigid-body motifs. Achieves 2-10x reduction in generation steps with 3.5x compression in molecular representation.",
      "importance_score": 50,
      "reasoning": "Efficient approach to molecular generation with good benchmark results; builds on established equivariant methods.",
      "themes": [
        "Molecular Generation",
        "Equivariant Networks",
        "Flow Models",
        "Drug Discovery"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes SE(3)-equivariant flow-based generation for 3D molecules treating them as rigid-body motifs. Achieves 2-10x reduction in generation steps with 3.5x compression in molecular representation.</p>",
      "content_html": "<p>arXiv:2601.16955v1 Announce Type: new  Abstract: Three-dimensional molecular structure generation is typically performed at the level of individual atoms, yet molecular graph generation techniques often consider fragments as their structural units. Building on the advances in frame-based protein structure generation, we extend these fragmentation ideas to 3D, treating general molecules as sets of rigid-body motifs. Utilising this representation, we employ SE(3)-equivariant generative modelling for de novo 3D molecule generation from rigid motifs. In our evaluations, we observe comparable or superior results to state-of-the-art across benchmarks, surpassing it in atom stability on GEOM-Drugs, while yielding a 2x to 10x reduction in generation steps and offering 3.5x compression in molecular representations compared to the standard atom-based methods.</p>"
    },
    {
      "id": "0cadc4310285",
      "title": "Better as Generators Than Classifiers: Leveraging LLMs and Synthetic Data for Low-Resource Multilingual Classification",
      "content": "arXiv:2601.16278v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable multilingual capabilities, making them promising tools in both high- and low-resource languages. One particularly valuable use case is generating synthetic samples that can be used to train smaller models in low-resource scenarios where human-labelled data is scarce. In this work, we investigate whether these synthetic data generation capabilities can serve as a form of distillation, producing smaller models that perform on par with or even better than massive LLMs across languages and tasks. To this end, we use a state-of-the-art multilingual LLM to generate synthetic datasets covering 11 languages and 4 classification tasks. These datasets are then used to train smaller models via fine-tuning or instruction tuning, or as synthetic in-context examples for compact LLMs. Our experiments show that even small amounts of synthetic data enable smaller models to outperform the large generator itself, particularly in low-resource languages. Overall, the results suggest that LLMs are best utilised as generators (teachers) rather than classifiers, producing data that empowers smaller and more efficient multilingual models.",
      "url": "http://arxiv.org/abs/2601.16278",
      "author": "Branislav Pecher, Jan Cegin, Robert Belanec, Ivan Srba, Jakub Simko, Maria Bielikova",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Shows LLMs are better as data generators than classifiers for low-resource multilingual scenarios. Synthetic data from LLMs trains smaller models that outperform LLM direct classification.",
      "importance_score": 50,
      "reasoning": "Practical insight for low-resource NLP; systematic evaluation across 11 languages and 4 tasks.",
      "themes": [
        "Large Language Models",
        "Synthetic Data",
        "Multilingual NLP",
        "Knowledge Distillation"
      ],
      "continuation": null,
      "summary_html": "<p>Shows LLMs are better as data generators than classifiers for low-resource multilingual scenarios. Synthetic data from LLMs trains smaller models that outperform LLM direct classification.</p>",
      "content_html": "<p>arXiv:2601.16278v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable multilingual capabilities, making them promising tools in both high- and low-resource languages. One particularly valuable use case is generating synthetic samples that can be used to train smaller models in low-resource scenarios where human-labelled data is scarce. In this work, we investigate whether these synthetic data generation capabilities can serve as a form of distillation, producing smaller models that perform on par with or even better than massive LLMs across languages and tasks. To this end, we use a state-of-the-art multilingual LLM to generate synthetic datasets covering 11 languages and 4 classification tasks. These datasets are then used to train smaller models via fine-tuning or instruction tuning, or as synthetic in-context examples for compact LLMs. Our experiments show that even small amounts of synthetic data enable smaller models to outperform the large generator itself, particularly in low-resource languages. Overall, the results suggest that LLMs are best utilised as generators (teachers) rather than classifiers, producing data that empowers smaller and more efficient multilingual models.</p>"
    },
    {
      "id": "ee3f6955d155",
      "title": "Memory-V2V: Augmenting Video-to-Video Diffusion Models with Memory",
      "content": "arXiv:2601.16296v1 Announce Type: cross  Abstract: Recent foundational video-to-video diffusion models have achieved impressive results in editing user provided videos by modifying appearance, motion, or camera movement. However, real-world video editing is often an iterative process, where users refine results across multiple rounds of interaction. In this multi-turn setting, current video editors struggle to maintain cross-consistency across sequential edits. In this work, we tackle, for the first time, the problem of cross-consistency in multi-turn video editing and introduce Memory-V2V, a simple, yet effective framework that augments existing video-to-video models with explicit memory. Given an external cache of previously edited videos, Memory-V2V employs accurate retrieval and dynamic tokenization strategies to condition the current editing step on prior results. To further mitigate redundancy and computational overhead, we propose a learnable token compressor within the DiT backbone that compresses redundant conditioning tokens while preserving essential visual cues, achieving an overall speedup of 30%. We validate Memory-V2V on challenging tasks including video novel view synthesis and text-conditioned long video editing. Extensive experiments show that Memory-V2V produces videos that are significantly more cross-consistent with minimal computational overhead, while maintaining or even improving task-specific performance over state-of-the-art baselines. Project page: https://dohunlee1.github.io/MemoryV2V",
      "url": "http://arxiv.org/abs/2601.16296",
      "author": "Dohun Lee, Chun-Hao Paul Huang, Xuelin Chen, Jong Chul Ye, Duygu Ceylan, Hyeonho Jeong",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces Memory-V2V for cross-consistency in multi-turn video editing. Uses external cache of previously edited videos with accurate retrieval and dynamic blending.",
      "importance_score": 50,
      "reasoning": "Novel problem formulation for iterative video editing; practical solution to real user workflow challenges.",
      "themes": [
        "Video Generation",
        "Video Editing",
        "Diffusion Models",
        "Memory Networks"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Memory-V2V for cross-consistency in multi-turn video editing. Uses external cache of previously edited videos with accurate retrieval and dynamic blending.</p>",
      "content_html": "<p>arXiv:2601.16296v1 Announce Type: cross  Abstract: Recent foundational video-to-video diffusion models have achieved impressive results in editing user provided videos by modifying appearance, motion, or camera movement. However, real-world video editing is often an iterative process, where users refine results across multiple rounds of interaction. In this multi-turn setting, current video editors struggle to maintain cross-consistency across sequential edits. In this work, we tackle, for the first time, the problem of cross-consistency in multi-turn video editing and introduce Memory-V2V, a simple, yet effective framework that augments existing video-to-video models with explicit memory. Given an external cache of previously edited videos, Memory-V2V employs accurate retrieval and dynamic tokenization strategies to condition the current editing step on prior results. To further mitigate redundancy and computational overhead, we propose a learnable token compressor within the DiT backbone that compresses redundant conditioning tokens while preserving essential visual cues, achieving an overall speedup of 30%. We validate Memory-V2V on challenging tasks including video novel view synthesis and text-conditioned long video editing. Extensive experiments show that Memory-V2V produces videos that are significantly more cross-consistent with minimal computational overhead, while maintaining or even improving task-specific performance over state-of-the-art baselines. Project page: https://dohunlee1.github.io/MemoryV2V</p>"
    },
    {
      "id": "34d5e2c7d4a7",
      "title": "Curate-Train-Refine: A Closed-Loop Agentic Framework for Zero Shot Classification",
      "content": "arXiv:2601.16530v1 Announce Type: cross  Abstract: Large language models (LLMs) and high-capacity encoders have advanced zero and few-shot classification, but their inference cost and latency limit practical deployment. We propose training lightweight text classifiers using dynamically generated supervision from an LLM. Our method employs an iterative, agentic loop in which the LLM curates training data, analyzes model successes and failures, and synthesizes targeted examples to address observed errors. This closed-loop generation and evaluation process progressively improves data quality and adapts it to the downstream classifier and task. Across four widely used benchmarks, our approach consistently outperforms standard zero and few-shot baselines. These results indicate that LLMs can serve effectively as data curators, enabling accurate and efficient classification without the operational cost of large-model deployment.",
      "url": "http://arxiv.org/abs/2601.16530",
      "author": "Gaurav Maheshwari, Kevin El Haddad",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes agentic loop where LLM curates training data, analyzes errors, and synthesizes targeted examples for lightweight text classifiers. Outperforms zero/few-shot baselines across four benchmarks.",
      "importance_score": 50,
      "reasoning": "Practical framework for LLM-guided classifier training; shows iterative refinement improves data quality.",
      "themes": [
        "Large Language Models",
        "Text Classification",
        "Synthetic Data",
        "Agentic AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes agentic loop where LLM curates training data, analyzes errors, and synthesizes targeted examples for lightweight text classifiers. Outperforms zero/few-shot baselines across four benchmarks.</p>",
      "content_html": "<p>arXiv:2601.16530v1 Announce Type: cross  Abstract: Large language models (LLMs) and high-capacity encoders have advanced zero and few-shot classification, but their inference cost and latency limit practical deployment. We propose training lightweight text classifiers using dynamically generated supervision from an LLM. Our method employs an iterative, agentic loop in which the LLM curates training data, analyzes model successes and failures, and synthesizes targeted examples to address observed errors. This closed-loop generation and evaluation process progressively improves data quality and adapts it to the downstream classifier and task. Across four widely used benchmarks, our approach consistently outperforms standard zero and few-shot baselines. These results indicate that LLMs can serve effectively as data curators, enabling accurate and efficient classification without the operational cost of large-model deployment.</p>"
    },
    {
      "id": "48631802f612",
      "title": "I Guess That's Why They Call it the Blues: Causal Analysis for Audio Classifiers",
      "content": "arXiv:2601.16675v1 Announce Type: cross  Abstract: It is well-known that audio classifiers often rely on non-musically relevant features and spurious correlations to classify audio. Hence audio classifiers are easy to manipulate or confuse, resulting in wrong classifications. While inducing a misclassification is not hard, until now the set of features that the classifiers rely on was not well understood.   In this paper we introduce a new method that uses causal reasoning to discover features of the frequency space that are sufficient and necessary for a given classification. We describe an implementation of this algorithm in the tool FreqReX and provide experimental results on a number of standard benchmark datasets. Our experiments show that causally sufficient and necessary subsets allow us to manipulate the outputs of the models in a variety of ways by changing the input very slightly. Namely, a change to one out of 240,000 frequencies results in a change in classification 58% of the time, and the change can be so small that it is practically inaudible. These results show that causal analysis is useful for understanding the reasoning process of audio classifiers and can be used to successfully manipulate their outputs.",
      "url": "http://arxiv.org/abs/2601.16675",
      "author": "David A. Kelly, Hana Chockler",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.SD"
      ],
      "summary": "Introduces FreqReX tool using causal reasoning to discover frequency-space features sufficient and necessary for audio classification. Shows causal features align across different model architectures.",
      "importance_score": 50,
      "reasoning": "Important contribution to audio classifier interpretability; causal approach provides stronger guarantees than correlational methods.",
      "themes": [
        "Audio Classification",
        "Causal Reasoning",
        "Interpretability",
        "Music AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces FreqReX tool using causal reasoning to discover frequency-space features sufficient and necessary for audio classification. Shows causal features align across different model architectures.</p>",
      "content_html": "<p>arXiv:2601.16675v1 Announce Type: cross  Abstract: It is well-known that audio classifiers often rely on non-musically relevant features and spurious correlations to classify audio. Hence audio classifiers are easy to manipulate or confuse, resulting in wrong classifications. While inducing a misclassification is not hard, until now the set of features that the classifiers rely on was not well understood.   In this paper we introduce a new method that uses causal reasoning to discover features of the frequency space that are sufficient and necessary for a given classification. We describe an implementation of this algorithm in the tool FreqReX and provide experimental results on a number of standard benchmark datasets. Our experiments show that causally sufficient and necessary subsets allow us to manipulate the outputs of the models in a variety of ways by changing the input very slightly. Namely, a change to one out of 240,000 frequencies results in a change in classification 58% of the time, and the change can be so small that it is practically inaudible. These results show that causal analysis is useful for understanding the reasoning process of audio classifiers and can be used to successfully manipulate their outputs.</p>"
    },
    {
      "id": "20a0d291ce1d",
      "title": "BanglaRobustNet: A Hybrid Denoising-Attention Architecture for Robust Bangla Speech Recognition",
      "content": "arXiv:2601.17679v1 Announce Type: cross  Abstract: Bangla, one of the most widely spoken languages, remains underrepresented in state-of-the-art automatic speech recognition (ASR) research, particularly under noisy and speaker-diverse conditions. This paper presents BanglaRobustNet, a hybrid denoising-attention framework built on Wav2Vec-BERT, designed to address these challenges. The architecture integrates a diffusion-based denoising module to suppress environmental noise while preserving Bangla-specific phonetic cues, and a contextual cross-attention module that conditions recognition on speaker embeddings for robustness across gender, age, and dialects. Trained end-to-end with a composite objective combining CTC loss, phonetic consistency, and speaker alignment, BanglaRobustNet achieves substantial reductions in word error rate (WER) and character error rate (CER) compared to Wav2Vec-BERT and Whisper baselines. Evaluations on Mozilla Common Voice Bangla and augmented noisy speech confirm the effectiveness of our approach, establishing BanglaRobustNet as a robust ASR system tailored to low-resource, noise-prone linguistic settings.",
      "url": "http://arxiv.org/abs/2601.17679",
      "author": "Md Sazzadul Islam Ridoy, Mubaswira Ibnat Zidney, Sumi Akter, Md. Aminur Rahman",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.SD"
      ],
      "summary": "Presents BanglaRobustNet, a hybrid denoising-attention framework for Bangla speech recognition that integrates diffusion-based denoising with speaker-embedding conditioning for robustness across demographics.",
      "importance_score": 50,
      "reasoning": "Addresses underrepresented language ASR but primarily application-focused rather than methodologically novel.",
      "themes": [
        "Speech Recognition",
        "Low-resource Languages",
        "Robustness"
      ],
      "continuation": null,
      "summary_html": "<p>Presents BanglaRobustNet, a hybrid denoising-attention framework for Bangla speech recognition that integrates diffusion-based denoising with speaker-embedding conditioning for robustness across demographics.</p>",
      "content_html": "<p>arXiv:2601.17679v1 Announce Type: cross  Abstract: Bangla, one of the most widely spoken languages, remains underrepresented in state-of-the-art automatic speech recognition (ASR) research, particularly under noisy and speaker-diverse conditions. This paper presents BanglaRobustNet, a hybrid denoising-attention framework built on Wav2Vec-BERT, designed to address these challenges. The architecture integrates a diffusion-based denoising module to suppress environmental noise while preserving Bangla-specific phonetic cues, and a contextual cross-attention module that conditions recognition on speaker embeddings for robustness across gender, age, and dialects. Trained end-to-end with a composite objective combining CTC loss, phonetic consistency, and speaker alignment, BanglaRobustNet achieves substantial reductions in word error rate (WER) and character error rate (CER) compared to Wav2Vec-BERT and Whisper baselines. Evaluations on Mozilla Common Voice Bangla and augmented noisy speech confirm the effectiveness of our approach, establishing BanglaRobustNet as a robust ASR system tailored to low-resource, noise-prone linguistic settings.</p>"
    },
    {
      "id": "1bfaa559fbca",
      "title": "Noise-Robust AV-ASR Using Visual Features Both in the Whisper Encoder and Decoder",
      "content": "arXiv:2601.18396v1 Announce Type: cross  Abstract: In audiovisual automatic speech recognition (AV-ASR) systems, information fusion of visual features in a pre-trained ASR has been proven as a promising method to improve noise robustness. In this work, based on the prominent Whisper ASR, first, we propose a simple and effective visual fusion method -- use of visual features both in encoder and decoder (dual-use) -- to learn the audiovisual interactions in the encoder and to weigh modalities in the decoder. Second, we compare visual fusion methods in Whisper models of various sizes. Our proposed dual-use method shows consistent noise robustness improvement, e.g., a 35% relative improvement (WER: 4.41% vs. 6.83%) based on Whisper small, and a 57% relative improvement (WER: 4.07% vs. 9.53%) based on Whisper medium, compared to typical reference middle fusion in babble noise with a signal-to-noise ratio (SNR) of 0dB. Third, we conduct ablation studies examining the impact of various module designs and fusion options. Fine-tuned on 1929 hours of audiovisual data, our dual-use method using Whisper medium achieves 4.08% (MUSAN babble noise) and 4.43% (NoiseX babble noise) average WER across various SNRs, thereby establishing a new state-of-the-art in noisy conditions on the LRS3 AV-ASR benchmark. Our code is at https://github.com/ifnspaml/Dual-Use-AVASR",
      "url": "http://arxiv.org/abs/2601.18396",
      "author": "Zhengyang Li, Thomas Graave, Bj\\\"orn M\\\"oller, Zehang Wu, Matthias Franz, Tim Fingscheidt",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "eess.AS"
      ],
      "summary": "Proposes dual-use of visual features in both Whisper encoder and decoder for noise-robust audio-visual ASR, achieving 35-57% relative WER improvements.",
      "importance_score": 50,
      "reasoning": "Straightforward improvement to existing AV-ASR with good empirical results but limited novelty.",
      "themes": [
        "Speech Recognition",
        "Multimodal Learning",
        "Robustness"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes dual-use of visual features in both Whisper encoder and decoder for noise-robust audio-visual ASR, achieving 35-57% relative WER improvements.</p>",
      "content_html": "<p>arXiv:2601.18396v1 Announce Type: cross  Abstract: In audiovisual automatic speech recognition (AV-ASR) systems, information fusion of visual features in a pre-trained ASR has been proven as a promising method to improve noise robustness. In this work, based on the prominent Whisper ASR, first, we propose a simple and effective visual fusion method -- use of visual features both in encoder and decoder (dual-use) -- to learn the audiovisual interactions in the encoder and to weigh modalities in the decoder. Second, we compare visual fusion methods in Whisper models of various sizes. Our proposed dual-use method shows consistent noise robustness improvement, e.g., a 35% relative improvement (WER: 4.41% vs. 6.83%) based on Whisper small, and a 57% relative improvement (WER: 4.07% vs. 9.53%) based on Whisper medium, compared to typical reference middle fusion in babble noise with a signal-to-noise ratio (SNR) of 0dB. Third, we conduct ablation studies examining the impact of various module designs and fusion options. Fine-tuned on 1929 hours of audiovisual data, our dual-use method using Whisper medium achieves 4.08% (MUSAN babble noise) and 4.43% (NoiseX babble noise) average WER across various SNRs, thereby establishing a new state-of-the-art in noisy conditions on the LRS3 AV-ASR benchmark. Our code is at https://github.com/ifnspaml/Dual-Use-AVASR</p>"
    },
    {
      "id": "bbc34f651ff6",
      "title": "Structural Complexity of Brain MRI reveals age-associated patterns",
      "content": "arXiv:2601.17211v1 Announce Type: new  Abstract: We adapt structural complexity analysis to three-dimensional signals, with an emphasis on brain magnetic resonance imaging (MRI). This framework captures the multiscale organization of volumetric data by coarse-graining the signal at progressively larger spatial scales and quantifying the information lost between successive resolutions. While the traditional block-based approach can become unstable at coarse resolutions due to limited sampling, we introduce a sliding-window coarse-graining scheme that provides smoother estimates and improved robustness at large scales. Using this refined method, we analyze large structural MRI datasets spanning mid- to late adulthood and find that structural complexity decreases systematically with age, with the strongest effects emerging at coarser scales. These findings highlight structural complexity as a reliable signal processing tool for multiscale analysis of 3D imaging data, while also demonstrating its utility in predicting biological age from brain MRI.",
      "url": "http://arxiv.org/abs/2601.17211",
      "author": "Anzhe Cheng, Italo Ivo Lima Dias Pinto, Paul Bogdan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Adapts structural complexity analysis to 3D brain MRI, finding systematic decrease in structural complexity with age using sliding-window coarse-graining scheme.",
      "importance_score": 50,
      "reasoning": "Novel application of complexity analysis to neuroimaging with interesting aging findings.",
      "themes": [
        "Medical Imaging",
        "Neuroscience",
        "Aging"
      ],
      "continuation": null,
      "summary_html": "<p>Adapts structural complexity analysis to 3D brain MRI, finding systematic decrease in structural complexity with age using sliding-window coarse-graining scheme.</p>",
      "content_html": "<p>arXiv:2601.17211v1 Announce Type: new  Abstract: We adapt structural complexity analysis to three-dimensional signals, with an emphasis on brain magnetic resonance imaging (MRI). This framework captures the multiscale organization of volumetric data by coarse-graining the signal at progressively larger spatial scales and quantifying the information lost between successive resolutions. While the traditional block-based approach can become unstable at coarse resolutions due to limited sampling, we introduce a sliding-window coarse-graining scheme that provides smoother estimates and improved robustness at large scales. Using this refined method, we analyze large structural MRI datasets spanning mid- to late adulthood and find that structural complexity decreases systematically with age, with the strongest effects emerging at coarser scales. These findings highlight structural complexity as a reliable signal processing tool for multiscale analysis of 3D imaging data, while also demonstrating its utility in predicting biological age from brain MRI.</p>"
    },
    {
      "id": "8b25eeb832f7",
      "title": "Fluxamba: Topology-Aware Anisotropic State Space Models for Geological Lineament Segmentation in Multi-Source Remote Sensing",
      "content": "arXiv:2601.17288v1 Announce Type: new  Abstract: The precise segmentation of geological linear features, spanning from planetary lineaments to terrestrial fractures, demands capturing long-range dependencies across complex anisotropic topologies. Although State Space Models (SSMs) offer near-linear computational complexity, their dependence on rigid, axis-aligned scanning trajectories induces a fundamental topological mismatch with curvilinear targets, resulting in fragmented context and feature erosion. To bridge this gap, we propose Fluxamba, a lightweight architecture that introduces a topology-aware feature rectification framework. Central to our design is the Structural Flux Block (SFB), which orchestrates an anisotropic information flux by integrating an Anisotropic Structural Gate (ASG) with a Prior-Modulated Flow (PMF). This mechanism decouples feature orientation from spatial location, dynamically gating context aggregation along the target's intrinsic geometry rather than rigid paths. Furthermore, to mitigate serialization-induced noise in low-contrast environments, we incorporate a Hierarchical Spatial Regulator (HSR) for multi-scale semantic alignment and a High-Fidelity Focus Unit (HFFU) to explicitly maximize the signal-to-noise ratio of faint features. Extensive experiments on diverse geological benchmarks (LROC-Lineament, LineaMapper, and GeoCrack) demonstrate that Fluxamba establishes a new state-of-the-art. Notably, on the challenging LROC-Lineament dataset, it achieves an F1-score of 89.22% and mIoU of 89.87%. Achieving a real-time inference speed of over 24 FPS with only 3.4M parameters and 6.3G FLOPs, Fluxamba reduces computational costs by up to two orders of magnitude compared to heavy-weight baselines, thereby establishing a new Pareto frontier between segmentation fidelity and onboard deployment feasibility.",
      "url": "http://arxiv.org/abs/2601.17288",
      "author": "Jin Bai, Huiyao Zhang, Qi Wen, Shengyang Li, Xiaolin Tian, Atta ur Rahman",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes Fluxamba for geological lineament segmentation using topology-aware feature rectification with Structural Flux Block for anisotropic information flow, addressing SSM limitations for curvilinear targets.",
      "importance_score": 50,
      "reasoning": "Domain-specific adaptation of state space models for remote sensing with novel topology-aware design.",
      "themes": [
        "Remote Sensing",
        "Segmentation",
        "State Space Models"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Fluxamba for geological lineament segmentation using topology-aware feature rectification with Structural Flux Block for anisotropic information flow, addressing SSM limitations for curvilinear targets.</p>",
      "content_html": "<p>arXiv:2601.17288v1 Announce Type: new  Abstract: The precise segmentation of geological linear features, spanning from planetary lineaments to terrestrial fractures, demands capturing long-range dependencies across complex anisotropic topologies. Although State Space Models (SSMs) offer near-linear computational complexity, their dependence on rigid, axis-aligned scanning trajectories induces a fundamental topological mismatch with curvilinear targets, resulting in fragmented context and feature erosion. To bridge this gap, we propose Fluxamba, a lightweight architecture that introduces a topology-aware feature rectification framework. Central to our design is the Structural Flux Block (SFB), which orchestrates an anisotropic information flux by integrating an Anisotropic Structural Gate (ASG) with a Prior-Modulated Flow (PMF). This mechanism decouples feature orientation from spatial location, dynamically gating context aggregation along the target's intrinsic geometry rather than rigid paths. Furthermore, to mitigate serialization-induced noise in low-contrast environments, we incorporate a Hierarchical Spatial Regulator (HSR) for multi-scale semantic alignment and a High-Fidelity Focus Unit (HFFU) to explicitly maximize the signal-to-noise ratio of faint features. Extensive experiments on diverse geological benchmarks (LROC-Lineament, LineaMapper, and GeoCrack) demonstrate that Fluxamba establishes a new state-of-the-art. Notably, on the challenging LROC-Lineament dataset, it achieves an F1-score of 89.22% and mIoU of 89.87%. Achieving a real-time inference speed of over 24 FPS with only 3.4M parameters and 6.3G FLOPs, Fluxamba reduces computational costs by up to two orders of magnitude compared to heavy-weight baselines, thereby establishing a new Pareto frontier between segmentation fidelity and onboard deployment feasibility.</p>"
    },
    {
      "id": "f9bd165e6bac",
      "title": "Learning with Geometric Priors in U-Net Variants for Polyp Segmentation",
      "content": "arXiv:2601.17331v1 Announce Type: new  Abstract: Accurate and robust polyp segmentation is essential for early colorectal cancer detection and for computer-aided diagnosis. While convolutional neural network-, Transformer-, and Mamba-based U-Net variants have achieved strong performance, they still struggle to capture geometric and structural cues, especially in low-contrast or cluttered colonoscopy scenes. To address this challenge, we propose a novel Geometric Prior-guided Module (GPM) that injects explicit geometric priors into U-Net-based architectures for polyp segmentation. Specifically, we fine-tune the Visual Geometry Grounded Transformer (VGGT) on a simulated ColonDepth dataset to estimate depth maps of polyp images tailored to the endoscopic domain. These depth maps are then processed by GPM to encode geometric priors into the encoder's feature maps, where they are further refined using spatial and channel attention mechanisms that emphasize both local spatial and global channel information. GPM is plug-and-play and can be seamlessly integrated into diverse U-Net variants. Extensive experiments on five public polyp segmentation datasets demonstrate consistent gains over three strong baselines. Code and the generated depth maps are available at: https://github.com/fvazqu/GPM-PolypSeg",
      "url": "http://arxiv.org/abs/2601.17331",
      "author": "Fabian Vazquez, Jose A. Nu\\~nez, Diego Adame, Alissen Moreno, Augustin Zhan, Huimin Li, Jinghao Yang, Haoteng Tang, Bin Fu, Pengfei Gu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes Geometric Prior-guided Module (GPM) injecting explicit geometric priors into U-Net variants for polyp segmentation, using fine-tuned VGGT for depth estimation from colonoscopy images.",
      "importance_score": 50,
      "reasoning": "Practical medical imaging improvement using geometric priors but incremental contribution.",
      "themes": [
        "Medical Image Segmentation",
        "Polyp Detection",
        "Geometric Priors"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Geometric Prior-guided Module (GPM) injecting explicit geometric priors into U-Net variants for polyp segmentation, using fine-tuned VGGT for depth estimation from colonoscopy images.</p>",
      "content_html": "<p>arXiv:2601.17331v1 Announce Type: new  Abstract: Accurate and robust polyp segmentation is essential for early colorectal cancer detection and for computer-aided diagnosis. While convolutional neural network-, Transformer-, and Mamba-based U-Net variants have achieved strong performance, they still struggle to capture geometric and structural cues, especially in low-contrast or cluttered colonoscopy scenes. To address this challenge, we propose a novel Geometric Prior-guided Module (GPM) that injects explicit geometric priors into U-Net-based architectures for polyp segmentation. Specifically, we fine-tune the Visual Geometry Grounded Transformer (VGGT) on a simulated ColonDepth dataset to estimate depth maps of polyp images tailored to the endoscopic domain. These depth maps are then processed by GPM to encode geometric priors into the encoder's feature maps, where they are further refined using spatial and channel attention mechanisms that emphasize both local spatial and global channel information. GPM is plug-and-play and can be seamlessly integrated into diverse U-Net variants. Extensive experiments on five public polyp segmentation datasets demonstrate consistent gains over three strong baselines. Code and the generated depth maps are available at: https://github.com/fvazqu/GPM-PolypSeg</p>"
    },
    {
      "id": "333209795f63",
      "title": "Revisiting Lightweight Low-Light Image Enhancement: From a YUV Color Space Perspective",
      "content": "arXiv:2601.17349v1 Announce Type: new  Abstract: In the current era of mobile internet, Lightweight Low-Light Image Enhancement (L3IE) is critical for mobile devices, which faces a persistent trade-off between visual quality and model compactness. While recent methods employ disentangling strategies to simplify lightweight architectural design, such as Retinex theory and YUV color space transformations, their performance is fundamentally limited by overlooking channel-specific degradation patterns and cross-channel interactions. To address this gap, we perform a frequency-domain analysis that confirms the superiority of the YUV color space for L3IE. We identify a key insight: the Y channel primarily loses low-frequency content, while the UV channels are corrupted by high-frequency noise. Leveraging this finding, we propose a novel YUV-based paradigm that strategically restores channels using a Dual-Stream Global-Local Attention module for the Y channel, a Y-guided Local-Aware Frequency Attention module for the UV channels, and a Guided Interaction module for final feature fusion. Extensive experiments validate that our model establishes a new state-of-the-art on multiple benchmarks, delivering superior visual quality with a significantly lower parameter count.",
      "url": "http://arxiv.org/abs/2601.17349",
      "author": "Hailong Yan, Shice Liu, Xiangtao Zhang, Lujian Yao, Fengxiang Yang, Jinwei Chen, Bo Li",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes lightweight low-light image enhancement from YUV color space perspective, identifying that Y channel loses low-frequency content while UV channels corrupted by high-frequency noise.",
      "importance_score": 50,
      "reasoning": "Frequency-domain analysis provides useful insights for lightweight enhancement but incremental contribution.",
      "themes": [
        "Low-Light Enhancement",
        "Image Processing",
        "Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes lightweight low-light image enhancement from YUV color space perspective, identifying that Y channel loses low-frequency content while UV channels corrupted by high-frequency noise.</p>",
      "content_html": "<p>arXiv:2601.17349v1 Announce Type: new  Abstract: In the current era of mobile internet, Lightweight Low-Light Image Enhancement (L3IE) is critical for mobile devices, which faces a persistent trade-off between visual quality and model compactness. While recent methods employ disentangling strategies to simplify lightweight architectural design, such as Retinex theory and YUV color space transformations, their performance is fundamentally limited by overlooking channel-specific degradation patterns and cross-channel interactions. To address this gap, we perform a frequency-domain analysis that confirms the superiority of the YUV color space for L3IE. We identify a key insight: the Y channel primarily loses low-frequency content, while the UV channels are corrupted by high-frequency noise. Leveraging this finding, we propose a novel YUV-based paradigm that strategically restores channels using a Dual-Stream Global-Local Attention module for the Y channel, a Y-guided Local-Aware Frequency Attention module for the UV channels, and a Guided Interaction module for final feature fusion. Extensive experiments validate that our model establishes a new state-of-the-art on multiple benchmarks, delivering superior visual quality with a significantly lower parameter count.</p>"
    },
    {
      "id": "13afdc4cb5c9",
      "title": "SMV-EAR: Bring Spatiotemporal Multi-View Representation Learning into Efficient Event-Based Action Recognition",
      "content": "arXiv:2601.17391v1 Announce Type: new  Abstract: Event cameras action recognition (EAR) offers compelling privacy-protecting and efficiency advantages, where temporal motion dynamics is of great importance. Existing spatiotemporal multi-view representation learning (SMVRL) methods for event-based object recognition (EOR) offer promising solutions by projecting H-W-T events along spatial axis H and W, yet are limited by its translation-variant spatial binning representation and naive early concatenation fusion architecture. This paper reexamines the key SMVRL design stages for EAR and propose: (i) a principled spatiotemporal multi-view representation through translation-invariant dense conversion of sparse events, (ii) a dual-branch, dynamic fusion architecture that models sample-wise complementarity between motion features from different views, and (iii) a bio-inspired temporal warping augmentation that mimics speed variability of real-world human actions. On three challenging EAR datasets of HARDVS, DailyDVS-200 and THU-EACT-50-CHL, we show +7.0%, +10.7%, and +10.2% Top-1 accuracy gains over existing SMVRL EOR method with surprising 30.1% reduced parameters and 35.7% lower computations, establishing our framework as a novel and powerful EAR paradigm.",
      "url": "http://arxiv.org/abs/2601.17391",
      "author": "Rui Fan, Weidong Hao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes SMV-EAR for efficient event-based action recognition using spatiotemporal multi-view representation with translation-invariant dense conversion and dual-branch dynamic fusion.",
      "importance_score": 50,
      "reasoning": "Solid event camera action recognition work but specialized area.",
      "themes": [
        "Event Cameras",
        "Action Recognition",
        "Efficient AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes SMV-EAR for efficient event-based action recognition using spatiotemporal multi-view representation with translation-invariant dense conversion and dual-branch dynamic fusion.</p>",
      "content_html": "<p>arXiv:2601.17391v1 Announce Type: new  Abstract: Event cameras action recognition (EAR) offers compelling privacy-protecting and efficiency advantages, where temporal motion dynamics is of great importance. Existing spatiotemporal multi-view representation learning (SMVRL) methods for event-based object recognition (EOR) offer promising solutions by projecting H-W-T events along spatial axis H and W, yet are limited by its translation-variant spatial binning representation and naive early concatenation fusion architecture. This paper reexamines the key SMVRL design stages for EAR and propose: (i) a principled spatiotemporal multi-view representation through translation-invariant dense conversion of sparse events, (ii) a dual-branch, dynamic fusion architecture that models sample-wise complementarity between motion features from different views, and (iii) a bio-inspired temporal warping augmentation that mimics speed variability of real-world human actions. On three challenging EAR datasets of HARDVS, DailyDVS-200 and THU-EACT-50-CHL, we show +7.0%, +10.7%, and +10.2% Top-1 accuracy gains over existing SMVRL EOR method with surprising 30.1% reduced parameters and 35.7% lower computations, establishing our framework as a novel and powerful EAR paradigm.</p>"
    },
    {
      "id": "40c0cd674402",
      "title": "PhaSR: Generalized Image Shadow Removal with Physically Aligned Priors",
      "content": "arXiv:2601.17470v1 Announce Type: new  Abstract: Shadow removal under diverse lighting conditions requires disentangling illumination from intrinsic reflectance, a challenge compounded when physical priors are not properly aligned. We propose PhaSR (Physically Aligned Shadow Removal), addressing this through dual-level prior alignment to enable robust performance from single-light shadows to multi-source ambient lighting. First, Physically Aligned Normalization (PAN) performs closed-form illumination correction via Gray-world normalization, log-domain Retinex decomposition, and dynamic range recombination, suppressing chromatic bias. Second, Geometric-Semantic Rectification Attention (GSRA) extends differential attention to cross-modal alignment, harmonizing depth-derived geometry with DINO-v2 semantic embeddings to resolve modal conflicts under varying illumination. Experiments show competitive performance in shadow removal with lower complexity and generalization to ambient lighting where traditional methods fail under multi-source illumination. Our source code is available at https://github.com/ming053l/PhaSR.",
      "url": "http://arxiv.org/abs/2601.17470",
      "author": "Chia-Ming Lee, Yu-Fan Lin, Yu-Jou Hsiao, Jing-Hui Jung, Yu-Lun Liu, Chih-Chung Hsu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes PhaSR for shadow removal using physically aligned priors with dual-level alignment: Physically Aligned Normalization for illumination correction and Geometric-Semantic Rectification Attention for cross-modal alignment.",
      "importance_score": 50,
      "reasoning": "Principled approach to shadow removal with physics-based priors.",
      "themes": [
        "Image Restoration",
        "Shadow Removal",
        "Physics-informed AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes PhaSR for shadow removal using physically aligned priors with dual-level alignment: Physically Aligned Normalization for illumination correction and Geometric-Semantic Rectification Attention for cross-modal alignment.</p>",
      "content_html": "<p>arXiv:2601.17470v1 Announce Type: new  Abstract: Shadow removal under diverse lighting conditions requires disentangling illumination from intrinsic reflectance, a challenge compounded when physical priors are not properly aligned. We propose PhaSR (Physically Aligned Shadow Removal), addressing this through dual-level prior alignment to enable robust performance from single-light shadows to multi-source ambient lighting. First, Physically Aligned Normalization (PAN) performs closed-form illumination correction via Gray-world normalization, log-domain Retinex decomposition, and dynamic range recombination, suppressing chromatic bias. Second, Geometric-Semantic Rectification Attention (GSRA) extends differential attention to cross-modal alignment, harmonizing depth-derived geometry with DINO-v2 semantic embeddings to resolve modal conflicts under varying illumination. Experiments show competitive performance in shadow removal with lower complexity and generalization to ambient lighting where traditional methods fail under multi-source illumination. Our source code is available at https://github.com/ming053l/PhaSR.</p>"
    },
    {
      "id": "7ea30594c834",
      "title": "Frequency-aware Neural Representation for Videos",
      "content": "arXiv:2601.17741v1 Announce Type: new  Abstract: Implicit Neural Representations (INRs) have emerged as a promising paradigm for video compression. However, existing INR-based frameworks typically suffer from inherent spectral bias, which favors low-frequency components and leads to over-smoothed reconstructions and suboptimal rate-distortion performance. In this paper, we propose FaNeRV, a Frequency-aware Neural Representation for videos, which explicitly decouples low- and high-frequency components to enable efficient and faithful video reconstruction. FaNeRV introduces a multi-resolution supervision strategy that guides the network to progressively capture global structures and fine-grained textures through staged supervision . To further enhance high-frequency reconstruction, we propose a dynamic high-frequency injection mechanism that adaptively emphasizes challenging regions. In addition, we design a frequency-decomposed network module to improve feature modeling across different spectral bands. Extensive experiments on standard benchmarks demonstrate that FaNeRV significantly outperforms state-of-the-art INR methods and achieves competitive rate-distortion performance against traditional codecs.",
      "url": "http://arxiv.org/abs/2601.17741",
      "author": "Jun Zhu, Xinfeng Zhang, Lv Tang, Junhao Jiang, Gai Zhang, Jia Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "FaNeRV addresses spectral bias in INR-based video compression by explicitly decoupling low- and high-frequency components through multi-resolution supervision and frequency-aware training strategies.",
      "importance_score": 50,
      "reasoning": "Addresses known limitation of neural video representations. Solid technical contribution but incremental.",
      "themes": [
        "Video Compression",
        "Neural Representations",
        "Frequency Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>FaNeRV addresses spectral bias in INR-based video compression by explicitly decoupling low- and high-frequency components through multi-resolution supervision and frequency-aware training strategies.</p>",
      "content_html": "<p>arXiv:2601.17741v1 Announce Type: new  Abstract: Implicit Neural Representations (INRs) have emerged as a promising paradigm for video compression. However, existing INR-based frameworks typically suffer from inherent spectral bias, which favors low-frequency components and leads to over-smoothed reconstructions and suboptimal rate-distortion performance. In this paper, we propose FaNeRV, a Frequency-aware Neural Representation for videos, which explicitly decouples low- and high-frequency components to enable efficient and faithful video reconstruction. FaNeRV introduces a multi-resolution supervision strategy that guides the network to progressively capture global structures and fine-grained textures through staged supervision . To further enhance high-frequency reconstruction, we propose a dynamic high-frequency injection mechanism that adaptively emphasizes challenging regions. In addition, we design a frequency-decomposed network module to improve feature modeling across different spectral bands. Extensive experiments on standard benchmarks demonstrate that FaNeRV significantly outperforms state-of-the-art INR methods and achieves competitive rate-distortion performance against traditional codecs.</p>"
    },
    {
      "id": "ff34cc339128",
      "title": "Revisiting 3D Reconstruction Kernels as Low-Pass Filters",
      "content": "arXiv:2601.17900v1 Announce Type: new  Abstract: 3D reconstruction is to recover 3D signals from the sampled discrete 2D pixels, with the goal to converge continuous 3D spaces. In this paper, we revisit 3D reconstruction from the perspective of signal processing, identifying the periodic spectral extension induced by discrete sampling as the fundamental challenge. Previous 3D reconstruction kernels, such as Gaussians, Exponential functions, and Student's t distributions, serve as the low pass filters to isolate the baseband spectrum. However, their unideal low-pass property results in the overlap of high-frequency components with low-frequency components in the discrete-time signal's spectrum. To this end, we introduce Jinc kernel with an instantaneous drop to zero magnitude exactly at the cutoff frequency, which is corresponding to the ideal low pass filters. As Jinc kernel suffers from low decay speed in the spatial domain, we further propose modulated kernels to strick an effective balance, and achieves superior rendering performance by reconciling spatial efficiency and frequency-domain fidelity. Experimental results have demonstrated the effectiveness of our Jinc and modulated kernels.",
      "url": "http://arxiv.org/abs/2601.17900",
      "author": "Shengjun Zhang, Min Chen, Yibo Wei, Mingyu Dong, Yueqi Duan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Revisits 3D reconstruction from signal processing perspective, identifying periodic spectral extension from sampling as the fundamental challenge and proposing Jinc kernel for improved low-pass filtering.",
      "importance_score": 50,
      "reasoning": "Interesting signal processing perspective on 3D reconstruction. Theoretical contribution but unclear practical impact.",
      "themes": [
        "3D Reconstruction",
        "Signal Processing",
        "Theoretical Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Revisits 3D reconstruction from signal processing perspective, identifying periodic spectral extension from sampling as the fundamental challenge and proposing Jinc kernel for improved low-pass filtering.</p>",
      "content_html": "<p>arXiv:2601.17900v1 Announce Type: new  Abstract: 3D reconstruction is to recover 3D signals from the sampled discrete 2D pixels, with the goal to converge continuous 3D spaces. In this paper, we revisit 3D reconstruction from the perspective of signal processing, identifying the periodic spectral extension induced by discrete sampling as the fundamental challenge. Previous 3D reconstruction kernels, such as Gaussians, Exponential functions, and Student's t distributions, serve as the low pass filters to isolate the baseband spectrum. However, their unideal low-pass property results in the overlap of high-frequency components with low-frequency components in the discrete-time signal's spectrum. To this end, we introduce Jinc kernel with an instantaneous drop to zero magnitude exactly at the cutoff frequency, which is corresponding to the ideal low pass filters. As Jinc kernel suffers from low decay speed in the spatial domain, we further propose modulated kernels to strick an effective balance, and achieves superior rendering performance by reconciling spatial efficiency and frequency-domain fidelity. Experimental results have demonstrated the effectiveness of our Jinc and modulated kernels.</p>"
    },
    {
      "id": "e82e9f1c298a",
      "title": "YOLO-DS: Fine-Grained Feature Decoupling via Dual-Statistic Synergy Operator for Object Detection",
      "content": "arXiv:2601.18172v1 Announce Type: new  Abstract: One-stage object detection, particularly the YOLO series, strikes a favorable balance between accuracy and efficiency. However, existing YOLO detectors lack explicit modeling of heterogeneous object responses within shared feature channels, which limits further performance gains. To address this, we propose YOLO-DS, a framework built around a novel Dual-Statistic Synergy Operator (DSO). The DSO decouples object features by jointly modeling the channel-wise mean and the peak-to-mean difference. Building upon the DSO, we design two lightweight gating modules: the Dual-Statistic Synergy Gating (DSG) module for adaptive channel-wise feature selection, and the Multi-Path Segmented Gating (MSG) module for depth-wise feature weighting. On the MS-COCO benchmark, YOLO-DS consistently outperforms YOLOv8 across five model scales (N, S, M, L, X), achieving AP gains of 1.1% to 1.7% with only a minimal increase in inference latency. Extensive visualization, ablation, and comparative studies validate the effectiveness of our approach, demonstrating its superior capability in discriminating heterogeneous objects with high efficiency.",
      "url": "http://arxiv.org/abs/2601.18172",
      "author": "Lin Huang, Yujuan Tan, Weisheng Li, Shitai Shan, Liu Liu, Bo Liu, Linlin Shen, Jing Yu, Yue Niu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "YOLO-DS introduces Dual-Statistic Synergy Operator for explicit modeling of heterogeneous object responses within shared feature channels, with lightweight gating modules for channel-wise selection.",
      "importance_score": 50,
      "reasoning": "Incremental YOLO improvement with novel feature decoupling. MS-COCO evaluation expected.",
      "themes": [
        "Object Detection",
        "YOLO",
        "Feature Engineering"
      ],
      "continuation": null,
      "summary_html": "<p>YOLO-DS introduces Dual-Statistic Synergy Operator for explicit modeling of heterogeneous object responses within shared feature channels, with lightweight gating modules for channel-wise selection.</p>",
      "content_html": "<p>arXiv:2601.18172v1 Announce Type: new  Abstract: One-stage object detection, particularly the YOLO series, strikes a favorable balance between accuracy and efficiency. However, existing YOLO detectors lack explicit modeling of heterogeneous object responses within shared feature channels, which limits further performance gains. To address this, we propose YOLO-DS, a framework built around a novel Dual-Statistic Synergy Operator (DSO). The DSO decouples object features by jointly modeling the channel-wise mean and the peak-to-mean difference. Building upon the DSO, we design two lightweight gating modules: the Dual-Statistic Synergy Gating (DSG) module for adaptive channel-wise feature selection, and the Multi-Path Segmented Gating (MSG) module for depth-wise feature weighting. On the MS-COCO benchmark, YOLO-DS consistently outperforms YOLOv8 across five model scales (N, S, M, L, X), achieving AP gains of 1.1% to 1.7% with only a minimal increase in inference latency. Extensive visualization, ablation, and comparative studies validate the effectiveness of our approach, demonstrating its superior capability in discriminating heterogeneous objects with high efficiency.</p>"
    },
    {
      "id": "10510ec373b3",
      "title": "GimmBO: Interactive Generative Image Model Merging via Bayesian Optimization",
      "content": "arXiv:2601.18585v1 Announce Type: new  Abstract: Fine-tuning-based adaptation is widely used to customize diffusion-based image generation, leading to large collections of community-created adapters that capture diverse subjects and styles. Adapters derived from the same base model can be merged with weights, enabling the synthesis of new visual results within a vast and continuous design space. To explore this space, current workflows rely on manual slider-based tuning, an approach that scales poorly and makes weight selection difficult, even when the candidate set is limited to 20-30 adapters. We propose GimmBO to support interactive exploration of adapter merging for image generation through Preferential Bayesian Optimization (PBO). Motivated by observations from real-world usage, including sparsity and constrained weight ranges, we introduce a two-stage BO backend that improves sampling efficiency and convergence in high-dimensional spaces. We evaluate our approach with simulated users and a user study, demonstrating improved convergence, high success rates, and consistent gains over BO and line-search baselines, and further show the flexibility of the framework through several extensions.",
      "url": "http://arxiv.org/abs/2601.18585",
      "author": "Chenxi Liu, Selena Ling, Alec Jacobson",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "GimmBO supports interactive exploration of diffusion model adapter merging through Preferential Bayesian Optimization, addressing poor scalability of manual slider-based tuning.",
      "importance_score": 50,
      "reasoning": "Practical tool for model merging exploration. Useful for community adapter usage.",
      "themes": [
        "Model Merging",
        "Bayesian Optimization",
        "Diffusion Models"
      ],
      "continuation": null,
      "summary_html": "<p>GimmBO supports interactive exploration of diffusion model adapter merging through Preferential Bayesian Optimization, addressing poor scalability of manual slider-based tuning.</p>",
      "content_html": "<p>arXiv:2601.18585v1 Announce Type: new  Abstract: Fine-tuning-based adaptation is widely used to customize diffusion-based image generation, leading to large collections of community-created adapters that capture diverse subjects and styles. Adapters derived from the same base model can be merged with weights, enabling the synthesis of new visual results within a vast and continuous design space. To explore this space, current workflows rely on manual slider-based tuning, an approach that scales poorly and makes weight selection difficult, even when the candidate set is limited to 20-30 adapters. We propose GimmBO to support interactive exploration of adapter merging for image generation through Preferential Bayesian Optimization (PBO). Motivated by observations from real-world usage, including sparsity and constrained weight ranges, we introduce a two-stage BO backend that improves sampling efficiency and convergence in high-dimensional spaces. We evaluate our approach with simulated users and a user study, demonstrating improved convergence, high success rates, and consistent gains over BO and line-search baselines, and further show the flexibility of the framework through several extensions.</p>"
    },
    {
      "id": "5c5beccb3eed",
      "title": "Deep Intrinsic Surprise-Regularized Control (DISRC): A Biologically Inspired Mechanism for Efficient Deep Q-Learning in Sparse Environments",
      "content": "arXiv:2601.17598v1 Announce Type: new  Abstract: Deep reinforcement learning (DRL) has driven major advances in autonomous control. Still, standard Deep Q-Network (DQN) agents tend to rely on fixed learning rates and uniform update scaling, even as updates are modulated by temporal-difference (TD) error. This rigidity destabilizes convergence, especially in sparse-reward settings where feedback is infrequent. We introduce Deep Intrinsic Surprise-Regularized Control (DISRC), a biologically inspired augmentation to DQN that dynamically scales Q-updates based on latent-space surprise. DISRC encodes states via a LayerNorm-based encoder and computes a deviation-based surprise score relative to a moving latent setpoint. Each update is then scaled in proportion to both TD error and surprise intensity, promoting plasticity during early exploration and stability as familiarity increases. We evaluate DISRC on two sparse-reward MiniGrid environments, which included MiniGrid-DoorKey-8x8 and MiniGrid-LavaCrossingS9N1, under identical settings as a vanilla DQN baseline. In DoorKey, DISRC reached the first successful episode (reward > 0.8) 33% faster than the vanilla DQN baseline (79 vs. 118 episodes), with lower reward standard deviation (0.25 vs. 0.34) and higher reward area under the curve (AUC: 596.42 vs. 534.90). These metrics reflect faster, more consistent learning - critical for sparse, delayed reward settings. In LavaCrossing, DISRC achieved a higher final reward (0.95 vs. 0.93) and the highest AUC of all agents (957.04), though it converged more gradually. These preliminary results establish DISRC as a novel mechanism for regulating learning intensity in off-policy agents, improving both efficiency and stability in sparse-reward domains. By treating surprise as an intrinsic learning signal, DISRC enables agents to modulate updates based on expectation violations, enhancing decision quality when conventional value-based methods fall short.",
      "url": "http://arxiv.org/abs/2601.17598",
      "author": "Yash Kini, Shiv Davay, Shreya Polavarapu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "cs.NE"
      ],
      "summary": "Introduces DISRC, a biologically-inspired augmentation to DQN that dynamically scales Q-updates based on latent-space surprise for improved convergence in sparse-reward settings.",
      "importance_score": 50,
      "reasoning": "Interesting bio-inspired approach to RL stability, addresses real challenge but limited experimental scope.",
      "themes": [
        "Reinforcement Learning",
        "Deep Q-Learning",
        "Biologically-Inspired AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces DISRC, a biologically-inspired augmentation to DQN that dynamically scales Q-updates based on latent-space surprise for improved convergence in sparse-reward settings.</p>",
      "content_html": "<p>arXiv:2601.17598v1 Announce Type: new  Abstract: Deep reinforcement learning (DRL) has driven major advances in autonomous control. Still, standard Deep Q-Network (DQN) agents tend to rely on fixed learning rates and uniform update scaling, even as updates are modulated by temporal-difference (TD) error. This rigidity destabilizes convergence, especially in sparse-reward settings where feedback is infrequent. We introduce Deep Intrinsic Surprise-Regularized Control (DISRC), a biologically inspired augmentation to DQN that dynamically scales Q-updates based on latent-space surprise. DISRC encodes states via a LayerNorm-based encoder and computes a deviation-based surprise score relative to a moving latent setpoint. Each update is then scaled in proportion to both TD error and surprise intensity, promoting plasticity during early exploration and stability as familiarity increases. We evaluate DISRC on two sparse-reward MiniGrid environments, which included MiniGrid-DoorKey-8x8 and MiniGrid-LavaCrossingS9N1, under identical settings as a vanilla DQN baseline. In DoorKey, DISRC reached the first successful episode (reward &gt; 0.8) 33% faster than the vanilla DQN baseline (79 vs. 118 episodes), with lower reward standard deviation (0.25 vs. 0.34) and higher reward area under the curve (AUC: 596.42 vs. 534.90). These metrics reflect faster, more consistent learning - critical for sparse, delayed reward settings. In LavaCrossing, DISRC achieved a higher final reward (0.95 vs. 0.93) and the highest AUC of all agents (957.04), though it converged more gradually. These preliminary results establish DISRC as a novel mechanism for regulating learning intensity in off-policy agents, improving both efficiency and stability in sparse-reward domains. By treating surprise as an intrinsic learning signal, DISRC enables agents to modulate updates based on expectation violations, enhancing decision quality when conventional value-based methods fall short.</p>"
    },
    {
      "id": "ced2a4bb28a1",
      "title": "Global Optimization of Atomic Clusters via Physically-Constrained Tensor Train Decomposition",
      "content": "arXiv:2601.18592v1 Announce Type: cross  Abstract: The global optimization of atomic clusters represents a fundamental challenge in computational chemistry and materials science due to the exponential growth of local minima with system size (i.e., the curse of dimensionality). We introduce a novel framework that overcomes this limitation by exploiting the low-rank structure of potential energy surfaces through Tensor Train (TT) decomposition. Our approach combines two complementary TT-based strategies: the algebraic TTOpt method, which utilizes maximum volume sampling, and the probabilistic PROTES method, which employs generative sampling. A key innovation is the development of physically-constrained encoding schemes that incorporate molecular constraints directly into the discretization process. We demonstrate the efficacy of our method by identifying global minima of Lennard-Jones clusters containing up to 45 atoms. Furthermore, we establish its practical applicability to real-world systems by optimizing 20-atom carbon clusters using a machine-learned Moment Tensor Potential, achieving geometries consistent with quantum-accurate simulations. This work establishes TT-decomposition as a powerful tool for molecular structure prediction and provides a general framework adaptable to a wide range of high-dimensional optimization problems in computational material science.",
      "url": "http://arxiv.org/abs/2601.18592",
      "author": "Konstantin Sozykin, Nikita Rybin, Andrei Chertkov, Anh-Huy Phan, Ivan Oseledets, Alexander Shapeev, Ivan Novikov, Gleb Ryzhakov",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "math.OC"
      ],
      "summary": "Introduces tensor train decomposition framework for global optimization of atomic clusters, combining TTOpt and PROTES methods with physically-constrained encoding schemes.",
      "importance_score": 50,
      "reasoning": "Applies tensor methods to important computational chemistry problem, addresses curse of dimensionality.",
      "themes": [
        "Global Optimization",
        "Computational Chemistry",
        "Tensor Methods"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces tensor train decomposition framework for global optimization of atomic clusters, combining TTOpt and PROTES methods with physically-constrained encoding schemes.</p>",
      "content_html": "<p>arXiv:2601.18592v1 Announce Type: cross  Abstract: The global optimization of atomic clusters represents a fundamental challenge in computational chemistry and materials science due to the exponential growth of local minima with system size (i.e., the curse of dimensionality). We introduce a novel framework that overcomes this limitation by exploiting the low-rank structure of potential energy surfaces through Tensor Train (TT) decomposition. Our approach combines two complementary TT-based strategies: the algebraic TTOpt method, which utilizes maximum volume sampling, and the probabilistic PROTES method, which employs generative sampling. A key innovation is the development of physically-constrained encoding schemes that incorporate molecular constraints directly into the discretization process. We demonstrate the efficacy of our method by identifying global minima of Lennard-Jones clusters containing up to 45 atoms. Furthermore, we establish its practical applicability to real-world systems by optimizing 20-atom carbon clusters using a machine-learned Moment Tensor Potential, achieving geometries consistent with quantum-accurate simulations. This work establishes TT-decomposition as a powerful tool for molecular structure prediction and provides a general framework adaptable to a wide range of high-dimensional optimization problems in computational material science.</p>"
    },
    {
      "id": "3856fdfb30c7",
      "title": "A Unified Kantorovich Duality for Multimarginal Optimal Transport",
      "content": "arXiv:2601.17171v1 Announce Type: cross  Abstract: Multimarginal optimal transport (MOT) has gained increasing attention in recent years, notably due to its relevance in machine learning and statistics, where one seeks to jointly compare and align multiple probability distributions. This paper presents a unified and complete Kantorovich duality theory for MOT problem on general Polish product spaces with bounded continuous cost function. For marginal compact spaces, the duality identity is derived through a convex-analytic reformulation, that identifies the dual problem as a Fenchel-Rockafellar conjugate. We obtain dual attainment and show that optimal potentials may always be chosen in the class of $c$-conjugate families, thereby extending classical two-marginal conjugacy principle into a genuinely multimarginal setting. In non-compact setting, where direct compactness arguments are unavailable, we recover duality via a truncation-tightness procedure based on weak compactness of multimarginal transference plans and boundedness of the cost. We prove that the dual value is preserved under restriction to compact subsets and that admissible dual families can be regularized into uniformly bounded $c$-conjugate potentials. The argument relies on a refined use of $c$-splitting sets and their equivalence with multimarginal $c$-cyclical monotonicity. We then obtain dual attainment and exact primal-dual equality for MOT on arbitrary Polish spaces, together with a canonical representation of optimal dual potentials by $c$-conjugacy. These results provide a structural foundation for further developments in probabilistic and statistical analysis of MOT, including stability, differentiability, and asymptotic theory under marginal perturbations.",
      "url": "http://arxiv.org/abs/2601.17171",
      "author": "Yehya Cheryala, Mokhtar Z. Alaya, Salim Bouzebda",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "math.OC"
      ],
      "summary": "Presents unified and complete Kantorovich duality theory for multimarginal optimal transport on Polish spaces, extending classical two-marginal conjugacy to multi-marginal setting.",
      "importance_score": 50,
      "reasoning": "Solid theoretical contribution to optimal transport but primarily mathematical.",
      "themes": [
        "Optimal Transport",
        "Duality Theory",
        "Mathematical ML"
      ],
      "continuation": null,
      "summary_html": "<p>Presents unified and complete Kantorovich duality theory for multimarginal optimal transport on Polish spaces, extending classical two-marginal conjugacy to multi-marginal setting.</p>",
      "content_html": "<p>arXiv:2601.17171v1 Announce Type: cross  Abstract: Multimarginal optimal transport (MOT) has gained increasing attention in recent years, notably due to its relevance in machine learning and statistics, where one seeks to jointly compare and align multiple probability distributions. This paper presents a unified and complete Kantorovich duality theory for MOT problem on general Polish product spaces with bounded continuous cost function. For marginal compact spaces, the duality identity is derived through a convex-analytic reformulation, that identifies the dual problem as a Fenchel-Rockafellar conjugate. We obtain dual attainment and show that optimal potentials may always be chosen in the class of $c$-conjugate families, thereby extending classical two-marginal conjugacy principle into a genuinely multimarginal setting. In non-compact setting, where direct compactness arguments are unavailable, we recover duality via a truncation-tightness procedure based on weak compactness of multimarginal transference plans and boundedness of the cost. We prove that the dual value is preserved under restriction to compact subsets and that admissible dual families can be regularized into uniformly bounded $c$-conjugate potentials. The argument relies on a refined use of $c$-splitting sets and their equivalence with multimarginal $c$-cyclical monotonicity. We then obtain dual attainment and exact primal-dual equality for MOT on arbitrary Polish spaces, together with a canonical representation of optimal dual potentials by $c$-conjugacy. These results provide a structural foundation for further developments in probabilistic and statistical analysis of MOT, including stability, differentiability, and asymptotic theory under marginal perturbations.</p>"
    },
    {
      "id": "f59be77144b3",
      "title": "Diversified Scaling Inference in Time Series Foundation Models",
      "content": "arXiv:2601.17376v1 Announce Type: cross  Abstract: The advancement of Time Series Foundation Models (TSFMs) has been driven primarily by large-scale pre-training, but inference-time compute potential remains largely untapped. This work systematically investigates two questions: how do TSFMs behave under standard sampling-based inference scaling, and can controlled sampling diversity enhance performance? We first examine the properties of TSFMs under standard sampling often fail to adhere to scaling laws due to insufficient exploration of the solution space. Building on this, we then delve into diversified inference scaling via tailored time series perturbations to expand the generative distribution's support. We theoretically analyze the diversity-fidelity trade-off and derive a critical sample threshold for diversified sampling to outperform standard sampling. Extensive experiments across various TSFMs and datasets show proper diversified inference scaling yields substantial performance gains without parameter updates, establishing inference design as a critical, compute-efficient dimension of TSFM optimization. As an application, we propose RobustMSE, a rigorous metric to quantify the headroom performance of TSFM under a fixed budget. Overall, our findings clarify these factor interactions, enabling reliable performance via diverse large-scale inference time series in parallel environments without re-training TSFMs.",
      "url": "http://arxiv.org/abs/2601.17376",
      "author": "Ruijin Hua, Zichuan Liu, Kun Zhang, Yiyuan Yang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Studies inference-time compute scaling in time series foundation models, finding standard sampling fails to follow scaling laws due to insufficient exploration.",
      "importance_score": 49,
      "reasoning": "Novel investigation of inference scaling in TSFMs. Theoretical analysis of diversity-fidelity tradeoff.",
      "themes": [
        "Time Series",
        "Foundation Models",
        "Inference Scaling"
      ],
      "continuation": null,
      "summary_html": "<p>Studies inference-time compute scaling in time series foundation models, finding standard sampling fails to follow scaling laws due to insufficient exploration.</p>",
      "content_html": "<p>arXiv:2601.17376v1 Announce Type: cross  Abstract: The advancement of Time Series Foundation Models (TSFMs) has been driven primarily by large-scale pre-training, but inference-time compute potential remains largely untapped. This work systematically investigates two questions: how do TSFMs behave under standard sampling-based inference scaling, and can controlled sampling diversity enhance performance? We first examine the properties of TSFMs under standard sampling often fail to adhere to scaling laws due to insufficient exploration of the solution space. Building on this, we then delve into diversified inference scaling via tailored time series perturbations to expand the generative distribution's support. We theoretically analyze the diversity-fidelity trade-off and derive a critical sample threshold for diversified sampling to outperform standard sampling. Extensive experiments across various TSFMs and datasets show proper diversified inference scaling yields substantial performance gains without parameter updates, establishing inference design as a critical, compute-efficient dimension of TSFM optimization. As an application, we propose RobustMSE, a rigorous metric to quantify the headroom performance of TSFM under a fixed budget. Overall, our findings clarify these factor interactions, enabling reliable performance via diverse large-scale inference time series in parallel environments without re-training TSFMs.</p>"
    },
    {
      "id": "c3c254c970ba",
      "title": "Motif Diversity in Human Liver ChIP-seq Data Using MAP-Elites",
      "content": "arXiv:2601.17808v1 Announce Type: new  Abstract: Motif discovery is a core problem in computational biology, traditionally formulated as a likelihood optimization task that returns a single dominant motif from a DNA sequence dataset. However, regulatory sequence data admit multiple plausible motif explanations, reflecting underlying biological heterogeneity. In this work, we frame motif discovery as a quality-diversity problem and apply the MAP-Elites algorithm to evolve position weight matrix motifs under a likelihood-based fitness objective while explicitly preserving diversity across biologically meaningful dimensions. We evaluate MAP-Elites using three complementary behavioral characterizations that capture trade-offs between motif specificity, compositional structure, coverage, and robustness. Experiments on human CTCF liver ChIP-seq data aligned to the human reference genome compare MAP-Elites against a standard motif discovery tool, MEME, under matched evaluation criteria across stratified dataset subsets. Results show that MAP-Elites recovers multiple high-quality motif variants with fitness comparable to MEME's strongest solutions while revealing structured diversity obscured by single-solution approaches.",
      "url": "http://arxiv.org/abs/2601.17808",
      "author": "Alejandro Medina, Mary Lauren Benton",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "cs.NE"
      ],
      "summary": "Applies MAP-Elites quality-diversity algorithm to DNA motif discovery, evolving diverse position weight matrix motifs while preserving biologically meaningful dimensions.",
      "importance_score": 49,
      "reasoning": "Creative application of QD algorithms to computational biology, demonstrates broader applicability of evolutionary methods.",
      "themes": [
        "Quality-Diversity",
        "Computational Biology",
        "Evolutionary Algorithms"
      ],
      "continuation": null,
      "summary_html": "<p>Applies MAP-Elites quality-diversity algorithm to DNA motif discovery, evolving diverse position weight matrix motifs while preserving biologically meaningful dimensions.</p>",
      "content_html": "<p>arXiv:2601.17808v1 Announce Type: new  Abstract: Motif discovery is a core problem in computational biology, traditionally formulated as a likelihood optimization task that returns a single dominant motif from a DNA sequence dataset. However, regulatory sequence data admit multiple plausible motif explanations, reflecting underlying biological heterogeneity. In this work, we frame motif discovery as a quality-diversity problem and apply the MAP-Elites algorithm to evolve position weight matrix motifs under a likelihood-based fitness objective while explicitly preserving diversity across biologically meaningful dimensions. We evaluate MAP-Elites using three complementary behavioral characterizations that capture trade-offs between motif specificity, compositional structure, coverage, and robustness. Experiments on human CTCF liver ChIP-seq data aligned to the human reference genome compare MAP-Elites against a standard motif discovery tool, MEME, under matched evaluation criteria across stratified dataset subsets. Results show that MAP-Elites recovers multiple high-quality motif variants with fitness comparable to MEME's strongest solutions while revealing structured diversity obscured by single-solution approaches.</p>"
    },
    {
      "id": "2e0d9af1d5c2",
      "title": "Error Analysis of Bayesian Inverse Problems with Generative Priors",
      "content": "arXiv:2601.17374v1 Announce Type: new  Abstract: Data-driven methods for the solution of inverse problems have become widely popular in recent years thanks to the rise of machine learning techniques. A popular approach concerns the training of a generative model on additional data to learn a bespoke prior for the problem at hand. In this article we present an analysis for such problems by presenting quantitative error bounds for minimum Wasserstein-2 generative models for the prior. We show that under some assumptions, the error in the posterior due to the generative prior will inherit the same rate as the prior with respect to the Wasserstein-1 distance. We further present numerical experiments that verify that aspects of our error analysis manifests in some benchmarks followed by an elliptic PDE inverse problem where a generative prior is used to model a non-stationary field.",
      "url": "http://arxiv.org/abs/2601.17374",
      "author": "Bamdad Hosseini, Ziqi Huang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "stat.ML"
      ],
      "summary": "Presents quantitative error bounds for Bayesian inverse problems with minimum Wasserstein-2 generative model priors, showing posterior error inherits prior's rate.",
      "importance_score": 49,
      "reasoning": "Solid theoretical contribution but primarily mathematical analysis with limited practical guidance.",
      "themes": [
        "Bayesian Inference",
        "Inverse Problems",
        "Generative Models",
        "Theory"
      ],
      "continuation": null,
      "summary_html": "<p>Presents quantitative error bounds for Bayesian inverse problems with minimum Wasserstein-2 generative model priors, showing posterior error inherits prior's rate.</p>",
      "content_html": "<p>arXiv:2601.17374v1 Announce Type: new  Abstract: Data-driven methods for the solution of inverse problems have become widely popular in recent years thanks to the rise of machine learning techniques. A popular approach concerns the training of a generative model on additional data to learn a bespoke prior for the problem at hand. In this article we present an analysis for such problems by presenting quantitative error bounds for minimum Wasserstein-2 generative models for the prior. We show that under some assumptions, the error in the posterior due to the generative prior will inherit the same rate as the prior with respect to the Wasserstein-1 distance. We further present numerical experiments that verify that aspects of our error analysis manifests in some benchmarks followed by an elliptic PDE inverse problem where a generative prior is used to model a non-stationary field.</p>"
    },
    {
      "id": "9dfad96a2b9f",
      "title": "Discovery of Feasible 3D Printing Configurations for Metal Alloys via AI-driven Adaptive Experimental Design",
      "content": "arXiv:2601.17587v1 Announce Type: new  Abstract: Configuring the parameters of additive manufacturing processes for metal alloys is a challenging problem due to complex relationships between input parameters (e.g., laser power, scan speed) and quality of printed outputs. The standard trial-and-error approach to find feasible parameter configurations is highly inefficient because validating each configuration is expensive in terms of resources (physical and human labor) and the configuration space is very large. This paper combines the general principles of AI-driven adaptive experimental design with domain knowledge to address the challenging problem of discovering feasible configurations. The key idea is to build a surrogate model from past experiments to intelligently select a small batch of input configurations for validation in each iteration. To demonstrate the effectiveness of this methodology, we deploy it for Directed Energy Deposition process to print GRCop--42, a high-performance copper--chromium--niobium alloy developed by NASA for aerospace applications. Within three months, our approach yielded multiple defect-free outputs across a range of laser powers dramatically reducing time to result and resource expenditure compared to several months of manual experimentation by domain scientists with no success. By enabling high-quality GRCop--42 fabrication on readily available infrared laser platforms for the first time, we democratize access to this critical alloy, paving the way for cost-effective, decentralized production for aerospace applications.",
      "url": "http://arxiv.org/abs/2601.17587",
      "author": "Azza Fadhel, Nathaniel W. Zuckschwerdt, Aryan Deshwal, Susmita Bose, Amit Bandyopadhyay, Jana Doppa",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Applies AI-driven adaptive experimental design with domain knowledge to discover feasible 3D printing configurations for metal alloys, using surrogate models to reduce expensive physical experiments.",
      "importance_score": 48,
      "reasoning": "Solid applied ML work in manufacturing; combines established techniques with domain expertise but limited fundamental AI advances.",
      "themes": [
        "Manufacturing AI",
        "Experimental Design",
        "Bayesian Optimization"
      ],
      "continuation": null,
      "summary_html": "<p>Applies AI-driven adaptive experimental design with domain knowledge to discover feasible 3D printing configurations for metal alloys, using surrogate models to reduce expensive physical experiments.</p>",
      "content_html": "<p>arXiv:2601.17587v1 Announce Type: new  Abstract: Configuring the parameters of additive manufacturing processes for metal alloys is a challenging problem due to complex relationships between input parameters (e.g., laser power, scan speed) and quality of printed outputs. The standard trial-and-error approach to find feasible parameter configurations is highly inefficient because validating each configuration is expensive in terms of resources (physical and human labor) and the configuration space is very large. This paper combines the general principles of AI-driven adaptive experimental design with domain knowledge to address the challenging problem of discovering feasible configurations. The key idea is to build a surrogate model from past experiments to intelligently select a small batch of input configurations for validation in each iteration. To demonstrate the effectiveness of this methodology, we deploy it for Directed Energy Deposition process to print GRCop--42, a high-performance copper--chromium--niobium alloy developed by NASA for aerospace applications. Within three months, our approach yielded multiple defect-free outputs across a range of laser powers dramatically reducing time to result and resource expenditure compared to several months of manual experimentation by domain scientists with no success. By enabling high-quality GRCop--42 fabrication on readily available infrared laser platforms for the first time, we democratize access to this critical alloy, paving the way for cost-effective, decentralized production for aerospace applications.</p>"
    },
    {
      "id": "f863c839c2de",
      "title": "LLM-Based SQL Generation: Prompting, Self-Refinement, and Adaptive Weighted Majority Voting",
      "content": "arXiv:2601.17942v1 Announce Type: new  Abstract: Text-to-SQL has emerged as a prominent research area, particularly with the rapid advancement of large language models (LLMs). By enabling users to query databases through natural language rather than SQL, this technology significantly lowers the barrier to data analysis. However, generating accurate SQL from natural language remains challenging due to ambiguity in user queries, the complexity of schema linking, limited generalization across SQL dialects, and the need for domain-specific understanding. In this study, we propose a Single-Agent Self-Refinement with Ensemble Voting (SSEV) pipeline built on PET-SQL that operates without ground-truth data, integrating self-refinement with Weighted Majority Voting (WMV) and its randomized variant (RWMA). Experimental results show that the SSEV achieves competitive performance across multiple benchmarks, attaining execution accuracies of 85.5% on Spider 1.0-Dev, 86.4% on Spider 1.0-Test, and 66.3% on BIRD-Dev. Building on insights from the SSEV pipeline, we further propose ReCAPAgent-SQL (Refinement-Critique-Act-Plan agent-based SQL framework) to address the growing complexity of enterprise databases and real-world Text-to-SQL tasks. The framework integrates multiple specialized agents for planning, external knowledge retrieval, critique, action generation, self-refinement, schema linking, and result validation, enabling iterative refinement of SQL predictions through agent collaboration. ReCAPAgent-SQL's WMA results achieve 31% execution accuracy on the first 100 queries of Spider 2.0-Lite, demonstrating significant improvements in handling real-world enterprise scenarios. Overall, our work facilitates the deployment of scalable Text-to-SQL systems in practical settings, supporting better data-driven decision-making at lower cost and with greater efficiency.",
      "url": "http://arxiv.org/abs/2601.17942",
      "author": "Yu-Jie Yang, Hung-Fu Chang, Po-An Chen",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes SSEV pipeline for text-to-SQL combining self-refinement with weighted majority voting without ground-truth data, built on PET-SQL framework.",
      "importance_score": 48,
      "reasoning": "Incremental improvement to text-to-SQL; combines known techniques without major innovation.",
      "themes": [
        "Text-to-SQL",
        "Ensemble Methods"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes SSEV pipeline for text-to-SQL combining self-refinement with weighted majority voting without ground-truth data, built on PET-SQL framework.</p>",
      "content_html": "<p>arXiv:2601.17942v1 Announce Type: new  Abstract: Text-to-SQL has emerged as a prominent research area, particularly with the rapid advancement of large language models (LLMs). By enabling users to query databases through natural language rather than SQL, this technology significantly lowers the barrier to data analysis. However, generating accurate SQL from natural language remains challenging due to ambiguity in user queries, the complexity of schema linking, limited generalization across SQL dialects, and the need for domain-specific understanding. In this study, we propose a Single-Agent Self-Refinement with Ensemble Voting (SSEV) pipeline built on PET-SQL that operates without ground-truth data, integrating self-refinement with Weighted Majority Voting (WMV) and its randomized variant (RWMA). Experimental results show that the SSEV achieves competitive performance across multiple benchmarks, attaining execution accuracies of 85.5% on Spider 1.0-Dev, 86.4% on Spider 1.0-Test, and 66.3% on BIRD-Dev. Building on insights from the SSEV pipeline, we further propose ReCAPAgent-SQL (Refinement-Critique-Act-Plan agent-based SQL framework) to address the growing complexity of enterprise databases and real-world Text-to-SQL tasks. The framework integrates multiple specialized agents for planning, external knowledge retrieval, critique, action generation, self-refinement, schema linking, and result validation, enabling iterative refinement of SQL predictions through agent collaboration. ReCAPAgent-SQL's WMA results achieve 31% execution accuracy on the first 100 queries of Spider 2.0-Lite, demonstrating significant improvements in handling real-world enterprise scenarios. Overall, our work facilitates the deployment of scalable Text-to-SQL systems in practical settings, supporting better data-driven decision-making at lower cost and with greater efficiency.</p>"
    },
    {
      "id": "f840f9f675e3",
      "title": "MANGO: A Global Single-Date Paired Dataset for Mangrove Segmentation",
      "content": "arXiv:2601.17039v1 Announce Type: cross  Abstract: Mangroves are critical for climate-change mitigation, requiring reliable monitoring for effective conservation. While deep learning has emerged as a powerful tool for mangrove detection, its progress is hindered by the limitations of existing datasets. In particular, many resources provide only annual map products without curated single-date image-mask pairs, limited to specific regions rather than global coverage, or remain inaccessible to the public. To address these challenges, we introduce MANGO, a large-scale global dataset comprising 42,703 labeled image-mask pairs across 124 countries. To construct this dataset, we retrieve all available Sentinel-2 imagery within the year 2020 for mangrove regions and select the best single-date observations that align with the mangrove annual mask. This selection is performed using a target detection-driven approach that leverages pixel-wise coordinate references to ensure adaptive and representative image-mask pairings. We also provide a benchmark across diverse semantic segmentation architectures under a country-disjoint split, establishing a foundation for scalable and reliable global mangrove monitoring.",
      "url": "http://arxiv.org/abs/2601.17039",
      "author": "Junhyuk Heo, Beomkyu Choi, Hyunjin Shin, Darongsae Kwon",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces MANGO, a large-scale global mangrove segmentation dataset with 42,703 labeled image-mask pairs from Sentinel-2 imagery across 124 countries for environmental monitoring.",
      "importance_score": 48,
      "reasoning": "Significant dataset contribution for environmental AI applications. Large scale and global coverage but narrow application domain.",
      "themes": [
        "Environmental AI",
        "Remote Sensing",
        "Datasets"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces MANGO, a large-scale global mangrove segmentation dataset with 42,703 labeled image-mask pairs from Sentinel-2 imagery across 124 countries for environmental monitoring.</p>",
      "content_html": "<p>arXiv:2601.17039v1 Announce Type: cross  Abstract: Mangroves are critical for climate-change mitigation, requiring reliable monitoring for effective conservation. While deep learning has emerged as a powerful tool for mangrove detection, its progress is hindered by the limitations of existing datasets. In particular, many resources provide only annual map products without curated single-date image-mask pairs, limited to specific regions rather than global coverage, or remain inaccessible to the public. To address these challenges, we introduce MANGO, a large-scale global dataset comprising 42,703 labeled image-mask pairs across 124 countries. To construct this dataset, we retrieve all available Sentinel-2 imagery within the year 2020 for mangrove regions and select the best single-date observations that align with the mangrove annual mask. This selection is performed using a target detection-driven approach that leverages pixel-wise coordinate references to ensure adaptive and representative image-mask pairings. We also provide a benchmark across diverse semantic segmentation architectures under a country-disjoint split, establishing a foundation for scalable and reliable global mangrove monitoring.</p>"
    },
    {
      "id": "3de07ed56dcd",
      "title": "PhysE-Inv: A Physics-Encoded Inverse Modeling approach for Arctic Snow Depth Prediction",
      "content": "arXiv:2601.17074v1 Announce Type: cross  Abstract: The accurate estimation of Arctic snow depth ($h_s$) remains a critical time-varying inverse problem due to the extreme scarcity and noise inherent in associated sea ice parameters. Existing process-based and data-driven models are either highly sensitive to sparse data or lack the physical interpretability required for climate-critical applications. To address this gap, we introduce PhysE-Inv, a novel framework that integrates a sophisticated sequential architecture, an LSTM Encoder-Decoder with Multi-head Attention and physics-guided contrastive learning, with physics-guided inference.Our core innovation lies in a surjective, physics-constrained inversion methodology. This methodology first leverages the hydrostatic balance forward model as a target-formulation proxy, enabling effective learning in the absence of direct $h_s$ ground truth; second, it uses reconstruction physics regularization over a latent space to dynamically discover hidden physical parameters from noisy, incomplete time-series input. Evaluated against state-of-the-art baselines, PhysE-Inv significantly improves prediction performance, reducing error by 20\\% while demonstrating superior physical consistency and resilience to data sparsity compared to empirical methods. This approach pioneers a path for noise-tolerant, interpretable inverse modeling, with wide applicability in geospatial and cryospheric domains.",
      "url": "http://arxiv.org/abs/2601.17074",
      "author": "Akila Sampath, Vandana Janeja, Jianwu Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces PhysE-Inv, a framework combining LSTM encoder-decoder with physics-guided contrastive learning for Arctic snow depth prediction under sparse, noisy data conditions.",
      "importance_score": 48,
      "reasoning": "Solid application of physics-informed ML for climate science. Domain-specific contribution with limited broader applicability.",
      "themes": [
        "Physics-Informed ML",
        "Climate Science",
        "Remote Sensing"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces PhysE-Inv, a framework combining LSTM encoder-decoder with physics-guided contrastive learning for Arctic snow depth prediction under sparse, noisy data conditions.</p>",
      "content_html": "<p>arXiv:2601.17074v1 Announce Type: cross  Abstract: The accurate estimation of Arctic snow depth ($h_s$) remains a critical time-varying inverse problem due to the extreme scarcity and noise inherent in associated sea ice parameters. Existing process-based and data-driven models are either highly sensitive to sparse data or lack the physical interpretability required for climate-critical applications. To address this gap, we introduce PhysE-Inv, a novel framework that integrates a sophisticated sequential architecture, an LSTM Encoder-Decoder with Multi-head Attention and physics-guided contrastive learning, with physics-guided inference.Our core innovation lies in a surjective, physics-constrained inversion methodology. This methodology first leverages the hydrostatic balance forward model as a target-formulation proxy, enabling effective learning in the absence of direct $h_s$ ground truth; second, it uses reconstruction physics regularization over a latent space to dynamically discover hidden physical parameters from noisy, incomplete time-series input. Evaluated against state-of-the-art baselines, PhysE-Inv significantly improves prediction performance, reducing error by 20\\% while demonstrating superior physical consistency and resilience to data sparsity compared to empirical methods. This approach pioneers a path for noise-tolerant, interpretable inverse modeling, with wide applicability in geospatial and cryospheric domains.</p>"
    },
    {
      "id": "b40dd88e120c",
      "title": "SonoEdit: Null-Space Constrained Knowledge Editing for Pronunciation Correction in LLM-Based TTS",
      "content": "arXiv:2601.17086v1 Announce Type: cross  Abstract: Neural text-to-speech (TTS) systems systematically mispronounce low-resource proper nouns, particularly non-English names, brands, and geographic locations, due to their underrepresentation in predominantly English training corpora. Existing solutions typically rely on expensive multilingual data collection, supervised finetuning, or manual phonetic annotation, which limits the deployment of TTS systems in linguistically diverse settings. We introduce SonoEdit, a model editing technique that surgically corrects pronunciation errors in pre-trained TTS models without retraining. Instead of costly finetuning or explicit phoneme injection, we propose a parsimonious alternative based on Null-Space Pronunciation Editing, which performs a single-shot parameter update to modify the pronunciation of specific words while provably preserving all other model behavior. We first adapt Acoustic Causal Tracing to identify the Transformer layers responsible for text-to-pronunciation mapping. We then apply Null-Space Constrained Editing to compute a closed-form weight update that corrects the target pronunciation while remaining mathematically orthogonal to the subspace governing general speech generation. This constrained update steers the model's acoustic output toward a desired pronunciation exemplar while guaranteeing zero first-order change on a preserved speech corpus.",
      "url": "http://arxiv.org/abs/2601.17086",
      "author": "Ayush Pratap Singh, Harshit Singh, Nityanand Mathur, Akshat Mandloi, Sudarshan Kamath",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.SD"
      ],
      "summary": "Introduces SonoEdit for correcting TTS pronunciation errors through null-space editing without retraining. Targets low-resource proper nouns and non-English names.",
      "importance_score": 48,
      "reasoning": "Novel model editing technique for practical TTS problem. Interesting null-space approach but narrow scope.",
      "themes": [
        "Text-to-Speech",
        "Model Editing",
        "Multilingual AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces SonoEdit for correcting TTS pronunciation errors through null-space editing without retraining. Targets low-resource proper nouns and non-English names.</p>",
      "content_html": "<p>arXiv:2601.17086v1 Announce Type: cross  Abstract: Neural text-to-speech (TTS) systems systematically mispronounce low-resource proper nouns, particularly non-English names, brands, and geographic locations, due to their underrepresentation in predominantly English training corpora. Existing solutions typically rely on expensive multilingual data collection, supervised finetuning, or manual phonetic annotation, which limits the deployment of TTS systems in linguistically diverse settings. We introduce SonoEdit, a model editing technique that surgically corrects pronunciation errors in pre-trained TTS models without retraining. Instead of costly finetuning or explicit phoneme injection, we propose a parsimonious alternative based on Null-Space Pronunciation Editing, which performs a single-shot parameter update to modify the pronunciation of specific words while provably preserving all other model behavior. We first adapt Acoustic Causal Tracing to identify the Transformer layers responsible for text-to-pronunciation mapping. We then apply Null-Space Constrained Editing to compute a closed-form weight update that corrects the target pronunciation while remaining mathematically orthogonal to the subspace governing general speech generation. This constrained update steers the model's acoustic output toward a desired pronunciation exemplar while guaranteeing zero first-order change on a preserved speech corpus.</p>"
    },
    {
      "id": "bc29980948ef",
      "title": "Decentralized Multi-Agent Swarms for Autonomous Grid Security in Industrial IoT: A Consensus-based Approach",
      "content": "arXiv:2601.17303v1 Announce Type: cross  Abstract: As Industrial Internet of Things (IIoT) environments expand to include tens of thousands of connected devices. The centralization of security monitoring architectures creates serious latency issues that savvy attackers can exploit to compromise an entire manufacturing ecosystem. This paper outlines a new, decentralized multi-agent swarm (DMAS) architecture that includes autonomous artificial intelligence (AI) agents at each edge gateway, functioning as a distributed digital \"immune system\" for IIoT networks. Instead of using a traditional static firewall approach, the DMAS agents communicate via a lightweight peer-to-peer protocol to cooperatively detect anomalous behavior across the IIoT network without sending data to a cloud infrastructure. The authors also outline a consensus-based threat validation (CVT) process in which agents vote on the threat level of an identified threat, enabling instant quarantine of a compromised node or nodes. The authors conducted experiments on a testbed that simulated an innovative factory environment with 2000 IIoT devices and found that the DMAS demonstrated sub-millisecond response times (average of 0.85ms), 97.3% accuracy in detecting malicious activity under high load, and 87% accuracy in detecting zero-day attacks. All significantly higher than baseline values for both centralized and edge computing. Additionally, the proposed architecture can prevent real-time cascading failures in industrial control systems and reduce network bandwidth use by 89% compared to cloud-based solutions.",
      "url": "http://arxiv.org/abs/2601.17303",
      "author": "Samaresh Kumar Singh, Joyjit Roy",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes decentralized multi-agent swarm (DMAS) architecture with autonomous AI agents at edge gateways functioning as distributed immune system for IIoT network security.",
      "importance_score": 48,
      "reasoning": "Novel architectural concept for IIoT security. Interesting distributed approach but high-level proposal.",
      "themes": [
        "IoT Security",
        "Multi-Agent Systems",
        "Distributed AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes decentralized multi-agent swarm (DMAS) architecture with autonomous AI agents at edge gateways functioning as distributed immune system for IIoT network security.</p>",
      "content_html": "<p>arXiv:2601.17303v1 Announce Type: cross  Abstract: As Industrial Internet of Things (IIoT) environments expand to include tens of thousands of connected devices. The centralization of security monitoring architectures creates serious latency issues that savvy attackers can exploit to compromise an entire manufacturing ecosystem. This paper outlines a new, decentralized multi-agent swarm (DMAS) architecture that includes autonomous artificial intelligence (AI) agents at each edge gateway, functioning as a distributed digital \"immune system\" for IIoT networks. Instead of using a traditional static firewall approach, the DMAS agents communicate via a lightweight peer-to-peer protocol to cooperatively detect anomalous behavior across the IIoT network without sending data to a cloud infrastructure. The authors also outline a consensus-based threat validation (CVT) process in which agents vote on the threat level of an identified threat, enabling instant quarantine of a compromised node or nodes. The authors conducted experiments on a testbed that simulated an innovative factory environment with 2000 IIoT devices and found that the DMAS demonstrated sub-millisecond response times (average of 0.85ms), 97.3% accuracy in detecting malicious activity under high load, and 87% accuracy in detecting zero-day attacks. All significantly higher than baseline values for both centralized and edge computing. Additionally, the proposed architecture can prevent real-time cascading failures in industrial control systems and reduce network bandwidth use by 89% compared to cloud-based solutions.</p>"
    },
    {
      "id": "bde4e48bf13c",
      "title": "ClinNet: Evidential Ordinal Regression with Bilateral Asymmetry and Prototype Memory for Knee Osteoarthritis Grading",
      "content": "arXiv:2601.17315v1 Announce Type: cross  Abstract: Knee osteoarthritis (KOA) grading based on radiographic images is a critical yet challenging task due to subtle inter-grade differences, annotation uncertainty, and the inherently ordinal nature of disease progression. Conventional deep learning approaches typically formulate this problem as deterministic multi-class classification, ignoring both the continuous progression of degeneration and the uncertainty in expert annotations. In this work, we propose ClinNet, a novel trustworthy framework that addresses KOA grading as an evidential ordinal regression problem. The proposed method integrates three key components: (1) a Bilateral Asymmetry Encoder (BAE) that explicitly models medial-lateral structural discrepancies; (2) a Diagnostic Memory Bank that maintains class-wise prototypes to stabilize feature representations; and (3) an Evidential Ordinal Head based on the Normal-Inverse-Gamma (NIG) distribution to jointly estimate continuous KL grades and epistemic uncertainty. Extensive experiments demonstrate that ClinNet achieves a Quadratic Weighted Kappa of 0.892 and Accuracy of 0.768, statistically outperforming state-of-the-art baselines (p < 0.001). Crucially, we demonstrate that the model's uncertainty estimates successfully flag out-of-distribution samples and potential misdiagnoses, paving the way for safe clinical deployment.",
      "url": "http://arxiv.org/abs/2601.17315",
      "author": "Xiaoyang Li, Runni Zhou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes ClinNet for knee osteoarthritis grading using evidential ordinal regression with bilateral asymmetry encoding and prototype memory for trustworthy diagnosis.",
      "importance_score": 48,
      "reasoning": "Solid medical AI contribution addressing uncertainty and ordinal nature of disease grading. Domain-specific application.",
      "themes": [
        "Medical AI",
        "Uncertainty Quantification",
        "Trustworthy AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes ClinNet for knee osteoarthritis grading using evidential ordinal regression with bilateral asymmetry encoding and prototype memory for trustworthy diagnosis.</p>",
      "content_html": "<p>arXiv:2601.17315v1 Announce Type: cross  Abstract: Knee osteoarthritis (KOA) grading based on radiographic images is a critical yet challenging task due to subtle inter-grade differences, annotation uncertainty, and the inherently ordinal nature of disease progression. Conventional deep learning approaches typically formulate this problem as deterministic multi-class classification, ignoring both the continuous progression of degeneration and the uncertainty in expert annotations. In this work, we propose ClinNet, a novel trustworthy framework that addresses KOA grading as an evidential ordinal regression problem. The proposed method integrates three key components: (1) a Bilateral Asymmetry Encoder (BAE) that explicitly models medial-lateral structural discrepancies; (2) a Diagnostic Memory Bank that maintains class-wise prototypes to stabilize feature representations; and (3) an Evidential Ordinal Head based on the Normal-Inverse-Gamma (NIG) distribution to jointly estimate continuous KL grades and epistemic uncertainty. Extensive experiments demonstrate that ClinNet achieves a Quadratic Weighted Kappa of 0.892 and Accuracy of 0.768, statistically outperforming state-of-the-art baselines (p &lt; 0.001). Crucially, we demonstrate that the model's uncertainty estimates successfully flag out-of-distribution samples and potential misdiagnoses, paving the way for safe clinical deployment.</p>"
    },
    {
      "id": "3973a781b36c",
      "title": "NeRF-MIR: Towards High-Quality Restoration of Masked Images with Neural Radiance Fields",
      "content": "arXiv:2601.17350v1 Announce Type: cross  Abstract: Neural Radiance Fields (NeRF) have demonstrated remarkable performance in novel view synthesis. However, there is much improvement room on restoring 3D scenes based on NeRF from corrupted images, which are common in natural scene captures and can significantly impact the effectiveness of NeRF. This paper introduces NeRF-MIR, a novel neural rendering approach specifically proposed for the restoration of masked images, demonstrating the potential of NeRF in this domain. Recognizing that randomly emitting rays to pixels in NeRF may not effectively learn intricate image textures, we propose a \\textbf{P}atch-based \\textbf{E}ntropy for \\textbf{R}ay \\textbf{E}mitting (\\textbf{PERE}) strategy to distribute emitted rays properly. This enables NeRF-MIR to fuse comprehensive information from images of different views. Additionally, we introduce a \\textbf{P}rogressively \\textbf{I}terative \\textbf{RE}storation (\\textbf{PIRE}) mechanism to restore the masked regions in a self-training process. Furthermore, we design a dynamically-weighted loss function that automatically recalibrates the loss weights for masked regions. As existing datasets do not support NeRF-based masked image restoration, we construct three masked datasets to simulate corrupted scenarios. Extensive experiments on real data and constructed datasets demonstrate the superiority of NeRF-MIR over its counterparts in masked image restoration.",
      "url": "http://arxiv.org/abs/2601.17350",
      "author": "Xianliang Huang, Zhizhou Zhong, Shuhang Chen, Yi Xu, Juhong Guan, Shuigeng Zhou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces NeRF-MIR for masked image restoration using PERE strategy to distribute rays based on patch entropy. Demonstrates NeRF potential for image restoration.",
      "importance_score": 48,
      "reasoning": "Novel application of NeRF to image restoration. Technical contribution but limited experimental validation.",
      "themes": [
        "Neural Radiance Fields",
        "Image Restoration",
        "3D Vision"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces NeRF-MIR for masked image restoration using PERE strategy to distribute rays based on patch entropy. Demonstrates NeRF potential for image restoration.</p>",
      "content_html": "<p>arXiv:2601.17350v1 Announce Type: cross  Abstract: Neural Radiance Fields (NeRF) have demonstrated remarkable performance in novel view synthesis. However, there is much improvement room on restoring 3D scenes based on NeRF from corrupted images, which are common in natural scene captures and can significantly impact the effectiveness of NeRF. This paper introduces NeRF-MIR, a novel neural rendering approach specifically proposed for the restoration of masked images, demonstrating the potential of NeRF in this domain. Recognizing that randomly emitting rays to pixels in NeRF may not effectively learn intricate image textures, we propose a \\textbf{P}atch-based \\textbf{E}ntropy for \\textbf{R}ay \\textbf{E}mitting (\\textbf{PERE}) strategy to distribute emitted rays properly. This enables NeRF-MIR to fuse comprehensive information from images of different views. Additionally, we introduce a \\textbf{P}rogressively \\textbf{I}terative \\textbf{RE}storation (\\textbf{PIRE}) mechanism to restore the masked regions in a self-training process. Furthermore, we design a dynamically-weighted loss function that automatically recalibrates the loss weights for masked regions. As existing datasets do not support NeRF-based masked image restoration, we construct three masked datasets to simulate corrupted scenarios. Extensive experiments on real data and constructed datasets demonstrate the superiority of NeRF-MIR over its counterparts in masked image restoration.</p>"
    },
    {
      "id": "fb0b38af0efb",
      "title": "ONRW: Optimizing inversion noise for high-quality and robust watermark",
      "content": "arXiv:2601.17388v1 Announce Type: cross  Abstract: Watermarking methods have always been effective means of protecting intellectual property, yet they face significant challenges. Although existing deep learning-based watermarking systems can hide watermarks in images with minimal impact on image quality, they often lack robustness when encountering image corruptions during transmission, which undermines their practical application value. To this end, we propose a high-quality and robust watermark framework based on the diffusion model. Our method first converts the clean image into inversion noise through a null-text optimization process, and after optimizing the inversion noise in the latent space, it produces a high-quality watermarked image through an iterative denoising process of the diffusion model. The iterative denoising process serves as a powerful purification mechanism, ensuring both the visual quality of the watermarked image and enhancing the robustness of the watermark against various corruptions. To prevent the optimizing of inversion noise from distorting the original semantics of the image, we specifically introduced self-attention constraints and pseudo-mask strategies. Extensive experimental results demonstrate the superior performance of our method against various image corruptions. In particular, our method outperforms the stable signature method by an average of 10\\% across 12 different image transformations on COCO datasets. Our codes are available at https://github.com/920927/ONRW.",
      "url": "http://arxiv.org/abs/2601.17388",
      "author": "Xuan Ding, Xiu Yan, Chuanlong Xie, Yao Zhu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "ONRW proposes diffusion-based watermarking through inversion noise optimization, achieving high quality and robustness to image corruptions.",
      "importance_score": 48,
      "reasoning": "Novel watermarking approach using diffusion models. Addresses robustness challenge.",
      "themes": [
        "Watermarking",
        "Diffusion Models",
        "IP Protection"
      ],
      "continuation": null,
      "summary_html": "<p>ONRW proposes diffusion-based watermarking through inversion noise optimization, achieving high quality and robustness to image corruptions.</p>",
      "content_html": "<p>arXiv:2601.17388v1 Announce Type: cross  Abstract: Watermarking methods have always been effective means of protecting intellectual property, yet they face significant challenges. Although existing deep learning-based watermarking systems can hide watermarks in images with minimal impact on image quality, they often lack robustness when encountering image corruptions during transmission, which undermines their practical application value. To this end, we propose a high-quality and robust watermark framework based on the diffusion model. Our method first converts the clean image into inversion noise through a null-text optimization process, and after optimizing the inversion noise in the latent space, it produces a high-quality watermarked image through an iterative denoising process of the diffusion model. The iterative denoising process serves as a powerful purification mechanism, ensuring both the visual quality of the watermarked image and enhancing the robustness of the watermark against various corruptions. To prevent the optimizing of inversion noise from distorting the original semantics of the image, we specifically introduced self-attention constraints and pseudo-mask strategies. Extensive experimental results demonstrate the superior performance of our method against various image corruptions. In particular, our method outperforms the stable signature method by an average of 10\\% across 12 different image transformations on COCO datasets. Our codes are available at https://github.com/920927/ONRW.</p>"
    },
    {
      "id": "2573533b56be",
      "title": "Understanding Users' Privacy Reasoning and Behaviors During Chatbot Use to Support Meaningful Agency in Privacy",
      "content": "arXiv:2601.18125v1 Announce Type: cross  Abstract: Conversational agents (CAs) (e.g., chatbots) are increasingly used in settings where users disclose sensitive information, raising significant privacy concerns. Because privacy judgments are highly contextual, supporting users to engage in privacy-protective actions during chatbot interactions is essential. However, enabling meaningful engagement requires a deeper understanding of how users currently reason about and manage sensitive information during realistic chatbot use scenarios. To investigate this, we qualitatively examined computer science (undergraduate and masters) students' in-the-moment disclosure and protection behaviors, as well as the reasoning underlying these behaviors, across a range of realistic chatbot tasks. Participants used a simulated ChatGPT interface with and without a privacy notice panel that intercepts message submissions, highlights potentially sensitive information, and offers privacy protective actions. The panel supports anonymization through retracting, faking, and generalizing, and surfaces two of ChatGPT's built-in privacy controls to improve their discoverability. Drawing on interaction logs, think-alouds, and survey responses, we analyzed how the panel fostered privacy awareness, encouraged protective actions, and supported context-specific reasoning about what information to protect and how. We further discuss design opportunities for tools that provide users greater and more meaningful agency in protecting sensitive information during CA interactions.",
      "url": "http://arxiv.org/abs/2601.18125",
      "author": "Mohammad Hadi Nezhad, Francisco Enrique Vicente Castro, Ivon Arroyo",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.HC"
      ],
      "summary": "Qualitative study examining how computer science students reason about privacy and manage sensitive information during realistic chatbot interactions. Investigates in-the-moment disclosure and protection behaviors.",
      "importance_score": 48,
      "reasoning": "HCI research on privacy with limited sample (CS students only). Useful for understanding user behavior but narrow scope and qualitative methodology limits generalizability.",
      "themes": [
        "Privacy",
        "Human-AI Interaction",
        "Chatbots"
      ],
      "continuation": null,
      "summary_html": "<p>Qualitative study examining how computer science students reason about privacy and manage sensitive information during realistic chatbot interactions. Investigates in-the-moment disclosure and protection behaviors.</p>",
      "content_html": "<p>arXiv:2601.18125v1 Announce Type: cross  Abstract: Conversational agents (CAs) (e.g., chatbots) are increasingly used in settings where users disclose sensitive information, raising significant privacy concerns. Because privacy judgments are highly contextual, supporting users to engage in privacy-protective actions during chatbot interactions is essential. However, enabling meaningful engagement requires a deeper understanding of how users currently reason about and manage sensitive information during realistic chatbot use scenarios. To investigate this, we qualitatively examined computer science (undergraduate and masters) students' in-the-moment disclosure and protection behaviors, as well as the reasoning underlying these behaviors, across a range of realistic chatbot tasks. Participants used a simulated ChatGPT interface with and without a privacy notice panel that intercepts message submissions, highlights potentially sensitive information, and offers privacy protective actions. The panel supports anonymization through retracting, faking, and generalizing, and surfaces two of ChatGPT's built-in privacy controls to improve their discoverability. Drawing on interaction logs, think-alouds, and survey responses, we analyzed how the panel fostered privacy awareness, encouraged protective actions, and supported context-specific reasoning about what information to protect and how. We further discuss design opportunities for tools that provide users greater and more meaningful agency in protecting sensitive information during CA interactions.</p>"
    },
    {
      "id": "76aa54041a7c",
      "title": "PaperTok: Exploring the Use of Generative AI for Creating Short-form Videos for Research Communication",
      "content": "arXiv:2601.18218v1 Announce Type: cross  Abstract: The dissemination of scholarly research is critical, yet researchers often lack the time and skills to create engaging content for popular media such as short-form videos. To address this gap, we explore the use of generative AI to help researchers transform their academic papers into accessible video content. Informed by a formative study with science communicators and content creators (N=8), we designed PaperTok, an end-to-end system that automates the initial creative labor by generating script options and corresponding audiovisual content from a source paper. Researchers can then refine based on their preferences with further prompting. A mixed-methods user study (N=18) and crowdsourced evaluation (N=100) demonstrate that PaperTok's workflow can help researchers create engaging and informative short-form videos. We also identified the need for more fine-grained controls in the creation process. To this end, we offer implications for future generative tools that support science outreach.",
      "url": "http://arxiv.org/abs/2601.18218",
      "author": "Meziah Ruby Cristobal, Hyeonjeong Byeon, Tze-Yu Chen, Ruoxi Shang, Donghoon Shin, Ruican Zhong, Tony Zhou, Gary Hsieh",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.HC"
      ],
      "summary": "Presents PaperTok system using generative AI to transform academic papers into short-form video content. Validated through mixed-methods study with 18 researchers and crowdsourced evaluation of 100 participants.",
      "importance_score": 48,
      "reasoning": "Novel application of generative AI for science communication. Small study sample limits conclusions. More HCI than core AI research.",
      "themes": [
        "Science Communication",
        "Generative AI",
        "Human-AI Interaction"
      ],
      "continuation": null,
      "summary_html": "<p>Presents PaperTok system using generative AI to transform academic papers into short-form video content. Validated through mixed-methods study with 18 researchers and crowdsourced evaluation of 100 participants.</p>",
      "content_html": "<p>arXiv:2601.18218v1 Announce Type: cross  Abstract: The dissemination of scholarly research is critical, yet researchers often lack the time and skills to create engaging content for popular media such as short-form videos. To address this gap, we explore the use of generative AI to help researchers transform their academic papers into accessible video content. Informed by a formative study with science communicators and content creators (N=8), we designed PaperTok, an end-to-end system that automates the initial creative labor by generating script options and corresponding audiovisual content from a source paper. Researchers can then refine based on their preferences with further prompting. A mixed-methods user study (N=18) and crowdsourced evaluation (N=100) demonstrate that PaperTok's workflow can help researchers create engaging and informative short-form videos. We also identified the need for more fine-grained controls in the creation process. To this end, we offer implications for future generative tools that support science outreach.</p>"
    },
    {
      "id": "8f92b2c946b3",
      "title": "Neural Network Approximation: A View from Polytope Decomposition",
      "content": "arXiv:2601.18264v1 Announce Type: cross  Abstract: Universal approximation theory offers a foundational framework to verify neural network expressiveness, enabling principled utilization in real-world applications. However, most existing theoretical constructions are established by uniformly dividing the input space into tiny hypercubes without considering the local regularity of the target function. In this work, we investigate the universal approximation capabilities of ReLU networks from a view of polytope decomposition, which offers a more realistic and task-oriented approach compared to current methods. To achieve this, we develop an explicit kernel polynomial method to derive an universal approximation of continuous functions, which is characterized not only by the refined Totik-Ditzian-type modulus of continuity, but also by polytopical domain decomposition. Then, a ReLU network is constructed to approximate the kernel polynomial in each subdomain separately. Furthermore, we find that polytope decomposition makes our approximation more efficient and flexible than existing methods in many cases, especially near singular points of the objective function. Lastly, we extend our approach to analytic functions to reach a higher approximation rate.",
      "url": "http://arxiv.org/abs/2601.18264",
      "author": "ZeYu Li, ShiJun Zhang, TieYong Zeng, FengLei Fan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Investigates universal approximation capabilities of ReLU networks from polytope decomposition perspective, developing kernel polynomial method for approximation characterized by Totik-Ditzian modulus.",
      "importance_score": 48,
      "reasoning": "Theoretical contribution to neural network approximation theory. More task-oriented than uniform division approaches but highly specialized.",
      "themes": [
        "Approximation Theory",
        "Neural Networks",
        "Theoretical ML"
      ],
      "continuation": null,
      "summary_html": "<p>Investigates universal approximation capabilities of ReLU networks from polytope decomposition perspective, developing kernel polynomial method for approximation characterized by Totik-Ditzian modulus.</p>",
      "content_html": "<p>arXiv:2601.18264v1 Announce Type: cross  Abstract: Universal approximation theory offers a foundational framework to verify neural network expressiveness, enabling principled utilization in real-world applications. However, most existing theoretical constructions are established by uniformly dividing the input space into tiny hypercubes without considering the local regularity of the target function. In this work, we investigate the universal approximation capabilities of ReLU networks from a view of polytope decomposition, which offers a more realistic and task-oriented approach compared to current methods. To achieve this, we develop an explicit kernel polynomial method to derive an universal approximation of continuous functions, which is characterized not only by the refined Totik-Ditzian-type modulus of continuity, but also by polytopical domain decomposition. Then, a ReLU network is constructed to approximate the kernel polynomial in each subdomain separately. Furthermore, we find that polytope decomposition makes our approximation more efficient and flexible than existing methods in many cases, especially near singular points of the objective function. Lastly, we extend our approach to analytic functions to reach a higher approximation rate.</p>"
    },
    {
      "id": "331a0d7458d6",
      "title": "3DGesPolicy: Phoneme-Aware Holistic Co-Speech Gesture Generation Based on Action Control",
      "content": "arXiv:2601.18451v1 Announce Type: cross  Abstract: Generating holistic co-speech gestures that integrate full-body motion with facial expressions suffers from semantically incoherent coordination on body motion and spatially unstable meaningless movements due to existing part-decomposed or frame-level regression methods, We introduce 3DGesPolicy, a novel action-based framework that reformulates holistic gesture generation as a continuous trajectory control problem through diffusion policy from robotics. By modeling frame-to-frame variations as unified holistic actions, our method effectively learns inter-frame holistic gesture motion patterns and ensures both spatially and semantically coherent movement trajectories that adhere to realistic motion manifolds. To further bridge the gap in expressive alignment, we propose a Gesture-Audio-Phoneme (GAP) fusion module that can deeply integrate and refine multi-modal signals, ensuring structured and fine-grained alignment between speech semantics, body motion, and facial expressions. Extensive quantitative and qualitative experiments on the BEAT2 dataset demonstrate the effectiveness of our 3DGesPolicy across other state-of-the-art methods in generating natural, expressive, and highly speech-aligned holistic gestures.",
      "url": "http://arxiv.org/abs/2601.18451",
      "author": "Xuanmeng Sha, Liyun Zhang, Tomohiro Mashita, Naoya Chiba, Yuki Uranishi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces 3DGesPolicy framework for holistic co-speech gesture generation using diffusion policy from robotics, modeling frame-to-frame variations as unified actions for coherent motion trajectories.",
      "importance_score": 48,
      "reasoning": "Novel application of diffusion policy to gesture generation. Addresses coordination issues but specialized application.",
      "themes": [
        "Gesture Generation",
        "Diffusion Models",
        "Human Animation"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces 3DGesPolicy framework for holistic co-speech gesture generation using diffusion policy from robotics, modeling frame-to-frame variations as unified actions for coherent motion trajectories.</p>",
      "content_html": "<p>arXiv:2601.18451v1 Announce Type: cross  Abstract: Generating holistic co-speech gestures that integrate full-body motion with facial expressions suffers from semantically incoherent coordination on body motion and spatially unstable meaningless movements due to existing part-decomposed or frame-level regression methods, We introduce 3DGesPolicy, a novel action-based framework that reformulates holistic gesture generation as a continuous trajectory control problem through diffusion policy from robotics. By modeling frame-to-frame variations as unified holistic actions, our method effectively learns inter-frame holistic gesture motion patterns and ensures both spatially and semantically coherent movement trajectories that adhere to realistic motion manifolds. To further bridge the gap in expressive alignment, we propose a Gesture-Audio-Phoneme (GAP) fusion module that can deeply integrate and refine multi-modal signals, ensuring structured and fine-grained alignment between speech semantics, body motion, and facial expressions. Extensive quantitative and qualitative experiments on the BEAT2 dataset demonstrate the effectiveness of our 3DGesPolicy across other state-of-the-art methods in generating natural, expressive, and highly speech-aligned holistic gestures.</p>"
    },
    {
      "id": "1a07b79bbb70",
      "title": "Learning temporal embeddings from electronic health records of chronic kidney disease patients",
      "content": "arXiv:2601.18675v1 Announce Type: cross  Abstract: We investigate whether temporal embedding models trained on longitudinal electronic health records can learn clinically meaningful representations without compromising predictive performance, and how architectural choices affect embedding quality. Model-guided medicine requires representations that capture disease dynamics while remaining transparent and task agnostic, whereas most clinical prediction models are optimised for a single task. Representation learning facilitates learning embeddings that generalise across downstream tasks, and recurrent architectures are well-suited for modelling temporal structure in observational clinical data. Using the MIMIC-IV dataset, we study patients with chronic kidney disease (CKD) and compare three recurrent architectures: a vanilla LSTM, an attention-augmented LSTM, and a time-aware LSTM (T-LSTM). All models are trained both as embedding models and as direct end-to-end predictors. Embedding quality is evaluated via CKD stage clustering and in-ICU mortality prediction. The T-LSTM produces more structured embeddings, achieving a lower Davies-Bouldin Index (DBI = 9.91) and higher CKD stage classification accuracy (0.74) than the vanilla LSTM (DBI = 15.85, accuracy = 0.63) and attention-augmented LSTM (DBI = 20.72, accuracy = 0.67). For in-ICU mortality prediction, embedding models consistently outperform end-to-end predictors, improving accuracy from 0.72-0.75 to 0.82-0.83, which indicates that learning embeddings as an intermediate step is more effective than direct end-to-end learning.",
      "url": "http://arxiv.org/abs/2601.18675",
      "author": "Aditya Kumar, Mario A. Cypko, Oliver Amft",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Investigates whether temporal embedding models trained on longitudinal EHR can learn clinically meaningful representations for chronic kidney disease patients without compromising prediction.",
      "importance_score": 48,
      "reasoning": "Medical representation learning study. Addresses interpretability vs performance trade-off but scope limited to CKD.",
      "themes": [
        "Medical AI",
        "Representation Learning",
        "EHR Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Investigates whether temporal embedding models trained on longitudinal EHR can learn clinically meaningful representations for chronic kidney disease patients without compromising prediction.</p>",
      "content_html": "<p>arXiv:2601.18675v1 Announce Type: cross  Abstract: We investigate whether temporal embedding models trained on longitudinal electronic health records can learn clinically meaningful representations without compromising predictive performance, and how architectural choices affect embedding quality. Model-guided medicine requires representations that capture disease dynamics while remaining transparent and task agnostic, whereas most clinical prediction models are optimised for a single task. Representation learning facilitates learning embeddings that generalise across downstream tasks, and recurrent architectures are well-suited for modelling temporal structure in observational clinical data. Using the MIMIC-IV dataset, we study patients with chronic kidney disease (CKD) and compare three recurrent architectures: a vanilla LSTM, an attention-augmented LSTM, and a time-aware LSTM (T-LSTM). All models are trained both as embedding models and as direct end-to-end predictors. Embedding quality is evaluated via CKD stage clustering and in-ICU mortality prediction. The T-LSTM produces more structured embeddings, achieving a lower Davies-Bouldin Index (DBI = 9.91) and higher CKD stage classification accuracy (0.74) than the vanilla LSTM (DBI = 15.85, accuracy = 0.63) and attention-augmented LSTM (DBI = 20.72, accuracy = 0.67). For in-ICU mortality prediction, embedding models consistently outperform end-to-end predictors, improving accuracy from 0.72-0.75 to 0.82-0.83, which indicates that learning embeddings as an intermediate step is more effective than direct end-to-end learning.</p>"
    },
    {
      "id": "4dc7ac01fd91",
      "title": "Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval",
      "content": "arXiv:2601.18747v1 Announce Type: cross  Abstract: Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions.   In this paper, we propose that a retrieval engine must be capable of ``Capturing $\\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\\mathbf{P}$. We introduce \\texttt{ComputePN}, a novel evaluation algorithm that makes $\\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \\texttt{ComputePN} ensures the efficient evaluation of any query in $\\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine.",
      "url": "http://arxiv.org/abs/2601.18747",
      "author": "Amir Aavani",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.IR"
      ],
      "summary": "Argues retrieval engines must support complex nested logic graphs efficiently, analyzing expressiveness and efficiency tradeoffs between Document-at-a-Time and Term-at-a-Time approaches.",
      "importance_score": 48,
      "reasoning": "Theoretical contribution to retrieval systems design. Relevant for neuro-symbolic systems but highly specialized.",
      "themes": [
        "Information Retrieval",
        "Boolean Logic",
        "Systems Design"
      ],
      "continuation": null,
      "summary_html": "<p>Argues retrieval engines must support complex nested logic graphs efficiently, analyzing expressiveness and efficiency tradeoffs between Document-at-a-Time and Term-at-a-Time approaches.</p>",
      "content_html": "<p>arXiv:2601.18747v1 Announce Type: cross  Abstract: Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions.   In this paper, we propose that a retrieval engine must be capable of ``Capturing $\\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\\mathbf{P}$. We introduce \\texttt{ComputePN}, a novel evaluation algorithm that makes $\\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \\texttt{ComputePN} ensures the efficient evaluation of any query in $\\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine.</p>"
    },
    {
      "id": "015e0c853268",
      "title": "Multi-Objective Reinforcement Learning for Efficient Tactical Decision Making for Trucks in Highway Traffic",
      "content": "arXiv:2601.18783v1 Announce Type: cross  Abstract: Balancing safety, efficiency, and operational costs in highway driving poses a challenging decision-making problem for heavy-duty vehicles. A central difficulty is that conventional scalar reward formulations, obtained by aggregating these competing objectives, often obscure the structure of their trade-offs. We present a Proximal Policy Optimization based multi-objective reinforcement learning framework that learns a continuous set of policies explicitly representing these trade-offs and evaluates it on a scalable simulation platform for tactical decision making in trucks. The proposed approach learns a continuous set of Pareto-optimal policies that capture the trade-offs among three conflicting objectives: safety, quantified in terms of collisions and successful completion; energy efficiency and time efficiency, quantified using energy cost and driver cost, respectively. The resulting Pareto frontier is smooth and interpretable, enabling flexibility in choosing driving behavior along different conflicting objectives. This framework allows seamless transitions between different driving policies without retraining, yielding a robust and adaptive decision-making strategy for autonomous trucking applications.",
      "url": "http://arxiv.org/abs/2601.18783",
      "author": "Deepthi Pathare, Leo Laine, Morteza Haghir Chehreghani",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Presents multi-objective RL framework for heavy-duty vehicle tactical decisions, learning continuous Pareto-optimal policies balancing safety, efficiency, and operational costs.",
      "importance_score": 48,
      "reasoning": "Applied MORL for autonomous trucking. Practical contribution but standard MORL application to specific domain.",
      "themes": [
        "Multi-Objective RL",
        "Autonomous Vehicles",
        "Transportation"
      ],
      "continuation": null,
      "summary_html": "<p>Presents multi-objective RL framework for heavy-duty vehicle tactical decisions, learning continuous Pareto-optimal policies balancing safety, efficiency, and operational costs.</p>",
      "content_html": "<p>arXiv:2601.18783v1 Announce Type: cross  Abstract: Balancing safety, efficiency, and operational costs in highway driving poses a challenging decision-making problem for heavy-duty vehicles. A central difficulty is that conventional scalar reward formulations, obtained by aggregating these competing objectives, often obscure the structure of their trade-offs. We present a Proximal Policy Optimization based multi-objective reinforcement learning framework that learns a continuous set of policies explicitly representing these trade-offs and evaluates it on a scalable simulation platform for tactical decision making in trucks. The proposed approach learns a continuous set of Pareto-optimal policies that capture the trade-offs among three conflicting objectives: safety, quantified in terms of collisions and successful completion; energy efficiency and time efficiency, quantified using energy cost and driver cost, respectively. The resulting Pareto frontier is smooth and interpretable, enabling flexibility in choosing driving behavior along different conflicting objectives. This framework allows seamless transitions between different driving policies without retraining, yielding a robust and adaptive decision-making strategy for autonomous trucking applications.</p>"
    },
    {
      "id": "13802cf335e8",
      "title": "RAM-SD: Retrieval-Augmented Multi-agent framework for Sarcasm Detection",
      "content": "arXiv:2601.17002v1 Announce Type: new  Abstract: Sarcasm detection remains a significant challenge due to its reliance on nuanced contextual understanding, world knowledge, and multi-faceted linguistic cues that vary substantially across different sarcastic expressions. Existing approaches, from fine-tuned transformers to large language models, apply a uniform reasoning strategy to all inputs, struggling to address the diverse analytical demands of sarcasm. These demands range from modeling contextual expectation violations to requiring external knowledge grounding or recognizing specific rhetorical patterns. To address this limitation, we introduce RAM-SD, a Retrieval-Augmented Multi-Agent framework for Sarcasm Detection. The framework operates through four stages: (1) contextual retrieval grounds the query in both sarcastic and non-sarcastic exemplars; (2) a meta-planner classifies the sarcasm type and selects an optimal reasoning plan from a predefined set; (3) an ensemble of specialized agents performs complementary, multi-view analysis; and (4) an integrator synthesizes these analyses into a final, interpretable judgment with a natural language explanation. Evaluated on four standard benchmarks, RAM-SD achieves a state-of-the-art Macro-F1 of 77.74%, outperforming the strong GPT-4o+CoC baseline by 7.01 points. Our framework not only sets a new performance benchmark but also provides transparent and interpretable reasoning traces, illuminating the cognitive processes behind sarcasm comprehension.",
      "url": "http://arxiv.org/abs/2601.17002",
      "author": "Ziyang Zhou, Ziqi Liu, Yan Wang, Yiming Lin, Yangbin Chen",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes RAM-SD, a retrieval-augmented multi-agent framework for sarcasm detection that operates through contextual retrieval, knowledge grounding, rhetorical pattern recognition, and deliberation stages.",
      "importance_score": 48,
      "reasoning": "Incremental improvement to sarcasm detection with standard RAG and multi-agent components. Limited novelty in the approach.",
      "themes": [
        "Sarcasm Detection",
        "Multi-Agent Systems",
        "RAG"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes RAM-SD, a retrieval-augmented multi-agent framework for sarcasm detection that operates through contextual retrieval, knowledge grounding, rhetorical pattern recognition, and deliberation stages.</p>",
      "content_html": "<p>arXiv:2601.17002v1 Announce Type: new  Abstract: Sarcasm detection remains a significant challenge due to its reliance on nuanced contextual understanding, world knowledge, and multi-faceted linguistic cues that vary substantially across different sarcastic expressions. Existing approaches, from fine-tuned transformers to large language models, apply a uniform reasoning strategy to all inputs, struggling to address the diverse analytical demands of sarcasm. These demands range from modeling contextual expectation violations to requiring external knowledge grounding or recognizing specific rhetorical patterns. To address this limitation, we introduce RAM-SD, a Retrieval-Augmented Multi-Agent framework for Sarcasm Detection. The framework operates through four stages: (1) contextual retrieval grounds the query in both sarcastic and non-sarcastic exemplars; (2) a meta-planner classifies the sarcasm type and selects an optimal reasoning plan from a predefined set; (3) an ensemble of specialized agents performs complementary, multi-view analysis; and (4) an integrator synthesizes these analyses into a final, interpretable judgment with a natural language explanation. Evaluated on four standard benchmarks, RAM-SD achieves a state-of-the-art Macro-F1 of 77.74%, outperforming the strong GPT-4o+CoC baseline by 7.01 points. Our framework not only sets a new performance benchmark but also provides transparent and interpretable reasoning traces, illuminating the cognitive processes behind sarcasm comprehension.</p>"
    },
    {
      "id": "25a81fea272d",
      "title": "Distance-to-Distance Ratio: A Similarity Measure for Sentences Based on Rate of Change in LLM Embeddings",
      "content": "arXiv:2601.17705v1 Announce Type: new  Abstract: A measure of similarity between text embeddings can be considered adequate only if it adheres to the human perception of similarity between texts. In this paper, we introduce the distance-to-distance ratio (DDR), a novel measure of similarity between LLM sentence embeddings. Inspired by Lipschitz continuity, DDR measures the rate of change in similarity between the pre-context word embeddings and the similarity between post-context LLM embeddings, thus measuring the semantic influence of context. We evaluate the performance of DDR in experiments designed as a series of perturbations applied to sentences drawn from a sentence dataset. For each sentence, we generate variants by replacing one, two, or three words with either synonyms, which constitute semantically similar text, or randomly chosen words, which constitute semantically dissimilar text. We compare the performance of DDR with other prevailing similarity metrics and demonstrate that DDR consistently provides finer discrimination between semantically similar and dissimilar texts, even under minimal, controlled edits.",
      "url": "http://arxiv.org/abs/2601.17705",
      "author": "Abdullah Qureshi, Kenneth Rice, Alexander Wolpert",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Introduces Distance-to-Distance Ratio (DDR), a similarity measure for sentence embeddings inspired by Lipschitz continuity that captures the rate of change between pre-context and post-context embeddings.",
      "importance_score": 48,
      "reasoning": "Theoretical contribution to embedding similarity measurement. Limited experimental validation of practical benefits.",
      "themes": [
        "Embeddings",
        "Similarity Metrics",
        "Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Distance-to-Distance Ratio (DDR), a similarity measure for sentence embeddings inspired by Lipschitz continuity that captures the rate of change between pre-context and post-context embeddings.</p>",
      "content_html": "<p>arXiv:2601.17705v1 Announce Type: new  Abstract: A measure of similarity between text embeddings can be considered adequate only if it adheres to the human perception of similarity between texts. In this paper, we introduce the distance-to-distance ratio (DDR), a novel measure of similarity between LLM sentence embeddings. Inspired by Lipschitz continuity, DDR measures the rate of change in similarity between the pre-context word embeddings and the similarity between post-context LLM embeddings, thus measuring the semantic influence of context. We evaluate the performance of DDR in experiments designed as a series of perturbations applied to sentences drawn from a sentence dataset. For each sentence, we generate variants by replacing one, two, or three words with either synonyms, which constitute semantically similar text, or randomly chosen words, which constitute semantically dissimilar text. We compare the performance of DDR with other prevailing similarity metrics and demonstrate that DDR consistently provides finer discrimination between semantically similar and dissimilar texts, even under minimal, controlled edits.</p>"
    },
    {
      "id": "4e2227b91824",
      "title": "CitiLink: Enhancing Municipal Transparency and Citizen Engagement through Searchable Meeting Minutes",
      "content": "arXiv:2601.18374v1 Announce Type: new  Abstract: City council minutes are typically lengthy and formal documents with a bureaucratic writing style. Although publicly available, their structure often makes it difficult for citizens or journalists to efficiently find information. In this demo, we present CitiLink, a platform designed to transform unstructured municipal meeting minutes into structured and searchable data, demonstrating how NLP and IR can enhance the accessibility and transparency of local government. The system employs LLMs to extract metadata, discussed subjects, and voting outcomes, which are then indexed in a database to support full-text search with BM25 ranking and faceted filtering through a user-friendly interface. The developed system was built over a collection of 120 minutes made available by six Portuguese municipalities. To assess its usability, CitiLink was tested through guided sessions with municipal personnel, providing insights into how real users interact with the system. In addition, we evaluated Gemini's performance in extracting relevant information from the minutes, highlighting its effectiveness in data extraction.",
      "url": "http://arxiv.org/abs/2601.18374",
      "author": "Rodrigo Silva, Jos\\'e Evans, Jos\\'e Isidro, Miguel Marques, Afonso Fonseca, Ricardo Morais, Jo\\~ao Canavilhas, Arian Pasquali, Purifica\\c{c}\\~ao Silvano, Al\\'ipio Jorge, Nuno Guimar\\~aes, S\\'ergio Nunes, Ricardo Campos",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents CitiLink platform transforming municipal meeting minutes into searchable structured data using LLMs for metadata extraction and BM25 ranking. Built over 12 years of Portuguese council data.",
      "importance_score": 48,
      "reasoning": "Applied NLP system with social value for government transparency. Limited technical novelty but good demonstration.",
      "themes": [
        "Information Extraction",
        "Government NLP",
        "Applied Systems"
      ],
      "continuation": null,
      "summary_html": "<p>Presents CitiLink platform transforming municipal meeting minutes into searchable structured data using LLMs for metadata extraction and BM25 ranking. Built over 12 years of Portuguese council data.</p>",
      "content_html": "<p>arXiv:2601.18374v1 Announce Type: new  Abstract: City council minutes are typically lengthy and formal documents with a bureaucratic writing style. Although publicly available, their structure often makes it difficult for citizens or journalists to efficiently find information. In this demo, we present CitiLink, a platform designed to transform unstructured municipal meeting minutes into structured and searchable data, demonstrating how NLP and IR can enhance the accessibility and transparency of local government. The system employs LLMs to extract metadata, discussed subjects, and voting outcomes, which are then indexed in a database to support full-text search with BM25 ranking and faceted filtering through a user-friendly interface. The developed system was built over a collection of 120 minutes made available by six Portuguese municipalities. To assess its usability, CitiLink was tested through guided sessions with municipal personnel, providing insights into how real users interact with the system. In addition, we evaluated Gemini's performance in extracting relevant information from the minutes, highlighting its effectiveness in data extraction.</p>"
    },
    {
      "id": "ffdb551ca185",
      "title": "To Case or Not to Case: An Empirical Study in Learned Sparse Retrieval",
      "content": "arXiv:2601.17500v1 Announce Type: cross  Abstract: Learned Sparse Retrieval (LSR) methods construct sparse lexical representations of queries and documents that can be efficiently searched using inverted indexes. Existing LSR approaches have relied almost exclusively on uncased backbone models, whose vocabularies exclude case-sensitive distinctions, thereby reducing vocabulary mismatch. However, the most recent state-of-the-art language models are only available in cased versions. Despite this shift, the impact of backbone model casing on LSR has not been studied, potentially posing a risk to the viability of the method going forward. To fill this gap, we systematically evaluate paired cased and uncased versions of the same backbone models across multiple datasets to assess their suitability for LSR. Our findings show that LSR models with cased backbone models by default perform substantially worse than their uncased counterparts; however, this gap can be eliminated by pre-processing the text to lowercase. Moreover, our token-level analysis reveals that, under lowercasing, cased models almost entirely suppress cased vocabulary items and behave effectively as uncased models, explaining their restored performance. This result broadens the applicability of recent cased models to the LSR setting and facilitates the integration of stronger backbone architectures into sparse retrieval. The complete code and implementation for this project are available at: https://github.com/lionisakis/Uncased-vs-cased-models-in-LSR",
      "url": "http://arxiv.org/abs/2601.17500",
      "author": "Emmanouil Georgios Lionis, Jia-Huei Ju, Angelos Nalmpantis, Casper Thuis, Sean MacAvaney, Andrew Yates",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.IR"
      ],
      "summary": "Studies impact of backbone model casing (cased vs uncased) on Learned Sparse Retrieval performance, addressing the shift to cased-only modern language models. Fills critical gap for LSR viability.",
      "importance_score": 48,
      "reasoning": "Practical empirical study for information retrieval community. Addresses real concern but limited novelty.",
      "themes": [
        "Information Retrieval",
        "Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>Studies impact of backbone model casing (cased vs uncased) on Learned Sparse Retrieval performance, addressing the shift to cased-only modern language models. Fills critical gap for LSR viability.</p>",
      "content_html": "<p>arXiv:2601.17500v1 Announce Type: cross  Abstract: Learned Sparse Retrieval (LSR) methods construct sparse lexical representations of queries and documents that can be efficiently searched using inverted indexes. Existing LSR approaches have relied almost exclusively on uncased backbone models, whose vocabularies exclude case-sensitive distinctions, thereby reducing vocabulary mismatch. However, the most recent state-of-the-art language models are only available in cased versions. Despite this shift, the impact of backbone model casing on LSR has not been studied, potentially posing a risk to the viability of the method going forward. To fill this gap, we systematically evaluate paired cased and uncased versions of the same backbone models across multiple datasets to assess their suitability for LSR. Our findings show that LSR models with cased backbone models by default perform substantially worse than their uncased counterparts; however, this gap can be eliminated by pre-processing the text to lowercase. Moreover, our token-level analysis reveals that, under lowercasing, cased models almost entirely suppress cased vocabulary items and behave effectively as uncased models, explaining their restored performance. This result broadens the applicability of recent cased models to the LSR setting and facilitates the integration of stronger backbone architectures into sparse retrieval. The complete code and implementation for this project are available at: https://github.com/lionisakis/Uncased-vs-cased-models-in-LSR</p>"
    },
    {
      "id": "f21519c14c68",
      "title": "MEGnifying Emotion: Sentiment Analysis from Annotated Brain Data",
      "content": "arXiv:2601.18792v1 Announce Type: cross  Abstract: Decoding emotion from brain activity could unlock a deeper understanding of the human experience. While a number of existing datasets align brain data with speech and with speech transcripts, no datasets have annotated brain data with sentiment. To bridge this gap, we explore the use of pre-trained Text-to-Sentiment models to annotate non invasive brain recordings, acquired using magnetoencephalography (MEG), while participants listened to audiobooks. Having annotated the text, we employ force-alignment of the text and audio to align our sentiment labels with the brain recordings. It is straightforward then to train Brainto-Sentiment models on these data. Experimental results show an improvement in balanced accuracy for Brain-to-Sentiment compared to baseline, supporting the proposed approach as a proof-of-concept for leveraging existing MEG datasets and learning to decode sentiment directly from the brain.",
      "url": "http://arxiv.org/abs/2601.18792",
      "author": "Brian Liu, Oiwi Parker Jones",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.HC"
      ],
      "summary": "Explores sentiment decoding from MEG brain recordings during audiobook listening, using text-to-sentiment models for annotation and force-alignment for temporal alignment. Shows improved balanced accuracy for brain-to-sentiment prediction.",
      "importance_score": 48,
      "reasoning": "Interesting brain-AI interface work but preliminary results in niche area.",
      "themes": [
        "Brain-Computer Interface",
        "Sentiment Analysis",
        "Neuroscience"
      ],
      "continuation": null,
      "summary_html": "<p>Explores sentiment decoding from MEG brain recordings during audiobook listening, using text-to-sentiment models for annotation and force-alignment for temporal alignment. Shows improved balanced accuracy for brain-to-sentiment prediction.</p>",
      "content_html": "<p>arXiv:2601.18792v1 Announce Type: cross  Abstract: Decoding emotion from brain activity could unlock a deeper understanding of the human experience. While a number of existing datasets align brain data with speech and with speech transcripts, no datasets have annotated brain data with sentiment. To bridge this gap, we explore the use of pre-trained Text-to-Sentiment models to annotate non invasive brain recordings, acquired using magnetoencephalography (MEG), while participants listened to audiobooks. Having annotated the text, we employ force-alignment of the text and audio to align our sentiment labels with the brain recordings. It is straightforward then to train Brainto-Sentiment models on these data. Experimental results show an improvement in balanced accuracy for Brain-to-Sentiment compared to baseline, supporting the proposed approach as a proof-of-concept for leveraging existing MEG datasets and learning to decode sentiment directly from the brain.</p>"
    },
    {
      "id": "37f2844718f5",
      "title": "Inference-Time Loss-Guided Colour Preservation in Diffusion Sampling",
      "content": "arXiv:2601.17259v1 Announce Type: new  Abstract: Precise color control remains a persistent failure mode in text-to-image diffusion systems, particularly in design-oriented workflows where outputs must satisfy explicit, user-specified color targets. We present an inference-time, region-constrained color preservation method that steers a pretrained diffusion model without any additional training. Our approach combines (i) ROI-based inpainting for spatial selectivity, (ii) background-latent re-imposition to prevent color drift outside the ROI, and (iii) latent nudging via gradient guidance using a composite loss defined in CIE Lab and linear RGB. The loss is constructed to control not only the mean ROI color but also the tail of the pixelwise error distribution through CVaR-style and soft-maximum penalties, with a late-start gate and a time-dependent schedule to stabilize guidance across denoising steps. We show that mean-only baselines can satisfy average color constraints while producing perceptually salient local failures, motivating our distribution-aware objective. The resulting method provides a practical, training-free mechanism for targeted color adherence that can be integrated into standard Stable Diffusion inpainting pipelines.",
      "url": "http://arxiv.org/abs/2601.17259",
      "author": "Angad Singh Ahuja, Aarush Ram Anandh",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents inference-time color preservation method for diffusion sampling using ROI-based inpainting, background latent re-imposition, and gradient guidance with composite Lab/RGB loss.",
      "importance_score": 48,
      "reasoning": "Practical improvement for design-oriented diffusion workflows but limited novelty.",
      "themes": [
        "Image Generation",
        "Diffusion Models",
        "Color Control"
      ],
      "continuation": null,
      "summary_html": "<p>Presents inference-time color preservation method for diffusion sampling using ROI-based inpainting, background latent re-imposition, and gradient guidance with composite Lab/RGB loss.</p>",
      "content_html": "<p>arXiv:2601.17259v1 Announce Type: new  Abstract: Precise color control remains a persistent failure mode in text-to-image diffusion systems, particularly in design-oriented workflows where outputs must satisfy explicit, user-specified color targets. We present an inference-time, region-constrained color preservation method that steers a pretrained diffusion model without any additional training. Our approach combines (i) ROI-based inpainting for spatial selectivity, (ii) background-latent re-imposition to prevent color drift outside the ROI, and (iii) latent nudging via gradient guidance using a composite loss defined in CIE Lab and linear RGB. The loss is constructed to control not only the mean ROI color but also the tail of the pixelwise error distribution through CVaR-style and soft-maximum penalties, with a late-start gate and a time-dependent schedule to stabilize guidance across denoising steps. We show that mean-only baselines can satisfy average color constraints while producing perceptually salient local failures, motivating our distribution-aware objective. The resulting method provides a practical, training-free mechanism for targeted color adherence that can be integrated into standard Stable Diffusion inpainting pipelines.</p>"
    },
    {
      "id": "6d7ec0124857",
      "title": "SymbolSight: Minimizing Inter-Symbol Interference for Reading with Prosthetic Vision",
      "content": "arXiv:2601.17326v1 Announce Type: new  Abstract: Retinal prostheses restore limited visual perception, but low spatial resolution and temporal persistence make reading difficult. In sequential letter presentation, the afterimage of one symbol can interfere with perception of the next, leading to systematic recognition errors. Rather than relying on future hardware improvements, we investigate whether optimizing the visual symbols themselves can mitigate this temporal interference. We present SymbolSight, a computational framework that selects symbol-to-letter mappings to minimize confusion among frequently adjacent letters. Using simulated prosthetic vision (SPV) and a neural proxy observer, we estimate pairwise symbol confusability and optimize assignments using language-specific bigram statistics. Across simulations in Arabic, Bulgarian, and English, the resulting heterogeneous symbol sets reduced predicted confusion by a median factor of 22 relative to native alphabets. These results suggest that standard typography is poorly matched to serial, low-bandwidth prosthetic vision and demonstrate how computational modeling can efficiently narrow the design space of visual encodings to generate high-potential candidates for future psychophysical and clinical evaluation.",
      "url": "http://arxiv.org/abs/2601.17326",
      "author": "Jasmine Lesner, Michael Beyeler",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes SymbolSight computational framework to minimize inter-symbol interference in prosthetic vision reading by optimizing symbol-to-letter mappings using simulated prosthetic vision and neural proxy observer.",
      "importance_score": 48,
      "reasoning": "Interesting accessibility application addressing unique challenges of visual prostheses.",
      "themes": [
        "Accessibility",
        "Prosthetic Vision",
        "Symbol Recognition"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes SymbolSight computational framework to minimize inter-symbol interference in prosthetic vision reading by optimizing symbol-to-letter mappings using simulated prosthetic vision and neural proxy observer.</p>",
      "content_html": "<p>arXiv:2601.17326v1 Announce Type: new  Abstract: Retinal prostheses restore limited visual perception, but low spatial resolution and temporal persistence make reading difficult. In sequential letter presentation, the afterimage of one symbol can interfere with perception of the next, leading to systematic recognition errors. Rather than relying on future hardware improvements, we investigate whether optimizing the visual symbols themselves can mitigate this temporal interference. We present SymbolSight, a computational framework that selects symbol-to-letter mappings to minimize confusion among frequently adjacent letters. Using simulated prosthetic vision (SPV) and a neural proxy observer, we estimate pairwise symbol confusability and optimize assignments using language-specific bigram statistics. Across simulations in Arabic, Bulgarian, and English, the resulting heterogeneous symbol sets reduced predicted confusion by a median factor of 22 relative to native alphabets. These results suggest that standard typography is poorly matched to serial, low-bandwidth prosthetic vision and demonstrate how computational modeling can efficiently narrow the design space of visual encodings to generate high-potential candidates for future psychophysical and clinical evaluation.</p>"
    },
    {
      "id": "d04ba3c2c605",
      "title": "ReflexSplit: Single Image Reflection Separation via Layer Fusion-Separation",
      "content": "arXiv:2601.17468v1 Announce Type: new  Abstract: Single Image Reflection Separation (SIRS) disentangles mixed images into transmission and reflection layers. Existing methods suffer from transmission-reflection confusion under nonlinear mixing, particularly in deep decoder layers, due to implicit fusion mechanisms and inadequate multi-scale coordination. We propose ReflexSplit, a dual-stream framework with three key innovations. (1) Cross-scale Gated Fusion (CrGF) adaptively aggregates semantic priors, texture details, and decoder context across hierarchical depths, stabilizing gradient flow and maintaining feature consistency. (2) Layer Fusion-Separation Blocks (LFSB) alternate between fusion for shared structure extraction and differential separation for layer-specific disentanglement. Inspired by Differential Transformer, we extend attention cancellation to dual-stream separation via cross-stream subtraction. (3) Curriculum training progressively strengthens differential separation through depth-dependent initialization and epoch-wise warmup. Extensive experiments on synthetic and real-world benchmarks demonstrate state-of-the-art performance with superior perceptual quality and robust generalization. Our code is available at https://github.com/wuw2135/ReflexSplit.",
      "url": "http://arxiv.org/abs/2601.17468",
      "author": "Chia-Ming Lee, Yu-Fan Lin, Jing-Hui Jung, Yu-Jou Hsiao, Chih-Chung Hsu, Yu-Lun Liu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes ReflexSplit for single image reflection separation using Cross-scale Gated Fusion and Layer Fusion-Separation Blocks to address transmission-reflection confusion in deep decoder layers.",
      "importance_score": 48,
      "reasoning": "Solid reflection separation work with reasonable architectural contributions.",
      "themes": [
        "Image Restoration",
        "Reflection Removal",
        "Deep Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes ReflexSplit for single image reflection separation using Cross-scale Gated Fusion and Layer Fusion-Separation Blocks to address transmission-reflection confusion in deep decoder layers.</p>",
      "content_html": "<p>arXiv:2601.17468v1 Announce Type: new  Abstract: Single Image Reflection Separation (SIRS) disentangles mixed images into transmission and reflection layers. Existing methods suffer from transmission-reflection confusion under nonlinear mixing, particularly in deep decoder layers, due to implicit fusion mechanisms and inadequate multi-scale coordination. We propose ReflexSplit, a dual-stream framework with three key innovations. (1) Cross-scale Gated Fusion (CrGF) adaptively aggregates semantic priors, texture details, and decoder context across hierarchical depths, stabilizing gradient flow and maintaining feature consistency. (2) Layer Fusion-Separation Blocks (LFSB) alternate between fusion for shared structure extraction and differential separation for layer-specific disentanglement. Inspired by Differential Transformer, we extend attention cancellation to dual-stream separation via cross-stream subtraction. (3) Curriculum training progressively strengthens differential separation through depth-dependent initialization and epoch-wise warmup. Extensive experiments on synthetic and real-world benchmarks demonstrate state-of-the-art performance with superior perceptual quality and robust generalization. Our code is available at https://github.com/wuw2135/ReflexSplit.</p>"
    },
    {
      "id": "1cc7ab1ea806",
      "title": "Flatten The Complex: Joint B-Rep Generation via Compositional $k$-Cell Particles",
      "content": "arXiv:2601.17733v1 Announce Type: new  Abstract: Boundary Representation (B-Rep) is the widely adopted standard   in Computer-Aided Design (CAD) and manufacturing. However, generative modeling of B-Reps remains a formidable challenge due to their inherent heterogeneity as geometric cell complexes, which entangles topology with geometry across cells of varying orders (i.e., $k$-cells such as vertices, edges, faces). Previous methods typically rely on cascaded sequences to handle this hierarchy, which fails to fully exploit the geometric relationships between cells, such as adjacency and sharing, limiting context awareness and error recovery. To fill this gap, we introduce a novel paradigm that reformulates B-Reps into sets of compositional $k$-cell particles. Our approach encodes each topological entity as a composition of particles, where adjacent cells share identical latents at their interfaces, thereby promoting geometric coupling along shared boundaries. By decoupling the rigid hierarchy, our representation unifies vertices, edges, and faces, enabling the joint generation of topology and geometry with global context awareness.   We synthesize these particle sets using a multi-modal flow matching framework to handle unconditional generation as well as precise conditional tasks, such as 3D reconstruction from single-view or point cloud. Furthermore, the explicit and localized nature of our representation naturally extends to downstream tasks like local in-painting and enables the direct synthesis of non-manifold structures (e.g., wireframes). Extensive experiments demonstrate that our method produces high-fidelity CAD models with superior validity and editability compared to state-of-the-art methods.",
      "url": "http://arxiv.org/abs/2601.17733",
      "author": "Junran Lu, Yuanqi Li, Hengji Li, Jie Guo, Yanwen Guo",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces a novel paradigm for B-Rep (Boundary Representation) generation in CAD by reformulating B-Reps as sets of compositional k-cell particles, encoding topology and geometry jointly rather than in cascaded sequences.",
      "importance_score": 48,
      "reasoning": "Novel approach for CAD generative modeling. Important for manufacturing but niche audience.",
      "themes": [
        "CAD",
        "Generative Models",
        "3D Generation"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces a novel paradigm for B-Rep (Boundary Representation) generation in CAD by reformulating B-Reps as sets of compositional k-cell particles, encoding topology and geometry jointly rather than in cascaded sequences.</p>",
      "content_html": "<p>arXiv:2601.17733v1 Announce Type: new  Abstract: Boundary Representation (B-Rep) is the widely adopted standard   in Computer-Aided Design (CAD) and manufacturing. However, generative modeling of B-Reps remains a formidable challenge due to their inherent heterogeneity as geometric cell complexes, which entangles topology with geometry across cells of varying orders (i.e., $k$-cells such as vertices, edges, faces). Previous methods typically rely on cascaded sequences to handle this hierarchy, which fails to fully exploit the geometric relationships between cells, such as adjacency and sharing, limiting context awareness and error recovery. To fill this gap, we introduce a novel paradigm that reformulates B-Reps into sets of compositional $k$-cell particles. Our approach encodes each topological entity as a composition of particles, where adjacent cells share identical latents at their interfaces, thereby promoting geometric coupling along shared boundaries. By decoupling the rigid hierarchy, our representation unifies vertices, edges, and faces, enabling the joint generation of topology and geometry with global context awareness.   We synthesize these particle sets using a multi-modal flow matching framework to handle unconditional generation as well as precise conditional tasks, such as 3D reconstruction from single-view or point cloud. Furthermore, the explicit and localized nature of our representation naturally extends to downstream tasks like local in-painting and enables the direct synthesis of non-manifold structures (e.g., wireframes). Extensive experiments demonstrate that our method produces high-fidelity CAD models with superior validity and editability compared to state-of-the-art methods.</p>"
    },
    {
      "id": "978170b980b1",
      "title": "Video Compression with Hierarchical Temporal Neural Representation",
      "content": "arXiv:2601.17743v1 Announce Type: new  Abstract: Video compression has recently benefited from implicit neural representations (INRs), which model videos as continuous functions. INRs offer compact storage and flexible reconstruction, providing a promising alternative to traditional codecs. However, most existing INR-based methods treat the temporal dimension as an independent input, limiting their ability to capture complex temporal dependencies. To address this, we propose a Hierarchical Temporal Neural Representation for Videos, TeNeRV. TeNeRV integrates short- and long-term dependencies through two key components. First, an Inter-Frame Feature Fusion (IFF) module aggregates features from adjacent frames, enforcing local temporal coherence and capturing fine-grained motion. Second, a GoP-Adaptive Modulation (GAM) mechanism partitions videos into Groups-of-Pictures and learns group-specific priors. The mechanism modulates network parameters, enabling adaptive representations across different GoPs. Extensive experiments demonstrate that TeNeRV consistently outperforms existing INR-based methods in rate-distortion performance, validating the effectiveness of our proposed approach.",
      "url": "http://arxiv.org/abs/2601.17743",
      "author": "Jun Zhu, Xinfeng Zhang, Lv Tang, Junhao Jiang, Gai Zhang, Jia Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "TeNeRV proposes hierarchical temporal neural representation for video compression with inter-frame feature fusion for local temporal coherence and global aggregation modules for long-term dependencies.",
      "importance_score": 48,
      "reasoning": "Similar to FaNeRV, addresses temporal modeling in INR-based video compression. Complementary approach.",
      "themes": [
        "Video Compression",
        "Neural Representations",
        "Temporal Modeling"
      ],
      "continuation": null,
      "summary_html": "<p>TeNeRV proposes hierarchical temporal neural representation for video compression with inter-frame feature fusion for local temporal coherence and global aggregation modules for long-term dependencies.</p>",
      "content_html": "<p>arXiv:2601.17743v1 Announce Type: new  Abstract: Video compression has recently benefited from implicit neural representations (INRs), which model videos as continuous functions. INRs offer compact storage and flexible reconstruction, providing a promising alternative to traditional codecs. However, most existing INR-based methods treat the temporal dimension as an independent input, limiting their ability to capture complex temporal dependencies. To address this, we propose a Hierarchical Temporal Neural Representation for Videos, TeNeRV. TeNeRV integrates short- and long-term dependencies through two key components. First, an Inter-Frame Feature Fusion (IFF) module aggregates features from adjacent frames, enforcing local temporal coherence and capturing fine-grained motion. Second, a GoP-Adaptive Modulation (GAM) mechanism partitions videos into Groups-of-Pictures and learns group-specific priors. The mechanism modulates network parameters, enabling adaptive representations across different GoPs. Extensive experiments demonstrate that TeNeRV consistently outperforms existing INR-based methods in rate-distortion performance, validating the effectiveness of our proposed approach.</p>"
    },
    {
      "id": "fefc9cb8ee8c",
      "title": "MorphXAI: An Explainable Framework for Morphological Analysis of Parasites in Blood Smear Images",
      "content": "arXiv:2601.18001v1 Announce Type: new  Abstract: Parasitic infections remain a pressing global health challenge, particularly in low-resource settings where diagnosis still depends on labor-intensive manual inspection of blood smears and the availability of expert domain knowledge. While deep learning models have shown strong performance in automating parasite detection, their clinical usefulness is constrained by limited interpretability. Existing explainability methods are largely restricted to visual heatmaps or attention maps, which highlight regions of interest but fail to capture the morphological traits that clinicians rely on for diagnosis. In this work, we present MorphXAI, an explainable framework that unifies parasite detection with fine-grained morphological analysis. MorphXAI integrates morphological supervision directly into the prediction pipeline, enabling the model to localize parasites while simultaneously characterizing clinically relevant attributes such as shape, curvature, visible dot count, flagellum presence, and developmental stage. To support this task, we curate a clinician-annotated dataset of three parasite species (Leishmania, Trypanosoma brucei, and Trypanosoma cruzi) with detailed morphological labels, establishing a new benchmark for interpretable parasite analysis. Experimental results show that MorphXAI not only improves detection performance over the baseline but also provides structured, biologically meaningful explanations.",
      "url": "http://arxiv.org/abs/2601.18001",
      "author": "Aqsa Yousaf, Sint Sint Win, Megan Coffee, Habeeb Olufowobi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "MorphXAI provides explainable parasite detection by unifying detection with fine-grained morphological analysis, moving beyond visual heatmaps to capture clinically-relevant morphological traits.",
      "importance_score": 48,
      "reasoning": "Important XAI contribution for medical diagnosis. Domain-specific but addresses real clinical interpretability needs.",
      "themes": [
        "Explainable AI",
        "Medical Imaging",
        "Parasitology"
      ],
      "continuation": null,
      "summary_html": "<p>MorphXAI provides explainable parasite detection by unifying detection with fine-grained morphological analysis, moving beyond visual heatmaps to capture clinically-relevant morphological traits.</p>",
      "content_html": "<p>arXiv:2601.18001v1 Announce Type: new  Abstract: Parasitic infections remain a pressing global health challenge, particularly in low-resource settings where diagnosis still depends on labor-intensive manual inspection of blood smears and the availability of expert domain knowledge. While deep learning models have shown strong performance in automating parasite detection, their clinical usefulness is constrained by limited interpretability. Existing explainability methods are largely restricted to visual heatmaps or attention maps, which highlight regions of interest but fail to capture the morphological traits that clinicians rely on for diagnosis. In this work, we present MorphXAI, an explainable framework that unifies parasite detection with fine-grained morphological analysis. MorphXAI integrates morphological supervision directly into the prediction pipeline, enabling the model to localize parasites while simultaneously characterizing clinically relevant attributes such as shape, curvature, visible dot count, flagellum presence, and developmental stage. To support this task, we curate a clinician-annotated dataset of three parasite species (Leishmania, Trypanosoma brucei, and Trypanosoma cruzi) with detailed morphological labels, establishing a new benchmark for interpretable parasite analysis. Experimental results show that MorphXAI not only improves detection performance over the baseline but also provides structured, biologically meaningful explanations.</p>"
    },
    {
      "id": "3d3eccc24ef8",
      "title": "Text-Pass Filter: An Efficient Scene Text Detector",
      "content": "arXiv:2601.18098v1 Announce Type: new  Abstract: To pursue an efficient text assembling process, existing methods detect texts via the shrink-mask expansion strategy. However, the shrinking operation loses the visual features of text margins and confuses the foreground and background difference, which brings intrinsic limitations to recognize text features. We follow this issue and design Text-Pass Filter (TPF) for arbitrary-shaped text detection. It segments the whole text directly, which avoids the intrinsic limitations. It is noteworthy that different from previous whole text region-based methods, TPF can separate adhesive texts naturally without complex decoding or post-processing processes, which makes it possible for real-time text detection. Concretely, we find that the band-pass filter allows through components in a specified band of frequencies, called its passband but blocks components with frequencies above or below this band. It provides a natural idea for extracting whole texts separately. By simulating the band-pass filter, TPF constructs a unique feature-filter pair for each text. In the inference stage, every filter extracts the corresponding matched text by passing its pass-feature and blocking other features. Meanwhile, considering the large aspect ratio problem of ribbon-like texts makes it hard to recognize texts wholly, a Reinforcement Ensemble Unit (REU) is designed to enhance the feature consistency of the same text and to enlarge the filter's recognition field to help recognize whole texts. Furthermore, a Foreground Prior Unit (FPU) is introduced to encourage TPF to discriminate the difference between the foreground and background, which improves the feature-filter pair quality. Experiments demonstrate the effectiveness of REU and FPU while showing the TPF's superiority.",
      "url": "http://arxiv.org/abs/2601.18098",
      "author": "Chuang Yang, Haozhao Ma, Xu Han, Yuan Yuan, Qi Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Text-Pass Filter proposes band-pass filtering analogy for scene text detection, segmenting whole text regions directly while naturally separating adhesive texts without complex post-processing.",
      "importance_score": 48,
      "reasoning": "Novel conceptual approach using signal processing analogy. Enables real-time text detection.",
      "themes": [
        "Text Detection",
        "Scene Understanding",
        "Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>Text-Pass Filter proposes band-pass filtering analogy for scene text detection, segmenting whole text regions directly while naturally separating adhesive texts without complex post-processing.</p>",
      "content_html": "<p>arXiv:2601.18098v1 Announce Type: new  Abstract: To pursue an efficient text assembling process, existing methods detect texts via the shrink-mask expansion strategy. However, the shrinking operation loses the visual features of text margins and confuses the foreground and background difference, which brings intrinsic limitations to recognize text features. We follow this issue and design Text-Pass Filter (TPF) for arbitrary-shaped text detection. It segments the whole text directly, which avoids the intrinsic limitations. It is noteworthy that different from previous whole text region-based methods, TPF can separate adhesive texts naturally without complex decoding or post-processing processes, which makes it possible for real-time text detection. Concretely, we find that the band-pass filter allows through components in a specified band of frequencies, called its passband but blocks components with frequencies above or below this band. It provides a natural idea for extracting whole texts separately. By simulating the band-pass filter, TPF constructs a unique feature-filter pair for each text. In the inference stage, every filter extracts the corresponding matched text by passing its pass-feature and blocking other features. Meanwhile, considering the large aspect ratio problem of ribbon-like texts makes it hard to recognize texts wholly, a Reinforcement Ensemble Unit (REU) is designed to enhance the feature consistency of the same text and to enlarge the filter's recognition field to help recognize whole texts. Furthermore, a Foreground Prior Unit (FPU) is introduced to encourage TPF to discriminate the difference between the foreground and background, which improves the feature-filter pair quality. Experiments demonstrate the effectiveness of REU and FPU while showing the TPF's superiority.</p>"
    },
    {
      "id": "c77b833104c4",
      "title": "Forward Consistency Learning with Gated Context Aggregation for Video Anomaly Detection",
      "content": "arXiv:2601.18135v1 Announce Type: new  Abstract: As a crucial element of public security, video anomaly detection (VAD) aims to measure deviations from normal patterns for various events in real-time surveillance systems. However, most existing VAD methods rely on large-scale models to pursue extreme accuracy, limiting their feasibility on resource-limited edge devices. Moreover, mainstream prediction-based VAD detects anomalies using only single-frame future prediction errors, overlooking the richer constraints from longer-term temporal forward information. In this paper, we introduce FoGA, a lightweight VAD model that performs Forward consistency learning with Gated context Aggregation, containing about 2M parameters and tailored for potential edge devices. Specifically, we propose a Unet-based method that performs feature extraction on consecutive frames to generate both immediate and forward predictions. Then, we introduce a gated context aggregation module into the skip connections to dynamically fuse encoder and decoder features at the same spatial scale. Finally, the model is jointly optimized with a novel forward consistency loss, and a hybrid anomaly measurement strategy is adopted to integrate errors from both immediate and forward frames for more accurate detection. Extensive experiments demonstrate the effectiveness of the proposed method, which substantially outperforms state-of-the-art competing methods, running up to 155 FPS. Hence, our FoGA achieves an excellent trade-off between performance and the efficiency metric.",
      "url": "http://arxiv.org/abs/2601.18135",
      "author": "Jiahao Lyu, Minghua Zhao, Xuewen Huang, Yifei Chen, Shuangli Du, Jing Hu, Cheng Shi, Zhiyong Lv",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "FoGA introduces lightweight (~2M parameters) video anomaly detection with forward consistency learning and gated context aggregation, designed for edge device deployment.",
      "importance_score": 48,
      "reasoning": "Practical contribution for edge deployment. Good efficiency focus but limited novelty.",
      "themes": [
        "Video Anomaly Detection",
        "Edge Computing",
        "Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>FoGA introduces lightweight (~2M parameters) video anomaly detection with forward consistency learning and gated context aggregation, designed for edge device deployment.</p>",
      "content_html": "<p>arXiv:2601.18135v1 Announce Type: new  Abstract: As a crucial element of public security, video anomaly detection (VAD) aims to measure deviations from normal patterns for various events in real-time surveillance systems. However, most existing VAD methods rely on large-scale models to pursue extreme accuracy, limiting their feasibility on resource-limited edge devices. Moreover, mainstream prediction-based VAD detects anomalies using only single-frame future prediction errors, overlooking the richer constraints from longer-term temporal forward information. In this paper, we introduce FoGA, a lightweight VAD model that performs Forward consistency learning with Gated context Aggregation, containing about 2M parameters and tailored for potential edge devices. Specifically, we propose a Unet-based method that performs feature extraction on consecutive frames to generate both immediate and forward predictions. Then, we introduce a gated context aggregation module into the skip connections to dynamically fuse encoder and decoder features at the same spatial scale. Finally, the model is jointly optimized with a novel forward consistency loss, and a hybrid anomaly measurement strategy is adopted to integrate errors from both immediate and forward frames for more accurate detection. Extensive experiments demonstrate the effectiveness of the proposed method, which substantially outperforms state-of-the-art competing methods, running up to 155 FPS. Hence, our FoGA achieves an excellent trade-off between performance and the efficiency metric.</p>"
    },
    {
      "id": "a30c1ffe292f",
      "title": "Multi-Perspective Subimage CLIP with Keyword Guidance for Remote Sensing Image-Text Retrieval",
      "content": "arXiv:2601.18190v1 Announce Type: new  Abstract: Vision-Language Pre-training (VLP) models like CLIP have significantly advanced Remote Sensing Image-Text Retrieval (RSITR). However, existing methods predominantly rely on coarse-grained global alignment, which often overlooks the dense, multi-scale semantics inherent in overhead imagery. Moreover, adapting these heavy models via full fine-tuning incurs prohibitive computational costs and risks catastrophic forgetting. To address these challenges, we propose MPS-CLIP, a parameter-efficient framework designed to shift the retrieval paradigm from global matching to keyword-guided fine-grained alignment. Specifically, we leverage a Large Language Model (LLM) to extract core semantic keywords, guiding the Segment Anything Model (SamGeo) to generate semantically relevant sub-perspectives. To efficiently adapt the frozen backbone, we introduce a Gated Global Attention (G^2A) adapter, which captures global context and long-range dependencies with minimal overhead. Furthermore, a Multi-Perspective Representation (MPR) module aggregates these local cues into robust multi-perspective embeddings. The framework is optimized via a hybrid objective combining multi-perspective contrastive and weighted triplet losses, which dynamically selects maximum-response perspectives to suppress noise and enforce precise semantic matching. Extensive experiments on the RSICD and RSITMD benchmarks demonstrate that MPS-CLIP achieves state-of-the-art performance with 35.18% and 48.40% mean Recall (mR), respectively, significantly outperforming full fine-tuning baselines and recent competitive methods. Code is available at https://github.com/Lcrucial1f/MPS-CLIP.",
      "url": "http://arxiv.org/abs/2601.18190",
      "author": "Yifan Li, Shiying Wang, Jianqiang Huang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "MPS-CLIP shifts remote sensing image-text retrieval from global matching to keyword-guided fine-grained alignment, using LLM for keyword extraction and SamGeo for subimage generation.",
      "importance_score": 48,
      "reasoning": "Practical framework combining multiple existing tools. Parameter-efficient approach for CLIP adaptation.",
      "themes": [
        "Remote Sensing",
        "Vision-Language Models",
        "Image Retrieval"
      ],
      "continuation": null,
      "summary_html": "<p>MPS-CLIP shifts remote sensing image-text retrieval from global matching to keyword-guided fine-grained alignment, using LLM for keyword extraction and SamGeo for subimage generation.</p>",
      "content_html": "<p>arXiv:2601.18190v1 Announce Type: new  Abstract: Vision-Language Pre-training (VLP) models like CLIP have significantly advanced Remote Sensing Image-Text Retrieval (RSITR). However, existing methods predominantly rely on coarse-grained global alignment, which often overlooks the dense, multi-scale semantics inherent in overhead imagery. Moreover, adapting these heavy models via full fine-tuning incurs prohibitive computational costs and risks catastrophic forgetting. To address these challenges, we propose MPS-CLIP, a parameter-efficient framework designed to shift the retrieval paradigm from global matching to keyword-guided fine-grained alignment. Specifically, we leverage a Large Language Model (LLM) to extract core semantic keywords, guiding the Segment Anything Model (SamGeo) to generate semantically relevant sub-perspectives. To efficiently adapt the frozen backbone, we introduce a Gated Global Attention (G^2A) adapter, which captures global context and long-range dependencies with minimal overhead. Furthermore, a Multi-Perspective Representation (MPR) module aggregates these local cues into robust multi-perspective embeddings. The framework is optimized via a hybrid objective combining multi-perspective contrastive and weighted triplet losses, which dynamically selects maximum-response perspectives to suppress noise and enforce precise semantic matching. Extensive experiments on the RSICD and RSITMD benchmarks demonstrate that MPS-CLIP achieves state-of-the-art performance with 35.18% and 48.40% mean Recall (mR), respectively, significantly outperforming full fine-tuning baselines and recent competitive methods. Code is available at https://github.com/Lcrucial1f/MPS-CLIP.</p>"
    },
    {
      "id": "15045db6ab3d",
      "title": "Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation",
      "content": "arXiv:2601.18242v1 Announce Type: new  Abstract: Accurate radio-frequency (RF) material parameters are essential for electromagnetic digital twins in 6G systems, yet gradient-based inverse ray tracing (RT) remains sensitive to initialization and costly under limited measurements. This paper proposes a vision-language-model (VLM) guided framework that accelerates and stabilizes multi-material parameter estimation in a differentiable RT (DRT) engine. A VLM parses scene images to infer material categories and maps them to quantitative priors via an ITU-R material table, yielding informed conductivity initializations. The VLM further selects informative transmitter/receiver placements that promote diverse, material-discriminative paths. Starting from these priors, the DRT performs gradient-based refinement using measured received signal strengths. Experiments in NVIDIA Sionna on indoor scenes show 2-4$\\times$ faster convergence and 10-100$\\times$ lower final parameter error compared with uniform or random initialization and random placement baselines, achieving sub-0.1\\% mean relative error with only a few receivers. Complexity analyses indicate per-iteration time scales near-linearly with the number of materials and measurement setups, while VLM-guided placement reduces the measurements required for accurate recovery. Ablations over RT depth and ray counts confirm further accuracy gains without significant per-iteration overhead. Results demonstrate that semantic priors from VLMs effectively guide physics-based optimization for fast and reliable RF material estimation.",
      "url": "http://arxiv.org/abs/2601.18242",
      "author": "Zerui Kang, Yishen Lim, Zhouyou Gu, Seung-Woo Ko, Tony Q. S. Quek, Jihong Park",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes VLM-guided framework for multi-material RF parameter estimation in differentiable ray tracing, using VLM to parse scenes for material priors and select informative transmitter/receiver placements.",
      "importance_score": 48,
      "reasoning": "Interesting application of VLMs to physics simulation. Niche 6G/digital twin application.",
      "themes": [
        "Vision-Language Models",
        "Physics Simulation",
        "Digital Twins"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes VLM-guided framework for multi-material RF parameter estimation in differentiable ray tracing, using VLM to parse scenes for material priors and select informative transmitter/receiver placements.</p>",
      "content_html": "<p>arXiv:2601.18242v1 Announce Type: new  Abstract: Accurate radio-frequency (RF) material parameters are essential for electromagnetic digital twins in 6G systems, yet gradient-based inverse ray tracing (RT) remains sensitive to initialization and costly under limited measurements. This paper proposes a vision-language-model (VLM) guided framework that accelerates and stabilizes multi-material parameter estimation in a differentiable RT (DRT) engine. A VLM parses scene images to infer material categories and maps them to quantitative priors via an ITU-R material table, yielding informed conductivity initializations. The VLM further selects informative transmitter/receiver placements that promote diverse, material-discriminative paths. Starting from these priors, the DRT performs gradient-based refinement using measured received signal strengths. Experiments in NVIDIA Sionna on indoor scenes show 2-4$\\times$ faster convergence and 10-100$\\times$ lower final parameter error compared with uniform or random initialization and random placement baselines, achieving sub-0.1\\% mean relative error with only a few receivers. Complexity analyses indicate per-iteration time scales near-linearly with the number of materials and measurement setups, while VLM-guided placement reduces the measurements required for accurate recovery. Ablations over RT depth and ray counts confirm further accuracy gains without significant per-iteration overhead. Results demonstrate that semantic priors from VLMs effectively guide physics-based optimization for fast and reliable RF material estimation.</p>"
    },
    {
      "id": "02635920a691",
      "title": "Gaze Prediction in Virtual Reality Without Eye Tracking Using Visual and Head Motion Cues",
      "content": "arXiv:2601.18372v1 Announce Type: new  Abstract: Gaze prediction plays a critical role in Virtual Reality (VR) applications by reducing sensor-induced latency and enabling computationally demanding techniques such as foveated rendering, which rely on anticipating user attention. However, direct eye tracking is often unavailable due to hardware limitations or privacy concerns. To address this, we present a novel gaze prediction framework that combines Head-Mounted Display (HMD) motion signals with visual saliency cues derived from video frames. Our method employs UniSal, a lightweight saliency encoder, to extract visual features, which are then fused with HMD motion data and processed through a time-series prediction module. We evaluate two lightweight architectures, TSMixer and LSTM, for forecasting future gaze directions. Experiments on the EHTask dataset, along with deployment on commercial VR hardware, show that our approach consistently outperforms baselines such as Center-of-HMD and Mean Gaze. These results demonstrate the effectiveness of predictive gaze modeling in reducing perceptual lag and enhancing natural interaction in VR environments where direct eye tracking is constrained.",
      "url": "http://arxiv.org/abs/2601.18372",
      "author": "Christos Petrou, Harris Partaourides, Athanasios Balomenos, Yannis Kopsinis, Sotirios Chatzis",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents gaze prediction framework for VR that combines HMD motion signals with visual saliency cues when eye tracking is unavailable due to hardware or privacy constraints.",
      "importance_score": 48,
      "reasoning": "Practical solution for VR applications. Addresses real deployment constraint.",
      "themes": [
        "Virtual Reality",
        "Gaze Prediction",
        "Privacy"
      ],
      "continuation": null,
      "summary_html": "<p>Presents gaze prediction framework for VR that combines HMD motion signals with visual saliency cues when eye tracking is unavailable due to hardware or privacy constraints.</p>",
      "content_html": "<p>arXiv:2601.18372v1 Announce Type: new  Abstract: Gaze prediction plays a critical role in Virtual Reality (VR) applications by reducing sensor-induced latency and enabling computationally demanding techniques such as foveated rendering, which rely on anticipating user attention. However, direct eye tracking is often unavailable due to hardware limitations or privacy concerns. To address this, we present a novel gaze prediction framework that combines Head-Mounted Display (HMD) motion signals with visual saliency cues derived from video frames. Our method employs UniSal, a lightweight saliency encoder, to extract visual features, which are then fused with HMD motion data and processed through a time-series prediction module. We evaluate two lightweight architectures, TSMixer and LSTM, for forecasting future gaze directions. Experiments on the EHTask dataset, along with deployment on commercial VR hardware, show that our approach consistently outperforms baselines such as Center-of-HMD and Mean Gaze. These results demonstrate the effectiveness of predictive gaze modeling in reducing perceptual lag and enhancing natural interaction in VR environments where direct eye tracking is constrained.</p>"
    },
    {
      "id": "b95755649d2d",
      "title": "AI-enabled Satellite Edge Computing: A Single-Pixel Feature based Shallow Classification Model for Hyperspectral Imaging",
      "content": "arXiv:2601.18560v1 Announce Type: new  Abstract: As the important component of the Earth observation system, hyperspectral imaging satellites provide high-fidelity and enriched information for the formulation of related policies due to the powerful spectral measurement capabilities. However, the transmission speed of the satellite downlink has become a major bottleneck in certain applications, such as disaster monitoring and emergency mapping, which demand a fast response ability. We propose an efficient AI-enabled Satellite Edge Computing paradigm for hyperspectral image classification, facilitating the satellites to attain autonomous decision-making. To accommodate the resource constraints of satellite platforms, the proposed method adopts a lightweight, non-deep learning framework integrated with a few-shot learning strategy. Moreover, onboard processing on satellites could be faced with sensor failure and scan pattern errors, which result in degraded image quality with bad/misaligned pixels and mixed noise. To address these challenges, we develop a novel two-stage pixel-wise label propagation scheme that utilizes only intrinsic spectral features at the single pixel level without the necessity to consider spatial structural information as requested by deep neural networks. In the first stage, initial pixel labels are obtained by propagating selected anchor labels through the constructed anchor-pixel affinity matrix. Subsequently, a top-k pruned sparse graph is generated by directly computing pixel-level similarities. In the second stage, a closed-form solution derived from the sparse graph is employed to replace iterative computations. Furthermore, we developed a rank constraint-based graph clustering algorithm to determine the anchor labels.",
      "url": "http://arxiv.org/abs/2601.18560",
      "author": "Li Fang, Tianyu Li, Yanghong Lin, Shudong Zhou, Wei Yao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes lightweight non-deep learning framework for hyperspectral classification on satellite edge computing, using single-pixel features for autonomous decision-making under resource constraints.",
      "importance_score": 48,
      "reasoning": "Practical edge deployment solution. Important for real-time satellite applications.",
      "themes": [
        "Satellite Imaging",
        "Edge Computing",
        "Hyperspectral"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes lightweight non-deep learning framework for hyperspectral classification on satellite edge computing, using single-pixel features for autonomous decision-making under resource constraints.</p>",
      "content_html": "<p>arXiv:2601.18560v1 Announce Type: new  Abstract: As the important component of the Earth observation system, hyperspectral imaging satellites provide high-fidelity and enriched information for the formulation of related policies due to the powerful spectral measurement capabilities. However, the transmission speed of the satellite downlink has become a major bottleneck in certain applications, such as disaster monitoring and emergency mapping, which demand a fast response ability. We propose an efficient AI-enabled Satellite Edge Computing paradigm for hyperspectral image classification, facilitating the satellites to attain autonomous decision-making. To accommodate the resource constraints of satellite platforms, the proposed method adopts a lightweight, non-deep learning framework integrated with a few-shot learning strategy. Moreover, onboard processing on satellites could be faced with sensor failure and scan pattern errors, which result in degraded image quality with bad/misaligned pixels and mixed noise. To address these challenges, we develop a novel two-stage pixel-wise label propagation scheme that utilizes only intrinsic spectral features at the single pixel level without the necessity to consider spatial structural information as requested by deep neural networks. In the first stage, initial pixel labels are obtained by propagating selected anchor labels through the constructed anchor-pixel affinity matrix. Subsequently, a top-k pruned sparse graph is generated by directly computing pixel-level similarities. In the second stage, a closed-form solution derived from the sparse graph is employed to replace iterative computations. Furthermore, we developed a rank constraint-based graph clustering algorithm to determine the anchor labels.</p>"
    },
    {
      "id": "5f3b36ee6927",
      "title": "AGSP-DSA: An Adaptive Graph Signal Processing Framework for Robust Multimodal Fusion with Dynamic Semantic Alignment",
      "content": "arXiv:2601.18589v1 Announce Type: new  Abstract: In this paper, we introduce an Adaptive Graph Signal Processing with Dynamic Semantic Alignment (AGSP DSA) framework to perform robust multimodal data fusion over heterogeneous sources, including text, audio, and images. The requested approach uses a dual-graph construction to learn both intra-modal and inter-modal relations, spectral graph filtering to boost the informative signals, and effective node embedding with Multi-scale Graph Convolutional Networks (GCNs). Semantic aware attention mechanism: each modality may dynamically contribute to the context with respect to contextual relevance. The experimental outcomes on three benchmark datasets, including CMU-MOSEI, AVE, and MM-IMDB, show that AGSP-DSA performs as the state of the art. More precisely, it achieves 95.3% accuracy, 0.936 F1-score, and 0.924 mAP on CMU-MOSEI, improving MM-GNN by 2.6 percent in accuracy. It gets 93.4% accuracy and 0.911 F1-score on AVE and 91.8% accuracy and 0.886 F1-score on MM-IMDB, which demonstrate good generalization and robustness in the missing modality setting. These findings verify the efficiency of AGSP-DSA in promoting multimodal learning in sentiment analysis, event recognition and multimedia classification.",
      "url": "http://arxiv.org/abs/2601.18589",
      "author": "KV Karthikeya, Ashok Kumar Das, Shantanu Pal, Vivekananda Bhat K, Arun Sekar Rajasekaran",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "AGSP-DSA introduces adaptive graph signal processing framework for multimodal fusion with dual-graph construction, spectral filtering, and semantic-aware attention for text, audio, and images.",
      "importance_score": 48,
      "reasoning": "Standard multimodal fusion framework with graph perspective. Benchmark results on standard datasets.",
      "themes": [
        "Multimodal Learning",
        "Graph Neural Networks",
        "Feature Fusion"
      ],
      "continuation": null,
      "summary_html": "<p>AGSP-DSA introduces adaptive graph signal processing framework for multimodal fusion with dual-graph construction, spectral filtering, and semantic-aware attention for text, audio, and images.</p>",
      "content_html": "<p>arXiv:2601.18589v1 Announce Type: new  Abstract: In this paper, we introduce an Adaptive Graph Signal Processing with Dynamic Semantic Alignment (AGSP DSA) framework to perform robust multimodal data fusion over heterogeneous sources, including text, audio, and images. The requested approach uses a dual-graph construction to learn both intra-modal and inter-modal relations, spectral graph filtering to boost the informative signals, and effective node embedding with Multi-scale Graph Convolutional Networks (GCNs). Semantic aware attention mechanism: each modality may dynamically contribute to the context with respect to contextual relevance. The experimental outcomes on three benchmark datasets, including CMU-MOSEI, AVE, and MM-IMDB, show that AGSP-DSA performs as the state of the art. More precisely, it achieves 95.3% accuracy, 0.936 F1-score, and 0.924 mAP on CMU-MOSEI, improving MM-GNN by 2.6 percent in accuracy. It gets 93.4% accuracy and 0.911 F1-score on AVE and 91.8% accuracy and 0.886 F1-score on MM-IMDB, which demonstrate good generalization and robustness in the missing modality setting. These findings verify the efficiency of AGSP-DSA in promoting multimodal learning in sentiment analysis, event recognition and multimedia classification.</p>"
    },
    {
      "id": "7735969bc9ee",
      "title": "EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery",
      "content": "arXiv:2601.18597v1 Announce Type: new  Abstract: Real-time small object detection in Unmanned Aerial Vehicle (UAV) imagery remains challenging due to limited feature representation and ineffective multi-scale fusion. Existing methods underutilize frequency information and rely on static convolutional operations, which constrain the capacity to obtain rich feature representations and hinder the effective exploitation of deep semantic features. To address these issues, we propose EFSI-DETR, a novel detection framework that integrates efficient semantic feature enhancement with dynamic frequency-spatial guidance. EFSI-DETR comprises two main components: (1) a Dynamic Frequency-Spatial Unified Synergy Network (DyFusNet) that jointly exploits frequency and spatial cues for robust multi-scale feature fusion, (2) an Efficient Semantic Feature Concentrator (ESFC) that enables deep semantic extraction with minimal computational cost. Furthermore, a Fine-grained Feature Retention (FFR) strategy is adopted to incorporate spatially rich shallow features during fusion to preserve fine-grained details, crucial for small object detection in UAV imagery. Extensive experiments on VisDrone and CODrone benchmarks demonstrate that our EFSI-DETR achieves the state-of-the-art performance with real-time efficiency, yielding improvement of \\textbf{1.6}\\% and \\textbf{5.8}\\% in AP and AP$_{s}$ on VisDrone, while obtaining \\textbf{188} FPS inference speed on a single RTX 4090 GPU.",
      "url": "http://arxiv.org/abs/2601.18597",
      "author": "Yu Xia, Chang Liu, Tianqi Xiang, Zhigang Tu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "EFSI-DETR addresses small object detection in UAV imagery through frequency-semantic integration with Dynamic Frequency-Spatial Unified Synergy Network for multi-scale feature enhancement.",
      "importance_score": 48,
      "reasoning": "Addresses practical UAV detection challenge. Domain-specific improvement.",
      "themes": [
        "Object Detection",
        "UAV",
        "Small Object Detection"
      ],
      "continuation": null,
      "summary_html": "<p>EFSI-DETR addresses small object detection in UAV imagery through frequency-semantic integration with Dynamic Frequency-Spatial Unified Synergy Network for multi-scale feature enhancement.</p>",
      "content_html": "<p>arXiv:2601.18597v1 Announce Type: new  Abstract: Real-time small object detection in Unmanned Aerial Vehicle (UAV) imagery remains challenging due to limited feature representation and ineffective multi-scale fusion. Existing methods underutilize frequency information and rely on static convolutional operations, which constrain the capacity to obtain rich feature representations and hinder the effective exploitation of deep semantic features. To address these issues, we propose EFSI-DETR, a novel detection framework that integrates efficient semantic feature enhancement with dynamic frequency-spatial guidance. EFSI-DETR comprises two main components: (1) a Dynamic Frequency-Spatial Unified Synergy Network (DyFusNet) that jointly exploits frequency and spatial cues for robust multi-scale feature fusion, (2) an Efficient Semantic Feature Concentrator (ESFC) that enables deep semantic extraction with minimal computational cost. Furthermore, a Fine-grained Feature Retention (FFR) strategy is adopted to incorporate spatially rich shallow features during fusion to preserve fine-grained details, crucial for small object detection in UAV imagery. Extensive experiments on VisDrone and CODrone benchmarks demonstrate that our EFSI-DETR achieves the state-of-the-art performance with real-time efficiency, yielding improvement of \\textbf{1.6}\\% and \\textbf{5.8}\\% in AP and AP$_{s}$ on VisDrone, while obtaining \\textbf{188} FPS inference speed on a single RTX 4090 GPU.</p>"
    },
    {
      "id": "741c2e5cc4fe",
      "title": "Systematic Characterization of Minimal Deep Learning Architectures: A Unified Analysis of Convergence, Pruning, and Quantization",
      "content": "arXiv:2601.17987v1 Announce Type: cross  Abstract: Deep learning networks excel at classification, yet identifying minimal architectures that reliably solve a task remains challenging. We present a computational methodology for systematically exploring and analyzing the relationships among convergence, pruning, and quantization. The workflow first performs a structured design sweep across a large set of architectures, then evaluates convergence behavior, pruning sensitivity, and quantization robustness on representative models. Focusing on well-known image classification of increasing complexity, and across Deep Neural Networks, Convolutional Neural Networks, and Vision Transformers, our initial results show that, despite architectural diversity, performance is largely invariant and learning dynamics consistently exhibit three regimes: unstable, learning, and overfitting. We further characterize the minimal learnable parameters required for stable learning, uncover distinct convergence and pruning phases, and quantify the effect of reduced numeric precision on trainable parameters. Aligning with intuition, the results confirm that deeper architectures are more resilient to pruning than shallower ones, with parameter redundancy as high as 60%, and quantization impacts models with fewer learnable parameters more severely and has a larger effect on harder image datasets. These findings provide actionable guidance for selecting compact, stable models under pruning and low-precision constraints in image classification.",
      "url": "http://arxiv.org/abs/2601.17987",
      "author": "Ziwei Zheng, Huizhi Liang, Vaclav Snasel, Vito Latora, Panos Pardalos, Giuseppe Nicosia, Varun Ojha",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Presents methodology for systematically exploring relationships among convergence, pruning, and quantization across DNNs, CNNs, and Vision Transformers on image classification.",
      "importance_score": 48,
      "reasoning": "Useful empirical study on model compression but results (performance largely invariant) are unsurprising given existing literature.",
      "themes": [
        "Model Compression",
        "Neural Architecture",
        "Empirical Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Presents methodology for systematically exploring relationships among convergence, pruning, and quantization across DNNs, CNNs, and Vision Transformers on image classification.</p>",
      "content_html": "<p>arXiv:2601.17987v1 Announce Type: cross  Abstract: Deep learning networks excel at classification, yet identifying minimal architectures that reliably solve a task remains challenging. We present a computational methodology for systematically exploring and analyzing the relationships among convergence, pruning, and quantization. The workflow first performs a structured design sweep across a large set of architectures, then evaluates convergence behavior, pruning sensitivity, and quantization robustness on representative models. Focusing on well-known image classification of increasing complexity, and across Deep Neural Networks, Convolutional Neural Networks, and Vision Transformers, our initial results show that, despite architectural diversity, performance is largely invariant and learning dynamics consistently exhibit three regimes: unstable, learning, and overfitting. We further characterize the minimal learnable parameters required for stable learning, uncover distinct convergence and pruning phases, and quantify the effect of reduced numeric precision on trainable parameters. Aligning with intuition, the results confirm that deeper architectures are more resilient to pruning than shallower ones, with parameter redundancy as high as 60%, and quantization impacts models with fewer learnable parameters more severely and has a larger effect on harder image datasets. These findings provide actionable guidance for selecting compact, stable models under pruning and low-precision constraints in image classification.</p>"
    },
    {
      "id": "07926f360669",
      "title": "Goal-oriented Communication for Fast and Robust Robotic Fault Detection and Recovery",
      "content": "arXiv:2601.18765v1 Announce Type: new  Abstract: Autonomous robotic systems are widely deployed in smart factories and operate in dynamic, uncertain, and human-involved environments that require low-latency and robust fault detection and recovery (FDR). However, existing FDR frameworks exhibit various limitations, such as significant delays in communication and computation, and unreliability in robot motion/trajectory generation, mainly because the communication-computation-control (3C) loop is designed without considering the downstream FDR goal. To address this, we propose a novel Goal-oriented Communication (GoC) framework that jointly designs the 3C loop tailored for fast and robust robotic FDR, with the goal of minimising the FDR time while maximising the robotic task (e.g., workpiece sorting) success rate. For fault detection, our GoC framework innovatively defines and extracts the 3D scene graph (3D-SG) as the semantic representation via our designed representation extractor, and detects faults by monitoring spatial relationship changes in the 3D-SG. For fault recovery, we fine-tune a small language model (SLM) via Low-Rank Adaptation (LoRA) and enhance its reasoning and generalization capabilities via knowledge distillation to generate recovery motions for robots. We also design a lightweight goal-oriented digital twin reconstruction module to refine the recovery motions generated by the SLM when fine-grained robotic control is required, using only task-relevant object contours for digital twin reconstruction. Extensive simulations demonstrate that our GoC framework reduces the FDR time by up to 82.6% and improves the task success rate by up to 76%, compared to the state-of-the-art frameworks that rely on vision language models for fault detection and large language models for fault recovery.",
      "url": "http://arxiv.org/abs/2601.18765",
      "author": "Shutong Chen, Adnan Aijaz, Yansha Deng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes goal-oriented communication framework for fast and robust robotic fault detection and recovery, jointly designing communication-computation-control loop.",
      "importance_score": 48,
      "reasoning": "Interesting cross-layer design for robotics reliability but limited experimental validation.",
      "themes": [
        "Goal-Oriented Communication",
        "Fault Detection",
        "Robotics"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes goal-oriented communication framework for fast and robust robotic fault detection and recovery, jointly designing communication-computation-control loop.</p>",
      "content_html": "<p>arXiv:2601.18765v1 Announce Type: new  Abstract: Autonomous robotic systems are widely deployed in smart factories and operate in dynamic, uncertain, and human-involved environments that require low-latency and robust fault detection and recovery (FDR). However, existing FDR frameworks exhibit various limitations, such as significant delays in communication and computation, and unreliability in robot motion/trajectory generation, mainly because the communication-computation-control (3C) loop is designed without considering the downstream FDR goal. To address this, we propose a novel Goal-oriented Communication (GoC) framework that jointly designs the 3C loop tailored for fast and robust robotic FDR, with the goal of minimising the FDR time while maximising the robotic task (e.g., workpiece sorting) success rate. For fault detection, our GoC framework innovatively defines and extracts the 3D scene graph (3D-SG) as the semantic representation via our designed representation extractor, and detects faults by monitoring spatial relationship changes in the 3D-SG. For fault recovery, we fine-tune a small language model (SLM) via Low-Rank Adaptation (LoRA) and enhance its reasoning and generalization capabilities via knowledge distillation to generate recovery motions for robots. We also design a lightweight goal-oriented digital twin reconstruction module to refine the recovery motions generated by the SLM when fine-grained robotic control is required, using only task-relevant object contours for digital twin reconstruction. Extensive simulations demonstrate that our GoC framework reduces the FDR time by up to 82.6% and improves the task success rate by up to 76%, compared to the state-of-the-art frameworks that rely on vision language models for fault detection and large language models for fault recovery.</p>"
    },
    {
      "id": "7fecc841715d",
      "title": "Boosting methods for interval-censored data with regression and classification",
      "content": "arXiv:2601.17973v1 Announce Type: new  Abstract: Boosting has garnered significant interest across both machine learning and statistical communities. Traditional boosting algorithms, designed for fully observed random samples, often struggle with real-world problems, particularly with interval-censored data. This type of data is common in survival analysis and time-to-event studies where exact event times are unobserved but fall within known intervals. Effective handling of such data is crucial in fields like medical research, reliability engineering, and social sciences. In this work, we introduce novel nonparametric boosting methods for regression and classification tasks with interval-censored data. Our approaches leverage censoring unbiased transformations to adjust loss functions and impute transformed responses while maintaining model accuracy. Implemented via functional gradient descent, these methods ensure scalability and adaptability. We rigorously establish their theoretical properties, including optimality and mean squared error trade-offs. Our proposed methods not only offer a robust framework for enhancing predictive accuracy in domains where interval-censored data are common but also complement existing work, expanding the applicability of existing boosting techniques. Empirical studies demonstrate robust performance across various finite-sample scenarios, highlighting the practical utility of our approaches.",
      "url": "http://arxiv.org/abs/2601.17973",
      "author": "Yuan Bian, Grace Y. Yi, Wenqing He",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "stat.ML"
      ],
      "summary": "Introduces nonparametric boosting methods for regression and classification with interval-censored data using censoring unbiased transformations.",
      "importance_score": 48,
      "reasoning": "Useful methodology for survival analysis but specialized statistical contribution.",
      "themes": [
        "Boosting",
        "Survival Analysis",
        "Statistical Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces nonparametric boosting methods for regression and classification with interval-censored data using censoring unbiased transformations.</p>",
      "content_html": "<p>arXiv:2601.17973v1 Announce Type: new  Abstract: Boosting has garnered significant interest across both machine learning and statistical communities. Traditional boosting algorithms, designed for fully observed random samples, often struggle with real-world problems, particularly with interval-censored data. This type of data is common in survival analysis and time-to-event studies where exact event times are unobserved but fall within known intervals. Effective handling of such data is crucial in fields like medical research, reliability engineering, and social sciences. In this work, we introduce novel nonparametric boosting methods for regression and classification tasks with interval-censored data. Our approaches leverage censoring unbiased transformations to adjust loss functions and impute transformed responses while maintaining model accuracy. Implemented via functional gradient descent, these methods ensure scalability and adaptability. We rigorously establish their theoretical properties, including optimality and mean squared error trade-offs. Our proposed methods not only offer a robust framework for enhancing predictive accuracy in domains where interval-censored data are common but also complement existing work, expanding the applicability of existing boosting techniques. Empirical studies demonstrate robust performance across various finite-sample scenarios, highlighting the practical utility of our approaches.</p>"
    },
    {
      "id": "7ff628e7883e",
      "title": "Contrasting Global and Patient-Specific Regression Models via a Neural Network Representation",
      "content": "arXiv:2601.18658v1 Announce Type: cross  Abstract: When developing clinical prediction models, it can be challenging to balance between global models that are valid for all patients and personalized models tailored to individuals or potentially unknown subgroups. To aid such decisions, we propose a diagnostic tool for contrasting global regression models and patient-specific (local) regression models. The core utility of this tool is to identify where and for whom a global model may be inadequate. We focus on regression models and specifically suggest a localized regression approach that identifies regions in the predictor space where patients are not well represented by the global model. As localization becomes challenging when dealing with many predictors, we propose modeling in a dimension-reduced latent representation obtained from an autoencoder. Using such a neural network architecture for dimension reduction enables learning a latent representation simultaneously optimized for both good data reconstruction and for revealing local outcome-related associations suitable for robust localized regression. We illustrate the proposed approach with a clinical study involving patients with chronic obstructive pulmonary disease. Our findings indicate that the global model is adequate for most patients but that indeed specific subgroups benefit from personalized models. We also demonstrate how to map these subgroup models back to the original predictors, providing insight into why the global model falls short for these groups. Thus, the principal application and diagnostic yield of our tool is the identification and characterization of patients or subgroups whose outcome associations deviate from the global model.",
      "url": "http://arxiv.org/abs/2601.18658",
      "author": "Max Behrens, Daiana Stolz, Eleni Papakonstantinou, Janis M. Nolde, Gabriele Bellerino, Angelika Rohde, Moritz Hess, Harald Binder",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "stat.ME"
      ],
      "summary": "Proposes diagnostic tool for contrasting global and patient-specific regression models using localized regression to identify where global models are inadequate.",
      "importance_score": 48,
      "reasoning": "Useful clinical ML methodology for personalized vs global model decisions.",
      "themes": [
        "Clinical ML",
        "Personalization",
        "Model Diagnostics"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes diagnostic tool for contrasting global and patient-specific regression models using localized regression to identify where global models are inadequate.</p>",
      "content_html": "<p>arXiv:2601.18658v1 Announce Type: cross  Abstract: When developing clinical prediction models, it can be challenging to balance between global models that are valid for all patients and personalized models tailored to individuals or potentially unknown subgroups. To aid such decisions, we propose a diagnostic tool for contrasting global regression models and patient-specific (local) regression models. The core utility of this tool is to identify where and for whom a global model may be inadequate. We focus on regression models and specifically suggest a localized regression approach that identifies regions in the predictor space where patients are not well represented by the global model. As localization becomes challenging when dealing with many predictors, we propose modeling in a dimension-reduced latent representation obtained from an autoencoder. Using such a neural network architecture for dimension reduction enables learning a latent representation simultaneously optimized for both good data reconstruction and for revealing local outcome-related associations suitable for robust localized regression. We illustrate the proposed approach with a clinical study involving patients with chronic obstructive pulmonary disease. Our findings indicate that the global model is adequate for most patients but that indeed specific subgroups benefit from personalized models. We also demonstrate how to map these subgroup models back to the original predictors, providing insight into why the global model falls short for these groups. Thus, the principal application and diagnostic yield of our tool is the identification and characterization of patients or subgroups whose outcome associations deviate from the global model.</p>"
    },
    {
      "id": "359b13e61f4c",
      "title": "Can you just vibe vulnerabilities?",
      "content": "Ive recently been wondering how close AI is to being able to reliably and autonomously find vulnerabilities in real-world software. I do not trust the academic research in this area, for a number of reasons (too focused on CTFs, too much pressure to achieve an affirmative result, too hand-wavy about leakage from the training data) and wanted to see for myself how the models perform on a real-world task. Here are two signals which sparked my curiosity:DARPAs AI CyberChallenge (AIxCC), in which 42 teams competed to build fully autonomous vulnerability research and patch synthesis tools using LLMs. I know some folks from some of the involved teams personally and think highly of them, plus, the benchmark results reported from DARPA look impressive.A former colleague of mine from the formal methods community sent me an interesting blog post on the topic, from someone impressive/reputable.On the other hand, here are two signals which sparked my pessimism:I spent yesterday at DistrictCon, surrounded by hackers, and I swear, I did not see one person using Claude Code, Codex, Cursor, etc. I heard lots of people complaining about AI.Apparently curl is withdrawing from HackerOne because theyre wasting so much time triaging AI slop. (I checked and immediately found some.)So, can you just do things? To find out, I decided to try and vibe a vulnerability.Some context on meI have a PhD in computer science and have published in security venues including Oakland and USENIX. I made a small contribution to the SCTP RFC, presented to the IETF ANRW, and found a minor CVE in GossipSub, a subcomponent of Ethereum. So, I am not completely new to cybersecurity. However, I am not a hacker. Ive never gotten a bug bounty in anything[1], presented at ShmooCon or BSides, or otherwise done anything very cool from a real hacker perspective.Choosing a targetI began by lsing /usr/bin. I wanted to find something with a lot of parsing logic in it, because Im seriously LangSec-pilled and believe...",
      "url": "https://www.lesswrong.com/posts/HrnaF9Qe5kokpLWFs/can-you-just-vibe-vulnerabilities",
      "author": "Max von Hippel",
      "published": "2026-01-25T22:07:46.040000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Explores whether AI can autonomously find real-world software vulnerabilities, noting both promising signals (DARPA AIxCC results) and skeptical signals (hackers not using AI tools, curl leaving HackerOne). Expresses cautious skepticism.",
      "importance_score": 48,
      "reasoning": "Relevant AI capabilities assessment from someone with security domain expertise. Provides useful grounding on current state of AI vulnerability research but more exploratory than conclusive.",
      "themes": [
        "AI Capabilities",
        "Cybersecurity",
        "Autonomous AI",
        "Vulnerability Research"
      ],
      "continuation": null,
      "summary_html": "<p>Explores whether AI can autonomously find real-world software vulnerabilities, noting both promising signals (DARPA AIxCC results) and skeptical signals (hackers not using AI tools, curl leaving HackerOne). Expresses cautious skepticism.</p>",
      "content_html": "<p>Ive recently been wondering how close AI is to being able to reliably and autonomously find vulnerabilities in real-world software. I do not trust the academic research in this area, for a number of reasons (too focused on CTFs, too much pressure to achieve an affirmative result, too hand-wavy about leakage from the training data) and wanted to see for myself how the models perform on a real-world task. Here are two signals which sparked my curiosity:DARPAs AI CyberChallenge (AIxCC), in which 42 teams competed to build fully autonomous vulnerability research and patch synthesis tools using LLMs. I know some folks from some of the involved teams personally and think highly of them, plus, the benchmark results reported from DARPA look impressive.A former colleague of mine from the formal methods community sent me an interesting blog post on the topic, from someone impressive/reputable.On the other hand, here are two signals which sparked my pessimism:I spent yesterday at DistrictCon, surrounded by hackers, and I swear, I did not see one person using Claude Code, Codex, Cursor, etc. I heard lots of people complaining about AI.Apparently curl is withdrawing from HackerOne because theyre wasting so much time triaging AI slop. (I checked and immediately found some.)So, can you just do things? To find out, I decided to try and vibe a vulnerability.Some context on meI have a PhD in computer science and have published in security venues including Oakland and USENIX. I made a small contribution to the SCTP RFC, presented to the IETF ANRW, and found a minor CVE in GossipSub, a subcomponent of Ethereum. So, I am not completely new to cybersecurity. However, I am not a hacker. Ive never gotten a bug bounty in anything[1], presented at ShmooCon or BSides, or otherwise done anything very cool from a real hacker perspective.Choosing a targetI began by lsing /usr/bin. I wanted to find something with a lot of parsing logic in it, because Im seriously LangSec-pilled and believe...</p>"
    },
    {
      "id": "6c0f544412df",
      "title": "RegGuard: AI-Powered Retrieval-Enhanced Assistant for Pharmaceutical Regulatory Compliance",
      "content": "arXiv:2601.17826v1 Announce Type: new  Abstract: The increasing frequency and complexity of regulatory updates present a significant burden for multinational pharmaceutical companies. Compliance teams must interpret evolving rules across jurisdictions, formats, and agencies, often manually, at high cost and risk of error. We introduce RegGuard, an industrial-scale AI assistant designed to automate the interpretation of heterogeneous regulatory texts and align them with internal corporate policies. The system ingests heterogeneous document sources through a secure pipeline and enhances retrieval and generation quality with two novel components: HiSACC (Hierarchical Semantic Aggregation for Contextual Chunking) semantically segments long documents into coherent units while maintaining consistency across non-contiguous sections. ReLACE (Regulatory Listwise Adaptive Cross-Encoder for Reranking), a domain-adapted cross-encoder built on an open-source model, jointly models user queries and retrieved candidates to improve ranking relevance. Evaluations in enterprise settings demonstrate that RegGuard improves answer quality specifically in terms of relevance, groundedness, and contextual focus, while significantly mitigating hallucination risk. The system architecture is built for auditability and traceability, featuring provenance tracking, access control, and incremental indexing, making it highly responsive to evolving document sources and relevant for any domain with stringent compliance demands.",
      "url": "http://arxiv.org/abs/2601.17826",
      "author": "Siyuan Yang, Xihan Bian, Jiayin Tang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Introduces RegGuard, an industrial AI assistant for pharmaceutical regulatory compliance using hierarchical semantic chunking and dense passage retrieval for heterogeneous regulatory documents.",
      "importance_score": 47,
      "reasoning": "Domain-specific RAG application; practical but limited generalizability beyond pharmaceutical compliance.",
      "themes": [
        "RAG",
        "Regulatory Compliance",
        "Enterprise AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces RegGuard, an industrial AI assistant for pharmaceutical regulatory compliance using hierarchical semantic chunking and dense passage retrieval for heterogeneous regulatory documents.</p>",
      "content_html": "<p>arXiv:2601.17826v1 Announce Type: new  Abstract: The increasing frequency and complexity of regulatory updates present a significant burden for multinational pharmaceutical companies. Compliance teams must interpret evolving rules across jurisdictions, formats, and agencies, often manually, at high cost and risk of error. We introduce RegGuard, an industrial-scale AI assistant designed to automate the interpretation of heterogeneous regulatory texts and align them with internal corporate policies. The system ingests heterogeneous document sources through a secure pipeline and enhances retrieval and generation quality with two novel components: HiSACC (Hierarchical Semantic Aggregation for Contextual Chunking) semantically segments long documents into coherent units while maintaining consistency across non-contiguous sections. ReLACE (Regulatory Listwise Adaptive Cross-Encoder for Reranking), a domain-adapted cross-encoder built on an open-source model, jointly models user queries and retrieved candidates to improve ranking relevance. Evaluations in enterprise settings demonstrate that RegGuard improves answer quality specifically in terms of relevance, groundedness, and contextual focus, while significantly mitigating hallucination risk. The system architecture is built for auditability and traceability, featuring provenance tracking, access control, and incremental indexing, making it highly responsive to evolving document sources and relevant for any domain with stringent compliance demands.</p>"
    },
    {
      "id": "b75b54f8a580",
      "title": "Embodiment-Induced Coordination Regimes in Tabular Multi-Agent Q-Learning",
      "content": "arXiv:2601.17454v1 Announce Type: cross  Abstract: Centralized value learning is often assumed to improve coordination and stability in multi-agent reinforcement learning, yet this assumption is rarely tested under controlled conditions. We directly evaluate it in a fully tabular predator-prey gridworld by comparing independent and centralized Q-learning under explicit embodiment constraints on agent speed and stamina. Across multiple kinematic regimes and asymmetric agent roles, centralized learning fails to provide a consistent advantage and is frequently outperformed by fully independent learning, even under full observability and exact value estimation. Moreover, asymmetric centralized-independent configurations induce persistent coordination breakdowns rather than transient learning instability. By eliminating confounding effects from function approximation and representation learning, our tabular analysis isolates coordination structure as the primary driver of these effects. The results show that increased coordination can become a liability under embodiment constraints, and that the effectiveness of centralized learning is fundamentally regime and role dependent rather than universal.",
      "url": "http://arxiv.org/abs/2601.17454",
      "author": "Muhammad Ahmed Atif, Nehal Naeem Haji, Mohammad Shahid Shaikh, Muhammad Ebad Atif",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.MA"
      ],
      "summary": "Shows centralized Q-learning fails to consistently outperform independent learning in multi-agent RL under controlled embodiment constraints, challenging common assumptions.",
      "importance_score": 47,
      "reasoning": "Counter-intuitive finding about centralized vs independent learning. Rigorous controlled evaluation.",
      "themes": [
        "Multi-agent RL",
        "Coordination",
        "Reinforcement Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Shows centralized Q-learning fails to consistently outperform independent learning in multi-agent RL under controlled embodiment constraints, challenging common assumptions.</p>",
      "content_html": "<p>arXiv:2601.17454v1 Announce Type: cross  Abstract: Centralized value learning is often assumed to improve coordination and stability in multi-agent reinforcement learning, yet this assumption is rarely tested under controlled conditions. We directly evaluate it in a fully tabular predator-prey gridworld by comparing independent and centralized Q-learning under explicit embodiment constraints on agent speed and stamina. Across multiple kinematic regimes and asymmetric agent roles, centralized learning fails to provide a consistent advantage and is frequently outperformed by fully independent learning, even under full observability and exact value estimation. Moreover, asymmetric centralized-independent configurations induce persistent coordination breakdowns rather than transient learning instability. By eliminating confounding effects from function approximation and representation learning, our tabular analysis isolates coordination structure as the primary driver of these effects. The results show that increased coordination can become a liability under embodiment constraints, and that the effectiveness of centralized learning is fundamentally regime and role dependent rather than universal.</p>"
    },
    {
      "id": "719af06cf998",
      "title": "SKETCH: Semantic Key-Point Conditioning for Long-Horizon Vessel Trajectory Prediction",
      "content": "arXiv:2601.18537v1 Announce Type: cross  Abstract: Accurate long-horizon vessel trajectory prediction remains challenging due to compounded uncertainty from complex navigation behaviors and environmental factors. Existing methods often struggle to maintain global directional consistency, leading to drifting or implausible trajectories when extrapolated over long time horizons. To address this issue, we propose a semantic-key-point-conditioned trajectory modeling framework, in which future trajectories are predicted by conditioning on a high-level Next Key Point (NKP) that captures navigational intent. This formulation decomposes long-horizon prediction into global semantic decision-making and local motion modeling, effectively restricting the support of future trajectories to semantically feasible subsets. To efficiently estimate the NKP prior from historical observations, we adopt a pretrain-finetune strategy. Extensive experiments on real-world AIS data demonstrate that the proposed method consistently outperforms state-of-the-art approaches, particularly for long travel durations, directional accuracy, and fine-grained trajectory prediction.",
      "url": "http://arxiv.org/abs/2601.18537",
      "author": "Linyong Gan, Zimo Li, Wenxin Xu, Xingjian Li, Jianhua Z. Huang, Enmei Tu, Shuhang Chen",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes SKETCH framework for long-horizon vessel trajectory prediction using semantic key-point conditioning, decomposing prediction into global semantic decision-making and local motion modeling.",
      "importance_score": 47,
      "reasoning": "Novel semantic key-point approach for trajectory prediction. Specialized maritime application limits broader impact.",
      "themes": [
        "Trajectory Prediction",
        "Maritime AI",
        "Semantic Modeling"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes SKETCH framework for long-horizon vessel trajectory prediction using semantic key-point conditioning, decomposing prediction into global semantic decision-making and local motion modeling.</p>",
      "content_html": "<p>arXiv:2601.18537v1 Announce Type: cross  Abstract: Accurate long-horizon vessel trajectory prediction remains challenging due to compounded uncertainty from complex navigation behaviors and environmental factors. Existing methods often struggle to maintain global directional consistency, leading to drifting or implausible trajectories when extrapolated over long time horizons. To address this issue, we propose a semantic-key-point-conditioned trajectory modeling framework, in which future trajectories are predicted by conditioning on a high-level Next Key Point (NKP) that captures navigational intent. This formulation decomposes long-horizon prediction into global semantic decision-making and local motion modeling, effectively restricting the support of future trajectories to semantically feasible subsets. To efficiently estimate the NKP prior from historical observations, we adopt a pretrain-finetune strategy. Extensive experiments on real-world AIS data demonstrate that the proposed method consistently outperforms state-of-the-art approaches, particularly for long travel durations, directional accuracy, and fine-grained trajectory prediction.</p>"
    },
    {
      "id": "b4afbeb16a14",
      "title": "Pisets: A Robust Speech Recognition System for Lectures and Interviews",
      "content": "arXiv:2601.18415v1 Announce Type: new  Abstract: This work presents a speech-to-text system \"Pisets\" for scientists and journalists which is based on a three-component architecture aimed at improving speech recognition accuracy while minimizing errors and hallucinations associated with the Whisper model. The architecture comprises primary recognition using Wav2Vec2, false positive filtering via the Audio Spectrogram Transformer (AST), and final speech recognition through Whisper. The implementation of curriculum learning methods and the utilization of diverse Russian-language speech corpora significantly enhanced the system's effectiveness. Additionally, advanced uncertainty modeling techniques were introduced, contributing to further improvements in transcription quality. The proposed approaches ensure robust transcribing of long audio data across various acoustic conditions compared to WhisperX and the usual Whisper model. The source code of \"Pisets\" system is publicly available at GitHub: https://github.com/bond005/pisets.",
      "url": "http://arxiv.org/abs/2601.18415",
      "author": "Ivan Bondarenko, Daniil Grebenkin, Oleg Sedukhin, Mikhail Klementev, Roman Derunets, Lyudmila Budneva",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents Pisets, a three-component Russian ASR system combining Wav2Vec2, Audio Spectrogram Transformer, and Whisper to reduce errors and hallucinations in lecture and interview transcription.",
      "importance_score": 47,
      "reasoning": "Applied ASR system for specific language and domain. Practical combination of existing components.",
      "themes": [
        "Speech Recognition",
        "Russian NLP",
        "Applied Systems"
      ],
      "continuation": null,
      "summary_html": "<p>Presents Pisets, a three-component Russian ASR system combining Wav2Vec2, Audio Spectrogram Transformer, and Whisper to reduce errors and hallucinations in lecture and interview transcription.</p>",
      "content_html": "<p>arXiv:2601.18415v1 Announce Type: new  Abstract: This work presents a speech-to-text system \"Pisets\" for scientists and journalists which is based on a three-component architecture aimed at improving speech recognition accuracy while minimizing errors and hallucinations associated with the Whisper model. The architecture comprises primary recognition using Wav2Vec2, false positive filtering via the Audio Spectrogram Transformer (AST), and final speech recognition through Whisper. The implementation of curriculum learning methods and the utilization of diverse Russian-language speech corpora significantly enhanced the system's effectiveness. Additionally, advanced uncertainty modeling techniques were introduced, contributing to further improvements in transcription quality. The proposed approaches ensure robust transcribing of long audio data across various acoustic conditions compared to WhisperX and the usual Whisper model. The source code of \"Pisets\" system is publicly available at GitHub: https://github.com/bond005/pisets.</p>"
    },
    {
      "id": "9ec9eaae769d",
      "title": "Differentiable Architecture Search for Adversarially Robust Quantum Computer Vision",
      "content": "arXiv:2601.18058v1 Announce Type: cross  Abstract: Current quantum neural networks suffer from extreme sensitivity to both adversarial perturbations and hardware noise, creating a significant barrier to real-world deployment. Existing robustness techniques typically sacrifice clean accuracy or require prohibitive computational resources. We propose a hybrid quantum-classical Differentiable Quantum Architecture Search (DQAS) framework that addresses these limitations by jointly optimizing circuit structure and robustness through gradient-based methods. Our approach enhances traditional DQAS with a lightweight Classical Noise Layer applied before quantum processing, enabling simultaneous optimization of gate selection and noise parameters. This design preserves the quantum circuit's integrity while introducing trainable perturbations that enhance robustness without compromising standard performance. Experimental validation on MNIST, FashionMNIST, and CIFAR datasets shows consistent improvements in both clean and adversarial accuracy compared to existing quantum architecture search methods. Under various attack scenarios, including Fast Gradient Sign Method (FGSM), Projected Gradient Descent (PGD), Basic Iterative Method (BIM), and Momentum Iterative Method (MIM), and under realistic quantum noise conditions, our hybrid framework maintains superior performance. Testing on actual quantum hardware confirms the practical viability of discovered architectures. These results demonstrate that strategic classical preprocessing combined with differentiable quantum architecture optimization can significantly enhance quantum neural network robustness while maintaining computational efficiency.",
      "url": "http://arxiv.org/abs/2601.18058",
      "author": "Mohamed Afane, Quanjiang Long, Haoting Shen, Ying Mao, Junaid Farooq, Ying Wang, Juntao Chen",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "quant-ph"
      ],
      "summary": "Proposes hybrid quantum-classical differentiable architecture search framework for adversarially robust quantum neural networks, using a Classical Noise Layer for joint optimization.",
      "importance_score": 47,
      "reasoning": "Novel combination of quantum NAS with adversarial robustness, but quantum ML applications remain limited in practice.",
      "themes": [
        "Quantum Machine Learning",
        "Neural Architecture Search",
        "Adversarial Robustness"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes hybrid quantum-classical differentiable architecture search framework for adversarially robust quantum neural networks, using a Classical Noise Layer for joint optimization.</p>",
      "content_html": "<p>arXiv:2601.18058v1 Announce Type: cross  Abstract: Current quantum neural networks suffer from extreme sensitivity to both adversarial perturbations and hardware noise, creating a significant barrier to real-world deployment. Existing robustness techniques typically sacrifice clean accuracy or require prohibitive computational resources. We propose a hybrid quantum-classical Differentiable Quantum Architecture Search (DQAS) framework that addresses these limitations by jointly optimizing circuit structure and robustness through gradient-based methods. Our approach enhances traditional DQAS with a lightweight Classical Noise Layer applied before quantum processing, enabling simultaneous optimization of gate selection and noise parameters. This design preserves the quantum circuit's integrity while introducing trainable perturbations that enhance robustness without compromising standard performance. Experimental validation on MNIST, FashionMNIST, and CIFAR datasets shows consistent improvements in both clean and adversarial accuracy compared to existing quantum architecture search methods. Under various attack scenarios, including Fast Gradient Sign Method (FGSM), Projected Gradient Descent (PGD), Basic Iterative Method (BIM), and Momentum Iterative Method (MIM), and under realistic quantum noise conditions, our hybrid framework maintains superior performance. Testing on actual quantum hardware confirms the practical viability of discovered architectures. These results demonstrate that strategic classical preprocessing combined with differentiable quantum architecture optimization can significantly enhance quantum neural network robustness while maintaining computational efficiency.</p>"
    },
    {
      "id": "2c7a9eb2096c",
      "title": "Hierarchical Informative Path Planning via Graph Guidance and Trajectory Optimization",
      "content": "arXiv:2601.17227v1 Announce Type: new  Abstract: We study informative path planning (IPP) with travel budgets in cluttered environments, where an agent collects measurements of a latent field modeled as a Gaussian process (GP) to reduce uncertainty at target locations. Graph-based solvers provide global guarantees but assume pre-selected measurement locations, while continuous trajectory optimization supports path-based sensing but is computationally intensive and sensitive to initialization in obstacle-dense settings. We propose a hierarchical framework with three stages: (i) graph-based global planning, (ii) segment-wise budget allocation using geometric and kernel bounds, and (iii) spline-based refinement of each segment with hard constraints and obstacle pruning. By combining global guidance with local refinement, our method achieves lower posterior uncertainty than graph-only and continuous baselines, while running faster than continuous-space solvers (up to 9x faster than gradient-based methods and 20x faster than black-box optimizers) across synthetic cluttered environments and Arctic datasets.",
      "url": "http://arxiv.org/abs/2601.17227",
      "author": "Avraiem Iskandar, Shamak Dutta, Kevin Murrant, Yash Vardhan Pant, Stephen L. Smith",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes hierarchical framework for informative path planning combining graph-based global planning, segment-wise budget allocation, and spline-based refinement for Gaussian process-based sensing.",
      "importance_score": 47,
      "reasoning": "Solid robotics planning contribution combining multiple techniques but incremental improvement.",
      "themes": [
        "Path Planning",
        "Gaussian Processes",
        "Robotics"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes hierarchical framework for informative path planning combining graph-based global planning, segment-wise budget allocation, and spline-based refinement for Gaussian process-based sensing.</p>",
      "content_html": "<p>arXiv:2601.17227v1 Announce Type: new  Abstract: We study informative path planning (IPP) with travel budgets in cluttered environments, where an agent collects measurements of a latent field modeled as a Gaussian process (GP) to reduce uncertainty at target locations. Graph-based solvers provide global guarantees but assume pre-selected measurement locations, while continuous trajectory optimization supports path-based sensing but is computationally intensive and sensitive to initialization in obstacle-dense settings. We propose a hierarchical framework with three stages: (i) graph-based global planning, (ii) segment-wise budget allocation using geometric and kernel bounds, and (iii) spline-based refinement of each segment with hard constraints and obstacle pruning. By combining global guidance with local refinement, our method achieves lower posterior uncertainty than graph-only and continuous baselines, while running faster than continuous-space solvers (up to 9x faster than gradient-based methods and 20x faster than black-box optimizers) across synthetic cluttered environments and Arctic datasets.</p>"
    },
    {
      "id": "0743e8548253",
      "title": "Transfer learning for scalar-on-function regression via control variates",
      "content": "arXiv:2601.17217v1 Announce Type: cross  Abstract: Transfer learning (TL) has emerged as a powerful tool for improving estimation and prediction performance by leveraging information from related datasets. In this paper, we repurpose the control-variates (CVS) method for TL in the context of scalar-on-function regression. Our proposed framework relies exclusively on dataset-specific summary statistics, avoiding the need to pool subject-level data and thus remaining applicable in privacy-restricted or decentralized settings. We establish theoretical connections among several existing TL strategies and derive convergence rates for our CVS-based proposals. These rates explicitly account for the typically overlooked smoothing error and reveal how the similarity among covariance functions across datasets influences convergence behavior. Numerical studies support the theoretical findings and demonstrate that the proposed methods achieve competitive estimation and prediction performance compared with existing alternatives.",
      "url": "http://arxiv.org/abs/2601.17217",
      "author": "Yuping Yang, Zhiyang Zhou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "stat.ME"
      ],
      "summary": "Proposes control-variates method for transfer learning in scalar-on-function regression using only summary statistics, applicable in privacy-restricted settings.",
      "importance_score": 47,
      "reasoning": "Useful methodology for functional data analysis with privacy constraints, specialized contribution.",
      "themes": [
        "Transfer Learning",
        "Functional Data Analysis",
        "Privacy"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes control-variates method for transfer learning in scalar-on-function regression using only summary statistics, applicable in privacy-restricted settings.</p>",
      "content_html": "<p>arXiv:2601.17217v1 Announce Type: cross  Abstract: Transfer learning (TL) has emerged as a powerful tool for improving estimation and prediction performance by leveraging information from related datasets. In this paper, we repurpose the control-variates (CVS) method for TL in the context of scalar-on-function regression. Our proposed framework relies exclusively on dataset-specific summary statistics, avoiding the need to pool subject-level data and thus remaining applicable in privacy-restricted or decentralized settings. We establish theoretical connections among several existing TL strategies and derive convergence rates for our CVS-based proposals. These rates explicitly account for the typically overlooked smoothing error and reveal how the similarity among covariance functions across datasets influences convergence behavior. Numerical studies support the theoretical findings and demonstrate that the proposed methods achieve competitive estimation and prediction performance compared with existing alternatives.</p>"
    },
    {
      "id": "59af672d0c49",
      "title": "Prompt and Circumstances: Evaluating the Efficacy of Human Prompt Inference in AI-Generated Art",
      "content": "arXiv:2601.17379v1 Announce Type: cross  Abstract: The emerging field of AI-generated art has witnessed the rise of prompt marketplaces, where creators can purchase, sell, or share prompts to generate unique artworks. These marketplaces often assert ownership over prompts, claiming them as intellectual property. This paper investigates whether concealed prompts sold on prompt marketplaces can be considered bona fide intellectual property, given that humans and AI tools may be able to infer the prompts based on publicly advertised sample images accompanying each prompt on sale. Specifically, our study aims to assess (i) how accurately humans can infer the original prompt solely by examining an AI-generated image, with the goal of generating images similar to the original image, and (ii) the possibility of improving upon individual human and AI prompt inferences by crafting combined human and AI prompts with the help of a large language model. Although previous research has explored AI-driven prompt inference and protection strategies, our work is the first to incorporate a human subject study and examine collaborative human-AI prompt inference in depth. Our findings indicate that while prompts inferred by humans and prompts inferred through a combined human and AI effort can generate images with a moderate level of similarity, they are not as successful as using the original prompt. Moreover, combining human- and AI-inferred prompts using our suggested merging techniques did not improve performance over purely human-inferred prompts.",
      "url": "http://arxiv.org/abs/2601.17379",
      "author": "Khoi Trinh, Scott Seidenberger, Joseph Spracklen, Raveen Wijewickrama, Bimal Viswanath, Murtuza Jadliwala, Anindya Maiti",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Studies whether humans and AI can infer prompts from AI-generated images, questioning intellectual property claims of prompt marketplaces.",
      "importance_score": 46,
      "reasoning": "Interesting IP/ownership question for AI art. Empirical study design.",
      "themes": [
        "AI Art",
        "Intellectual Property",
        "Human-AI Comparison"
      ],
      "continuation": null,
      "summary_html": "<p>Studies whether humans and AI can infer prompts from AI-generated images, questioning intellectual property claims of prompt marketplaces.</p>",
      "content_html": "<p>arXiv:2601.17379v1 Announce Type: cross  Abstract: The emerging field of AI-generated art has witnessed the rise of prompt marketplaces, where creators can purchase, sell, or share prompts to generate unique artworks. These marketplaces often assert ownership over prompts, claiming them as intellectual property. This paper investigates whether concealed prompts sold on prompt marketplaces can be considered bona fide intellectual property, given that humans and AI tools may be able to infer the prompts based on publicly advertised sample images accompanying each prompt on sale. Specifically, our study aims to assess (i) how accurately humans can infer the original prompt solely by examining an AI-generated image, with the goal of generating images similar to the original image, and (ii) the possibility of improving upon individual human and AI prompt inferences by crafting combined human and AI prompts with the help of a large language model. Although previous research has explored AI-driven prompt inference and protection strategies, our work is the first to incorporate a human subject study and examine collaborative human-AI prompt inference in depth. Our findings indicate that while prompts inferred by humans and prompts inferred through a combined human and AI effort can generate images with a moderate level of similarity, they are not as successful as using the original prompt. Moreover, combining human- and AI-inferred prompts using our suggested merging techniques did not improve performance over purely human-inferred prompts.</p>"
    },
    {
      "id": "72f7dd83cc78",
      "title": "From Classification to Ranking: Enhancing LLM Reasoning Capabilities for MBTI Personality Detection",
      "content": "arXiv:2601.18582v1 Announce Type: new  Abstract: Personality detection aims to measure an individual's corresponding personality traits through their social media posts. The advancements in Large Language Models (LLMs) offer novel perspectives for personality detection tasks. Existing approaches enhance personality trait analysis by leveraging LLMs to extract semantic information from textual posts as prompts, followed by training classifiers for categorization. However, accurately classifying personality traits remains challenging due to the inherent complexity of human personality and subtle inter-trait distinctions. Moreover, prompt-based methods often exhibit excessive dependency on expert-crafted knowledge without autonomous pattern-learning capacity. To address these limitations, we view personality detection as a ranking task rather than a classification and propose a corresponding reinforcement learning training paradigm. First, we employ supervised fine-tuning (SFT) to establish personality trait ranking capabilities while enforcing standardized output formats, creating a robust initialization. Subsequently, we introduce Group Relative Policy Optimization (GRPO) with a specialized ranking-based reward function. Unlike verification tasks with definitive solutions, personality assessment involves subjective interpretations and blurred boundaries between trait categories. Our reward function explicitly addresses this challenge by training LLMs to learn optimal answer rankings. Comprehensive experiments have demonstrated that our method achieves state-of-the-art performance across multiple personality detection benchmarks.",
      "url": "http://arxiv.org/abs/2601.18582",
      "author": "Yuan Cao, Feixiang Liu, Xinyue Wang, Yihan Zhu, Hui Xu, Zheng Wang, Qiang Qiu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Proposes ranking-based approach to MBTI personality detection from social media posts, moving from classification to pairwise comparison of personality traits.",
      "importance_score": 46,
      "reasoning": "Incremental methodological contribution to personality detection. Limited novelty in the approach.",
      "themes": [
        "Personality Detection",
        "Social Media NLP",
        "Classification"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes ranking-based approach to MBTI personality detection from social media posts, moving from classification to pairwise comparison of personality traits.</p>",
      "content_html": "<p>arXiv:2601.18582v1 Announce Type: new  Abstract: Personality detection aims to measure an individual's corresponding personality traits through their social media posts. The advancements in Large Language Models (LLMs) offer novel perspectives for personality detection tasks. Existing approaches enhance personality trait analysis by leveraging LLMs to extract semantic information from textual posts as prompts, followed by training classifiers for categorization. However, accurately classifying personality traits remains challenging due to the inherent complexity of human personality and subtle inter-trait distinctions. Moreover, prompt-based methods often exhibit excessive dependency on expert-crafted knowledge without autonomous pattern-learning capacity. To address these limitations, we view personality detection as a ranking task rather than a classification and propose a corresponding reinforcement learning training paradigm. First, we employ supervised fine-tuning (SFT) to establish personality trait ranking capabilities while enforcing standardized output formats, creating a robust initialization. Subsequently, we introduce Group Relative Policy Optimization (GRPO) with a specialized ranking-based reward function. Unlike verification tasks with definitive solutions, personality assessment involves subjective interpretations and blurred boundaries between trait categories. Our reward function explicitly addresses this challenge by training LLMs to learn optimal answer rankings. Comprehensive experiments have demonstrated that our method achieves state-of-the-art performance across multiple personality detection benchmarks.</p>"
    },
    {
      "id": "fe1584dfdd2e",
      "title": "Automated HER2 scoring with uncertainty quantification using lensfree holography and deep learning",
      "content": "arXiv:2601.18219v1 Announce Type: cross  Abstract: Accurate assessment of human epidermal growth factor receptor 2 (HER2) expression is critical for breast cancer diagnosis, prognosis, and therapy selection; yet, most existing digital HER2 scoring methods rely on bulky and expensive optical systems. Here, we present a compact and cost-effective lensfree holography platform integrated with deep learning for automated HER2 scoring of immunohistochemically stained breast tissue sections. The system captures lensfree diffraction patterns of stained HER2 tissue sections under RGB laser illumination and acquires complex field information over a sample area of ~1,250 mm^2 at an effective throughput of ~84 mm^2 per minute. To enhance diagnostic reliability, we incorporated an uncertainty quantification strategy based on Bayesian Monte Carlo dropout, which provides autonomous uncertainty estimates for each prediction and supports reliable, robust HER2 scoring, with an overall correction rate of 30.4%. Using a blinded test set of 412 unique tissue samples, our approach achieved a testing accuracy of 84.9% for 4-class (0, 1+, 2+, 3+) HER2 classification and 94.8% for binary (0/1+ vs. 2+/3+) HER2 scoring with uncertainty quantification. Overall, this lensfree holography approach provides a practical pathway toward portable, high-throughput, and cost-effective HER2 scoring, particularly suited for resource-limited settings, where traditional digital pathology infrastructure is unavailable.",
      "url": "http://arxiv.org/abs/2601.18219",
      "author": "Che-Yung Shen, Xilin Yang, Yuzhu Li, Leon Lenk, Aydogan Ozcan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "physics.med-ph"
      ],
      "summary": "Presents compact lensfree holography platform with deep learning for automated HER2 scoring of breast cancer tissue, achieving ~84 mm/minute throughput with uncertainty quantification.",
      "importance_score": 46,
      "reasoning": "Solid medical imaging application with practical deployment potential, but primarily engineering integration.",
      "themes": [
        "Medical Imaging",
        "Deep Learning",
        "Diagnostics"
      ],
      "continuation": null,
      "summary_html": "<p>Presents compact lensfree holography platform with deep learning for automated HER2 scoring of breast cancer tissue, achieving ~84 mm/minute throughput with uncertainty quantification.</p>",
      "content_html": "<p>arXiv:2601.18219v1 Announce Type: cross  Abstract: Accurate assessment of human epidermal growth factor receptor 2 (HER2) expression is critical for breast cancer diagnosis, prognosis, and therapy selection; yet, most existing digital HER2 scoring methods rely on bulky and expensive optical systems. Here, we present a compact and cost-effective lensfree holography platform integrated with deep learning for automated HER2 scoring of immunohistochemically stained breast tissue sections. The system captures lensfree diffraction patterns of stained HER2 tissue sections under RGB laser illumination and acquires complex field information over a sample area of ~1,250 mm^2 at an effective throughput of ~84 mm^2 per minute. To enhance diagnostic reliability, we incorporated an uncertainty quantification strategy based on Bayesian Monte Carlo dropout, which provides autonomous uncertainty estimates for each prediction and supports reliable, robust HER2 scoring, with an overall correction rate of 30.4%. Using a blinded test set of 412 unique tissue samples, our approach achieved a testing accuracy of 84.9% for 4-class (0, 1+, 2+, 3+) HER2 classification and 94.8% for binary (0/1+ vs. 2+/3+) HER2 scoring with uncertainty quantification. Overall, this lensfree holography approach provides a practical pathway toward portable, high-throughput, and cost-effective HER2 scoring, particularly suited for resource-limited settings, where traditional digital pathology infrastructure is unavailable.</p>"
    },
    {
      "id": "8b3653d6af5f",
      "title": "Eye-Tracking-Driven Control in Daily Task Assistance for Assistive Robotic Arms",
      "content": "arXiv:2601.17404v1 Announce Type: new  Abstract: Shared control improves Human-Robot Interaction by reducing the user's workload and increasing the robot's autonomy. It allows robots to perform tasks under the user's supervision. Current eye-tracking-driven approaches face several challenges. These include accuracy issues in 3D gaze estimation and difficulty interpreting gaze when differentiating between multiple tasks. We present an eye-tracking-driven control framework, aimed at enabling individuals with severe physical disabilities to perform daily tasks independently. Our system uses task pictograms as fiducial markers combined with a feature matching approach that transmits data of the selected object to accomplish necessary task related measurements with an eye-in-hand configuration. This eye-tracking control does not require knowledge of the user's position in relation to the object. The framework correctly interpreted object and task selection in up to 97.9% of measurements. Issues were found in the evaluation, that were improved and shared as lessons learned. The open-source framework can be adapted to new tasks and objects due to the integration of state-of-the-art object detection models.",
      "url": "http://arxiv.org/abs/2601.17404",
      "author": "Anke Fischer-Janzen, Thomas M. Wendt, Kristof Van Laerhoven",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents eye-tracking-driven shared control framework for assistive robotic arms using task pictograms as fiducial markers combined with feature matching.",
      "importance_score": 46,
      "reasoning": "Important accessibility application but incremental technical contribution.",
      "themes": [
        "Assistive Robotics",
        "Eye Tracking",
        "Shared Control"
      ],
      "continuation": null,
      "summary_html": "<p>Presents eye-tracking-driven shared control framework for assistive robotic arms using task pictograms as fiducial markers combined with feature matching.</p>",
      "content_html": "<p>arXiv:2601.17404v1 Announce Type: new  Abstract: Shared control improves Human-Robot Interaction by reducing the user's workload and increasing the robot's autonomy. It allows robots to perform tasks under the user's supervision. Current eye-tracking-driven approaches face several challenges. These include accuracy issues in 3D gaze estimation and difficulty interpreting gaze when differentiating between multiple tasks. We present an eye-tracking-driven control framework, aimed at enabling individuals with severe physical disabilities to perform daily tasks independently. Our system uses task pictograms as fiducial markers combined with a feature matching approach that transmits data of the selected object to accomplish necessary task related measurements with an eye-in-hand configuration. This eye-tracking control does not require knowledge of the user's position in relation to the object. The framework correctly interpreted object and task selection in up to 97.9% of measurements. Issues were found in the evaluation, that were improved and shared as lessons learned. The open-source framework can be adapted to new tasks and objects due to the integration of state-of-the-art object detection models.</p>"
    },
    {
      "id": "c21e04054576",
      "title": "Nonlinear multi-study factor analysis",
      "content": "arXiv:2601.18128v1 Announce Type: new  Abstract: High-dimensional data often exhibit variation that can be captured by lower dimensional factors. For high-dimensional data from multiple studies or environments, one goal is to understand which underlying factors are common to all studies, and which factors are study or environment-specific. As a particular example, we consider platelet gene expression data from patients in different disease groups. In this data, factors correspond to clusters of genes which are co-expressed; we may expect some clusters (or biological pathways) to be active for all diseases, while some clusters are only active for a specific disease. To learn these factors, we consider a nonlinear multi-study factor model, which allows for both shared and specific factors. To fit this model, we propose a multi-study sparse variational autoencoder. The underlying model is sparse in that each observed feature (i.e. each dimension of the data) depends on a small subset of the latent factors. In the genomics example, this means each gene is active in only a few biological processes. Further, the model implicitly induces a penalty on the number of latent factors, which helps separate the shared factors from the group-specific factors. We prove that the latent factors are identified, and demonstrate our method recovers meaningful factors in the platelet gene expression data.",
      "url": "http://arxiv.org/abs/2601.18128",
      "author": "Gemma E. Moran, Anandi Krishnan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "stat.ML"
      ],
      "summary": "Proposes nonlinear multi-study factor model for learning shared and study-specific factors from multiple datasets through shared simplex geometry.",
      "importance_score": 46,
      "reasoning": "Useful methodology for multi-study analysis but incremental contribution to factor models.",
      "themes": [
        "Factor Analysis",
        "Multi-Study Learning",
        "Statistical Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes nonlinear multi-study factor model for learning shared and study-specific factors from multiple datasets through shared simplex geometry.</p>",
      "content_html": "<p>arXiv:2601.18128v1 Announce Type: new  Abstract: High-dimensional data often exhibit variation that can be captured by lower dimensional factors. For high-dimensional data from multiple studies or environments, one goal is to understand which underlying factors are common to all studies, and which factors are study or environment-specific. As a particular example, we consider platelet gene expression data from patients in different disease groups. In this data, factors correspond to clusters of genes which are co-expressed; we may expect some clusters (or biological pathways) to be active for all diseases, while some clusters are only active for a specific disease. To learn these factors, we consider a nonlinear multi-study factor model, which allows for both shared and specific factors. To fit this model, we propose a multi-study sparse variational autoencoder. The underlying model is sparse in that each observed feature (i.e. each dimension of the data) depends on a small subset of the latent factors. In the genomics example, this means each gene is active in only a few biological processes. Further, the model implicitly induces a penalty on the number of latent factors, which helps separate the shared factors from the group-specific factors. We prove that the latent factors are identified, and demonstrate our method recovers meaningful factors in the platelet gene expression data.</p>"
    },
    {
      "id": "e74a41d800bf",
      "title": "Semantic-Aware Task Clustering for Federated Cooperative Multi-Task Semantic Communication",
      "content": "arXiv:2601.17419v1 Announce Type: cross  Abstract: Task-oriented semantic communication (SemCom) prioritizes task execution over accurate symbol reconstruction and is well-suited to emerging intelligent applications. Cooperative multi-task SemCom (CMT-SemCom) further improves task execution performance. However, [1] demonstrates that cooperative multi-tasking can be either constructive or destructive. Moreover, the existing CMT-SemCom framework is not directly applicable to distributed multi-user scenarios, such as non-terrestrial satellite networks, where each satellite employs an individual semantic encoder. In this paper, we extend our earlier CMT-SemCom framework to distributed settings by proposing a federated learning (FL) based CMT-SemCom that enables cooperative multi-tasking across distributed users. Moreover, to address performance degradation caused by negative information transfer among heterogeneous tasks, we propose a semantic-aware task clustering method integrated in the FL process to ensure constructive cooperation based on an information-theoretic approach. Unlike common clustering methods that rely on high-dimensional data or feature space similarity, our proposed approach operates in the low-dimensional semantic domain to identify meaningful task relationships. Simulation results based on a LEO satellite network setup demonstrate the effectiveness of our approach and performance gain over unclustered FL and individual single-task SemCom.",
      "url": "http://arxiv.org/abs/2601.17419",
      "author": "Ahmad Halimi Razlighi, Pallavi Dhingra, Edgar Beck, Bho Matthiesen, Armin Dekorsy",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "eess.SP"
      ],
      "summary": "Extends CMT-SemCom to distributed settings using federated learning for cooperative multi-task semantic communication across distributed users.",
      "importance_score": 46,
      "reasoning": "Useful extension of semantic communication to federated setting, combines two active research areas.",
      "themes": [
        "Semantic Communication",
        "Federated Learning",
        "Wireless Communications"
      ],
      "continuation": null,
      "summary_html": "<p>Extends CMT-SemCom to distributed settings using federated learning for cooperative multi-task semantic communication across distributed users.</p>",
      "content_html": "<p>arXiv:2601.17419v1 Announce Type: cross  Abstract: Task-oriented semantic communication (SemCom) prioritizes task execution over accurate symbol reconstruction and is well-suited to emerging intelligent applications. Cooperative multi-task SemCom (CMT-SemCom) further improves task execution performance. However, [1] demonstrates that cooperative multi-tasking can be either constructive or destructive. Moreover, the existing CMT-SemCom framework is not directly applicable to distributed multi-user scenarios, such as non-terrestrial satellite networks, where each satellite employs an individual semantic encoder. In this paper, we extend our earlier CMT-SemCom framework to distributed settings by proposing a federated learning (FL) based CMT-SemCom that enables cooperative multi-tasking across distributed users. Moreover, to address performance degradation caused by negative information transfer among heterogeneous tasks, we propose a semantic-aware task clustering method integrated in the FL process to ensure constructive cooperation based on an information-theoretic approach. Unlike common clustering methods that rely on high-dimensional data or feature space similarity, our proposed approach operates in the low-dimensional semantic domain to identify meaningful task relationships. Simulation results based on a LEO satellite network setup demonstrate the effectiveness of our approach and performance gain over unclustered FL and individual single-task SemCom.</p>"
    },
    {
      "id": "727df0d8f212",
      "title": "Multi-Agent Learning Path Planning via LLMs",
      "content": "arXiv:2601.17346v1 Announce Type: new  Abstract: The integration of large language models (LLMs) into intelligent tutoring systems offers transformative potential for personalized learning in higher education. However, most existing learning path planning approaches lack transparency, adaptability, and learner-centered explainability. To address these challenges, this study proposes a novel Multi-Agent Learning Path Planning (MALPP) framework that leverages a role- and rule-based collaboration mechanism among intelligent agents, each powered by LLMs. The framework includes three task-specific agents: a learner analytics agent, a path planning agent, and a reflection agent. These agents collaborate via structured prompts and predefined rules to analyze learning profiles, generate tailored learning paths, and iteratively refine them with interpretable feedback. Grounded in Cognitive Load Theory and Zone of Proximal Development, the system ensures that recommended paths are cognitively aligned and pedagogically meaningful. Experiments conducted on the MOOCCubeX dataset using seven LLMs show that MALPP significantly outperforms baseline models in path quality, knowledge sequence consistency, and cognitive load alignment. Ablation studies further validate the effectiveness of the collaborative mechanism and theoretical constraints. This research contributes to the development of trustworthy, explainable AI in education and demonstrates a scalable approach to learner-centered adaptive instruction powered by LLMs.",
      "url": "http://arxiv.org/abs/2601.17346",
      "author": "Haoxin Xu, Changyong Qi, Tong Liu, Bohao Zhang, Anna He, Bingqian Jiang, Longwei Zheng, Xiaoqing Gu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes MALPP framework using multiple LLM-powered agents (learner analytics, path planning, reflection) collaborating via structured prompts to generate personalized learning paths in educational contexts.",
      "importance_score": 45,
      "reasoning": "Straightforward application of multi-agent LLMs to education; limited technical novelty though practical relevance.",
      "themes": [
        "Educational AI",
        "Multi-Agent Systems",
        "Personalization"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes MALPP framework using multiple LLM-powered agents (learner analytics, path planning, reflection) collaborating via structured prompts to generate personalized learning paths in educational contexts.</p>",
      "content_html": "<p>arXiv:2601.17346v1 Announce Type: new  Abstract: The integration of large language models (LLMs) into intelligent tutoring systems offers transformative potential for personalized learning in higher education. However, most existing learning path planning approaches lack transparency, adaptability, and learner-centered explainability. To address these challenges, this study proposes a novel Multi-Agent Learning Path Planning (MALPP) framework that leverages a role- and rule-based collaboration mechanism among intelligent agents, each powered by LLMs. The framework includes three task-specific agents: a learner analytics agent, a path planning agent, and a reflection agent. These agents collaborate via structured prompts and predefined rules to analyze learning profiles, generate tailored learning paths, and iteratively refine them with interpretable feedback. Grounded in Cognitive Load Theory and Zone of Proximal Development, the system ensures that recommended paths are cognitively aligned and pedagogically meaningful. Experiments conducted on the MOOCCubeX dataset using seven LLMs show that MALPP significantly outperforms baseline models in path quality, knowledge sequence consistency, and cognitive load alignment. Ablation studies further validate the effectiveness of the collaborative mechanism and theoretical constraints. This research contributes to the development of trustworthy, explainable AI in education and demonstrates a scalable approach to learner-centered adaptive instruction powered by LLMs.</p>"
    },
    {
      "id": "1c4221e547a2",
      "title": "AI Agent for Reverse-Engineering Legacy Finite-Difference Code and Translating to Devito",
      "content": "arXiv:2601.18381v1 Announce Type: new  Abstract: To facilitate the transformation of legacy finite difference implementations into the Devito environment, this study develops an integrated AI agent framework. Retrieval-Augmented Generation (RAG) and open-source Large Language Models are combined through multi-stage iterative workflows in the system's hybrid LangGraph architecture. The agent constructs an extensive Devito knowledge graph through document parsing, structure-aware segmentation, extraction of entity relationships, and Leiden-based community detection. GraphRAG optimisation enhances query performance across semantic communities that include seismic wave simulation, computational fluid dynamics, and performance tuning libraries. A reverse engineering component derives three-level query strategies for RAG retrieval through static analysis of Fortran source code. To deliver precise contextual information for language model guidance, the multi-stage retrieval pipeline performs parallel searching, concept expansion, community-scale retrieval, and semantic similarity analysis. Code synthesis is governed by Pydantic-based constraints to guarantee structured outputs and reliability. A comprehensive validation framework integrates conventional static analysis with the G-Eval approach, covering execution correctness, structural soundness, mathematical consistency, and API compliance. The overall agent workflow is implemented on the LangGraph framework and adopts concurrent processing to support quality-based iterative refinement and state-aware dynamic routing. The principal contribution lies in the incorporation of feedback mechanisms motivated by reinforcement learning, enabling a transition from static code translation toward dynamic and adaptive analytical behavior.",
      "url": "http://arxiv.org/abs/2601.18381",
      "author": "Yinghan Hou, Zongyou Yang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Develops AI agent framework for reverse-engineering legacy finite difference code and translating to Devito using RAG with knowledge graphs and multi-stage workflows.",
      "importance_score": 45,
      "reasoning": "Specialized code translation tool; practical but narrow application scope.",
      "themes": [
        "Code Generation",
        "Legacy Systems",
        "RAG"
      ],
      "continuation": null,
      "summary_html": "<p>Develops AI agent framework for reverse-engineering legacy finite difference code and translating to Devito using RAG with knowledge graphs and multi-stage workflows.</p>",
      "content_html": "<p>arXiv:2601.18381v1 Announce Type: new  Abstract: To facilitate the transformation of legacy finite difference implementations into the Devito environment, this study develops an integrated AI agent framework. Retrieval-Augmented Generation (RAG) and open-source Large Language Models are combined through multi-stage iterative workflows in the system's hybrid LangGraph architecture. The agent constructs an extensive Devito knowledge graph through document parsing, structure-aware segmentation, extraction of entity relationships, and Leiden-based community detection. GraphRAG optimisation enhances query performance across semantic communities that include seismic wave simulation, computational fluid dynamics, and performance tuning libraries. A reverse engineering component derives three-level query strategies for RAG retrieval through static analysis of Fortran source code. To deliver precise contextual information for language model guidance, the multi-stage retrieval pipeline performs parallel searching, concept expansion, community-scale retrieval, and semantic similarity analysis. Code synthesis is governed by Pydantic-based constraints to guarantee structured outputs and reliability. A comprehensive validation framework integrates conventional static analysis with the G-Eval approach, covering execution correctness, structural soundness, mathematical consistency, and API compliance. The overall agent workflow is implemented on the LangGraph framework and adopts concurrent processing to support quality-based iterative refinement and state-aware dynamic routing. The principal contribution lies in the incorporation of feedback mechanisms motivated by reinforcement learning, enabling a transition from static code translation toward dynamic and adaptive analytical behavior.</p>"
    },
    {
      "id": "8d5605367ac2",
      "title": "Data-Efficient Meningioma Segmentation via Implicit Spatiotemporal Mixing and Sim2Real Semantic Injection",
      "content": "arXiv:2601.17031v1 Announce Type: cross  Abstract: The performance of medical image segmentation is increasingly defined by the efficiency of data utilization rather than merely the volume of raw data. Accurate segmentation, particularly for complex pathologies like meningiomas, demands that models fully exploit the latent information within limited high-quality annotations. To maximize the value of existing datasets, we propose a novel dual-augmentation framework that synergistically integrates spatial manifold expansion and semantic object injection. Specifically, we leverage Implicit Neural Representations (INR) to model continuous velocity fields. Unlike previous methods, we perform linear mixing on the integrated deformation fields, enabling the efficient generation of anatomically plausible variations by interpolating within the deformation space. This approach allows for the extensive exploration of structural diversity from a small set of anchors. Furthermore, we introduce a Sim2Real lesion injection module. This module constructs a high-fidelity simulation domain by transplanting lesion textures into healthy anatomical backgrounds, effectively bridging the gap between synthetic augmentation and real-world pathology. Comprehensive experiments on a hybrid dataset demonstrate that our framework significantly enhances the data efficiency and robustness of state-of-the-art models, including nnU-Net and U-Mamba, offering a potent strategy for high-performance medical image analysis with limited annotation budgets.",
      "url": "http://arxiv.org/abs/2601.17031",
      "author": "Yunhao Xu, Fuquan Zong, Yexuan Xing, Chulong Zhang, Guang Yang, Shilong Yang, Xiaokun Liang, Juan Yu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes dual-augmentation framework for meningioma segmentation combining Implicit Neural Representations for spatial expansion and semantic object injection. Addresses data efficiency in medical imaging.",
      "importance_score": 45,
      "reasoning": "Solid medical imaging contribution using INR for data augmentation. Domain-specific application with limited broader impact.",
      "themes": [
        "Medical Imaging",
        "Data Augmentation",
        "Neural Representations"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes dual-augmentation framework for meningioma segmentation combining Implicit Neural Representations for spatial expansion and semantic object injection. Addresses data efficiency in medical imaging.</p>",
      "content_html": "<p>arXiv:2601.17031v1 Announce Type: cross  Abstract: The performance of medical image segmentation is increasingly defined by the efficiency of data utilization rather than merely the volume of raw data. Accurate segmentation, particularly for complex pathologies like meningiomas, demands that models fully exploit the latent information within limited high-quality annotations. To maximize the value of existing datasets, we propose a novel dual-augmentation framework that synergistically integrates spatial manifold expansion and semantic object injection. Specifically, we leverage Implicit Neural Representations (INR) to model continuous velocity fields. Unlike previous methods, we perform linear mixing on the integrated deformation fields, enabling the efficient generation of anatomically plausible variations by interpolating within the deformation space. This approach allows for the extensive exploration of structural diversity from a small set of anchors. Furthermore, we introduce a Sim2Real lesion injection module. This module constructs a high-fidelity simulation domain by transplanting lesion textures into healthy anatomical backgrounds, effectively bridging the gap between synthetic augmentation and real-world pathology. Comprehensive experiments on a hybrid dataset demonstrate that our framework significantly enhances the data efficiency and robustness of state-of-the-art models, including nnU-Net and U-Mamba, offering a potent strategy for high-performance medical image analysis with limited annotation budgets.</p>"
    },
    {
      "id": "e1eb59b1c67d",
      "title": "MambaNet: Mamba-assisted Channel Estimation Neural Network With Attention Mechanism",
      "content": "arXiv:2601.17108v1 Announce Type: cross  Abstract: This paper proposes a Mamba-assisted neural network framework incorporating self-attention mechanism to achieve improved channel estimation with low complexity for orthogonal frequency-division multiplexing (OFDM) waveforms, particularly for configurations with a large number of subcarriers. With the integration of customized Mamba architecture, the proposed framework handles large-scale subcarrier channel estimation efficiently while capturing long-distance dependencies among these subcarriers effectively. Unlike conventional Mamba structure, this paper implements a bidirectional selective scan to improve channel estimation performance, because channel gains at different subcarriers are non-causal. Moreover, the proposed framework exhibits relatively lower space complexity than transformer-based neural networks. Simulation results tested on the 3GPP TS 36.101 channel demonstrate that compared to other baseline neural network solutions, the proposed method achieves improved channel estimation performance with a reduced number of tunable parameters.",
      "url": "http://arxiv.org/abs/2601.17108",
      "author": "Dianxin Luan, Chengsi Liang, Jie Huang, Zheng Lin, Kaitao Meng, John Thompson, Cheng-Xiang Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes MambaNet combining Mamba architecture with bidirectional selective scan and self-attention for OFDM channel estimation with large subcarrier configurations.",
      "importance_score": 45,
      "reasoning": "Applies Mamba architecture to signal processing domain. Technical contribution but narrow application scope.",
      "themes": [
        "Mamba Architecture",
        "Signal Processing",
        "Communications"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes MambaNet combining Mamba architecture with bidirectional selective scan and self-attention for OFDM channel estimation with large subcarrier configurations.</p>",
      "content_html": "<p>arXiv:2601.17108v1 Announce Type: cross  Abstract: This paper proposes a Mamba-assisted neural network framework incorporating self-attention mechanism to achieve improved channel estimation with low complexity for orthogonal frequency-division multiplexing (OFDM) waveforms, particularly for configurations with a large number of subcarriers. With the integration of customized Mamba architecture, the proposed framework handles large-scale subcarrier channel estimation efficiently while capturing long-distance dependencies among these subcarriers effectively. Unlike conventional Mamba structure, this paper implements a bidirectional selective scan to improve channel estimation performance, because channel gains at different subcarriers are non-causal. Moreover, the proposed framework exhibits relatively lower space complexity than transformer-based neural networks. Simulation results tested on the 3GPP TS 36.101 channel demonstrate that compared to other baseline neural network solutions, the proposed method achieves improved channel estimation performance with a reduced number of tunable parameters.</p>"
    },
    {
      "id": "2ed423808846",
      "title": "Benchmarking Deep Learning-Based Reconstruction Methods for Photoacoustic Computed Tomography with Clinically Relevant Synthetic Datasets",
      "content": "arXiv:2601.17165v1 Announce Type: cross  Abstract: Deep learning (DL)-based image reconstruction methods for photoacoustic computed tomography (PACT) have developed rapidly in recent years. However, most existing methods have not employed standardized datasets, and their evaluations rely on traditional image quality (IQ) metrics that may lack clinical relevance. The absence of a standardized framework for clinically meaningful IQ assessment hinders fair comparison and raises concerns about the reproducibility and reliability of reported advancements in PACT. A benchmarking framework is proposed that provides open-source, anatomically plausible synthetic datasets and evaluation strategies for DL-based acoustic inversion methods in PACT. The datasets each include over 11,000 two-dimensional (2D) stochastic breast objects with clinically relevant lesions and paired measurements at varying modeling complexity. The evaluation strategies incorporate both traditional and task-based IQ measures to assess fidelity and clinical utility. A preliminary benchmarking study is conducted to demonstrate the framework's utility by comparing DL-based and physics-based reconstruction methods. The benchmarking study demonstrated that the proposed framework enabled comprehensive, quantitative comparisons of reconstruction performance and revealed important limitations in certain DL-based methods. Although they performed well according to traditional IQ measures, they often failed to accurately recover lesions. This highlights the inadequacy of traditional metrics and motivates the need for task-based assessments. The proposed benchmarking framework enables systematic comparisons of DL-based acoustic inversion methods for 2D PACT. By integrating clinically relevant synthetic datasets with rigorous evaluation protocols, it enables reproducible, objective assessments and facilitates method development and system optimization in PACT.",
      "url": "http://arxiv.org/abs/2601.17165",
      "author": "Panpan Chen, Seonyeong Park, Gangwon Jeong, Refik Mert Cam, Umberto Villa, Mark A. Anastasio",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "physics.med-ph"
      ],
      "summary": "Proposes benchmarking framework for DL-based photoacoustic computed tomography with anatomically plausible synthetic datasets and clinically relevant evaluation strategies.",
      "importance_score": 45,
      "reasoning": "Useful benchmark contribution for medical imaging. Addresses reproducibility concerns but domain-specific impact.",
      "themes": [
        "Medical Imaging",
        "Benchmarks",
        "Deep Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes benchmarking framework for DL-based photoacoustic computed tomography with anatomically plausible synthetic datasets and clinically relevant evaluation strategies.</p>",
      "content_html": "<p>arXiv:2601.17165v1 Announce Type: cross  Abstract: Deep learning (DL)-based image reconstruction methods for photoacoustic computed tomography (PACT) have developed rapidly in recent years. However, most existing methods have not employed standardized datasets, and their evaluations rely on traditional image quality (IQ) metrics that may lack clinical relevance. The absence of a standardized framework for clinically meaningful IQ assessment hinders fair comparison and raises concerns about the reproducibility and reliability of reported advancements in PACT. A benchmarking framework is proposed that provides open-source, anatomically plausible synthetic datasets and evaluation strategies for DL-based acoustic inversion methods in PACT. The datasets each include over 11,000 two-dimensional (2D) stochastic breast objects with clinically relevant lesions and paired measurements at varying modeling complexity. The evaluation strategies incorporate both traditional and task-based IQ measures to assess fidelity and clinical utility. A preliminary benchmarking study is conducted to demonstrate the framework's utility by comparing DL-based and physics-based reconstruction methods. The benchmarking study demonstrated that the proposed framework enabled comprehensive, quantitative comparisons of reconstruction performance and revealed important limitations in certain DL-based methods. Although they performed well according to traditional IQ measures, they often failed to accurately recover lesions. This highlights the inadequacy of traditional metrics and motivates the need for task-based assessments. The proposed benchmarking framework enables systematic comparisons of DL-based acoustic inversion methods for 2D PACT. By integrating clinically relevant synthetic datasets with rigorous evaluation protocols, it enables reproducible, objective assessments and facilitates method development and system optimization in PACT.</p>"
    },
    {
      "id": "2e8aac698491",
      "title": "Spatiotemporal Semantic V2X Framework for Cooperative Collision Prediction",
      "content": "arXiv:2601.17216v1 Announce Type: cross  Abstract: Intelligent Transportation Systems (ITS) demand real-time collision prediction to ensure road safety and reduce accident severity. Conventional approaches rely on transmitting raw video or high-dimensional sensory data from roadside units (RSUs) to vehicles, which is impractical under vehicular communication bandwidth and latency constraints. In this work, we propose a semantic V2X framework in which RSU-mounted cameras generate spatiotemporal semantic embeddings of future frames using the Video Joint Embedding Predictive Architecture (V-JEPA). To evaluate the system, we construct a digital twin of an urban traffic environment enabling the generation of d verse traffic scenarios with both safe and collision events. These embeddings of the future frame, extracted from V-JEPA, capture task-relevant traffic dynamics and are transmitted via V2X links to vehicles, where a lightweight attentive probe and classifier decode them to predict imminent collisions. By transmitting only semantic embeddings instead of raw frames, the proposed system significantly reduces communication overhead while maintaining predictive accuracy. Experimental results demonstrate that the framework with an appropriate processing method achieves a 10% F1-score improvement for collision prediction while reducing transmission requirements by four orders of magnitude compared to raw video. This validates the potential of semantic V2X communication to enable cooperative, real-time collision prediction in ITS.",
      "url": "http://arxiv.org/abs/2601.17216",
      "author": "Murat Arda Onsu, Poonam Lohan, Burak Kantarci, Aisha Syed, Matthew Andrews, Sean Kennedy",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes semantic V2X framework using V-JEPA to generate spatiotemporal embeddings for cooperative collision prediction in intelligent transportation systems.",
      "importance_score": 45,
      "reasoning": "Novel application of V-JEPA for vehicular communication. Addresses bandwidth constraints but simulation-only evaluation.",
      "themes": [
        "Autonomous Vehicles",
        "Semantic Communication",
        "Video Understanding"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes semantic V2X framework using V-JEPA to generate spatiotemporal embeddings for cooperative collision prediction in intelligent transportation systems.</p>",
      "content_html": "<p>arXiv:2601.17216v1 Announce Type: cross  Abstract: Intelligent Transportation Systems (ITS) demand real-time collision prediction to ensure road safety and reduce accident severity. Conventional approaches rely on transmitting raw video or high-dimensional sensory data from roadside units (RSUs) to vehicles, which is impractical under vehicular communication bandwidth and latency constraints. In this work, we propose a semantic V2X framework in which RSU-mounted cameras generate spatiotemporal semantic embeddings of future frames using the Video Joint Embedding Predictive Architecture (V-JEPA). To evaluate the system, we construct a digital twin of an urban traffic environment enabling the generation of d verse traffic scenarios with both safe and collision events. These embeddings of the future frame, extracted from V-JEPA, capture task-relevant traffic dynamics and are transmitted via V2X links to vehicles, where a lightweight attentive probe and classifier decode them to predict imminent collisions. By transmitting only semantic embeddings instead of raw frames, the proposed system significantly reduces communication overhead while maintaining predictive accuracy. Experimental results demonstrate that the framework with an appropriate processing method achieves a 10% F1-score improvement for collision prediction while reducing transmission requirements by four orders of magnitude compared to raw video. This validates the potential of semantic V2X communication to enable cooperative, real-time collision prediction in ITS.</p>"
    },
    {
      "id": "224052d6094a",
      "title": "Retell, Reward, Repeat: Reinforcement Learning for Narrative Theory-Informed Story Generation",
      "content": "arXiv:2601.17226v1 Announce Type: cross  Abstract: Despite the subjective nature of storytelling, past works on automatic story generation (ASG) have relied on limited ground truths for training and evaluation. In this work, we explore reinforcement learning (d-RLAIF) as a post-training alternative to supervised fine-tuning (SFT). We first apply Todorov's Theory of Narrative Equilibrium to establish principles that define desirable ASG qualities. We prompt 7B and 14B LLM-as-judge models with our principles to test alignment with human annotators and provide reward signals during d-RLAIF. We use Gemini-3-Flash to evaluate the output of our post-trained models and compare them to human-written stories from the TimeTravel dataset. We show that d-RLAIF offers a viable alternative to supervised fine-tuning (SFT)--producing stories that are more diverse and aligned with human narrative conventions. Our paper demonstrates the promise of reinforcement learning for linguistically grounded post-training for subjective tasks such as ASG.",
      "url": "http://arxiv.org/abs/2601.17226",
      "author": "David Y. Liu, Xanthe Muston, Aditya Joshi, Sebastian Sequoiah-Grayson",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Explores d-RLAIF for narrative-informed story generation using Todorov's Theory of Narrative Equilibrium. Uses LLM-as-judge for reward signals aligned with narrative principles.",
      "importance_score": 45,
      "reasoning": "Interesting application of narrative theory to RL. Novel combination but limited evaluation scope.",
      "themes": [
        "Story Generation",
        "RLAIF",
        "Narrative AI"
      ],
      "continuation": null,
      "summary_html": "<p>Explores d-RLAIF for narrative-informed story generation using Todorov's Theory of Narrative Equilibrium. Uses LLM-as-judge for reward signals aligned with narrative principles.</p>",
      "content_html": "<p>arXiv:2601.17226v1 Announce Type: cross  Abstract: Despite the subjective nature of storytelling, past works on automatic story generation (ASG) have relied on limited ground truths for training and evaluation. In this work, we explore reinforcement learning (d-RLAIF) as a post-training alternative to supervised fine-tuning (SFT). We first apply Todorov's Theory of Narrative Equilibrium to establish principles that define desirable ASG qualities. We prompt 7B and 14B LLM-as-judge models with our principles to test alignment with human annotators and provide reward signals during d-RLAIF. We use Gemini-3-Flash to evaluate the output of our post-trained models and compare them to human-written stories from the TimeTravel dataset. We show that d-RLAIF offers a viable alternative to supervised fine-tuning (SFT)--producing stories that are more diverse and aligned with human narrative conventions. Our paper demonstrates the promise of reinforcement learning for linguistically grounded post-training for subjective tasks such as ASG.</p>"
    },
    {
      "id": "4dfceb7f20c6",
      "title": "UrduLM: A Resource-Efficient Monolingual Urdu Language Model",
      "content": "arXiv:2601.17664v1 Announce Type: cross  Abstract: Urdu, spoken by 230 million people worldwide, lacks dedicated transformer-based language models and curated corpora. While multilingual models provide limited Urdu support, they suffer from poor performance, high computational costs, and cultural inaccuracies due to insufficient training data. To address these challenges, we present UrduLM, a pretrained Urdu monolingual language model trained in low-resource settings. We curate a 33GB Urdu corpus from diverse sources, develop a custom BPE tokenizer that reduces tokenization overhead by atleast 20-30% compared to multilingual alternatives, and pretrain a 100M-parameter decoder-only model. In few-shot evaluations, UrduLM achieves competitive performance with multilingual models up to 30x its size, reaching 66.6% accuracy on sentiment classification and BLEU scores exceeding 30 on grammar correction tasks. The complete methodology -- including corpus, tokenizer, model weights, and evaluation benchmarks -- is released openly to establish a baseline for Urdu NLP research and provide a scalable framework for other underrepresented languages.",
      "url": "http://arxiv.org/abs/2601.17664",
      "author": "Syed Muhammad Ali, Hammad Sajid, Zainab Haider, Ali Muhammad Asad, Haya Fatima, Abdul Samad",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "UrduLM presents a 100M-parameter monolingual Urdu LLM with custom tokenizer achieving 20-30% tokenization efficiency improvement over multilingual alternatives.",
      "importance_score": 45,
      "reasoning": "Low-resource language model development. Custom tokenizer contribution. Important for language diversity.",
      "themes": [
        "Low-resource NLP",
        "Language Models",
        "Tokenization"
      ],
      "continuation": null,
      "summary_html": "<p>UrduLM presents a 100M-parameter monolingual Urdu LLM with custom tokenizer achieving 20-30% tokenization efficiency improvement over multilingual alternatives.</p>",
      "content_html": "<p>arXiv:2601.17664v1 Announce Type: cross  Abstract: Urdu, spoken by 230 million people worldwide, lacks dedicated transformer-based language models and curated corpora. While multilingual models provide limited Urdu support, they suffer from poor performance, high computational costs, and cultural inaccuracies due to insufficient training data. To address these challenges, we present UrduLM, a pretrained Urdu monolingual language model trained in low-resource settings. We curate a 33GB Urdu corpus from diverse sources, develop a custom BPE tokenizer that reduces tokenization overhead by atleast 20-30% compared to multilingual alternatives, and pretrain a 100M-parameter decoder-only model. In few-shot evaluations, UrduLM achieves competitive performance with multilingual models up to 30x its size, reaching 66.6% accuracy on sentiment classification and BLEU scores exceeding 30 on grammar correction tasks. The complete methodology -- including corpus, tokenizer, model weights, and evaluation benchmarks -- is released openly to establish a baseline for Urdu NLP research and provide a scalable framework for other underrepresented languages.</p>"
    },
    {
      "id": "674751b6b0ac",
      "title": "LungCRCT: Causal Representation based Lung CT Processing for Lung Cancer Treatment",
      "content": "arXiv:2601.18118v1 Announce Type: cross  Abstract: Due to silence in early stages, lung cancer has been one of the most leading causes of mortality in cancer patients world-wide. Moreover, major symptoms of lung cancer are hard to differentiate with other respiratory disease symptoms such as COPD, further leading patients to overlook cancer progression in early stages. Thus, to enhance survival rates in lung cancer, early detection from consistent proactive respiratory system monitoring becomes crucial. One of the most prevalent and effective methods for lung cancer monitoring would be low-dose computed tomography(LDCT) chest scans, which led to remarkable enhancements in lung cancer detection or tumor classification tasks under rapid advancements and applications of computer vision based AI models such as EfficientNet or ResNet in image processing. However, though advanced CNN models under transfer learning or ViT based models led to high performing lung cancer detections, due to its intrinsic limitations in terms of correlation dependence and low interpretability due to complexity, expansions of deep learning models to lung cancer treatment analysis or causal intervention analysis simulations are still limited. Therefore, this research introduced LungCRCT: a latent causal representation learning based lung cancer analysis framework that retrieves causal representations of factors within the physical causal mechanism of lung cancer progression. With the use of advanced graph autoencoder based causal discovery algorithms with distance Correlation disentanglement and entropy-based image reconstruction refinement, LungCRCT not only enables causal intervention analysis for lung cancer treatments, but also leads to robust, yet extremely light downstream models in malignant tumor classification tasks with an AUC score of 93.91%.",
      "url": "http://arxiv.org/abs/2601.18118",
      "author": "Daeyoung Kim",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes causal representation learning approach for lung CT processing to enhance lung cancer detection. Aims to address early-stage detection challenges where symptoms overlap with other respiratory diseases.",
      "importance_score": 45,
      "reasoning": "Single author, specialized medical application. Causal representation angle is interesting but limited details on novelty and validation.",
      "themes": [
        "Medical AI",
        "Causal Representation",
        "Computer Vision"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes causal representation learning approach for lung CT processing to enhance lung cancer detection. Aims to address early-stage detection challenges where symptoms overlap with other respiratory diseases.</p>",
      "content_html": "<p>arXiv:2601.18118v1 Announce Type: cross  Abstract: Due to silence in early stages, lung cancer has been one of the most leading causes of mortality in cancer patients world-wide. Moreover, major symptoms of lung cancer are hard to differentiate with other respiratory disease symptoms such as COPD, further leading patients to overlook cancer progression in early stages. Thus, to enhance survival rates in lung cancer, early detection from consistent proactive respiratory system monitoring becomes crucial. One of the most prevalent and effective methods for lung cancer monitoring would be low-dose computed tomography(LDCT) chest scans, which led to remarkable enhancements in lung cancer detection or tumor classification tasks under rapid advancements and applications of computer vision based AI models such as EfficientNet or ResNet in image processing. However, though advanced CNN models under transfer learning or ViT based models led to high performing lung cancer detections, due to its intrinsic limitations in terms of correlation dependence and low interpretability due to complexity, expansions of deep learning models to lung cancer treatment analysis or causal intervention analysis simulations are still limited. Therefore, this research introduced LungCRCT: a latent causal representation learning based lung cancer analysis framework that retrieves causal representations of factors within the physical causal mechanism of lung cancer progression. With the use of advanced graph autoencoder based causal discovery algorithms with distance Correlation disentanglement and entropy-based image reconstruction refinement, LungCRCT not only enables causal intervention analysis for lung cancer treatments, but also leads to robust, yet extremely light downstream models in malignant tumor classification tasks with an AUC score of 93.91%.</p>"
    },
    {
      "id": "ca4f2baca3a0",
      "title": "HeterCSI: Channel-Adaptive Heterogeneous CSI Pretraining Framework for Generalized Wireless Foundation Models",
      "content": "arXiv:2601.18200v1 Announce Type: cross  Abstract: Wireless foundation models promise transformative capabilities for channel state information (CSI) processing across diverse 6G network applications, yet face fundamental challenges due to the inherent dual heterogeneity of CSI across both scale and scenario dimensions. However, current pretraining approaches either constrain inputs to fixed dimensions or isolate training by scale, limiting the generalization and scalability of wireless foundation models. In this paper, we propose HeterCSI, a channel-adaptive pretraining framework that reconciles training efficiency with robust cross-scenario generalization via a new understanding of gradient dynamics in heterogeneous CSI pretraining. Our key insight reveals that CSI scale heterogeneity primarily causes destructive gradient interference, while scenario diversity actually promotes constructive gradient alignment when properly managed. Specifically, we formulate heterogeneous CSI batch construction as a partitioning optimization problem that minimizes zero-padding overhead while preserving scenario diversity. To solve this, we develop a scale-aware adaptive batching strategy that aligns CSI samples of similar scales, and design a double-masking mechanism to isolate valid signals from padding artifacts. Extensive experiments on 12 datasets demonstrate that HeterCSI establishes a generalized foundation model without scenario-specific finetuning, achieving superior average performance over full-shot baselines. Compared to the state-of-the-art zero-shot benchmark WiFo, it reduces NMSE by 7.19 dB, 4.08 dB, and 5.27 dB for CSI reconstruction, time-domain, and frequency-domain prediction, respectively. The proposed HeterCSI framework also reduces training latency by 53% compared to existing approaches while improving generalization performance by 1.53 dB on average.",
      "url": "http://arxiv.org/abs/2601.18200",
      "author": "Chenyu Zhang, Xinchen Lyu, Chenshan Ren, Shuhan Liu, Qimei Cui, Xiaofeng Tao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes HeterCSI framework for channel-adaptive pretraining of wireless foundation models, addressing heterogeneity across scale and scenario dimensions in CSI processing for 6G networks.",
      "importance_score": 45,
      "reasoning": "Specialized wireless communications research. Novel foundation model approach for CSI but limited broader AI relevance.",
      "themes": [
        "Wireless Communications",
        "Foundation Models",
        "6G Networks"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes HeterCSI framework for channel-adaptive pretraining of wireless foundation models, addressing heterogeneity across scale and scenario dimensions in CSI processing for 6G networks.</p>",
      "content_html": "<p>arXiv:2601.18200v1 Announce Type: cross  Abstract: Wireless foundation models promise transformative capabilities for channel state information (CSI) processing across diverse 6G network applications, yet face fundamental challenges due to the inherent dual heterogeneity of CSI across both scale and scenario dimensions. However, current pretraining approaches either constrain inputs to fixed dimensions or isolate training by scale, limiting the generalization and scalability of wireless foundation models. In this paper, we propose HeterCSI, a channel-adaptive pretraining framework that reconciles training efficiency with robust cross-scenario generalization via a new understanding of gradient dynamics in heterogeneous CSI pretraining. Our key insight reveals that CSI scale heterogeneity primarily causes destructive gradient interference, while scenario diversity actually promotes constructive gradient alignment when properly managed. Specifically, we formulate heterogeneous CSI batch construction as a partitioning optimization problem that minimizes zero-padding overhead while preserving scenario diversity. To solve this, we develop a scale-aware adaptive batching strategy that aligns CSI samples of similar scales, and design a double-masking mechanism to isolate valid signals from padding artifacts. Extensive experiments on 12 datasets demonstrate that HeterCSI establishes a generalized foundation model without scenario-specific finetuning, achieving superior average performance over full-shot baselines. Compared to the state-of-the-art zero-shot benchmark WiFo, it reduces NMSE by 7.19 dB, 4.08 dB, and 5.27 dB for CSI reconstruction, time-domain, and frequency-domain prediction, respectively. The proposed HeterCSI framework also reduces training latency by 53% compared to existing approaches while improving generalization performance by 1.53 dB on average.</p>"
    },
    {
      "id": "be68d6192564",
      "title": "Co-PLNet: A Collaborative Point-Line Network for Prompt-Guided Wireframe Parsing",
      "content": "arXiv:2601.18252v1 Announce Type: cross  Abstract: Wireframe parsing aims to recover line segments and their junctions to form a structured geometric representation useful for downstream tasks such as Simultaneous Localization and Mapping (SLAM). Existing methods predict lines and junctions separately and reconcile them post-hoc, causing mismatches and reduced robustness. We present Co-PLNet, a point-line collaborative framework that exchanges spatial cues between the two tasks, where early detections are converted into spatial prompts via a Point-Line Prompt Encoder (PLP-Encoder), which encodes geometric attributes into compact and spatially aligned maps. A Cross-Guidance Line Decoder (CGL-Decoder) then refines predictions with sparse attention conditioned on complementary prompts, enforcing point-line consistency and efficiency. Experiments on Wireframe and YorkUrban show consistent improvements in accuracy and robustness, together with favorable real-time efficiency, demonstrating our effectiveness for structured geometry perception.",
      "url": "http://arxiv.org/abs/2601.18252",
      "author": "Chao Wang, Xuanying Li, Cheng Dai, Jinglei Feng, Yuxiang Luo, Yuqi Ouyang, Hao Qin",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents Co-PLNet for wireframe parsing that collaboratively exchanges spatial cues between line and junction detection via Point-Line Prompt Encoder and Cross-Guidance Line Decoder.",
      "importance_score": 45,
      "reasoning": "Technical improvement for specific computer vision task (wireframe parsing for SLAM). Limited broader impact.",
      "themes": [
        "Computer Vision",
        "SLAM",
        "Geometric Understanding"
      ],
      "continuation": null,
      "summary_html": "<p>Presents Co-PLNet for wireframe parsing that collaboratively exchanges spatial cues between line and junction detection via Point-Line Prompt Encoder and Cross-Guidance Line Decoder.</p>",
      "content_html": "<p>arXiv:2601.18252v1 Announce Type: cross  Abstract: Wireframe parsing aims to recover line segments and their junctions to form a structured geometric representation useful for downstream tasks such as Simultaneous Localization and Mapping (SLAM). Existing methods predict lines and junctions separately and reconcile them post-hoc, causing mismatches and reduced robustness. We present Co-PLNet, a point-line collaborative framework that exchanges spatial cues between the two tasks, where early detections are converted into spatial prompts via a Point-Line Prompt Encoder (PLP-Encoder), which encodes geometric attributes into compact and spatially aligned maps. A Cross-Guidance Line Decoder (CGL-Decoder) then refines predictions with sparse attention conditioned on complementary prompts, enforcing point-line consistency and efficiency. Experiments on Wireframe and YorkUrban show consistent improvements in accuracy and robustness, together with favorable real-time efficiency, demonstrating our effectiveness for structured geometry perception.</p>"
    },
    {
      "id": "ba9f3b77fdf7",
      "title": "Analytic Incremental Learning For Sound Source Localization With Imbalance Rectification",
      "content": "arXiv:2601.18335v1 Announce Type: cross  Abstract: Sound source localization (SSL) demonstrates remarkable results in controlled settings but struggles in real-world deployment due to dual imbalance challenges: intra-task imbalance arising from long-tailed direction-of-arrival (DoA) distributions, and inter-task imbalance induced by cross-task skews and overlaps. These often lead to catastrophic forgetting, significantly degrading the localization accuracy. To mitigate these issues, we propose a unified framework with two key innovations. Specifically, we design a GCC-PHAT-based data augmentation (GDA) method that leverages peak characteristics to alleviate intra-task distribution skews. We also propose an Analytic dynamic imbalance rectifier (ADIR) with task-adaption regularization, which enables analytic updates that adapt to inter-task dynamics. On the SSLR benchmark, our proposal achieves state-of-the-art (SoTA) results of 89.0% accuracy, 5.3{\\deg} mean absolute error, and 1.6 backward transfer, demonstrating robustness to evolving imbalances without exemplar storage.",
      "url": "http://arxiv.org/abs/2601.18335",
      "author": "Zexia Fan, Yu Chen, Qiquan Zhang, Kainan Chen, Xinyuan Qian",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.SD"
      ],
      "summary": "Proposes unified framework for sound source localization addressing intra-task (long-tailed DoA) and inter-task imbalance using GCC-PHAT augmentation and analytic dynamic imbalance rectifier.",
      "importance_score": 45,
      "reasoning": "Specialized audio processing contribution. Novel approach to distribution imbalance but limited broader impact.",
      "themes": [
        "Audio Processing",
        "Sound Localization",
        "Incremental Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes unified framework for sound source localization addressing intra-task (long-tailed DoA) and inter-task imbalance using GCC-PHAT augmentation and analytic dynamic imbalance rectifier.</p>",
      "content_html": "<p>arXiv:2601.18335v1 Announce Type: cross  Abstract: Sound source localization (SSL) demonstrates remarkable results in controlled settings but struggles in real-world deployment due to dual imbalance challenges: intra-task imbalance arising from long-tailed direction-of-arrival (DoA) distributions, and inter-task imbalance induced by cross-task skews and overlaps. These often lead to catastrophic forgetting, significantly degrading the localization accuracy. To mitigate these issues, we propose a unified framework with two key innovations. Specifically, we design a GCC-PHAT-based data augmentation (GDA) method that leverages peak characteristics to alleviate intra-task distribution skews. We also propose an Analytic dynamic imbalance rectifier (ADIR) with task-adaption regularization, which enables analytic updates that adapt to inter-task dynamics. On the SSLR benchmark, our proposal achieves state-of-the-art (SoTA) results of 89.0% accuracy, 5.3{\\deg} mean absolute error, and 1.6 backward transfer, demonstrating robustness to evolving imbalances without exemplar storage.</p>"
    },
    {
      "id": "457e540747eb",
      "title": "Scalable Transit Delay Prediction at City Scale: A Systematic Approach with Multi-Resolution Feature Engineering and Deep Learning",
      "content": "arXiv:2601.18521v1 Announce Type: cross  Abstract: Urban bus transit agencies need reliable, network-wide delay predictions to provide accurate arrival information to passengers and support real-time operational control. Accurate predictions help passengers plan their trips, reduce waiting time, and allow operations staff to adjust headways, dispatch extra vehicles, and manage disruptions. Although real-time feeds such as GTFS-Realtime (GTFS-RT) are now widely available, most existing delay prediction systems handle only a few routes, depend on hand-crafted features, and offer little guidance on how to design a scalable, reusable architecture.   We present a city-scale prediction pipeline that combines multi-resolution feature engineering, dimensionality reduction, and deep learning. The framework generates 1,683 spatiotemporal features by exploring 23 aggregation combinations over H3 cells, routes, segments, and temporal patterns, and compresses them into 83 components using Adaptive PCA while preserving 95% of the variance. To avoid the \"giant cluster\" problem that occurs when dense urban areas fall into a single H3 region, we introduce a hybrid H3+topology clustering method that yields 12 balanced route clusters (coefficient of variation 0.608) and enables efficient distributed training.   We compare five model architectures on six months of bus operations from the Soci\\'et\\'e de transport de Montr\\'eal (STM) network in Montr\\'eal. A global LSTM with cluster-aware features achieves the best trade-off between accuracy and efficiency, outperforming transformer models by 18 to 52% while using 275 times fewer parameters. We also report multi-level evaluation at the elementary segment, segment, and trip level with walk-forward validation and latency analysis, showing that the proposed pipeline is suitable for real-time, city-scale deployment and can be reused for other networks with limited adaptation.",
      "url": "http://arxiv.org/abs/2601.18521",
      "author": "Emna Boudabbous, Mohamed Karaa, Lokman Sboui, Julio Montecinos, Omar Alam",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Presents city-scale transit delay prediction pipeline combining multi-resolution feature engineering, dimensionality reduction, and deep learning for scalable real-time bus arrival prediction.",
      "importance_score": 45,
      "reasoning": "Applied ML for transportation. Practical engineering contribution but limited methodological novelty.",
      "themes": [
        "Transportation",
        "Time Series",
        "Applied ML"
      ],
      "continuation": null,
      "summary_html": "<p>Presents city-scale transit delay prediction pipeline combining multi-resolution feature engineering, dimensionality reduction, and deep learning for scalable real-time bus arrival prediction.</p>",
      "content_html": "<p>arXiv:2601.18521v1 Announce Type: cross  Abstract: Urban bus transit agencies need reliable, network-wide delay predictions to provide accurate arrival information to passengers and support real-time operational control. Accurate predictions help passengers plan their trips, reduce waiting time, and allow operations staff to adjust headways, dispatch extra vehicles, and manage disruptions. Although real-time feeds such as GTFS-Realtime (GTFS-RT) are now widely available, most existing delay prediction systems handle only a few routes, depend on hand-crafted features, and offer little guidance on how to design a scalable, reusable architecture.   We present a city-scale prediction pipeline that combines multi-resolution feature engineering, dimensionality reduction, and deep learning. The framework generates 1,683 spatiotemporal features by exploring 23 aggregation combinations over H3 cells, routes, segments, and temporal patterns, and compresses them into 83 components using Adaptive PCA while preserving 95% of the variance. To avoid the \"giant cluster\" problem that occurs when dense urban areas fall into a single H3 region, we introduce a hybrid H3+topology clustering method that yields 12 balanced route clusters (coefficient of variation 0.608) and enables efficient distributed training.   We compare five model architectures on six months of bus operations from the Soci\\'et\\'e de transport de Montr\\'eal (STM) network in Montr\\'eal. A global LSTM with cluster-aware features achieves the best trade-off between accuracy and efficiency, outperforming transformer models by 18 to 52% while using 275 times fewer parameters. We also report multi-level evaluation at the elementary segment, segment, and trip level with walk-forward validation and latency analysis, showing that the proposed pipeline is suitable for real-time, city-scale deployment and can be reused for other networks with limited adaptation.</p>"
    },
    {
      "id": "018e73a1368c",
      "title": "Neural Multi-Speaker Voice Cloning for Nepali in Low-Resource Settings",
      "content": "arXiv:2601.18694v1 Announce Type: cross  Abstract: This research presents a few-shot voice cloning system for Nepali speakers, designed to synthesize speech in a specific speaker's voice from Devanagari text using minimal data. Voice cloning in Nepali remains largely unexplored due to its low-resource nature. To address this, we constructed separate datasets: untranscribed audio for training a speaker encoder and paired text-audio data for training a Tacotron2-based synthesizer. The speaker encoder, optimized with Generative End2End loss, generates embeddings that capture the speaker's vocal identity, validated through Uniform Manifold Approximation and Projection (UMAP) for dimension reduction visualizations. These embeddings are fused with Tacotron2's text embeddings to produce mel-spectrograms, which are then converted into audio using a WaveRNN vocoder. Audio data were collected from various sources, including self-recordings, and underwent thorough preprocessing for quality and alignment. Training was performed using mel and gate loss functions under multiple hyperparameter settings. The system effectively clones speaker characteristics even for unseen voices, demonstrating the feasibility of few-shot voice cloning for the Nepali language and establishing a foundation for personalized speech synthesis in low-resource scenarios.",
      "url": "http://arxiv.org/abs/2601.18694",
      "author": "Aayush M. Shrestha, Aditya Bajracharya, Projan Shakya, Dinesh B. Kshatri",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.SD"
      ],
      "summary": "Presents few-shot voice cloning system for Nepali speakers using speaker encoder with GE2E loss and Tacotron2, addressing low-resource TTS for underrepresented language.",
      "importance_score": 45,
      "reasoning": "Valuable contribution to low-resource TTS but methodology not novel - applies existing techniques to new language.",
      "themes": [
        "Text-to-Speech",
        "Low-Resource Languages",
        "Voice Cloning"
      ],
      "continuation": null,
      "summary_html": "<p>Presents few-shot voice cloning system for Nepali speakers using speaker encoder with GE2E loss and Tacotron2, addressing low-resource TTS for underrepresented language.</p>",
      "content_html": "<p>arXiv:2601.18694v1 Announce Type: cross  Abstract: This research presents a few-shot voice cloning system for Nepali speakers, designed to synthesize speech in a specific speaker's voice from Devanagari text using minimal data. Voice cloning in Nepali remains largely unexplored due to its low-resource nature. To address this, we constructed separate datasets: untranscribed audio for training a speaker encoder and paired text-audio data for training a Tacotron2-based synthesizer. The speaker encoder, optimized with Generative End2End loss, generates embeddings that capture the speaker's vocal identity, validated through Uniform Manifold Approximation and Projection (UMAP) for dimension reduction visualizations. These embeddings are fused with Tacotron2's text embeddings to produce mel-spectrograms, which are then converted into audio using a WaveRNN vocoder. Audio data were collected from various sources, including self-recordings, and underwent thorough preprocessing for quality and alignment. Training was performed using mel and gate loss functions under multiple hyperparameter settings. The system effectively clones speaker characteristics even for unseen voices, demonstrating the feasibility of few-shot voice cloning for the Nepali language and establishing a foundation for personalized speech synthesis in low-resource scenarios.</p>"
    },
    {
      "id": "c2b9555d22ca",
      "title": "Low Cost, High Efficiency: LiDAR Place Recognition in Vineyards with Matryoshka Representation Learning",
      "content": "arXiv:2601.18714v1 Announce Type: cross  Abstract: Localization in agricultural environments is challenging due to their unstructured nature and lack of distinctive landmarks. Although agricultural settings have been studied in the context of object classification and segmentation, the place recognition task for mobile robots is not trivial in the current state of the art. In this study, we propose MinkUNeXt-VINE, a lightweight, deep-learning-based method that surpasses state-of-the-art methods in vineyard environments thanks to its pre-processing and Matryoshka Representation Learning multi-loss approach. Our method prioritizes enhanced performance with low-cost, sparse LiDAR inputs and lower-dimensionality outputs to ensure high efficiency in real-time scenarios. Additionally, we present a comprehensive ablation study of the results on various evaluation cases and two extensive long-term vineyard datasets employing different LiDAR sensors. The results demonstrate the efficiency of the trade-off output produced by this approach, as well as its robust performance on low-cost and low-resolution input data. The code is publicly available for reproduction.",
      "url": "http://arxiv.org/abs/2601.18714",
      "author": "Judith Vilella-Cantos, Mauro Martini, Marcello Chiaberge, M\\'onica Ballesta, David Valiente",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes MinkUNeXt-VINE for LiDAR place recognition in vineyard environments using Matryoshka Representation Learning, achieving state-of-the-art with sparse LiDAR inputs.",
      "importance_score": 45,
      "reasoning": "Specialized agricultural robotics contribution. Novel application of Matryoshka learning but narrow domain.",
      "themes": [
        "Agricultural Robotics",
        "Place Recognition",
        "LiDAR"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes MinkUNeXt-VINE for LiDAR place recognition in vineyard environments using Matryoshka Representation Learning, achieving state-of-the-art with sparse LiDAR inputs.</p>",
      "content_html": "<p>arXiv:2601.18714v1 Announce Type: cross  Abstract: Localization in agricultural environments is challenging due to their unstructured nature and lack of distinctive landmarks. Although agricultural settings have been studied in the context of object classification and segmentation, the place recognition task for mobile robots is not trivial in the current state of the art. In this study, we propose MinkUNeXt-VINE, a lightweight, deep-learning-based method that surpasses state-of-the-art methods in vineyard environments thanks to its pre-processing and Matryoshka Representation Learning multi-loss approach. Our method prioritizes enhanced performance with low-cost, sparse LiDAR inputs and lower-dimensionality outputs to ensure high efficiency in real-time scenarios. Additionally, we present a comprehensive ablation study of the results on various evaluation cases and two extensive long-term vineyard datasets employing different LiDAR sensors. The results demonstrate the efficiency of the trade-off output produced by this approach, as well as its robust performance on low-cost and low-resolution input data. The code is publicly available for reproduction.</p>"
    },
    {
      "id": "c96851203f62",
      "title": "Student Mental Health Screening via Fitbit Data Collected During the COVID-19 Pandemic",
      "content": "arXiv:2601.16324v1 Announce Type: new  Abstract: College students experience many stressors, resulting in high levels of anxiety and depression. Wearable technology provides unobtrusive sensor data that can be used for the early detection of mental illness. However, current research is limited concerning the variety of psychological instruments administered, physiological modalities, and time series parameters. In this research, we collect the Student Mental and Environmental Health (StudentMEH) Fitbit dataset from students at our institution during the pandemic. We provide a comprehensive assessment of the ability of predictive machine learning models to screen for depression, anxiety, and stress using different Fitbit modalities. Our findings indicate potential in physiological modalities such as heart rate and sleep to screen for mental illness with the F1 scores as high as 0.79 for anxiety, the former modality reaching 0.77 for stress screening, and the latter modality achieving 0.78 for depression. This research highlights the potential of wearable devices to support continuous mental health monitoring, the importance of identifying best data aggregation levels and appropriate modalities for screening for different mental ailments.",
      "url": "http://arxiv.org/abs/2601.16324",
      "author": "Rebecca Lopez, Avantika Shrestha, ML Tlachac, Kevin Hickey, Xingtong Guo, Shichao Liu, Elke Rundensteiner",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Evaluates machine learning models for mental health screening (depression, anxiety, stress) using Fitbit data from students during COVID-19 pandemic, comparing different physiological modalities.",
      "importance_score": 45,
      "reasoning": "Applied ML for mental health with real pandemic-era data. Useful findings on physiological modality effectiveness but limited novelty.",
      "themes": [
        "Mental Health",
        "Wearables",
        "Healthcare ML"
      ],
      "continuation": null,
      "summary_html": "<p>Evaluates machine learning models for mental health screening (depression, anxiety, stress) using Fitbit data from students during COVID-19 pandemic, comparing different physiological modalities.</p>",
      "content_html": "<p>arXiv:2601.16324v1 Announce Type: new  Abstract: College students experience many stressors, resulting in high levels of anxiety and depression. Wearable technology provides unobtrusive sensor data that can be used for the early detection of mental illness. However, current research is limited concerning the variety of psychological instruments administered, physiological modalities, and time series parameters. In this research, we collect the Student Mental and Environmental Health (StudentMEH) Fitbit dataset from students at our institution during the pandemic. We provide a comprehensive assessment of the ability of predictive machine learning models to screen for depression, anxiety, and stress using different Fitbit modalities. Our findings indicate potential in physiological modalities such as heart rate and sleep to screen for mental illness with the F1 scores as high as 0.79 for anxiety, the former modality reaching 0.77 for stress screening, and the latter modality achieving 0.78 for depression. This research highlights the potential of wearable devices to support continuous mental health monitoring, the importance of identifying best data aggregation levels and appropriate modalities for screening for different mental ailments.</p>"
    },
    {
      "id": "fad530be9330",
      "title": "Analyzing Neural Network Information Flow Using Differential Geometry",
      "content": "arXiv:2601.16366v1 Announce Type: new  Abstract: This paper provides a fresh view of the neural network (NN) data flow problem, i.e., identifying the NN connections that are most important for the performance of the full model, through the lens of graph theory. Understanding the NN data flow provides a tool for symbolic NN analysis, e.g.,~robustness analysis or model repair. Unlike the standard approach to NN data flow analysis, which is based on information theory, we employ the notion of graph curvature, specifically Ollivier-Ricci curvature (ORC). The ORC has been successfully used to identify important graph edges in various domains such as road traffic analysis, biological and social networks. In particular, edges with negative ORC are considered bottlenecks and as such are critical to the graph's overall connectivity, whereas positive-ORC edges are not essential. We use this intuition for the case of NNs as well: we 1)~construct a graph induced by the NN structure and introduce the notion of neural curvature (NC) based on the ORC; 2)~calculate curvatures based on activation patterns for a set of input examples; 3)~aim to demonstrate that NC can indeed be used to rank edges according to their importance for the overall NN functionality. We evaluate our method through pruning experiments and show that removing negative-ORC edges quickly degrades the overall NN performance, whereas positive-ORC edges have little impact. The proposed method is evaluated on a variety of models trained on three image datasets, namely MNIST, CIFAR-10 and CIFAR-100. The results indicate that our method can identify a larger number of unimportant edges as compared to state-of-the-art pruning methods.",
      "url": "http://arxiv.org/abs/2601.16366",
      "author": "Shuhang Tan, Jayson Sia, Paul Bogdan, Radoslav Ivanov",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Uses Ollivier-Ricci curvature from differential geometry to identify critical neural network connections, treating NNs as graphs. Negative curvature edges are identified as bottlenecks important for model performance.",
      "importance_score": 45,
      "reasoning": "Novel interdisciplinary approach connecting graph theory to NN analysis; could enable better robustness analysis and model repair.",
      "themes": [
        "Neural Network Analysis",
        "Interpretability",
        "Graph Theory"
      ],
      "continuation": null,
      "summary_html": "<p>Uses Ollivier-Ricci curvature from differential geometry to identify critical neural network connections, treating NNs as graphs. Negative curvature edges are identified as bottlenecks important for model performance.</p>",
      "content_html": "<p>arXiv:2601.16366v1 Announce Type: new  Abstract: This paper provides a fresh view of the neural network (NN) data flow problem, i.e., identifying the NN connections that are most important for the performance of the full model, through the lens of graph theory. Understanding the NN data flow provides a tool for symbolic NN analysis, e.g.,~robustness analysis or model repair. Unlike the standard approach to NN data flow analysis, which is based on information theory, we employ the notion of graph curvature, specifically Ollivier-Ricci curvature (ORC). The ORC has been successfully used to identify important graph edges in various domains such as road traffic analysis, biological and social networks. In particular, edges with negative ORC are considered bottlenecks and as such are critical to the graph's overall connectivity, whereas positive-ORC edges are not essential. We use this intuition for the case of NNs as well: we 1)~construct a graph induced by the NN structure and introduce the notion of neural curvature (NC) based on the ORC; 2)~calculate curvatures based on activation patterns for a set of input examples; 3)~aim to demonstrate that NC can indeed be used to rank edges according to their importance for the overall NN functionality. We evaluate our method through pruning experiments and show that removing negative-ORC edges quickly degrades the overall NN performance, whereas positive-ORC edges have little impact. The proposed method is evaluated on a variety of models trained on three image datasets, namely MNIST, CIFAR-10 and CIFAR-100. The results indicate that our method can identify a larger number of unimportant edges as compared to state-of-the-art pruning methods.</p>"
    },
    {
      "id": "674529985c55",
      "title": "DANCE: Dynamic, Available, Neighbor-gated Condensation for Federated Text-Attributed Graphs",
      "content": "arXiv:2601.16519v1 Announce Type: new  Abstract: Federated graph learning (FGL) enables collaborative training on graph data across multiple clients. With the rise of large language models (LLMs), textual attributes in FGL graphs are gaining attention. Text-attributed graph federated learning (TAG-FGL) improves FGL by explicitly leveraging LLMs to process and integrate these textual features. However, current TAG-FGL methods face three main challenges: \\textbf{(1) Overhead.} LLMs for processing long texts incur high token and computation costs. To make TAG-FGL practical, we introduce graph condensation (GC) to reduce computation load, but this choice also brings new issues. \\textbf{(2) Suboptimal.} To reduce LLM overhead, we introduce GC into TAG-FGL by compressing multi-hop texts/neighborhoods into a condensed core with fixed LLM surrogates. However, this one-shot condensation is often not client-adaptive, leading to suboptimal performance. \\textbf{(3) Interpretability.} LLM-based condensation further introduces a black-box bottleneck: summaries lack faithful attribution and clear grounding to specific source spans, making local inspection and auditing difficult. To address the above issues, we propose \\textbf{DANCE}, a new TAG-FGL paradigm with GC. To improve \\textbf{suboptimal} performance, DANCE performs round-wise, model-in-the-loop condensation refresh using the latest global model. To enhance \\textbf{interpretability}, DANCE preserves provenance by storing locally inspectable evidence packs that trace predictions to selected neighbors and source text spans. Across 8 TAG datasets, DANCE improves accuracy by \\textbf{2.33\\%} at an \\textbf{8\\%} condensation ratio, with \\textbf{33.42\\%} fewer tokens than baselines.",
      "url": "http://arxiv.org/abs/2601.16519",
      "author": "Zekai Chen, Haodong Lu, Xunkai Li, Henan Sun, Jia Li, Hongchao Qin, Rong-Hua Li, Guoren Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes DANCE for federated learning on text-attributed graphs, using graph condensation to reduce LLM computation costs. Addresses overhead, suboptimality, and instability challenges in TAG-FGL.",
      "importance_score": 45,
      "reasoning": "Solid work combining multiple recent trends (FGL, LLMs, graph condensation); practical but incremental.",
      "themes": [
        "Federated Learning",
        "Graph Neural Networks",
        "Large Language Models",
        "Graph Condensation"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes DANCE for federated learning on text-attributed graphs, using graph condensation to reduce LLM computation costs. Addresses overhead, suboptimality, and instability challenges in TAG-FGL.</p>",
      "content_html": "<p>arXiv:2601.16519v1 Announce Type: new  Abstract: Federated graph learning (FGL) enables collaborative training on graph data across multiple clients. With the rise of large language models (LLMs), textual attributes in FGL graphs are gaining attention. Text-attributed graph federated learning (TAG-FGL) improves FGL by explicitly leveraging LLMs to process and integrate these textual features. However, current TAG-FGL methods face three main challenges: \\textbf{(1) Overhead.} LLMs for processing long texts incur high token and computation costs. To make TAG-FGL practical, we introduce graph condensation (GC) to reduce computation load, but this choice also brings new issues. \\textbf{(2) Suboptimal.} To reduce LLM overhead, we introduce GC into TAG-FGL by compressing multi-hop texts/neighborhoods into a condensed core with fixed LLM surrogates. However, this one-shot condensation is often not client-adaptive, leading to suboptimal performance. \\textbf{(3) Interpretability.} LLM-based condensation further introduces a black-box bottleneck: summaries lack faithful attribution and clear grounding to specific source spans, making local inspection and auditing difficult. To address the above issues, we propose \\textbf{DANCE}, a new TAG-FGL paradigm with GC. To improve \\textbf{suboptimal} performance, DANCE performs round-wise, model-in-the-loop condensation refresh using the latest global model. To enhance \\textbf{interpretability}, DANCE preserves provenance by storing locally inspectable evidence packs that trace predictions to selected neighbors and source text spans. Across 8 TAG datasets, DANCE improves accuracy by \\textbf{2.33\\%} at an \\textbf{8\\%} condensation ratio, with \\textbf{33.42\\%} fewer tokens than baselines.</p>"
    },
    {
      "id": "d84ca6481540",
      "title": "Understanding and Improving UMAP with Geometric and Topological Priors: The JORC-UMAP Algorithm",
      "content": "arXiv:2601.16552v1 Announce Type: new  Abstract: Nonlinear dimensionality reduction techniques, particularly UMAP, are widely used for visualizing high-dimensional data. However, UMAP's local Euclidean distance assumption often fails to capture intrinsic manifold geometry, leading to topological tearing and structural collapse. We identify UMAP's sensitivity to the k-nearest neighbor graph as a key cause. To address this, we introduce Ollivier-Ricci curvature as a geometric prior, reinforcing edges at geometric bottlenecks and reducing redundant links. Since curvature estimation is noise-sensitive, we also incorporate a topological prior using Jaccard similarity to ensure neighborhood consistency. The resulting method, JORC-UMAP, better distinguishes true manifold structure from spurious connections. Experiments on synthetic and real-world datasets show that JORC-UMAP reduces tearing and collapse more effectively than standard UMAP and other DR methods, as measured by SVM accuracy and triplet preservation scores, while maintaining computational efficiency. This work offers a geometry-aware enhancement to UMAP for more faithful data visualization.",
      "url": "http://arxiv.org/abs/2601.16552",
      "author": "Xiaobin Li, Run Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Improves UMAP by introducing Ollivier-Ricci curvature as geometric prior and Jaccard similarity as topological prior. Addresses UMAP's sensitivity to k-NN graph construction that causes topological tearing.",
      "importance_score": 45,
      "reasoning": "Useful improvement to widely-used visualization method; principled approach addressing known limitations.",
      "themes": [
        "Dimensionality Reduction",
        "UMAP",
        "Manifold Learning",
        "Visualization"
      ],
      "continuation": null,
      "summary_html": "<p>Improves UMAP by introducing Ollivier-Ricci curvature as geometric prior and Jaccard similarity as topological prior. Addresses UMAP's sensitivity to k-NN graph construction that causes topological tearing.</p>",
      "content_html": "<p>arXiv:2601.16552v1 Announce Type: new  Abstract: Nonlinear dimensionality reduction techniques, particularly UMAP, are widely used for visualizing high-dimensional data. However, UMAP's local Euclidean distance assumption often fails to capture intrinsic manifold geometry, leading to topological tearing and structural collapse. We identify UMAP's sensitivity to the k-nearest neighbor graph as a key cause. To address this, we introduce Ollivier-Ricci curvature as a geometric prior, reinforcing edges at geometric bottlenecks and reducing redundant links. Since curvature estimation is noise-sensitive, we also incorporate a topological prior using Jaccard similarity to ensure neighborhood consistency. The resulting method, JORC-UMAP, better distinguishes true manifold structure from spurious connections. Experiments on synthetic and real-world datasets show that JORC-UMAP reduces tearing and collapse more effectively than standard UMAP and other DR methods, as measured by SVM accuracy and triplet preservation scores, while maintaining computational efficiency. This work offers a geometry-aware enhancement to UMAP for more faithful data visualization.</p>"
    },
    {
      "id": "99f70544eb9a",
      "title": "Dynamic Expert-Guided Model Averaging for Causal Discovery",
      "content": "arXiv:2601.16715v1 Announce Type: new  Abstract: Understanding causal relationships is critical for healthcare. Accurate causal models provide a means to enhance the interpretability of predictive models, and furthermore a basis for counterfactual and interventional reasoning and the estimation of treatment effects. However, would-be practitioners of causal discovery face a dizzying array of algorithms without a clear best choice. This abundance of competitive algorithms makes ensembling a natural choice for practical applications. At the same time, real-world use cases frequently face challenges that violate the assumptions of common causal discovery algorithms, forcing heavy reliance on expert knowledge. Inspired by recent work on dynamically requested expert knowledge and LLMs as experts, we present a flexible model averaging method leveraging dynamically requested expert knowledge to ensemble a diverse array of causal discovery algorithms. Experiments demonstrate the efficacy of our method with imperfect experts such as LLMs on both clean and noisy data. We also analyze the impact of different degrees of expert correctness and assess the capabilities of LLMs for clinical causal discovery, providing valuable insights for practitioners.",
      "url": "http://arxiv.org/abs/2601.16715",
      "author": "Adrick Tench, Thomas Demeester",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes ensemble method for causal discovery that dynamically combines multiple algorithms guided by expert knowledge. Inspired by using LLMs as expert stand-ins for causal knowledge.",
      "importance_score": 45,
      "reasoning": "Practical approach to causal discovery; addresses real challenge of algorithm selection but limited novelty.",
      "themes": [
        "Causal Discovery",
        "Ensemble Methods",
        "Healthcare AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes ensemble method for causal discovery that dynamically combines multiple algorithms guided by expert knowledge. Inspired by using LLMs as expert stand-ins for causal knowledge.</p>",
      "content_html": "<p>arXiv:2601.16715v1 Announce Type: new  Abstract: Understanding causal relationships is critical for healthcare. Accurate causal models provide a means to enhance the interpretability of predictive models, and furthermore a basis for counterfactual and interventional reasoning and the estimation of treatment effects. However, would-be practitioners of causal discovery face a dizzying array of algorithms without a clear best choice. This abundance of competitive algorithms makes ensembling a natural choice for practical applications. At the same time, real-world use cases frequently face challenges that violate the assumptions of common causal discovery algorithms, forcing heavy reliance on expert knowledge. Inspired by recent work on dynamically requested expert knowledge and LLMs as experts, we present a flexible model averaging method leveraging dynamically requested expert knowledge to ensemble a diverse array of causal discovery algorithms. Experiments demonstrate the efficacy of our method with imperfect experts such as LLMs on both clean and noisy data. We also analyze the impact of different degrees of expert correctness and assess the capabilities of LLMs for clinical causal discovery, providing valuable insights for practitioners.</p>"
    },
    {
      "id": "22b15b2d7535",
      "title": "Multigrade Neural Network Approximation",
      "content": "arXiv:2601.16884v1 Announce Type: new  Abstract: We study multigrade deep learning (MGDL) as a principled framework for structured error refinement in deep neural networks. While the approximation power of neural networks is now relatively well understood, training very deep architectures remains challenging due to highly non-convex and often ill-conditioned optimization landscapes. In contrast, for relatively shallow networks, most notably one-hidden-layer $\\texttt{ReLU}$ models, training admits convex reformulations with global guarantees, motivating learning paradigms that improve stability while scaling to depth. MGDL builds upon this insight by training deep networks grade by grade: previously learned grades are frozen, and each new residual block is trained solely to reduce the remaining approximation error, yielding an interpretable and stable hierarchical refinement process. We develop an operator-theoretic foundation for MGDL and prove that, for any continuous target function, there exists a fixed-width multigrade $\\texttt{ReLU}$ scheme whose residuals decrease strictly across grades and converge uniformly to zero. To the best of our knowledge, this work provides the first rigorous theoretical guarantee that grade-wise training yields provable vanishing approximation error in deep networks. Numerical experiments further illustrate the theoretical results.",
      "url": "http://arxiv.org/abs/2601.16884",
      "author": "Shijun Zhang, Zuowei Shen, Yuesheng Xu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Studies multigrade deep learning (MGDL) where deep networks are trained grade-by-grade with previously learned components frozen. Provides theoretical framework for structured error refinement.",
      "importance_score": 45,
      "reasoning": "Principled framework for training deep networks; good theoretical analysis but practical advantages unclear.",
      "themes": [
        "Deep Learning Theory",
        "Neural Network Training",
        "Approximation Theory"
      ],
      "continuation": null,
      "summary_html": "<p>Studies multigrade deep learning (MGDL) where deep networks are trained grade-by-grade with previously learned components frozen. Provides theoretical framework for structured error refinement.</p>",
      "content_html": "<p>arXiv:2601.16884v1 Announce Type: new  Abstract: We study multigrade deep learning (MGDL) as a principled framework for structured error refinement in deep neural networks. While the approximation power of neural networks is now relatively well understood, training very deep architectures remains challenging due to highly non-convex and often ill-conditioned optimization landscapes. In contrast, for relatively shallow networks, most notably one-hidden-layer $\\texttt{ReLU}$ models, training admits convex reformulations with global guarantees, motivating learning paradigms that improve stability while scaling to depth. MGDL builds upon this insight by training deep networks grade by grade: previously learned grades are frozen, and each new residual block is trained solely to reduce the remaining approximation error, yielding an interpretable and stable hierarchical refinement process. We develop an operator-theoretic foundation for MGDL and prove that, for any continuous target function, there exists a fixed-width multigrade $\\texttt{ReLU}$ scheme whose residuals decrease strictly across grades and converge uniformly to zero. To the best of our knowledge, this work provides the first rigorous theoretical guarantee that grade-wise training yields provable vanishing approximation error in deep networks. Numerical experiments further illustrate the theoretical results.</p>"
    },
    {
      "id": "7ba83748352c",
      "title": "The Trajectory Alignment Coefficient in Two Acts: From Reward Tuning to Reward Learning",
      "content": "arXiv:2601.16906v1 Announce Type: new  Abstract: The success of reinforcement learning (RL) is fundamentally tied to having a reward function that accurately reflects the task objective. Yet, designing reward functions is notoriously time-consuming and prone to misspecification. To address this issue, our first goal is to understand how to support RL practitioners in specifying appropriate weights for a reward function. We leverage the Trajectory Alignment Coefficient (TAC), a metric that evaluates how closely a reward function's induced preferences match those of a domain expert. To evaluate whether TAC provides effective support in practice, we conducted a human-subject study in which RL practitioners tuned reward weights for Lunar Lander. We found that providing TAC during reward tuning led participants to produce more performant reward functions and report lower cognitive workload relative to standard tuning without TAC. However, the study also underscored that manual reward design, even with TAC, remains labor-intensive. This limitation motivated our second goal: to learn a reward model that maximizes TAC directly. Specifically, we propose Soft-TAC, a differentiable approximation of TAC that can be used as a loss function to train reward models from human preference data. Validated in the racing simulator Gran Turismo 7, reward models trained using Soft-TAC successfully captured preference-specific objectives, resulting in policies with qualitatively more distinct behaviors than models trained with standard Cross-Entropy loss. This work demonstrates that TAC can serve as both a practical tool for guiding reward tuning and a reward learning objective in complex domains.",
      "url": "http://arxiv.org/abs/2601.16906",
      "author": "Calarina Muslimani, Yunshu Du, Kenta Kawamoto, Kaushik Subramanian, Peter Stone, Peter Wurman",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Studies Trajectory Alignment Coefficient (TAC) for reward function specification through human study on Lunar Lander. Shows TAC helps practitioners tune rewards, but TAC alone is insufficient for identifying optimal rewards.",
      "importance_score": 45,
      "reasoning": "Valuable human-subjects study on practical RL challenges; provides empirical insights on reward engineering.",
      "themes": [
        "Reinforcement Learning",
        "Reward Engineering",
        "Human-AI Interaction"
      ],
      "continuation": null,
      "summary_html": "<p>Studies Trajectory Alignment Coefficient (TAC) for reward function specification through human study on Lunar Lander. Shows TAC helps practitioners tune rewards, but TAC alone is insufficient for identifying optimal rewards.</p>",
      "content_html": "<p>arXiv:2601.16906v1 Announce Type: new  Abstract: The success of reinforcement learning (RL) is fundamentally tied to having a reward function that accurately reflects the task objective. Yet, designing reward functions is notoriously time-consuming and prone to misspecification. To address this issue, our first goal is to understand how to support RL practitioners in specifying appropriate weights for a reward function. We leverage the Trajectory Alignment Coefficient (TAC), a metric that evaluates how closely a reward function's induced preferences match those of a domain expert. To evaluate whether TAC provides effective support in practice, we conducted a human-subject study in which RL practitioners tuned reward weights for Lunar Lander. We found that providing TAC during reward tuning led participants to produce more performant reward functions and report lower cognitive workload relative to standard tuning without TAC. However, the study also underscored that manual reward design, even with TAC, remains labor-intensive. This limitation motivated our second goal: to learn a reward model that maximizes TAC directly. Specifically, we propose Soft-TAC, a differentiable approximation of TAC that can be used as a loss function to train reward models from human preference data. Validated in the racing simulator Gran Turismo 7, reward models trained using Soft-TAC successfully captured preference-specific objectives, resulting in policies with qualitatively more distinct behaviors than models trained with standard Cross-Entropy loss. This work demonstrates that TAC can serve as both a practical tool for guiding reward tuning and a reward learning objective in complex domains.</p>"
    },
    {
      "id": "125ddd506370",
      "title": "Test-Time Adaptation for Speech Emotion Recognition",
      "content": "arXiv:2601.16240v1 Announce Type: cross  Abstract: The practical utility of Speech Emotion Recognition (SER) systems is undermined by their fragility to domain shifts, such as speaker variability, the distinction between acted and naturalistic emotions, and cross-corpus variations. While domain adaptation and fine-tuning are widely studied, they require either source data or labelled target data, which are often unavailable or raise privacy concerns in SER. Test-time adaptation (TTA) bridges this gap by adapting models at inference using only unlabeled target data. Yet, having been predominantly designed for image classification and speech recognition, the efficacy of TTA for mitigating the unique domain shifts in SER has not been investigated. In this paper, we present the first systematic evaluation and comparison covering 11 TTA methods across three representative SER tasks. The results indicate that backpropagation-free TTA methods are the most promising. Conversely, entropy minimization and pseudo-labeling generally fail, as their core assumption of a single, confident ground-truth label is incompatible with the inherent ambiguity of emotional expression. Further, no single method universally excels, and its effectiveness is highly dependent on the distributional shifts and tasks.",
      "url": "http://arxiv.org/abs/2601.16240",
      "author": "Jiaheng Dong, Hong Jia, Ting Dang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "eess.AS"
      ],
      "summary": "First systematic investigation of test-time adaptation for speech emotion recognition. Evaluates TTA methods designed for images/speech recognition on SER-specific domain shifts like speaker variability.",
      "importance_score": 45,
      "reasoning": "Fills gap in SER research; systematic evaluation provides practical guidance for practitioners.",
      "themes": [
        "Speech Emotion Recognition",
        "Test-Time Adaptation",
        "Domain Adaptation"
      ],
      "continuation": null,
      "summary_html": "<p>First systematic investigation of test-time adaptation for speech emotion recognition. Evaluates TTA methods designed for images/speech recognition on SER-specific domain shifts like speaker variability.</p>",
      "content_html": "<p>arXiv:2601.16240v1 Announce Type: cross  Abstract: The practical utility of Speech Emotion Recognition (SER) systems is undermined by their fragility to domain shifts, such as speaker variability, the distinction between acted and naturalistic emotions, and cross-corpus variations. While domain adaptation and fine-tuning are widely studied, they require either source data or labelled target data, which are often unavailable or raise privacy concerns in SER. Test-time adaptation (TTA) bridges this gap by adapting models at inference using only unlabeled target data. Yet, having been predominantly designed for image classification and speech recognition, the efficacy of TTA for mitigating the unique domain shifts in SER has not been investigated. In this paper, we present the first systematic evaluation and comparison covering 11 TTA methods across three representative SER tasks. The results indicate that backpropagation-free TTA methods are the most promising. Conversely, entropy minimization and pseudo-labeling generally fail, as their core assumption of a single, confident ground-truth label is incompatible with the inherent ambiguity of emotional expression. Further, no single method universally excels, and its effectiveness is highly dependent on the distributional shifts and tasks.</p>"
    },
    {
      "id": "089b6b090c69",
      "title": "Experience with Single Domain Generalization in Real World Medical Imaging Deployments",
      "content": "arXiv:2601.16359v1 Announce Type: cross  Abstract: A desirable property of any deployed artificial intelligence is generalization across domains, i.e. data generation distribution under a specific acquisition condition. In medical imagining applications the most coveted property for effective deployment is Single Domain Generalization (SDG), which addresses the challenge of training a model on a single domain to ensure it generalizes well to unseen target domains. In multi-center studies, differences in scanners and imaging protocols introduce domain shifts that exacerbate variability in rare class characteristics. This paper presents our experience on SDG in real life deployment for two exemplary medical imaging case studies on seizure onset zone detection using fMRI data, and stress electrocardiogram based coronary artery detection. Utilizing the commonly used application of diabetic retinopathy, we first demonstrate that state-of-the-art SDG techniques fail to achieve generalized performance across data domains. We then develop a generic expert knowledge integrated deep learning technique DL+EKE and instantiate it for the DR application and show that DL+EKE outperforms SOTA SDG methods on DR. We then deploy instances of DL+EKE technique on the two real world examples of stress ECG and resting state (rs)-fMRI and discuss issues faced with SDG techniques.",
      "url": "http://arxiv.org/abs/2601.16359",
      "author": "Ayan Banerjee, Komandoor Srivathsan, Sandeep K. S. Gupta",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "eess.IV"
      ],
      "summary": "Shares practical experience with single domain generalization in real medical imaging deployments. Covers seizure detection from fMRI and stress echocardiography across different acquisition conditions.",
      "importance_score": 45,
      "reasoning": "Valuable practical insights from real deployments; addresses gap between research and deployment in medical AI.",
      "themes": [
        "Medical Imaging",
        "Domain Generalization",
        "Deployment",
        "Healthcare AI"
      ],
      "continuation": null,
      "summary_html": "<p>Shares practical experience with single domain generalization in real medical imaging deployments. Covers seizure detection from fMRI and stress echocardiography across different acquisition conditions.</p>",
      "content_html": "<p>arXiv:2601.16359v1 Announce Type: cross  Abstract: A desirable property of any deployed artificial intelligence is generalization across domains, i.e. data generation distribution under a specific acquisition condition. In medical imagining applications the most coveted property for effective deployment is Single Domain Generalization (SDG), which addresses the challenge of training a model on a single domain to ensure it generalizes well to unseen target domains. In multi-center studies, differences in scanners and imaging protocols introduce domain shifts that exacerbate variability in rare class characteristics. This paper presents our experience on SDG in real life deployment for two exemplary medical imaging case studies on seizure onset zone detection using fMRI data, and stress electrocardiogram based coronary artery detection. Utilizing the commonly used application of diabetic retinopathy, we first demonstrate that state-of-the-art SDG techniques fail to achieve generalized performance across data domains. We then develop a generic expert knowledge integrated deep learning technique DL+EKE and instantiate it for the DR application and show that DL+EKE outperforms SOTA SDG methods on DR. We then deploy instances of DL+EKE technique on the two real world examples of stress ECG and resting state (rs)-fMRI and discuss issues faced with SDG techniques.</p>"
    },
    {
      "id": "3a43c1f195c0",
      "title": "Tight Regret Bounds for Bilateral Trade under Semi Feedback",
      "content": "arXiv:2601.16412v1 Announce Type: cross  Abstract: The study of \\textit{regret minimization in fixed-price bilateral trade} has received considerable attention in recent research. Previous works [CCC+24a, CCC+24b, AFF24, BCCF24, CJLZ25, LCM25a, GDFS25] have acquired a thorough understanding of the problem, except for determining the tight regret bound for GBB semi-feedback fixed-price mechanisms under adversarial values.   In this paper, we resolve this open question by devising an $\\widetilde{O}(T^{2 / 3})$-regret mechanism, matching the $\\Omega(T^{2 / 3})$ lower bound from [CJLZ25] up to polylogarithmic factors.",
      "url": "http://arxiv.org/abs/2601.16412",
      "author": "Yaonan Jin",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.GT"
      ],
      "summary": "Resolves open question on regret bounds for fixed-price bilateral trade under GBB semi-feedback. Achieves O(T^{2/3}) regret matching the known lower bound up to log factors.",
      "importance_score": 45,
      "reasoning": "Complete resolution of open theoretical question; solid contribution to online learning theory.",
      "themes": [
        "Online Learning",
        "Regret Minimization",
        "Mechanism Design"
      ],
      "continuation": null,
      "summary_html": "<p>Resolves open question on regret bounds for fixed-price bilateral trade under GBB semi-feedback. Achieves O(T^{2/3}) regret matching the known lower bound up to log factors.</p>",
      "content_html": "<p>arXiv:2601.16412v1 Announce Type: cross  Abstract: The study of \\textit{regret minimization in fixed-price bilateral trade} has received considerable attention in recent research. Previous works [CCC+24a, CCC+24b, AFF24, BCCF24, CJLZ25, LCM25a, GDFS25] have acquired a thorough understanding of the problem, except for determining the tight regret bound for GBB semi-feedback fixed-price mechanisms under adversarial values.   In this paper, we resolve this open question by devising an $\\widetilde{O}(T^{2 / 3})$-regret mechanism, matching the $\\Omega(T^{2 / 3})$ lower bound from [CJLZ25] up to polylogarithmic factors.</p>"
    },
    {
      "id": "da38323f019b",
      "title": "Learning to Optimize by Differentiable Programming",
      "content": "arXiv:2601.16510v1 Announce Type: cross  Abstract: Solving massive-scale optimization problems requires scalable first-order methods with low per-iteration cost. This tutorial highlights a shift in optimization: using differentiable programming not only to execute algorithms but to learn how to design them. Modern frameworks such as PyTorch, TensorFlow, and JAX enable this paradigm through efficient automatic differentiation. Embedding first-order methods within these systems allows end-to-end training that improves convergence and solution quality. Guided by Fenchel-Rockafellar duality, the tutorial demonstrates how duality-informed iterative schemes such as ADMM and PDHG can be learned and adapted. Case studies across LP, OPF, Laplacian regularization, and neural network verification illustrate these gains.",
      "url": "http://arxiv.org/abs/2601.16510",
      "author": "Liping Tao, Xindi Tong, Chee Wei Tan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.MS"
      ],
      "summary": "Tutorial on using differentiable programming frameworks to learn optimization algorithms. Demonstrates how duality-informed schemes like ADMM and PDHG can be learned through end-to-end training.",
      "importance_score": 45,
      "reasoning": "Educational contribution bridging optimization and deep learning; useful practical guidance.",
      "themes": [
        "Differentiable Programming",
        "Optimization",
        "Learning to Optimize",
        "Tutorial"
      ],
      "continuation": null,
      "summary_html": "<p>Tutorial on using differentiable programming frameworks to learn optimization algorithms. Demonstrates how duality-informed schemes like ADMM and PDHG can be learned through end-to-end training.</p>",
      "content_html": "<p>arXiv:2601.16510v1 Announce Type: cross  Abstract: Solving massive-scale optimization problems requires scalable first-order methods with low per-iteration cost. This tutorial highlights a shift in optimization: using differentiable programming not only to execute algorithms but to learn how to design them. Modern frameworks such as PyTorch, TensorFlow, and JAX enable this paradigm through efficient automatic differentiation. Embedding first-order methods within these systems allows end-to-end training that improves convergence and solution quality. Guided by Fenchel-Rockafellar duality, the tutorial demonstrates how duality-informed iterative schemes such as ADMM and PDHG can be learned and adapted. Case studies across LP, OPF, Laplacian regularization, and neural network verification illustrate these gains.</p>"
    },
    {
      "id": "096e29dd9c30",
      "title": "Semi-Supervised Hierarchical Open-Set Classification",
      "content": "arXiv:2601.16541v1 Announce Type: cross  Abstract: Hierarchical open-set classification handles previously unseen classes by assigning them to the most appropriate high-level category in a class taxonomy. We extend this paradigm to the semi-supervised setting, enabling the use of large-scale, uncurated datasets containing a mixture of known and unknown classes to improve the hierarchical open-set performance. To this end, we propose a teacher-student framework based on pseudo-labeling. Two key components are introduced: 1) subtree pseudo-labels, which provide reliable supervision in the presence of unknown data, and 2) age-gating, a mechanism that mitigates overconfidence in pseudo-labels. Experiments show that our framework outperforms self-supervised pretraining followed by supervised adaptation, and even matches the fully supervised counterpart when using only 20 labeled samples per class on the iNaturalist19 benchmark. Our code is available at https://github.com/walline/semihoc.",
      "url": "http://arxiv.org/abs/2601.16541",
      "author": "Erik Wallin, Fredrik Kahl, Lars Hammarstrand",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Extends hierarchical open-set classification to semi-supervised setting with unknown classes in unlabeled data. Proposes subtree pseudo-labels and age-gating to handle uncertainty about novel classes.",
      "importance_score": 45,
      "reasoning": "Addresses practical scenario where unlabeled data contains unknown classes; solid methodology.",
      "themes": [
        "Semi-Supervised Learning",
        "Open-Set Classification",
        "Pseudo-Labeling"
      ],
      "continuation": null,
      "summary_html": "<p>Extends hierarchical open-set classification to semi-supervised setting with unknown classes in unlabeled data. Proposes subtree pseudo-labels and age-gating to handle uncertainty about novel classes.</p>",
      "content_html": "<p>arXiv:2601.16541v1 Announce Type: cross  Abstract: Hierarchical open-set classification handles previously unseen classes by assigning them to the most appropriate high-level category in a class taxonomy. We extend this paradigm to the semi-supervised setting, enabling the use of large-scale, uncurated datasets containing a mixture of known and unknown classes to improve the hierarchical open-set performance. To this end, we propose a teacher-student framework based on pseudo-labeling. Two key components are introduced: 1) subtree pseudo-labels, which provide reliable supervision in the presence of unknown data, and 2) age-gating, a mechanism that mitigates overconfidence in pseudo-labels. Experiments show that our framework outperforms self-supervised pretraining followed by supervised adaptation, and even matches the fully supervised counterpart when using only 20 labeled samples per class on the iNaturalist19 benchmark. Our code is available at https://github.com/walline/semihoc.</p>"
    },
    {
      "id": "bf039b82f865",
      "title": "PRISM: Purified Representation and Integrated Semantic Modeling for Generative Sequential Recommendation",
      "content": "arXiv:2601.16556v1 Announce Type: cross  Abstract: Generative Sequential Recommendation (GSR) has emerged as a promising paradigm, reframing recommendation as an autoregressive sequence generation task over discrete Semantic IDs (SIDs), typically derived via codebook-based quantization. Despite its great potential in unifying retrieval and ranking, existing GSR frameworks still face two critical limitations: (1) impure and unstable semantic tokenization, where quantization methods struggle with interaction noise and codebook collapse, resulting in SIDs with ambiguous discrimination; and (2) lossy and weakly structured generation, where reliance solely on coarse-grained discrete tokens inevitably introduces information loss and neglects items' hierarchical logic. To address these issues, we propose a novel generative recommendation framework, PRISM, with Purified Representation and Integrated Semantic Modeling. Specifically, to ensure high-quality tokenization, we design a Purified Semantic Quantizer that constructs a robust codebook via adaptive collaborative denoising and hierarchical semantic anchoring mechanisms. To compensate for information loss during quantization, we further propose an Integrated Semantic Recommender, which incorporates a dynamic semantic integration mechanism to integrate fine-grained semantics and enforces logical validity through a semantic structure alignment objective. PRISM consistently outperforms state-of-the-art baselines across four real-world datasets, demonstrating substantial performance gains, particularly in high-sparsity scenarios.",
      "url": "http://arxiv.org/abs/2601.16556",
      "author": "Dengzhao Fang, Jingtong Gao, Yu Li, Xiangyu Zhao, Yi Chang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.IR"
      ],
      "summary": "Proposes PRISM for generative sequential recommendation addressing semantic tokenization impurity and information loss. Introduces purified representation with hierarchical structure for better generation.",
      "importance_score": 45,
      "reasoning": "Solid contribution to generative recommendation; addresses known limitations of semantic ID approaches.",
      "themes": [
        "Recommender Systems",
        "Generative Models",
        "Sequential Recommendation"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes PRISM for generative sequential recommendation addressing semantic tokenization impurity and information loss. Introduces purified representation with hierarchical structure for better generation.</p>",
      "content_html": "<p>arXiv:2601.16556v1 Announce Type: cross  Abstract: Generative Sequential Recommendation (GSR) has emerged as a promising paradigm, reframing recommendation as an autoregressive sequence generation task over discrete Semantic IDs (SIDs), typically derived via codebook-based quantization. Despite its great potential in unifying retrieval and ranking, existing GSR frameworks still face two critical limitations: (1) impure and unstable semantic tokenization, where quantization methods struggle with interaction noise and codebook collapse, resulting in SIDs with ambiguous discrimination; and (2) lossy and weakly structured generation, where reliance solely on coarse-grained discrete tokens inevitably introduces information loss and neglects items' hierarchical logic. To address these issues, we propose a novel generative recommendation framework, PRISM, with Purified Representation and Integrated Semantic Modeling. Specifically, to ensure high-quality tokenization, we design a Purified Semantic Quantizer that constructs a robust codebook via adaptive collaborative denoising and hierarchical semantic anchoring mechanisms. To compensate for information loss during quantization, we further propose an Integrated Semantic Recommender, which incorporates a dynamic semantic integration mechanism to integrate fine-grained semantics and enforces logical validity through a semantic structure alignment objective. PRISM consistently outperforms state-of-the-art baselines across four real-world datasets, demonstrating substantial performance gains, particularly in high-sparsity scenarios.</p>"
    },
    {
      "id": "be06956dee25",
      "title": "Efficient Learning of Stationary Diffusions with Stein-type Discrepancies",
      "content": "arXiv:2601.16597v1 Announce Type: cross  Abstract: Learning a stationary diffusion amounts to estimating the parameters of a stochastic differential equation whose stationary distribution matches a target distribution. We build on the recently introduced kernel deviation from stationarity (KDS), which enforces stationarity by evaluating expectations of the diffusion's generator in a reproducing kernel Hilbert space. Leveraging the connection between KDS and Stein discrepancies, we introduce the Stein-type KDS (SKDS) as an alternative formulation. We prove that a vanishing SKDS guarantees alignment of the learned diffusion's stationary distribution with the target. Furthermore, under broad parametrizations, SKDS is convex with an empirical version that is $\\epsilon$-quasiconvex with high probability. Empirically, learning with SKDS attains comparable accuracy to KDS while substantially reducing computational cost and yields improvements over the majority of competitive baselines.",
      "url": "http://arxiv.org/abs/2601.16597",
      "author": "Fabian Bleile, Sarah Lumpp, Mathias Drton",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "stat.ML"
      ],
      "summary": "Introduces Stein-type KDS for learning stationary diffusions from data. Proves vanishing SKDS guarantees alignment with target distribution; shows convexity under broad parametrizations.",
      "importance_score": 45,
      "reasoning": "Solid theoretical contribution connecting Stein discrepancies to diffusion learning; provides useful convexity guarantees.",
      "themes": [
        "Stochastic Differential Equations",
        "Stein Discrepancies",
        "Generative Models"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Stein-type KDS for learning stationary diffusions from data. Proves vanishing SKDS guarantees alignment with target distribution; shows convexity under broad parametrizations.</p>",
      "content_html": "<p>arXiv:2601.16597v1 Announce Type: cross  Abstract: Learning a stationary diffusion amounts to estimating the parameters of a stochastic differential equation whose stationary distribution matches a target distribution. We build on the recently introduced kernel deviation from stationarity (KDS), which enforces stationarity by evaluating expectations of the diffusion's generator in a reproducing kernel Hilbert space. Leveraging the connection between KDS and Stein discrepancies, we introduce the Stein-type KDS (SKDS) as an alternative formulation. We prove that a vanishing SKDS guarantees alignment of the learned diffusion's stationary distribution with the target. Furthermore, under broad parametrizations, SKDS is convex with an empirical version that is $\\epsilon$-quasiconvex with high probability. Empirically, learning with SKDS attains comparable accuracy to KDS while substantially reducing computational cost and yields improvements over the majority of competitive baselines.</p>"
    },
    {
      "id": "901f8c6152d1",
      "title": "A Lightweight Medical Image Classification Framework via Self-Supervised Contrastive Learning and Quantum-Enhanced Feature Modeling",
      "content": "arXiv:2601.16608v1 Announce Type: cross  Abstract: Intelligent medical image analysis is essential for clinical decision support but is often limited by scarce annotations, constrained computational resources, and suboptimal model generalization. To address these challenges, we propose a lightweight medical image classification framework that integrates self-supervised contrastive learning with quantum-enhanced feature modeling. MobileNetV2 is employed as a compact backbone and pretrained using a SimCLR-style self-supervised paradigm on unlabeled images. A lightweight parameterized quantum circuit (PQC) is embedded as a quantum feature enhancement module, forming a hybrid classical-quantum architecture, which is subsequently fine-tuned on limited labeled data. Experimental results demonstrate that, with only approximately 2-3 million parameters and low computational cost, the proposed method consistently outperforms classical baselines without self-supervised learning or quantum enhancement in terms of Accuracy, AUC, and F1-score. Feature visualization further indicates improved discriminability and representation stability. Overall, this work provides a practical and forward-looking solution for high-performance medical artificial intelligence under resource-constrained settings.",
      "url": "http://arxiv.org/abs/2601.16608",
      "author": "Jingsong Xia, Siqi Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes hybrid classical-quantum framework for medical image classification combining SimCLR self-supervised pretraining with parameterized quantum circuits for feature enhancement.",
      "importance_score": 45,
      "reasoning": "Interesting intersection of quantum ML and medical imaging; early exploration of potential quantum advantages.",
      "themes": [
        "Quantum Machine Learning",
        "Medical Imaging",
        "Self-Supervised Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes hybrid classical-quantum framework for medical image classification combining SimCLR self-supervised pretraining with parameterized quantum circuits for feature enhancement.</p>",
      "content_html": "<p>arXiv:2601.16608v1 Announce Type: cross  Abstract: Intelligent medical image analysis is essential for clinical decision support but is often limited by scarce annotations, constrained computational resources, and suboptimal model generalization. To address these challenges, we propose a lightweight medical image classification framework that integrates self-supervised contrastive learning with quantum-enhanced feature modeling. MobileNetV2 is employed as a compact backbone and pretrained using a SimCLR-style self-supervised paradigm on unlabeled images. A lightweight parameterized quantum circuit (PQC) is embedded as a quantum feature enhancement module, forming a hybrid classical-quantum architecture, which is subsequently fine-tuned on limited labeled data. Experimental results demonstrate that, with only approximately 2-3 million parameters and low computational cost, the proposed method consistently outperforms classical baselines without self-supervised learning or quantum enhancement in terms of Accuracy, AUC, and F1-score. Feature visualization further indicates improved discriminability and representation stability. Overall, this work provides a practical and forward-looking solution for high-performance medical artificial intelligence under resource-constrained settings.</p>"
    },
    {
      "id": "b0d205226066",
      "title": "Fast, faithful and photorealistic diffusion-based image super-resolution with enhanced Flow Map models",
      "content": "arXiv:2601.16660v1 Announce Type: cross  Abstract: Diffusion-based image super-resolution (SR) has recently attracted significant attention by leveraging the expressive power of large pre-trained text-to-image diffusion models (DMs). A central practical challenge is resolving the trade-off between reconstruction faithfulness and photorealism. To address inference efficiency, many recent works have explored knowledge distillation strategies specifically tailored to SR, enabling one-step diffusion-based approaches. However, these teacher-student formulations are inherently constrained by information compression, which can degrade perceptual cues such as lifelike textures and depth of field, even with high overall perceptual quality. In parallel, self-distillation DMs, known as Flow Map models, have emerged as a promising alternative for image generation tasks, enabling fast inference while preserving the expressivity and training stability of standard DMs. Building on these developments, we propose FlowMapSR, a novel diffusion-based framework for image super-resolution explicitly designed for efficient inference. Beyond adapting Flow Map models to SR, we introduce two complementary enhancements: (i) positive-negative prompting guidance, based on a generalization of classifier free-guidance paradigm to Flow Map models, and (ii) adversarial fine-tuning using Low-Rank Adaptation (LoRA). Among the considered Flow Map formulations (Eulerian, Lagrangian, and Shortcut), we find that the Shortcut variant consistently achieves the best performance when combined with these enhancements. Extensive experiments show that FlowMapSR achieves a better balance between reconstruction faithfulness and photorealism than recent state-of-the-art methods for both x4 and x8 upscaling, while maintaining competitive inference time. Notably, a single model is used for both upscaling factors, without any scale-specific conditioning or degradation-guided mechanisms.",
      "url": "http://arxiv.org/abs/2601.16660",
      "author": "Maxence Noble, Gonzalo I\\~naki Quintana, Benjamin Aubin, Cl\\'ement Chadebec",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "eess.IV"
      ],
      "summary": "Proposes enhanced Flow Map models for fast, faithful diffusion-based image super-resolution. Addresses trade-off between reconstruction faithfulness and photorealism in one-step approaches.",
      "importance_score": 45,
      "reasoning": "Good contribution to image SR; balances efficiency and quality effectively.",
      "themes": [
        "Image Super-Resolution",
        "Diffusion Models",
        "Knowledge Distillation"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes enhanced Flow Map models for fast, faithful diffusion-based image super-resolution. Addresses trade-off between reconstruction faithfulness and photorealism in one-step approaches.</p>",
      "content_html": "<p>arXiv:2601.16660v1 Announce Type: cross  Abstract: Diffusion-based image super-resolution (SR) has recently attracted significant attention by leveraging the expressive power of large pre-trained text-to-image diffusion models (DMs). A central practical challenge is resolving the trade-off between reconstruction faithfulness and photorealism. To address inference efficiency, many recent works have explored knowledge distillation strategies specifically tailored to SR, enabling one-step diffusion-based approaches. However, these teacher-student formulations are inherently constrained by information compression, which can degrade perceptual cues such as lifelike textures and depth of field, even with high overall perceptual quality. In parallel, self-distillation DMs, known as Flow Map models, have emerged as a promising alternative for image generation tasks, enabling fast inference while preserving the expressivity and training stability of standard DMs. Building on these developments, we propose FlowMapSR, a novel diffusion-based framework for image super-resolution explicitly designed for efficient inference. Beyond adapting Flow Map models to SR, we introduce two complementary enhancements: (i) positive-negative prompting guidance, based on a generalization of classifier free-guidance paradigm to Flow Map models, and (ii) adversarial fine-tuning using Low-Rank Adaptation (LoRA). Among the considered Flow Map formulations (Eulerian, Lagrangian, and Shortcut), we find that the Shortcut variant consistently achieves the best performance when combined with these enhancements. Extensive experiments show that FlowMapSR achieves a better balance between reconstruction faithfulness and photorealism than recent state-of-the-art methods for both x4 and x8 upscaling, while maintaining competitive inference time. Notably, a single model is used for both upscaling factors, without any scale-specific conditioning or degradation-guided mechanisms.</p>"
    },
    {
      "id": "e2956075e3af",
      "title": "ReLU Networks for Model Predictive Control: Network Complexity and Performance Guarantees",
      "content": "arXiv:2601.16764v1 Announce Type: cross  Abstract: Recent years have witnessed a resurgence in using ReLU neural networks (NNs) to represent model predictive control (MPC) policies. However, determining the required network complexity to ensure closed-loop performance remains a fundamental open problem. This involves a critical precision-complexity trade-off: undersized networks may fail to capture the MPC policy, while oversized ones may outweigh the benefits of ReLU network approximation. In this work, we propose a projection-based method to enforce hard constraints and establish a state-dependent Lipschitz continuity property for the optimal MPC cost function, which enables sharp convergence analysis of the closed-loop system. For the first time, we derive explicit bounds on ReLU network width and depth for approximating MPC policies with guaranteed closed-loop performance. To further reduce network complexity and enhance closed-loop performance, we propose a non-uniform error framework with a state-aware scaling function to adaptively adjust both the input and output of the ReLU network. Our contributions provide a foundational step toward certifiable ReLU NN-based MPC.",
      "url": "http://arxiv.org/abs/2601.16764",
      "author": "Xingchen Li, Keyou You",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "eess.SY"
      ],
      "summary": "Derives explicit bounds on ReLU network complexity required to ensure MPC closed-loop performance. Establishes state-dependent Lipschitz continuity enabling sharp convergence analysis.",
      "importance_score": 45,
      "reasoning": "Important theoretical contribution bridging neural networks and control theory; provides first explicit complexity bounds.",
      "themes": [
        "Model Predictive Control",
        "Neural Network Approximation",
        "Control Theory"
      ],
      "continuation": null,
      "summary_html": "<p>Derives explicit bounds on ReLU network complexity required to ensure MPC closed-loop performance. Establishes state-dependent Lipschitz continuity enabling sharp convergence analysis.</p>",
      "content_html": "<p>arXiv:2601.16764v1 Announce Type: cross  Abstract: Recent years have witnessed a resurgence in using ReLU neural networks (NNs) to represent model predictive control (MPC) policies. However, determining the required network complexity to ensure closed-loop performance remains a fundamental open problem. This involves a critical precision-complexity trade-off: undersized networks may fail to capture the MPC policy, while oversized ones may outweigh the benefits of ReLU network approximation. In this work, we propose a projection-based method to enforce hard constraints and establish a state-dependent Lipschitz continuity property for the optimal MPC cost function, which enables sharp convergence analysis of the closed-loop system. For the first time, we derive explicit bounds on ReLU network width and depth for approximating MPC policies with guaranteed closed-loop performance. To further reduce network complexity and enhance closed-loop performance, we propose a non-uniform error framework with a state-aware scaling function to adaptively adjust both the input and output of the ReLU network. Our contributions provide a foundational step toward certifiable ReLU NN-based MPC.</p>"
    },
    {
      "id": "3f80a721258b",
      "title": "Building a Robust Risk-Based Access Control System to Combat Ransomware's Capability to Encrypt: A Machine Learning Approach",
      "content": "arXiv:2601.16795v1 Announce Type: cross  Abstract: Ransomware core capability, unauthorized encryption, demands controls that identify and block malicious cryptographic activity without disrupting legitimate use. We present a probabilistic, risk-based access control architecture that couples machine learning inference with mandatory access control to regulate encryption on Linux in real time. The system builds a specialized dataset from the native ftrace framework using the function_graph tracer, yielding high-resolution kernel-function execution traces augmented with resource and I/O counters. These traces support both a supervised classifier and interpretable rules that drive an SELinux policy via lightweight booleans, enabling context-sensitive permit/deny decisions at the moment encryption begins. Compared to approaches centered on sandboxing, hypervisor introspection, or coarse system-call telemetry, the function-level tracing we adopt provides finer behavioral granularity than syscall-only telemetry while avoiding the virtualization/VMI overhead of sandbox-based approaches. Our current user-space prototype has a non-trivial footprint under burst I/O; we quantify it and recognize that a production kernel-space solution should aim to address this. We detail dataset construction, model training and rule extraction, and the run-time integration that gates file writes for suspect encryption while preserving benign cryptographic workflows. During evaluation, the two-layer composition retains model-level detection quality while delivering rule-like responsiveness; we also quantify operational footprint and outline engineering steps to reduce CPU and memory overhead for enterprise deployment. The result is a practical path from behavioral tracing and learning to enforceable, explainable, and risk-proportionate encryption control on production Linux systems.",
      "url": "http://arxiv.org/abs/2601.16795",
      "author": "Kenan Begovic, Abdulaziz Al-Ali, Qutaibah Malluhi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.CR"
      ],
      "summary": "Presents a probabilistic risk-based access control system using ML to detect and block ransomware encryption in real-time on Linux. Uses kernel function traces with SELinux integration for context-sensitive permit/deny decisions.",
      "importance_score": 45,
      "reasoning": "Applied security research with specialized focus. Sound methodology but limited novelty for broader AI community.",
      "themes": [
        "Security",
        "Machine Learning Applications"
      ],
      "continuation": null,
      "summary_html": "<p>Presents a probabilistic risk-based access control system using ML to detect and block ransomware encryption in real-time on Linux. Uses kernel function traces with SELinux integration for context-sensitive permit/deny decisions.</p>",
      "content_html": "<p>arXiv:2601.16795v1 Announce Type: cross  Abstract: Ransomware core capability, unauthorized encryption, demands controls that identify and block malicious cryptographic activity without disrupting legitimate use. We present a probabilistic, risk-based access control architecture that couples machine learning inference with mandatory access control to regulate encryption on Linux in real time. The system builds a specialized dataset from the native ftrace framework using the function_graph tracer, yielding high-resolution kernel-function execution traces augmented with resource and I/O counters. These traces support both a supervised classifier and interpretable rules that drive an SELinux policy via lightweight booleans, enabling context-sensitive permit/deny decisions at the moment encryption begins. Compared to approaches centered on sandboxing, hypervisor introspection, or coarse system-call telemetry, the function-level tracing we adopt provides finer behavioral granularity than syscall-only telemetry while avoiding the virtualization/VMI overhead of sandbox-based approaches. Our current user-space prototype has a non-trivial footprint under burst I/O; we quantify it and recognize that a production kernel-space solution should aim to address this. We detail dataset construction, model training and rule extraction, and the run-time integration that gates file writes for suspect encryption while preserving benign cryptographic workflows. During evaluation, the two-layer composition retains model-level detection quality while delivering rule-like responsiveness; we also quantify operational footprint and outline engineering steps to reduce CPU and memory overhead for enterprise deployment. The result is a practical path from behavioral tracing and learning to enforceable, explainable, and risk-proportionate encryption control on production Linux systems.</p>"
    },
    {
      "id": "7f0ab47cabcc",
      "title": "Fine-Grained Emotion Detection on GoEmotions: Experimental Comparison of Classical Machine Learning, BiLSTM, and Transformer Models",
      "content": "arXiv:2601.18162v1 Announce Type: new  Abstract: Fine-grained emotion recognition is a challenging multi-label NLP task due to label overlap and class imbalance. In this work, we benchmark three modeling families on the GoEmotions dataset: a TF-IDF-based logistic regression system trained with binary relevance, a BiLSTM with attention, and a BERT model fine-tuned for multi-label classification. Experiments follow the official train/validation/test split, and imbalance is mitigated using inverse-frequency class weights. Across several metrics, namely Micro-F1, Macro-F1, Hamming Loss, and Subset Accuracy, we observe that logistic regression attains the highest Micro-F1 of 0.51, while BERT achieves the best overall balance surpassing the official paper's reported results, reaching Macro-F1 0.49, Hamming Loss 0.036, and Subset Accuracy 0.36. This suggests that frequent emotions often rely on surface lexical cues, whereas contextual representations improve performance on rarer emotions and more ambiguous examples.",
      "url": "http://arxiv.org/abs/2601.18162",
      "author": "Ani Harutyunyan, Sachin Kumar",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Benchmarks classical ML, BiLSTM, and BERT models on GoEmotions fine-grained emotion detection. Finds logistic regression achieves highest Micro-F1 while BERT shows best overall balance.",
      "importance_score": 45,
      "reasoning": "Standard benchmarking study with limited novelty. Useful empirical comparison but incremental contribution.",
      "themes": [
        "Emotion Detection",
        "Text Classification",
        "Benchmarking"
      ],
      "continuation": null,
      "summary_html": "<p>Benchmarks classical ML, BiLSTM, and BERT models on GoEmotions fine-grained emotion detection. Finds logistic regression achieves highest Micro-F1 while BERT shows best overall balance.</p>",
      "content_html": "<p>arXiv:2601.18162v1 Announce Type: new  Abstract: Fine-grained emotion recognition is a challenging multi-label NLP task due to label overlap and class imbalance. In this work, we benchmark three modeling families on the GoEmotions dataset: a TF-IDF-based logistic regression system trained with binary relevance, a BiLSTM with attention, and a BERT model fine-tuned for multi-label classification. Experiments follow the official train/validation/test split, and imbalance is mitigated using inverse-frequency class weights. Across several metrics, namely Micro-F1, Macro-F1, Hamming Loss, and Subset Accuracy, we observe that logistic regression attains the highest Micro-F1 of 0.51, while BERT achieves the best overall balance surpassing the official paper's reported results, reaching Macro-F1 0.49, Hamming Loss 0.036, and Subset Accuracy 0.36. This suggests that frequent emotions often rely on surface lexical cues, whereas contextual representations improve performance on rarer emotions and more ambiguous examples.</p>"
    },
    {
      "id": "99ace715448a",
      "title": "Structure-Aware NL-to-SQL for SFC Provisioning via AST-Masking Empowered Language Models",
      "content": "arXiv:2601.17295v1 Announce Type: cross  Abstract: Effective Service Function Chain (SFC) provisioning requires precise orchestration in dynamic and latency-sensitive networks. Reinforcement Learning (RL) improves adaptability but often ignores structured domain knowledge, which limits generalization and interpretability. Large Language Models (LLMs) address this gap by translating natural language (NL) specifications into executable Structured Query Language (SQL) commands for specification-driven SFC management. Conventional fine-tuning, however, can cause syntactic inconsistencies and produce inefficient queries. To overcome this, we introduce Abstract Syntax Tree (AST)-Masking, a structure-aware fine-tuning method that uses SQL ASTs to assign weights to key components and enforce syntax-aware learning without adding inference overhead. Experiments show that AST-Masking significantly improves SQL generation accuracy across multiple language models. FLAN-T5 reaches an Execution Accuracy (EA) of 99.6%, while Gemma achieves the largest absolute gain from 7.5% to 72.0%. These results confirm the effectiveness of structure-aware fine-tuning in ensuring syntactically correct and efficient SQL generation for interpretable SFC orchestration.",
      "url": "http://arxiv.org/abs/2601.17295",
      "author": "Xinyu Zhu, Parisa Fard Moshiri, Poonam Lohan, Burak Kantarci, Emil Janulewicz",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.NI"
      ],
      "summary": "Proposes AST-Masking for natural language to SQL conversion in network service function chain provisioning, using abstract syntax trees to enforce syntactic consistency during fine-tuning.",
      "importance_score": 45,
      "reasoning": "Domain-specific NL-to-SQL application with reasonable technical contribution but narrow application scope.",
      "themes": [
        "NL-to-SQL",
        "Network Management",
        "Fine-tuning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes AST-Masking for natural language to SQL conversion in network service function chain provisioning, using abstract syntax trees to enforce syntactic consistency during fine-tuning.</p>",
      "content_html": "<p>arXiv:2601.17295v1 Announce Type: cross  Abstract: Effective Service Function Chain (SFC) provisioning requires precise orchestration in dynamic and latency-sensitive networks. Reinforcement Learning (RL) improves adaptability but often ignores structured domain knowledge, which limits generalization and interpretability. Large Language Models (LLMs) address this gap by translating natural language (NL) specifications into executable Structured Query Language (SQL) commands for specification-driven SFC management. Conventional fine-tuning, however, can cause syntactic inconsistencies and produce inefficient queries. To overcome this, we introduce Abstract Syntax Tree (AST)-Masking, a structure-aware fine-tuning method that uses SQL ASTs to assign weights to key components and enforce syntax-aware learning without adding inference overhead. Experiments show that AST-Masking significantly improves SQL generation accuracy across multiple language models. FLAN-T5 reaches an Execution Accuracy (EA) of 99.6%, while Gemma achieves the largest absolute gain from 7.5% to 72.0%. These results confirm the effectiveness of structure-aware fine-tuning in ensuring syntactically correct and efficient SQL generation for interpretable SFC orchestration.</p>"
    },
    {
      "id": "a9c5f53a918a",
      "title": "Synthetic Data Guided Feature Selection for Robust Activity Recognition in Older Adults",
      "content": "arXiv:2601.17053v1 Announce Type: new  Abstract: Physical activity during hip fracture rehabilitation is essential for mitigating long-term functional decline in geriatric patients. However, it is rarely quantified in clinical practice. Existing continuous monitoring systems with commercially available wearable activity trackers are typically developed in middle-aged adults and therefore perform unreliably in older adults with slower and more variable gait patterns. This study aimed to develop a robust human activity recognition (HAR) system to improve continuous physical activity recognition in the context of hip fracture rehabilitation. 24 healthy older adults aged over 80 years were included to perform activities of daily living (walking, standing, sitting, lying down, and postural transfers) under simulated free-living conditions for 75 minutes while wearing two accelerometers positioned on the lower back and anterior upper thigh. Model robustness was evaluated using leave-one-subject-out cross-validation. The synthetic data demonstrated potential to improve generalization across participants. The resulting feature intervention model (FIM), aided by synthetic data guidance, achieved reliable activity recognition with mean F1-scores of 0.896 for walking, 0.927 for standing, 0.997 for sitting, 0.937 for lying down, and 0.816 for postural transfers. Compared with a control condition model without synthetic data, the FIM significantly improved the postural transfer detection, i.e., an activity class of high clinical relevance that is often overlooked in existing HAR literature. In conclusion, these preliminary results demonstrate the feasibility of robust activity recognition in older adults. Further validation in hip fracture patient populations is required to assess the clinical utility of the proposed monitoring system.",
      "url": "http://arxiv.org/abs/2601.17053",
      "author": "Shuhao Que, Dieuwke van Dartel, Ilse Heeringa, Han Hegeman, Miriam Vollenbroek-Hutten, Ying Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Develops robust human activity recognition for hip fracture rehabilitation using synthetic data-guided feature selection, addressing challenges with older adults' slower, variable gait patterns.",
      "importance_score": 45,
      "reasoning": "Practical healthcare application addressing real-world data challenges but limited methodological novelty.",
      "themes": [
        "Activity Recognition",
        "Healthcare AI",
        "Wearables"
      ],
      "continuation": null,
      "summary_html": "<p>Develops robust human activity recognition for hip fracture rehabilitation using synthetic data-guided feature selection, addressing challenges with older adults' slower, variable gait patterns.</p>",
      "content_html": "<p>arXiv:2601.17053v1 Announce Type: new  Abstract: Physical activity during hip fracture rehabilitation is essential for mitigating long-term functional decline in geriatric patients. However, it is rarely quantified in clinical practice. Existing continuous monitoring systems with commercially available wearable activity trackers are typically developed in middle-aged adults and therefore perform unreliably in older adults with slower and more variable gait patterns. This study aimed to develop a robust human activity recognition (HAR) system to improve continuous physical activity recognition in the context of hip fracture rehabilitation. 24 healthy older adults aged over 80 years were included to perform activities of daily living (walking, standing, sitting, lying down, and postural transfers) under simulated free-living conditions for 75 minutes while wearing two accelerometers positioned on the lower back and anterior upper thigh. Model robustness was evaluated using leave-one-subject-out cross-validation. The synthetic data demonstrated potential to improve generalization across participants. The resulting feature intervention model (FIM), aided by synthetic data guidance, achieved reliable activity recognition with mean F1-scores of 0.896 for walking, 0.927 for standing, 0.997 for sitting, 0.937 for lying down, and 0.816 for postural transfers. Compared with a control condition model without synthetic data, the FIM significantly improved the postural transfer detection, i.e., an activity class of high clinical relevance that is often overlooked in existing HAR literature. In conclusion, these preliminary results demonstrate the feasibility of robust activity recognition in older adults. Further validation in hip fracture patient populations is required to assess the clinical utility of the proposed monitoring system.</p>"
    },
    {
      "id": "d4b6d6451474",
      "title": "Decoding Psychological States Through Movement: Inferring Human Kinesic Functions with Application to Built Environments",
      "content": "arXiv:2601.17194v1 Announce Type: new  Abstract: Social infrastructure and other built environments are increasingly expected to support well-being and community resilience by enabling social interaction. Yet in civil and built-environment research, there is no consistent and privacy-preserving way to represent and measure socially meaningful interaction in these spaces, leaving studies to operationalize \"interaction\" differently across contexts and limiting practitioners' ability to evaluate whether design interventions are changing the forms of interaction that social capital theory predicts should matter. To address this field-level and methodological gap, we introduce the Dyadic User Engagement DataseT (DUET) dataset and an embedded kinesics recognition framework that operationalize Ekman and Friesen's kinesics taxonomy as a function-level interaction vocabulary aligned with social capital-relevant behaviors (e.g., reciprocity and attention coordination). DUET captures 12 dyadic interactions spanning all five kinesic functions-emblems, illustrators, affect displays, adaptors, and regulators-across four sensing modalities and three built-environment contexts, enabling privacy-preserving analysis of communicative intent through movement. Benchmarking six open-source, state-of-the-art human activity recognition models quantifies the difficulty of communicative-function recognition on DUET and highlights the limitations of ubiquitous monadic, action-level recognition when extended to dyadic, socially grounded interaction measurement. Building on DUET, our recognition framework infers communicative function directly from privacy-preserving skeletal motion without handcrafted action-to-function dictionaries; using a transfer-learning architecture, it reveals structured clustering of kinesic functions and a strong association between representation quality and classification performance while generalizing across subjects and contexts.",
      "url": "http://arxiv.org/abs/2601.17194",
      "author": "Cheyu Lin, Katherine A. Flanigan, Sirajum Munir",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces DUET dataset and kinesics recognition framework for measuring socially meaningful interaction in built environments using privacy-preserving movement analysis.",
      "importance_score": 45,
      "reasoning": "Interesting interdisciplinary work but niche application area.",
      "themes": [
        "Human Activity Recognition",
        "Social Computing",
        "Built Environment"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces DUET dataset and kinesics recognition framework for measuring socially meaningful interaction in built environments using privacy-preserving movement analysis.</p>",
      "content_html": "<p>arXiv:2601.17194v1 Announce Type: new  Abstract: Social infrastructure and other built environments are increasingly expected to support well-being and community resilience by enabling social interaction. Yet in civil and built-environment research, there is no consistent and privacy-preserving way to represent and measure socially meaningful interaction in these spaces, leaving studies to operationalize \"interaction\" differently across contexts and limiting practitioners' ability to evaluate whether design interventions are changing the forms of interaction that social capital theory predicts should matter. To address this field-level and methodological gap, we introduce the Dyadic User Engagement DataseT (DUET) dataset and an embedded kinesics recognition framework that operationalize Ekman and Friesen's kinesics taxonomy as a function-level interaction vocabulary aligned with social capital-relevant behaviors (e.g., reciprocity and attention coordination). DUET captures 12 dyadic interactions spanning all five kinesic functions-emblems, illustrators, affect displays, adaptors, and regulators-across four sensing modalities and three built-environment contexts, enabling privacy-preserving analysis of communicative intent through movement. Benchmarking six open-source, state-of-the-art human activity recognition models quantifies the difficulty of communicative-function recognition on DUET and highlights the limitations of ubiquitous monadic, action-level recognition when extended to dyadic, socially grounded interaction measurement. Building on DUET, our recognition framework infers communicative function directly from privacy-preserving skeletal motion without handcrafted action-to-function dictionaries; using a transfer-learning architecture, it reveals structured clustering of kinesic functions and a strong association between representation quality and classification performance while generalizing across subjects and contexts.</p>"
    },
    {
      "id": "5654ecde67a5",
      "title": "Multi-stage Bridge Inspection System: Integrating Foundation Models with Location Anonymization",
      "content": "arXiv:2601.17254v1 Announce Type: new  Abstract: In Japan, civil infrastructure condition monitoring is mandated through visual inspection every five years. Field-captured damage images frequently contain concrete cracks and rebar exposure, often accompanied by construction signs revealing regional information. To enable safe infrastructure use without causing public anxiety, it is essential to protect regional information while accurately extracting damage features and visualizing key indicators for repair decision-making. This paper presents an open-source bridge damage detection system with regional privacy protection capabilities. We employ Segment Anything Model (SAM) 3 for rebar corrosion detection and utilize DBSCAN for automatic completion of missed regions. Construction sign regions are detected and protected through Gaussian blur. Four preprocessing methods improve OCR accuracy, and GPU optimization enables 1.7-second processing per image. The technology stack includes SAM3, PyTorch, OpenCV, pytesseract, and scikit-learn, achieving efficient bridge inspection with regional information protection.",
      "url": "http://arxiv.org/abs/2601.17254",
      "author": "Takato Yasuno",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents open-source bridge damage detection system with regional privacy protection using SAM 3 for rebar corrosion detection and DBSCAN for completion, with construction sign anonymization.",
      "importance_score": 45,
      "reasoning": "Practical infrastructure inspection application combining existing techniques.",
      "themes": [
        "Infrastructure Inspection",
        "Privacy",
        "Object Detection"
      ],
      "continuation": null,
      "summary_html": "<p>Presents open-source bridge damage detection system with regional privacy protection using SAM 3 for rebar corrosion detection and DBSCAN for completion, with construction sign anonymization.</p>",
      "content_html": "<p>arXiv:2601.17254v1 Announce Type: new  Abstract: In Japan, civil infrastructure condition monitoring is mandated through visual inspection every five years. Field-captured damage images frequently contain concrete cracks and rebar exposure, often accompanied by construction signs revealing regional information. To enable safe infrastructure use without causing public anxiety, it is essential to protect regional information while accurately extracting damage features and visualizing key indicators for repair decision-making. This paper presents an open-source bridge damage detection system with regional privacy protection capabilities. We employ Segment Anything Model (SAM) 3 for rebar corrosion detection and utilize DBSCAN for automatic completion of missed regions. Construction sign regions are detected and protected through Gaussian blur. Four preprocessing methods improve OCR accuracy, and GPU optimization enables 1.7-second processing per image. The technology stack includes SAM3, PyTorch, OpenCV, pytesseract, and scikit-learn, achieving efficient bridge inspection with regional information protection.</p>"
    },
    {
      "id": "5894632df2c9",
      "title": "HyDeMiC: A Deep Learning-based Mineral Classifier using Hyperspectral Data",
      "content": "arXiv:2601.17352v1 Announce Type: new  Abstract: Hyperspectral imaging (HSI) has emerged as a powerful remote sensing tool for mineral exploration, capitalizing on unique spectral signatures of minerals. However, traditional classification methods such as discriminant analysis, logistic regression, and support vector machines often struggle with environmental noise in data, sensor limitations, and the computational complexity of analyzing high-dimensional HSI data. This study presents HyDeMiC (Hyperspectral Deep Learning-based Mineral Classifier), a convolutional neural network (CNN) model designed for robust mineral classification under noisy data. To train HyDeMiC, laboratory-measured hyperspectral data for 115 minerals spanning various mineral groups were used from the United States Geological Survey (USGS) library. The training dataset was generated by convolving reference mineral spectra with an HSI sensor response function. These datasets contained three copper-bearing minerals, Cuprite, Malachite, and Chalcopyrite, used as case studies for performance demonstration. The trained CNN model was evaluated on several synthetic 2D hyperspectral datasets with noise levels of 1%, 2%, 5%, and 10%. Our noisy data analysis aims to replicate realistic field conditions. The HyDeMiC's performance was assessed using the Matthews Correlation Coefficient (MCC), providing a comprehensive measure across different noise regimes. Results demonstrate that HyDeMiC achieved near-perfect classification accuracy (MCC = 1.00) on clean and low-noise datasets and maintained strong performance under moderate noise conditions. These findings emphasize HyDeMiC's robustness in the presence of moderate noise, highlighting its potential for real-world applications in hyperspectral imaging, where noise is often a significant challenge.",
      "url": "http://arxiv.org/abs/2601.17352",
      "author": "M. L. Mamud, Piyoosh Jaysaval, Frederick D Day-Lewis, M. K. Mudunuru",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes HyDeMiC CNN for hyperspectral mineral classification robust to noisy data, trained on laboratory-measured data for 115 minerals from USGS.",
      "importance_score": 45,
      "reasoning": "Domain-specific application with practical value but limited methodological novelty.",
      "themes": [
        "Hyperspectral Imaging",
        "Mineral Classification",
        "Remote Sensing"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes HyDeMiC CNN for hyperspectral mineral classification robust to noisy data, trained on laboratory-measured data for 115 minerals from USGS.</p>",
      "content_html": "<p>arXiv:2601.17352v1 Announce Type: new  Abstract: Hyperspectral imaging (HSI) has emerged as a powerful remote sensing tool for mineral exploration, capitalizing on unique spectral signatures of minerals. However, traditional classification methods such as discriminant analysis, logistic regression, and support vector machines often struggle with environmental noise in data, sensor limitations, and the computational complexity of analyzing high-dimensional HSI data. This study presents HyDeMiC (Hyperspectral Deep Learning-based Mineral Classifier), a convolutional neural network (CNN) model designed for robust mineral classification under noisy data. To train HyDeMiC, laboratory-measured hyperspectral data for 115 minerals spanning various mineral groups were used from the United States Geological Survey (USGS) library. The training dataset was generated by convolving reference mineral spectra with an HSI sensor response function. These datasets contained three copper-bearing minerals, Cuprite, Malachite, and Chalcopyrite, used as case studies for performance demonstration. The trained CNN model was evaluated on several synthetic 2D hyperspectral datasets with noise levels of 1%, 2%, 5%, and 10%. Our noisy data analysis aims to replicate realistic field conditions. The HyDeMiC's performance was assessed using the Matthews Correlation Coefficient (MCC), providing a comprehensive measure across different noise regimes. Results demonstrate that HyDeMiC achieved near-perfect classification accuracy (MCC = 1.00) on clean and low-noise datasets and maintained strong performance under moderate noise conditions. These findings emphasize HyDeMiC's robustness in the presence of moderate noise, highlighting its potential for real-world applications in hyperspectral imaging, where noise is often a significant challenge.</p>"
    },
    {
      "id": "ea0facf5dc9b",
      "title": "Saliency Driven Imagery Preprocessing for Efficient Compression -- Industrial Paper",
      "content": "arXiv:2601.17555v1 Announce Type: new  Abstract: The compression of satellite imagery remains an important research area as hundreds of terabytes of images are collected every day, which drives up storage and bandwidth costs. Although progress has been made in increasing the resolution of these satellite images, many downstream tasks are only interested in small regions of any given image. These areas of interest vary by task but, once known, can be used to optimize how information within the image is encoded. Whereas standard image encoding methods, even those optimized for remote sensing, work on the whole image equally, there are emerging methods that can be guided by saliency maps to focus on important areas. In this work we show how imagery preprocessing techniques driven by saliency maps can be used with traditional lossy compression coding standards to create variable rate image compression within a single large satellite image. Specifically, we use variable sized smoothing kernels that map to different quantized saliency levels to process imagery pixels in order to optimize downstream compression and encoding schemes.",
      "url": "http://arxiv.org/abs/2601.17555",
      "author": "Justin Downes, Sam Saltwick, Anthony Chen",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes saliency-driven preprocessing for satellite imagery compression, focusing encoding on areas of interest identified by saliency maps to optimize storage and bandwidth.",
      "importance_score": 45,
      "reasoning": "Practical application of saliency for satellite image compression but limited novelty.",
      "themes": [
        "Image Compression",
        "Remote Sensing",
        "Saliency"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes saliency-driven preprocessing for satellite imagery compression, focusing encoding on areas of interest identified by saliency maps to optimize storage and bandwidth.</p>",
      "content_html": "<p>arXiv:2601.17555v1 Announce Type: new  Abstract: The compression of satellite imagery remains an important research area as hundreds of terabytes of images are collected every day, which drives up storage and bandwidth costs. Although progress has been made in increasing the resolution of these satellite images, many downstream tasks are only interested in small regions of any given image. These areas of interest vary by task but, once known, can be used to optimize how information within the image is encoded. Whereas standard image encoding methods, even those optimized for remote sensing, work on the whole image equally, there are emerging methods that can be guided by saliency maps to focus on important areas. In this work we show how imagery preprocessing techniques driven by saliency maps can be used with traditional lossy compression coding standards to create variable rate image compression within a single large satellite image. Specifically, we use variable sized smoothing kernels that map to different quantized saliency levels to process imagery pixels in order to optimize downstream compression and encoding schemes.</p>"
    },
    {
      "id": "f993999cad2c",
      "title": "Stylizing ViT: Anatomy-Preserving Instance Style Transfer for Domain Generalization",
      "content": "arXiv:2601.17586v1 Announce Type: new  Abstract: Deep learning models in medical image analysis often struggle with generalizability across domains and demographic groups due to data heterogeneity and scarcity. Traditional augmentation improves robustness, but fails under substantial domain shifts. Recent advances in stylistic augmentation enhance domain generalization by varying image styles but fall short in terms of style diversity or by introducing artifacts into the generated images. To address these limitations, we propose Stylizing ViT, a novel Vision Transformer encoder that utilizes weight-shared attention blocks for both self- and cross-attention. This design allows the same attention block to maintain anatomical consistency through self-attention while performing style transfer via cross-attention. We assess the effectiveness of our method for domain generalization by employing it for data augmentation on three distinct image classification tasks in the context of histopathology and dermatology. Results demonstrate an improved robustness (up to +13% accuracy) over the state of the art while generating perceptually convincing images without artifacts. Additionally, we show that Stylizing ViT is effective beyond training, achieving a 17% performance improvement during inference when used for test-time augmentation. The source code is available at https://github.com/sdoerrich97/stylizing-vit .",
      "url": "http://arxiv.org/abs/2601.17586",
      "author": "Sebastian Doerrich, Francesco Di Salvo, Jonas Alle, Christian Ledig",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes Stylizing ViT, a Vision Transformer that uses weight-shared attention blocks for both self- and cross-attention to enable domain generalization in medical imaging through instance-level style transfer while preserving anatomical structures.",
      "importance_score": 45,
      "reasoning": "Incremental improvement for medical image domain adaptation. Uses established ViT architectures with style transfer approach.",
      "themes": [
        "Medical Imaging",
        "Domain Generalization",
        "Vision Transformers"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Stylizing ViT, a Vision Transformer that uses weight-shared attention blocks for both self- and cross-attention to enable domain generalization in medical imaging through instance-level style transfer while preserving anatomical structures.</p>",
      "content_html": "<p>arXiv:2601.17586v1 Announce Type: new  Abstract: Deep learning models in medical image analysis often struggle with generalizability across domains and demographic groups due to data heterogeneity and scarcity. Traditional augmentation improves robustness, but fails under substantial domain shifts. Recent advances in stylistic augmentation enhance domain generalization by varying image styles but fall short in terms of style diversity or by introducing artifacts into the generated images. To address these limitations, we propose Stylizing ViT, a novel Vision Transformer encoder that utilizes weight-shared attention blocks for both self- and cross-attention. This design allows the same attention block to maintain anatomical consistency through self-attention while performing style transfer via cross-attention. We assess the effectiveness of our method for domain generalization by employing it for data augmentation on three distinct image classification tasks in the context of histopathology and dermatology. Results demonstrate an improved robustness (up to +13% accuracy) over the state of the art while generating perceptually convincing images without artifacts. Additionally, we show that Stylizing ViT is effective beyond training, achieving a 17% performance improvement during inference when used for test-time augmentation. The source code is available at https://github.com/sdoerrich97/stylizing-vit .</p>"
    },
    {
      "id": "6561dc82ed4f",
      "title": "Learning Sewing Patterns via Latent Flow Matching of Implicit Fields",
      "content": "arXiv:2601.17740v1 Announce Type: new  Abstract: Sewing patterns define the structural foundation of garments and are essential for applications such as fashion design, fabrication, and physical simulation. Despite progress in automated pattern generation, accurately modeling sewing patterns remains difficult due to the broad variability in panel geometry and seam arrangements. In this work, we introduce a sewing pattern modeling method based on an implicit representation. We represent each panel using a signed distance field that defines its boundary and an unsigned distance field that identifies seam endpoints, and encode these fields into a continuous latent space that enables differentiable meshing. A latent flow matching model learns distributions over panel combinations in this representation, and a stitching prediction module recovers seam relations from extracted edge segments. This formulation allows accurate modeling and generation of sewing patterns with complex structures. We further show that it can be used to estimate sewing patterns from images with improved accuracy relative to existing approaches, and supports applications such as pattern completion and refitting, providing a practical tool for digital fashion design.",
      "url": "http://arxiv.org/abs/2601.17740",
      "author": "Cong Cao, Ren Li, Corentin Dumery, Hao Li",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents a sewing pattern generation method using implicit representation with signed/unsigned distance fields encoded into a continuous latent space, combined with flow matching to learn distributions over panel combinations.",
      "importance_score": 45,
      "reasoning": "Creative application of modern generative techniques to garment design. Niche but technically interesting.",
      "themes": [
        "Generative Models",
        "Flow Matching",
        "Fashion Design"
      ],
      "continuation": null,
      "summary_html": "<p>Presents a sewing pattern generation method using implicit representation with signed/unsigned distance fields encoded into a continuous latent space, combined with flow matching to learn distributions over panel combinations.</p>",
      "content_html": "<p>arXiv:2601.17740v1 Announce Type: new  Abstract: Sewing patterns define the structural foundation of garments and are essential for applications such as fashion design, fabrication, and physical simulation. Despite progress in automated pattern generation, accurately modeling sewing patterns remains difficult due to the broad variability in panel geometry and seam arrangements. In this work, we introduce a sewing pattern modeling method based on an implicit representation. We represent each panel using a signed distance field that defines its boundary and an unsigned distance field that identifies seam endpoints, and encode these fields into a continuous latent space that enables differentiable meshing. A latent flow matching model learns distributions over panel combinations in this representation, and a stitching prediction module recovers seam relations from extracted edge segments. This formulation allows accurate modeling and generation of sewing patterns with complex structures. We further show that it can be used to estimate sewing patterns from images with improved accuracy relative to existing approaches, and supports applications such as pattern completion and refitting, providing a practical tool for digital fashion design.</p>"
    },
    {
      "id": "9abb7585832b",
      "title": "DTC: A Deformable Transposed Convolution Module for Medical Image Segmentation",
      "content": "arXiv:2601.17939v1 Announce Type: new  Abstract: In medical image segmentation, particularly in UNet-like architectures, upsampling is primarily used to transform smaller feature maps into larger ones, enabling feature fusion between encoder and decoder features and supporting multi-scale prediction. Conventional upsampling methods, such as transposed convolution and linear interpolation, operate on fixed positions: transposed convolution applies kernel elements to predetermined pixel or voxel locations, while linear interpolation assigns values based on fixed coordinates in the original feature map. These fixed-position approaches may fail to capture structural information beyond predefined sampling positions and can lead to artifacts or loss of detail. Inspired by deformable convolutions, we propose a novel upsampling method, Deformable Transposed Convolution (DTC), which learns dynamic coordinates (i.e., sampling positions) to generate high-resolution feature maps for both 2D and 3D medical image segmentation tasks. Experiments on 3D (e.g., BTCV15) and 2D datasets (e.g., ISIC18, BUSI) demonstrate that DTC can be effectively integrated into existing medical image segmentation models, consistently improving the decoder's feature reconstruction and detail recovery capability.",
      "url": "http://arxiv.org/abs/2601.17939",
      "author": "Chengkun Sun, Jinqian Pan, Renjie Liang, Zhengkang Fan, Xin Miao, Jiang Bian, Jie Xu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "DTC introduces deformable transposed convolution for medical image segmentation, allowing adaptive sampling positions during upsampling to better capture structural information in UNet-like architectures.",
      "importance_score": 45,
      "reasoning": "Incremental improvement to upsampling in medical segmentation. Extends deformable convolution concept.",
      "themes": [
        "Medical Imaging",
        "Segmentation",
        "Network Architecture"
      ],
      "continuation": null,
      "summary_html": "<p>DTC introduces deformable transposed convolution for medical image segmentation, allowing adaptive sampling positions during upsampling to better capture structural information in UNet-like architectures.</p>",
      "content_html": "<p>arXiv:2601.17939v1 Announce Type: new  Abstract: In medical image segmentation, particularly in UNet-like architectures, upsampling is primarily used to transform smaller feature maps into larger ones, enabling feature fusion between encoder and decoder features and supporting multi-scale prediction. Conventional upsampling methods, such as transposed convolution and linear interpolation, operate on fixed positions: transposed convolution applies kernel elements to predetermined pixel or voxel locations, while linear interpolation assigns values based on fixed coordinates in the original feature map. These fixed-position approaches may fail to capture structural information beyond predefined sampling positions and can lead to artifacts or loss of detail. Inspired by deformable convolutions, we propose a novel upsampling method, Deformable Transposed Convolution (DTC), which learns dynamic coordinates (i.e., sampling positions) to generate high-resolution feature maps for both 2D and 3D medical image segmentation tasks. Experiments on 3D (e.g., BTCV15) and 2D datasets (e.g., ISIC18, BUSI) demonstrate that DTC can be effectively integrated into existing medical image segmentation models, consistently improving the decoder's feature reconstruction and detail recovery capability.</p>"
    },
    {
      "id": "cbfd89cdf26e",
      "title": "Strip-Fusion: Spatiotemporal Fusion for Multispectral Pedestrian Detection",
      "content": "arXiv:2601.18008v1 Announce Type: new  Abstract: Pedestrian detection is a critical task in robot perception. Multispectral modalities (visible light and thermal) can boost pedestrian detection performance by providing complementary visual information. Several gaps remain with multispectral pedestrian detection methods. First, existing approaches primarily focus on spatial fusion and often neglect temporal information. Second, RGB and thermal image pairs in multispectral benchmarks may not always be perfectly aligned. Pedestrians are also challenging to detect due to varying lighting conditions, occlusion, etc. This work proposes Strip-Fusion, a spatial-temporal fusion network that is robust to misalignment in input images, as well as varying lighting conditions and heavy occlusions. The Strip-Fusion pipeline integrates temporally adaptive convolutions to dynamically weigh spatial-temporal features, enabling our model to better capture pedestrian motion and context over time. A novel Kullback-Leibler divergence loss was designed to mitigate modality imbalance between visible and thermal inputs, guiding feature alignment toward the more informative modality during training. Furthermore, a novel post-processing algorithm was developed to reduce false positives. Extensive experimental results show that our method performs competitively for both the KAIST and the CVC-14 benchmarks. We also observed significant improvements compared to previous state-of-the-art on challenging conditions such as heavy occlusion and misalignment.",
      "url": "http://arxiv.org/abs/2601.18008",
      "author": "Asiegbu Miracle Kanu-Asiegbu, Nitin Jotwani, Xiaoxiao Du",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Strip-Fusion proposes spatial-temporal fusion network for multispectral pedestrian detection that is robust to misalignment between RGB and thermal images and handles varying lighting conditions.",
      "importance_score": 45,
      "reasoning": "Addresses practical problems in multispectral detection but incremental improvement.",
      "themes": [
        "Pedestrian Detection",
        "Multimodal Fusion",
        "Thermal Imaging"
      ],
      "continuation": null,
      "summary_html": "<p>Strip-Fusion proposes spatial-temporal fusion network for multispectral pedestrian detection that is robust to misalignment between RGB and thermal images and handles varying lighting conditions.</p>",
      "content_html": "<p>arXiv:2601.18008v1 Announce Type: new  Abstract: Pedestrian detection is a critical task in robot perception. Multispectral modalities (visible light and thermal) can boost pedestrian detection performance by providing complementary visual information. Several gaps remain with multispectral pedestrian detection methods. First, existing approaches primarily focus on spatial fusion and often neglect temporal information. Second, RGB and thermal image pairs in multispectral benchmarks may not always be perfectly aligned. Pedestrians are also challenging to detect due to varying lighting conditions, occlusion, etc. This work proposes Strip-Fusion, a spatial-temporal fusion network that is robust to misalignment in input images, as well as varying lighting conditions and heavy occlusions. The Strip-Fusion pipeline integrates temporally adaptive convolutions to dynamically weigh spatial-temporal features, enabling our model to better capture pedestrian motion and context over time. A novel Kullback-Leibler divergence loss was designed to mitigate modality imbalance between visible and thermal inputs, guiding feature alignment toward the more informative modality during training. Furthermore, a novel post-processing algorithm was developed to reduce false positives. Extensive experimental results show that our method performs competitively for both the KAIST and the CVC-14 benchmarks. We also observed significant improvements compared to previous state-of-the-art on challenging conditions such as heavy occlusion and misalignment.</p>"
    },
    {
      "id": "658a48f0118a",
      "title": "Cross-Domain Transfer with Self-Supervised Spectral-Spatial Modeling for Hyperspectral Image Classification",
      "content": "arXiv:2601.18088v1 Announce Type: new  Abstract: Self-supervised learning has demonstrated considerable potential in hyperspectral representation, yet its application in cross-domain transfer scenarios remains under-explored. Existing methods, however, still rely on source domain annotations and are susceptible to distribution shifts, leading to degraded generalization performance in the target domain. To address this, this paper proposes a self-supervised cross-domain transfer framework that learns transferable spectral-spatial joint representations without source labels and achieves efficient adaptation under few samples in the target domain. During the self-supervised pre-training phase, a Spatial-Spectral Transformer (S2Former) module is designed. It adopts a dual-branch spatial-spectral transformer and introduces a bidirectional cross-attention mechanism to achieve spectral-spatial collaborative modeling: the spatial branch enhances structural awareness through random masking, while the spectral branch captures fine-grained differences. Both branches mutually guide each other to improve semantic consistency. We further propose a Frequency Domain Constraint (FDC) to maintain frequency-domain consistency through real Fast Fourier Transform (rFFT) and high-frequency magnitude loss, thereby enhancing the model's capability to discern fine details and boundaries. During the fine-tuning phase, we introduce a Diffusion-Aligned Fine-tuning (DAFT) distillation mechanism. This aligns semantic evolution trajectories through a teacher-student structure, enabling robust transfer learning under low-label conditions. Experimental results demonstrate stable classification performance and strong cross-domain adaptability across four hyperspectral datasets, validating the method's effectiveness under resource-constrained conditions.",
      "url": "http://arxiv.org/abs/2601.18088",
      "author": "Jianshu Chao, Tianhua Lv, Qiqiong Ma, Yunfei Qiu, Li Fang, Huifang Shen, Wei Yao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces self-supervised cross-domain transfer framework for hyperspectral classification that learns transferable spectral-spatial representations without source labels using Spatial-Spectral Transformer.",
      "importance_score": 45,
      "reasoning": "Addresses practical domain shift problem in hyperspectral imaging. Standard self-supervised approach.",
      "themes": [
        "Hyperspectral Imaging",
        "Self-Supervised Learning",
        "Domain Adaptation"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces self-supervised cross-domain transfer framework for hyperspectral classification that learns transferable spectral-spatial representations without source labels using Spatial-Spectral Transformer.</p>",
      "content_html": "<p>arXiv:2601.18088v1 Announce Type: new  Abstract: Self-supervised learning has demonstrated considerable potential in hyperspectral representation, yet its application in cross-domain transfer scenarios remains under-explored. Existing methods, however, still rely on source domain annotations and are susceptible to distribution shifts, leading to degraded generalization performance in the target domain. To address this, this paper proposes a self-supervised cross-domain transfer framework that learns transferable spectral-spatial joint representations without source labels and achieves efficient adaptation under few samples in the target domain. During the self-supervised pre-training phase, a Spatial-Spectral Transformer (S2Former) module is designed. It adopts a dual-branch spatial-spectral transformer and introduces a bidirectional cross-attention mechanism to achieve spectral-spatial collaborative modeling: the spatial branch enhances structural awareness through random masking, while the spectral branch captures fine-grained differences. Both branches mutually guide each other to improve semantic consistency. We further propose a Frequency Domain Constraint (FDC) to maintain frequency-domain consistency through real Fast Fourier Transform (rFFT) and high-frequency magnitude loss, thereby enhancing the model's capability to discern fine details and boundaries. During the fine-tuning phase, we introduce a Diffusion-Aligned Fine-tuning (DAFT) distillation mechanism. This aligns semantic evolution trajectories through a teacher-student structure, enabling robust transfer learning under low-label conditions. Experimental results demonstrate stable classification performance and strong cross-domain adaptability across four hyperspectral datasets, validating the method's effectiveness under resource-constrained conditions.</p>"
    },
    {
      "id": "c6ddf3a03e9e",
      "title": "TempDiffReg: Temporal Diffusion Model for Non-Rigid 2D-3D Vascular Registration",
      "content": "arXiv:2601.18168v1 Announce Type: new  Abstract: Transarterial chemoembolization (TACE) is a preferred treatment option for hepatocellular carcinoma and other liver malignancies, yet it remains a highly challenging procedure due to complex intra-operative vascular navigation and anatomical variability. Accurate and robust 2D-3D vessel registration is essential to guide microcatheter and instruments during TACE, enabling precise localization of vascular structures and optimal therapeutic targeting. To tackle this issue, we develop a coarse-to-fine registration strategy. First, we introduce a global alignment module, structure-aware perspective n-point (SA-PnP), to establish correspondence between 2D and 3D vessel structures. Second, we propose TempDiffReg, a temporal diffusion model that performs vessel deformation iteratively by leveraging temporal context to capture complex anatomical variations and local structural changes. We collected data from 23 patients and constructed 626 paired multi-frame samples for comprehensive evaluation. Experimental results demonstrate that the proposed method consistently outperforms state-of-the-art (SOTA) methods in both accuracy and anatomical plausibility. Specifically, our method achieves a mean squared error (MSE) of 0.63 mm and a mean absolute error (MAE) of 0.51 mm in registration accuracy, representing 66.7\\% lower MSE and 17.7\\% lower MAE compared to the most competitive existing approaches. It has the potential to assist less-experienced clinicians in safely and efficiently performing complex TACE procedures, ultimately enhancing both surgical outcomes and patient care. Code and data are available at: \\textcolor{blue}{https://github.com/LZH970328/TempDiffReg.git}",
      "url": "http://arxiv.org/abs/2601.18168",
      "author": "Zehua Liu, Shihao Zou, Jincai Huang, Yanfang Zhang, Chao Tong, Weixin Si",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "TempDiffReg proposes temporal diffusion model for non-rigid 2D-3D vascular registration in liver interventions, using coarse-to-fine strategy with structure-aware perspective n-point alignment.",
      "importance_score": 45,
      "reasoning": "Domain-specific medical imaging application. Applies diffusion to registration problem.",
      "themes": [
        "Medical Imaging",
        "Image Registration",
        "Diffusion Models"
      ],
      "continuation": null,
      "summary_html": "<p>TempDiffReg proposes temporal diffusion model for non-rigid 2D-3D vascular registration in liver interventions, using coarse-to-fine strategy with structure-aware perspective n-point alignment.</p>",
      "content_html": "<p>arXiv:2601.18168v1 Announce Type: new  Abstract: Transarterial chemoembolization (TACE) is a preferred treatment option for hepatocellular carcinoma and other liver malignancies, yet it remains a highly challenging procedure due to complex intra-operative vascular navigation and anatomical variability. Accurate and robust 2D-3D vessel registration is essential to guide microcatheter and instruments during TACE, enabling precise localization of vascular structures and optimal therapeutic targeting. To tackle this issue, we develop a coarse-to-fine registration strategy. First, we introduce a global alignment module, structure-aware perspective n-point (SA-PnP), to establish correspondence between 2D and 3D vessel structures. Second, we propose TempDiffReg, a temporal diffusion model that performs vessel deformation iteratively by leveraging temporal context to capture complex anatomical variations and local structural changes. We collected data from 23 patients and constructed 626 paired multi-frame samples for comprehensive evaluation. Experimental results demonstrate that the proposed method consistently outperforms state-of-the-art (SOTA) methods in both accuracy and anatomical plausibility. Specifically, our method achieves a mean squared error (MSE) of 0.63 mm and a mean absolute error (MAE) of 0.51 mm in registration accuracy, representing 66.7\\% lower MSE and 17.7\\% lower MAE compared to the most competitive existing approaches. It has the potential to assist less-experienced clinicians in safely and efficiently performing complex TACE procedures, ultimately enhancing both surgical outcomes and patient care. Code and data are available at: \\textcolor{blue}{https://github.com/LZH970328/TempDiffReg.git}</p>"
    },
    {
      "id": "23edecf9f39b",
      "title": "Contextual Range-View Projection for 3D LiDAR Point Clouds",
      "content": "arXiv:2601.18301v1 Announce Type: new  Abstract: Range-view projection provides an efficient method for transforming 3D LiDAR point clouds into 2D range image representations, enabling effective processing with 2D deep learning models. However, a major challenge in this projection is the many-to-one conflict, where multiple 3D points are mapped onto the same pixel in the range image, requiring a selection strategy. Existing approaches typically retain the point with the smallest depth (closest to the LiDAR), disregarding semantic relevance and object structure, which leads to the loss of important contextual information. In this paper, we extend the depth-based selection rule by incorporating contextual information from both instance centers and class labels, introducing two mechanisms: \\textit{Centerness-Aware Projection (CAP)} and \\textit{Class-Weighted-Aware Projection (CWAP)}. In CAP, point depths are adjusted according to their distance from the instance center, thereby prioritizing central instance points over noisy boundary and background points. In CWAP, object classes are prioritized through user-defined weights, offering flexibility in the projection strategy. Our evaluations on the SemanticKITTI dataset show that CAP preserves more instance points during projection, achieving up to a 3.1\\% mIoU improvement compared to the baseline. Furthermore, CWAP enhances the performance of targeted classes while having a negligible impact on the performance of other classes",
      "url": "http://arxiv.org/abs/2601.18301",
      "author": "Seyedali Mousavi, Seyedhamidreza Mousavi, Masoud Daneshtalab",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Extends depth-based point selection in LiDAR range-view projection by incorporating contextual information from instance centers and class labels to address many-to-one mapping conflicts.",
      "importance_score": 45,
      "reasoning": "Practical improvement for LiDAR processing. Simple but effective context-aware approach.",
      "themes": [
        "LiDAR",
        "Point Cloud Processing",
        "Autonomous Driving"
      ],
      "continuation": null,
      "summary_html": "<p>Extends depth-based point selection in LiDAR range-view projection by incorporating contextual information from instance centers and class labels to address many-to-one mapping conflicts.</p>",
      "content_html": "<p>arXiv:2601.18301v1 Announce Type: new  Abstract: Range-view projection provides an efficient method for transforming 3D LiDAR point clouds into 2D range image representations, enabling effective processing with 2D deep learning models. However, a major challenge in this projection is the many-to-one conflict, where multiple 3D points are mapped onto the same pixel in the range image, requiring a selection strategy. Existing approaches typically retain the point with the smallest depth (closest to the LiDAR), disregarding semantic relevance and object structure, which leads to the loss of important contextual information. In this paper, we extend the depth-based selection rule by incorporating contextual information from both instance centers and class labels, introducing two mechanisms: \\textit{Centerness-Aware Projection (CAP)} and \\textit{Class-Weighted-Aware Projection (CWAP)}. In CAP, point depths are adjusted according to their distance from the instance center, thereby prioritizing central instance points over noisy boundary and background points. In CWAP, object classes are prioritized through user-defined weights, offering flexibility in the projection strategy. Our evaluations on the SemanticKITTI dataset show that CAP preserves more instance points during projection, achieving up to a 3.1\\% mIoU improvement compared to the baseline. Furthermore, CWAP enhances the performance of targeted classes while having a negligible impact on the performance of other classes</p>"
    },
    {
      "id": "6225065b1111",
      "title": "REMAC: Reference-Based Martian Asymmetrical Image Compression",
      "content": "arXiv:2601.18547v1 Announce Type: new  Abstract: To expedite space exploration on Mars, it is indispensable to develop an efficient Martian image compression method for transmitting images through the constrained Mars-to-Earth communication channel. Although the existing learned compression methods have achieved promising results for natural images from earth, there remain two critical issues that hinder their effectiveness for Martian image compression: 1) They overlook the highly-limited computational resources on Mars; 2) They do not utilize the strong \\textit{inter-image} similarities across Martian images to advance image compression performance. Motivated by our empirical analysis of the strong \\textit{intra-} and \\textit{inter-image} similarities from the perspective of texture, color, and semantics, we propose a reference-based Martian asymmetrical image compression (REMAC) approach, which shifts computational complexity from the encoder to the resource-rich decoder and simultaneously improves compression performance. To leverage \\textit{inter-image} similarities, we propose a reference-guided entropy module and a ref-decoder that utilize useful information from reference images, reducing redundant operations at the encoder and achieving superior compression performance. To exploit \\textit{intra-image} similarities, the ref-decoder adopts a deep, multi-scale architecture with enlarged receptive field size to model long-range spatial dependencies. Additionally, we develop a latent feature recycling mechanism to further alleviate the extreme computational constraints on Mars. Experimental results show that REMAC reduces encoder complexity by 43.51\\% compared to the state-of-the-art method, while achieving a BD-PSNR gain of 0.2664 dB.",
      "url": "http://arxiv.org/abs/2601.18547",
      "author": "Qing Ding, Mai Xu, Shengxi Li, Xin Deng, Xin Zou",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "REMAC develops efficient Martian image compression exploiting strong intra- and inter-image similarities in texture, color, and structure, addressing computational constraints on Mars.",
      "importance_score": 45,
      "reasoning": "Novel space exploration application. Addresses real constraint but very specialized domain.",
      "themes": [
        "Image Compression",
        "Space Exploration",
        "Edge Computing"
      ],
      "continuation": null,
      "summary_html": "<p>REMAC develops efficient Martian image compression exploiting strong intra- and inter-image similarities in texture, color, and structure, addressing computational constraints on Mars.</p>",
      "content_html": "<p>arXiv:2601.18547v1 Announce Type: new  Abstract: To expedite space exploration on Mars, it is indispensable to develop an efficient Martian image compression method for transmitting images through the constrained Mars-to-Earth communication channel. Although the existing learned compression methods have achieved promising results for natural images from earth, there remain two critical issues that hinder their effectiveness for Martian image compression: 1) They overlook the highly-limited computational resources on Mars; 2) They do not utilize the strong \\textit{inter-image} similarities across Martian images to advance image compression performance. Motivated by our empirical analysis of the strong \\textit{intra-} and \\textit{inter-image} similarities from the perspective of texture, color, and semantics, we propose a reference-based Martian asymmetrical image compression (REMAC) approach, which shifts computational complexity from the encoder to the resource-rich decoder and simultaneously improves compression performance. To leverage \\textit{inter-image} similarities, we propose a reference-guided entropy module and a ref-decoder that utilize useful information from reference images, reducing redundant operations at the encoder and achieving superior compression performance. To exploit \\textit{intra-image} similarities, the ref-decoder adopts a deep, multi-scale architecture with enlarged receptive field size to model long-range spatial dependencies. Additionally, we develop a latent feature recycling mechanism to further alleviate the extreme computational constraints on Mars. Experimental results show that REMAC reduces encoder complexity by 43.51\\% compared to the state-of-the-art method, while achieving a BD-PSNR gain of 0.2664 dB.</p>"
    },
    {
      "id": "ae7d0efca0bc",
      "title": "Automated Landmark Detection for assessing hip conditions: A Cross-Modality Validation of MRI versus X-ray",
      "content": "arXiv:2601.18555v1 Announce Type: new  Abstract: Many clinical screening decisions are based on angle measurements. In particular, FemoroAcetabular Impingement (FAI) screening relies on angles traditionally measured on X-rays. However, assessing the height and span of the impingement area requires also a 3D view through an MRI scan. The two modalities inform the surgeon on different aspects of the condition. In this work, we conduct a matched-cohort validation study (89 patients, paired MRI/X-ray) using standard heatmap regression architectures to assess cross-modality clinical equivalence. Seen that landmark detection has been proven effective on X-rays, we show that MRI also achieves equivalent localisation and diagnostic accuracy for cam-type impingement. Our method demonstrates clinical feasibility for FAI assessment in coronal views of 3D MRI volumes, opening the possibility for volumetric analysis through placing further landmarks. These results support integrating automated FAI assessment into routine MRI workflows. Code is released at https://github.com/Malga-Vision/Landmarks-Hip-Conditions",
      "url": "http://arxiv.org/abs/2601.18555",
      "author": "Roberto Di Via, Vito Paolo Pastore, Francesca Odone, Si\\^on Glyn-Jones, Irina Voiculescu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Conducts matched-cohort validation study comparing automated landmark detection on MRI versus X-ray for hip condition assessment, demonstrating clinical equivalence for cam-type impingement.",
      "importance_score": 45,
      "reasoning": "Practical clinical validation study. Important for medical adoption but incremental research.",
      "themes": [
        "Medical Imaging",
        "Landmark Detection",
        "Clinical Validation"
      ],
      "continuation": null,
      "summary_html": "<p>Conducts matched-cohort validation study comparing automated landmark detection on MRI versus X-ray for hip condition assessment, demonstrating clinical equivalence for cam-type impingement.</p>",
      "content_html": "<p>arXiv:2601.18555v1 Announce Type: new  Abstract: Many clinical screening decisions are based on angle measurements. In particular, FemoroAcetabular Impingement (FAI) screening relies on angles traditionally measured on X-rays. However, assessing the height and span of the impingement area requires also a 3D view through an MRI scan. The two modalities inform the surgeon on different aspects of the condition. In this work, we conduct a matched-cohort validation study (89 patients, paired MRI/X-ray) using standard heatmap regression architectures to assess cross-modality clinical equivalence. Seen that landmark detection has been proven effective on X-rays, we show that MRI also achieves equivalent localisation and diagnostic accuracy for cam-type impingement. Our method demonstrates clinical feasibility for FAI assessment in coronal views of 3D MRI volumes, opening the possibility for volumetric analysis through placing further landmarks. These results support integrating automated FAI assessment into routine MRI workflows. Code is released at https://github.com/Malga-Vision/Landmarks-Hip-Conditions</p>"
    },
    {
      "id": "c7a4b11433e7",
      "title": "Attention-Based Variational Framework for Joint and Individual Components Learning with Applications in Brain Network Analysis",
      "content": "arXiv:2601.17073v1 Announce Type: cross  Abstract: Brain organization is increasingly characterized through multiple imaging modalities, most notably structural connectivity (SC) and functional connectivity (FC). Integrating these inherently distinct yet complementary data sources is essential for uncovering the cross-modal patterns that drive behavioral phenotypes. However, effective integration is hindered by the high dimensionality and non-linearity of connectome data, complex non-linear SC-FC coupling, and the challenge of disentangling shared information from modality-specific variations. To address these issues, we propose the Cross-Modal Joint-Individual Variational Network (CM-JIVNet), a unified probabilistic framework designed to learn factorized latent representations from paired SC-FC datasets. Our model utilizes a multi-head attention fusion module to capture non-linear cross-modal dependencies while isolating independent, modality-specific signals. Validated on Human Connectome Project Young Adult (HCP-YA) data, CM-JIVNet demonstrates superior performance in cross-modal reconstruction and behavioral trait prediction. By effectively disentangling joint and individual feature spaces, CM-JIVNet provides a robust, interpretable, and scalable solution for large-scale multimodal brain analysis.",
      "url": "http://arxiv.org/abs/2601.17073",
      "author": "Yifei Zhang, Meimei Liu, Zhengwu Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes CM-JIVNet, a variational framework for learning joint and modality-specific latent representations from paired brain connectivity data (structural and functional connectivity).",
      "importance_score": 45,
      "reasoning": "Useful methodology for neuroscience applications but primarily domain-specific with limited broader ML impact.",
      "themes": [
        "Neuroscience",
        "Variational Methods",
        "Multimodal Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes CM-JIVNet, a variational framework for learning joint and modality-specific latent representations from paired brain connectivity data (structural and functional connectivity).</p>",
      "content_html": "<p>arXiv:2601.17073v1 Announce Type: cross  Abstract: Brain organization is increasingly characterized through multiple imaging modalities, most notably structural connectivity (SC) and functional connectivity (FC). Integrating these inherently distinct yet complementary data sources is essential for uncovering the cross-modal patterns that drive behavioral phenotypes. However, effective integration is hindered by the high dimensionality and non-linearity of connectome data, complex non-linear SC-FC coupling, and the challenge of disentangling shared information from modality-specific variations. To address these issues, we propose the Cross-Modal Joint-Individual Variational Network (CM-JIVNet), a unified probabilistic framework designed to learn factorized latent representations from paired SC-FC datasets. Our model utilizes a multi-head attention fusion module to capture non-linear cross-modal dependencies while isolating independent, modality-specific signals. Validated on Human Connectome Project Young Adult (HCP-YA) data, CM-JIVNet demonstrates superior performance in cross-modal reconstruction and behavioral trait prediction. By effectively disentangling joint and individual feature spaces, CM-JIVNet provides a robust, interpretable, and scalable solution for large-scale multimodal brain analysis.</p>"
    },
    {
      "id": "7a627907cbe1",
      "title": "Real-Time Synchronized Interaction Framework for Emotion-Aware Humanoid Robots",
      "content": "arXiv:2601.17287v1 Announce Type: new  Abstract: As humanoid robots increasingly introduced into social scene, achieving emotionally synchronized multimodal interaction remains a significant challenges. To facilitate the further adoption and integration of humanoid robots into service roles, we present a real-time framework for NAO robots that synchronizes speech prosody with full-body gestures through three key innovations: (1) A dual-channel emotion engine where large language model (LLM) simultaneously generates context-aware text responses and biomechanically feasible motion descriptors, constrained by a structured joint movement library; (2) Duration-aware dynamic time warping for precise temporal alignment of speech output and kinematic motion keyframes; (3) Closed-loop feasibility verification ensuring gestures adhere to NAO's physical joint limits through real-time adaptation. Evaluations show 21% higher emotional alignment compared to rule-based systems, achieved by coordinating vocal pitch (arousal-driven) with upper-limb kinematics while maintaining lower-body stability. By enabling seamless sensorimotor coordination, this framework advances the deployment of context-aware social robots in dynamic applications such as personalized healthcare, interactive education, and responsive customer service platforms.",
      "url": "http://arxiv.org/abs/2601.17287",
      "author": "Yanrong Chen, Xihan Bian",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents real-time framework for NAO robots synchronizing speech prosody with gestures using LLM-generated motion descriptors and dynamic time warping.",
      "importance_score": 45,
      "reasoning": "Applied HRI system with LLM integration but limited novelty in individual components.",
      "themes": [
        "Human-Robot Interaction",
        "Social Robotics",
        "LLM Applications"
      ],
      "continuation": null,
      "summary_html": "<p>Presents real-time framework for NAO robots synchronizing speech prosody with gestures using LLM-generated motion descriptors and dynamic time warping.</p>",
      "content_html": "<p>arXiv:2601.17287v1 Announce Type: new  Abstract: As humanoid robots increasingly introduced into social scene, achieving emotionally synchronized multimodal interaction remains a significant challenges. To facilitate the further adoption and integration of humanoid robots into service roles, we present a real-time framework for NAO robots that synchronizes speech prosody with full-body gestures through three key innovations: (1) A dual-channel emotion engine where large language model (LLM) simultaneously generates context-aware text responses and biomechanically feasible motion descriptors, constrained by a structured joint movement library; (2) Duration-aware dynamic time warping for precise temporal alignment of speech output and kinematic motion keyframes; (3) Closed-loop feasibility verification ensuring gestures adhere to NAO's physical joint limits through real-time adaptation. Evaluations show 21% higher emotional alignment compared to rule-based systems, achieved by coordinating vocal pitch (arousal-driven) with upper-limb kinematics while maintaining lower-body stability. By enabling seamless sensorimotor coordination, this framework advances the deployment of context-aware social robots in dynamic applications such as personalized healthcare, interactive education, and responsive customer service platforms.</p>"
    },
    {
      "id": "3c2e9183c12b",
      "title": "Out-of-Distribution Radar Detection with Complex VAEs: Theory, Whitening, and ANMF Fusion",
      "content": "arXiv:2601.18677v1 Announce Type: new  Abstract: We investigate the detection of weak complex-valued signals immersed in non-Gaussian, range-varying interference, with emphasis on maritime radar scenarios. The proposed methodology exploits a Complex-valued Variational AutoEncoder (CVAE) trained exclusively on clutter-plus-noise to perform Out-Of-Distribution detection. By operating directly on in-phase / quadrature samples, the CVAE preserves phase and Doppler structure and is assessed in two configurations: (i) using unprocessed range profiles and (ii) after local whitening, where per-range covariance estimates are obtained from neighboring profiles. Using extensive simulations together with real sea-clutter data from the CSIR maritime dataset, we benchmark performance against classical and adaptive detectors (MF, NMF, AMF-SCM, ANMF-SCM, ANMF-Tyler). In both configurations, the CVAE yields a higher detection probability Pd at matched false-alarm rate Pfa, with the most notable improvements observed under whitening. We further integrate the CVAE with the ANMF through a weighted log-p fusion rule at the decision level, attaining enhanced robustness in strongly non-Gaussian clutter and enabling empirically calibrated Pfa control under H0. Overall, the results demonstrate that statistical normalization combined with complex-valued generative modeling substantively improves detection in realistic sea-clutter conditions, and that the fused CVAE-ANMF scheme constitutes a competitive alternative to established model-based detectors.",
      "url": "http://arxiv.org/abs/2601.18677",
      "author": "Yadang Alexis Rouzoumka, Jean Pinsolle, Eug\\'enie Terreaux, Christ\\`ele Morisseau, Jean-Philippe Ovarlez, Chengfang Ren",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "stat.ML"
      ],
      "summary": "Investigates OOD detection for radar using Complex VAEs trained on clutter-plus-noise, with local whitening preprocessing and ANMF fusion.",
      "importance_score": 45,
      "reasoning": "Applied ML for radar detection, useful domain contribution but limited broader impact.",
      "themes": [
        "Anomaly Detection",
        "Radar",
        "VAEs"
      ],
      "continuation": null,
      "summary_html": "<p>Investigates OOD detection for radar using Complex VAEs trained on clutter-plus-noise, with local whitening preprocessing and ANMF fusion.</p>",
      "content_html": "<p>arXiv:2601.18677v1 Announce Type: new  Abstract: We investigate the detection of weak complex-valued signals immersed in non-Gaussian, range-varying interference, with emphasis on maritime radar scenarios. The proposed methodology exploits a Complex-valued Variational AutoEncoder (CVAE) trained exclusively on clutter-plus-noise to perform Out-Of-Distribution detection. By operating directly on in-phase / quadrature samples, the CVAE preserves phase and Doppler structure and is assessed in two configurations: (i) using unprocessed range profiles and (ii) after local whitening, where per-range covariance estimates are obtained from neighboring profiles. Using extensive simulations together with real sea-clutter data from the CSIR maritime dataset, we benchmark performance against classical and adaptive detectors (MF, NMF, AMF-SCM, ANMF-SCM, ANMF-Tyler). In both configurations, the CVAE yields a higher detection probability Pd at matched false-alarm rate Pfa, with the most notable improvements observed under whitening. We further integrate the CVAE with the ANMF through a weighted log-p fusion rule at the decision level, attaining enhanced robustness in strongly non-Gaussian clutter and enabling empirically calibrated Pfa control under H0. Overall, the results demonstrate that statistical normalization combined with complex-valued generative modeling substantively improves detection in realistic sea-clutter conditions, and that the fused CVAE-ANMF scheme constitutes a competitive alternative to established model-based detectors.</p>"
    },
    {
      "id": "1f30cdd74d5b",
      "title": "Covariate-assisted Grade of Membership Models via Shared Latent Geometry",
      "content": "arXiv:2601.17265v1 Announce Type: cross  Abstract: The grade of membership model is a flexible latent variable model for analyzing multivariate categorical data through individual-level mixed membership scores. In many modern applications, auxiliary covariates are collected alongside responses and encode information about the same latent structure. Traditional approaches to incorporating such covariates typically rely on fully specified joint likelihoods, which are computationally intensive and sensitive to misspecification. We introduce a covariate-assisted grade of membership model that integrates response and covariate information by exploiting their shared low-rank simplex geometry, rather than modeling their joint distribution. We propose a likelihood-free spectral estimation procedure that combines heterogeneous data sources through a balance parameter controlling their relative contribution. To accommodate high-dimensional and heteroskedastic noise, we employ heteroskedastic principal component analysis before performing simplex-based geometric recovery. Our theoretical analysis establishes weaker identifiability conditions than those required in the covariate-free model, and further derives finite-sample, entrywise error bounds for both mixed membership scores and item parameters. These results demonstrate that auxiliary covariates can provably improve latent structure recovery, yielding faster convergence rates in high-dimensional regimes. Simulation studies and an application to educational assessment data illustrate the computational efficiency, statistical accuracy, and interpretability gains of the proposed method. The code for reproducing these results is open-source and available at \\texttt{https://github.com/Toby-X/Covariate-Assisted-GoM}",
      "url": "http://arxiv.org/abs/2601.17265",
      "author": "Zhiyu Xu, Yuqi Gu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "stat.ME"
      ],
      "summary": "Introduces covariate-assisted grade of membership model integrating response and covariate information through shared simplex geometry with spectral estimation procedure.",
      "importance_score": 45,
      "reasoning": "Methodological contribution to mixed membership models, specialized statistical work.",
      "themes": [
        "Mixed Membership Models",
        "Spectral Methods",
        "Statistical Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces covariate-assisted grade of membership model integrating response and covariate information through shared simplex geometry with spectral estimation procedure.</p>",
      "content_html": "<p>arXiv:2601.17265v1 Announce Type: cross  Abstract: The grade of membership model is a flexible latent variable model for analyzing multivariate categorical data through individual-level mixed membership scores. In many modern applications, auxiliary covariates are collected alongside responses and encode information about the same latent structure. Traditional approaches to incorporating such covariates typically rely on fully specified joint likelihoods, which are computationally intensive and sensitive to misspecification. We introduce a covariate-assisted grade of membership model that integrates response and covariate information by exploiting their shared low-rank simplex geometry, rather than modeling their joint distribution. We propose a likelihood-free spectral estimation procedure that combines heterogeneous data sources through a balance parameter controlling their relative contribution. To accommodate high-dimensional and heteroskedastic noise, we employ heteroskedastic principal component analysis before performing simplex-based geometric recovery. Our theoretical analysis establishes weaker identifiability conditions than those required in the covariate-free model, and further derives finite-sample, entrywise error bounds for both mixed membership scores and item parameters. These results demonstrate that auxiliary covariates can provably improve latent structure recovery, yielding faster convergence rates in high-dimensional regimes. Simulation studies and an application to educational assessment data illustrate the computational efficiency, statistical accuracy, and interpretability gains of the proposed method. The code for reproducing these results is open-source and available at \\texttt{https://github.com/Toby-X/Covariate-Assisted-GoM}</p>"
    },
    {
      "id": "123447e69d06",
      "title": "Learning Transferable Skills in Action RPGs via Directed Skill Graphs and Selective Adaptation",
      "content": "arXiv:2601.17923v1 Announce Type: new  Abstract: Lifelong agents should expand their competence over time without retraining from scratch or overwriting previously learned behaviors. We investigate this in a challenging real-time control setting (Dark Souls III) by representing combat as a directed skill graph and training its components in a hierarchical curriculum. The resulting agent decomposes control into five reusable skills: camera control, target lock-on, movement, dodging, and a heal-attack decision policy, each optimized for a narrow responsibility. This factorization improves sample efficiency by reducing the burden on any single policy and supports selective post-training: when the environment shifts from Phase 1 to Phase 2, only a subset of skills must be adapted, while upstream skills remain transferable. Empirically, we find that targeted fine-tuning of just two skills rapidly recovers performance under a limited interaction budget, suggesting that skill-graph curricula together with selective fine-tuning offer a practical pathway toward evolving, continually learning agents in complex real-time environments.",
      "url": "http://arxiv.org/abs/2601.17923",
      "author": "Ali Najar",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Learns transferable combat skills in Dark Souls III using directed skill graphs and hierarchical curriculum, demonstrating selective adaptation when game phases change.",
      "importance_score": 44,
      "reasoning": "Interesting demonstration of skill transfer in challenging game environment; limited broader applicability.",
      "themes": [
        "Game AI",
        "Reinforcement Learning",
        "Skill Transfer"
      ],
      "continuation": null,
      "summary_html": "<p>Learns transferable combat skills in Dark Souls III using directed skill graphs and hierarchical curriculum, demonstrating selective adaptation when game phases change.</p>",
      "content_html": "<p>arXiv:2601.17923v1 Announce Type: new  Abstract: Lifelong agents should expand their competence over time without retraining from scratch or overwriting previously learned behaviors. We investigate this in a challenging real-time control setting (Dark Souls III) by representing combat as a directed skill graph and training its components in a hierarchical curriculum. The resulting agent decomposes control into five reusable skills: camera control, target lock-on, movement, dodging, and a heal-attack decision policy, each optimized for a narrow responsibility. This factorization improves sample efficiency by reducing the burden on any single policy and supports selective post-training: when the environment shifts from Phase 1 to Phase 2, only a subset of skills must be adapted, while upstream skills remain transferable. Empirically, we find that targeted fine-tuning of just two skills rapidly recovers performance under a limited interaction budget, suggesting that skill-graph curricula together with selective fine-tuning offer a practical pathway toward evolving, continually learning agents in complex real-time environments.</p>"
    },
    {
      "id": "6353be84a247",
      "title": "Cross-Lingual Probing and Community-Grounded Analysis of Gender Bias in Low-Resource Bengali",
      "content": "arXiv:2601.17764v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have achieved significant success in recent years; yet, issues of intrinsic gender bias persist, especially in non-English languages. Although current research mostly emphasizes English, the linguistic and cultural biases inherent in Global South languages, like Bengali, are little examined. This research seeks to examine the characteristics and magnitude of gender bias in Bengali, evaluating the efficacy of current approaches in identifying and alleviating bias. We use several methods to extract gender-biased utterances, including lexicon-based mining, computational classification models, translation-based comparison analysis, and GPT-based bias creation. Our research indicates that the straight application of English-centric bias detection frameworks to Bengali is severely constrained by language disparities and socio-cultural factors that impact implicit biases. To tackle these difficulties, we executed two field investigations inside rural and low-income areas, gathering authentic insights on gender bias. The findings demonstrate that gender bias in Bengali presents distinct characteristics relative to English, requiring a more localized and context-sensitive methodology. Additionally, our research emphasizes the need of integrating community-driven research approaches to identify culturally relevant biases often neglected by automated systems. Our research enhances the ongoing discussion around gender bias in AI by illustrating the need to create linguistic tools specifically designed for underrepresented languages. This study establishes a foundation for further investigations into bias reduction in Bengali and other Indic languages, promoting the development of more inclusive and fair NLP systems.",
      "url": "http://arxiv.org/abs/2601.17764",
      "author": "Md Asgor Hossain Reaj, Rajan Das Gupta, Jui Saha Pritha, Abdullah Al Noman, Abir Ahmed, Golam Md Mohiuddin, Tze Hui Liew",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Cross-lingual probing of gender bias in Bengali LLMs using multiple extraction methods including translation-based comparison and GPT-based bias generation.",
      "importance_score": 44,
      "reasoning": "Important bias research for underrepresented language. Multiple methodological approaches.",
      "themes": [
        "AI Fairness",
        "Gender Bias",
        "Low-resource Languages"
      ],
      "continuation": null,
      "summary_html": "<p>Cross-lingual probing of gender bias in Bengali LLMs using multiple extraction methods including translation-based comparison and GPT-based bias generation.</p>",
      "content_html": "<p>arXiv:2601.17764v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have achieved significant success in recent years; yet, issues of intrinsic gender bias persist, especially in non-English languages. Although current research mostly emphasizes English, the linguistic and cultural biases inherent in Global South languages, like Bengali, are little examined. This research seeks to examine the characteristics and magnitude of gender bias in Bengali, evaluating the efficacy of current approaches in identifying and alleviating bias. We use several methods to extract gender-biased utterances, including lexicon-based mining, computational classification models, translation-based comparison analysis, and GPT-based bias creation. Our research indicates that the straight application of English-centric bias detection frameworks to Bengali is severely constrained by language disparities and socio-cultural factors that impact implicit biases. To tackle these difficulties, we executed two field investigations inside rural and low-income areas, gathering authentic insights on gender bias. The findings demonstrate that gender bias in Bengali presents distinct characteristics relative to English, requiring a more localized and context-sensitive methodology. Additionally, our research emphasizes the need of integrating community-driven research approaches to identify culturally relevant biases often neglected by automated systems. Our research enhances the ongoing discussion around gender bias in AI by illustrating the need to create linguistic tools specifically designed for underrepresented languages. This study establishes a foundation for further investigations into bias reduction in Bengali and other Indic languages, promoting the development of more inclusive and fair NLP systems.</p>"
    },
    {
      "id": "e6fcb32695cf",
      "title": "SPADE: A SIMD Posit-enabled compute engine for Accelerating DNN Efficiency",
      "content": "arXiv:2601.17279v1 Announce Type: cross  Abstract: The growing demand for edge-AI systems requires arithmetic units that balance numerical precision, energy efficiency, and compact hardware while supporting diverse formats. Posit arithmetic offers advantages over floating- and fixed-point representations through its tapered precision, wide dynamic range, and improved numerical robustness. This work presents SPADE, a unified multi-precision SIMD Posit-based multiplyaccumulate (MAC) architecture supporting Posit (8,0), Posit (16,1), and Posit (32,2) within a single framework. Unlike prior single-precision or floating/fixed-point SIMD MACs, SPADE introduces a regime-aware, lane-fused SIMD Posit datapath that hierarchically reuses Posit-specific submodules (LOD, complementor, shifter, and multiplier) across 8/16/32-bit precisions without datapath replication. FPGA implementation on a Xilinx Virtex-7 shows 45.13% LUT and 80% slice reduction for Posit (8,0), and up to 28.44% and 17.47% improvement for Posit (16,1) and Posit (32,2) over prior work, with only 6.9% LUT and 14.9% register overhead for multi-precision support. ASIC results across TSMC nodes achieve 1.38 GHz at 6.1 mW (28 nm). Evaluation on MNIST, CIFAR-10/100, and alphabet datasets confirms competitive inference accuracy.",
      "url": "http://arxiv.org/abs/2601.17279",
      "author": "Sonu Kumar, Lavanya Vinnakota, Mukul Lokhande, Santosh Kumar Vishvakarma, Adam Teman",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.AR"
      ],
      "summary": "Presents SPADE, a unified multi-precision SIMD Posit-based MAC architecture supporting multiple Posit formats for energy-efficient DNN inference at the edge.",
      "importance_score": 44,
      "reasoning": "Hardware efficiency contribution but focused on Posit arithmetic which has limited adoption compared to mainstream quantization approaches.",
      "themes": [
        "Hardware Acceleration",
        "Neural Network Efficiency",
        "Edge Computing"
      ],
      "continuation": null,
      "summary_html": "<p>Presents SPADE, a unified multi-precision SIMD Posit-based MAC architecture supporting multiple Posit formats for energy-efficient DNN inference at the edge.</p>",
      "content_html": "<p>arXiv:2601.17279v1 Announce Type: cross  Abstract: The growing demand for edge-AI systems requires arithmetic units that balance numerical precision, energy efficiency, and compact hardware while supporting diverse formats. Posit arithmetic offers advantages over floating- and fixed-point representations through its tapered precision, wide dynamic range, and improved numerical robustness. This work presents SPADE, a unified multi-precision SIMD Posit-based multiplyaccumulate (MAC) architecture supporting Posit (8,0), Posit (16,1), and Posit (32,2) within a single framework. Unlike prior single-precision or floating/fixed-point SIMD MACs, SPADE introduces a regime-aware, lane-fused SIMD Posit datapath that hierarchically reuses Posit-specific submodules (LOD, complementor, shifter, and multiplier) across 8/16/32-bit precisions without datapath replication. FPGA implementation on a Xilinx Virtex-7 shows 45.13% LUT and 80% slice reduction for Posit (8,0), and up to 28.44% and 17.47% improvement for Posit (16,1) and Posit (32,2) over prior work, with only 6.9% LUT and 14.9% register overhead for multi-precision support. ASIC results across TSMC nodes achieve 1.38 GHz at 6.1 mW (28 nm). Evaluation on MNIST, CIFAR-10/100, and alphabet datasets confirms competitive inference accuracy.</p>"
    },
    {
      "id": "6cdc9fcf5760",
      "title": "Over-The-Air Extreme Learning Machines with XL Reception via Nonlinear Cascaded Metasurfaces",
      "content": "arXiv:2601.17749v1 Announce Type: cross  Abstract: The recently envisioned goal-oriented communications paradigm calls for the application of inference on wirelessly transferred data via Machine Learning (ML) tools. An emerging research direction deals with the realization of inference ML models directly in the physical layer of Multiple-Input Multiple-Output (MIMO) systems, which, however, entails certain significant challenges. In this paper, leveraging the technology of programmable MetaSurfaces (MSs), we present an eXtremely Large (XL) MIMO system that acts as an Extreme Learning Machine (ELM) performing binary classification tasks completely Over-The-Air (OTA), which can be trained in closed form. The proposed system comprises a receiver architecture consisting of densely parallel placed diffractive layers of XL MSs followed by a single reception radio-frequency chain. The front layer facing the MIMO channel consists of identical unit cells of a fixed NonLinear (NL) response, while the remaining layers of elements of tunable linear responses are utilized to approximate OTA the trained ELM weights. Our numerical investigations showcase that, in the XL regime of MS elements, the proposed XL-MIMO-ELM system achieves performance comparable to that of digital and idealized ML models across diverse datasets and wireless scenarios, thereby demonstrating the feasibility of embedding OTA learning capabilities into future communication systems.",
      "url": "http://arxiv.org/abs/2601.17749",
      "author": "Kyriakos Stylianopoulos, Mattia Fabiani, Giulia Torcolacci, Davide Dardari, George C. Alexandropoulos",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "eess.SP"
      ],
      "summary": "Presents XL-MIMO system using programmable metasurfaces as Extreme Learning Machine for over-the-air binary classification with closed-form training.",
      "importance_score": 44,
      "reasoning": "Novel hardware-based ML approach but narrow application scope and practical deployment challenges.",
      "themes": [
        "Wireless Communications",
        "Physical Layer ML",
        "Hardware ML"
      ],
      "continuation": null,
      "summary_html": "<p>Presents XL-MIMO system using programmable metasurfaces as Extreme Learning Machine for over-the-air binary classification with closed-form training.</p>",
      "content_html": "<p>arXiv:2601.17749v1 Announce Type: cross  Abstract: The recently envisioned goal-oriented communications paradigm calls for the application of inference on wirelessly transferred data via Machine Learning (ML) tools. An emerging research direction deals with the realization of inference ML models directly in the physical layer of Multiple-Input Multiple-Output (MIMO) systems, which, however, entails certain significant challenges. In this paper, leveraging the technology of programmable MetaSurfaces (MSs), we present an eXtremely Large (XL) MIMO system that acts as an Extreme Learning Machine (ELM) performing binary classification tasks completely Over-The-Air (OTA), which can be trained in closed form. The proposed system comprises a receiver architecture consisting of densely parallel placed diffractive layers of XL MSs followed by a single reception radio-frequency chain. The front layer facing the MIMO channel consists of identical unit cells of a fixed NonLinear (NL) response, while the remaining layers of elements of tunable linear responses are utilized to approximate OTA the trained ELM weights. Our numerical investigations showcase that, in the XL regime of MS elements, the proposed XL-MIMO-ELM system achieves performance comparable to that of digital and idealized ML models across diverse datasets and wireless scenarios, thereby demonstrating the feasibility of embedding OTA learning capabilities into future communication systems.</p>"
    },
    {
      "id": "6c9b5b6d5152",
      "title": "Delay-Compensated Stiffness Estimation for Robot-Mediated Dyadic Interaction",
      "content": "arXiv:2601.17812v1 Announce Type: new  Abstract: Robot-mediated human-human (dyadic) interactions enable therapists to provide physical therapy remotely, yet an accurate perception of patient stiffness remains challenging due to network-induced haptic delays. Conventional stiffness estimation methods, which neglect delay, suffer from temporal misalignment between force and position signals, leading to significant estimation errors as delays increase. To address this, we propose a robust, delay-compensated stiffness estimation framework by deriving an algebraic estimator based on quasi-static equilibrium that explicitly accounts for temporally aligning the expert's input with the novice's response. A Normalised Weighted Least Squares (NWLS) implementation is then introduced to robustly filter dynamic bias resulting from the algebraic derivation. Experiments using commercial rehabilitation robots (H-MAN) as the platform demonstrate that the proposed method significantly outperforms the standard estimator, maintaining consistent tracking accuracy under multiple introduced delays. These findings offer a promising solution for achieving high-fidelity haptic perception in remote dyadic interaction, potentially facilitating reliable stiffness assessment in therapeutic settings across networks.",
      "url": "http://arxiv.org/abs/2601.17812",
      "author": "Mingtian Du, Suhas Raghavendra Kulkarni, Bernardo Noronha, Domenico Campolo",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes delay-compensated stiffness estimation framework for robot-mediated dyadic interaction that explicitly accounts for network-induced haptic delays.",
      "importance_score": 44,
      "reasoning": "Specialized teleoperation contribution, useful for remote physical therapy but narrow scope.",
      "themes": [
        "Teleoperation",
        "Haptics",
        "Physical Therapy"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes delay-compensated stiffness estimation framework for robot-mediated dyadic interaction that explicitly accounts for network-induced haptic delays.</p>",
      "content_html": "<p>arXiv:2601.17812v1 Announce Type: new  Abstract: Robot-mediated human-human (dyadic) interactions enable therapists to provide physical therapy remotely, yet an accurate perception of patient stiffness remains challenging due to network-induced haptic delays. Conventional stiffness estimation methods, which neglect delay, suffer from temporal misalignment between force and position signals, leading to significant estimation errors as delays increase. To address this, we propose a robust, delay-compensated stiffness estimation framework by deriving an algebraic estimator based on quasi-static equilibrium that explicitly accounts for temporally aligning the expert's input with the novice's response. A Normalised Weighted Least Squares (NWLS) implementation is then introduced to robustly filter dynamic bias resulting from the algebraic derivation. Experiments using commercial rehabilitation robots (H-MAN) as the platform demonstrate that the proposed method significantly outperforms the standard estimator, maintaining consistent tracking accuracy under multiple introduced delays. These findings offer a promising solution for achieving high-fidelity haptic perception in remote dyadic interaction, potentially facilitating reliable stiffness assessment in therapeutic settings across networks.</p>"
    },
    {
      "id": "08472c2eb94f",
      "title": "Exact Minimum-Volume Confidence Set Intersection for Multinomial Outcomes",
      "content": "arXiv:2601.18145v1 Announce Type: new  Abstract: Computation of confidence sets is central to data science and machine learning, serving as the workhorse of A/B testing and underpinning the operation and analysis of reinforcement learning algorithms. Among all valid confidence sets for the multinomial parameter, minimum-volume confidence sets (MVCs) are optimal in that they minimize average volume, but they are defined as level sets of an exact p-value that is discontinuous and difficult to compute. Rather than attempting to characterize the geometry of MVCs directly, this paper studies a practically motivated decision problem: given two observed multinomial outcomes, can one certify whether their MVCs intersect? We present a certified, tolerance-aware algorithm for this intersection problem. The method exploits the fact that likelihood ordering induces halfspace constraints in log-odds coordinates, enabling adaptive geometric partitioning of parameter space and computable lower and upper bounds on p-values over each cell. For three categories, this yields an efficient and provably sound algorithm that either certifies intersection, certifies disjointness, or returns an indeterminate result when the decision lies within a prescribed margin. We further show how the approach extends to higher dimensions. The results demonstrate that, despite their irregular geometry, MVCs admit reliable certified decision procedures for core tasks in A/B testing.",
      "url": "http://arxiv.org/abs/2601.18145",
      "author": "Heguang Lin, Binhao Chen, Mengze Li, Daniel Pimentel-Alarc\\'on, Matthew L. Malloy",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning (Statistics))",
      "source_type": "arxiv",
      "tags": [
        "stat.ML"
      ],
      "summary": "Presents certified algorithm for determining whether minimum-volume confidence sets intersect for multinomial outcomes, encoding as decision problem.",
      "importance_score": 44,
      "reasoning": "Solid statistical methodology but narrow application scope.",
      "themes": [
        "Statistical Inference",
        "Confidence Sets",
        "Algorithms"
      ],
      "continuation": null,
      "summary_html": "<p>Presents certified algorithm for determining whether minimum-volume confidence sets intersect for multinomial outcomes, encoding as decision problem.</p>",
      "content_html": "<p>arXiv:2601.18145v1 Announce Type: new  Abstract: Computation of confidence sets is central to data science and machine learning, serving as the workhorse of A/B testing and underpinning the operation and analysis of reinforcement learning algorithms. Among all valid confidence sets for the multinomial parameter, minimum-volume confidence sets (MVCs) are optimal in that they minimize average volume, but they are defined as level sets of an exact p-value that is discontinuous and difficult to compute. Rather than attempting to characterize the geometry of MVCs directly, this paper studies a practically motivated decision problem: given two observed multinomial outcomes, can one certify whether their MVCs intersect? We present a certified, tolerance-aware algorithm for this intersection problem. The method exploits the fact that likelihood ordering induces halfspace constraints in log-odds coordinates, enabling adaptive geometric partitioning of parameter space and computable lower and upper bounds on p-values over each cell. For three categories, this yields an efficient and provably sound algorithm that either certifies intersection, certifies disjointness, or returns an indeterminate result when the decision lies within a prescribed margin. We further show how the approach extends to higher dimensions. The results demonstrate that, despite their irregular geometry, MVCs admit reliable certified decision procedures for core tasks in A/B testing.</p>"
    },
    {
      "id": "d986cabf4b5e",
      "title": "Coding-Enforced Resilient and Secure Aggregation for Hierarchical Federated Learning",
      "content": "arXiv:2601.17995v1 Announce Type: cross  Abstract: Hierarchical federated learning (HFL) has emerged as an effective paradigm to enhance link quality between clients and the server. However, ensuring model accuracy while preserving privacy under unreliable communication remains a key challenge in HFL, as the coordination among privacy noise can be randomly disrupted. To address this limitation, we propose a robust hierarchical secure aggregation scheme, termed H-SecCoGC, which integrates coding strategies to enforce structured aggregation. The proposed scheme not only ensures accurate global model construction under varying levels of privacy, but also avoids the partial participation issue, thereby significantly improving robustness, privacy preservation, and learning efficiency. Both theoretical analyses and experimental results demonstrate the superiority of our scheme under unreliable communication across arbitrarily strong privacy guarantees",
      "url": "http://arxiv.org/abs/2601.17995",
      "author": "Shudi Weng, Ming Xiao, Mikael Skoglund",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "H-SecCoGC proposes coding-based secure aggregation for hierarchical federated learning, ensuring accurate aggregation under varying privacy levels.",
      "importance_score": 43,
      "reasoning": "Addresses privacy-accuracy tradeoff in HFL. Coding theory approach.",
      "themes": [
        "Federated Learning",
        "Privacy",
        "Secure Aggregation"
      ],
      "continuation": null,
      "summary_html": "<p>H-SecCoGC proposes coding-based secure aggregation for hierarchical federated learning, ensuring accurate aggregation under varying privacy levels.</p>",
      "content_html": "<p>arXiv:2601.17995v1 Announce Type: cross  Abstract: Hierarchical federated learning (HFL) has emerged as an effective paradigm to enhance link quality between clients and the server. However, ensuring model accuracy while preserving privacy under unreliable communication remains a key challenge in HFL, as the coordination among privacy noise can be randomly disrupted. To address this limitation, we propose a robust hierarchical secure aggregation scheme, termed H-SecCoGC, which integrates coding strategies to enforce structured aggregation. The proposed scheme not only ensures accurate global model construction under varying levels of privacy, but also avoids the partial participation issue, thereby significantly improving robustness, privacy preservation, and learning efficiency. Both theoretical analyses and experimental results demonstrate the superiority of our scheme under unreliable communication across arbitrarily strong privacy guarantees</p>"
    },
    {
      "id": "5a7d2eff686a",
      "title": "Entropy-Guided Agreement-Diversity: A Semi-Supervised Active Learning Framework for Fetal Head Segmentation in Ultrasound",
      "content": "arXiv:2601.17460v1 Announce Type: cross  Abstract: Fetal ultrasound (US) data is often limited due to privacy and regulatory restrictions, posing challenges for training deep learning (DL) models. While semi-supervised learning (SSL) is commonly used for fetal US image analysis, existing SSL methods typically rely on random limited selection, which can lead to suboptimal model performance by overfitting to homogeneous labeled data. To address this, we propose a two-stage Active Learning (AL) sampler, Entropy-Guided Agreement-Diversity (EGAD), for fetal head segmentation. Our method first selects the most uncertain samples using predictive entropy, and then refines the final selection using the agreement-diversity score combining cosine similarity and mutual information. Additionally, our SSL framework employs a consistency learning strategy with feature downsampling to further enhance segmentation performance. In experiments, SSL-EGAD achieves an average Dice score of 94.57\\% and 96.32\\% on two public datasets for fetal head segmentation, using 5\\% and 10\\% labeled data for training, respectively. Our method outperforms current SSL models and showcases consistent robustness across diverse pregnancy stage data. The code is available on \\href{https://github.com/13204942/Semi-supervised-EGAD}{GitHub}.",
      "url": "http://arxiv.org/abs/2601.17460",
      "author": "Fangyijie Wang, Siteng Ma, Gu\\'enol\\'e Silvestre, Kathleen M. Curran",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "eess.IV"
      ],
      "summary": "Proposes EGAD, a two-stage active learning sampler for fetal head segmentation that combines entropy-based uncertainty selection with agreement-diversity scoring.",
      "importance_score": 43,
      "reasoning": "Domain-specific medical imaging contribution with standard active learning improvements, limited novelty.",
      "themes": [
        "Medical Imaging",
        "Active Learning",
        "Segmentation"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes EGAD, a two-stage active learning sampler for fetal head segmentation that combines entropy-based uncertainty selection with agreement-diversity scoring.</p>",
      "content_html": "<p>arXiv:2601.17460v1 Announce Type: cross  Abstract: Fetal ultrasound (US) data is often limited due to privacy and regulatory restrictions, posing challenges for training deep learning (DL) models. While semi-supervised learning (SSL) is commonly used for fetal US image analysis, existing SSL methods typically rely on random limited selection, which can lead to suboptimal model performance by overfitting to homogeneous labeled data. To address this, we propose a two-stage Active Learning (AL) sampler, Entropy-Guided Agreement-Diversity (EGAD), for fetal head segmentation. Our method first selects the most uncertain samples using predictive entropy, and then refines the final selection using the agreement-diversity score combining cosine similarity and mutual information. Additionally, our SSL framework employs a consistency learning strategy with feature downsampling to further enhance segmentation performance. In experiments, SSL-EGAD achieves an average Dice score of 94.57\\% and 96.32\\% on two public datasets for fetal head segmentation, using 5\\% and 10\\% labeled data for training, respectively. Our method outperforms current SSL models and showcases consistent robustness across diverse pregnancy stage data. The code is available on \\href{https://github.com/13204942/Semi-supervised-EGAD}{GitHub}.</p>"
    },
    {
      "id": "7ad725a3fad6",
      "title": "Constraint-Aware Discrete-Time PID Gain Optimization for Robotic Joint Control Under Actuator Saturation",
      "content": "arXiv:2601.18639v1 Announce Type: new  Abstract: The precise regulation of rotary actuation is fundamental in autonomous robotics, yet practical PID loops deviate from continuous-time theory due to discrete-time execution, actuator saturation, and small delays and measurement imperfections. We present an implementation-aware analysis and tuning workflow for saturated discrete-time joint control. We (i) derive PI stability regions under Euler and exact zero-order-hold (ZOH) discretizations using the Jury criterion, (ii) evaluate a discrete back-calculation anti-windup realization under saturation-dominant regimes, and (iii) propose a hybrid-certified Bayesian optimization workflow that screens analytically unstable candidates and behaviorally unsafe transients while optimizing a robust IAE objective with soft penalties on overshoot and saturation duty. Baseline sweeps ($\\tau=1.0$~s, $\\Delta t=0.01$~s, $u\\in[-10,10]$) quantify rise/settle trends for P/PI/PID. Under a randomized model family emulating uncertainty, delay, noise, quantization, and tighter saturation, robustness-oriented tuning improves median IAE from $0.843$ to $0.430$ while keeping median overshoot below $2\\%$. In simulation-only tuning, the certification screen rejects $11.6\\%$ of randomly sampled gains within bounds before full robust evaluation, improving sample efficiency without hardware experiments.",
      "url": "http://arxiv.org/abs/2601.18639",
      "author": "Ojasva Mishra, Xiaolong Wu, Min Xu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents implementation-aware analysis and Bayesian optimization workflow for discrete-time PID control under actuator saturation with analytical stability guarantees.",
      "importance_score": 43,
      "reasoning": "Thorough engineering contribution but focused on classical control with limited ML novelty.",
      "themes": [
        "Robot Control",
        "PID Tuning",
        "Bayesian Optimization"
      ],
      "continuation": null,
      "summary_html": "<p>Presents implementation-aware analysis and Bayesian optimization workflow for discrete-time PID control under actuator saturation with analytical stability guarantees.</p>",
      "content_html": "<p>arXiv:2601.18639v1 Announce Type: new  Abstract: The precise regulation of rotary actuation is fundamental in autonomous robotics, yet practical PID loops deviate from continuous-time theory due to discrete-time execution, actuator saturation, and small delays and measurement imperfections. We present an implementation-aware analysis and tuning workflow for saturated discrete-time joint control. We (i) derive PI stability regions under Euler and exact zero-order-hold (ZOH) discretizations using the Jury criterion, (ii) evaluate a discrete back-calculation anti-windup realization under saturation-dominant regimes, and (iii) propose a hybrid-certified Bayesian optimization workflow that screens analytically unstable candidates and behaviorally unsafe transients while optimizing a robust IAE objective with soft penalties on overshoot and saturation duty. Baseline sweeps ($\\tau=1.0$~s, $\\Delta t=0.01$~s, $u\\in[-10,10]$) quantify rise/settle trends for P/PI/PID. Under a randomized model family emulating uncertainty, delay, noise, quantization, and tighter saturation, robustness-oriented tuning improves median IAE from $0.843$ to $0.430$ while keeping median overshoot below $2\\%$. In simulation-only tuning, the certification screen rejects $11.6\\%$ of randomly sampled gains within bounds before full robust evaluation, improving sample efficiency without hardware experiments.</p>"
    },
    {
      "id": "a19f3c8416e3",
      "title": "Cognitive Platform Engineering for Autonomous Cloud Operations",
      "content": "arXiv:2601.17542v1 Announce Type: new  Abstract: Modern DevOps practices have accelerated software delivery through automation, CI/CD pipelines, and observability tooling,but these approaches struggle to keep pace with the scale and dynamism of cloud-native systems. As telemetry volume grows and configuration drift increases, traditional, rule-driven automation often results in reactive operations, delayed remediation, and dependency on manual expertise. This paper introduces Cognitive Platform Engineering, a next-generation paradigm that integrates sensing, reasoning, and autonomous action directly into the platform lifecycle. This paper propose a four-plane reference architecture that unifies data collection, intelligent inference, policy-driven orchestration, and human experience layers within a continuous feedback loop. A prototype implementation built with Kubernetes, Terraform, Open Policy Agent, and ML-based anomaly detection demonstrates improvements in mean time to resolution, resource efficiency, and compliance. The results show that embedding intelligence into platform operations enables resilient, self-adjusting, and intent-aligned cloud environments. The paper concludes with research opportunities in reinforcement learning, explainable governance, and sustainable self-managing cloud ecosystems.",
      "url": "http://arxiv.org/abs/2601.17542",
      "author": "Vinoth Punniyamoorthy, Nitin Saksena, Srivenkateswara Reddy Sankiti, Nachiappan Chockalingam, Aswathnarayan Muthukrishnan Kirubakaran, Shiva Kumar Reddy Carimireddy, Durgaraman Maruthavanan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes Cognitive Platform Engineering integrating AI sensing, reasoning, and autonomous action into cloud operations through a four-plane reference architecture for next-generation DevOps.",
      "importance_score": 42,
      "reasoning": "Applied work on DevOps automation; limited AI research novelty, more of a systems architecture proposal.",
      "themes": [
        "Cloud Computing",
        "DevOps",
        "Applied AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Cognitive Platform Engineering integrating AI sensing, reasoning, and autonomous action into cloud operations through a four-plane reference architecture for next-generation DevOps.</p>",
      "content_html": "<p>arXiv:2601.17542v1 Announce Type: new  Abstract: Modern DevOps practices have accelerated software delivery through automation, CI/CD pipelines, and observability tooling,but these approaches struggle to keep pace with the scale and dynamism of cloud-native systems. As telemetry volume grows and configuration drift increases, traditional, rule-driven automation often results in reactive operations, delayed remediation, and dependency on manual expertise. This paper introduces Cognitive Platform Engineering, a next-generation paradigm that integrates sensing, reasoning, and autonomous action directly into the platform lifecycle. This paper propose a four-plane reference architecture that unifies data collection, intelligent inference, policy-driven orchestration, and human experience layers within a continuous feedback loop. A prototype implementation built with Kubernetes, Terraform, Open Policy Agent, and ML-based anomaly detection demonstrates improvements in mean time to resolution, resource efficiency, and compliance. The results show that embedding intelligence into platform operations enables resilient, self-adjusting, and intent-aligned cloud environments. The paper concludes with research opportunities in reinforcement learning, explainable governance, and sustainable self-managing cloud ecosystems.</p>"
    },
    {
      "id": "3faa5d5e915d",
      "title": "Between Search and Platform: ChatGPT Under the DSA",
      "content": "arXiv:2601.17064v1 Announce Type: cross  Abstract: This article examines the applicability of the Digital Services Act (DSA) to ChatGPT, arguing that it should be classified as a hybrid of the two types of hosting services: online search engines and platforms. This requires classifying search engines as hosting services, which we show is appropriate under the DSA, thereby resolving an ambiguity in the legal framework. ChatGPT performs core search functions and stores user-provided inputs and custom GPTs, meeting the definition of hosting service. We compare ChatGPT's systemic risks with those of existing Very Large Online Search Engines (VLOSEs) and Platforms (VLOPs), showing that it raises similarly serious concerns regarding illegal content, fundamental rights, democratic integrity, and public health. Now that ChatGPT has reached the 45 million EU user threshold, it should be subject to the most onerous DSA obligations, requiring the assessment and mitigation of risk emanating from both its online search engine- and platform-like characteristics.",
      "url": "http://arxiv.org/abs/2601.17064",
      "author": "Toni Lorente, Kathrin Gardhouse",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Legal analysis arguing ChatGPT should be classified as a hybrid of online search engines and platforms under the EU Digital Services Act, requiring specific regulatory treatment.",
      "importance_score": 42,
      "reasoning": "Important policy analysis for AI regulation. Relevant to ongoing regulatory debates but legal rather than technical contribution.",
      "themes": [
        "AI Regulation",
        "AI Policy",
        "EU Law"
      ],
      "continuation": null,
      "summary_html": "<p>Legal analysis arguing ChatGPT should be classified as a hybrid of online search engines and platforms under the EU Digital Services Act, requiring specific regulatory treatment.</p>",
      "content_html": "<p>arXiv:2601.17064v1 Announce Type: cross  Abstract: This article examines the applicability of the Digital Services Act (DSA) to ChatGPT, arguing that it should be classified as a hybrid of the two types of hosting services: online search engines and platforms. This requires classifying search engines as hosting services, which we show is appropriate under the DSA, thereby resolving an ambiguity in the legal framework. ChatGPT performs core search functions and stores user-provided inputs and custom GPTs, meeting the definition of hosting service. We compare ChatGPT's systemic risks with those of existing Very Large Online Search Engines (VLOSEs) and Platforms (VLOPs), showing that it raises similarly serious concerns regarding illegal content, fundamental rights, democratic integrity, and public health. Now that ChatGPT has reached the 45 million EU user threshold, it should be subject to the most onerous DSA obligations, requiring the assessment and mitigation of risk emanating from both its online search engine- and platform-like characteristics.</p>"
    },
    {
      "id": "564cf8e4a27d",
      "title": "PC-MCL: Patient-Consistent Multi-Cycle Learning with multi-label bias correction for respiratory sound classification",
      "content": "arXiv:2601.17080v1 Announce Type: cross  Abstract: Automated respiratory sound classification supports the diagnosis of pulmonary diseases. However, many deep models still rely on cycle-level analysis and suffer from patient-specific overfitting. We propose PC-MCL (Patient-Consistent Multi-Cycle Learning) to address these limitations by utilizing three key components: multi-cycle concatenation, a 3-label formulation, and a patient-matching auxiliary task. Our work resolves a multi-label distributional bias in respiratory sound classification, a critical issue inherent to applying multi-cycle concatenation with the conventional 2-label formulation (crackle, wheeze). This bias manifests as a systematic loss of normal signal information when normal and abnormal cycles are combined. Our proposed 3-label formulation (normal, crackle, wheeze) corrects this by preserving information from all constituent cycles in mixed samples. Furthermore, the patient-matching auxiliary task acts as a multi-task regularizer, encouraging the model to learn more robust features and improving generalization. On the ICBHI 2017 benchmark, PC-MCL achieves an ICBHI Score of 65.37%, outperforming existing baselines. Ablation studies confirm that all three components are essential, working synergistically to improve the detection of abnormal respiratory events.",
      "url": "http://arxiv.org/abs/2601.17080",
      "author": "Seung Gyu Jeong, Seong-Eun Kim",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "eess.AS"
      ],
      "summary": "Proposes PC-MCL for respiratory sound classification addressing multi-label distributional bias through multi-cycle concatenation and patient-matching auxiliary task.",
      "importance_score": 42,
      "reasoning": "Identifies and addresses specific bias issue in respiratory sound classification. Domain-specific contribution.",
      "themes": [
        "Medical AI",
        "Audio Classification"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes PC-MCL for respiratory sound classification addressing multi-label distributional bias through multi-cycle concatenation and patient-matching auxiliary task.</p>",
      "content_html": "<p>arXiv:2601.17080v1 Announce Type: cross  Abstract: Automated respiratory sound classification supports the diagnosis of pulmonary diseases. However, many deep models still rely on cycle-level analysis and suffer from patient-specific overfitting. We propose PC-MCL (Patient-Consistent Multi-Cycle Learning) to address these limitations by utilizing three key components: multi-cycle concatenation, a 3-label formulation, and a patient-matching auxiliary task. Our work resolves a multi-label distributional bias in respiratory sound classification, a critical issue inherent to applying multi-cycle concatenation with the conventional 2-label formulation (crackle, wheeze). This bias manifests as a systematic loss of normal signal information when normal and abnormal cycles are combined. Our proposed 3-label formulation (normal, crackle, wheeze) corrects this by preserving information from all constituent cycles in mixed samples. Furthermore, the patient-matching auxiliary task acts as a multi-task regularizer, encouraging the model to learn more robust features and improving generalization. On the ICBHI 2017 benchmark, PC-MCL achieves an ICBHI Score of 65.37%, outperforming existing baselines. Ablation studies confirm that all three components are essential, working synergistically to improve the detection of abnormal respiratory events.</p>"
    },
    {
      "id": "2e9d0b430f8d",
      "title": "Parameter Efficient Fine Tuning Llama 3.1 for Answering Arabic Legal Questions: A Case Study on Jordanian Laws",
      "content": "arXiv:2601.17364v1 Announce Type: cross  Abstract: This study uses Jordanian law as a case study to explore the fine-tuning of the Llama-3.1 large language model for Arabic question-answering. Two versions of the model - Llama-3.1-8B-bnb-4bit and Llama-3.1-8B-Instruct-bnb-4bit - were fine-tuned using parameter-efficient fine-tuning (PEFT) with LoRA adapters and 4-bit quantized models, leveraging the Unsloth framework for accelerated and resource-efficient training. A custom dataset of 6000 legal question-answer pairs was curated from Jordanian laws and formatted into structured prompts. Performance was evaluated using the BLEU and the ROUGE metrics to compare the fine-tuned models to their respective base versions. Results demonstrated improved legal reasoning and accuracy while achieving resource efficiency through quantization and optimized fine-tuning strategies. This work underscores the potential of adapting large language models for Arabic legal domains and highlights effective techniques for fine-tuning domain-specific tasks.",
      "url": "http://arxiv.org/abs/2601.17364",
      "author": "Mohammed Fasha, Bassam Hammo, Bilal Sowan, Husam Barham, Esam Nsour",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Fine-tunes Llama-3.1 8B for Arabic legal QA using PEFT with LoRA adapters and 4-bit quantization. Custom dataset of 6000 legal question-answer pairs from Jordanian laws.",
      "importance_score": 42,
      "reasoning": "Applied fine-tuning for underrepresented legal domain. Standard methodology but useful for Arabic NLP community.",
      "themes": [
        "Legal AI",
        "Arabic NLP",
        "Fine-tuning"
      ],
      "continuation": null,
      "summary_html": "<p>Fine-tunes Llama-3.1 8B for Arabic legal QA using PEFT with LoRA adapters and 4-bit quantization. Custom dataset of 6000 legal question-answer pairs from Jordanian laws.</p>",
      "content_html": "<p>arXiv:2601.17364v1 Announce Type: cross  Abstract: This study uses Jordanian law as a case study to explore the fine-tuning of the Llama-3.1 large language model for Arabic question-answering. Two versions of the model - Llama-3.1-8B-bnb-4bit and Llama-3.1-8B-Instruct-bnb-4bit - were fine-tuned using parameter-efficient fine-tuning (PEFT) with LoRA adapters and 4-bit quantized models, leveraging the Unsloth framework for accelerated and resource-efficient training. A custom dataset of 6000 legal question-answer pairs was curated from Jordanian laws and formatted into structured prompts. Performance was evaluated using the BLEU and the ROUGE metrics to compare the fine-tuned models to their respective base versions. Results demonstrated improved legal reasoning and accuracy while achieving resource efficiency through quantization and optimized fine-tuning strategies. This work underscores the potential of adapting large language models for Arabic legal domains and highlights effective techniques for fine-tuning domain-specific tasks.</p>"
    },
    {
      "id": "cc820d97950f",
      "title": "DIETA: A Decoder-only transformer-based model for Italian-English machine TrAnslation",
      "content": "arXiv:2601.17823v1 Announce Type: cross  Abstract: In this paper, we present DIETA, a small, decoder-only Transformer model with 0.5 billion parameters, specifically designed and trained for Italian-English machine translation. We collect and curate a large parallel corpus consisting of approximately 207 million Italian-English sentence pairs across diverse domains, including parliamentary proceedings, legal texts, web-crawled content, subtitles, news, literature and 352 million back-translated data using pretrained models. Additionally, we create and release a new small-scale evaluation set, consisting of 450 sentences, based on 2025 WikiNews articles, enabling assessment of translation quality on contemporary text. Comprehensive evaluations show that DIETA achieves competitive performance on multiple Italian-English benchmarks, consistently ranking in the second quartile of a 32-system leaderboard and outperforming most other sub-3B models on four out of five test suites. The training script, trained models, curated corpus, and newly introduced evaluation set are made publicly available, facilitating further research and development in specialized Italian-English machine translation. https://github.com/pkasela/DIETA-Machine-Translation",
      "url": "http://arxiv.org/abs/2601.17823",
      "author": "Pranav Kasela, Marco Braga, Alessandro Ghiotto, Andrea Pilzer, Marco Viviani, Alessandro Raganato",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "DIETA: 0.5B decoder-only transformer for Italian-English translation trained on 207M sentence pairs plus back-translated data, with new WikiNews evaluation set.",
      "importance_score": 42,
      "reasoning": "Focused MT model with substantial training data. New evaluation resource.",
      "themes": [
        "Machine Translation",
        "Language Models"
      ],
      "continuation": null,
      "summary_html": "<p>DIETA: 0.5B decoder-only transformer for Italian-English translation trained on 207M sentence pairs plus back-translated data, with new WikiNews evaluation set.</p>",
      "content_html": "<p>arXiv:2601.17823v1 Announce Type: cross  Abstract: In this paper, we present DIETA, a small, decoder-only Transformer model with 0.5 billion parameters, specifically designed and trained for Italian-English machine translation. We collect and curate a large parallel corpus consisting of approximately 207 million Italian-English sentence pairs across diverse domains, including parliamentary proceedings, legal texts, web-crawled content, subtitles, news, literature and 352 million back-translated data using pretrained models. Additionally, we create and release a new small-scale evaluation set, consisting of 450 sentences, based on 2025 WikiNews articles, enabling assessment of translation quality on contemporary text. Comprehensive evaluations show that DIETA achieves competitive performance on multiple Italian-English benchmarks, consistently ranking in the second quartile of a 32-system leaderboard and outperforming most other sub-3B models on four out of five test suites. The training script, trained models, curated corpus, and newly introduced evaluation set are made publicly available, facilitating further research and development in specialized Italian-English machine translation. https://github.com/pkasela/DIETA-Machine-Translation</p>"
    },
    {
      "id": "2238b8d75db0",
      "title": "Diffusion Model-based Reinforcement Learning for Version Age of Information Scheduling: Average and Tail-Risk-Sensitive Control",
      "content": "arXiv:2601.18069v1 Announce Type: cross  Abstract: Ensuring timely and semantically accurate information delivery is critical in real-time wireless systems. While Age of Information (AoI) quantifies temporal freshness, Version Age of Information (VAoI) captures semantic staleness by accounting for version evolution between transmitters and receivers. Existing VAoI scheduling approaches primarily focus on minimizing average VAoI, overlooking rare but severe staleness events that can compromise reliability under stochastic packet arrivals and unreliable channels. This paper investigates both average-oriented and tail-risk-sensitive VAoI scheduling in a multi-user status update system with long-term transmission cost constraints. We first formulate the average VAoI minimization problem as a constrained Markov decision process and introduce a deep diffusion-based Soft Actor-Critic (D2SAC) algorithm. By generating actions through a diffusion-based denoising process, D2SAC enhances policy expressiveness and establishes a strong baseline for mean performance. Building on this foundation, we put forth RS-D3SAC, a risk-sensitive deep distributional diffusion-based Soft Actor-Critic algorithm. RS-D3SAC integrates a diffusion-based actor with a quantile-based distributional critic, explicitly modeling the full VAoI return distribution. This enables principled tail-risk optimization via Conditional Value-at-Risk (CVaR) while satisfying long-term transmission cost constraints. Extensive simulations show that, while D2SAC reduces average VAoI, RS-D3SAC consistently achieves substantial reductions in CVaR without sacrificing mean performance. The dominant gain in tail-risk reduction stems from the distributional critic, with the diffusion-based actor providing complementary refinement to stabilize and enrich policy decisions, highlighting their effectiveness for robust and risk-aware VAoI scheduling in multi-user wireless systems.",
      "url": "http://arxiv.org/abs/2601.18069",
      "author": "Haoyuan Pan, Sizhao Chen, Zhaorui Wang, Tse-Tin Chan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.NI"
      ],
      "summary": "Applies diffusion model-based reinforcement learning to optimize Version Age of Information scheduling in wireless systems, addressing both average and tail-risk scenarios. Novel combination of generative models with wireless resource allocation under long-term constraints.",
      "importance_score": 42,
      "reasoning": "Niche cross-domain application combining diffusion models with wireless systems. Limited broader AI impact but methodologically interesting.",
      "themes": [
        "Reinforcement Learning",
        "Wireless Systems",
        "Diffusion Models"
      ],
      "continuation": null,
      "summary_html": "<p>Applies diffusion model-based reinforcement learning to optimize Version Age of Information scheduling in wireless systems, addressing both average and tail-risk scenarios. Novel combination of generative models with wireless resource allocation under long-term constraints.</p>",
      "content_html": "<p>arXiv:2601.18069v1 Announce Type: cross  Abstract: Ensuring timely and semantically accurate information delivery is critical in real-time wireless systems. While Age of Information (AoI) quantifies temporal freshness, Version Age of Information (VAoI) captures semantic staleness by accounting for version evolution between transmitters and receivers. Existing VAoI scheduling approaches primarily focus on minimizing average VAoI, overlooking rare but severe staleness events that can compromise reliability under stochastic packet arrivals and unreliable channels. This paper investigates both average-oriented and tail-risk-sensitive VAoI scheduling in a multi-user status update system with long-term transmission cost constraints. We first formulate the average VAoI minimization problem as a constrained Markov decision process and introduce a deep diffusion-based Soft Actor-Critic (D2SAC) algorithm. By generating actions through a diffusion-based denoising process, D2SAC enhances policy expressiveness and establishes a strong baseline for mean performance. Building on this foundation, we put forth RS-D3SAC, a risk-sensitive deep distributional diffusion-based Soft Actor-Critic algorithm. RS-D3SAC integrates a diffusion-based actor with a quantile-based distributional critic, explicitly modeling the full VAoI return distribution. This enables principled tail-risk optimization via Conditional Value-at-Risk (CVaR) while satisfying long-term transmission cost constraints. Extensive simulations show that, while D2SAC reduces average VAoI, RS-D3SAC consistently achieves substantial reductions in CVaR without sacrificing mean performance. The dominant gain in tail-risk reduction stems from the distributional critic, with the diffusion-based actor providing complementary refinement to stabilize and enrich policy decisions, highlighting their effectiveness for robust and risk-aware VAoI scheduling in multi-user wireless systems.</p>"
    },
    {
      "id": "26e282b00a8f",
      "title": "Emergent Cooperation in Quantum Multi-Agent Reinforcement Learning Using Communication",
      "content": "arXiv:2601.18419v1 Announce Type: cross  Abstract: Emergent cooperation in classical Multi-Agent Reinforcement Learning has gained significant attention, particularly in the context of Sequential Social Dilemmas (SSDs). While classical reinforcement learning approaches have demonstrated capability for emergent cooperation, research on extending these methods to Quantum Multi-Agent Reinforcement Learning remains limited, particularly through communication. In this paper, we apply communication approaches to quantum Q-Learning agents: the Mutual Acknowledgment Token Exchange (MATE) protocol, its extension Mutually Endorsed Distributed Incentive Acknowledgment Token Exchange (MEDIATE), the peer rewarding mechanism Gifting, and Reinforced Inter-Agent Learning (RIAL). We evaluate these approaches in three SSDs: the Iterated Prisoner's Dilemma, Iterated Stag Hunt, and Iterated Game of Chicken. Our experimental results show that approaches using MATE with temporal-difference measure (MATE\\textsubscript{TD}), AutoMATE, MEDIATE-I, and MEDIATE-S achieved high cooperation levels across all dilemmas, demonstrating that communication is a viable mechanism for fostering emergent cooperation in Quantum Multi-Agent Reinforcement Learning.",
      "url": "http://arxiv.org/abs/2601.18419",
      "author": "Michael K\\\"olle, Christian Reff, Leo S\\\"unkel, Julian Hager, Gerhard Stenzel, Claudia Linnhoff-Popien",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "quant-ph"
      ],
      "summary": "Applies communication protocols (MATE, MEDIATE, Gifting, RIAL) to quantum Q-Learning agents for emergent cooperation in Sequential Social Dilemmas.",
      "importance_score": 42,
      "reasoning": "Niche intersection of quantum computing and MARL. Interesting but very early stage and specialized.",
      "themes": [
        "Quantum Machine Learning",
        "Multi-Agent RL",
        "Emergent Cooperation"
      ],
      "continuation": null,
      "summary_html": "<p>Applies communication protocols (MATE, MEDIATE, Gifting, RIAL) to quantum Q-Learning agents for emergent cooperation in Sequential Social Dilemmas.</p>",
      "content_html": "<p>arXiv:2601.18419v1 Announce Type: cross  Abstract: Emergent cooperation in classical Multi-Agent Reinforcement Learning has gained significant attention, particularly in the context of Sequential Social Dilemmas (SSDs). While classical reinforcement learning approaches have demonstrated capability for emergent cooperation, research on extending these methods to Quantum Multi-Agent Reinforcement Learning remains limited, particularly through communication. In this paper, we apply communication approaches to quantum Q-Learning agents: the Mutual Acknowledgment Token Exchange (MATE) protocol, its extension Mutually Endorsed Distributed Incentive Acknowledgment Token Exchange (MEDIATE), the peer rewarding mechanism Gifting, and Reinforced Inter-Agent Learning (RIAL). We evaluate these approaches in three SSDs: the Iterated Prisoner's Dilemma, Iterated Stag Hunt, and Iterated Game of Chicken. Our experimental results show that approaches using MATE with temporal-difference measure (MATE\\textsubscript{TD}), AutoMATE, MEDIATE-I, and MEDIATE-S achieved high cooperation levels across all dilemmas, demonstrating that communication is a viable mechanism for fostering emergent cooperation in Quantum Multi-Agent Reinforcement Learning.</p>"
    },
    {
      "id": "291b3046d6e1",
      "title": "Systematicity between Forms and Meanings across Languages Supports Efficient Communication",
      "content": "arXiv:2601.17181v1 Announce Type: new  Abstract: Languages vary widely in how meanings map to word forms. These mappings have been found to support efficient communication; however, this theory does not account for systematic relations within word forms. We examine how a restricted set of grammatical meanings (e.g. person, number) are expressed on verbs and pronouns across typologically diverse languages. Consistent with prior work, we find that verb and pronoun forms are shaped by competing communicative pressures for simplicity (minimizing the inventory of grammatical distinctions) and accuracy (enabling recovery of intended meanings). Crucially, our proposed model uses a novel measure of complexity (inverse of simplicity) based on the learnability of meaning-to-form mappings. This innovation captures fine-grained regularities in linguistic form, allowing better discrimination between attested and unattested systems, and establishes a new connection from efficient communication theory to systematicity in natural language.",
      "url": "http://arxiv.org/abs/2601.17181",
      "author": "Doreen Osmelak, Yang Xu, Michael Hahn, Kate McCurdy",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Examines how grammatical meanings map to word forms across languages, finding evidence for competing pressures of simplicity and accuracy. Introduces novel complexity measure based on learnability of meaning-to-form mappings.",
      "importance_score": 42,
      "reasoning": "Computational linguistics work with theoretical interest but limited practical AI applications.",
      "themes": [
        "Computational Linguistics",
        "Typology",
        "Language Evolution"
      ],
      "continuation": null,
      "summary_html": "<p>Examines how grammatical meanings map to word forms across languages, finding evidence for competing pressures of simplicity and accuracy. Introduces novel complexity measure based on learnability of meaning-to-form mappings.</p>",
      "content_html": "<p>arXiv:2601.17181v1 Announce Type: new  Abstract: Languages vary widely in how meanings map to word forms. These mappings have been found to support efficient communication; however, this theory does not account for systematic relations within word forms. We examine how a restricted set of grammatical meanings (e.g. person, number) are expressed on verbs and pronouns across typologically diverse languages. Consistent with prior work, we find that verb and pronoun forms are shaped by competing communicative pressures for simplicity (minimizing the inventory of grammatical distinctions) and accuracy (enabling recovery of intended meanings). Crucially, our proposed model uses a novel measure of complexity (inverse of simplicity) based on the learnability of meaning-to-form mappings. This innovation captures fine-grained regularities in linguistic form, allowing better discrimination between attested and unattested systems, and establishes a new connection from efficient communication theory to systematicity in natural language.</p>"
    },
    {
      "id": "bf7e413fdd1a",
      "title": "Corpus-Based Approaches to Igbo Diacritic Restoration",
      "content": "arXiv:2601.18380v1 Announce Type: new  Abstract: With natural language processing (NLP), researchers aim to enable computers to identify and understand patterns in human languages. This is often difficult because a language embeds many dynamic and varied properties in its syntax, pragmatics and phonology, which need to be captured and processed. The capacity of computers to process natural languages is increasing because NLP researchers are pushing its boundaries. But these research works focus more on well-resourced languages such as English, Japanese, German, French, Russian, Mandarin Chinese, etc. Over 95% of the world's 7000 languages are low-resourced for NLP, i.e. they have little or no data, tools, and techniques for NLP work.   In this thesis, we present an overview of diacritic ambiguity and a review of previous diacritic disambiguation approaches on other languages. Focusing on the Igbo language, we report the steps taken to develop a flexible framework for generating datasets for diacritic restoration. Three main approaches, the standard n-gram model, the classification models and the embedding models were proposed. The standard n-gram models use a sequence of previous words to the target stripped word as key predictors of the correct variants. For the classification models, a window of words on both sides of the target stripped word was used. The embedding models compare the similarity scores of the combined context word embeddings and the embeddings of each of the candidate variant vectors.",
      "url": "http://arxiv.org/abs/2601.18380",
      "author": "Ignatius Ezeani",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "PhD thesis presenting corpus-based approaches to diacritic restoration for Igbo, a low-resource African language. Addresses NLP resource gaps for under-served languages.",
      "importance_score": 42,
      "reasoning": "Specialized low-resource NLP work. Important for language preservation but limited broader technical novelty.",
      "themes": [
        "Low-Resource NLP",
        "African Languages",
        "Diacritic Restoration"
      ],
      "continuation": null,
      "summary_html": "<p>PhD thesis presenting corpus-based approaches to diacritic restoration for Igbo, a low-resource African language. Addresses NLP resource gaps for under-served languages.</p>",
      "content_html": "<p>arXiv:2601.18380v1 Announce Type: new  Abstract: With natural language processing (NLP), researchers aim to enable computers to identify and understand patterns in human languages. This is often difficult because a language embeds many dynamic and varied properties in its syntax, pragmatics and phonology, which need to be captured and processed. The capacity of computers to process natural languages is increasing because NLP researchers are pushing its boundaries. But these research works focus more on well-resourced languages such as English, Japanese, German, French, Russian, Mandarin Chinese, etc. Over 95% of the world's 7000 languages are low-resourced for NLP, i.e. they have little or no data, tools, and techniques for NLP work.   In this thesis, we present an overview of diacritic ambiguity and a review of previous diacritic disambiguation approaches on other languages. Focusing on the Igbo language, we report the steps taken to develop a flexible framework for generating datasets for diacritic restoration. Three main approaches, the standard n-gram model, the classification models and the embedding models were proposed. The standard n-gram models use a sequence of previous words to the target stripped word as key predictors of the correct variants. For the classification models, a window of words on both sides of the target stripped word was used. The embedding models compare the similarity scores of the combined context word embeddings and the embeddings of each of the candidate variant vectors.</p>"
    },
    {
      "id": "ebe967f3464b",
      "title": "Memento: Towards Proactive Visualization of Everyday Memories with Personal Wearable AR Assistant",
      "content": "arXiv:2601.17622v1 Announce Type: cross  Abstract: We introduce Memento, a conversational AR assistant that permanently captures and memorizes user's verbal queries alongside their spatiotemporal and activity contexts. By storing these \"memories,\" Memento discovers connections between users' recurring interests and the contexts that trigger them. Upon detection of similar or identical spatiotemporal activity, Memento proactively recalls user interests and delivers up-to-date responses through AR, seamlessly integrating AR experience into their daily routine. Unlike prior work, each interaction in Memento is not a transient event, but a connected series of interactions with coherent long--term perspective, tailored to the user's broader multimodal (visual, spatial, temporal, and embodied) context. We conduct preliminary evaluation through user feedbacks with participants of diverse expertise in immersive apps, and explore the value of proactive context-aware AR assistant in everyday settings. We share our findings and challenges in designing a proactive, context-aware AR system.",
      "url": "http://arxiv.org/abs/2601.17622",
      "author": "Yoonsang Kim, Yalong Yang, Arie E. Kaufman",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.HC"
      ],
      "summary": "Introduces Memento, an AR assistant that permanently captures user queries with spatiotemporal context, discovering connections between recurring interests and proactively delivering relevant information.",
      "importance_score": 42,
      "reasoning": "Interesting AR application concept but primarily a system description without substantial technical innovation.",
      "themes": [
        "Augmented Reality",
        "Conversational AI",
        "Context-aware Systems"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Memento, an AR assistant that permanently captures user queries with spatiotemporal context, discovering connections between recurring interests and proactively delivering relevant information.</p>",
      "content_html": "<p>arXiv:2601.17622v1 Announce Type: cross  Abstract: We introduce Memento, a conversational AR assistant that permanently captures and memorizes user's verbal queries alongside their spatiotemporal and activity contexts. By storing these \"memories,\" Memento discovers connections between users' recurring interests and the contexts that trigger them. Upon detection of similar or identical spatiotemporal activity, Memento proactively recalls user interests and delivers up-to-date responses through AR, seamlessly integrating AR experience into their daily routine. Unlike prior work, each interaction in Memento is not a transient event, but a connected series of interactions with coherent long--term perspective, tailored to the user's broader multimodal (visual, spatial, temporal, and embodied) context. We conduct preliminary evaluation through user feedbacks with participants of diverse expertise in immersive apps, and explore the value of proactive context-aware AR assistant in everyday settings. We share our findings and challenges in designing a proactive, context-aware AR system.</p>"
    },
    {
      "id": "e743921035a1",
      "title": "Diagnosis Support of Sickle Cell Anemia by Classifying Red Blood Cell Shape in Peripheral Blood Images",
      "content": "arXiv:2601.17032v1 Announce Type: new  Abstract: Red blood cell (RBC) deformation is the consequence of several diseases, including sickle cell anemia, which causes recurring episodes of pain and severe pronounced anemia. Monitoring patients with these diseases involves the observation of peripheral blood samples under a microscope, a time-consuming procedure. Moreover, a specialist is required to perform this technique, and owing to the subjective nature of the observation of isolated RBCs, the error rate is high. In this paper, we propose an automated method for differentially enumerating RBCs that uses peripheral blood smear image analysis. In this method, the objects of interest in the image are segmented using a Chan-Vese active contour model. An analysis is then performed to classify the RBCs, also called erythrocytes, as normal or elongated or having other deformations, using the basic shape analysis descriptors: circular shape factor (CSF) and elliptical shape factor (ESF). To analyze cells that become partially occluded in a cluster during sample preparation, an elliptical adjustment is performed to allow the analysis of erythrocytes with discoidal and elongated shapes. The images of patient blood samples used in the study were acquired by a clinical laboratory specialist in the Special Hematology Department of the ``Dr. Juan Bruno Zayas'' General Hospital in Santiago de Cuba. A comparison of the results obtained by the proposed method in our experiments with those obtained by some state-of-the-art methods showed that the proposed method is superior for the diagnosis of sickle cell anemia. This superiority is achieved for evidenced by the obtained F-measure value (0.97 for normal cells and 0.95 for elongated ones) and several overall multiclass performance measures. The results achieved by the proposed method are suitable for the purpose of clinical treatment and diagnostic support of sickle cell anemia.",
      "url": "http://arxiv.org/abs/2601.17032",
      "author": "Wilkie Delgado-Font, Miriela Escobedo-Nicot, Manuel Gonz\\'alez-Hidalgo, Silena Herold-Garcia, Antoni Jaume-i-Cap\\'o, Arnau Mir",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes automated method for red blood cell classification in peripheral blood images using Chan-Vese segmentation for sickle cell anemia diagnosis support.",
      "importance_score": 42,
      "reasoning": "Useful medical image analysis application but established methodology with limited novelty.",
      "themes": [
        "Medical Image Analysis",
        "Segmentation",
        "Healthcare AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes automated method for red blood cell classification in peripheral blood images using Chan-Vese segmentation for sickle cell anemia diagnosis support.</p>",
      "content_html": "<p>arXiv:2601.17032v1 Announce Type: new  Abstract: Red blood cell (RBC) deformation is the consequence of several diseases, including sickle cell anemia, which causes recurring episodes of pain and severe pronounced anemia. Monitoring patients with these diseases involves the observation of peripheral blood samples under a microscope, a time-consuming procedure. Moreover, a specialist is required to perform this technique, and owing to the subjective nature of the observation of isolated RBCs, the error rate is high. In this paper, we propose an automated method for differentially enumerating RBCs that uses peripheral blood smear image analysis. In this method, the objects of interest in the image are segmented using a Chan-Vese active contour model. An analysis is then performed to classify the RBCs, also called erythrocytes, as normal or elongated or having other deformations, using the basic shape analysis descriptors: circular shape factor (CSF) and elliptical shape factor (ESF). To analyze cells that become partially occluded in a cluster during sample preparation, an elliptical adjustment is performed to allow the analysis of erythrocytes with discoidal and elongated shapes. The images of patient blood samples used in the study were acquired by a clinical laboratory specialist in the Special Hematology Department of the ``Dr. Juan Bruno Zayas'' General Hospital in Santiago de Cuba. A comparison of the results obtained by the proposed method in our experiments with those obtained by some state-of-the-art methods showed that the proposed method is superior for the diagnosis of sickle cell anemia. This superiority is achieved for evidenced by the obtained F-measure value (0.97 for normal cells and 0.95 for elongated ones) and several overall multiclass performance measures. The results achieved by the proposed method are suitable for the purpose of clinical treatment and diagnostic support of sickle cell anemia.</p>"
    },
    {
      "id": "6cb7344d2e86",
      "title": "An AI-enabled tool for quantifying overlapping red blood cell sickling dynamics in microfluidic assays",
      "content": "arXiv:2601.17703v1 Announce Type: new  Abstract: Understanding sickle cell dynamics requires accurate identification of morphological transitions under diverse biophysical conditions, particularly in densely packed and overlapping cell populations. Here, we present an automated deep learning framework that integrates AI-assisted annotation, segmentation, classification, and instance counting to quantify red blood cell (RBC) populations across varying density regimes in time-lapse microscopy data. Experimental images were annotated using the Roboflow platform to generate labeled dataset for training an nnU-Net segmentation model. The trained network enables prediction of the temporal evolution of the sickle cell fraction, while a watershed algorithm resolves overlapping cells to enhance quantification accuracy. Despite requiring only a limited amount of labeled data for training, the framework achieves high segmentation performance, effectively addressing challenges associated with scarce manual annotations and cell overlap. By quantitatively tracking dynamic changes in RBC morphology, this approach can more than double the experimental throughput via densely packed cell suspensions, capture drug-dependent sickling behavior, and reveal distinct mechanobiological signatures of cellular morphological evolution. Overall, this AI-driven framework establishes a scalable and reproducible computational platform for investigating cellular biomechanics and assessing therapeutic efficacy in microphysiological systems.",
      "url": "http://arxiv.org/abs/2601.17703",
      "author": "Nikhil Kadivar, Guansheng Li, Jianlu Zheng, John M. Higgins, Ming Dao, George Em Karniadakis, Mengjia Xu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents an automated deep learning framework for quantifying sickle cell populations in microscopy data, combining AI-assisted annotation, nnU-Net segmentation, and watershed algorithms to track morphological transitions in densely packed cells.",
      "importance_score": 42,
      "reasoning": "Practical medical application but domain-specific. Standard deep learning pipeline application.",
      "themes": [
        "Medical Imaging",
        "Cell Biology",
        "Segmentation"
      ],
      "continuation": null,
      "summary_html": "<p>Presents an automated deep learning framework for quantifying sickle cell populations in microscopy data, combining AI-assisted annotation, nnU-Net segmentation, and watershed algorithms to track morphological transitions in densely packed cells.</p>",
      "content_html": "<p>arXiv:2601.17703v1 Announce Type: new  Abstract: Understanding sickle cell dynamics requires accurate identification of morphological transitions under diverse biophysical conditions, particularly in densely packed and overlapping cell populations. Here, we present an automated deep learning framework that integrates AI-assisted annotation, segmentation, classification, and instance counting to quantify red blood cell (RBC) populations across varying density regimes in time-lapse microscopy data. Experimental images were annotated using the Roboflow platform to generate labeled dataset for training an nnU-Net segmentation model. The trained network enables prediction of the temporal evolution of the sickle cell fraction, while a watershed algorithm resolves overlapping cells to enhance quantification accuracy. Despite requiring only a limited amount of labeled data for training, the framework achieves high segmentation performance, effectively addressing challenges associated with scarce manual annotations and cell overlap. By quantitatively tracking dynamic changes in RBC morphology, this approach can more than double the experimental throughput via densely packed cell suspensions, capture drug-dependent sickling behavior, and reveal distinct mechanobiological signatures of cellular morphological evolution. Overall, this AI-driven framework establishes a scalable and reproducible computational platform for investigating cellular biomechanics and assessing therapeutic efficacy in microphysiological systems.</p>"
    },
    {
      "id": "4cf6a0121769",
      "title": "Domain Generalization with Quantum Enhancement for Medical Image Classification: A Lightweight Approach for Cross-Center Deployment",
      "content": "arXiv:2601.17862v1 Announce Type: new  Abstract: Medical image artificial intelligence models often achieve strong performance in single-center or single-device settings, yet their effectiveness frequently deteriorates in real-world cross-center deployment due to domain shift, limiting clinical generalizability. To address this challenge, we propose a lightweight domain generalization framework with quantum-enhanced collaborative learning, enabling robust generalization to unseen target domains without relying on real multi-center labeled data. Specifically, a MobileNetV2-based domain-invariant encoder is constructed and optimized through three key components: (1) multi-domain imaging shift simulation using brightness, contrast, sharpening, and noise perturbations to emulate heterogeneous acquisition conditions; (2) domain-adversarial training with gradient reversal to suppress domain-discriminative features; and (3) a lightweight quantum feature enhancement layer that applies parameterized quantum circuits for nonlinear feature mapping and entanglement modeling. In addition, a test-time adaptation strategy is employed during inference to further alleviate distribution shifts. Experiments on simulated multi-center medical imaging datasets demonstrate that the proposed method significantly outperforms baseline models without domain generalization or quantum enhancement on unseen domains, achieving reduced domain-specific performance variance and improved AUC and sensitivity. These results highlight the clinical potential of quantum-enhanced domain generalization under constrained computational resources and provide a feasible paradigm for hybrid quantum--classical medical imaging systems.",
      "url": "http://arxiv.org/abs/2601.17862",
      "author": "Jingsong Xia, Siqi Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes a lightweight domain generalization framework with quantum-enhanced collaborative learning for medical image classification, combining MobileNetV2 encoder with multi-domain imaging shift simulation.",
      "importance_score": 42,
      "reasoning": "Quantum component appears incremental. Domain generalization approach is practical but not groundbreaking.",
      "themes": [
        "Medical Imaging",
        "Quantum Computing",
        "Domain Generalization"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes a lightweight domain generalization framework with quantum-enhanced collaborative learning for medical image classification, combining MobileNetV2 encoder with multi-domain imaging shift simulation.</p>",
      "content_html": "<p>arXiv:2601.17862v1 Announce Type: new  Abstract: Medical image artificial intelligence models often achieve strong performance in single-center or single-device settings, yet their effectiveness frequently deteriorates in real-world cross-center deployment due to domain shift, limiting clinical generalizability. To address this challenge, we propose a lightweight domain generalization framework with quantum-enhanced collaborative learning, enabling robust generalization to unseen target domains without relying on real multi-center labeled data. Specifically, a MobileNetV2-based domain-invariant encoder is constructed and optimized through three key components: (1) multi-domain imaging shift simulation using brightness, contrast, sharpening, and noise perturbations to emulate heterogeneous acquisition conditions; (2) domain-adversarial training with gradient reversal to suppress domain-discriminative features; and (3) a lightweight quantum feature enhancement layer that applies parameterized quantum circuits for nonlinear feature mapping and entanglement modeling. In addition, a test-time adaptation strategy is employed during inference to further alleviate distribution shifts. Experiments on simulated multi-center medical imaging datasets demonstrate that the proposed method significantly outperforms baseline models without domain generalization or quantum enhancement on unseen domains, achieving reduced domain-specific performance variance and improved AUC and sensitivity. These results highlight the clinical potential of quantum-enhanced domain generalization under constrained computational resources and provide a feasible paradigm for hybrid quantum--classical medical imaging systems.</p>"
    },
    {
      "id": "730a648909c3",
      "title": "Semi-Supervised Hyperspectral Image Classification with Edge-Aware Superpixel Label Propagation and Adaptive Pseudo-Labeling",
      "content": "arXiv:2601.18049v1 Announce Type: new  Abstract: Significant progress has been made in semi-supervised hyperspectral image (HSI) classification regarding feature extraction and classification performance. However, due to high annotation costs and limited sample availability, semi-supervised learning still faces challenges such as boundary label diffusion and pseudo-label instability. To address these issues, this paper proposes a novel semi-supervised hyperspectral classification framework integrating spatial prior information with a dynamic learning mechanism. First, we design an Edge-Aware Superpixel Label Propagation (EASLP) module. By integrating edge intensity penalty with neighborhood correction strategy, it mitigates label diffusion from superpixel segmentation while enhancing classification robustness in boundary regions. Second, we introduce a Dynamic History-Fused Prediction (DHP) method. By maintaining historical predictions and dynamically weighting them with current results, DHP smoothens pseudo-label fluctuations and improves temporal consistency and noise resistance. Concurrently, incorporating condifence and consistency measures, the Adaptive Tripartite Sample Categorization (ATSC) strategy implements hierarchical utilization of easy, ambiguous, and hard samples, leading to enhanced pseudo-label quality and learning efficiency. The Dynamic Reliability-Enhanced Pseudo-Label Framework (DREPL), composed of DHP and ATSC, strengthens pseudo-label stability across temporal and sample domains. Through synergizes operation with EASLP, it achieves spatio-temporal consistency optimization. Evaluations on four benchmark datasets demonstrate its capability to maintain superior classification performance.",
      "url": "http://arxiv.org/abs/2601.18049",
      "author": "Yunfei Qiu, Qiqiong Ma, Tianhua Lv, Li Fang, Shudong Zhou, Wei Yao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes semi-supervised hyperspectral image classification with edge-aware superpixel label propagation and adaptive pseudo-labeling to address boundary diffusion and pseudo-label instability.",
      "importance_score": 42,
      "reasoning": "Incremental improvement for hyperspectral classification. Standard semi-supervised techniques applied.",
      "themes": [
        "Hyperspectral Imaging",
        "Semi-Supervised Learning",
        "Remote Sensing"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes semi-supervised hyperspectral image classification with edge-aware superpixel label propagation and adaptive pseudo-labeling to address boundary diffusion and pseudo-label instability.</p>",
      "content_html": "<p>arXiv:2601.18049v1 Announce Type: new  Abstract: Significant progress has been made in semi-supervised hyperspectral image (HSI) classification regarding feature extraction and classification performance. However, due to high annotation costs and limited sample availability, semi-supervised learning still faces challenges such as boundary label diffusion and pseudo-label instability. To address these issues, this paper proposes a novel semi-supervised hyperspectral classification framework integrating spatial prior information with a dynamic learning mechanism. First, we design an Edge-Aware Superpixel Label Propagation (EASLP) module. By integrating edge intensity penalty with neighborhood correction strategy, it mitigates label diffusion from superpixel segmentation while enhancing classification robustness in boundary regions. Second, we introduce a Dynamic History-Fused Prediction (DHP) method. By maintaining historical predictions and dynamically weighting them with current results, DHP smoothens pseudo-label fluctuations and improves temporal consistency and noise resistance. Concurrently, incorporating condifence and consistency measures, the Adaptive Tripartite Sample Categorization (ATSC) strategy implements hierarchical utilization of easy, ambiguous, and hard samples, leading to enhanced pseudo-label quality and learning efficiency. The Dynamic Reliability-Enhanced Pseudo-Label Framework (DREPL), composed of DHP and ATSC, strengthens pseudo-label stability across temporal and sample domains. Through synergizes operation with EASLP, it achieves spatio-temporal consistency optimization. Evaluations on four benchmark datasets demonstrate its capability to maintain superior classification performance.</p>"
    },
    {
      "id": "886c1e898115",
      "title": "A Tumor Aware DenseNet Swin Hybrid Learning with Boosted and Hierarchical Feature Spaces for Large-Scale Brain MRI Classification",
      "content": "arXiv:2601.18330v1 Announce Type: new  Abstract: This study proposes an efficient Densely Swin Hybrid (EDSH) framework for brain tumor MRI analysis, designed to jointly capture fine grained texture patterns and long range contextual dependencies. Two tumor aware experimental setups are introduced to address class-specific diagnostic challenges. The first setup employs a Boosted Feature Space (BFS), where independently customized DenseNet and Swint branches learn complementary local and global representations that are dimension aligned, fused, and boosted, enabling highly sensitive detection of diffuse glioma patterns by successfully learning the features of irregular shape, poorly defined mass, and heterogeneous texture. The second setup adopts a hierarchical DenseNet Swint architecture with Deep Feature Extraction have Dual Residual connections (DFE and DR), in which DenseNet serves as a stem CNN for structured local feature learning, while Swin_t models global tumor morphology, effectively suppressing false negatives in meningioma and pituitary tumor classification by learning the features of well defined mass, location (outside brain) and enlargments in tumors (dural tail or upward extension). DenseNet is customized at the input level to match MRI spatial characteristics, leveraging dense residual connectivity to preserve texture information and mitigate vanishing-gradient effects. In parallel, Swint is tailored through task aligned patch embedding and shifted-window self attention to efficiently capture hierarchical global dependencies. Extensive evaluation on a large-scale MRI dataset (stringent 40,260 images across four tumor classes) demonstrates consistent superiority over standalone CNNs, Vision Transformers, and hybrids, achieving 98.50 accuracy and recall on the test unseen dataset.",
      "url": "http://arxiv.org/abs/2601.18330",
      "author": "Muhammad Ali Shah (Riphah International University, Islamabad, Pakistan), Muhammad Mansoor Alam (Riphah International University, Islamabad, Pakistan, Multimedia University, Malaysia), Saddam Hussain Khan (University of Engineering and Applied Sciences, Swat, Kanju Township, Pakistan)",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes Densely Swin Hybrid framework for brain tumor MRI classification with boosted feature spaces combining DenseNet local patterns and Swin Transformer global context.",
      "importance_score": 42,
      "reasoning": "Domain-specific hybrid architecture. Standard approach combining CNNs and Transformers.",
      "themes": [
        "Medical Imaging",
        "Brain Tumors",
        "Hybrid Architectures"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Densely Swin Hybrid framework for brain tumor MRI classification with boosted feature spaces combining DenseNet local patterns and Swin Transformer global context.</p>",
      "content_html": "<p>arXiv:2601.18330v1 Announce Type: new  Abstract: This study proposes an efficient Densely Swin Hybrid (EDSH) framework for brain tumor MRI analysis, designed to jointly capture fine grained texture patterns and long range contextual dependencies. Two tumor aware experimental setups are introduced to address class-specific diagnostic challenges. The first setup employs a Boosted Feature Space (BFS), where independently customized DenseNet and Swint branches learn complementary local and global representations that are dimension aligned, fused, and boosted, enabling highly sensitive detection of diffuse glioma patterns by successfully learning the features of irregular shape, poorly defined mass, and heterogeneous texture. The second setup adopts a hierarchical DenseNet Swint architecture with Deep Feature Extraction have Dual Residual connections (DFE and DR), in which DenseNet serves as a stem CNN for structured local feature learning, while Swin_t models global tumor morphology, effectively suppressing false negatives in meningioma and pituitary tumor classification by learning the features of well defined mass, location (outside brain) and enlargments in tumors (dural tail or upward extension). DenseNet is customized at the input level to match MRI spatial characteristics, leveraging dense residual connectivity to preserve texture information and mitigate vanishing-gradient effects. In parallel, Swint is tailored through task aligned patch embedding and shifted-window self attention to efficiently capture hierarchical global dependencies. Extensive evaluation on a large-scale MRI dataset (stringent 40,260 images across four tumor classes) demonstrates consistent superiority over standalone CNNs, Vision Transformers, and hybrids, achieving 98.50 accuracy and recall on the test unseen dataset.</p>"
    },
    {
      "id": "4aa48ce34a41",
      "title": "OREHAS: A fully automated deep-learning pipeline for volumetric endolymphatic hydrops quantification in MRI",
      "content": "arXiv:2601.18368v1 Announce Type: new  Abstract: We present OREHAS (Optimized Recognition & Evaluation of volumetric Hydrops in the Auditory System), the first fully automatic pipeline for volumetric quantification of endolymphatic hydrops (EH) from routine 3D-SPACE-MRC and 3D-REAL-IR MRI. The system integrates three components -- slice classification, inner ear localization, and sequence-specific segmentation -- into a single workflow that computes per-ear endolymphatic-to-vestibular volume ratios (ELR) directly from whole MRI volumes, eliminating the need for manual intervention.   Trained with only 3 to 6 annotated slices per patient, OREHAS generalized effectively to full 3D volumes, achieving Dice scores of 0.90 for SPACE-MRC and 0.75 for REAL-IR. In an external validation cohort with complete manual annotations, OREHAS closely matched expert ground truth (VSI = 74.3%) and substantially outperformed the clinical syngo.via software (VSI = 42.5%), which tended to overestimate endolymphatic volumes. Across 19 test patients, vestibular measurements from OREHAS were consistent with syngo.via, while endolymphatic volumes were systematically smaller and more physiologically realistic.   These results show that reliable and reproducible EH quantification can be achieved from standard MRI using limited supervision. By combining efficient deep-learning-based segmentation with a clinically aligned volumetric workflow, OREHAS reduces operator dependence, ensures methodological consistency. Besides, the results are compatible with established imaging protocols. The approach provides a robust foundation for large-scale studies and for recalibrating clinical diagnostic thresholds based on accurate volumetric measurements of the inner ear.",
      "url": "http://arxiv.org/abs/2601.18368",
      "author": "Caterina Fuster-Barcel\\'o, Claudia Castrill\\'on, Laura Rodrigo-Mu\\~noz, Victor Manuel Vega-Su\\'arez, Nicol\\'as P\\'erez-Fern\\'andez, Gorka Bastarrika, Arrate Mu\\~noz-Barrutia",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "OREHAS provides first fully automatic pipeline for volumetric endolymphatic hydrops quantification from clinical MRI, integrating slice classification, localization, and sequence-specific segmentation.",
      "importance_score": 42,
      "reasoning": "Domain-specific medical imaging automation. Practical but narrow application.",
      "themes": [
        "Medical Imaging",
        "Ear Disease",
        "Automated Diagnosis"
      ],
      "continuation": null,
      "summary_html": "<p>OREHAS provides first fully automatic pipeline for volumetric endolymphatic hydrops quantification from clinical MRI, integrating slice classification, localization, and sequence-specific segmentation.</p>",
      "content_html": "<p>arXiv:2601.18368v1 Announce Type: new  Abstract: We present OREHAS (Optimized Recognition &amp; Evaluation of volumetric Hydrops in the Auditory System), the first fully automatic pipeline for volumetric quantification of endolymphatic hydrops (EH) from routine 3D-SPACE-MRC and 3D-REAL-IR MRI. The system integrates three components -- slice classification, inner ear localization, and sequence-specific segmentation -- into a single workflow that computes per-ear endolymphatic-to-vestibular volume ratios (ELR) directly from whole MRI volumes, eliminating the need for manual intervention.   Trained with only 3 to 6 annotated slices per patient, OREHAS generalized effectively to full 3D volumes, achieving Dice scores of 0.90 for SPACE-MRC and 0.75 for REAL-IR. In an external validation cohort with complete manual annotations, OREHAS closely matched expert ground truth (VSI = 74.3%) and substantially outperformed the clinical syngo.via software (VSI = 42.5%), which tended to overestimate endolymphatic volumes. Across 19 test patients, vestibular measurements from OREHAS were consistent with syngo.via, while endolymphatic volumes were systematically smaller and more physiologically realistic.   These results show that reliable and reproducible EH quantification can be achieved from standard MRI using limited supervision. By combining efficient deep-learning-based segmentation with a clinically aligned volumetric workflow, OREHAS reduces operator dependence, ensures methodological consistency. Besides, the results are compatible with established imaging protocols. The approach provides a robust foundation for large-scale studies and for recalibrating clinical diagnostic thresholds based on accurate volumetric measurements of the inner ear.</p>"
    },
    {
      "id": "2b9e949fc912",
      "title": "Generative Diffusion Augmentation with Quantum-Enhanced Discrimination for Medical Image Diagnosis",
      "content": "arXiv:2601.18556v1 Announce Type: new  Abstract: In biomedical engineering, artificial intelligence has become a pivotal tool for enhancing medical diagnostics, particularly in medical image classification tasks such as detecting pneumonia from chest X-rays and breast cancer screening. However, real-world medical datasets frequently exhibit severe class imbalance, where positive samples substantially outnumber negative samples, leading to biased models with low recall rates for minority classes. This imbalance not only compromises diagnostic accuracy but also poses clinical misdiagnosis risks. To address this challenge, we propose SDA-QEC (Simplified Diffusion Augmentation with Quantum-Enhanced Classification), an innovative framework that integrates simplified diffusion-based data augmentation with quantum-enhanced feature discrimination. Our approach employs a lightweight diffusion augmentor to generate high-quality synthetic samples for minority classes, rebalancing the training distribution. Subsequently, a quantum feature layer embedded within MobileNetV2 architecture enhances the model's discriminative capability through high-dimensional feature mapping in Hilbert space. Comprehensive experiments on coronary angiography image classification demonstrate that SDA-QEC achieves 98.33% accuracy, 98.78% AUC, and 98.33% F1-score, significantly outperforming classical baselines including ResNet18, MobileNetV2, DenseNet121, and VGG16. Notably, our framework simultaneously attains 98.33% sensitivity and 98.33% specificity, achieving a balanced performance critical for clinical deployment. The proposed method validates the feasibility of integrating generative augmentation with quantum-enhanced modeling in real-world medical imaging tasks, offering a novel research pathway for developing highly reliable medical AI systems in small-sample, highly imbalanced, and high-risk diagnostic scenarios.",
      "url": "http://arxiv.org/abs/2601.18556",
      "author": "Jingsong Xia, Siqi Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "SDA-QEC combines simplified diffusion-based augmentation with quantum-enhanced classification for medical image diagnosis, addressing class imbalance in datasets like pneumonia detection.",
      "importance_score": 42,
      "reasoning": "Quantum component is novelty but early-stage. Addresses real class imbalance problem.",
      "themes": [
        "Medical Imaging",
        "Quantum Computing",
        "Data Augmentation"
      ],
      "continuation": null,
      "summary_html": "<p>SDA-QEC combines simplified diffusion-based augmentation with quantum-enhanced classification for medical image diagnosis, addressing class imbalance in datasets like pneumonia detection.</p>",
      "content_html": "<p>arXiv:2601.18556v1 Announce Type: new  Abstract: In biomedical engineering, artificial intelligence has become a pivotal tool for enhancing medical diagnostics, particularly in medical image classification tasks such as detecting pneumonia from chest X-rays and breast cancer screening. However, real-world medical datasets frequently exhibit severe class imbalance, where positive samples substantially outnumber negative samples, leading to biased models with low recall rates for minority classes. This imbalance not only compromises diagnostic accuracy but also poses clinical misdiagnosis risks. To address this challenge, we propose SDA-QEC (Simplified Diffusion Augmentation with Quantum-Enhanced Classification), an innovative framework that integrates simplified diffusion-based data augmentation with quantum-enhanced feature discrimination. Our approach employs a lightweight diffusion augmentor to generate high-quality synthetic samples for minority classes, rebalancing the training distribution. Subsequently, a quantum feature layer embedded within MobileNetV2 architecture enhances the model's discriminative capability through high-dimensional feature mapping in Hilbert space. Comprehensive experiments on coronary angiography image classification demonstrate that SDA-QEC achieves 98.33% accuracy, 98.78% AUC, and 98.33% F1-score, significantly outperforming classical baselines including ResNet18, MobileNetV2, DenseNet121, and VGG16. Notably, our framework simultaneously attains 98.33% sensitivity and 98.33% specificity, achieving a balanced performance critical for clinical deployment. The proposed method validates the feasibility of integrating generative augmentation with quantum-enhanced modeling in real-world medical imaging tasks, offering a novel research pathway for developing highly reliable medical AI systems in small-sample, highly imbalanced, and high-risk diagnostic scenarios.</p>"
    },
    {
      "id": "b796a234c846",
      "title": "CONQUER: Context-Aware Representation with Query Enhancement for Text-Based Person Search",
      "content": "arXiv:2601.18625v1 Announce Type: new  Abstract: Text-Based Person Search (TBPS) aims to retrieve pedestrian images from large galleries using natural language descriptions. This task, essential for public safety applications, is hindered by cross-modal discrepancies and ambiguous user queries. We introduce CONQUER, a two-stage framework designed to address these challenges by enhancing cross-modal alignment during training and adaptively refining queries at inference. During training, CONQUER employs multi-granularity encoding, complementary pair mining, and context-guided optimal matching based on Optimal Transport to learn robust embeddings. At inference, a plug-and-play query enhancement module refines vague or incomplete queries via anchor selection and attribute-driven enrichment, without requiring retraining of the backbone. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that CONQUER consistently outperforms strong baselines in both Rank-1 accuracy and mAP, yielding notable improvements in cross-domain and incomplete-query scenarios. These results highlight CONQUER as a practical and effective solution for real-world TBPS deployment. Source code is available at https://github.com/zqxie77/CONQUER.",
      "url": "http://arxiv.org/abs/2601.18625",
      "author": "Zequn Xie",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces CONQUER, a two-stage framework for text-based person search that improves cross-modal alignment using optimal transport and a plug-and-play query enhancement module at inference time.",
      "importance_score": 42,
      "reasoning": "Solid applied CV work for pedestrian retrieval but incremental contributions to cross-modal alignment without major novelty.",
      "themes": [
        "Computer Vision",
        "Cross-Modal Learning",
        "Person Re-identification"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces CONQUER, a two-stage framework for text-based person search that improves cross-modal alignment using optimal transport and a plug-and-play query enhancement module at inference time.</p>",
      "content_html": "<p>arXiv:2601.18625v1 Announce Type: new  Abstract: Text-Based Person Search (TBPS) aims to retrieve pedestrian images from large galleries using natural language descriptions. This task, essential for public safety applications, is hindered by cross-modal discrepancies and ambiguous user queries. We introduce CONQUER, a two-stage framework designed to address these challenges by enhancing cross-modal alignment during training and adaptively refining queries at inference. During training, CONQUER employs multi-granularity encoding, complementary pair mining, and context-guided optimal matching based on Optimal Transport to learn robust embeddings. At inference, a plug-and-play query enhancement module refines vague or incomplete queries via anchor selection and attribute-driven enrichment, without requiring retraining of the backbone. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that CONQUER consistently outperforms strong baselines in both Rank-1 accuracy and mAP, yielding notable improvements in cross-domain and incomplete-query scenarios. These results highlight CONQUER as a practical and effective solution for real-world TBPS deployment. Source code is available at https://github.com/zqxie77/CONQUER.</p>"
    },
    {
      "id": "fa3bbf5bbd31",
      "title": "Quest2ROS2: A ROS 2 Framework for Bi-manual VR Teleoperation",
      "content": "arXiv:2601.18289v1 Announce Type: new  Abstract: Quest2ROS2 is an open-source ROS2 framework for bi-manual teleoperation designed to scale robot data collection. Extending Quest2ROS, it overcomes workspace limitations via relative motion-based control, calculating robot movement from VR controller pose changes to enable intuitive, pose-independent operation. The framework integrates essential usability and safety features, including real-time RViz visualization, streamlined gripper control, and a pause-and-reset function for smooth transitions. We detail a modular architecture that supports \"Side-by-Side\" and \"Mirror\" control modes to optimize operator experience across diverse platforms. Code is available at: https://github.com/Taokt/Quest2ROS2.",
      "url": "http://arxiv.org/abs/2601.18289",
      "author": "Jialong Li, Zhenguo Wang, Tianci Wang, Maj Stenmark, Volker Krueger",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents Quest2ROS2, open-source ROS2 framework for bi-manual VR teleoperation with relative motion-based control overcoming workspace limitations.",
      "importance_score": 42,
      "reasoning": "Useful infrastructure contribution but primarily engineering work with limited research novelty.",
      "themes": [
        "Teleoperation",
        "VR",
        "Robotics Infrastructure"
      ],
      "continuation": null,
      "summary_html": "<p>Presents Quest2ROS2, open-source ROS2 framework for bi-manual VR teleoperation with relative motion-based control overcoming workspace limitations.</p>",
      "content_html": "<p>arXiv:2601.18289v1 Announce Type: new  Abstract: Quest2ROS2 is an open-source ROS2 framework for bi-manual teleoperation designed to scale robot data collection. Extending Quest2ROS, it overcomes workspace limitations via relative motion-based control, calculating robot movement from VR controller pose changes to enable intuitive, pose-independent operation. The framework integrates essential usability and safety features, including real-time RViz visualization, streamlined gripper control, and a pause-and-reset function for smooth transitions. We detail a modular architecture that supports \"Side-by-Side\" and \"Mirror\" control modes to optimize operator experience across diverse platforms. Code is available at: https://github.com/Taokt/Quest2ROS2.</p>"
    },
    {
      "id": "2ec4c2eb5caf",
      "title": "MV-S2V: Multi-View Subject-Consistent Video Generation",
      "content": "arXiv:2601.17756v1 Announce Type: cross  Abstract: Existing Subject-to-Video Generation (S2V) methods have achieved high-fidelity and subject-consistent video generation, yet remain constrained to single-view subject references. This limitation renders the S2V task reducible to an S2I + I2V pipeline, failing to exploit the full potential of video subject control. In this work, we propose and address the challenging Multi-View S2V (MV-S2V) task, which synthesizes videos from multiple reference views to enforce 3D-level subject consistency. Regarding the scarcity of training data, we first develop a synthetic data curation pipeline to generate highly customized synthetic data, complemented by a small-scale real-world captured dataset to boost the training of MV-S2V. Another key issue lies in the potential confusion between cross-subject and cross-view references in conditional generation. To overcome this, we further introduce Temporally Shifted RoPE (TS-RoPE) to distinguish between different subjects and distinct views of the same subject in reference conditioning. Our framework achieves superior 3D subject consistency w.r.t. multi-view reference images and high-quality visual outputs, establishing a new meaningful direction for subject-driven video generation. Our project page is available at <a href=\"https://szy-young.github.io/mv-s2v\">this URL</a>",
      "url": "http://arxiv.org/abs/2601.17756",
      "author": "Ziyang Song, Xinyu Gong, Bangya Liu, Zelin Zhao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "MV-S2V addresses multi-view subject-to-video generation with synthetic data pipeline and real-world captured dataset for 3D-consistent subject control.",
      "importance_score": 41,
      "reasoning": "Novel task formulation beyond single-view S2V. Data curation contribution.",
      "themes": [
        "Video Generation",
        "3D Consistency",
        "Subject Control"
      ],
      "continuation": null,
      "summary_html": "<p>MV-S2V addresses multi-view subject-to-video generation with synthetic data pipeline and real-world captured dataset for 3D-consistent subject control.</p>",
      "content_html": "<p>arXiv:2601.17756v1 Announce Type: cross  Abstract: Existing Subject-to-Video Generation (S2V) methods have achieved high-fidelity and subject-consistent video generation, yet remain constrained to single-view subject references. This limitation renders the S2V task reducible to an S2I + I2V pipeline, failing to exploit the full potential of video subject control. In this work, we propose and address the challenging Multi-View S2V (MV-S2V) task, which synthesizes videos from multiple reference views to enforce 3D-level subject consistency. Regarding the scarcity of training data, we first develop a synthetic data curation pipeline to generate highly customized synthetic data, complemented by a small-scale real-world captured dataset to boost the training of MV-S2V. Another key issue lies in the potential confusion between cross-subject and cross-view references in conditional generation. To overcome this, we further introduce Temporally Shifted RoPE (TS-RoPE) to distinguish between different subjects and distinct views of the same subject in reference conditioning. Our framework achieves superior 3D subject consistency w.r.t. multi-view reference images and high-quality visual outputs, establishing a new meaningful direction for subject-driven video generation. Our project page is available at <a href=\"https://szy-young.github.io/mv-s2v\" rel=\"noopener noreferrer\">this URL</a></p>"
    },
    {
      "id": "64d959bf9072",
      "title": "An Unsupervised Tensor-Based Domain Alignment",
      "content": "arXiv:2601.18564v1 Announce Type: cross  Abstract: We propose a tensor-based domain alignment (DA) algorithm designed to align source and target tensors within an invariant subspace through the use of alignment matrices. These matrices along with the subspace undergo iterative optimization of which constraint is on oblique manifold, which offers greater flexibility and adaptability compared to the traditional Stiefel manifold. Moreover, regularization terms defined to preserve the variance of both source and target tensors, ensures robust performance. Our framework is versatile, effectively generalizing existing tensor-based DA methods as special cases. Through extensive experiments, we demonstrate that our approach not only enhances DA conversion speed but also significantly boosts classification accuracy. This positions our method as superior to current state-of-the-art techniques, making it a preferable choice for complex domain adaptation tasks.",
      "url": "http://arxiv.org/abs/2601.18564",
      "author": "Chong Hyun Lee, Kibae Lee, Hyun Hee Yim",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes tensor-based domain alignment algorithm using alignment matrices on oblique manifold with regularization to preserve variance of source and target tensors.",
      "importance_score": 41,
      "reasoning": "Incremental improvement to domain adaptation methodology without major novelty.",
      "themes": [
        "Domain Adaptation",
        "Transfer Learning",
        "Tensor Methods"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes tensor-based domain alignment algorithm using alignment matrices on oblique manifold with regularization to preserve variance of source and target tensors.</p>",
      "content_html": "<p>arXiv:2601.18564v1 Announce Type: cross  Abstract: We propose a tensor-based domain alignment (DA) algorithm designed to align source and target tensors within an invariant subspace through the use of alignment matrices. These matrices along with the subspace undergo iterative optimization of which constraint is on oblique manifold, which offers greater flexibility and adaptability compared to the traditional Stiefel manifold. Moreover, regularization terms defined to preserve the variance of both source and target tensors, ensures robust performance. Our framework is versatile, effectively generalizing existing tensor-based DA methods as special cases. Through extensive experiments, we demonstrate that our approach not only enhances DA conversion speed but also significantly boosts classification accuracy. This positions our method as superior to current state-of-the-art techniques, making it a preferable choice for complex domain adaptation tasks.</p>"
    },
    {
      "id": "16d68c1b1ae9",
      "title": "Intelligence Requires Grounding But Not Embodiment",
      "content": "arXiv:2601.17588v1 Announce Type: new  Abstract: Recent advances in LLMs have reignited scientific debate over whether embodiment is necessary for intelligence. We present the argument that intelligence requires grounding, a phenomenon entailed by embodiment, but not embodiment itself. We define intelligence as the possession of four properties -- motivation, predictive ability, understanding of causality, and learning from experience -- and argue that each can be achieved by a non-embodied, grounded agent. We use this to conclude that grounding, not embodiment, is necessary for intelligence. We then present a thought experiment of an intelligent LLM agent in a digital environment and address potential counterarguments.",
      "url": "http://arxiv.org/abs/2601.17588",
      "author": "Marcus Ma, Shrikanth Narayanan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Argues philosophically that intelligence requires grounding (connection to meaning) but not necessarily physical embodiment, proposing four properties of intelligence achievable by non-embodied grounded agents.",
      "importance_score": 40,
      "reasoning": "Philosophical position paper; interesting perspective but lacks empirical validation or technical contribution.",
      "themes": [
        "AGI Theory",
        "Embodiment",
        "Philosophy of AI"
      ],
      "continuation": null,
      "summary_html": "<p>Argues philosophically that intelligence requires grounding (connection to meaning) but not necessarily physical embodiment, proposing four properties of intelligence achievable by non-embodied grounded agents.</p>",
      "content_html": "<p>arXiv:2601.17588v1 Announce Type: new  Abstract: Recent advances in LLMs have reignited scientific debate over whether embodiment is necessary for intelligence. We present the argument that intelligence requires grounding, a phenomenon entailed by embodiment, but not embodiment itself. We define intelligence as the possession of four properties -- motivation, predictive ability, understanding of causality, and learning from experience -- and argue that each can be achieved by a non-embodied, grounded agent. We use this to conclude that grounding, not embodiment, is necessary for intelligence. We then present a thought experiment of an intelligent LLM agent in a digital environment and address potential counterarguments.</p>"
    },
    {
      "id": "c7909a820df2",
      "title": "Summary of the Unusual Activity Recognition Challenge for Developmental Disability Support",
      "content": "arXiv:2601.17049v1 Announce Type: cross  Abstract: This paper presents an overview of the Recognize the Unseen: Unusual Behavior Recognition from Pose Data Challenge, hosted at ISAS 2025. The challenge aims to address the critical need for automated recognition of unusual behaviors in facilities for individuals with developmental disabilities using non-invasive pose estimation data. Participating teams were tasked with distinguishing between normal and unusual activities based on skeleton keypoints extracted from video recordings of simulated scenarios. The dataset reflects real-world imbalance and temporal irregularities in behavior, and the evaluation adopted a Leave-One-Subject-Out (LOSO) strategy to ensure subject-agnostic generalization. The challenge attracted broad participation from 40 teams applying diverse approaches ranging from classical machine learning to deep learning architectures. Submissions were assessed primarily using macro-averaged F1 scores to account for class imbalance. The results highlight the difficulty of modeling rare, abrupt actions in noisy, low-dimensional data, and emphasize the importance of capturing both temporal and contextual nuances in behavior modeling. Insights from this challenge may contribute to future developments in socially responsible AI applications for healthcare and behavior monitoring.",
      "url": "http://arxiv.org/abs/2601.17049",
      "author": "Christina Garcia, Nhat Tan Le, Taihei Fujioka, Umang Dobhal, Milyun Ni'ma Shoumi, Thanh Nha Nguyen, Sozo Inoue",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Overview of challenge for recognizing unusual behaviors from pose estimation data in facilities for individuals with developmental disabilities using Leave-One-Subject-Out evaluation.",
      "importance_score": 40,
      "reasoning": "Important application domain for assistive technology. Challenge summary provides useful benchmark but limited technical novelty.",
      "themes": [
        "Activity Recognition",
        "Assistive Technology",
        "Pose Estimation"
      ],
      "continuation": null,
      "summary_html": "<p>Overview of challenge for recognizing unusual behaviors from pose estimation data in facilities for individuals with developmental disabilities using Leave-One-Subject-Out evaluation.</p>",
      "content_html": "<p>arXiv:2601.17049v1 Announce Type: cross  Abstract: This paper presents an overview of the Recognize the Unseen: Unusual Behavior Recognition from Pose Data Challenge, hosted at ISAS 2025. The challenge aims to address the critical need for automated recognition of unusual behaviors in facilities for individuals with developmental disabilities using non-invasive pose estimation data. Participating teams were tasked with distinguishing between normal and unusual activities based on skeleton keypoints extracted from video recordings of simulated scenarios. The dataset reflects real-world imbalance and temporal irregularities in behavior, and the evaluation adopted a Leave-One-Subject-Out (LOSO) strategy to ensure subject-agnostic generalization. The challenge attracted broad participation from 40 teams applying diverse approaches ranging from classical machine learning to deep learning architectures. Submissions were assessed primarily using macro-averaged F1 scores to account for class imbalance. The results highlight the difficulty of modeling rare, abrupt actions in noisy, low-dimensional data, and emphasize the importance of capturing both temporal and contextual nuances in behavior modeling. Insights from this challenge may contribute to future developments in socially responsible AI applications for healthcare and behavior monitoring.</p>"
    },
    {
      "id": "35ea9ad96e59",
      "title": "Dynamic Meta-Ensemble Framework for Efficient and Accurate Deep Learning in Plant Leaf Disease Detection on Resource-Constrained Edge Devices",
      "content": "arXiv:2601.17290v1 Announce Type: cross  Abstract: Deploying deep learning models for plant disease detection on edge devices such as IoT sensors, smartphones, and embedded systems is severely constrained by limited computational resources and energy budgets. To address this challenge, we introduce a novel Dynamic Meta-Ensemble Framework (DMEF) for high-accuracy plant disease diagnosis under resource constraints. DMEF employs an adaptive weighting mechanism that dynamically combines the predictions of three lightweight convolutional neural networks (MobileNetV2, NASNetMobile, and InceptionV3) by optimizing a trade-off between accuracy improvements (DeltaAcc) and computational efficiency (model size). During training, the ensemble weights are updated iteratively, favoring models exhibiting high performance and low complexity. Extensive experiments on benchmark datasets for potato and maize diseases demonstrate state-of-the-art classification accuracies of 99.53% and 96.61%, respectively, surpassing standalone models and static ensembles by 2.1% and 6.3%. With computationally efficient inference latency (<75ms) and a compact footprint (<1 million parameters), DMEF shows strong potential for edge-based agricultural monitoring, suggesting viability for scalable crop disease management. This bridges the gap between high-accuracy AI and practical field applications.",
      "url": "http://arxiv.org/abs/2601.17290",
      "author": "Weloday Fikadu Moges, Jianmei Su, Amin Waqas",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces Dynamic Meta-Ensemble Framework combining MobileNetV2, NASNetMobile, and InceptionV3 with adaptive weighting for plant disease detection on edge devices.",
      "importance_score": 40,
      "reasoning": "Applied ensemble learning for edge deployment. Standard techniques applied to agricultural domain.",
      "themes": [
        "Edge AI",
        "Ensemble Learning",
        "Agricultural AI"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Dynamic Meta-Ensemble Framework combining MobileNetV2, NASNetMobile, and InceptionV3 with adaptive weighting for plant disease detection on edge devices.</p>",
      "content_html": "<p>arXiv:2601.17290v1 Announce Type: cross  Abstract: Deploying deep learning models for plant disease detection on edge devices such as IoT sensors, smartphones, and embedded systems is severely constrained by limited computational resources and energy budgets. To address this challenge, we introduce a novel Dynamic Meta-Ensemble Framework (DMEF) for high-accuracy plant disease diagnosis under resource constraints. DMEF employs an adaptive weighting mechanism that dynamically combines the predictions of three lightweight convolutional neural networks (MobileNetV2, NASNetMobile, and InceptionV3) by optimizing a trade-off between accuracy improvements (DeltaAcc) and computational efficiency (model size). During training, the ensemble weights are updated iteratively, favoring models exhibiting high performance and low complexity. Extensive experiments on benchmark datasets for potato and maize diseases demonstrate state-of-the-art classification accuracies of 99.53% and 96.61%, respectively, surpassing standalone models and static ensembles by 2.1% and 6.3%. With computationally efficient inference latency (&lt;75ms) and a compact footprint (&lt;1 million parameters), DMEF shows strong potential for edge-based agricultural monitoring, suggesting viability for scalable crop disease management. This bridges the gap between high-accuracy AI and practical field applications.</p>"
    },
    {
      "id": "7764722d3284",
      "title": "BrainDistill: Implantable Motor Decoding with Task-Specific Knowledge Distillation",
      "content": "arXiv:2601.17625v1 Announce Type: cross  Abstract: Transformer-based neural decoders with large parameter counts, pre-trained on large-scale datasets, have recently outperformed classical machine learning models and small neural networks on brain-computer interface (BCI) tasks. However, their large parameter counts and high computational demands hinder deployment in power-constrained implantable systems. To address this challenge, we introduce BrainDistill, a novel implantable motor decoding pipeline that integrates an implantable neural decoder (IND) with a task-specific knowledge distillation (TSKD) framework. Unlike standard feature distillation methods that attempt to preserve teacher representations in full, TSKD explicitly prioritizes features critical for decoding through supervised projection. Across multiple neural datasets, IND consistently outperforms prior neural decoders on motor decoding tasks, while its TSKD-distilled variant further surpasses alternative distillation methods in few-shot calibration settings. Finally, we present a quantization-aware training scheme that enables integer-only inference with activation clipping ranges learned during training. The quantized IND enables deployment under the strict power constraints of implantable BCIs with minimal performance loss.",
      "url": "http://arxiv.org/abs/2601.17625",
      "author": "Yuhan Xie, Jinhan Liu, Xiaoyong Ni, Fei Tan, Icare Sakr, Thibault Collin, Shiqi Sun, Alejandro Rodriguez Guajardo, Demon Fanny, Charles-francois Vincent Latchoumane, Henri Lorach, Jocelyne Bloch, Gregoire Courtine, Mahsa Shoaran",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "BrainDistill uses task-specific knowledge distillation for implantable BCIs, prioritizing decoding-critical features for power-constrained deployment.",
      "importance_score": 40,
      "reasoning": "Important for real-world BCI deployment. Task-specific distillation approach.",
      "themes": [
        "Brain-Computer Interfaces",
        "Knowledge Distillation",
        "Edge AI"
      ],
      "continuation": null,
      "summary_html": "<p>BrainDistill uses task-specific knowledge distillation for implantable BCIs, prioritizing decoding-critical features for power-constrained deployment.</p>",
      "content_html": "<p>arXiv:2601.17625v1 Announce Type: cross  Abstract: Transformer-based neural decoders with large parameter counts, pre-trained on large-scale datasets, have recently outperformed classical machine learning models and small neural networks on brain-computer interface (BCI) tasks. However, their large parameter counts and high computational demands hinder deployment in power-constrained implantable systems. To address this challenge, we introduce BrainDistill, a novel implantable motor decoding pipeline that integrates an implantable neural decoder (IND) with a task-specific knowledge distillation (TSKD) framework. Unlike standard feature distillation methods that attempt to preserve teacher representations in full, TSKD explicitly prioritizes features critical for decoding through supervised projection. Across multiple neural datasets, IND consistently outperforms prior neural decoders on motor decoding tasks, while its TSKD-distilled variant further surpasses alternative distillation methods in few-shot calibration settings. Finally, we present a quantization-aware training scheme that enables integer-only inference with activation clipping ranges learned during training. The quantized IND enables deployment under the strict power constraints of implantable BCIs with minimal performance loss.</p>"
    },
    {
      "id": "c0de09ffa81b",
      "title": "Generative AI in Saudi Arabia: A National Survey of Adoption, Risks, and Public Perceptions",
      "content": "arXiv:2601.18234v1 Announce Type: cross  Abstract: Generative Artificial Intelligence (GenAI) is rapidly becoming embedded in Saudi Arabia's digital transformation under Vision 2030, yet public awareness, adoption, and concerns surrounding these tools remain underexplored. This study provides an early snapshot of GenAI engagement among Saudi nationals. Using a nationwide survey of 330 participants across regions, age groups, and employment sectors, we examine seven dimensions of GenAI use: awareness and understanding, adoption patterns, perceived impacts, training needs, risks and barriers, data-sharing behaviors, and future expectations. Findings show that 93% of respondents actively use GenAI primarily for text-based tasks, while more advanced uses such as programming or multimodal generation are less common. Despite the prevalence of use, overall awareness and conceptual understanding remain uneven, with many reporting limited technical knowledge. Participants recognize GenAI's benefits for productivity, work quality, and understanding complex information, yet caution that sustained reliance may undermine critical thinking and key professional skills. Trust in AI-generated outputs remains cautious, with widespread concerns about privacy, misinformation, and ethical misuse, including potential job displacement. Respondents show strong interest in structured GenAI training that combines foundational skills, domain-specific applications, and clear guidance on privacy, ethics, and responsible use. These results establish a baseline for GenAI engagement in Saudi Arabia and highlight priorities for policymakers and developers: expanding AI literacy, ensuring culturally and linguistically aligned GenAI solutions, and strengthening frameworks for privacy and responsible deployment.",
      "url": "http://arxiv.org/abs/2601.18234",
      "author": "Abdulaziz AlDakheel, Ali Alshehre, Esraa Alamoudi, Moslim AlKhabbaz, Ahmed Aljohani, Raed Alharbi",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Nationwide survey of 330 participants examining generative AI adoption, risks, and perceptions in Saudi Arabia. Finds 93% actively use GenAI primarily for text tasks with limited advanced usage.",
      "importance_score": 40,
      "reasoning": "Regional adoption survey with modest sample size. Useful for understanding regional AI adoption but limited methodological novelty.",
      "themes": [
        "AI Adoption",
        "Survey Research",
        "Regional AI Studies"
      ],
      "continuation": null,
      "summary_html": "<p>Nationwide survey of 330 participants examining generative AI adoption, risks, and perceptions in Saudi Arabia. Finds 93% actively use GenAI primarily for text tasks with limited advanced usage.</p>",
      "content_html": "<p>arXiv:2601.18234v1 Announce Type: cross  Abstract: Generative Artificial Intelligence (GenAI) is rapidly becoming embedded in Saudi Arabia's digital transformation under Vision 2030, yet public awareness, adoption, and concerns surrounding these tools remain underexplored. This study provides an early snapshot of GenAI engagement among Saudi nationals. Using a nationwide survey of 330 participants across regions, age groups, and employment sectors, we examine seven dimensions of GenAI use: awareness and understanding, adoption patterns, perceived impacts, training needs, risks and barriers, data-sharing behaviors, and future expectations. Findings show that 93% of respondents actively use GenAI primarily for text-based tasks, while more advanced uses such as programming or multimodal generation are less common. Despite the prevalence of use, overall awareness and conceptual understanding remain uneven, with many reporting limited technical knowledge. Participants recognize GenAI's benefits for productivity, work quality, and understanding complex information, yet caution that sustained reliance may undermine critical thinking and key professional skills. Trust in AI-generated outputs remains cautious, with widespread concerns about privacy, misinformation, and ethical misuse, including potential job displacement. Respondents show strong interest in structured GenAI training that combines foundational skills, domain-specific applications, and clear guidance on privacy, ethics, and responsible use. These results establish a baseline for GenAI engagement in Saudi Arabia and highlight priorities for policymakers and developers: expanding AI literacy, ensuring culturally and linguistically aligned GenAI solutions, and strengthening frameworks for privacy and responsible deployment.</p>"
    },
    {
      "id": "2d09371ccc88",
      "title": "Reasoning-Enhanced Rare-Event Prediction with Balanced Outcome Correction",
      "content": "arXiv:2601.16406v1 Announce Type: new  Abstract: Rare-event prediction is critical in domains such as healthcare, finance, reliability engineering, customer support, aviation safety, where positive outcomes are infrequent yet potentially catastrophic. Extreme class imbalance biases conventional models toward majority-class predictions, limiting recall, calibration, and operational usefulness. We propose LPCORP (Low-Prevalence CORrector for Prediction)*, a two-stage framework that combines reasoningenhanced prediction with confidence-based outcome correction. A reasoning model first produces enriched predictions from narrative inputs, after which a lightweight logistic-regression classifier evaluates and selectively corrects these outputs to mitigate prevalence-driven bias. We evaluate LPCORP on real-world datasets from medical and consumer service domains. The results show that this method transforms a highly imbalanced setting into a well-balanced one while preserving the original number of samples and without applying any resampling strategies. Test-set evaluation demonstrates substantially improved performance, particularly in precision, which is a known weakness in low-prevalence data. We further provide a costreduction analysis comparing the expenses associated with rare-event damage control without preventive measures to those incurred when low-cost, prediction-based preventive interventions are applied that showed more than 50% reduction in some cases. * Patent pending: U.S. Provisional 63/933,518, filed 8 December 2025.",
      "url": "http://arxiv.org/abs/2601.16406",
      "author": "Vitaly Bulgakov, Alexander Turchin",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Introduces LPCORP, a two-stage framework for rare-event prediction combining reasoning-enhanced prediction with confidence-based outcome correction. Uses logistic regression to correct prevalence-driven bias in predictions.",
      "importance_score": 40,
      "reasoning": "Practical framework for important problem domain (rare events in healthcare/finance) but methodology is incremental.",
      "themes": [
        "Rare Event Prediction",
        "Healthcare AI",
        "Class Imbalance"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces LPCORP, a two-stage framework for rare-event prediction combining reasoning-enhanced prediction with confidence-based outcome correction. Uses logistic regression to correct prevalence-driven bias in predictions.</p>",
      "content_html": "<p>arXiv:2601.16406v1 Announce Type: new  Abstract: Rare-event prediction is critical in domains such as healthcare, finance, reliability engineering, customer support, aviation safety, where positive outcomes are infrequent yet potentially catastrophic. Extreme class imbalance biases conventional models toward majority-class predictions, limiting recall, calibration, and operational usefulness. We propose LPCORP (Low-Prevalence CORrector for Prediction)*, a two-stage framework that combines reasoningenhanced prediction with confidence-based outcome correction. A reasoning model first produces enriched predictions from narrative inputs, after which a lightweight logistic-regression classifier evaluates and selectively corrects these outputs to mitigate prevalence-driven bias. We evaluate LPCORP on real-world datasets from medical and consumer service domains. The results show that this method transforms a highly imbalanced setting into a well-balanced one while preserving the original number of samples and without applying any resampling strategies. Test-set evaluation demonstrates substantially improved performance, particularly in precision, which is a known weakness in low-prevalence data. We further provide a costreduction analysis comparing the expenses associated with rare-event damage control without preventive measures to those incurred when low-cost, prediction-based preventive interventions are applied that showed more than 50% reduction in some cases. * Patent pending: U.S. Provisional 63/933,518, filed 8 December 2025.</p>"
    },
    {
      "id": "23d5b5ac5bdb",
      "title": "Bayesian Experimental Design for Model Discrepancy Calibration: A Rivalry between Kullback--Leibler Divergence and Wasserstein Distance",
      "content": "arXiv:2601.16425v1 Announce Type: new  Abstract: Designing experiments that systematically gather data from complex physical systems is central to accelerating scientific discovery. While Bayesian experimental design (BED) provides a principled, information-based framework that integrates experimental planning with probabilistic inference, the selection of utility functions in BED is a long-standing and active topic, where different criteria emphasize different notions of information. Although Kullback--Leibler (KL) divergence has been one of the most common choices, recent studies have proposed Wasserstein distance as an alternative. In this work, we first employ a toy example to illustrate an issue of Wasserstein distance - the value of Wasserstein distance of a fixed-shape posterior depends on the relative position of its main mass within the support and can exhibit false rewards unrelated to information gain, especially with a non-informative prior (e.g., uniform distribution). We then further provide a systematic comparison between these two criteria through a classical source inversion problem in the BED literature, revealing that the KL divergence tends to lead to faster convergence in the absence of model discrepancy, while Wasserstein metrics provide more robust sequential BED results if model discrepancy is non-negligible. These findings clarify the trade-offs between KL divergence and Wasserstein metrics for the utility function and provide guidelines for selecting suitable criteria in practical BED applications.",
      "url": "http://arxiv.org/abs/2601.16425",
      "author": "Huchen Yang, Xinghao Dong, Jin-Long Wu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Compares KL divergence vs Wasserstein distance as utility functions for Bayesian experimental design. Identifies an issue with Wasserstein distance where its value depends on posterior shape rather than just location.",
      "importance_score": 40,
      "reasoning": "Useful methodological comparison for experimental design practitioners; provides practical guidance for utility function selection.",
      "themes": [
        "Bayesian Methods",
        "Experimental Design",
        "Uncertainty Quantification"
      ],
      "continuation": null,
      "summary_html": "<p>Compares KL divergence vs Wasserstein distance as utility functions for Bayesian experimental design. Identifies an issue with Wasserstein distance where its value depends on posterior shape rather than just location.</p>",
      "content_html": "<p>arXiv:2601.16425v1 Announce Type: new  Abstract: Designing experiments that systematically gather data from complex physical systems is central to accelerating scientific discovery. While Bayesian experimental design (BED) provides a principled, information-based framework that integrates experimental planning with probabilistic inference, the selection of utility functions in BED is a long-standing and active topic, where different criteria emphasize different notions of information. Although Kullback--Leibler (KL) divergence has been one of the most common choices, recent studies have proposed Wasserstein distance as an alternative. In this work, we first employ a toy example to illustrate an issue of Wasserstein distance - the value of Wasserstein distance of a fixed-shape posterior depends on the relative position of its main mass within the support and can exhibit false rewards unrelated to information gain, especially with a non-informative prior (e.g., uniform distribution). We then further provide a systematic comparison between these two criteria through a classical source inversion problem in the BED literature, revealing that the KL divergence tends to lead to faster convergence in the absence of model discrepancy, while Wasserstein metrics provide more robust sequential BED results if model discrepancy is non-negligible. These findings clarify the trade-offs between KL divergence and Wasserstein metrics for the utility function and provide guidelines for selecting suitable criteria in practical BED applications.</p>"
    },
    {
      "id": "0b01e15b3dac",
      "title": "Process-Tensor Tomography of SGD: Measuring Non-Markovian Memory via Back-Flow of Distinguishability",
      "content": "arXiv:2601.16563v1 Announce Type: new  Abstract: This work proposes neural training as a \\emph{process tensor}: a multi-time map that takes a sequence of controllable instruments (batch choices, augmentations, optimizer micro-steps) and returns an observable of the trained model. Building on this operational lens, we introduce a simple, model-agnostic witness of training memory based on \\emph{back-flow of distinguishability}. In a controlled two-step protocol, we compare outcome distributions after one intervention versus two; the increase $\\Delta_{\\mathrm{BF}} = D_2 - D_1>0$ (with $D\\in\\{\\mathrm{TV}, \\mathrm{JS}, \\mathrm{H}\\}$ measured on softmax predictions over a fixed probe set) certifies non-Markovianity. We observe consistent positive back-flow with tight bootstrap confidence intervals, amplification under higher momentum, larger batch overlap, and more micro-steps, and collapse under a \\emph{causal break} (resetting optimizer state), directly attributing the effect to optimizer/data-state memory. The witness is robust across TV/JS/Hellinger, inexpensive to compute, and requires no architectural changes. We position this as a \\emph{measurement} contribution: a principled diagnostic and empirical evidence that practical SGD deviates from the Markov idealization. An exploratory case study illustrates how the micro-level signal can inform curriculum orderings. \"Data order matters\" turns into a testable operator with confidence bounds, our framework offers a common stage to compare optimizers, curricula, and schedules through their induced training memory.",
      "url": "http://arxiv.org/abs/2601.16563",
      "author": "Vasileios Sevetlidis, George Pavlidis",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes viewing neural network training as a 'process tensor' and introduces back-flow of distinguishability as a witness of training memory. Demonstrates non-Markovianity in SGD training dynamics.",
      "importance_score": 40,
      "reasoning": "Novel theoretical perspective on training dynamics; interesting conceptual contribution but unclear practical implications.",
      "themes": [
        "Training Dynamics",
        "Optimization Theory",
        "Stochastic Gradient Descent"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes viewing neural network training as a 'process tensor' and introduces back-flow of distinguishability as a witness of training memory. Demonstrates non-Markovianity in SGD training dynamics.</p>",
      "content_html": "<p>arXiv:2601.16563v1 Announce Type: new  Abstract: This work proposes neural training as a \\emph{process tensor}: a multi-time map that takes a sequence of controllable instruments (batch choices, augmentations, optimizer micro-steps) and returns an observable of the trained model. Building on this operational lens, we introduce a simple, model-agnostic witness of training memory based on \\emph{back-flow of distinguishability}. In a controlled two-step protocol, we compare outcome distributions after one intervention versus two; the increase $\\Delta_{\\mathrm{BF}} = D_2 - D_1&gt;0$ (with $D\\in\\{\\mathrm{TV}, \\mathrm{JS}, \\mathrm{H}\\}$ measured on softmax predictions over a fixed probe set) certifies non-Markovianity. We observe consistent positive back-flow with tight bootstrap confidence intervals, amplification under higher momentum, larger batch overlap, and more micro-steps, and collapse under a \\emph{causal break} (resetting optimizer state), directly attributing the effect to optimizer/data-state memory. The witness is robust across TV/JS/Hellinger, inexpensive to compute, and requires no architectural changes. We position this as a \\emph{measurement} contribution: a principled diagnostic and empirical evidence that practical SGD deviates from the Markov idealization. An exploratory case study illustrates how the micro-level signal can inform curriculum orderings. \"Data order matters\" turns into a testable operator with confidence bounds, our framework offers a common stage to compare optimizers, curricula, and schedules through their induced training memory.</p>"
    },
    {
      "id": "7d29857b690b",
      "title": "Dual-Prototype Disentanglement: A Context-Aware Enhancement Framework for Time Series Forecasting",
      "content": "arXiv:2601.16632v1 Announce Type: new  Abstract: Time series forecasting has witnessed significant progress with deep learning. While prevailing approaches enhance forecasting performance by modifying architectures or introducing novel enhancement strategies, they often fail to dynamically disentangle and leverage the complex, intertwined temporal patterns inherent in time series, thus resulting in the learning of static, averaged representations that lack context-aware capabilities. To address this, we propose the Dual-Prototype Adaptive Disentanglement framework (DPAD), a model-agnostic auxiliary method that equips forecasting models with the ability of pattern disentanglement and context-aware adaptation. Specifically, we construct a Dynamic Dual-Prototype bank (DDP), comprising a common pattern bank with strong temporal priors to capture prevailing trend or seasonal patterns, and a rare pattern bank dynamically memorizing critical yet infrequent events, and then an Dual-Path Context-aware routing (DPC) mechanism is proposed to enhance outputs with selectively retrieved context-specific pattern representations from the DDP. Additionally, we introduce a Disentanglement-Guided Loss (DGLoss) to ensure that each prototype bank specializes in its designated role while maintaining comprehensive coverage. Comprehensive experiments demonstrate that DPAD consistently improves forecasting performance and reliability of state-of-the-art models across diverse real-world benchmarks.",
      "url": "http://arxiv.org/abs/2601.16632",
      "author": "Haonan Yang, Jianchao Tang, Zhuo Li",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes DPAD, a model-agnostic framework for time series forecasting that disentangles and leverages complex temporal patterns. Uses dual-prototype bank with common and distinctive components.",
      "importance_score": 40,
      "reasoning": "Solid contribution to time series forecasting; model-agnostic approach is practical but methodology is incremental.",
      "themes": [
        "Time Series Forecasting",
        "Pattern Disentanglement",
        "Deep Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes DPAD, a model-agnostic framework for time series forecasting that disentangles and leverages complex temporal patterns. Uses dual-prototype bank with common and distinctive components.</p>",
      "content_html": "<p>arXiv:2601.16632v1 Announce Type: new  Abstract: Time series forecasting has witnessed significant progress with deep learning. While prevailing approaches enhance forecasting performance by modifying architectures or introducing novel enhancement strategies, they often fail to dynamically disentangle and leverage the complex, intertwined temporal patterns inherent in time series, thus resulting in the learning of static, averaged representations that lack context-aware capabilities. To address this, we propose the Dual-Prototype Adaptive Disentanglement framework (DPAD), a model-agnostic auxiliary method that equips forecasting models with the ability of pattern disentanglement and context-aware adaptation. Specifically, we construct a Dynamic Dual-Prototype bank (DDP), comprising a common pattern bank with strong temporal priors to capture prevailing trend or seasonal patterns, and a rare pattern bank dynamically memorizing critical yet infrequent events, and then an Dual-Path Context-aware routing (DPC) mechanism is proposed to enhance outputs with selectively retrieved context-specific pattern representations from the DDP. Additionally, we introduce a Disentanglement-Guided Loss (DGLoss) to ensure that each prototype bank specializes in its designated role while maintaining comprehensive coverage. Comprehensive experiments demonstrate that DPAD consistently improves forecasting performance and reliability of state-of-the-art models across diverse real-world benchmarks.</p>"
    },
    {
      "id": "eaeb9f144af7",
      "title": "Uncertainty propagation through trained multi-layer perceptrons: Exact analytical results",
      "content": "arXiv:2601.16830v1 Announce Type: new  Abstract: We give analytical results for propagation of uncertainty through trained multi-layer perceptrons (MLPs) with a single hidden layer and ReLU activation functions. More precisely, we give expressions for the mean and variance of the output when the input is multivariate Gaussian. In contrast to previous results, we obtain exact expressions without resort to a series expansion.",
      "url": "http://arxiv.org/abs/2601.16830",
      "author": "Andrew Thompson, Miles McCrory",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Provides exact analytical expressions for mean and variance of MLP output when input is multivariate Gaussian. Works for single hidden layer with ReLU activations without series expansion.",
      "importance_score": 40,
      "reasoning": "Useful theoretical result for uncertainty propagation; exact expressions are valuable but limited to simple architectures.",
      "themes": [
        "Uncertainty Quantification",
        "Neural Networks",
        "Analytical Methods"
      ],
      "continuation": null,
      "summary_html": "<p>Provides exact analytical expressions for mean and variance of MLP output when input is multivariate Gaussian. Works for single hidden layer with ReLU activations without series expansion.</p>",
      "content_html": "<p>arXiv:2601.16830v1 Announce Type: new  Abstract: We give analytical results for propagation of uncertainty through trained multi-layer perceptrons (MLPs) with a single hidden layer and ReLU activation functions. More precisely, we give expressions for the mean and variance of the output when the input is multivariate Gaussian. In contrast to previous results, we obtain exact expressions without resort to a series expansion.</p>"
    },
    {
      "id": "17d869ce0efe",
      "title": "Calibrated Similarity for Reliable Geometric Analysis of Embedding Spaces",
      "content": "arXiv:2601.16907v1 Announce Type: new  Abstract: While raw cosine similarity in pretrained embedding spaces exhibits strong rank correlation with human judgments, anisotropy induces systematic miscalibration of absolute values: scores concentrate in a narrow high-similarity band regardless of actual semantic relatedness, limiting interpretability as a quantitative measure. Prior work addresses this by modifying the embedding space (whitening, contrastive fine tuning), but such transformations alter geometric structure and require recomputing all embeddings.   Using isotonic regression trained on human similarity judgments, we construct a monotonic transformation that achieves near-perfect calibration while preserving rank correlation and local stability(98% across seven perturbation types). Our contribution is not to replace cosine similarity, but to restore interpretability of its absolute values through monotone calibration, without altering its ranking properties.   We characterize isotonic calibration as an order-preserving reparameterization and prove that all order-based constructions (angular ordering, nearest neighbors, threshold graphs and quantile-based decisions) are invariant under this transformation.",
      "url": "http://arxiv.org/abs/2601.16907",
      "author": "Nicolas Tacheny",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Uses isotonic regression to calibrate cosine similarity in embedding spaces to human judgments. Achieves near-perfect calibration while preserving rank correlation and local stability.",
      "importance_score": 40,
      "reasoning": "Practical solution to known anisotropy problem in embeddings; simple but effective approach.",
      "themes": [
        "Embeddings",
        "Calibration",
        "Semantic Similarity"
      ],
      "continuation": null,
      "summary_html": "<p>Uses isotonic regression to calibrate cosine similarity in embedding spaces to human judgments. Achieves near-perfect calibration while preserving rank correlation and local stability.</p>",
      "content_html": "<p>arXiv:2601.16907v1 Announce Type: new  Abstract: While raw cosine similarity in pretrained embedding spaces exhibits strong rank correlation with human judgments, anisotropy induces systematic miscalibration of absolute values: scores concentrate in a narrow high-similarity band regardless of actual semantic relatedness, limiting interpretability as a quantitative measure. Prior work addresses this by modifying the embedding space (whitening, contrastive fine tuning), but such transformations alter geometric structure and require recomputing all embeddings.   Using isotonic regression trained on human similarity judgments, we construct a monotonic transformation that achieves near-perfect calibration while preserving rank correlation and local stability(98% across seven perturbation types). Our contribution is not to replace cosine similarity, but to restore interpretability of its absolute values through monotone calibration, without altering its ranking properties.   We characterize isotonic calibration as an order-preserving reparameterization and prove that all order-based constructions (angular ordering, nearest neighbors, threshold graphs and quantile-based decisions) are invariant under this transformation.</p>"
    },
    {
      "id": "b674918090aa",
      "title": "Group-realizable multi-group learning by minimizing empirical risk",
      "content": "arXiv:2601.16922v1 Announce Type: new  Abstract: The sample complexity of multi-group learning is shown to improve in the group-realizable setting over the agnostic setting, even when the family of groups is infinite so long as it has finite VC dimension. The improved sample complexity is obtained by empirical risk minimization over the class of group-realizable concepts, which itself could have infinite VC dimension. Implementing this approach is also shown to be computationally intractable, and an alternative approach is suggested based on improper learning.",
      "url": "http://arxiv.org/abs/2601.16922",
      "author": "Navid Ardeshir, Samuel Deng, Daniel Hsu, Jingwen Liu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Shows sample complexity of multi-group learning improves in group-realizable setting with ERM. Also proves implementing this is computationally intractable when group class has infinite VC dimension.",
      "importance_score": 40,
      "reasoning": "Solid theoretical contribution to multi-group fairness; identifies fundamental computational barriers.",
      "themes": [
        "Multi-group Learning",
        "Sample Complexity",
        "Computational Complexity",
        "Fairness"
      ],
      "continuation": null,
      "summary_html": "<p>Shows sample complexity of multi-group learning improves in group-realizable setting with ERM. Also proves implementing this is computationally intractable when group class has infinite VC dimension.</p>",
      "content_html": "<p>arXiv:2601.16922v1 Announce Type: new  Abstract: The sample complexity of multi-group learning is shown to improve in the group-realizable setting over the agnostic setting, even when the family of groups is infinite so long as it has finite VC dimension. The improved sample complexity is obtained by empirical risk minimization over the class of group-realizable concepts, which itself could have infinite VC dimension. Implementing this approach is also shown to be computationally intractable, and an alternative approach is suggested based on improper learning.</p>"
    },
    {
      "id": "19244c82857a",
      "title": "Distributional Computational Graphs: Error Bounds",
      "content": "arXiv:2601.16250v1 Announce Type: cross  Abstract: We study a general framework of distributional computational graphs: computational graphs whose inputs are probability distributions rather than point values. We analyze the discretization error that arises when these graphs are evaluated using finite approximations of continuous probability distributions. Such an approximation might be the result of representing a continuous real-valued distribution using a discrete representation or from constructing an empirical distribution from samples (or might be the output of another distributional computational graph). We establish non-asymptotic error bounds in terms of the Wasserstein-1 distance, without imposing structural assumptions on the computational graph.",
      "url": "http://arxiv.org/abs/2601.16250",
      "author": "Olof Hallqvist Elias, Michael Selby, Phillip Stanley-Marbell",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "stat.ML"
      ],
      "summary": "Establishes non-asymptotic Wasserstein-1 error bounds for distributional computational graphs where inputs are probability distributions. Applies to empirical distributions and finite approximations.",
      "importance_score": 40,
      "reasoning": "Solid theoretical contribution for uncertainty propagation; general framework with broad applicability.",
      "themes": [
        "Uncertainty Quantification",
        "Computational Graphs",
        "Error Bounds"
      ],
      "continuation": null,
      "summary_html": "<p>Establishes non-asymptotic Wasserstein-1 error bounds for distributional computational graphs where inputs are probability distributions. Applies to empirical distributions and finite approximations.</p>",
      "content_html": "<p>arXiv:2601.16250v1 Announce Type: cross  Abstract: We study a general framework of distributional computational graphs: computational graphs whose inputs are probability distributions rather than point values. We analyze the discretization error that arises when these graphs are evaluated using finite approximations of continuous probability distributions. Such an approximation might be the result of representing a continuous real-valued distribution using a discrete representation or from constructing an empirical distribution from samples (or might be the output of another distributional computational graph). We establish non-asymptotic error bounds in terms of the Wasserstein-1 distance, without imposing structural assumptions on the computational graph.</p>"
    },
    {
      "id": "f71030e2c6bc",
      "title": "Perfect Clustering for Sparse Directed Stochastic Block Models",
      "content": "arXiv:2601.16427v1 Announce Type: cross  Abstract: Exact recovery in stochastic block models (SBMs) is well understood in undirected settings, but remains considerably less developed for directed and sparse networks, particularly when the number of communities diverges. Spectral methods for directed SBMs often lack stability in asymmetric, low-degree regimes, and existing non-spectral approaches focus primarily on undirected or dense settings.   We propose a fully non-spectral, two-stage procedure for community detection in sparse directed SBMs with potentially growing numbers of communities. The method first estimates the directed probability matrix using a neighborhood-smoothing scheme tailored to the asymmetric setting, and then applies $K$-means clustering to the estimated rows, thereby avoiding the limitations of eigen- or singular value decompositions in sparse, asymmetric networks. Our main theoretical contribution is a uniform row-wise concentration bound for the smoothed estimator, obtained through new arguments that control asymmetric neighborhoods and separate in- and out-degree effects. These results imply the exact recovery of all community labels with probability tending to one, under mild sparsity and separation conditions that allow both $\\gamma_n \\to 0$ and $K_n \\to \\infty$.   Simulation studies, including highly directed, sparse, and non-symmetric block structures, demonstrate that the proposed procedure performs reliably in regimes where directed spectral and score-based methods deteriorate. To the best of our knowledge, this provides the first exact recovery guarantee for this class of non-spectral, neighborhood-smoothing methods in the sparse, directed setting.",
      "url": "http://arxiv.org/abs/2601.16427",
      "author": "Behzad Aalipur, Yichen Qin",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "stat.ML"
      ],
      "summary": "Proposes non-spectral method for community detection in sparse directed stochastic block models. Uses neighborhood-smoothing followed by K-means, working when number of communities grows.",
      "importance_score": 40,
      "reasoning": "Extends community detection theory to more challenging directed/sparse settings; solid theoretical contribution.",
      "themes": [
        "Community Detection",
        "Network Analysis",
        "Clustering"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes non-spectral method for community detection in sparse directed stochastic block models. Uses neighborhood-smoothing followed by K-means, working when number of communities grows.</p>",
      "content_html": "<p>arXiv:2601.16427v1 Announce Type: cross  Abstract: Exact recovery in stochastic block models (SBMs) is well understood in undirected settings, but remains considerably less developed for directed and sparse networks, particularly when the number of communities diverges. Spectral methods for directed SBMs often lack stability in asymmetric, low-degree regimes, and existing non-spectral approaches focus primarily on undirected or dense settings.   We propose a fully non-spectral, two-stage procedure for community detection in sparse directed SBMs with potentially growing numbers of communities. The method first estimates the directed probability matrix using a neighborhood-smoothing scheme tailored to the asymmetric setting, and then applies $K$-means clustering to the estimated rows, thereby avoiding the limitations of eigen- or singular value decompositions in sparse, asymmetric networks. Our main theoretical contribution is a uniform row-wise concentration bound for the smoothed estimator, obtained through new arguments that control asymmetric neighborhoods and separate in- and out-degree effects. These results imply the exact recovery of all community labels with probability tending to one, under mild sparsity and separation conditions that allow both $\\gamma_n \\to 0$ and $K_n \\to \\infty$.   Simulation studies, including highly directed, sparse, and non-symmetric block structures, demonstrate that the proposed procedure performs reliably in regimes where directed spectral and score-based methods deteriorate. To the best of our knowledge, this provides the first exact recovery guarantee for this class of non-spectral, neighborhood-smoothing methods in the sparse, directed setting.</p>"
    },
    {
      "id": "6db3b23ae929",
      "title": "Neurocomputational Mechanisms of Syntactic Transfer in Bilingual Sentence Production",
      "content": "arXiv:2601.18056v1 Announce Type: new  Abstract: We discuss the benefits of incorporating into the study of bilingual production errors and their traditionally documented timing signatures (e.g., event-related potentials) certain types of oscillatory signatures, which can offer new implementational-level constraints for theories of bilingualism. We argue that a recent neural model of language, ROSE, can offer a neurocomputational account of syntactic transfer in bilingual production, capturing some of its formal properties and the scope of morphosyntactic sequencing failure modes. We take as a case study cross-linguistic influence (CLI) and attendant theories of functional inhibition/competition, and present these as being driven by specific oscillatory failure modes during L2 sentence planning. We argue that modeling CLI in this way not only offers the kind of linking hypothesis ROSE was built to encourage, but also licenses the exploration of more spatiotemporally complex biomarkers of language dysfunction than more commonly discussed neural signatures.",
      "url": "http://arxiv.org/abs/2601.18056",
      "author": "Ahmet Yavuz Uluslu, Elliot Murphy",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Discusses incorporating oscillatory neural signatures into study of bilingual production errors, proposing ROSE model can account for syntactic transfer and cross-linguistic influence.",
      "importance_score": 40,
      "reasoning": "Theoretical neurolinguistics work with limited direct AI relevance. Specialized audience.",
      "themes": [
        "Neurolinguistics",
        "Bilingualism",
        "Cognitive Science"
      ],
      "continuation": null,
      "summary_html": "<p>Discusses incorporating oscillatory neural signatures into study of bilingual production errors, proposing ROSE model can account for syntactic transfer and cross-linguistic influence.</p>",
      "content_html": "<p>arXiv:2601.18056v1 Announce Type: new  Abstract: We discuss the benefits of incorporating into the study of bilingual production errors and their traditionally documented timing signatures (e.g., event-related potentials) certain types of oscillatory signatures, which can offer new implementational-level constraints for theories of bilingualism. We argue that a recent neural model of language, ROSE, can offer a neurocomputational account of syntactic transfer in bilingual production, capturing some of its formal properties and the scope of morphosyntactic sequencing failure modes. We take as a case study cross-linguistic influence (CLI) and attendant theories of functional inhibition/competition, and present these as being driven by specific oscillatory failure modes during L2 sentence planning. We argue that modeling CLI in this way not only offers the kind of linking hypothesis ROSE was built to encourage, but also licenses the exploration of more spatiotemporally complex biomarkers of language dysfunction than more commonly discussed neural signatures.</p>"
    },
    {
      "id": "36d627561ce7",
      "title": "Hybrid Deep Feature Extraction and ML for Construction and Demolition Debris Classification",
      "content": "arXiv:2601.17038v1 Announce Type: new  Abstract: The construction industry produces significant volumes of debris, making effective sorting and classification critical for sustainable waste management and resource recovery. This study presents a hybrid vision-based pipeline that integrates deep feature extraction with classical machine learning (ML) classifiers for automated construction and demolition (C\\&amp;D) debris classification. A novel dataset comprising 1,800 balanced, high-quality images representing four material categories, Ceramic/Tile, Concrete, Trash/Waste, and Wood was collected from real construction sites in the UAE, capturing diverse real-world conditions. Deep features were extracted using a pre-trained Xception network, and multiple ML classifiers, including SVM, kNN, Bagged Trees, LDA, and Logistic Regression, were systematically evaluated. The results demonstrate that hybrid pipelines using Xception features with simple classifiers such as Linear SVM, kNN, and Bagged Trees achieve state-of-the-art performance, with up to 99.5\\% accuracy and macro-F1 scores, surpassing more complex or end-to-end deep learning approaches. The analysis highlights the operational benefits of this approach for robust, field-deployable debris identification and provides pathways for future integration with robotics and onsite automation systems.",
      "url": "http://arxiv.org/abs/2601.17038",
      "author": "Obai Alashram, Nejad Alagha, Mahmoud AlKakuri, Zeeshan Swaveel, Abigail Copiaco",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents hybrid pipeline using deep feature extraction (Xception) with classical ML classifiers for construction debris classification on novel UAE dataset of 1,800 images across 4 material categories.",
      "importance_score": 40,
      "reasoning": "Applied computer vision with practical application but limited methodological innovation.",
      "themes": [
        "Image Classification",
        "Sustainability",
        "Dataset"
      ],
      "continuation": null,
      "summary_html": "<p>Presents hybrid pipeline using deep feature extraction (Xception) with classical ML classifiers for construction debris classification on novel UAE dataset of 1,800 images across 4 material categories.</p>",
      "content_html": "<p>arXiv:2601.17038v1 Announce Type: new  Abstract: The construction industry produces significant volumes of debris, making effective sorting and classification critical for sustainable waste management and resource recovery. This study presents a hybrid vision-based pipeline that integrates deep feature extraction with classical machine learning (ML) classifiers for automated construction and demolition (C\\&amp;D) debris classification. A novel dataset comprising 1,800 balanced, high-quality images representing four material categories, Ceramic/Tile, Concrete, Trash/Waste, and Wood was collected from real construction sites in the UAE, capturing diverse real-world conditions. Deep features were extracted using a pre-trained Xception network, and multiple ML classifiers, including SVM, kNN, Bagged Trees, LDA, and Logistic Regression, were systematically evaluated. The results demonstrate that hybrid pipelines using Xception features with simple classifiers such as Linear SVM, kNN, and Bagged Trees achieve state-of-the-art performance, with up to 99.5\\% accuracy and macro-F1 scores, surpassing more complex or end-to-end deep learning approaches. The analysis highlights the operational benefits of this approach for robust, field-deployable debris identification and provides pathways for future integration with robotics and onsite automation systems.</p>"
    },
    {
      "id": "e584bf67700d",
      "title": "GlassesGB: Controllable 2D GAN-Based Eyewear Personalization for 3D Gaussian Blendshapes Head Avatars",
      "content": "arXiv:2601.17088v1 Announce Type: new  Abstract: Virtual try-on systems allow users to interactively try different products within VR scenarios. However, most existing VTON methods operate only on predefined eyewear templates and lack support for fine-grained, user-driven customization. While GlassesGAN enables personalized 2D eyewear design, its capability remains limited to 2D image generation. Motivated by the success of 3D Gaussian Blendshapes in head reconstruction, we integrate these two techniques and propose GlassesGB, a framework that supports customizable eyewear generation for 3D head avatars. GlassesGB effectively bridges 2D generative customization with 3D head avatar rendering, addressing the challenge in achieving personalized eyewear design for VR applications. The implementation code is available at https://ruiyangju.github.io/GlassesGB.",
      "url": "http://arxiv.org/abs/2601.17088",
      "author": "Rui-Yang Ju, Jen-Shiun Chiang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes GlassesGB framework for customizable eyewear generation on 3D head avatars, bridging 2D GAN-based eyewear design with 3D Gaussian Blendshapes head reconstruction.",
      "importance_score": 40,
      "reasoning": "Application-specific system combining existing techniques for VR eyewear try-on.",
      "themes": [
        "3D Avatars",
        "Virtual Try-on",
        "Generative Models"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes GlassesGB framework for customizable eyewear generation on 3D head avatars, bridging 2D GAN-based eyewear design with 3D Gaussian Blendshapes head reconstruction.</p>",
      "content_html": "<p>arXiv:2601.17088v1 Announce Type: new  Abstract: Virtual try-on systems allow users to interactively try different products within VR scenarios. However, most existing VTON methods operate only on predefined eyewear templates and lack support for fine-grained, user-driven customization. While GlassesGAN enables personalized 2D eyewear design, its capability remains limited to 2D image generation. Motivated by the success of 3D Gaussian Blendshapes in head reconstruction, we integrate these two techniques and propose GlassesGB, a framework that supports customizable eyewear generation for 3D head avatars. GlassesGB effectively bridges 2D generative customization with 3D head avatar rendering, addressing the challenge in achieving personalized eyewear design for VR applications. The implementation code is available at https://ruiyangju.github.io/GlassesGB.</p>"
    },
    {
      "id": "90f31cc04030",
      "title": "Quantifying Ergonomics in the Elevate Soft Robotic Suit",
      "content": "arXiv:2601.17249v1 Announce Type: new  Abstract: Soft robotic suits have the potential to rehabilitate, assist, and augment the human body. The low weight, cost, and minimal form-factor of these devices make them ideal for daily use by both healthy and impaired individuals. However, challenges associated with data-driven, user-specific, and comfort-first design of human-robot interfaces using soft materials limit their widespread translation and adoption. In this work, we present the quantitative evaluation of ergonomics and comfort of the Elevate suit - a cable driven soft robotic suit that assists shoulder elevation. Using a motion-capture system and force sensors, we measured the suit's ergonomics during assisted shoulder elevation up to 70 degrees. Two 4-hour sessions were conducted with one subject, involving transmitting cable tensions of up to 200N with no discomfort reported. We estimated that the pressure applied to the shoulder during assisted movements was within the range seen in a human grasp (approximately 69.1-85.1kPa), and estimated volumetric compression of <3% and <8% across the torso and upper arm, respectively. These results provide early validation of Elevate's ergonomic design in preparation for future studies with patient groups.",
      "url": "http://arxiv.org/abs/2601.17249",
      "author": "Peter Bryan, Rejin John Varghese, Dario Farina",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Presents quantitative evaluation of ergonomics and comfort for the Elevate cable-driven soft robotic suit for shoulder elevation assistance.",
      "importance_score": 40,
      "reasoning": "Useful evaluation study for soft robotics but limited novelty beyond specific system evaluation.",
      "themes": [
        "Soft Robotics",
        "Wearable Robotics",
        "Ergonomics"
      ],
      "continuation": null,
      "summary_html": "<p>Presents quantitative evaluation of ergonomics and comfort for the Elevate cable-driven soft robotic suit for shoulder elevation assistance.</p>",
      "content_html": "<p>arXiv:2601.17249v1 Announce Type: new  Abstract: Soft robotic suits have the potential to rehabilitate, assist, and augment the human body. The low weight, cost, and minimal form-factor of these devices make them ideal for daily use by both healthy and impaired individuals. However, challenges associated with data-driven, user-specific, and comfort-first design of human-robot interfaces using soft materials limit their widespread translation and adoption. In this work, we present the quantitative evaluation of ergonomics and comfort of the Elevate suit - a cable driven soft robotic suit that assists shoulder elevation. Using a motion-capture system and force sensors, we measured the suit's ergonomics during assisted shoulder elevation up to 70 degrees. Two 4-hour sessions were conducted with one subject, involving transmitting cable tensions of up to 200N with no discomfort reported. We estimated that the pressure applied to the shoulder during assisted movements was within the range seen in a human grasp (approximately 69.1-85.1kPa), and estimated volumetric compression of &lt;3% and &lt;8% across the torso and upper arm, respectively. These results provide early validation of Elevate's ergonomic design in preparation for future studies with patient groups.</p>"
    },
    {
      "id": "ee47f5cb2e1f",
      "title": "Uni-RS: A Spatially Faithful Unified Understanding and Generation Model for Remote Sensing",
      "content": "arXiv:2601.17673v1 Announce Type: cross  Abstract: Unified remote sensing multimodal models exhibit a pronounced spatial reversal curse: Although they can accurately recognize and describe object locations in images, they often fail to faithfully execute the same spatial relations during text-to-image generation, where such relations constitute core semantic information in remote sensing. Motivated by this observation, we propose Uni-RS, the first unified multimodal model tailored for remote sensing, to explicitly address the spatial asymmetry between understanding and generation. Specifically, we first introduce explicit Spatial-Layout Planning to transform textual instructions into spatial layout plans, decoupling geometric planning from visual synthesis. We then impose Spatial-Aware Query Supervision to bias learnable queries toward spatial relations explicitly specified in the instruction. Finally, we develop Image-Caption Spatial Layout Variation to expose the model to systematic geometry-consistent spatial transformations. Extensive experiments across multiple benchmarks show that our approach substantially improves spatial faithfulness in text-to-image generation, while maintaining strong performance on multimodal understanding tasks like image captioning, visual grounding, and VQA tasks.",
      "url": "http://arxiv.org/abs/2601.17673",
      "author": "Weiyu Zhang, Yuan Hu, Yong Li, Yu Liu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Uni-RS addresses spatial asymmetry in remote sensing multimodal models through explicit spatial-layout planning and spatial-aware query injection.",
      "importance_score": 39,
      "reasoning": "Addresses real problem in remote sensing models. Novel spatial decoupling approach.",
      "themes": [
        "Remote Sensing",
        "Multimodal Models",
        "Spatial Understanding"
      ],
      "continuation": null,
      "summary_html": "<p>Uni-RS addresses spatial asymmetry in remote sensing multimodal models through explicit spatial-layout planning and spatial-aware query injection.</p>",
      "content_html": "<p>arXiv:2601.17673v1 Announce Type: cross  Abstract: Unified remote sensing multimodal models exhibit a pronounced spatial reversal curse: Although they can accurately recognize and describe object locations in images, they often fail to faithfully execute the same spatial relations during text-to-image generation, where such relations constitute core semantic information in remote sensing. Motivated by this observation, we propose Uni-RS, the first unified multimodal model tailored for remote sensing, to explicitly address the spatial asymmetry between understanding and generation. Specifically, we first introduce explicit Spatial-Layout Planning to transform textual instructions into spatial layout plans, decoupling geometric planning from visual synthesis. We then impose Spatial-Aware Query Supervision to bias learnable queries toward spatial relations explicitly specified in the instruction. Finally, we develop Image-Caption Spatial Layout Variation to expose the model to systematic geometry-consistent spatial transformations. Extensive experiments across multiple benchmarks show that our approach substantially improves spatial faithfulness in text-to-image generation, while maintaining strong performance on multimodal understanding tasks like image captioning, visual grounding, and VQA tasks.</p>"
    },
    {
      "id": "43527e640b1b",
      "title": "Private Accountability in the Age of Artificial Intelligence",
      "content": "arXiv:2601.17013v1 Announce Type: cross  Abstract: In this Article, I explore the impending conflict between the protection of civil rights and artificial intelligence (AI). While both areas of law have amassed rich and well-developed areas of scholarly work and doctrinal support, a growing body of scholars are interrogating the intersection between them. This Article argues that the issues surrounding algorithmic accountability demonstrate a deeper, more structural tension within a new generation of disputes regarding law and technology. As I argue, the true promise of AI does not lie in the information we reveal to one another, but rather in the questions it raises about the interaction of technology, property, and civil rights. For this reason, I argue that we are looking in the wrong place if we look only to the state to address issues of algorithmic accountability. Instead, we must turn to other ways to ensure more transparency and accountability that stem from private industry, rather than public regulation. The issue of algorithmic bias represents a crucial new world of civil rights concerns, one that is distinct in nature from the ones that preceded it. Since we are in a world where the activities of private corporations, rather than the state, are raising concerns about privacy, due process, and discrimination, we must focus on the role of private corporations in addressing the issue. Towards this end, I discuss a variety of tools to help eliminate the opacity of AI, including codes of conduct, impact statements, and whistleblower protection, which I argue carries the potential to encourage greater endogeneity in civil rights enforcement. Ultimately, by examining the relationship between private industry and civil rights, we can perhaps develop a new generation of forms of accountability in the process.",
      "url": "http://arxiv.org/abs/2601.17013",
      "author": "Sonia Katyal",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Legal/academic analysis exploring conflicts between AI and civil rights protection, arguing for focus on technology-property-civil rights interactions rather than algorithmic accountability alone.",
      "importance_score": 38,
      "reasoning": "Policy and legal scholarship rather than technical AI research. Important societal considerations but limited technical contribution.",
      "themes": [
        "AI Policy",
        "AI Ethics",
        "Civil Rights"
      ],
      "continuation": null,
      "summary_html": "<p>Legal/academic analysis exploring conflicts between AI and civil rights protection, arguing for focus on technology-property-civil rights interactions rather than algorithmic accountability alone.</p>",
      "content_html": "<p>arXiv:2601.17013v1 Announce Type: cross  Abstract: In this Article, I explore the impending conflict between the protection of civil rights and artificial intelligence (AI). While both areas of law have amassed rich and well-developed areas of scholarly work and doctrinal support, a growing body of scholars are interrogating the intersection between them. This Article argues that the issues surrounding algorithmic accountability demonstrate a deeper, more structural tension within a new generation of disputes regarding law and technology. As I argue, the true promise of AI does not lie in the information we reveal to one another, but rather in the questions it raises about the interaction of technology, property, and civil rights. For this reason, I argue that we are looking in the wrong place if we look only to the state to address issues of algorithmic accountability. Instead, we must turn to other ways to ensure more transparency and accountability that stem from private industry, rather than public regulation. The issue of algorithmic bias represents a crucial new world of civil rights concerns, one that is distinct in nature from the ones that preceded it. Since we are in a world where the activities of private corporations, rather than the state, are raising concerns about privacy, due process, and discrimination, we must focus on the role of private corporations in addressing the issue. Towards this end, I discuss a variety of tools to help eliminate the opacity of AI, including codes of conduct, impact statements, and whistleblower protection, which I argue carries the potential to encourage greater endogeneity in civil rights enforcement. Ultimately, by examining the relationship between private industry and civil rights, we can perhaps develop a new generation of forms of accountability in the process.</p>"
    },
    {
      "id": "08e4f8579d2c",
      "title": "Arabic Sign Language Recognition using Multimodal Approach",
      "content": "arXiv:2601.17041v1 Announce Type: cross  Abstract: Arabic Sign Language (ArSL) is an essential communication method for individuals in the Deaf and Hard-of-Hearing community. However, existing recognition systems face significant challenges due to their reliance on single sensor approaches like Leap Motion or RGB cameras. These systems struggle with limitations such as inadequate tracking of complex hand orientations and imprecise recognition of 3D hand movements. This research paper aims to investigate the potential of a multimodal approach that combines Leap Motion and RGB camera data to explore the feasibility of recognition of ArSL. The system architecture includes two parallel subnetworks: a custom dense neural network for Leap Motion data, incorporating dropout and L2 regularization, and an image subnetwork based on a fine-tuned VGG16 model enhanced with data augmentation techniques. Feature representations from both modalities are concatenated in a fusion model and passed through fully connected layers, with final classification performed via SoftMax activation to analyze spatial and temporal features of hand gestures. The system was evaluated on a custom dataset comprising 18 ArSL words, of which 13 were correctly recognized, yielding an overall accuracy of 78%. These results offer preliminary insights into the viability of multimodal fusion for sign language recognition and highlight areas for further optimization and dataset expansion.",
      "url": "http://arxiv.org/abs/2601.17041",
      "author": "Ghadeer Alanazi, Abir Benabid",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Investigates multimodal approach combining Leap Motion and RGB camera data for Arabic Sign Language recognition using custom dense neural networks with dropout and L2 regularization.",
      "importance_score": 38,
      "reasoning": "Addresses underrepresented language domain but uses standard multimodal fusion techniques. Limited technical novelty.",
      "themes": [
        "Sign Language Recognition",
        "Multimodal Learning",
        "Accessibility"
      ],
      "continuation": null,
      "summary_html": "<p>Investigates multimodal approach combining Leap Motion and RGB camera data for Arabic Sign Language recognition using custom dense neural networks with dropout and L2 regularization.</p>",
      "content_html": "<p>arXiv:2601.17041v1 Announce Type: cross  Abstract: Arabic Sign Language (ArSL) is an essential communication method for individuals in the Deaf and Hard-of-Hearing community. However, existing recognition systems face significant challenges due to their reliance on single sensor approaches like Leap Motion or RGB cameras. These systems struggle with limitations such as inadequate tracking of complex hand orientations and imprecise recognition of 3D hand movements. This research paper aims to investigate the potential of a multimodal approach that combines Leap Motion and RGB camera data to explore the feasibility of recognition of ArSL. The system architecture includes two parallel subnetworks: a custom dense neural network for Leap Motion data, incorporating dropout and L2 regularization, and an image subnetwork based on a fine-tuned VGG16 model enhanced with data augmentation techniques. Feature representations from both modalities are concatenated in a fusion model and passed through fully connected layers, with final classification performed via SoftMax activation to analyze spatial and temporal features of hand gestures. The system was evaluated on a custom dataset comprising 18 ArSL words, of which 13 were correctly recognized, yielding an overall accuracy of 78%. These results offer preliminary insights into the viability of multimodal fusion for sign language recognition and highlight areas for further optimization and dataset expansion.</p>"
    },
    {
      "id": "584e3057dcb0",
      "title": "LoD Sketch Extraction from Architectural Models Using Generative AI: Dataset Construction for Multi-Level Architectural Design Generation",
      "content": "arXiv:2601.17095v1 Announce Type: cross  Abstract: For architectural design, representation across multiple Levels of Details (LoD) is essential for achieving a smooth transition from conceptual massing to detailed modeling. However, traditional LoD modeling processes rely on manual operations that are time-consuming, labor-intensive, and prone to geometric inconsistencies. While the rapid advancement of generative artificial intelligence (AI) has opened new possibilities for generating multi-level architectural models from sketch inputs, its application remains limited by the lack of high-quality paired LoD training data. To address this issue, we propose an automatic LoD sketch extraction framework using generative AI models, which progressively simplifies high-detail architectural models to automatically generate geometrically consistent and hierarchically coherent multi-LoD representations. The proposed framework integrates computer vision techniques with generative AI methods to establish a progressive extraction pipeline that transitions from detailed representations to volumetric abstractions. Experimental results demonstrate that the method maintains strong geometric consistency across LoD levels, achieving SSIM values of 0.7319 and 0.7532 for the transitions from LoD3 to LoD2 and from LoD2 to LoD1, respectively, with corresponding normalized Hausdorff distances of 25.1% and 61.0% of the image diagonal, reflecting controlled geometric deviation during abstraction. These results verify that the proposed framework effectively preserves global structure while achieving progressive semantic simplification across different LoD levels, providing reliable data and technical support for AI-driven multi-level architectural generation and hierarchical modeling.",
      "url": "http://arxiv.org/abs/2601.17095",
      "author": "Xusheng Du, Athiwat Kongkaeo, Ye Zhang, Haoran Xie",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes automatic LoD sketch extraction framework using generative AI for multi-level architectural design, addressing lack of paired training data for LoD modeling.",
      "importance_score": 38,
      "reasoning": "Domain-specific application for architectural design. Dataset construction contribution but limited broader impact.",
      "themes": [
        "Generative AI",
        "Architecture Design",
        "Data Synthesis"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes automatic LoD sketch extraction framework using generative AI for multi-level architectural design, addressing lack of paired training data for LoD modeling.</p>",
      "content_html": "<p>arXiv:2601.17095v1 Announce Type: cross  Abstract: For architectural design, representation across multiple Levels of Details (LoD) is essential for achieving a smooth transition from conceptual massing to detailed modeling. However, traditional LoD modeling processes rely on manual operations that are time-consuming, labor-intensive, and prone to geometric inconsistencies. While the rapid advancement of generative artificial intelligence (AI) has opened new possibilities for generating multi-level architectural models from sketch inputs, its application remains limited by the lack of high-quality paired LoD training data. To address this issue, we propose an automatic LoD sketch extraction framework using generative AI models, which progressively simplifies high-detail architectural models to automatically generate geometrically consistent and hierarchically coherent multi-LoD representations. The proposed framework integrates computer vision techniques with generative AI methods to establish a progressive extraction pipeline that transitions from detailed representations to volumetric abstractions. Experimental results demonstrate that the method maintains strong geometric consistency across LoD levels, achieving SSIM values of 0.7319 and 0.7532 for the transitions from LoD3 to LoD2 and from LoD2 to LoD1, respectively, with corresponding normalized Hausdorff distances of 25.1% and 61.0% of the image diagonal, reflecting controlled geometric deviation during abstraction. These results verify that the proposed framework effectively preserves global structure while achieving progressive semantic simplification across different LoD levels, providing reliable data and technical support for AI-driven multi-level architectural generation and hierarchical modeling.</p>"
    },
    {
      "id": "064fcf7685f2",
      "title": "Federated Proximal Optimization for Privacy-Preserving Heart Disease Prediction: A Controlled Simulation Study on Non-IID Clinical Data",
      "content": "arXiv:2601.17183v1 Announce Type: cross  Abstract: Healthcare institutions have access to valuable patient data that could be of great help in the development of improved diagnostic models, but privacy regulations like HIPAA and GDPR prevent hospitals from directly sharing data with one another. Federated Learning offers a way out to this problem by facilitating collaborative model training without having the raw patient data centralized. However, clinical datasets intrinsically have non-IID (non-independent and identically distributed) features brought about by demographic disparity and diversity in disease prevalence and institutional practices. This paper presents a comprehensive simulation research of Federated Proximal Optimization (FedProx) for Heart Disease prediction based on UCI Heart Disease dataset. We generate realistic non-IID data partitions by simulating four heterogeneous hospital clients from the Cleveland Clinic dataset (303 patients), by inducing statistical heterogeneity by demographic-based stratification. Our experimental results show that FedProx with proximal parameter mu=0.05 achieves 85.00% accuracy, which is better than both centralized learning (83.33%) and isolated local models (78.45% average) without revealing patient privacy. Through generous sheer ablation studies with statistical validation on 50 independent runs we demonstrate that proximal regularization is effective in curbing client drift in heterogeneous environments. This proof-of-concept research offers algorithmic insights and practical deployment guidelines for real-world federated healthcare systems, and thus, our results are directly transferable to hospital IT-administrators, implementing privacy-preserving collaborative learning.",
      "url": "http://arxiv.org/abs/2601.17183",
      "author": "Farzam Asad, Junaid Saif Khan, Maria Tariq, Sundus Munir, Muhammad Adnan Khan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Simulation study of FedProx for heart disease prediction on non-IID clinical data using UCI Heart Disease dataset. Addresses privacy constraints in healthcare.",
      "importance_score": 38,
      "reasoning": "Applied federated learning study with standard methods. Limited novelty in methodology.",
      "themes": [
        "Federated Learning",
        "Medical AI",
        "Privacy"
      ],
      "continuation": null,
      "summary_html": "<p>Simulation study of FedProx for heart disease prediction on non-IID clinical data using UCI Heart Disease dataset. Addresses privacy constraints in healthcare.</p>",
      "content_html": "<p>arXiv:2601.17183v1 Announce Type: cross  Abstract: Healthcare institutions have access to valuable patient data that could be of great help in the development of improved diagnostic models, but privacy regulations like HIPAA and GDPR prevent hospitals from directly sharing data with one another. Federated Learning offers a way out to this problem by facilitating collaborative model training without having the raw patient data centralized. However, clinical datasets intrinsically have non-IID (non-independent and identically distributed) features brought about by demographic disparity and diversity in disease prevalence and institutional practices. This paper presents a comprehensive simulation research of Federated Proximal Optimization (FedProx) for Heart Disease prediction based on UCI Heart Disease dataset. We generate realistic non-IID data partitions by simulating four heterogeneous hospital clients from the Cleveland Clinic dataset (303 patients), by inducing statistical heterogeneity by demographic-based stratification. Our experimental results show that FedProx with proximal parameter mu=0.05 achieves 85.00% accuracy, which is better than both centralized learning (83.33%) and isolated local models (78.45% average) without revealing patient privacy. Through generous sheer ablation studies with statistical validation on 50 independent runs we demonstrate that proximal regularization is effective in curbing client drift in heterogeneous environments. This proof-of-concept research offers algorithmic insights and practical deployment guidelines for real-world federated healthcare systems, and thus, our results are directly transferable to hospital IT-administrators, implementing privacy-preserving collaborative learning.</p>"
    },
    {
      "id": "c994d16cbeef",
      "title": "Feature-Space Generative Models for One-Shot Class-Incremental Learning",
      "content": "arXiv:2601.17905v1 Announce Type: cross  Abstract: Few-shot class-incremental learning (FSCIL) is a paradigm where a model, initially trained on a dataset of base classes, must adapt to an expanding problem space by recognizing novel classes with limited data. We focus on the challenging FSCIL setup where a model receives only a single sample (1-shot) for each novel class and no further training or model alterations are allowed after the base training phase. This makes generalization to novel classes particularly difficult. We propose a novel approach predicated on the hypothesis that base and novel class embeddings have structural similarity. We map the original embedding space into a residual space by subtracting the class prototype (i.e., the average class embedding) of input samples. Then, we leverage generative modeling with VAE or diffusion models to learn the multi-modal distribution of residuals over the base classes, and we use this as a valuable structural prior to improve recognition of novel classes. Our approach, Gen1S, consistently improves novel class recognition over the state of the art across multiple benchmarks and backbone architectures.",
      "url": "http://arxiv.org/abs/2601.17905",
      "author": "Jack Foster, Kirill Paramonov, Mete Ozay, Umberto Michieli",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Uses feature-space generative models for one-shot class-incremental learning by mapping embeddings to residual space and learning prototypes.",
      "importance_score": 38,
      "reasoning": "Novel approach to FSCIL using residual space. Addresses challenging 1-shot setting.",
      "themes": [
        "Few-shot Learning",
        "Class-incremental Learning",
        "Generative Models"
      ],
      "continuation": null,
      "summary_html": "<p>Uses feature-space generative models for one-shot class-incremental learning by mapping embeddings to residual space and learning prototypes.</p>",
      "content_html": "<p>arXiv:2601.17905v1 Announce Type: cross  Abstract: Few-shot class-incremental learning (FSCIL) is a paradigm where a model, initially trained on a dataset of base classes, must adapt to an expanding problem space by recognizing novel classes with limited data. We focus on the challenging FSCIL setup where a model receives only a single sample (1-shot) for each novel class and no further training or model alterations are allowed after the base training phase. This makes generalization to novel classes particularly difficult. We propose a novel approach predicated on the hypothesis that base and novel class embeddings have structural similarity. We map the original embedding space into a residual space by subtracting the class prototype (i.e., the average class embedding) of input samples. Then, we leverage generative modeling with VAE or diffusion models to learn the multi-modal distribution of residuals over the base classes, and we use this as a valuable structural prior to improve recognition of novel classes. Our approach, Gen1S, consistently improves novel class recognition over the state of the art across multiple benchmarks and backbone architectures.</p>"
    },
    {
      "id": "6995376210cc",
      "title": "Design Techniques for LLM-Powered Interactive Storytelling: A Case Study of the Dramamancer System",
      "content": "arXiv:2601.18785v1 Announce Type: cross  Abstract: The rise of Large Language Models (LLMs) has enabled a new paradigm for bridging authorial intent and player agency in interactive narrative. We consider this paradigm through the example of Dramamancer, a system that uses an LLM to transform author-created story schemas into player-driven playthroughs. This extended abstract outlines some design techniques and evaluation considerations associated with this system.",
      "url": "http://arxiv.org/abs/2601.18785",
      "author": "Tiffany Wang, Yuqian Sun, Yi Wang, Melissa Roemmele, John Joon Young Chung, Max Kreminski",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.HC"
      ],
      "summary": "Extended abstract outlining design techniques for LLM-powered interactive storytelling in Dramamancer system, bridging authorial intent and player agency through story schemas.",
      "importance_score": 38,
      "reasoning": "Brief extended abstract with limited technical detail. Design patterns for narrative AI but preliminary work.",
      "themes": [
        "Interactive Narrative",
        "LLM Applications",
        "Game AI"
      ],
      "continuation": null,
      "summary_html": "<p>Extended abstract outlining design techniques for LLM-powered interactive storytelling in Dramamancer system, bridging authorial intent and player agency through story schemas.</p>",
      "content_html": "<p>arXiv:2601.18785v1 Announce Type: cross  Abstract: The rise of Large Language Models (LLMs) has enabled a new paradigm for bridging authorial intent and player agency in interactive narrative. We consider this paradigm through the example of Dramamancer, a system that uses an LLM to transform author-created story schemas into player-driven playthroughs. This extended abstract outlines some design techniques and evaluation considerations associated with this system.</p>"
    },
    {
      "id": "6a4da2ddad5f",
      "title": "Hylog: A Hybrid Approach to Logging Text Production in Non-alphabetic Scripts",
      "content": "arXiv:2601.17753v1 Announce Type: new  Abstract: Research keyloggers are essential for cognitive studies of text production, yet most fail to capture the on-screen transformations performed by Input Method Editors (IMEs) for non-alphabetic scripts. To address this methodological gap, we present Hylog, a novel hybrid logging system that combines analytical keylogging with ecological text logging for a more complete and finer-grained analysis. Our modular, open-source system uses plug-ins for standard applications (Microsoft Word, Google Chrome) to capture both keyboard output and rendered text, which a hybridizer module then synchronizes into a dual trace. To validate the system's technical feasibility and demonstrate its analytical capabilities, we conducted a proof-of-concept study where two volunteers translated a text into simplified Chinese. Hylog successfully captured keypresses and temporal intervals between Latin letters, Chinese characters, and IME confirmations -- some measurements invisible to traditional keyloggers. The resulting data enable the formulation of new, testable hypotheses about the cognitive restrictions and affordances at different linguistic layers in IME-mediated typing. Our plug-in architecture enables extension to other IME systems and fosters more inclusive multilingual text-production research.",
      "url": "http://arxiv.org/abs/2601.17753",
      "author": "Roberto Crotti, Giovanni Denaro, Zhiqiang Du, Ricardo Mu\\~noz Mart\\'in",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Presents Hylog, a hybrid logging system combining analytical keylogging with ecological text logging to capture Input Method Editor transformations for non-alphabetic scripts like Chinese.",
      "importance_score": 38,
      "reasoning": "Specialized tool for cognitive studies of text production. Limited relevance to broader AI community.",
      "themes": [
        "Tools",
        "Writing Systems",
        "Human-Computer Interaction"
      ],
      "continuation": null,
      "summary_html": "<p>Presents Hylog, a hybrid logging system combining analytical keylogging with ecological text logging to capture Input Method Editor transformations for non-alphabetic scripts like Chinese.</p>",
      "content_html": "<p>arXiv:2601.17753v1 Announce Type: new  Abstract: Research keyloggers are essential for cognitive studies of text production, yet most fail to capture the on-screen transformations performed by Input Method Editors (IMEs) for non-alphabetic scripts. To address this methodological gap, we present Hylog, a novel hybrid logging system that combines analytical keylogging with ecological text logging for a more complete and finer-grained analysis. Our modular, open-source system uses plug-ins for standard applications (Microsoft Word, Google Chrome) to capture both keyboard output and rendered text, which a hybridizer module then synchronizes into a dual trace. To validate the system's technical feasibility and demonstrate its analytical capabilities, we conducted a proof-of-concept study where two volunteers translated a text into simplified Chinese. Hylog successfully captured keypresses and temporal intervals between Latin letters, Chinese characters, and IME confirmations -- some measurements invisible to traditional keyloggers. The resulting data enable the formulation of new, testable hypotheses about the cognitive restrictions and affordances at different linguistic layers in IME-mediated typing. Our plug-in architecture enables extension to other IME systems and fosters more inclusive multilingual text-production research.</p>"
    },
    {
      "id": "a67a252e5f20",
      "title": "Designing large language model prompts to extract scores from messy text: A shared dataset and challenge",
      "content": "arXiv:2601.18271v1 Announce Type: cross  Abstract: In some areas of computing, natural language processing and information science, progress is made by sharing datasets and challenging the community to design the best algorithm for an associated task. This article introduces a shared dataset of 1446 short texts, each of which describes a research quality score on the UK scale of 1* to 4*. This is a messy collection, with some texts not containing scores and others including invalid scores or strange formats. With this dataset there is also a description of what constitutes a valid score and a \"gold standard\" of the correct scores for these texts (including missing values). The challenge is to design a prompt for Large Language Models (LLMs) to extract the scores from these texts as accurately as possible. The format for the response should be a number and no other text so there are two aspects to the challenge: ensuring that the LLM returns only a number, and instructing it to deduce the correct number for the text. As part of this, the LLM prompt needs to explain when to return the missing value code, -1, instead of a number when the text does not clearly contain one. The article also provides an example of a simple prompt. The purpose of the challenge is twofold: to get an effective solution to this problem, and to increase understanding of prompt design and LLM capabilities for complex numerical tasks. The initial solution suggested has an accuracy of 72.6%, so the challenge is to beat this.",
      "url": "http://arxiv.org/abs/2601.18271",
      "author": "Mike Thelwall",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.DL"
      ],
      "summary": "Introduces dataset and challenge for designing LLM prompts to extract research quality scores from messy text, providing benchmark for NLP extraction tasks.",
      "importance_score": 38,
      "reasoning": "Narrow application focus with limited methodological contribution. Useful resource but minimal research novelty.",
      "themes": [
        "NLP",
        "LLM Prompting",
        "Information Extraction"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces dataset and challenge for designing LLM prompts to extract research quality scores from messy text, providing benchmark for NLP extraction tasks.</p>",
      "content_html": "<p>arXiv:2601.18271v1 Announce Type: cross  Abstract: In some areas of computing, natural language processing and information science, progress is made by sharing datasets and challenging the community to design the best algorithm for an associated task. This article introduces a shared dataset of 1446 short texts, each of which describes a research quality score on the UK scale of 1* to 4*. This is a messy collection, with some texts not containing scores and others including invalid scores or strange formats. With this dataset there is also a description of what constitutes a valid score and a \"gold standard\" of the correct scores for these texts (including missing values). The challenge is to design a prompt for Large Language Models (LLMs) to extract the scores from these texts as accurately as possible. The format for the response should be a number and no other text so there are two aspects to the challenge: ensuring that the LLM returns only a number, and instructing it to deduce the correct number for the text. As part of this, the LLM prompt needs to explain when to return the missing value code, -1, instead of a number when the text does not clearly contain one. The article also provides an example of a simple prompt. The purpose of the challenge is twofold: to get an effective solution to this problem, and to increase understanding of prompt design and LLM capabilities for complex numerical tasks. The initial solution suggested has an accuracy of 72.6%, so the challenge is to beat this.</p>"
    },
    {
      "id": "2ed1fd8eeea6",
      "title": "Quran-MD: A Fine-Grained Multilingual Multimodal Dataset of the Quran",
      "content": "arXiv:2601.17880v1 Announce Type: new  Abstract: We present Quran MD, a comprehensive multimodal dataset of the Quran that integrates textual, linguistic, and audio dimensions at the verse and word levels. For each verse (ayah), the dataset provides its original Arabic text, English translation, and phonetic transliteration. To capture the rich oral tradition of Quranic recitation, we include verse-level audio from 32 distinct reciters, reflecting diverse recitation styles and dialectical nuances. At the word level, each token is paired with its corresponding Arabic script, English translation, transliteration, and an aligned audio recording, allowing fine-grained analysis of pronunciation, phonology, and semantic context. This dataset supports various applications, including natural language processing, speech recognition, text-to-speech synthesis, linguistic analysis, and digital Islamic studies. Bridging text and audio modalities across multiple reciters, this dataset provides a unique resource to advance computational approaches to Quranic recitation and study. Beyond enabling tasks such as ASR, tajweed detection, and Quranic TTS, it lays the foundation for multimodal embeddings, semantic retrieval, style transfer, and personalized tutoring systems that can support both research and community applications. The dataset is available at https://huggingface.co/datasets/Buraaq/quran-audio-text-dataset",
      "url": "http://arxiv.org/abs/2601.17880",
      "author": "Muhammad Umar Salman, Mohammad Areeb Qazi, Mohammed Talha Alam",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents Quran-MD, a comprehensive multimodal dataset integrating textual, linguistic, and audio dimensions of the Quran at verse and word levels, including recordings from 32 reciters.",
      "importance_score": 38,
      "reasoning": "Specialized dataset for religious text processing. Limited broader ML impact but valuable for specific applications.",
      "themes": [
        "Datasets",
        "Multimodal Learning",
        "Speech Processing"
      ],
      "continuation": null,
      "summary_html": "<p>Presents Quran-MD, a comprehensive multimodal dataset integrating textual, linguistic, and audio dimensions of the Quran at verse and word levels, including recordings from 32 reciters.</p>",
      "content_html": "<p>arXiv:2601.17880v1 Announce Type: new  Abstract: We present Quran MD, a comprehensive multimodal dataset of the Quran that integrates textual, linguistic, and audio dimensions at the verse and word levels. For each verse (ayah), the dataset provides its original Arabic text, English translation, and phonetic transliteration. To capture the rich oral tradition of Quranic recitation, we include verse-level audio from 32 distinct reciters, reflecting diverse recitation styles and dialectical nuances. At the word level, each token is paired with its corresponding Arabic script, English translation, transliteration, and an aligned audio recording, allowing fine-grained analysis of pronunciation, phonology, and semantic context. This dataset supports various applications, including natural language processing, speech recognition, text-to-speech synthesis, linguistic analysis, and digital Islamic studies. Bridging text and audio modalities across multiple reciters, this dataset provides a unique resource to advance computational approaches to Quranic recitation and study. Beyond enabling tasks such as ASR, tajweed detection, and Quranic TTS, it lays the foundation for multimodal embeddings, semantic retrieval, style transfer, and personalized tutoring systems that can support both research and community applications. The dataset is available at https://huggingface.co/datasets/Buraaq/quran-audio-text-dataset</p>"
    },
    {
      "id": "0c742804d1e7",
      "title": "Revisiting Aerial Scene Classification on the AID Benchmark",
      "content": "arXiv:2601.18263v1 Announce Type: new  Abstract: Aerial images play a vital role in urban planning and environmental preservation, as they consist of various structures, representing different types of buildings, forests, mountains, and unoccupied lands. Due to its heterogeneous nature, developing robust models for scene classification remains a challenge. In this study, we conduct a literature review of various machine learning methods for aerial image classification. Our survey covers a range of approaches from handcrafted features (e.g., SIFT, LBP) to traditional CNNs (e.g., VGG, GoogLeNet), and advanced deep hybrid networks. In this connection, we have also designed Aerial-Y-Net, a spatial attention-enhanced CNN with multi-scale feature fusion mechanism, which acts as an attention-based model and helps us to better understand the complexities of aerial images. Evaluated on the AID dataset, our model achieves 91.72% accuracy, outperforming several baseline architectures.",
      "url": "http://arxiv.org/abs/2601.18263",
      "author": "Subhajeet Das, Susmita Ghosh, Abhiroop Chatterjee",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Surveys aerial scene classification methods from handcrafted features to deep hybrid networks, and proposes Aerial-Y-Net with spatial attention and multi-scale feature fusion.",
      "importance_score": 38,
      "reasoning": "Literature review with incremental new method. Survey value but limited novelty.",
      "themes": [
        "Aerial Imaging",
        "Scene Classification",
        "Survey"
      ],
      "continuation": null,
      "summary_html": "<p>Surveys aerial scene classification methods from handcrafted features to deep hybrid networks, and proposes Aerial-Y-Net with spatial attention and multi-scale feature fusion.</p>",
      "content_html": "<p>arXiv:2601.18263v1 Announce Type: new  Abstract: Aerial images play a vital role in urban planning and environmental preservation, as they consist of various structures, representing different types of buildings, forests, mountains, and unoccupied lands. Due to its heterogeneous nature, developing robust models for scene classification remains a challenge. In this study, we conduct a literature review of various machine learning methods for aerial image classification. Our survey covers a range of approaches from handcrafted features (e.g., SIFT, LBP) to traditional CNNs (e.g., VGG, GoogLeNet), and advanced deep hybrid networks. In this connection, we have also designed Aerial-Y-Net, a spatial attention-enhanced CNN with multi-scale feature fusion mechanism, which acts as an attention-based model and helps us to better understand the complexities of aerial images. Evaluated on the AID dataset, our model achieves 91.72% accuracy, outperforming several baseline architectures.</p>"
    },
    {
      "id": "e719a160d6a2",
      "title": "Comparative Evaluation of Machine Learning Algorithms for Affective State Recognition from Children's Drawings",
      "content": "arXiv:2601.18414v1 Announce Type: new  Abstract: Autism spectrum disorder (ASD) represents a neurodevelopmental condition characterized by difficulties in expressing emotions and communication, particularly during early childhood. Understanding the affective state of children at an early age remains challenging, as conventional assessment methods are often intrusive, subjective, or difficult to apply consistently. This paper builds upon previous work on affective state recognition from children's drawings by presenting a comparative evaluation of machine learning models for emotion classification. Three deep learning architectures -- MobileNet, EfficientNet, and VGG16 -- are evaluated within a unified experimental framework to analyze classification performance, robustness, and computational efficiency. The models are trained using transfer learning on a dataset of children's drawings annotated with emotional labels provided by psychological experts. The results highlight important trade-offs between lightweight and deeper architectures when applied to drawing-based affective computing tasks, particularly in mobile and real-time application contexts.",
      "url": "http://arxiv.org/abs/2601.18414",
      "author": "Aura Loredana Dan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Compares deep learning architectures (MobileNet, EfficientNet, VGG16) for affective state recognition from children's drawings for autism assessment.",
      "importance_score": 38,
      "reasoning": "Applied comparison study. Social impact potential but limited technical novelty.",
      "themes": [
        "Healthcare AI",
        "Autism",
        "Emotion Recognition"
      ],
      "continuation": null,
      "summary_html": "<p>Compares deep learning architectures (MobileNet, EfficientNet, VGG16) for affective state recognition from children's drawings for autism assessment.</p>",
      "content_html": "<p>arXiv:2601.18414v1 Announce Type: new  Abstract: Autism spectrum disorder (ASD) represents a neurodevelopmental condition characterized by difficulties in expressing emotions and communication, particularly during early childhood. Understanding the affective state of children at an early age remains challenging, as conventional assessment methods are often intrusive, subjective, or difficult to apply consistently. This paper builds upon previous work on affective state recognition from children's drawings by presenting a comparative evaluation of machine learning models for emotion classification. Three deep learning architectures -- MobileNet, EfficientNet, and VGG16 -- are evaluated within a unified experimental framework to analyze classification performance, robustness, and computational efficiency. The models are trained using transfer learning on a dataset of children's drawings annotated with emotional labels provided by psychological experts. The results highlight important trade-offs between lightweight and deeper architectures when applied to drawing-based affective computing tasks, particularly in mobile and real-time application contexts.</p>"
    },
    {
      "id": "f2f4216f42ea",
      "title": "ME-WARD: A multimodal ergonomic analysis tool for musculoskeletal risk assessment from inertial and video data in working plac",
      "content": "arXiv:2601.17571v1 Announce Type: cross  Abstract: This study presents ME-WARD (Multimodal Ergonomic Workplace Assessment and Risk from Data), a novel system for ergonomic assessment and musculoskeletal risk evaluation that implements the Rapid Upper Limb Assessment (RULA) method. ME-WARD is designed to process joint angle data from motion capture systems, including inertial measurement unit (IMU)-based setups, and deep learning human body pose tracking models. The tool's flexibility enables ergonomic risk assessment using any system capable of reliably measuring joint angles, extending the applicability of RULA beyond proprietary setups. To validate its performance, the tool was tested in an industrial setting during the assembly of conveyor belts, which involved high-risk tasks such as inserting rods and pushing conveyor belt components. The experiments leveraged gold standard IMU systems alongside a state-of-the-art monocular 3D pose estimation system. The results confirmed that ME-WARD produces reliable RULA scores that closely align with IMU-derived metrics for flexion-dominated movements and comparable performance with the monocular system, despite limitations in tracking lateral and rotational motions. This work highlights the potential of integrating multiple motion capture technologies into a unified and accessible ergonomic assessment pipeline. By supporting diverse input sources, including low-cost video-based systems, the proposed multimodal approach offers a scalable, cost-effective solution for ergonomic assessments, paving the way for broader adoption in resource-constrained industrial environments.",
      "url": "http://arxiv.org/abs/2601.17571",
      "author": "Javier Gonz\\'alez-Alonso, Paula Mart\\'in-Tapia, David Gonz\\'alez-Ortega, M\\'iriam Ant\\'on-Rodr\\'iguez, Francisco Javier D\\'iaz-Pernas, Mario Mart\\'inez-Zarzuela",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "eess.SP"
      ],
      "summary": "Presents ME-WARD, a multimodal ergonomic assessment tool implementing RULA methodology using IMU-based motion capture and deep learning pose tracking.",
      "importance_score": 38,
      "reasoning": "Applied tool for workplace safety assessment, useful but limited research novelty.",
      "themes": [
        "Ergonomics",
        "Pose Estimation",
        "Applied Robotics"
      ],
      "continuation": null,
      "summary_html": "<p>Presents ME-WARD, a multimodal ergonomic assessment tool implementing RULA methodology using IMU-based motion capture and deep learning pose tracking.</p>",
      "content_html": "<p>arXiv:2601.17571v1 Announce Type: cross  Abstract: This study presents ME-WARD (Multimodal Ergonomic Workplace Assessment and Risk from Data), a novel system for ergonomic assessment and musculoskeletal risk evaluation that implements the Rapid Upper Limb Assessment (RULA) method. ME-WARD is designed to process joint angle data from motion capture systems, including inertial measurement unit (IMU)-based setups, and deep learning human body pose tracking models. The tool's flexibility enables ergonomic risk assessment using any system capable of reliably measuring joint angles, extending the applicability of RULA beyond proprietary setups. To validate its performance, the tool was tested in an industrial setting during the assembly of conveyor belts, which involved high-risk tasks such as inserting rods and pushing conveyor belt components. The experiments leveraged gold standard IMU systems alongside a state-of-the-art monocular 3D pose estimation system. The results confirmed that ME-WARD produces reliable RULA scores that closely align with IMU-derived metrics for flexion-dominated movements and comparable performance with the monocular system, despite limitations in tracking lateral and rotational motions. This work highlights the potential of integrating multiple motion capture technologies into a unified and accessible ergonomic assessment pipeline. By supporting diverse input sources, including low-cost video-based systems, the proposed multimodal approach offers a scalable, cost-effective solution for ergonomic assessments, paving the way for broader adoption in resource-constrained industrial environments.</p>"
    },
    {
      "id": "6b4df5dc789c",
      "title": "No silver bullet: Lessons about how to create safety from the history of fire",
      "content": "Reality is a dangerous place. From the dawn of humanity we have faced the hazards of nature: fire, flood, disease, famine. Better technology and infrastructure have made us safer from many of these risksbut have also created new risks, from boiler explosions to carcinogens to ozone depletion, and exacerbated old ones.Safety, security, and resilience against these hazards is not the default state of humanity. It is an achievement, and in each case it came about deliberately.A striking theme from the history of such achievements is that there is rarely if ever a silver bullet for risk. Safety is achieved through defense in depth, and through the orchestration of a wide variety of solutions, all working in concert.Recently, in a private talk, I gave a historical example: the history of fire safety. It resonated so strongly with the audience that Im writing it up here for wider distribution.Up until and through the 1800s, city fires were a great hazard. Neighborhoods were full of densely packed wooden structures without flame-retardant chemicals, fire alarms, or sprinkler systems; open flames were used everywhere for lighting, heating, and cooking; there were no best practices in place for storing or handling combustible materials; fire departments lacked training and discipline, and they worked with inadequate equipment and insufficient water supply. All this meant that large swaths of cities regularly burned to the ground: Rome in AD 64; Constantinople in 406; London in 1135, 1212, and 1666; Hangzhou 1137; Amsterdam 1421 and 1452; Stockholm 1625 and 1759; Nagasaki 1663; Boston 1711, 1760, 1787, and 1872; New York 1776, 1835, and 1845; New Orleans 1788 and 1794; Pittsburgh 1845; Chicago 1871; Seattle 1889; Shanghai 1894; Baltimore 1904; Atlanta 1917; and Tokyo 1923 are just a short list of the most well-known.Chicago in Flames, by Currier &amp; Ives (1871). Wikimedia / Chicago Historical SocietyFire is not unknown today, but it is far less lethal, and great city fire...",
      "url": "https://www.lesswrong.com/posts/PHpooGs65uBzmCEqx/no-silver-bullet-lessons-about-how-to-create-safety-from-the",
      "author": "jasoncrawford",
      "published": "2026-01-26T17:18:32.164000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Historical analysis of fire safety development arguing that safety is achieved through 'defense in depth' and multiple coordinated solutions, not silver bullets. Uses this as an analogy for thinking about AI safety approaches.",
      "importance_score": 38,
      "reasoning": "Useful framing analogy for AI safety but not original technical research. The defense-in-depth concept is well-established; this applies it to a new domain with historical illustration.",
      "themes": [
        "AI Safety",
        "Historical Analysis",
        "Risk Management"
      ],
      "continuation": null,
      "summary_html": "<p>Historical analysis of fire safety development arguing that safety is achieved through 'defense in depth' and multiple coordinated solutions, not silver bullets. Uses this as an analogy for thinking about AI safety approaches.</p>",
      "content_html": "<p>Reality is a dangerous place. From the dawn of humanity we have faced the hazards of nature: fire, flood, disease, famine. Better technology and infrastructure have made us safer from many of these risksbut have also created new risks, from boiler explosions to carcinogens to ozone depletion, and exacerbated old ones.Safety, security, and resilience against these hazards is not the default state of humanity. It is an achievement, and in each case it came about deliberately.A striking theme from the history of such achievements is that there is rarely if ever a silver bullet for risk. Safety is achieved through defense in depth, and through the orchestration of a wide variety of solutions, all working in concert.Recently, in a private talk, I gave a historical example: the history of fire safety. It resonated so strongly with the audience that Im writing it up here for wider distribution.Up until and through the 1800s, city fires were a great hazard. Neighborhoods were full of densely packed wooden structures without flame-retardant chemicals, fire alarms, or sprinkler systems; open flames were used everywhere for lighting, heating, and cooking; there were no best practices in place for storing or handling combustible materials; fire departments lacked training and discipline, and they worked with inadequate equipment and insufficient water supply. All this meant that large swaths of cities regularly burned to the ground: Rome in AD 64; Constantinople in 406; London in 1135, 1212, and 1666; Hangzhou 1137; Amsterdam 1421 and 1452; Stockholm 1625 and 1759; Nagasaki 1663; Boston 1711, 1760, 1787, and 1872; New York 1776, 1835, and 1845; New Orleans 1788 and 1794; Pittsburgh 1845; Chicago 1871; Seattle 1889; Shanghai 1894; Baltimore 1904; Atlanta 1917; and Tokyo 1923 are just a short list of the most well-known.Chicago in Flames, by Currier &amp; Ives (1871). Wikimedia / Chicago Historical SocietyFire is not unknown today, but it is far less lethal, and great city fire...</p>"
    },
    {
      "id": "6fa59ccdeae2",
      "title": "Futarchy is Parasitic on What It Tries to Govern",
      "content": "SummaryEpistemic status: quite confident.Futarchy is bound to fail because conditional decision markets are structurally incapable of estimating causal policy effects once their outputs are acted upon. Traders must price contracts based on welfare conditional on approval, not welfare caused by approval. As a result, decision markets systematically reward traders for exploiting non-causal correlations between policy adoption and latent welfare fundamentals. We can expect futarchy markets to endogenously generate such correlations. Policies that signal strong fundamentals are favored even if causally harmful, while policies that signal weakness are disfavored even if causally beneficial. This effect persists under full rationality, common knowledge, and perfect supporting institutions (welfare metric, courts, legislatures, etc.).This bias is worst when individual estimates of fundamentals are noisy and dispersed, i.e. where markets should be most useful as information aggregators. The resulting inefficiency cost is paid by the organization being governed, while gains accrue to market participants, making futarchy parasitic on its host. Randomization schemes can recover causal estimates only by breaking the feedback loop between prices and decisions, but doing so either renders futarchy ineffective as a decision making tool, fails to fix the problem, or collapses it into an influence market where the wealthy can buy policy.There is no payout structure that simultaneously incentivizes decision market participants to price in causal knowledge and allows that knowledge to be acted upon.IntroductionFutarchy is a form of governance that leverages conditional predictions markets to take decisions, invented by Robin Hanson. In theory, because markets are great at aggregating dispersed, tacit information, futarchy could lead to better decisions than private-business autocracy or democracy, but it has so far failed to gain much traction as a practical decision-making tool. Many...",
      "url": "https://www.lesswrong.com/posts/mW4ypzR6cTwKqncvp/futarchy-is-parasitic-on-what-it-tries-to-govern",
      "author": "Nicolas Rasmont",
      "published": "2026-01-26T00:05:33.248000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Argues futarchy (governance by prediction markets) fails structurally because conditional decision markets cannot estimate causal policy effects once acted upon. Traders price welfare conditional on approval rather than caused by approval.",
      "importance_score": 38,
      "reasoning": "Interesting theoretical critique of prediction market governance with formal argument. Not directly AI-related but relevant to AI governance discussions. Well-reasoned but narrow application.",
      "themes": [
        "Governance",
        "Prediction Markets",
        "Futarchy",
        "Decision Theory"
      ],
      "continuation": null,
      "summary_html": "<p>Argues futarchy (governance by prediction markets) fails structurally because conditional decision markets cannot estimate causal policy effects once acted upon. Traders price welfare conditional on approval rather than caused by approval.</p>",
      "content_html": "<p>SummaryEpistemic status: quite confident.Futarchy is bound to fail because conditional decision markets are structurally incapable of estimating causal policy effects once their outputs are acted upon. Traders must price contracts based on welfare conditional on approval, not welfare caused by approval. As a result, decision markets systematically reward traders for exploiting non-causal correlations between policy adoption and latent welfare fundamentals. We can expect futarchy markets to endogenously generate such correlations. Policies that signal strong fundamentals are favored even if causally harmful, while policies that signal weakness are disfavored even if causally beneficial. This effect persists under full rationality, common knowledge, and perfect supporting institutions (welfare metric, courts, legislatures, etc.).This bias is worst when individual estimates of fundamentals are noisy and dispersed, i.e. where markets should be most useful as information aggregators. The resulting inefficiency cost is paid by the organization being governed, while gains accrue to market participants, making futarchy parasitic on its host. Randomization schemes can recover causal estimates only by breaking the feedback loop between prices and decisions, but doing so either renders futarchy ineffective as a decision making tool, fails to fix the problem, or collapses it into an influence market where the wealthy can buy policy.There is no payout structure that simultaneously incentivizes decision market participants to price in causal knowledge and allows that knowledge to be acted upon.IntroductionFutarchy is a form of governance that leverages conditional predictions markets to take decisions, invented by Robin Hanson. In theory, because markets are great at aggregating dispersed, tacit information, futarchy could lead to better decisions than private-business autocracy or democracy, but it has so far failed to gain much traction as a practical decision-making tool. Many...</p>"
    },
    {
      "id": "da091845f8d8",
      "title": "Credit Fairness: Online Fairness In Shared Resource Pools",
      "content": "arXiv:2601.17944v1 Announce Type: cross  Abstract: We consider a setting in which a group of agents share resources that must be allocated among them in each discrete time period. Agents have time-varying demands and derive constant marginal utility from each unit of resource received up to their demand, with zero utility for any additional resources. In this setting, it is known that independently maximizing the minimum utility in each round satisfies sharing incentives (agents weakly prefer participating in the mechanism to not participating), strategyproofness (agents have no incentive to misreport their demands), and Pareto efficiency (Freeman et al. 2018). However, recent work (Vuppalapati et al. 2023) has shown that this max-min mechanism can lead to large disparities in the total resources received by agents, even when they have the same average demand. In this paper, we introduce credit fairness, a strengthening of sharing incentives that ensures agents who lend resources in early rounds are able to recoup them in later rounds. Credit fairness can be achieved in conjunction with either Pareto efficiency or strategyproofness, but not both. We propose a mechanism that is credit fair and Pareto efficient, and we evaluate its performance in a computational resource-sharing setting.",
      "url": "http://arxiv.org/abs/2601.17944",
      "author": "Seyed Majid Zahedi, Rupert Freeman",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.GT"
      ],
      "summary": "Credit Fairness addresses online fairness in shared resource allocation, showing max-min mechanism leads to large disparities over time.",
      "importance_score": 37,
      "reasoning": "Important fairness analysis of resource allocation. Theoretical contribution.",
      "themes": [
        "Fairness",
        "Resource Allocation",
        "Online Algorithms"
      ],
      "continuation": null,
      "summary_html": "<p>Credit Fairness addresses online fairness in shared resource allocation, showing max-min mechanism leads to large disparities over time.</p>",
      "content_html": "<p>arXiv:2601.17944v1 Announce Type: cross  Abstract: We consider a setting in which a group of agents share resources that must be allocated among them in each discrete time period. Agents have time-varying demands and derive constant marginal utility from each unit of resource received up to their demand, with zero utility for any additional resources. In this setting, it is known that independently maximizing the minimum utility in each round satisfies sharing incentives (agents weakly prefer participating in the mechanism to not participating), strategyproofness (agents have no incentive to misreport their demands), and Pareto efficiency (Freeman et al. 2018). However, recent work (Vuppalapati et al. 2023) has shown that this max-min mechanism can lead to large disparities in the total resources received by agents, even when they have the same average demand. In this paper, we introduce credit fairness, a strengthening of sharing incentives that ensures agents who lend resources in early rounds are able to recoup them in later rounds. Credit fairness can be achieved in conjunction with either Pareto efficiency or strategyproofness, but not both. We propose a mechanism that is credit fair and Pareto efficient, and we evaluate its performance in a computational resource-sharing setting.</p>"
    },
    {
      "id": "da87a29427e8",
      "title": "Autonomous Mars Rover Module for Soil Sampling and Life Component Analysis",
      "content": "arXiv:2601.17158v1 Announce Type: cross  Abstract: The search for extraterrestrial life has long been a primary focus of scientific exploration, driven by rapid advancements in technology and our understanding of the universe. The discovery of water on Mars has sparked significant interest, raising the question of whether life could exist on the planet. This study proposes a novel approach to simulate and illustrate the detection of life using a proof-of-life module integrated into a Mars rover. The module is an autonomous system capable of traveling to designated regions, excavating soil, collecting samples, and performing biochemical testing onboard the rover itself. The project is inherently multidisciplinary, integrating mechanical systems such as a drill mechanism and a vacuum system, alongside biochemical analysis for soil testing. The module is capable of successfully detecting the presence or absence of living components of life from the collected soil particles. This proof-of-life module serves as a proof-of-concept for autonomous life detection in extraterrestrial environments and lays the foundation for future exploration missions.",
      "url": "http://arxiv.org/abs/2601.17158",
      "author": "Bibek Adhikari, Rishab Rijal, Rakesh Yadav, Nikchey Khatri, Sandesh Dhakal",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Robotics)",
      "source_type": "arxiv",
      "tags": [
        "eess.SY"
      ],
      "summary": "Proposes autonomous Mars rover module for soil sampling and biochemical testing using multidisciplinary integration of mechanical and vision systems.",
      "importance_score": 37,
      "reasoning": "Applied space robotics project, primarily engineering integration with limited research novelty.",
      "themes": [
        "Space Robotics",
        "Autonomous Systems",
        "Astrobiology"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes autonomous Mars rover module for soil sampling and biochemical testing using multidisciplinary integration of mechanical and vision systems.</p>",
      "content_html": "<p>arXiv:2601.17158v1 Announce Type: cross  Abstract: The search for extraterrestrial life has long been a primary focus of scientific exploration, driven by rapid advancements in technology and our understanding of the universe. The discovery of water on Mars has sparked significant interest, raising the question of whether life could exist on the planet. This study proposes a novel approach to simulate and illustrate the detection of life using a proof-of-life module integrated into a Mars rover. The module is an autonomous system capable of traveling to designated regions, excavating soil, collecting samples, and performing biochemical testing onboard the rover itself. The project is inherently multidisciplinary, integrating mechanical systems such as a drill mechanism and a vacuum system, alongside biochemical analysis for soil testing. The module is capable of successfully detecting the presence or absence of living components of life from the collected soil particles. This proof-of-life module serves as a proof-of-concept for autonomous life detection in extraterrestrial environments and lays the foundation for future exploration missions.</p>"
    },
    {
      "id": "2a989221adf8",
      "title": "Grammar-Aware Literate Generative Mathematical Programming with Compiler-in-the-Loop",
      "content": "arXiv:2601.17670v1 Announce Type: cross  Abstract: This work investigates generative mathematical programming through the lens of Algebraic Modelling Languages (AMLs) and compiler-guided model synthesis. By leveraging PyOPL, an OPL-like AML compiler that provides detailed syntax diagnostics, we introduce SyntAGM, an end-to-end system that translates natural language problem descriptions into PyOPL models via a generate--compile--assess--revise loop. SyntAGM is grammar-aware thanks to in-context exposure to the PyOPL BNF grammar, and benefits from few-shot retrieval of literate PyOPL model exemplars. To obtain a valid PyOPL model that matches the problem description, SyntAGM mobilises compiler feedback and an LLM-based alignment judge. In a comparative study against established prompting baselines SyntAGM achieves competitive accuracy with superior token, cost, and latency profiles.",
      "url": "http://arxiv.org/abs/2601.17670",
      "author": "Roberto Rossi, Steven D. Prestwich",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.PL"
      ],
      "summary": "SyntAGM translates natural language to PyOPL mathematical models via generate-compile-assess-revise loop with grammar awareness.",
      "importance_score": 36,
      "reasoning": "Practical application of LLMs to mathematical programming. Compiler-in-the-loop approach.",
      "themes": [
        "Mathematical Programming",
        "Code Generation",
        "LLM Applications"
      ],
      "continuation": null,
      "summary_html": "<p>SyntAGM translates natural language to PyOPL mathematical models via generate-compile-assess-revise loop with grammar awareness.</p>",
      "content_html": "<p>arXiv:2601.17670v1 Announce Type: cross  Abstract: This work investigates generative mathematical programming through the lens of Algebraic Modelling Languages (AMLs) and compiler-guided model synthesis. By leveraging PyOPL, an OPL-like AML compiler that provides detailed syntax diagnostics, we introduce SyntAGM, an end-to-end system that translates natural language problem descriptions into PyOPL models via a generate--compile--assess--revise loop. SyntAGM is grammar-aware thanks to in-context exposure to the PyOPL BNF grammar, and benefits from few-shot retrieval of literate PyOPL model exemplars. To obtain a valid PyOPL model that matches the problem description, SyntAGM mobilises compiler feedback and an LLM-based alignment judge. In a comparative study against established prompting baselines SyntAGM achieves competitive accuracy with superior token, cost, and latency profiles.</p>"
    },
    {
      "id": "eca5801891d8",
      "title": "HyCARD-Net: A Synergistic Hybrid Intelligence Framework for Cardiovascular Disease Diagnosis",
      "content": "arXiv:2601.17767v1 Announce Type: new  Abstract: Cardiovascular disease (CVD) remains the foremost cause of mortality worldwide, underscoring the urgent need for intelligent and data-driven diagnostic tools. Traditional predictive models often struggle to generalize across heterogeneous datasets and complex physiological patterns. To address this, we propose a hybrid ensemble framework that integrates deep learning architectures, Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM), with classical machine learning algorithms, including K-Nearest Neighbor (KNN) and Extreme Gradient Boosting (XGB), using an ensemble voting mechanism. This approach combines the representational power of deep networks with the interpretability and efficiency of traditional models. Experiments on two publicly available Kaggle datasets demonstrate that the proposed model achieves superior performance, reaching 82.30 percent accuracy on Dataset I and 97.10 percent on Dataset II, with consistent gains in precision, recall, and F1-score. These findings underscore the robustness and clinical potential of hybrid AI frameworks for predicting cardiovascular disease and facilitating early intervention. Furthermore, this study directly supports the United Nations Sustainable Development Goal 3 (Good Health and Well-being) by promoting early diagnosis, prevention, and management of non-communicable diseases through innovative, data-driven healthcare solutions.",
      "url": "http://arxiv.org/abs/2601.17767",
      "author": "Rajan Das Gupta, Xiaobin Wu, Xun Liu, Jiaqi He",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Proposes HyCARD-Net combining CNNs, LSTMs with KNN and XGBoost via ensemble voting for cardiovascular disease diagnosis, achieving high accuracy on benchmark datasets.",
      "importance_score": 35,
      "reasoning": "Standard ensemble approach to medical classification; limited novelty in methodology or application.",
      "themes": [
        "Healthcare AI",
        "Ensemble Methods"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes HyCARD-Net combining CNNs, LSTMs with KNN and XGBoost via ensemble voting for cardiovascular disease diagnosis, achieving high accuracy on benchmark datasets.</p>",
      "content_html": "<p>arXiv:2601.17767v1 Announce Type: new  Abstract: Cardiovascular disease (CVD) remains the foremost cause of mortality worldwide, underscoring the urgent need for intelligent and data-driven diagnostic tools. Traditional predictive models often struggle to generalize across heterogeneous datasets and complex physiological patterns. To address this, we propose a hybrid ensemble framework that integrates deep learning architectures, Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM), with classical machine learning algorithms, including K-Nearest Neighbor (KNN) and Extreme Gradient Boosting (XGB), using an ensemble voting mechanism. This approach combines the representational power of deep networks with the interpretability and efficiency of traditional models. Experiments on two publicly available Kaggle datasets demonstrate that the proposed model achieves superior performance, reaching 82.30 percent accuracy on Dataset I and 97.10 percent on Dataset II, with consistent gains in precision, recall, and F1-score. These findings underscore the robustness and clinical potential of hybrid AI frameworks for predicting cardiovascular disease and facilitating early intervention. Furthermore, this study directly supports the United Nations Sustainable Development Goal 3 (Good Health and Well-being) by promoting early diagnosis, prevention, and management of non-communicable diseases through innovative, data-driven healthcare solutions.</p>"
    },
    {
      "id": "4ae9744b472c",
      "title": "Investigating Self-regulated Learning Sequences within a Generative AI-based Intelligent Tutoring System",
      "content": "arXiv:2601.17000v1 Announce Type: cross  Abstract: There has been a growing trend in employing generative artificial intelligence (GenAI) techniques to support learning. Moreover, scholars have reached a consensus on the critical role of self-regulated learning (SRL) in ensuring learning effectiveness within GenAI-assisted learning environments, making it essential to capture students' dynamic SRL patterns. In this study, we extracted students' interaction patterns with GenAI from trace data as they completed a problem-solving task within a GenAI-assisted intelligent tutoring system. Students' purpose of using GenAI was also analyzed from the perspective of information processing, i.e., information acquisition and information transformation. Using sequential and clustering analysis, this study classified participants into two groups based on their SRL sequences. These two groups differed in the frequency and temporal characteristics of GenAI use. In addition, most students used GenAI for information acquisition rather than information transformation, while the correlation between the purpose of using GenAI and learning performance was not statistically significant. Our findings inform both pedagogical design and the development of GenAI-assisted learning environments.",
      "url": "http://arxiv.org/abs/2601.17000",
      "author": "Jie Gao, Shasha Li, Jianhua Zhang, Shan Li, Tingting Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Studies self-regulated learning patterns in GenAI-assisted tutoring systems by analyzing student interaction traces and information processing behaviors. Uses sequential and clustering analysis to identify learning patterns.",
      "importance_score": 35,
      "reasoning": "Applied education research with limited novelty in AI methodology. Niche application study.",
      "themes": [
        "Education AI",
        "Human-AI Interaction"
      ],
      "continuation": null,
      "summary_html": "<p>Studies self-regulated learning patterns in GenAI-assisted tutoring systems by analyzing student interaction traces and information processing behaviors. Uses sequential and clustering analysis to identify learning patterns.</p>",
      "content_html": "<p>arXiv:2601.17000v1 Announce Type: cross  Abstract: There has been a growing trend in employing generative artificial intelligence (GenAI) techniques to support learning. Moreover, scholars have reached a consensus on the critical role of self-regulated learning (SRL) in ensuring learning effectiveness within GenAI-assisted learning environments, making it essential to capture students' dynamic SRL patterns. In this study, we extracted students' interaction patterns with GenAI from trace data as they completed a problem-solving task within a GenAI-assisted intelligent tutoring system. Students' purpose of using GenAI was also analyzed from the perspective of information processing, i.e., information acquisition and information transformation. Using sequential and clustering analysis, this study classified participants into two groups based on their SRL sequences. These two groups differed in the frequency and temporal characteristics of GenAI use. In addition, most students used GenAI for information acquisition rather than information transformation, while the correlation between the purpose of using GenAI and learning performance was not statistically significant. Our findings inform both pedagogical design and the development of GenAI-assisted learning environments.</p>"
    },
    {
      "id": "40d52ee98b76",
      "title": "AI-based System for Transforming text and sound to Educational Videos",
      "content": "arXiv:2601.17022v1 Announce Type: cross  Abstract: Technological developments have produced methods that can generate educational videos from input text or sound. Recently, the use of deep learning techniques for image and video generation has been widely explored, particularly in education. However, generating video content from conditional inputs such as text or speech remains a challenging area. In this paper, we introduce a novel method to the educational structure, Generative Adversarial Network (GAN), which develop frame-for-frame frameworks and are able to create full educational videos. The proposed system is structured into three main phases In the first phase, the input (either text or speech) is transcribed using speech recognition. In the second phase, key terms are extracted and relevant images are generated using advanced models such as CLIP and diffusion models to enhance visual quality and semantic alignment. In the final phase, the generated images are synthesized into a video format, integrated with either pre-recorded or synthesized sound, resulting in a fully interactive educational video. The proposed system is compared with other systems such as TGAN, MoCoGAN, and TGANS-C, achieving a Fr\\'echet Inception Distance (FID) score of 28.75%, which indicates improved visual quality and better over existing methods.",
      "url": "http://arxiv.org/abs/2601.17022",
      "author": "M. E. ElAlami, S. M. Khater, M. El. R. Rehan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.MM"
      ],
      "summary": "Proposes a GAN-based system for converting text or speech inputs into educational videos through three phases: transcription, keyword extraction, and frame-by-frame video generation.",
      "importance_score": 35,
      "reasoning": "Applied educational technology with standard GAN architecture. Limited technical novelty in the generation approach.",
      "themes": [
        "Video Generation",
        "Education AI",
        "GANs"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes a GAN-based system for converting text or speech inputs into educational videos through three phases: transcription, keyword extraction, and frame-by-frame video generation.</p>",
      "content_html": "<p>arXiv:2601.17022v1 Announce Type: cross  Abstract: Technological developments have produced methods that can generate educational videos from input text or sound. Recently, the use of deep learning techniques for image and video generation has been widely explored, particularly in education. However, generating video content from conditional inputs such as text or speech remains a challenging area. In this paper, we introduce a novel method to the educational structure, Generative Adversarial Network (GAN), which develop frame-for-frame frameworks and are able to create full educational videos. The proposed system is structured into three main phases In the first phase, the input (either text or speech) is transcribed using speech recognition. In the second phase, key terms are extracted and relevant images are generated using advanced models such as CLIP and diffusion models to enhance visual quality and semantic alignment. In the final phase, the generated images are synthesized into a video format, integrated with either pre-recorded or synthesized sound, resulting in a fully interactive educational video. The proposed system is compared with other systems such as TGAN, MoCoGAN, and TGANS-C, achieving a Fr\\'echet Inception Distance (FID) score of 28.75%, which indicates improved visual quality and better over existing methods.</p>"
    },
    {
      "id": "6b033a90c977",
      "title": "SiMiC: Context-Aware Silicon Microstructure Characterization Using Attention-Based Convolutional Neural Networks for Field-Emission Tip Analysis",
      "content": "arXiv:2601.17048v1 Announce Type: cross  Abstract: Accurate characterization of silicon microstructures is essential for advancing microscale fabrication, quality control, and device performance. Traditional analysis using Scanning Electron Microscopy (SEM) often requires labor-intensive, manual evaluation of feature geometry, limiting throughput and reproducibility. In this study, we propose SiMiC: Context-Aware Silicon Microstructure Characterization Using Attention-Based Convolutional Neural Networks for Field-Emission Tip Analysis. By leveraging deep learning, our approach efficiently extracts morphological features-such as size, shape, and apex curvature-from SEM images, significantly reducing human intervention while improving measurement consistency. A specialized dataset of silicon-based field-emitter tips was developed, and a customized CNN architecture incorporating attention mechanisms was trained for multi-class microstructure classification and dimensional prediction. Comparative analysis with classical image processing techniques demonstrates that SiMiC achieves high accuracy while maintaining interpretability. The proposed framework establishes a foundation for data-driven microstructure analysis directly linked to field-emission performance, opening avenues for correlating emitter geometry with emission behavior and guiding the design of optimized cold-cathode and SEM electron sources. The related dataset and algorithm repository that could serve as a baseline in this area can be found at https://research.jingjietan.com/?q=SIMIC",
      "url": "http://arxiv.org/abs/2601.17048",
      "author": "Jing Jie Tan, Rupert Schreiner, Matthias Hausladen, Ali Asgharzade, Simon Edler, Julian Bartsch, Michael Bachmann, Andreas Schels, Ban-Hoe Kwan, Danny Wee-Kiat Ng, Yan-Chai Hum",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes SiMiC, an attention-based CNN for characterizing silicon microstructures from SEM images, automatically extracting morphological features like size, shape, and apex curvature.",
      "importance_score": 35,
      "reasoning": "Domain-specific application of attention CNNs. Standard deep learning approach for specialized manufacturing application.",
      "themes": [
        "Computer Vision",
        "Manufacturing AI"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes SiMiC, an attention-based CNN for characterizing silicon microstructures from SEM images, automatically extracting morphological features like size, shape, and apex curvature.</p>",
      "content_html": "<p>arXiv:2601.17048v1 Announce Type: cross  Abstract: Accurate characterization of silicon microstructures is essential for advancing microscale fabrication, quality control, and device performance. Traditional analysis using Scanning Electron Microscopy (SEM) often requires labor-intensive, manual evaluation of feature geometry, limiting throughput and reproducibility. In this study, we propose SiMiC: Context-Aware Silicon Microstructure Characterization Using Attention-Based Convolutional Neural Networks for Field-Emission Tip Analysis. By leveraging deep learning, our approach efficiently extracts morphological features-such as size, shape, and apex curvature-from SEM images, significantly reducing human intervention while improving measurement consistency. A specialized dataset of silicon-based field-emitter tips was developed, and a customized CNN architecture incorporating attention mechanisms was trained for multi-class microstructure classification and dimensional prediction. Comparative analysis with classical image processing techniques demonstrates that SiMiC achieves high accuracy while maintaining interpretability. The proposed framework establishes a foundation for data-driven microstructure analysis directly linked to field-emission performance, opening avenues for correlating emitter geometry with emission behavior and guiding the design of optimized cold-cathode and SEM electron sources. The related dataset and algorithm repository that could serve as a baseline in this area can be found at https://research.jingjietan.com/?q=SIMIC</p>"
    },
    {
      "id": "97915db58d93",
      "title": "Trademark Search, Artificial Intelligence and the Role of the Private Sector",
      "content": "arXiv:2601.17072v1 Announce Type: cross  Abstract: Almost every industry today confronts the potential role of artificial intelligence and machine learning in its future. While many studies examine AI in consumer marketing, less attention addresses AI's role in creating and selecting trademarks that are distinctive, recognizable, and meaningful to consumers. Traditional economic approaches to trademarks focus almost exclusively on consumer-based, demand-side considerations regarding search. However, these approaches are incomplete because they fail to account for substantial costs faced not just by consumers, but by trademark applicants as well. Given AI's rapidly increasing role in trademark search and similarity analysis, lawyers and scholars should understand its dramatic implications. This paper proposes that AI should interest anyone studying trademarks and their role in economic decision-making. We examine how machine learning techniques will transform the application and interpretation of foundational trademark doctrines, producing significant implications for the trademark ecosystem. We run empirical experiments regarding trademark search to assess the efficacy of various trademark search engines, many of which employ machine learning methods. Through comparative analysis, we evaluate how these AI-powered tools function in practice. In an age where artificial intelligence increasingly governs trademark selection, the classic division between consumers and trademark owners deserves an updated, supply-side framework. This insight has transformative potential for encouraging both innovation and efficiency in trademark law and practice.",
      "url": "http://arxiv.org/abs/2601.17072",
      "author": "Sonia Katyal, Aniket Kesari",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Examines AI's role in trademark search and similarity analysis, highlighting implications for lawyers and scholars as AI transforms intellectual property practices.",
      "importance_score": 35,
      "reasoning": "Policy and legal analysis with limited technical AI contribution. Descriptive rather than advancing AI methodology.",
      "themes": [
        "AI Policy",
        "Intellectual Property"
      ],
      "continuation": null,
      "summary_html": "<p>Examines AI's role in trademark search and similarity analysis, highlighting implications for lawyers and scholars as AI transforms intellectual property practices.</p>",
      "content_html": "<p>arXiv:2601.17072v1 Announce Type: cross  Abstract: Almost every industry today confronts the potential role of artificial intelligence and machine learning in its future. While many studies examine AI in consumer marketing, less attention addresses AI's role in creating and selecting trademarks that are distinctive, recognizable, and meaningful to consumers. Traditional economic approaches to trademarks focus almost exclusively on consumer-based, demand-side considerations regarding search. However, these approaches are incomplete because they fail to account for substantial costs faced not just by consumers, but by trademark applicants as well. Given AI's rapidly increasing role in trademark search and similarity analysis, lawyers and scholars should understand its dramatic implications. This paper proposes that AI should interest anyone studying trademarks and their role in economic decision-making. We examine how machine learning techniques will transform the application and interpretation of foundational trademark doctrines, producing significant implications for the trademark ecosystem. We run empirical experiments regarding trademark search to assess the efficacy of various trademark search engines, many of which employ machine learning methods. Through comparative analysis, we evaluate how these AI-powered tools function in practice. In an age where artificial intelligence increasingly governs trademark selection, the classic division between consumers and trademark owners deserves an updated, supply-side framework. This insight has transformative potential for encouraging both innovation and efficiency in trademark law and practice.</p>"
    },
    {
      "id": "d376f77cc29a",
      "title": "CUROCKET: Optimizing ROCKET for GPU",
      "content": "arXiv:2601.17091v1 Announce Type: cross  Abstract: ROCKET (RandOm Convolutional KErnel Transform) is a feature extraction algorithm created for Time Series Classification (TSC), published in 2019. It applies convolution with randomly generated kernels on a time series, producing features that can be used to train a linear classifier or regressor like Ridge. At the time of publication, ROCKET was on par with the best state-of-the-art algorithms for TSC in terms of accuracy while being significantly less computationally expensive, making ROCKET a compelling algorithm for TSC. This also led to several subsequent versions, further improving accuracy and computational efficiency. The currently available ROCKET implementations are mostly bound to execution on CPU. However, convolution is a task that can be highly parallelized and is therefore suited to be executed on GPU, which speeds up the computation significantly. A key difficulty arises from the inhomogeneous kernels ROCKET uses, making standard methods for applying convolution on GPU inefficient. In this work, we propose an algorithm that is able to efficiently perform ROCKET on GPU and achieves up to 11 times higher computational efficiency per watt than ROCKET on CPU. The code for CUROCKET is available in this repository https://github.com/oleeven/CUROCKET on github.",
      "url": "http://arxiv.org/abs/2601.17091",
      "author": "Ole St\\\"uven, Keno Moenck, Thorsten Sch\\\"uppstuhl",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Optimizes ROCKET time series classification algorithm for GPU execution with CuPy implementation. Enables convolution acceleration on GPU hardware.",
      "importance_score": 35,
      "reasoning": "Engineering optimization of existing algorithm. Useful but limited novelty in methodology.",
      "themes": [
        "Time Series",
        "GPU Optimization"
      ],
      "continuation": null,
      "summary_html": "<p>Optimizes ROCKET time series classification algorithm for GPU execution with CuPy implementation. Enables convolution acceleration on GPU hardware.</p>",
      "content_html": "<p>arXiv:2601.17091v1 Announce Type: cross  Abstract: ROCKET (RandOm Convolutional KErnel Transform) is a feature extraction algorithm created for Time Series Classification (TSC), published in 2019. It applies convolution with randomly generated kernels on a time series, producing features that can be used to train a linear classifier or regressor like Ridge. At the time of publication, ROCKET was on par with the best state-of-the-art algorithms for TSC in terms of accuracy while being significantly less computationally expensive, making ROCKET a compelling algorithm for TSC. This also led to several subsequent versions, further improving accuracy and computational efficiency. The currently available ROCKET implementations are mostly bound to execution on CPU. However, convolution is a task that can be highly parallelized and is therefore suited to be executed on GPU, which speeds up the computation significantly. A key difficulty arises from the inhomogeneous kernels ROCKET uses, making standard methods for applying convolution on GPU inefficient. In this work, we propose an algorithm that is able to efficiently perform ROCKET on GPU and achieves up to 11 times higher computational efficiency per watt than ROCKET on CPU. The code for CUROCKET is available in this repository https://github.com/oleeven/CUROCKET on github.</p>"
    },
    {
      "id": "3e1f406ef343",
      "title": "FinMetaMind: A Tech Blueprint on NLQ Systems for Financial Knowledge Search",
      "content": "arXiv:2601.17333v1 Announce Type: cross  Abstract: Natural Language Query (NLQ) allows users to search and interact with information systems using plain, human language instead of structured query syntax. This paper presents a technical blueprint on the design of a modern NLQ system tailored to financial knowledge search. The introduction of NLQ not only enhances the precision and recall of the knowledge search compared to traditional methods, but also facilitates deeper insights by efficiently linking disparate financial objects, events, and relationships. Using core constructs from natural language processing, search engineering, and vector data models, the proposed system aims to address key challenges in discovering, relevance ranking, data freshness, and entity recognition intrinsic to financial data retrieval. In this work, we detail the unique requirements of NLQ for financial datasets and documents, outline the architectural components for offline indexing and online retrieval, and discuss the real-world use cases of enhanced knowledge search in financial services. We delve into the theoretical underpinnings and experimental evidence supporting our proposed architecture, ultimately providing a comprehensive analysis on the subject matter. We also provide a detailed elaboration of our experimental methodology, the data used, the results and future optimizations in this study.",
      "url": "http://arxiv.org/abs/2601.17333",
      "author": "Lalit Pant, Shivang Nagar",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.IR"
      ],
      "summary": "Technical blueprint for NLQ system for financial knowledge search addressing relevance ranking, data freshness, and entity recognition using NLP and vector data models.",
      "importance_score": 35,
      "reasoning": "System design document rather than research contribution. Applied industry focus.",
      "themes": [
        "Financial AI",
        "Information Retrieval",
        "NLQ"
      ],
      "continuation": null,
      "summary_html": "<p>Technical blueprint for NLQ system for financial knowledge search addressing relevance ranking, data freshness, and entity recognition using NLP and vector data models.</p>",
      "content_html": "<p>arXiv:2601.17333v1 Announce Type: cross  Abstract: Natural Language Query (NLQ) allows users to search and interact with information systems using plain, human language instead of structured query syntax. This paper presents a technical blueprint on the design of a modern NLQ system tailored to financial knowledge search. The introduction of NLQ not only enhances the precision and recall of the knowledge search compared to traditional methods, but also facilitates deeper insights by efficiently linking disparate financial objects, events, and relationships. Using core constructs from natural language processing, search engineering, and vector data models, the proposed system aims to address key challenges in discovering, relevance ranking, data freshness, and entity recognition intrinsic to financial data retrieval. In this work, we detail the unique requirements of NLQ for financial datasets and documents, outline the architectural components for offline indexing and online retrieval, and discuss the real-world use cases of enhanced knowledge search in financial services. We delve into the theoretical underpinnings and experimental evidence supporting our proposed architecture, ultimately providing a comprehensive analysis on the subject matter. We also provide a detailed elaboration of our experimental methodology, the data used, the results and future optimizations in this study.</p>"
    },
    {
      "id": "b8a99275ca46",
      "title": "Do readers prefer AI-generated Italian short stories?",
      "content": "arXiv:2601.17363v1 Announce Type: cross  Abstract: This study investigates whether readers prefer AI-generated short stories in Italian over one written by a renowned Italian author. In a blind setup, 20 participants read and evaluated three stories, two created with ChatGPT-4o and one by Alberto Moravia, without being informed of their origin. To explore potential influencing factors, reading habits and demographic data, comprising age, gender, education and first language, were also collected. The results showed that the AI-written texts received slightly higher average ratings and were more frequently preferred, although differences were modest. No statistically significant associations were found between text preference and demographic or reading-habit variables. These findings challenge assumptions about reader preference for human-authored fiction and raise questions about the necessity of synthetic-text editing in literary contexts.",
      "url": "http://arxiv.org/abs/2601.17363",
      "author": "Michael Farrell",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "User study investigating reader preferences for AI-generated Italian short stories vs human author. Found AI texts received slightly higher ratings but no significant demographic associations.",
      "importance_score": 35,
      "reasoning": "Small-scale empirical study with limited generalizability. Interesting but preliminary findings.",
      "themes": [
        "Creative AI",
        "Human-AI Perception",
        "User Studies"
      ],
      "continuation": null,
      "summary_html": "<p>User study investigating reader preferences for AI-generated Italian short stories vs human author. Found AI texts received slightly higher ratings but no significant demographic associations.</p>",
      "content_html": "<p>arXiv:2601.17363v1 Announce Type: cross  Abstract: This study investigates whether readers prefer AI-generated short stories in Italian over one written by a renowned Italian author. In a blind setup, 20 participants read and evaluated three stories, two created with ChatGPT-4o and one by Alberto Moravia, without being informed of their origin. To explore potential influencing factors, reading habits and demographic data, comprising age, gender, education and first language, were also collected. The results showed that the AI-written texts received slightly higher average ratings and were more frequently preferred, although differences were modest. No statistically significant associations were found between text preference and demographic or reading-habit variables. These findings challenge assumptions about reader preference for human-authored fiction and raise questions about the necessity of synthetic-text editing in literary contexts.</p>"
    },
    {
      "id": "f3469f160fd7",
      "title": "FedCCA: Client-Centric Adaptation against Data Heterogeneity in Federated Learning on IoT Devices",
      "content": "arXiv:2601.17713v1 Announce Type: cross  Abstract: With the rapid development of the Internet of Things (IoT), AI model training on private data such as human sensing data is highly desired. Federated learning (FL) has emerged as a privacy-preserving distributed training framework for this purpuse. However, the data heterogeneity issue among IoT devices can significantly degrade the model performance and convergence speed in FL. Existing approaches limit in fixed client selection and aggregation on cloud server, making the privacy-preserving extraction of client-specific information during local training challenging. To this end, we propose Client-Centric Adaptation federated learning (FedCCA), an algorithm that optimally utilizes client-specific knowledge to learn a unique model for each client through selective adaptation, aiming to alleviate the influence of data heterogeneity. Specifically, FedCCA employs dynamic client selection and adaptive aggregation based on the additional client-specific encoder. To enhance multi-source knowledge transfer, we adopt an attention-based global aggregation strategy. We conducted extensive experiments on diverse datasets to assess the efficacy of FedCCA. The experimental results demonstrate that our approach exhibits a substantial performance advantage over competing baselines in addressing this specific problem.",
      "url": "http://arxiv.org/abs/2601.17713",
      "author": "Kaile Wang, Jiannong Cao, Yu Yang, Xiaoyin Li, Yinfeng Cao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "FedCCA addresses data heterogeneity in federated learning on IoT through client-centric adaptation extracting client-specific knowledge.",
      "importance_score": 35,
      "reasoning": "Addresses FL heterogeneity for IoT. Client-side optimization.",
      "themes": [
        "Federated Learning",
        "IoT",
        "Data Heterogeneity"
      ],
      "continuation": null,
      "summary_html": "<p>FedCCA addresses data heterogeneity in federated learning on IoT through client-centric adaptation extracting client-specific knowledge.</p>",
      "content_html": "<p>arXiv:2601.17713v1 Announce Type: cross  Abstract: With the rapid development of the Internet of Things (IoT), AI model training on private data such as human sensing data is highly desired. Federated learning (FL) has emerged as a privacy-preserving distributed training framework for this purpuse. However, the data heterogeneity issue among IoT devices can significantly degrade the model performance and convergence speed in FL. Existing approaches limit in fixed client selection and aggregation on cloud server, making the privacy-preserving extraction of client-specific information during local training challenging. To this end, we propose Client-Centric Adaptation federated learning (FedCCA), an algorithm that optimally utilizes client-specific knowledge to learn a unique model for each client through selective adaptation, aiming to alleviate the influence of data heterogeneity. Specifically, FedCCA employs dynamic client selection and adaptive aggregation based on the additional client-specific encoder. To enhance multi-source knowledge transfer, we adopt an attention-based global aggregation strategy. We conducted extensive experiments on diverse datasets to assess the efficacy of FedCCA. The experimental results demonstrate that our approach exhibits a substantial performance advantage over competing baselines in addressing this specific problem.</p>"
    },
    {
      "id": "f5ca602aea5a",
      "title": "From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic",
      "content": "arXiv:2601.18702v1 Announce Type: cross  Abstract: Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the \"hallucinations\" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI.",
      "url": "http://arxiv.org/abs/2601.18702",
      "author": "Hansheng Ren",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes 'Exactness Hypothesis' claiming AGI requires arbitrary precision arithmetic, and introduces Halo Architecture using rational arithmetic to address LLM hallucinations attributed to floating-point errors.",
      "importance_score": 35,
      "reasoning": "Speculative claims about hallucinations arising from floating-point errors lack strong evidence. Extraordinary claims without adequate support.",
      "themes": [
        "AGI",
        "Numerical Precision",
        "Hallucinations"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes 'Exactness Hypothesis' claiming AGI requires arbitrary precision arithmetic, and introduces Halo Architecture using rational arithmetic to address LLM hallucinations attributed to floating-point errors.</p>",
      "content_html": "<p>arXiv:2601.18702v1 Announce Type: cross  Abstract: Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the \"hallucinations\" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI.</p>"
    },
    {
      "id": "ae8a0c3b4823",
      "title": "Efficient Gaussian process learning via subspace projections",
      "content": "arXiv:2601.16332v1 Announce Type: new  Abstract: We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \\emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random projections on the unit sphere. We show the superiority of the PL, in terms of accuracy and computational efficiency, over the exact GP training and the variational free energy approach to sparse GPs over different optimisers, kernels and datasets of moderately large sizes.",
      "url": "http://arxiv.org/abs/2601.16332",
      "author": "Felipe Tobar, Elsa Cazelles",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes 'projected likelihood' for Gaussian Process training using lower-dimensional data projections, providing closed-form expressions for information loss. Shows improvements over exact GP training and variational sparse GPs in accuracy and computational efficiency.",
      "importance_score": 35,
      "reasoning": "Incremental improvement to GP methods; useful for practitioners but limited novelty in methodology.",
      "themes": [
        "Gaussian Processes",
        "Efficient Learning",
        "Dimensionality Reduction"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes 'projected likelihood' for Gaussian Process training using lower-dimensional data projections, providing closed-form expressions for information loss. Shows improvements over exact GP training and variational sparse GPs in accuracy and computational efficiency.</p>",
      "content_html": "<p>arXiv:2601.16332v1 Announce Type: new  Abstract: We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \\emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random projections on the unit sphere. We show the superiority of the PL, in terms of accuracy and computational efficiency, over the exact GP training and the variational free energy approach to sparse GPs over different optimisers, kernels and datasets of moderately large sizes.</p>"
    },
    {
      "id": "aebca3c17189",
      "title": "kNN-Graph: An adaptive graph model for $k$-nearest neighbors",
      "content": "arXiv:2601.16509v1 Announce Type: new  Abstract: The k-nearest neighbors (kNN) algorithm is a cornerstone of non-parametric classification in artificial intelligence, yet its deployment in large-scale applications is persistently constrained by the computational trade-off between inference speed and accuracy. Existing approximate nearest neighbor solutions accelerate retrieval but often degrade classification precision and lack adaptability in selecting the optimal neighborhood size (k). Here, we present an adaptive graph model that decouples inference latency from computational complexity. By integrating a Hierarchical Navigable Small World (HNSW) graph with a pre-computed voting mechanism, our framework completely transfers the computational burden of neighbor selection and weighting to the training phase. Within this topological structure, higher graph layers enable rapid navigation, while lower layers encode precise, node-specific decision boundaries with adaptive neighbor counts. Benchmarking against eight state-of-the-art baselines across six diverse datasets, we demonstrate that this architecture significantly accelerates inference speeds, achieving real-time performance, without compromising classification accuracy. These findings offer a scalable, robust solution to the long-standing inference bottleneck of kNN, establishing a new structural paradigm for graph-based nonparametric learning.",
      "url": "http://arxiv.org/abs/2601.16509",
      "author": "Jiaye Li, Gang Chen, Hang Xu, Shichao Zhang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes adaptive graph model for k-nearest neighbors that integrates HNSW graphs with pre-computed voting. Decouples inference latency from computational complexity by shifting neighbor selection to preprocessing.",
      "importance_score": 35,
      "reasoning": "Practical improvement to fundamental algorithm; engineering contribution without significant methodological novelty.",
      "themes": [
        "k-Nearest Neighbors",
        "Efficient Inference",
        "Approximate Search"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes adaptive graph model for k-nearest neighbors that integrates HNSW graphs with pre-computed voting. Decouples inference latency from computational complexity by shifting neighbor selection to preprocessing.</p>",
      "content_html": "<p>arXiv:2601.16509v1 Announce Type: new  Abstract: The k-nearest neighbors (kNN) algorithm is a cornerstone of non-parametric classification in artificial intelligence, yet its deployment in large-scale applications is persistently constrained by the computational trade-off between inference speed and accuracy. Existing approximate nearest neighbor solutions accelerate retrieval but often degrade classification precision and lack adaptability in selecting the optimal neighborhood size (k). Here, we present an adaptive graph model that decouples inference latency from computational complexity. By integrating a Hierarchical Navigable Small World (HNSW) graph with a pre-computed voting mechanism, our framework completely transfers the computational burden of neighbor selection and weighting to the training phase. Within this topological structure, higher graph layers enable rapid navigation, while lower layers encode precise, node-specific decision boundaries with adaptive neighbor counts. Benchmarking against eight state-of-the-art baselines across six diverse datasets, we demonstrate that this architecture significantly accelerates inference speeds, achieving real-time performance, without compromising classification accuracy. These findings offer a scalable, robust solution to the long-standing inference bottleneck of kNN, establishing a new structural paradigm for graph-based nonparametric learning.</p>"
    },
    {
      "id": "fe2320675fd3",
      "title": "A Collision-Free Hot-Tier Extension for Engram-Style Conditional Memory: A Controlled Study of Training Dynamics",
      "content": "arXiv:2601.16531v2 Announce Type: new  Abstract: We investigate whether high-frequency key collisions are a primary bottleneck in Engram-style conditional memory. To isolate the effect of collisions, we introduce Engram-Nine, a collision-free hot-tier extension that maps the most frequent n-grams through a Minimal Perfect Hash Function (MPHF) while retaining the original multi-head hashed lookup as a cold tier. Under a strictly iso-parameter setup, the collision-free design does not consistently improve validation loss.   Through route-stratified evaluation (decomposing per-token loss into hot/cold contributions), we uncover a consistent \"hot-to-cold advantage flip\" during training: hot (high-frequency) positions initially have lower loss, but cold positions eventually surpass them. Crucially, collision-free configurations flip earlier than collision-prone baselines, suggesting that collisions act as implicit regularization. We also identify a gating mismatch: the gate learns to favor hot positions early in training, but this preference persists even after the flip, assigning higher weights to positions with higher loss.   Our findings suggest that improving lookup precision alone does not guarantee better training outcomes. The dominant limitation may lie in gating credit assignment rather than index accuracy, and collision-induced noise may provide beneficial regularization that should not be naively eliminated.",
      "url": "http://arxiv.org/abs/2601.16531",
      "author": "Tao Lin",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Investigates whether high-frequency key collisions bottleneck Engram-style conditional memory. Introduces collision-free hot-tier extension but finds it doesn't consistently improve validation loss.",
      "importance_score": 35,
      "reasoning": "Interesting negative result about memory architectures; niche contribution with limited broader impact.",
      "themes": [
        "Memory Networks",
        "Language Models",
        "Architecture Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Investigates whether high-frequency key collisions bottleneck Engram-style conditional memory. Introduces collision-free hot-tier extension but finds it doesn't consistently improve validation loss.</p>",
      "content_html": "<p>arXiv:2601.16531v2 Announce Type: new  Abstract: We investigate whether high-frequency key collisions are a primary bottleneck in Engram-style conditional memory. To isolate the effect of collisions, we introduce Engram-Nine, a collision-free hot-tier extension that maps the most frequent n-grams through a Minimal Perfect Hash Function (MPHF) while retaining the original multi-head hashed lookup as a cold tier. Under a strictly iso-parameter setup, the collision-free design does not consistently improve validation loss.   Through route-stratified evaluation (decomposing per-token loss into hot/cold contributions), we uncover a consistent \"hot-to-cold advantage flip\" during training: hot (high-frequency) positions initially have lower loss, but cold positions eventually surpass them. Crucially, collision-free configurations flip earlier than collision-prone baselines, suggesting that collisions act as implicit regularization. We also identify a gating mismatch: the gate learns to favor hot positions early in training, but this preference persists even after the flip, assigning higher weights to positions with higher loss.   Our findings suggest that improving lookup precision alone does not guarantee better training outcomes. The dominant limitation may lie in gating credit assignment rather than index accuracy, and collision-induced noise may provide beneficial regularization that should not be naively eliminated.</p>"
    },
    {
      "id": "ef6b48af7f79",
      "title": "Predicting Startup Success Using Large Language Models: A Novel In-Context Learning Approach",
      "content": "arXiv:2601.16568v1 Announce Type: new  Abstract: Venture capital (VC) investments in early-stage startups that end up being successful can yield high returns. However, predicting early-stage startup success remains challenging due to data scarcity (e.g., many VC firms have information about only a few dozen of early-stage startups and whether they were successful). This limits the effectiveness of traditional machine learning methods that rely on large labeled datasets for model training. To address this challenge, we propose an in-context learning framework for startup success prediction using large language models (LLMs) that requires no model training and leverages only a small set of labeled startups as demonstration examples. Specifically, we propose a novel k-nearest-neighbor-based in-context learning framework, called kNN-ICL, which selects the most relevant past startups as examples based on similarity. Using real-world profiles from Crunchbase, we find that the kNN-ICL approach achieves higher prediction accuracy than supervised machine learning baselines and vanilla in-context learning. Further, we study how performance varies with the number of in-context examples and find that a high balanced accuracy can be achieved with as few as 50 examples. Together, we demonstrate that in-context learning can serve as a decision-making tool for VC firms operating in data-scarce environments.",
      "url": "http://arxiv.org/abs/2601.16568",
      "author": "Abdurahman Maarouf, Alket Bakiaj, Stefan Feuerriegel",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Uses in-context learning with LLMs for startup success prediction without model training. Proposes k-NN based example selection for demonstrations when labeled data is scarce.",
      "importance_score": 35,
      "reasoning": "Application of LLMs to VC prediction; limited methodological novelty, primarily application-focused.",
      "themes": [
        "Large Language Models",
        "In-Context Learning",
        "Financial Prediction"
      ],
      "continuation": null,
      "summary_html": "<p>Uses in-context learning with LLMs for startup success prediction without model training. Proposes k-NN based example selection for demonstrations when labeled data is scarce.</p>",
      "content_html": "<p>arXiv:2601.16568v1 Announce Type: new  Abstract: Venture capital (VC) investments in early-stage startups that end up being successful can yield high returns. However, predicting early-stage startup success remains challenging due to data scarcity (e.g., many VC firms have information about only a few dozen of early-stage startups and whether they were successful). This limits the effectiveness of traditional machine learning methods that rely on large labeled datasets for model training. To address this challenge, we propose an in-context learning framework for startup success prediction using large language models (LLMs) that requires no model training and leverages only a small set of labeled startups as demonstration examples. Specifically, we propose a novel k-nearest-neighbor-based in-context learning framework, called kNN-ICL, which selects the most relevant past startups as examples based on similarity. Using real-world profiles from Crunchbase, we find that the kNN-ICL approach achieves higher prediction accuracy than supervised machine learning baselines and vanilla in-context learning. Further, we study how performance varies with the number of in-context examples and find that a high balanced accuracy can be achieved with as few as 50 examples. Together, we demonstrate that in-context learning can serve as a decision-making tool for VC firms operating in data-scarce environments.</p>"
    },
    {
      "id": "619087a7702c",
      "title": "Integrating Meteorological and Operational Data: A Novel Approach to Understanding Railway Delays in Finland",
      "content": "arXiv:2601.16592v1 Announce Type: new  Abstract: Train delays result from complex interactions between operational, technical, and environmental factors. While weather impacts railway reliability, particularly in Nordic regions, existing datasets rarely integrate meteorological information with operational train data. This study presents the first publicly available dataset combining Finnish railway operations with synchronized meteorological observations from 2018-2024. The dataset integrates operational metrics from Finland Digitraffic Railway Traffic Service with weather measurements from 209 environmental monitoring stations, using spatial-temporal alignment via Haversine distance. It encompasses 28 engineered features across operational variables and meteorological measurements, covering approximately 38.5 million observations from Finland's 5,915-kilometer rail network. Preprocessing includes strategic missing data handling through spatial fallback algorithms, cyclical encoding of temporal features, and robust scaling of weather data to address sensor outliers. Analysis reveals distinct seasonal patterns, with winter months exhibiting delay rates exceeding 25\\% and geographic clustering of high-delay corridors in central and northern Finland. Furthermore, the work demonstrates applications of the data set in analysing the reliability of railway traffic in Finland. A baseline experiment using XGBoost regression achieved a Mean Absolute Error of 2.73 minutes for predicting station-specific delays, demonstrating the dataset's utility for machine learning applications. The dataset enables diverse applications, including train delay prediction, weather impact assessment, and infrastructure vulnerability mapping, providing researchers with a flexible resource for machine learning applications in railway operations research.",
      "url": "http://arxiv.org/abs/2601.16592",
      "author": "Vinicius Pozzobon Borin, Jean Michel de Souza Sant'Ana, Usama Raheel, Nurul Huda Mahmood",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Presents first public dataset combining Finnish railway operations with synchronized meteorological observations 2018-2024. Integrates data from 209 weather stations with 28 engineered features.",
      "importance_score": 35,
      "reasoning": "Useful dataset contribution for transportation research; limited methodological contribution.",
      "themes": [
        "Transportation",
        "Dataset",
        "Weather Impact Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Presents first public dataset combining Finnish railway operations with synchronized meteorological observations 2018-2024. Integrates data from 209 weather stations with 28 engineered features.</p>",
      "content_html": "<p>arXiv:2601.16592v1 Announce Type: new  Abstract: Train delays result from complex interactions between operational, technical, and environmental factors. While weather impacts railway reliability, particularly in Nordic regions, existing datasets rarely integrate meteorological information with operational train data. This study presents the first publicly available dataset combining Finnish railway operations with synchronized meteorological observations from 2018-2024. The dataset integrates operational metrics from Finland Digitraffic Railway Traffic Service with weather measurements from 209 environmental monitoring stations, using spatial-temporal alignment via Haversine distance. It encompasses 28 engineered features across operational variables and meteorological measurements, covering approximately 38.5 million observations from Finland's 5,915-kilometer rail network. Preprocessing includes strategic missing data handling through spatial fallback algorithms, cyclical encoding of temporal features, and robust scaling of weather data to address sensor outliers. Analysis reveals distinct seasonal patterns, with winter months exhibiting delay rates exceeding 25\\% and geographic clustering of high-delay corridors in central and northern Finland. Furthermore, the work demonstrates applications of the data set in analysing the reliability of railway traffic in Finland. A baseline experiment using XGBoost regression achieved a Mean Absolute Error of 2.73 minutes for predicting station-specific delays, demonstrating the dataset's utility for machine learning applications. The dataset enables diverse applications, including train delay prediction, weather impact assessment, and infrastructure vulnerability mapping, providing researchers with a flexible resource for machine learning applications in railway operations research.</p>"
    },
    {
      "id": "8fbbd1847d0e",
      "title": "Sample-wise Constrained Learning via a Sequential Penalty Approach with Applications in Image Processing",
      "content": "arXiv:2601.16812v1 Announce Type: new  Abstract: In many learning tasks, certain requirements on the processing of individual data samples should arguably be formalized as strict constraints in the underlying optimization problem, rather than by means of arbitrary penalties. We show that, in these scenarios, learning can be carried out exploiting a sequential penalty method that allows to properly deal with constraints. The proposed algorithm is shown to possess convergence guarantees under assumptions that are reasonable in deep learning scenarios. Moreover, the results of experiments on image processing tasks show that the method is indeed viable to be used in practice.",
      "url": "http://arxiv.org/abs/2601.16812",
      "author": "Francesca Lanzillotta, Chiara Albisani, Davide Pucci, Daniele Baracchi, Alessandro Piva, Matteo Lapucci",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Shows sample-wise constraints in learning should be enforced via sequential penalty methods rather than arbitrary penalties. Proves convergence guarantees and demonstrates viability in image processing.",
      "importance_score": 35,
      "reasoning": "Solid optimization contribution for constrained learning; theoretically grounded but incremental.",
      "themes": [
        "Constrained Optimization",
        "Image Processing",
        "Deep Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Shows sample-wise constraints in learning should be enforced via sequential penalty methods rather than arbitrary penalties. Proves convergence guarantees and demonstrates viability in image processing.</p>",
      "content_html": "<p>arXiv:2601.16812v1 Announce Type: new  Abstract: In many learning tasks, certain requirements on the processing of individual data samples should arguably be formalized as strict constraints in the underlying optimization problem, rather than by means of arbitrary penalties. We show that, in these scenarios, learning can be carried out exploiting a sequential penalty method that allows to properly deal with constraints. The proposed algorithm is shown to possess convergence guarantees under assumptions that are reasonable in deep learning scenarios. Moreover, the results of experiments on image processing tasks show that the method is indeed viable to be used in practice.</p>"
    },
    {
      "id": "a5bbe8042f80",
      "title": "Calibrated Probabilistic Interpolation for GEDI Biomass",
      "content": "arXiv:2601.16834v1 Announce Type: new  Abstract: Reliable wall-to-wall biomass mapping from NASA's GEDI mission requires interpolating sparse LiDAR observations across heterogeneous landscapes. While machine learning approaches like Random Forest and XGBoost are standard for this task, they treat spatial predictions of GEDI observations from multispectral or SAR remote sensing data as independent without adapting to the varying difficulty of heterogeneous landscapes. We demonstrate these approaches generally fail to produce calibrated prediction intervals. We identify that this stems from conflating ensemble variance with aleatoric uncertainty and ignoring local spatial context.   To resolve this, we introduce Attentive Neural Processes (ANPs), a probabilistic meta-learning framework that explicitly conditions predictions on local observation sets and geospatial foundation model embeddings. Unlike static ensembles, ANPs learn a flexible spatial covariance function, allowing uncertainty estimates to expand in complex landscapes and contract in homogeneous areas. We validate this approach across five distinct biomes ranging from Tropical Amazonian forests to Boreal and Alpine ecosystems, demonstrating that ANPs achieve competitive accuracy while maintaining near-ideal uncertainty calibration. We demonstrate the operational utility of the method through few-shot adaptation, where the model recovers most of the performance gap in cross-region transfer using minimal local data. This work provides a scalable, theoretically rigorous alternative to ensemble variance for continental scale earth observation.",
      "url": "http://arxiv.org/abs/2601.16834",
      "author": "Robin Young, Srinivasan Keshav",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Uses Attentive Neural Processes for interpolating sparse GEDI LiDAR observations for biomass mapping. Shows RF and XGBoost fail to produce calibrated prediction intervals; ANPs provide calibrated uncertainty.",
      "importance_score": 35,
      "reasoning": "Domain application demonstrating value of probabilistic meta-learning; limited broader methodological contribution.",
      "themes": [
        "Remote Sensing",
        "Uncertainty Quantification",
        "Climate",
        "Neural Processes"
      ],
      "continuation": null,
      "summary_html": "<p>Uses Attentive Neural Processes for interpolating sparse GEDI LiDAR observations for biomass mapping. Shows RF and XGBoost fail to produce calibrated prediction intervals; ANPs provide calibrated uncertainty.</p>",
      "content_html": "<p>arXiv:2601.16834v1 Announce Type: new  Abstract: Reliable wall-to-wall biomass mapping from NASA's GEDI mission requires interpolating sparse LiDAR observations across heterogeneous landscapes. While machine learning approaches like Random Forest and XGBoost are standard for this task, they treat spatial predictions of GEDI observations from multispectral or SAR remote sensing data as independent without adapting to the varying difficulty of heterogeneous landscapes. We demonstrate these approaches generally fail to produce calibrated prediction intervals. We identify that this stems from conflating ensemble variance with aleatoric uncertainty and ignoring local spatial context.   To resolve this, we introduce Attentive Neural Processes (ANPs), a probabilistic meta-learning framework that explicitly conditions predictions on local observation sets and geospatial foundation model embeddings. Unlike static ensembles, ANPs learn a flexible spatial covariance function, allowing uncertainty estimates to expand in complex landscapes and contract in homogeneous areas. We validate this approach across five distinct biomes ranging from Tropical Amazonian forests to Boreal and Alpine ecosystems, demonstrating that ANPs achieve competitive accuracy while maintaining near-ideal uncertainty calibration. We demonstrate the operational utility of the method through few-shot adaptation, where the model recovers most of the performance gap in cross-region transfer using minimal local data. This work provides a scalable, theoretically rigorous alternative to ensemble variance for continental scale earth observation.</p>"
    },
    {
      "id": "082aedf626cc",
      "title": "Latent Diffusion for Internet of Things Attack Data Generation in Intrusion Detection",
      "content": "arXiv:2601.16976v1 Announce Type: new  Abstract: Intrusion Detection Systems (IDSs) are a key component for protecting Internet of Things (IoT) environments. However, in Machine Learning-based (ML-based) IDSs, performance is often degraded by the strong class imbalance between benign and attack traffic. Although data augmentation has been widely explored to mitigate this issue, existing approaches typically rely on simple oversampling techniques or generative models that struggle to simultaneously achieve high sample fidelity, diversity, and computational efficiency. To address these limitations, we propose the use of a Latent Diffusion Model (LDM) for attack data augmentation in IoT intrusion detection and provide a comprehensive comparison against state-of-the-art baselines. Experiments were conducted on three representative IoT attack types, specifically Distributed Denial-of-Service (DDoS), Mirai, and Man-in-the-Middle, evaluating both downstream IDS performance and intrinsic generative quality using distributional, dependency-based, and diversity metrics. Results show that balancing the training data with LDM-generated samples substantially improves IDS performance, achieving F1-scores of up to 0.99 for DDoS and Mirai attacks and consistently outperforming competing methods. Additionally, quantitative and qualitative analyses demonstrate that LDMs effectively preserve feature dependencies while generating diverse samples and reduce sampling time by approximately 25\\% compared to diffusion models operating directly in data space. These findings highlight latent diffusion as an effective and scalable solution for synthetic IoT attack data generation, substantially mitigating the impact of class imbalance in ML-based IDSs for IoT scenarios.",
      "url": "http://arxiv.org/abs/2601.16976",
      "author": "Estela S\\'anchez-Carballo, Francisco M. Melgarejo-Meseguer, Jos\\'e Luis Rojo-\\'Alvarez",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes Latent Diffusion Model for IoT intrusion detection data augmentation. Addresses class imbalance between benign and attack traffic in ML-based intrusion detection systems.",
      "importance_score": 35,
      "reasoning": "Domain application of LDMs; addresses practical problem but limited methodological novelty.",
      "themes": [
        "Intrusion Detection",
        "IoT Security",
        "Data Augmentation",
        "Diffusion Models"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes Latent Diffusion Model for IoT intrusion detection data augmentation. Addresses class imbalance between benign and attack traffic in ML-based intrusion detection systems.</p>",
      "content_html": "<p>arXiv:2601.16976v1 Announce Type: new  Abstract: Intrusion Detection Systems (IDSs) are a key component for protecting Internet of Things (IoT) environments. However, in Machine Learning-based (ML-based) IDSs, performance is often degraded by the strong class imbalance between benign and attack traffic. Although data augmentation has been widely explored to mitigate this issue, existing approaches typically rely on simple oversampling techniques or generative models that struggle to simultaneously achieve high sample fidelity, diversity, and computational efficiency. To address these limitations, we propose the use of a Latent Diffusion Model (LDM) for attack data augmentation in IoT intrusion detection and provide a comprehensive comparison against state-of-the-art baselines. Experiments were conducted on three representative IoT attack types, specifically Distributed Denial-of-Service (DDoS), Mirai, and Man-in-the-Middle, evaluating both downstream IDS performance and intrinsic generative quality using distributional, dependency-based, and diversity metrics. Results show that balancing the training data with LDM-generated samples substantially improves IDS performance, achieving F1-scores of up to 0.99 for DDoS and Mirai attacks and consistently outperforming competing methods. Additionally, quantitative and qualitative analyses demonstrate that LDMs effectively preserve feature dependencies while generating diverse samples and reduce sampling time by approximately 25\\% compared to diffusion models operating directly in data space. These findings highlight latent diffusion as an effective and scalable solution for synthetic IoT attack data generation, substantially mitigating the impact of class imbalance in ML-based IDSs for IoT scenarios.</p>"
    },
    {
      "id": "88d184460f1b",
      "title": "Active learning for photonics",
      "content": "arXiv:2601.16287v1 Announce Type: cross  Abstract: Active learning for photonic crystals explores the integration of analytic approximate Bayesian last layer neural networks (LL-BNNs) with uncertainty-driven sample selection to accelerate photonic band gap prediction. We employ an analytic LL-BNN formulation, corresponding to the infinite Monte Carlo sample limit, to obtain uncertainty estimates that are strongly correlated with the true predictive error on unlabeled candidate structures. These uncertainty scores drive an active learning strategy that prioritizes the most informative simulations during training. Applied to the task of predicting band gap sizes in two-dimensional, two-tone photonic crystals, our approach achieves up to a 2.6x reduction in required training data compared to a random sampling baseline while maintaining predictive accuracy. The efficiency gains arise from concentrating computational resources on high uncertainty regions of the design space rather than sampling uniformly. Given the substantial cost of full band structure simulations, especially in three dimensions, this data efficiency enables rapid and scalable surrogate modeling. Our results suggest that analytic LL-BNN based active learning can substantially accelerate topological optimization and inverse design workflows for photonic crystals, and more broadly, offers a general framework for data efficient regression across scientific machine learning domains.",
      "url": "http://arxiv.org/abs/2601.16287",
      "author": "Ryan Lopez, Charlotte Loh, Rumen Dangovski, Marin Solja\\v{c}i\\'c",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "physics.optics"
      ],
      "summary": "Uses analytic last-layer Bayesian neural networks for active learning in photonic crystal band gap prediction. Achieves 2.6x reduction in required training data through uncertainty-driven sample selection.",
      "importance_score": 35,
      "reasoning": "Domain application demonstrating active learning benefits; limited broader methodological contribution.",
      "themes": [
        "Active Learning",
        "Photonics",
        "Bayesian Neural Networks",
        "Materials Science"
      ],
      "continuation": null,
      "summary_html": "<p>Uses analytic last-layer Bayesian neural networks for active learning in photonic crystal band gap prediction. Achieves 2.6x reduction in required training data through uncertainty-driven sample selection.</p>",
      "content_html": "<p>arXiv:2601.16287v1 Announce Type: cross  Abstract: Active learning for photonic crystals explores the integration of analytic approximate Bayesian last layer neural networks (LL-BNNs) with uncertainty-driven sample selection to accelerate photonic band gap prediction. We employ an analytic LL-BNN formulation, corresponding to the infinite Monte Carlo sample limit, to obtain uncertainty estimates that are strongly correlated with the true predictive error on unlabeled candidate structures. These uncertainty scores drive an active learning strategy that prioritizes the most informative simulations during training. Applied to the task of predicting band gap sizes in two-dimensional, two-tone photonic crystals, our approach achieves up to a 2.6x reduction in required training data compared to a random sampling baseline while maintaining predictive accuracy. The efficiency gains arise from concentrating computational resources on high uncertainty regions of the design space rather than sampling uniformly. Given the substantial cost of full band structure simulations, especially in three dimensions, this data efficiency enables rapid and scalable surrogate modeling. Our results suggest that analytic LL-BNN based active learning can substantially accelerate topological optimization and inverse design workflows for photonic crystals, and more broadly, offers a general framework for data efficient regression across scientific machine learning domains.</p>"
    },
    {
      "id": "8dd39a49da36",
      "title": "Reinforcement Learning-Based Energy-Aware Coverage Path Planning for Precision Agriculture",
      "content": "arXiv:2601.16405v1 Announce Type: cross  Abstract: Coverage Path Planning (CPP) is a fundamental capability for agricultural robots; however, existing solutions often overlook energy constraints, resulting in incomplete operations in large-scale or resource-limited environments. This paper proposes an energy-aware CPP framework grounded in Soft Actor-Critic (SAC) reinforcement learning, designed for grid-based environments with obstacles and charging stations. To enable robust and adaptive decision-making under energy limitations, the framework integrates Convolutional Neural Networks (CNNs) for spatial feature extraction and Long Short-Term Memory (LSTM) networks for temporal dynamics. A dedicated reward function is designed to jointly optimize coverage efficiency, energy consumption, and return-to-base constraints. Experimental results demonstrate that the proposed approach consistently achieves over 90% coverage while ensuring energy safety, outperforming traditional heuristic algorithms such as Rapidly-exploring Random Tree (RRT), Particle Swarm Optimization (PSO), and Ant Colony Optimization (ACO) baselines by 13.4-19.5% in coverage and reducing constraint violations by 59.9-88.3%. These findings validate the proposed SAC-based framework as an effective and scalable solution for energy-constrained CPP in agricultural robotics.",
      "url": "http://arxiv.org/abs/2601.16405",
      "author": "Beining Wu, Zihao Ding, Leo Ostigaard, Jun Huang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes energy-aware coverage path planning for agricultural robots using Soft Actor-Critic RL. Integrates CNNs and LSTMs for spatial-temporal decision-making with energy constraints.",
      "importance_score": 35,
      "reasoning": "Domain application of RL; addresses practical agricultural robotics problem but standard methodology.",
      "themes": [
        "Reinforcement Learning",
        "Agricultural Robotics",
        "Path Planning",
        "Energy Efficiency"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes energy-aware coverage path planning for agricultural robots using Soft Actor-Critic RL. Integrates CNNs and LSTMs for spatial-temporal decision-making with energy constraints.</p>",
      "content_html": "<p>arXiv:2601.16405v1 Announce Type: cross  Abstract: Coverage Path Planning (CPP) is a fundamental capability for agricultural robots; however, existing solutions often overlook energy constraints, resulting in incomplete operations in large-scale or resource-limited environments. This paper proposes an energy-aware CPP framework grounded in Soft Actor-Critic (SAC) reinforcement learning, designed for grid-based environments with obstacles and charging stations. To enable robust and adaptive decision-making under energy limitations, the framework integrates Convolutional Neural Networks (CNNs) for spatial feature extraction and Long Short-Term Memory (LSTM) networks for temporal dynamics. A dedicated reward function is designed to jointly optimize coverage efficiency, energy consumption, and return-to-base constraints. Experimental results demonstrate that the proposed approach consistently achieves over 90% coverage while ensuring energy safety, outperforming traditional heuristic algorithms such as Rapidly-exploring Random Tree (RRT), Particle Swarm Optimization (PSO), and Ant Colony Optimization (ACO) baselines by 13.4-19.5% in coverage and reducing constraint violations by 59.9-88.3%. These findings validate the proposed SAC-based framework as an effective and scalable solution for energy-constrained CPP in agricultural robotics.</p>"
    },
    {
      "id": "8a3d291aee3f",
      "title": "Learning Successive Interference Cancellation for Low-Complexity Soft-Output MIMO Detection",
      "content": "arXiv:2601.16586v1 Announce Type: cross  Abstract: Low-complexity multiple-input multiple-output (MIMO) detection remains a key challenge in modern wireless systems, particularly for 5G reduced capability (RedCap) and internet-of-things (IoT) devices. In this context, the growing interest in deploying machine learning on edge devices must be balanced against stringent constraints on computational complexity and memory while supporting high-order modulation. Beyond accurate hard detection, reliable soft information is equally critical, as modern receivers rely on soft-input channel decoding, imposing additional requirements on the detector design. In this work, we propose recurSIC, a lightweight learning-based MIMO detection framework that is structurally inspired by successive interference cancellation (SIC) and incorporates learned processing stages. It generates reliable soft information via multi-path hypothesis tracking with a tunable complexity parameter while requiring only a single forward pass and a minimal parameter count. Numerical results in realistic wireless scenarios show that recurSIC achieves strong hard- and soft-detection performance at very low complexity, making it well suited for edge-constrained MIMO receivers.",
      "url": "http://arxiv.org/abs/2601.16586",
      "author": "Benedikt Fesl, Fatih Capar",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "eess.SP"
      ],
      "summary": "Proposes recurSIC, a lightweight learning-based MIMO detector inspired by successive interference cancellation. Targets low-complexity requirements for 5G RedCap and IoT devices.",
      "importance_score": 35,
      "reasoning": "Domain-specific application of neural networks to wireless communications; practical but incremental.",
      "themes": [
        "Wireless Communications",
        "MIMO Detection",
        "Neural Networks"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes recurSIC, a lightweight learning-based MIMO detector inspired by successive interference cancellation. Targets low-complexity requirements for 5G RedCap and IoT devices.</p>",
      "content_html": "<p>arXiv:2601.16586v1 Announce Type: cross  Abstract: Low-complexity multiple-input multiple-output (MIMO) detection remains a key challenge in modern wireless systems, particularly for 5G reduced capability (RedCap) and internet-of-things (IoT) devices. In this context, the growing interest in deploying machine learning on edge devices must be balanced against stringent constraints on computational complexity and memory while supporting high-order modulation. Beyond accurate hard detection, reliable soft information is equally critical, as modern receivers rely on soft-input channel decoding, imposing additional requirements on the detector design. In this work, we propose recurSIC, a lightweight learning-based MIMO detection framework that is structurally inspired by successive interference cancellation (SIC) and incorporates learned processing stages. It generates reliable soft information via multi-path hypothesis tracking with a tunable complexity parameter while requiring only a single forward pass and a minimal parameter count. Numerical results in realistic wireless scenarios show that recurSIC achieves strong hard- and soft-detection performance at very low complexity, making it well suited for edge-constrained MIMO receivers.</p>"
    },
    {
      "id": "280baac9c306",
      "title": "Kernel smoothing on manifolds",
      "content": "arXiv:2601.16777v1 Announce Type: cross  Abstract: Under the assumption that data lie on a compact (unknown) manifold without boundary, we derive finite sample bounds for kernel smoothing and its (first and second) derivatives, and we establish asymptotic normality through Berry-Esseen type bounds. Special cases include kernel density estimation, kernel regression and the heat kernel signature. Connections to the graph Laplacian are also discussed.",
      "url": "http://arxiv.org/abs/2601.16777",
      "author": "Eunseong Bae, Wolfgang Polonik",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "math.ST"
      ],
      "summary": "Derives finite sample bounds and asymptotic normality results for kernel smoothing on compact manifolds, with applications to density estimation and regression. Establishes theoretical foundations for manifold-based statistical methods.",
      "importance_score": 35,
      "reasoning": "Theoretical statistics work with limited direct relevance to current ML/AI systems. More foundational mathematics than applied AI.",
      "themes": [
        "Statistical Theory",
        "Manifold Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Derives finite sample bounds and asymptotic normality results for kernel smoothing on compact manifolds, with applications to density estimation and regression. Establishes theoretical foundations for manifold-based statistical methods.</p>",
      "content_html": "<p>arXiv:2601.16777v1 Announce Type: cross  Abstract: Under the assumption that data lie on a compact (unknown) manifold without boundary, we derive finite sample bounds for kernel smoothing and its (first and second) derivatives, and we establish asymptotic normality through Berry-Esseen type bounds. Special cases include kernel density estimation, kernel regression and the heat kernel signature. Connections to the graph Laplacian are also discussed.</p>"
    },
    {
      "id": "60041a299d0e",
      "title": "How Do We Engage with Other Disciplines? A Framework to Study Meaningful Interdisciplinary Discourse in Scholarly Publications",
      "content": "arXiv:2601.17020v1 Announce Type: cross  Abstract: With the rising popularity of interdisciplinary work and increasing institutional incentives in this direction, there is a growing need to understand how resulting publications incorporate ideas from multiple disciplines. Existing computational approaches, such as affiliation diversity, keywords, and citation patterns, do not account for how individual citations are used to advance the citing work. Although, in line with addressing this gap, prior studies have proposed taxonomies to classify citation purpose, these frameworks are not well-suited to interdisciplinary research and do not provide quantitative measures of citation engagement quality. To address these limitations, we propose a framework for the evaluation of citation engagement in interdisciplinary Natural Language Processing (NLP) publications. Our approach introduces a citation purpose taxonomy tailored to interdisciplinary work, supported by an annotation study. We demonstrate the utility of this framework through a thorough analysis of publications at the intersection of NLP and Computational Social Science.",
      "url": "http://arxiv.org/abs/2601.17020",
      "author": "Bagyasree Sudharsan, Alexandria Leto, Maria Leonor Pacheco",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.DL"
      ],
      "summary": "Proposes framework for evaluating citation engagement quality in interdisciplinary research, moving beyond simple affiliation/keyword diversity to assess how citations actually advance the citing work.",
      "importance_score": 35,
      "reasoning": "Meta-research about research practices. Limited direct relevance to AI capabilities or applications.",
      "themes": [
        "Scientometrics",
        "Research Methods"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes framework for evaluating citation engagement quality in interdisciplinary research, moving beyond simple affiliation/keyword diversity to assess how citations actually advance the citing work.</p>",
      "content_html": "<p>arXiv:2601.17020v1 Announce Type: cross  Abstract: With the rising popularity of interdisciplinary work and increasing institutional incentives in this direction, there is a growing need to understand how resulting publications incorporate ideas from multiple disciplines. Existing computational approaches, such as affiliation diversity, keywords, and citation patterns, do not account for how individual citations are used to advance the citing work. Although, in line with addressing this gap, prior studies have proposed taxonomies to classify citation purpose, these frameworks are not well-suited to interdisciplinary research and do not provide quantitative measures of citation engagement quality. To address these limitations, we propose a framework for the evaluation of citation engagement in interdisciplinary Natural Language Processing (NLP) publications. Our approach introduces a citation purpose taxonomy tailored to interdisciplinary work, supported by an annotation study. We demonstrate the utility of this framework through a thorough analysis of publications at the intersection of NLP and Computational Social Science.</p>"
    },
    {
      "id": "870f3518413d",
      "title": "Training-Free Text-to-Image Compositional Food Generation via Prompt Grafting",
      "content": "arXiv:2601.17666v1 Announce Type: new  Abstract: Real-world meal images often contain multiple food items, making reliable compositional food image generation important for applications such as image-based dietary assessment, where multi-food data augmentation is needed, and recipe visualization. However, modern text-to-image diffusion models struggle to generate accurate multi-food images due to object entanglement, where adjacent foods (e.g., rice and soup) fuse together because many foods do not have clear boundaries. To address this challenge, we introduce Prompt Grafting (PG), a training-free framework that combines explicit spatial cues in text with implicit layout guidance during sampling. PG runs a two-stage process where a layout prompt first establishes distinct regions and the target prompt is grafted once layout formation stabilizes. The framework enables food entanglement control: users can specify which food items should remain separated or be intentionally mixed by editing the arrangement of layouts. Across two food datasets, our method significantly improves the presence of target objects and provides qualitative evidence of controllable separation.",
      "url": "http://arxiv.org/abs/2601.17666",
      "author": "Xinyue Pan, Yuhao Chen, Fengqing Zhu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces Prompt Grafting, a training-free framework for compositional food image generation that combines explicit spatial cues in text with implicit layout guidance to address object entanglement in multi-food images.",
      "importance_score": 35,
      "reasoning": "Narrow application domain (food images). Training-free approach is useful but limited broader impact.",
      "themes": [
        "Image Generation",
        "Diffusion Models",
        "Compositional Generation"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces Prompt Grafting, a training-free framework for compositional food image generation that combines explicit spatial cues in text with implicit layout guidance to address object entanglement in multi-food images.</p>",
      "content_html": "<p>arXiv:2601.17666v1 Announce Type: new  Abstract: Real-world meal images often contain multiple food items, making reliable compositional food image generation important for applications such as image-based dietary assessment, where multi-food data augmentation is needed, and recipe visualization. However, modern text-to-image diffusion models struggle to generate accurate multi-food images due to object entanglement, where adjacent foods (e.g., rice and soup) fuse together because many foods do not have clear boundaries. To address this challenge, we introduce Prompt Grafting (PG), a training-free framework that combines explicit spatial cues in text with implicit layout guidance during sampling. PG runs a two-stage process where a layout prompt first establishes distinct regions and the target prompt is grafted once layout formation stabilizes. The framework enables food entanglement control: users can specify which food items should remain separated or be intentionally mixed by editing the arrangement of layouts. Across two food datasets, our method significantly improves the presence of target objects and provides qualitative evidence of controllable separation.</p>"
    },
    {
      "id": "8d90c9cc1a9d",
      "title": "Estimation of geometric transformation matrices using grid-shaped pilot signals",
      "content": "arXiv:2601.18385v1 Announce Type: new  Abstract: Digital watermarking techniques are essential to prevent unauthorized use of images. Since pirated images are often geometrically distorted by operations such as scaling and cropping, accurate synchronization - detecting the embedding position of the watermark - is critical for proper extraction. In particular, cropping changes the origin of the image, making synchronization difficult. However, few existing methods are robust against cropping. To address this issue, we propose a watermarking method that estimates geometric transformations applied to a stego image using a pilot signal, allowing synchronization even after cropping. A grid-shaped pilot signal with distinct horizontal and vertical values is embedded in the image. When the image is transformed, the grid is also distorted. By analyzing this distortion, the transformation matrix can be estimated. Applying the Radon transform to the distorted image allows estimation of the grid angles and intervals. In addition, since the horizontal and vertical grid lines are encoded differently, the grid orientation can be determined, which reduces ambiguity. To validate our method, we performed simulations with anisotropic scaling, rotation, shearing, and cropping. The results show that the proposed method accurately estimates transformation matrices with low error under both single and composite attacks.",
      "url": "http://arxiv.org/abs/2601.18385",
      "author": "Rinka Kawano, Masaki Kawamura",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes watermarking method using grid-shaped pilot signals to estimate geometric transformations including cropping, enabling synchronization even after complex image manipulations.",
      "importance_score": 35,
      "reasoning": "Specialized image processing contribution. Limited ML relevance.",
      "themes": [
        "Digital Watermarking",
        "Image Security"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes watermarking method using grid-shaped pilot signals to estimate geometric transformations including cropping, enabling synchronization even after complex image manipulations.</p>",
      "content_html": "<p>arXiv:2601.18385v1 Announce Type: new  Abstract: Digital watermarking techniques are essential to prevent unauthorized use of images. Since pirated images are often geometrically distorted by operations such as scaling and cropping, accurate synchronization - detecting the embedding position of the watermark - is critical for proper extraction. In particular, cropping changes the origin of the image, making synchronization difficult. However, few existing methods are robust against cropping. To address this issue, we propose a watermarking method that estimates geometric transformations applied to a stego image using a pilot signal, allowing synchronization even after cropping. A grid-shaped pilot signal with distinct horizontal and vertical values is embedded in the image. When the image is transformed, the grid is also distorted. By analyzing this distortion, the transformation matrix can be estimated. Applying the Radon transform to the distorted image allows estimation of the grid angles and intervals. In addition, since the horizontal and vertical grid lines are encoded differently, the grid orientation can be determined, which reduces ambiguity. To validate our method, we performed simulations with anisotropic scaling, rotation, shearing, and cropping. The results show that the proposed method accurately estimates transformation matrices with low error under both single and composite attacks.</p>"
    },
    {
      "id": "af6906f6c15a",
      "title": "In-situ On-demand Digital Image Correlation: A New Data-rich Characterization Paradigm for Deformation and Damage Development in Solids",
      "content": "arXiv:2601.17545v1 Announce Type: cross  Abstract: Digital image correlation (DIC) has become one of the most popular methods for deformation characterization in experimental mechanics. DIC is based on optical images taken during experimentation and post-test image processing. Its advantages include the capability to capture full-field deformation in a non-contact manner, the robustness in characterizing excessive deformation induced by events such as yielding and cracking, and the versatility to integrate optical cameras with a variety of open-source and commercial codes. In this paper, we developed a new paradigm of DIC analysis by integrating camera control into the DIC process flow. The essential idea is to dynamically increase the camera imaging frame rate with excessive deformation or deformation rate, while maintaining a relatively low imaging frame rate with small and slow deformation. We refer to this new DIC paradigm as in-situ on-demand (ISOD) DIC. ISOD DIC enables real-time deformation analysis, visualization, and closed-loop camera control. ISOD DIC has captured approximately 178% more images than conventional DIC for samples undergoing crack growth due to its dynamically adjusted frame rate, with the potential to significantly enhance data richness for damage inspection without consuming excessive storage space and analysis time, thereby benefiting the characterization of intrinsic constitutive behaviors and damage mechanisms",
      "url": "http://arxiv.org/abs/2601.17545",
      "author": "Ravi Venkata Surya Sai Mogilisetti, Partha Pratim Das, Rassel Raihan, Shiyao Lin",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "eess.IV"
      ],
      "summary": "Develops a new paradigm for digital image correlation by integrating camera control into the DIC process flow, dynamically adjusting frame rate based on deformation.",
      "importance_score": 35,
      "reasoning": "Engineering contribution for experimental mechanics, outside core ML research focus.",
      "themes": [
        "Computer Vision",
        "Engineering Applications",
        "Experimental Mechanics"
      ],
      "continuation": null,
      "summary_html": "<p>Develops a new paradigm for digital image correlation by integrating camera control into the DIC process flow, dynamically adjusting frame rate based on deformation.</p>",
      "content_html": "<p>arXiv:2601.17545v1 Announce Type: cross  Abstract: Digital image correlation (DIC) has become one of the most popular methods for deformation characterization in experimental mechanics. DIC is based on optical images taken during experimentation and post-test image processing. Its advantages include the capability to capture full-field deformation in a non-contact manner, the robustness in characterizing excessive deformation induced by events such as yielding and cracking, and the versatility to integrate optical cameras with a variety of open-source and commercial codes. In this paper, we developed a new paradigm of DIC analysis by integrating camera control into the DIC process flow. The essential idea is to dynamically increase the camera imaging frame rate with excessive deformation or deformation rate, while maintaining a relatively low imaging frame rate with small and slow deformation. We refer to this new DIC paradigm as in-situ on-demand (ISOD) DIC. ISOD DIC enables real-time deformation analysis, visualization, and closed-loop camera control. ISOD DIC has captured approximately 178% more images than conventional DIC for samples undergoing crack growth due to its dynamically adjusted frame rate, with the potential to significantly enhance data richness for damage inspection without consuming excessive storage space and analysis time, thereby benefiting the characterization of intrinsic constitutive behaviors and damage mechanisms</p>"
    },
    {
      "id": "cba0e4049c3f",
      "title": "Constrained Multi-Objective Genetic Algorithm Variants for Design and Optimization of Tri-Band Microstrip Patch Antenna loaded CSRR for IoT Applications: A Comparative Case Study",
      "content": "arXiv:2601.17513v1 Announce Type: new  Abstract: This paper presents an automated antenna design and optimization framework employing multi-objective genetic algorithms (MOGAs) to investigate various evolutionary optimization approaches, with a primary emphasis on multi-band frequency optimization. Five MOGA variants were implemented and compared: the Pareto genetic algorithm (PGA), non-dominated sorting genetic algorithm with niching (NSGA-I), non-dominated sorting genetic algorithm with elitism (NSGA-II), non-dominated sorting genetic algorithm using reference points (NSGA-III), and strength Pareto evolutionary algorithm (SPEA). These algorithms are employed to design and optimize microstrip patch antennas loaded with complementary split-ring resonators (CSRRs). A weighted-sum scalarization approach was adopted within a single-objective genetic algorithm framework enhanced with domain-specific constraint handling mechanisms. The optimization addresses the conflicting objectives of minimizing the return loss ($S_{11} < -10$~dB) and achieving multi-band resonance at 2.4~GHz, 3.6~GHz, and 5.2~GHz. The proposed method delivers a superior overall performance by aggregating these objectives into a unified fitness function encompassing $S_{11}$(2.4~GHz), $S_{11}$(3.6~GHz), and $S_{11}$(5.2~GHz). This approach effectively balances all three frequency bands simultaneously, rather than exploring trade-off solutions typical of traditional multi-objective approaches. The antenna was printed on a Rogers RT5880 substrate with a dielectric constant of 2.2 , loss tangent of 0.0009 , and thickness of 1.57~mm . Scalarization approach achieved return loss values of $-21.56$~dB, $-16.60$~dB, and $-27.69$~dB, with corresponding gains of 1.96~dBi, 2.6~dB, and 3.99~dBi at 2.4~GHz, 3.6~GHz, and 5.2~GHz, respectively.",
      "url": "http://arxiv.org/abs/2601.17513",
      "author": "Moahmed Hamza Boulaich, Said Ohamouddou, Mohammed Ali Ennasar, Abdelatif El Afia",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Neural and Evolutionary Computing)",
      "source_type": "arxiv",
      "tags": [
        "cs.NE"
      ],
      "summary": "Compares five multi-objective genetic algorithm variants for automated antenna design with complementary split-ring resonators for IoT applications.",
      "importance_score": 35,
      "reasoning": "Applied evolutionary optimization for specific engineering domain, limited broader impact.",
      "themes": [
        "Evolutionary Algorithms",
        "Antenna Design",
        "Optimization"
      ],
      "continuation": null,
      "summary_html": "<p>Compares five multi-objective genetic algorithm variants for automated antenna design with complementary split-ring resonators for IoT applications.</p>",
      "content_html": "<p>arXiv:2601.17513v1 Announce Type: new  Abstract: This paper presents an automated antenna design and optimization framework employing multi-objective genetic algorithms (MOGAs) to investigate various evolutionary optimization approaches, with a primary emphasis on multi-band frequency optimization. Five MOGA variants were implemented and compared: the Pareto genetic algorithm (PGA), non-dominated sorting genetic algorithm with niching (NSGA-I), non-dominated sorting genetic algorithm with elitism (NSGA-II), non-dominated sorting genetic algorithm using reference points (NSGA-III), and strength Pareto evolutionary algorithm (SPEA). These algorithms are employed to design and optimize microstrip patch antennas loaded with complementary split-ring resonators (CSRRs). A weighted-sum scalarization approach was adopted within a single-objective genetic algorithm framework enhanced with domain-specific constraint handling mechanisms. The optimization addresses the conflicting objectives of minimizing the return loss ($S_{11} &lt; -10$~dB) and achieving multi-band resonance at 2.4~GHz, 3.6~GHz, and 5.2~GHz. The proposed method delivers a superior overall performance by aggregating these objectives into a unified fitness function encompassing $S_{11}$(2.4~GHz), $S_{11}$(3.6~GHz), and $S_{11}$(5.2~GHz). This approach effectively balances all three frequency bands simultaneously, rather than exploring trade-off solutions typical of traditional multi-objective approaches. The antenna was printed on a Rogers RT5880 substrate with a dielectric constant of 2.2 , loss tangent of 0.0009 , and thickness of 1.57~mm . Scalarization approach achieved return loss values of $-21.56$~dB, $-16.60$~dB, and $-27.69$~dB, with corresponding gains of 1.96~dBi, 2.6~dB, and 3.99~dBi at 2.4~GHz, 3.6~GHz, and 5.2~GHz, respectively.</p>"
    },
    {
      "id": "298c31cb7824",
      "title": "Towards Generalisable Imitation Learning Through Conditioned Transition Estimation and Online Behaviour Alignment",
      "content": "arXiv:2601.17563v1 Announce Type: cross  Abstract: State-of-the-art imitation learning from observation methods (ILfO) have recently made significant progress, but they still have some limitations: they need action-based supervised optimisation, assume that states have a single optimal action, and tend to apply teacher actions without full consideration of the actual environment state. While the truth may be out there in observed trajectories, existing methods struggle to extract it without supervision. In this work, we propose Unsupervised Imitation Learning from Observation (UfO) that addresses all of these limitations. UfO learns a policy through a two-stage process, in which the agent first obtains an approximation of the teacher's true actions in the observed state transitions, and then refines the learned policy further by adjusting agent trajectories to closely align them with the teacher's. Experiments we conducted in five widely used environments show that UfO not only outperforms the teacher and all other ILfO methods but also displays the smallest standard deviation. This reduction in standard deviation indicates better generalisation in unseen scenarios.",
      "url": "http://arxiv.org/abs/2601.17563",
      "author": "Nathan Gavenski, Matteo Leonetti, Odinaldo Rodrigues",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "UfO proposes unsupervised imitation learning from observation through two-stage process: estimating teacher actions then online alignment.",
      "importance_score": 34,
      "reasoning": "Novel unsupervised approach to ILfO. Addresses action supervision limitation.",
      "themes": [
        "Imitation Learning",
        "Reinforcement Learning",
        "Unsupervised Learning"
      ],
      "continuation": null,
      "summary_html": "<p>UfO proposes unsupervised imitation learning from observation through two-stage process: estimating teacher actions then online alignment.</p>",
      "content_html": "<p>arXiv:2601.17563v1 Announce Type: cross  Abstract: State-of-the-art imitation learning from observation methods (ILfO) have recently made significant progress, but they still have some limitations: they need action-based supervised optimisation, assume that states have a single optimal action, and tend to apply teacher actions without full consideration of the actual environment state. While the truth may be out there in observed trajectories, existing methods struggle to extract it without supervision. In this work, we propose Unsupervised Imitation Learning from Observation (UfO) that addresses all of these limitations. UfO learns a policy through a two-stage process, in which the agent first obtains an approximation of the teacher's true actions in the observed state transitions, and then refines the learned policy further by adjusting agent trajectories to closely align them with the teacher's. Experiments we conducted in five widely used environments show that UfO not only outperforms the teacher and all other ILfO methods but also displays the smallest standard deviation. This reduction in standard deviation indicates better generalisation in unseen scenarios.</p>"
    },
    {
      "id": "0303e28890e6",
      "title": "Real-Time Trend Prediction via Continually-Aligned LLM Query Generation",
      "content": "arXiv:2601.17567v1 Announce Type: cross  Abstract: Trending news detection in low-traffic search environments faces a fundamental cold-start problem, where a lack of query volume prevents systems from identifying emerging or long-tail trends. Existing methods relying on keyword frequency or query spikes are inherently slow and ineffective in these sparse settings, lagging behind real-world shifts in attention. We introduce RTTP, a novel Real-Time Trending Prediction framework that generates search queries directly from news content instead of waiting for users to issue them. RTTP leverages a continual learning LLM (CL-LLM) that converts posts into search-style queries and scores them using engagement strength + creator authority, enabling early trend surfacing before search volume forms. To ensure adaptation without degrading reasoning, we propose Mix-Policy DPO, a new preference-based continual learning approach that combines on-policy stability with off-policy novelty to mitigate catastrophic forgetting during model upgrades. Deployed at production scale on Facebook and Meta AI products, RTTP delivers +91.4% improvement in tail-trend detection precision@500 and +19% query generation accuracy over industry baselines, while sustaining stable performance after multi-week online training. This work demonstrates that LLM-generated synthetic search signals, when aligned and continually updated, unlock timely trend understanding in low-traffic search environments.",
      "url": "http://arxiv.org/abs/2601.17567",
      "author": "Zijing Hui, Wenhan Lyu, Shusen Wang, Li Chen, Chu Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.IR"
      ],
      "summary": "RTTP addresses cold-start in trending detection by generating search queries from news content using continually-learning LLM.",
      "importance_score": 33,
      "reasoning": "Practical solution for trend detection. Continual learning integration.",
      "themes": [
        "Trend Detection",
        "Continual Learning",
        "Information Retrieval"
      ],
      "continuation": null,
      "summary_html": "<p>RTTP addresses cold-start in trending detection by generating search queries from news content using continually-learning LLM.</p>",
      "content_html": "<p>arXiv:2601.17567v1 Announce Type: cross  Abstract: Trending news detection in low-traffic search environments faces a fundamental cold-start problem, where a lack of query volume prevents systems from identifying emerging or long-tail trends. Existing methods relying on keyword frequency or query spikes are inherently slow and ineffective in these sparse settings, lagging behind real-world shifts in attention. We introduce RTTP, a novel Real-Time Trending Prediction framework that generates search queries directly from news content instead of waiting for users to issue them. RTTP leverages a continual learning LLM (CL-LLM) that converts posts into search-style queries and scores them using engagement strength + creator authority, enabling early trend surfacing before search volume forms. To ensure adaptation without degrading reasoning, we propose Mix-Policy DPO, a new preference-based continual learning approach that combines on-policy stability with off-policy novelty to mitigate catastrophic forgetting during model upgrades. Deployed at production scale on Facebook and Meta AI products, RTTP delivers +91.4% improvement in tail-trend detection precision@500 and +19% query generation accuracy over industry baselines, while sustaining stable performance after multi-week online training. This work demonstrates that LLM-generated synthetic search signals, when aligned and continually updated, unlock timely trend understanding in low-traffic search environments.</p>"
    },
    {
      "id": "a423723ae095",
      "title": "FP-THD: Full page transcription of historical documents",
      "content": "arXiv:2601.17040v1 Announce Type: cross  Abstract: The transcription of historical documents written in Latin in XV and XVI centuries has special challenges as it must maintain the characters and special symbols that have distinct meanings to ensure that historical texts retain their original style and significance. This work proposes a pipeline for the transcription of historical documents preserving these special features. We propose to extend an existing text line recognition method with a layout analysis model. We analyze historical text images using a layout analysis model to extract text lines, which are then processed by an OCR model to generate a fully digitized page. We showed that our pipeline facilitates the processing of the page and produces an efficient result. We evaluated our approach on multiple datasets and demonstrate that the masked autoencoder effectively processes different types of text, including handwritten, printed and multi-language.",
      "url": "http://arxiv.org/abs/2601.17040",
      "author": "H Neji, J Nogueras-Iso, J Lacasta, M\\'A Latre, FJ Garc\\'ia-Marco",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes pipeline for transcribing 15th-16th century Latin historical documents, extending text line recognition with layout analysis to preserve special characters and symbols.",
      "importance_score": 32,
      "reasoning": "Applied OCR research for historical documents. Incremental improvements to existing methods for niche domain.",
      "themes": [
        "Document Analysis",
        "OCR"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes pipeline for transcribing 15th-16th century Latin historical documents, extending text line recognition with layout analysis to preserve special characters and symbols.</p>",
      "content_html": "<p>arXiv:2601.17040v1 Announce Type: cross  Abstract: The transcription of historical documents written in Latin in XV and XVI centuries has special challenges as it must maintain the characters and special symbols that have distinct meanings to ensure that historical texts retain their original style and significance. This work proposes a pipeline for the transcription of historical documents preserving these special features. We propose to extend an existing text line recognition method with a layout analysis model. We analyze historical text images using a layout analysis model to extract text lines, which are then processed by an OCR model to generate a fully digitized page. We showed that our pipeline facilitates the processing of the page and produces an efficient result. We evaluated our approach on multiple datasets and demonstrate that the masked autoencoder effectively processes different types of text, including handwritten, printed and multi-language.</p>"
    },
    {
      "id": "993885a431c2",
      "title": "\"Rebuilding\" Statistics in the Age of AI: A Town Hall Discussion on Culture, Infrastructure, and Training",
      "content": "arXiv:2601.17510v1 Announce Type: cross  Abstract: This article presents the full, original record of the 2024 Joint Statistical Meetings (JSM) town hall, \"Statistics in the Age of AI,\" which convened leading statisticians to discuss how the field is evolving in response to advances in artificial intelligence, foundation models, large-scale empirical modeling, and data-intensive infrastructures. The town hall was structured around open panel discussion and extensive audience Q&amp;A, with the aim of eliciting candid, experience-driven perspectives rather than formal presentations or prepared statements. This document preserves the extended exchanges among panelists and audience members, with minimal editorial intervention, and organizes the conversation around five recurring questions concerning disciplinary culture and practices, data curation and \"data work,\" engagement with modern empirical modeling, training for large-scale AI applications, and partnerships with key AI stakeholders. By providing an archival record of this discussion, the preprint aims to support transparency, community reflection, and ongoing dialogue about the evolving role of statistics in the data- and AI-centric future.",
      "url": "http://arxiv.org/abs/2601.17510",
      "author": "David L. Donoho, Jian Kang, Xihong Lin, Bhramar Mukherjee, Dan Nettleton, Rebecca Nugent, Abel Rodriguez, Eric P. Xing, Tian Zheng, Hongtu Zhu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "stat.ML"
      ],
      "summary": "Records JSM 2024 town hall discussion on statistics in AI age, covering culture, infrastructure, and training perspectives.",
      "importance_score": 32,
      "reasoning": "Valuable perspective piece on statistics-AI intersection. Community discussion.",
      "themes": [
        "Statistics",
        "AI Education",
        "Community Perspectives"
      ],
      "continuation": null,
      "summary_html": "<p>Records JSM 2024 town hall discussion on statistics in AI age, covering culture, infrastructure, and training perspectives.</p>",
      "content_html": "<p>arXiv:2601.17510v1 Announce Type: cross  Abstract: This article presents the full, original record of the 2024 Joint Statistical Meetings (JSM) town hall, \"Statistics in the Age of AI,\" which convened leading statisticians to discuss how the field is evolving in response to advances in artificial intelligence, foundation models, large-scale empirical modeling, and data-intensive infrastructures. The town hall was structured around open panel discussion and extensive audience Q&amp;A, with the aim of eliciting candid, experience-driven perspectives rather than formal presentations or prepared statements. This document preserves the extended exchanges among panelists and audience members, with minimal editorial intervention, and organizes the conversation around five recurring questions concerning disciplinary culture and practices, data curation and \"data work,\" engagement with modern empirical modeling, training for large-scale AI applications, and partnerships with key AI stakeholders. By providing an archival record of this discussion, the preprint aims to support transparency, community reflection, and ongoing dialogue about the evolving role of statistics in the data- and AI-centric future.</p>"
    },
    {
      "id": "888c5236c999",
      "title": "Window Size Versus Accuracy Experiments in Voice Activity Detectors",
      "content": "arXiv:2601.17270v1 Announce Type: cross  Abstract: Voice activity detection (VAD) plays a vital role in enabling applications such as speech recognition. We analyze the impact of window size on the accuracy of three VAD algorithms: Silero, WebRTC, and Root Mean Square (RMS) across a set of diverse real-world digital audio streams. We additionally explore the use of hysteresis on top of each VAD output. Our results offer practical references for optimizing VAD systems. Silero significantly outperforms WebRTC and RMS, and hysteresis provides a benefit for WebRTC.",
      "url": "http://arxiv.org/abs/2601.17270",
      "author": "Max McKinnon, Samir Khaki, Chandan KA Reddy, William Huang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computation and Language)",
      "source_type": "arxiv",
      "tags": [
        "cs.SD"
      ],
      "summary": "Analyzes impact of window size on voice activity detection accuracy across three algorithms (Silero, WebRTC, RMS), with Silero significantly outperforming others and hysteresis providing benefits for WebRTC.",
      "importance_score": 32,
      "reasoning": "Incremental applied work with limited novelty. Useful practical reference but no significant methodological contributions.",
      "themes": [
        "Speech Processing",
        "Voice Activity Detection"
      ],
      "continuation": null,
      "summary_html": "<p>Analyzes impact of window size on voice activity detection accuracy across three algorithms (Silero, WebRTC, RMS), with Silero significantly outperforming others and hysteresis providing benefits for WebRTC.</p>",
      "content_html": "<p>arXiv:2601.17270v1 Announce Type: cross  Abstract: Voice activity detection (VAD) plays a vital role in enabling applications such as speech recognition. We analyze the impact of window size on the accuracy of three VAD algorithms: Silero, WebRTC, and Root Mean Square (RMS) across a set of diverse real-world digital audio streams. We additionally explore the use of hysteresis on top of each VAD output. Our results offer practical references for optimizing VAD systems. Silero significantly outperforms WebRTC and RMS, and hysteresis provides a benefit for WebRTC.</p>"
    },
    {
      "id": "85d5e0b1d7ea",
      "title": "Facial Emotion Recognition on FER-2013 using an EfficientNetB2-Based Approach",
      "content": "arXiv:2601.18228v1 Announce Type: new  Abstract: Detection of human emotions based on facial images in real-world scenarios is a difficult task due to low image quality, variations in lighting, pose changes, background distractions, small inter-class variations, noisy crowd-sourced labels, and severe class imbalance, as observed in the FER-2013 dataset of 48x48 grayscale images. Although recent approaches using large CNNs such as VGG and ResNet achieve reasonable accuracy, they are computationally expensive and memory-intensive, limiting their practicality for real-time applications. We address these challenges using a lightweight and efficient facial emotion recognition pipeline based on EfficientNetB2, trained using a two-stage warm-up and fine-tuning strategy. The model is enhanced with AdamW optimization, decoupled weight decay, label smoothing (epsilon = 0.06) to reduce annotation noise, and clipped class weights to mitigate class imbalance, along with dropout, mixed-precision training, and extensive real-time data augmentation. The model is trained using a stratified 87.5%/12.5% train-validation split while keeping the official test set intact, achieving a test accuracy of 68.78% with nearly ten times fewer parameters than VGG16-based baselines. Experimental results, including per-class metrics and learning dynamics, demonstrate stable training and strong generalization, making the proposed approach suitable for real-time and edge-based applications.",
      "url": "http://arxiv.org/abs/2601.18228",
      "author": "Sahil Naik, Soham Bagayatkar, Pavankumar Singh",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents lightweight facial emotion recognition pipeline using EfficientNetB2 with two-stage training strategy, enhanced with attention mechanisms and Mixup augmentation for FER-2013.",
      "importance_score": 32,
      "reasoning": "Standard application of existing techniques to well-studied benchmark. Limited novelty.",
      "themes": [
        "Facial Recognition",
        "Emotion Detection",
        "Lightweight Models"
      ],
      "continuation": null,
      "summary_html": "<p>Presents lightweight facial emotion recognition pipeline using EfficientNetB2 with two-stage training strategy, enhanced with attention mechanisms and Mixup augmentation for FER-2013.</p>",
      "content_html": "<p>arXiv:2601.18228v1 Announce Type: new  Abstract: Detection of human emotions based on facial images in real-world scenarios is a difficult task due to low image quality, variations in lighting, pose changes, background distractions, small inter-class variations, noisy crowd-sourced labels, and severe class imbalance, as observed in the FER-2013 dataset of 48x48 grayscale images. Although recent approaches using large CNNs such as VGG and ResNet achieve reasonable accuracy, they are computationally expensive and memory-intensive, limiting their practicality for real-time applications. We address these challenges using a lightweight and efficient facial emotion recognition pipeline based on EfficientNetB2, trained using a two-stage warm-up and fine-tuning strategy. The model is enhanced with AdamW optimization, decoupled weight decay, label smoothing (epsilon = 0.06) to reduce annotation noise, and clipped class weights to mitigate class imbalance, along with dropout, mixed-precision training, and extensive real-time data augmentation. The model is trained using a stratified 87.5%/12.5% train-validation split while keeping the official test set intact, achieving a test accuracy of 68.78% with nearly ten times fewer parameters than VGG16-based baselines. Experimental results, including per-class metrics and learning dynamics, demonstrate stable training and strong generalization, making the proposed approach suitable for real-time and edge-based applications.</p>"
    },
    {
      "id": "8e5edeb1bf65",
      "title": "What actually matters in neurotech startups (and what doesn't)",
      "content": "Note: Extraordinarily grateful to Milan Cvitkovic, Sumner Norman, Ben Woodington, and Adam Marblestone for all the helpful conversations, comments, and critiques on drafts of this essay.IntroductionThe whole field of neurotech is nauseatingly complicated. This seems to be because you need to understand at least five fields at once to actually grasp what is/isnt possible: electrical engineering, mechanical engineering, biology, neuroscience, and computer science. And, if youre really trying to cover all the bases: surgery, ultrasound and optical physics as well. And Ive met relatively few people in my life who can operate at the intersection of three fields, much less eight! As a result, Ive stayed away from the entire subject, hoping that Id eventually learn whats going on via osmosis.This has not worked. Each time a new neurotech startup comes out, Id optimistically chat about them with some friend in the field and they inevitably wave it off for some bizarre reason that I would never, ever understand. But the more questions I asked, the more confused I would get. And so, at a certain point, Id just start politely nodding to their Does that make sense? questions.I have, for months, been wanting to write an article to codify the exact mental steps these people go through when evaluating these companies. After talking to many experts, I have decided that this is a mostly impossible task, but that there are at least a few, small, legible fractions of their decision-making framework that are amenable to being written out. This essay is the end result.My hope is that this helps set up the mental scaffolding necessary to triage which approaches are tractable, and which ones are more speculative. Obviously, take all of my writing with a grain of salt; anything that touches the brain is going to be complicated, and while I will try to offer as much nuance as possible, I cannot promise I will offer as much as an Actual Expert can. Grab coffee with your local neuro...",
      "url": "https://www.lesswrong.com/posts/Bn8CNvEHbKg2KPkvD/what-actually-matters-in-neurotech-startups-and-what-doesn-t",
      "author": "Abhishaike Mahajan",
      "published": "2026-01-26T10:19:36.352000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Comprehensive overview of neurotech startup landscape, explaining what technical factors actually matter for success across electrical engineering, mechanical engineering, biology, and neuroscience dimensions.",
      "importance_score": 32,
      "reasoning": "Well-researched domain overview but tangential to AI/ML research. Relevant to brain-computer interfaces but not directly to language models or AI safety.",
      "themes": [
        "Neurotechnology",
        "Brain-Computer Interfaces",
        "Startups"
      ],
      "continuation": null,
      "summary_html": "<p>Comprehensive overview of neurotech startup landscape, explaining what technical factors actually matter for success across electrical engineering, mechanical engineering, biology, and neuroscience dimensions.</p>",
      "content_html": "<p>Note: Extraordinarily grateful to Milan Cvitkovic, Sumner Norman, Ben Woodington, and Adam Marblestone for all the helpful conversations, comments, and critiques on drafts of this essay.IntroductionThe whole field of neurotech is nauseatingly complicated. This seems to be because you need to understand at least five fields at once to actually grasp what is/isnt possible: electrical engineering, mechanical engineering, biology, neuroscience, and computer science. And, if youre really trying to cover all the bases: surgery, ultrasound and optical physics as well. And Ive met relatively few people in my life who can operate at the intersection of three fields, much less eight! As a result, Ive stayed away from the entire subject, hoping that Id eventually learn whats going on via osmosis.This has not worked. Each time a new neurotech startup comes out, Id optimistically chat about them with some friend in the field and they inevitably wave it off for some bizarre reason that I would never, ever understand. But the more questions I asked, the more confused I would get. And so, at a certain point, Id just start politely nodding to their Does that make sense? questions.I have, for months, been wanting to write an article to codify the exact mental steps these people go through when evaluating these companies. After talking to many experts, I have decided that this is a mostly impossible task, but that there are at least a few, small, legible fractions of their decision-making framework that are amenable to being written out. This essay is the end result.My hope is that this helps set up the mental scaffolding necessary to triage which approaches are tractable, and which ones are more speculative. Obviously, take all of my writing with a grain of salt; anything that touches the brain is going to be complicated, and while I will try to offer as much nuance as possible, I cannot promise I will offer as much as an Actual Expert can. Grab coffee with your local neuro...</p>"
    },
    {
      "id": "434045b8efbb",
      "title": "Athanor: Authoring Action Modification-based Interactions on Static Visualizations via Natural Language",
      "content": "arXiv:2601.17736v1 Announce Type: cross  Abstract: Interactivity is crucial for effective data visualizations. However, it is often challenging to implement interactions for existing static visualizations, since the underlying code and data for existing static visualizations are often not available, and it also takes significant time and effort to enable interactions for them even if the original code and data are available. To fill this gap, we propose Athanor, a novel approach to transform existing static visualizations into interactive ones using multimodal large language models (MLLMs) and natural language instructions. Our approach introduces three key innovations: (1) an action-modification interaction design space that maps visualization interactions into user actions and corresponding adjustments, (2) a multi-agent requirement analyzer that translates natural language instructions into an actionable operational space, and (3) a visualization abstraction transformer that converts static visualizations into flexible and interactive representations regardless of their underlying implementation. Athanor allows users to effortlessly author interactions through natural language instructions, eliminating the need for programming. We conducted two case studies and in-depth interviews with target users to evaluate our approach. The results demonstrate the effectiveness and usability of our approach in allowing users to conveniently enable flexible interactions for static visualizations.",
      "url": "http://arxiv.org/abs/2601.17736",
      "author": "Can Liu, Jaeuk Lee, Tianhe Chen, Zhibang Jiang, Xiaolin Wen, Yong Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.HC"
      ],
      "summary": "Athanor uses MLLMs to transform static visualizations into interactive ones via natural language, with action-modification interaction design space.",
      "importance_score": 31,
      "reasoning": "Novel application for visualization enhancement. MLLM-based interaction design.",
      "themes": [
        "Visualization",
        "Human-Computer Interaction",
        "MLLMs"
      ],
      "continuation": null,
      "summary_html": "<p>Athanor uses MLLMs to transform static visualizations into interactive ones via natural language, with action-modification interaction design space.</p>",
      "content_html": "<p>arXiv:2601.17736v1 Announce Type: cross  Abstract: Interactivity is crucial for effective data visualizations. However, it is often challenging to implement interactions for existing static visualizations, since the underlying code and data for existing static visualizations are often not available, and it also takes significant time and effort to enable interactions for them even if the original code and data are available. To fill this gap, we propose Athanor, a novel approach to transform existing static visualizations into interactive ones using multimodal large language models (MLLMs) and natural language instructions. Our approach introduces three key innovations: (1) an action-modification interaction design space that maps visualization interactions into user actions and corresponding adjustments, (2) a multi-agent requirement analyzer that translates natural language instructions into an actionable operational space, and (3) a visualization abstraction transformer that converts static visualizations into flexible and interactive representations regardless of their underlying implementation. Athanor allows users to effortlessly author interactions through natural language instructions, eliminating the need for programming. We conducted two case studies and in-depth interviews with target users to evaluate our approach. The results demonstrate the effectiveness and usability of our approach in allowing users to conveniently enable flexible interactions for static visualizations.</p>"
    },
    {
      "id": "d5cf63d0f6c5",
      "title": "Ensuring Computer Science Learning in the AI Era: Open Generative AI Policies and Assignment-Driven Written Quizzes",
      "content": "arXiv:2601.17024v1 Announce Type: cross  Abstract: The widespread availability of generative artificial intelligence (GenAI) has created a pressing challenge in computer science (CS) education: how to incorporate powerful AI tools into programming coursework without undermining student learning through cognitive offloading. This paper presents an assessment model that permits the use of generative AI for take-home programming assignments while enforcing individual mastery through immediate, assignment-driven written quizzes. To promote authentic learning, these in-class, closed-book assessments are weighted more heavily than the assignments themselves and are specifically designed to verify the student's comprehension of the algorithms, structure, and implementation details of their submitted code. Preliminary empirical data were collected from an upper-level computer science course to examine the relationship between self-reported GenAI usage and performance on AI-free quizzes, exams, and final course grades. Statistical analyses revealed no meaningful linear correlation between GenAI usage levels and assessment outcomes, with Pearson correlation coefficients consistently near zero. These preliminary results suggest that allowing GenAI for programming assignments does not diminish students' mastery of course concepts when learning is verified through targeted, assignment-driven quizzes. Although limited by a small sample size, this study provides preliminary evidence that the risks of cognitive offloading can be mitigated by allowing AI-assisted programming practice while verifying understanding through assignment-driven, AI-free quizzes. The findings support the responsible adoption of open GenAI policies in upper-level CS courses, when paired with rigorous, independent assessment mechanisms.",
      "url": "http://arxiv.org/abs/2601.17024",
      "author": "Chan-Jin Chung",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Presents an assessment model for CS education that permits GenAI use for assignments while enforcing mastery through immediate, assignment-driven in-class written quizzes.",
      "importance_score": 30,
      "reasoning": "Educational policy proposal rather than technical AI research. Addresses practical concerns about AI in education.",
      "themes": [
        "Education AI",
        "AI Policy"
      ],
      "continuation": null,
      "summary_html": "<p>Presents an assessment model for CS education that permits GenAI use for assignments while enforcing mastery through immediate, assignment-driven in-class written quizzes.</p>",
      "content_html": "<p>arXiv:2601.17024v1 Announce Type: cross  Abstract: The widespread availability of generative artificial intelligence (GenAI) has created a pressing challenge in computer science (CS) education: how to incorporate powerful AI tools into programming coursework without undermining student learning through cognitive offloading. This paper presents an assessment model that permits the use of generative AI for take-home programming assignments while enforcing individual mastery through immediate, assignment-driven written quizzes. To promote authentic learning, these in-class, closed-book assessments are weighted more heavily than the assignments themselves and are specifically designed to verify the student's comprehension of the algorithms, structure, and implementation details of their submitted code. Preliminary empirical data were collected from an upper-level computer science course to examine the relationship between self-reported GenAI usage and performance on AI-free quizzes, exams, and final course grades. Statistical analyses revealed no meaningful linear correlation between GenAI usage levels and assessment outcomes, with Pearson correlation coefficients consistently near zero. These preliminary results suggest that allowing GenAI for programming assignments does not diminish students' mastery of course concepts when learning is verified through targeted, assignment-driven quizzes. Although limited by a small sample size, this study provides preliminary evidence that the risks of cognitive offloading can be mitigated by allowing AI-assisted programming practice while verifying understanding through assignment-driven, AI-free quizzes. The findings support the responsible adoption of open GenAI policies in upper-level CS courses, when paired with rigorous, independent assessment mechanisms.</p>"
    },
    {
      "id": "40d956f63465",
      "title": "A Computer Vision Pipeline for Iterative Bullet Hole Tracking in Rifle Zeroing",
      "content": "arXiv:2601.17062v1 Announce Type: cross  Abstract: Adjusting rifle sights, a process commonly called \"zeroing,\" requires shooters to identify and differentiate bullet holes from multiple firing iterations. Traditionally, this process demands physical inspection, introducing delays due to range safety protocols and increasing the risk of human error. We present an end-to-end computer vision system for automated bullet hole detection and iteration-based tracking directly from images taken at the firing line. Our approach combines YOLOv8 for accurate small-object detection with Intersection over Union (IoU) analysis to differentiate bullet holes across sequential images. To address the scarcity of labeled sequential data, we propose a novel data augmentation technique that removes rather than adds objects to simulate realistic firing sequences. Additionally, we introduce a preprocessing pipeline that standardizes target orientation using ORB-based perspective correction, improving model accuracy. Our system achieves 97.0% mean average precision on bullet hole detection and 88.8% accuracy in assigning bullet holes to the correct firing iteration. While designed for rifle zeroing, this framework offers broader applicability in domains requiring the temporal differentiation of visually similar objects.",
      "url": "http://arxiv.org/abs/2601.17062",
      "author": "Robert M. Belcher, Brendan C. Degryse, Leonard R. Kosta, Christopher J. Lowrance",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "End-to-end computer vision system for bullet hole detection and tracking using YOLOv8 with IoU analysis. Proposes novel data augmentation that removes rather than adds bullet holes.",
      "importance_score": 30,
      "reasoning": "Narrow application domain with standard object detection approach. Novel augmentation idea but limited broader impact.",
      "themes": [
        "Object Detection",
        "Computer Vision"
      ],
      "continuation": null,
      "summary_html": "<p>End-to-end computer vision system for bullet hole detection and tracking using YOLOv8 with IoU analysis. Proposes novel data augmentation that removes rather than adds bullet holes.</p>",
      "content_html": "<p>arXiv:2601.17062v1 Announce Type: cross  Abstract: Adjusting rifle sights, a process commonly called \"zeroing,\" requires shooters to identify and differentiate bullet holes from multiple firing iterations. Traditionally, this process demands physical inspection, introducing delays due to range safety protocols and increasing the risk of human error. We present an end-to-end computer vision system for automated bullet hole detection and iteration-based tracking directly from images taken at the firing line. Our approach combines YOLOv8 for accurate small-object detection with Intersection over Union (IoU) analysis to differentiate bullet holes across sequential images. To address the scarcity of labeled sequential data, we propose a novel data augmentation technique that removes rather than adds objects to simulate realistic firing sequences. Additionally, we introduce a preprocessing pipeline that standardizes target orientation using ORB-based perspective correction, improving model accuracy. Our system achieves 97.0% mean average precision on bullet hole detection and 88.8% accuracy in assigning bullet holes to the correct firing iteration. While designed for rifle zeroing, this framework offers broader applicability in domains requiring the temporal differentiation of visually similar objects.</p>"
    },
    {
      "id": "3abd7f8e67ef",
      "title": "Evaluating Semantic and Syntactic Understanding in Large Language Models for Payroll Systems",
      "content": "arXiv:2601.18012v1 Announce Type: cross  Abstract: Large language models are now used daily for writing, search, and analysis, and their natural language understanding continues to improve. However, they remain unreliable on exact numerical calculation and on producing outputs that are straightforward to audit. We study synthetic payroll system as a focused, high-stakes example and evaluate whether models can understand a payroll schema, apply rules in the right order, and deliver cent-accurate results. Our experiments span a tiered dataset from basic to complex cases, a spectrum of prompts from minimal baselines to schema-guided and reasoning variants, and multiple model families including GPT, Claude, Perplexity, Grok and Gemini. Results indicate clear regimes where careful prompting is sufficient and regimes where explicit computation is required. The work offers a compact, reproducible framework and practical guidance for deploying LLMs in settings that demand both accuracy and assurance.",
      "url": "http://arxiv.org/abs/2601.18012",
      "author": "Hendrika Maclean, Mert Can Cakmak, Muzakkiruddin Ahmed Mohammed, Shames Al Mandalawi, John Talburt",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Evaluates LLMs on synthetic payroll system for semantic/syntactic understanding, finding clear regimes where prompting helps but numerical accuracy remains challenging.",
      "importance_score": 30,
      "reasoning": "Systematic evaluation of LLM numerical reasoning. Practical domain focus.",
      "themes": [
        "LLM Evaluation",
        "Numerical Reasoning",
        "Enterprise Applications"
      ],
      "continuation": null,
      "summary_html": "<p>Evaluates LLMs on synthetic payroll system for semantic/syntactic understanding, finding clear regimes where prompting helps but numerical accuracy remains challenging.</p>",
      "content_html": "<p>arXiv:2601.18012v1 Announce Type: cross  Abstract: Large language models are now used daily for writing, search, and analysis, and their natural language understanding continues to improve. However, they remain unreliable on exact numerical calculation and on producing outputs that are straightforward to audit. We study synthetic payroll system as a focused, high-stakes example and evaluate whether models can understand a payroll schema, apply rules in the right order, and deliver cent-accurate results. Our experiments span a tiered dataset from basic to complex cases, a spectrum of prompts from minimal baselines to schema-guided and reasoning variants, and multiple model families including GPT, Claude, Perplexity, Grok and Gemini. Results indicate clear regimes where careful prompting is sufficient and regimes where explicit computation is required. The work offers a compact, reproducible framework and practical guidance for deploying LLMs in settings that demand both accuracy and assurance.</p>"
    },
    {
      "id": "07f17b640619",
      "title": "A Refinement of Vapnik--Chervonenkis' Theorem",
      "content": "arXiv:2601.16411v1 Announce Type: new  Abstract: Vapnik--Chervonenkis' theorem is a seminal result in machine learning. It establishes sufficient conditions for empirical probabilities to converge to theoretical probabilities, uniformly over families of events. It also provides an estimate for the rate of such uniform convergence.   We revisit the probabilistic component of the classical argument. Instead of applying Hoeffding's inequality at the final step, we use a normal approximation with explicit Berry--Esseen error control. This yields a moderate-deviation sharpening of the usual VC estimate, with an additional factor of order $(\\varepsilon\\sqrt{n})^{-1}$ in the leading exponential term when $\\varepsilon\\sqrt{n}$ is large.",
      "url": "http://arxiv.org/abs/2601.16411",
      "author": "A. Iosevich, A. Vagharshakyan, E. Wyman",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Refines the classical Vapnik-Chervonenkis theorem by using Berry-Esseen normal approximation instead of Hoeffding's inequality. Achieves moderate-deviation sharpening with additional factor improvement when sample size is large.",
      "importance_score": 30,
      "reasoning": "Pure theoretical refinement with limited practical impact; incremental improvement to classical result.",
      "themes": [
        "Learning Theory",
        "VC Dimension",
        "Statistical Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Refines the classical Vapnik-Chervonenkis theorem by using Berry-Esseen normal approximation instead of Hoeffding's inequality. Achieves moderate-deviation sharpening with additional factor improvement when sample size is large.</p>",
      "content_html": "<p>arXiv:2601.16411v1 Announce Type: new  Abstract: Vapnik--Chervonenkis' theorem is a seminal result in machine learning. It establishes sufficient conditions for empirical probabilities to converge to theoretical probabilities, uniformly over families of events. It also provides an estimate for the rate of such uniform convergence.   We revisit the probabilistic component of the classical argument. Instead of applying Hoeffding's inequality at the final step, we use a normal approximation with explicit Berry--Esseen error control. This yields a moderate-deviation sharpening of the usual VC estimate, with an additional factor of order $(\\varepsilon\\sqrt{n})^{-1}$ in the leading exponential term when $\\varepsilon\\sqrt{n}$ is large.</p>"
    },
    {
      "id": "2b790177c84a",
      "title": "Safe Multitask Molecular Graph Networks for Vapor Pressure and Odor Threshold Prediction",
      "content": "arXiv:2601.16426v1 Announce Type: new  Abstract: We investigate two important tasks in odor-related property modeling: Vapor Pressure (VP) and Odor Threshold (OP). To evaluate the model's out-of-distribution (OOD) capability, we adopt the Bemis-Murcko scaffold split. In terms of features, we introduce the rich A20/E17 molecular graph features (20-dimensional atom features + 17-dimensional bond features) and systematically compare GINE and PNA backbones. The results show: for VP, PNA with a simple regression head achieves Val MSE $\\approx$ 0.21 (normalized space); for the OP single task under the same scaffold split, using A20/E17 with robust training (Huber/winsor) achieves Val MSE $\\approx$ 0.60-0.61. For multitask training, we propose a **\"safe multitask\"** approach: VP as the primary task and OP as the auxiliary task, using delayed activation + gradient clipping + small weight, which avoids harming the primary task and simultaneously yields the best VP generalization performance. This paper provides complete reproducible experiments, ablation studies, and error-similarity analysis while discussing the impact of data noise and method limitations.",
      "url": "http://arxiv.org/abs/2601.16426",
      "author": "Shuang Wu, Meijie Wang, Lun Yu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Applies molecular graph networks to predict vapor pressure and odor threshold using A20/E17 molecular features. Proposes 'safe multitask' training using VP as auxiliary task to improve OOD generalization for odor prediction.",
      "importance_score": 30,
      "reasoning": "Domain-specific application with limited broader impact; standard GNN methodology applied to chemistry problem.",
      "themes": [
        "Molecular Property Prediction",
        "Graph Neural Networks",
        "Chemistry"
      ],
      "continuation": null,
      "summary_html": "<p>Applies molecular graph networks to predict vapor pressure and odor threshold using A20/E17 molecular features. Proposes 'safe multitask' training using VP as auxiliary task to improve OOD generalization for odor prediction.</p>",
      "content_html": "<p>arXiv:2601.16426v1 Announce Type: new  Abstract: We investigate two important tasks in odor-related property modeling: Vapor Pressure (VP) and Odor Threshold (OP). To evaluate the model's out-of-distribution (OOD) capability, we adopt the Bemis-Murcko scaffold split. In terms of features, we introduce the rich A20/E17 molecular graph features (20-dimensional atom features + 17-dimensional bond features) and systematically compare GINE and PNA backbones. The results show: for VP, PNA with a simple regression head achieves Val MSE $\\approx$ 0.21 (normalized space); for the OP single task under the same scaffold split, using A20/E17 with robust training (Huber/winsor) achieves Val MSE $\\approx$ 0.60-0.61. For multitask training, we propose a <strong>\"safe multitask\"</strong> approach: VP as the primary task and OP as the auxiliary task, using delayed activation + gradient clipping + small weight, which avoids harming the primary task and simultaneously yields the best VP generalization performance. This paper provides complete reproducible experiments, ablation studies, and error-similarity analysis while discussing the impact of data noise and method limitations.</p>"
    },
    {
      "id": "09c10ec47356",
      "title": "Robust Categorical Data Clustering Guided by Multi-Granular Competitive Learning",
      "content": "arXiv:2601.16491v1 Announce Type: new  Abstract: Data set composed of categorical features is very common in big data analysis tasks. Since categorical features are usually with a limited number of qualitative possible values, the nested granular cluster effect is prevalent in the implicit discrete distance space of categorical data. That is, data objects frequently overlap in space or subspace to form small compact clusters, and similar small clusters often form larger clusters. However, the distance space cannot be well-defined like the Euclidean distance due to the qualitative categorical data values, which brings great challenges to the cluster analysis of categorical data. In view of this, we design a Multi-Granular Competitive Penalization Learning (MGCPL) algorithm to allow potential clusters to interactively tune themselves and converge in stages with different numbers of naturally compact clusters. To leverage MGCPL, we also propose a Cluster Aggregation strategy based on MGCPL Encoding (CAME) to first encode the data objects according to the learned multi-granular distributions, and then perform final clustering on the embeddings. It turns out that the proposed MGCPL-guided Categorical Data Clustering (MCDC) approach is competent in automatically exploring the nested distribution of multi-granular clusters and highly robust to categorical data sets from various domains. Benefiting from its linear time complexity, MCDC is scalable to large-scale data sets and promising in pre-partitioning data sets or compute nodes for boosting distributed computing. Extensive experiments with statistical evidence demonstrate its superiority compared to state-of-the-art counterparts on various real public data sets.",
      "url": "http://arxiv.org/abs/2601.16491",
      "author": "Shenghong Cai, Yiqun Zhang, Xiaopeng Luo, Yiu-Ming Cheung, Hong Jia, Peng Liu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes MGCPL algorithm for clustering categorical data by allowing potential clusters to compete at multiple granularity levels. Addresses challenge of nested granular cluster effects in discrete distance spaces.",
      "importance_score": 30,
      "reasoning": "Standard clustering methodology for specific data type; limited novelty and broader impact.",
      "themes": [
        "Clustering",
        "Categorical Data",
        "Unsupervised Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes MGCPL algorithm for clustering categorical data by allowing potential clusters to compete at multiple granularity levels. Addresses challenge of nested granular cluster effects in discrete distance spaces.</p>",
      "content_html": "<p>arXiv:2601.16491v1 Announce Type: new  Abstract: Data set composed of categorical features is very common in big data analysis tasks. Since categorical features are usually with a limited number of qualitative possible values, the nested granular cluster effect is prevalent in the implicit discrete distance space of categorical data. That is, data objects frequently overlap in space or subspace to form small compact clusters, and similar small clusters often form larger clusters. However, the distance space cannot be well-defined like the Euclidean distance due to the qualitative categorical data values, which brings great challenges to the cluster analysis of categorical data. In view of this, we design a Multi-Granular Competitive Penalization Learning (MGCPL) algorithm to allow potential clusters to interactively tune themselves and converge in stages with different numbers of naturally compact clusters. To leverage MGCPL, we also propose a Cluster Aggregation strategy based on MGCPL Encoding (CAME) to first encode the data objects according to the learned multi-granular distributions, and then perform final clustering on the embeddings. It turns out that the proposed MGCPL-guided Categorical Data Clustering (MCDC) approach is competent in automatically exploring the nested distribution of multi-granular clusters and highly robust to categorical data sets from various domains. Benefiting from its linear time complexity, MCDC is scalable to large-scale data sets and promising in pre-partitioning data sets or compute nodes for boosting distributed computing. Extensive experiments with statistical evidence demonstrate its superiority compared to state-of-the-art counterparts on various real public data sets.</p>"
    },
    {
      "id": "1f88cf482a56",
      "title": "Embedding -based Crop Type Classification in the Groundnut Basin of Senegal",
      "content": "arXiv:2601.16900v1 Announce Type: new  Abstract: Crop type maps from satellite remote sensing are important tools for food security, local livelihood support and climate change mitigation in smallholder regions of the world, but most satellite-based methods are not well suited to smallholder conditions. To address this gap, we establish a four-part criteria for a useful embedding-based approach consisting of 1) performance, 2) plausibility, 3) transferability and 4) accessibility and evaluate geospatial foundation model (FM) embeddings -based approaches using TESSERA and AlphaEarth against current baseline methods for a region in the groundnut basin of Senegal. We find that the TESSERA -based approach to land cover and crop type mapping fulfills the selection criteria best, and in one temporal transfer example shows 28% higher accuracy compared to the next best method. These results indicate that TESSERA embeddings are an effective approach for crop type classification and mapping tasks in Senegal.",
      "url": "http://arxiv.org/abs/2601.16900",
      "author": "Madeline C. Lisaius, Srinivasan Keshav, Andrew Blake, Clement Atzberger",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Evaluates geospatial foundation model embeddings for crop type classification in Senegal's groundnut basin. Finds TESSERA-based approach best fulfills criteria of performance, plausibility, transferability, and accessibility.",
      "importance_score": 30,
      "reasoning": "Domain application with limited methodological contribution; evaluation of existing foundation models.",
      "themes": [
        "Remote Sensing",
        "Agriculture",
        "Foundation Models"
      ],
      "continuation": null,
      "summary_html": "<p>Evaluates geospatial foundation model embeddings for crop type classification in Senegal's groundnut basin. Finds TESSERA-based approach best fulfills criteria of performance, plausibility, transferability, and accessibility.</p>",
      "content_html": "<p>arXiv:2601.16900v1 Announce Type: new  Abstract: Crop type maps from satellite remote sensing are important tools for food security, local livelihood support and climate change mitigation in smallholder regions of the world, but most satellite-based methods are not well suited to smallholder conditions. To address this gap, we establish a four-part criteria for a useful embedding-based approach consisting of 1) performance, 2) plausibility, 3) transferability and 4) accessibility and evaluate geospatial foundation model (FM) embeddings -based approaches using TESSERA and AlphaEarth against current baseline methods for a region in the groundnut basin of Senegal. We find that the TESSERA -based approach to land cover and crop type mapping fulfills the selection criteria best, and in one temporal transfer example shows 28% higher accuracy compared to the next best method. These results indicate that TESSERA embeddings are an effective approach for crop type classification and mapping tasks in Senegal.</p>"
    },
    {
      "id": "5e6345b40bf3",
      "title": "Long-Term Probabilistic Forecast of Vegetation Conditions Using Climate Attributes in the Four Corners Region",
      "content": "arXiv:2601.16347v1 Announce Type: cross  Abstract: Weather conditions can drastically alter the state of crops and rangelands, and in turn, impact the incomes and food security of individuals worldwide. Satellite-based remote sensing offers an effective way to monitor vegetation and climate variables on regional and global scales. The annual peak Normalized Difference Vegetation Index (NDVI), derived from satellite observations, is closely associated with crop development, rangeland biomass, and vegetation growth. Although various machine learning methods have been developed to forecast NDVI over short time ranges, such as one-month-ahead predictions, long-term forecasting approaches, such as one-year-ahead predictions of vegetation conditions, are not yet available. To fill this gap, we develop a two-phase machine learning model to forecast the one-year-ahead peak NDVI over high-resolution grids, using the Four Corners region of the Southwestern United States as a testbed. In phase one, we identify informative climate attributes, including precipitation and maximum vapor pressure deficit, and develop the generalized parallel Gaussian process that captures the relationship between climate attributes and NDVI. In phase two, we forecast these climate attributes using historical data at least one year before the NDVI prediction month, which then serve as inputs to forecast the peak NDVI at each spatial grid. We developed open-source tools that outperform alternative methods for both gross NDVI and grid-based NDVI one-year forecasts, providing information that can help farmers and ranchers make actionable plans a year in advance.",
      "url": "http://arxiv.org/abs/2601.16347",
      "author": "Erika McPhillips, Hyeongseong Lee, Xiangyu Xie, Kathy Baylis, Chris Funk, Mengyang Gu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "stat.AP"
      ],
      "summary": "Develops probabilistic framework for year-ahead NDVI prediction using climate attributes. Addresses gap in long-term vegetation condition forecasting for food security applications.",
      "importance_score": 30,
      "reasoning": "Domain-specific application; useful for agriculture but limited methodological novelty.",
      "themes": [
        "Remote Sensing",
        "Climate",
        "Vegetation Forecasting",
        "Food Security"
      ],
      "continuation": null,
      "summary_html": "<p>Develops probabilistic framework for year-ahead NDVI prediction using climate attributes. Addresses gap in long-term vegetation condition forecasting for food security applications.</p>",
      "content_html": "<p>arXiv:2601.16347v1 Announce Type: cross  Abstract: Weather conditions can drastically alter the state of crops and rangelands, and in turn, impact the incomes and food security of individuals worldwide. Satellite-based remote sensing offers an effective way to monitor vegetation and climate variables on regional and global scales. The annual peak Normalized Difference Vegetation Index (NDVI), derived from satellite observations, is closely associated with crop development, rangeland biomass, and vegetation growth. Although various machine learning methods have been developed to forecast NDVI over short time ranges, such as one-month-ahead predictions, long-term forecasting approaches, such as one-year-ahead predictions of vegetation conditions, are not yet available. To fill this gap, we develop a two-phase machine learning model to forecast the one-year-ahead peak NDVI over high-resolution grids, using the Four Corners region of the Southwestern United States as a testbed. In phase one, we identify informative climate attributes, including precipitation and maximum vapor pressure deficit, and develop the generalized parallel Gaussian process that captures the relationship between climate attributes and NDVI. In phase two, we forecast these climate attributes using historical data at least one year before the NDVI prediction month, which then serve as inputs to forecast the peak NDVI at each spatial grid. We developed open-source tools that outperform alternative methods for both gross NDVI and grid-based NDVI one-year forecasts, providing information that can help farmers and ranchers make actionable plans a year in advance.</p>"
    },
    {
      "id": "389444d1beb0",
      "title": "A Feature Extraction Pipeline for Enhancing Lightweight Neural Networks in sEMG-based Joint Torque Estimation",
      "content": "arXiv:2601.16712v1 Announce Type: cross  Abstract: Robot-assisted rehabilitation offers an effective approach, wherein exoskeletons adapt to users' needs and provide personalized assistance. However, to deliver such assistance, accurate prediction of the user's joint torques is essential. In this work, we propose a feature extraction pipeline using 8-channel surface electromyography (sEMG) signals to predict elbow and shoulder joint torques. For preliminary evaluation, this pipeline was integrated into two neural network models: the Multilayer Perceptron (MLP) and the Temporal Convolutional Network (TCN). Data were collected from a single subject performing elbow and shoulder movements under three load conditions (0 kg, 1.10 kg, and 1.85 kg) using three motion-capture cameras. Reference torques were estimated from center-of-mass kinematics under the assumption of static equilibrium. Our offline analyses showed that, with our feature extraction pipeline, MLP model achieved mean RMSE of 0.963 N m, 1.403 N m, and 1.434 N m (over five seeds) for elbow, front-shoulder, and side-shoulder joints, respectively, which were comparable to the TCN performance. These results demonstrate that the proposed feature extraction pipeline enables a simple MLP to achieve performance comparable to that of a network designed explicitly for temporal dependencies. This finding is particularly relevant for applications with limited training data, a common scenario patient care.",
      "url": "http://arxiv.org/abs/2601.16712",
      "author": "Kartik Chari, Raid Dokhan, Anas Homsi, Niklas Kueper, Elsa Andrea Kirchner",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.RO"
      ],
      "summary": "Proposes feature extraction pipeline from 8-channel sEMG signals for predicting elbow and shoulder joint torques. Evaluates MLP and TCN models for rehabilitation robot applications.",
      "importance_score": 30,
      "reasoning": "Domain-specific application; standard methodology applied to rehabilitation robotics.",
      "themes": [
        "EMG Analysis",
        "Rehabilitation Robotics",
        "Neural Networks"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes feature extraction pipeline from 8-channel sEMG signals for predicting elbow and shoulder joint torques. Evaluates MLP and TCN models for rehabilitation robot applications.</p>",
      "content_html": "<p>arXiv:2601.16712v1 Announce Type: cross  Abstract: Robot-assisted rehabilitation offers an effective approach, wherein exoskeletons adapt to users' needs and provide personalized assistance. However, to deliver such assistance, accurate prediction of the user's joint torques is essential. In this work, we propose a feature extraction pipeline using 8-channel surface electromyography (sEMG) signals to predict elbow and shoulder joint torques. For preliminary evaluation, this pipeline was integrated into two neural network models: the Multilayer Perceptron (MLP) and the Temporal Convolutional Network (TCN). Data were collected from a single subject performing elbow and shoulder movements under three load conditions (0 kg, 1.10 kg, and 1.85 kg) using three motion-capture cameras. Reference torques were estimated from center-of-mass kinematics under the assumption of static equilibrium. Our offline analyses showed that, with our feature extraction pipeline, MLP model achieved mean RMSE of 0.963 N m, 1.403 N m, and 1.434 N m (over five seeds) for elbow, front-shoulder, and side-shoulder joints, respectively, which were comparable to the TCN performance. These results demonstrate that the proposed feature extraction pipeline enables a simple MLP to achieve performance comparable to that of a network designed explicitly for temporal dependencies. This finding is particularly relevant for applications with limited training data, a common scenario patient care.</p>"
    },
    {
      "id": "8ec0eb805d14",
      "title": "Agreement-Driven Multi-View 3D Reconstruction for Live Cattle Weight Estimation",
      "content": "arXiv:2601.17791v1 Announce Type: new  Abstract: Accurate cattle live weight estimation is vital for livestock management, welfare, and productivity. Traditional methods, such as manual weighing using a walk-over weighing system or proximate measurements using body condition scoring, involve manual handling of stock and can impact productivity from both a stock and economic perspective. To address these issues, this study investigated a cost-effective, non-contact method for live weight calculation in cattle using 3D reconstruction. The proposed pipeline utilized multi-view RGB images with SAM 3D-based agreement-guided fusion, followed by ensemble regression. Our approach generates a single 3D point cloud per animal and compares classical ensemble models with deep learning models under low-data conditions. Results show that SAM 3D with multi-view agreement fusion outperforms other 3D generation methods, while classical ensemble models provide the most consistent performance for practical farm scenarios (R$^2$ = 0.69 $\\pm$ 0.10, MAPE = 2.22 $\\pm$ 0.56 \\%), making this practical for on-farm implementation. These findings demonstrate that improving reconstruction quality is more critical than increasing model complexity for scalable deployment on farms where producing a large volume of 3D data is challenging.",
      "url": "http://arxiv.org/abs/2601.17791",
      "author": "Rabin Dulal, Wenfeng Jia, Lihong Zheng, Jane Quinn",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Proposes an agreement-driven multi-view 3D reconstruction approach for cattle weight estimation using SAM-3D-based fusion and ensemble regression from RGB images.",
      "importance_score": 30,
      "reasoning": "Very narrow agricultural application. Standard pipeline with limited novelty.",
      "themes": [
        "Agriculture AI",
        "3D Reconstruction",
        "Animal Science"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes an agreement-driven multi-view 3D reconstruction approach for cattle weight estimation using SAM-3D-based fusion and ensemble regression from RGB images.</p>",
      "content_html": "<p>arXiv:2601.17791v1 Announce Type: new  Abstract: Accurate cattle live weight estimation is vital for livestock management, welfare, and productivity. Traditional methods, such as manual weighing using a walk-over weighing system or proximate measurements using body condition scoring, involve manual handling of stock and can impact productivity from both a stock and economic perspective. To address these issues, this study investigated a cost-effective, non-contact method for live weight calculation in cattle using 3D reconstruction. The proposed pipeline utilized multi-view RGB images with SAM 3D-based agreement-guided fusion, followed by ensemble regression. Our approach generates a single 3D point cloud per animal and compares classical ensemble models with deep learning models under low-data conditions. Results show that SAM 3D with multi-view agreement fusion outperforms other 3D generation methods, while classical ensemble models provide the most consistent performance for practical farm scenarios (R$^2$ = 0.69 $\\pm$ 0.10, MAPE = 2.22 $\\pm$ 0.56 \\%), making this practical for on-farm implementation. These findings demonstrate that improving reconstruction quality is more critical than increasing model complexity for scalable deployment on farms where producing a large volume of 3D data is challenging.</p>"
    },
    {
      "id": "10a053cc47b5",
      "title": "Computational Framework for Estimating Relative Gaussian Blur Kernels between Image Pairs",
      "content": "arXiv:2601.18099v1 Announce Type: new  Abstract: Following the earlier verification for Gaussian model in \\cite{ASaa2026}, this paper introduces a zero training forward computational framework for the model to realize it in real time applications. The framework is based on discrete calculation of the analytic expression of the defocused image from the sharper one for the application range of the standard deviation of the Gaussian kernels and selecting the best matches. The analytic expression yields multiple solutions at certain image points, but is filtered down to a single solution using similarity measures over neighboring points.The framework is structured to handle cases where two given images are partial blurred versions of each other. Experimental evaluations on real images demonstrate that the proposed framework achieves a mean absolute error (MAE) below $1.7\\%$ in estimating synthetic blur values. Furthermore, the discrepancy between actual blurred image intensities and their corresponding estimates remains under $2\\%$, obtained by applying the extracted defocus filters to less blurred images.",
      "url": "http://arxiv.org/abs/2601.18099",
      "author": "Akbar Saadat",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Introduces computational framework for estimating relative Gaussian blur kernels between image pairs with zero training, using discrete calculation of analytic defocus expressions.",
      "importance_score": 30,
      "reasoning": "Basic image processing contribution with limited novelty or impact.",
      "themes": [
        "Image Processing",
        "Blur Estimation"
      ],
      "continuation": null,
      "summary_html": "<p>Introduces computational framework for estimating relative Gaussian blur kernels between image pairs with zero training, using discrete calculation of analytic defocus expressions.</p>",
      "content_html": "<p>arXiv:2601.18099v1 Announce Type: new  Abstract: Following the earlier verification for Gaussian model in \\cite{ASaa2026}, this paper introduces a zero training forward computational framework for the model to realize it in real time applications. The framework is based on discrete calculation of the analytic expression of the defocused image from the sharper one for the application range of the standard deviation of the Gaussian kernels and selecting the best matches. The analytic expression yields multiple solutions at certain image points, but is filtered down to a single solution using similarity measures over neighboring points.The framework is structured to handle cases where two given images are partial blurred versions of each other. Experimental evaluations on real images demonstrate that the proposed framework achieves a mean absolute error (MAE) below $1.7\\%$ in estimating synthetic blur values. Furthermore, the discrepancy between actual blurred image intensities and their corresponding estimates remains under $2\\%$, obtained by applying the extracted defocus filters to less blurred images.</p>"
    },
    {
      "id": "95c0eb49db49",
      "title": "Dialogue: Is there a Natural Abstraction of Good?",
      "content": "Disclaimer: this is published without any post-processing or editing for typos after the dialogue took place.Gabriel AlfourLet's split the conversation in three parts (with no time commitment for each):1) Exposing our ThesesWe start with a brief overview of our theses, just for some high-level context.2) Probing QuestionsWe ask each other a bunch of questions to understand our mutual points of view: probe around what we expect to be our respective blindspots.Ideally, wed end this half with a better understanding of our positions. And also of our K-positions (as in, X vs Ka(X) in epistemic modal logic): where we expect each other to miss facts and considerations3) Investigative DebateWe look for concrete cruxes. We debate, but rather than resolving disagreements, we aim to make them more precise. Ie: working to identify where we disagree&nbsp;in practice rather than&nbsp;in words.Ideally, wed end this half with a list of better-specified disagreements: empiricals, thought experiments, concrete scenarios, predictions, and the like--Also, for some context:The conversation was sparked by&nbsp;this Tweet.Davidad and I have already discussed AI x-risks IRL a few times. We agree&nbsp;and disagree on many related topics!davidadHappy to follow your lead! That sounds good to me.davidadThesis:Somewhere between the capability profile of GPT-4 and the capability profile of Opus 4.5, there seems to have been a phase transition where frontier LLMs have grokked the natural abstraction of what it means to be Good, rather than merely mirroring human values. These observations seem vastly more likely under my old (19992012) belief system (which would say that being superhuman in all cognitive domains implies being superhuman at morality) than my newer (20162023) belief system (which would say that AlphaZero and systems like it are strong evidence that strategic capabilities and moral capabilities can be decoupled). My current (20252026) belief system says that strategic capabilit...",
      "url": "https://www.lesswrong.com/posts/M5s6WgScRfmeWsLD4/dialogue-is-there-a-natural-abstraction-of-good",
      "author": "davidad",
      "published": "2026-01-26T13:40:29.306000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Disclaimer: this is published without any post-processing or editing for typos after the dialogue took place.Gabriel AlfourLet's split the conversation in three parts (with no time commitment for each...",
      "importance_score": 30,
      "reasoning": "Not analyzed (batch processing)",
      "themes": [],
      "continuation": null,
      "summary_html": "<p>Disclaimer: this is published without any post-processing or editing for typos after the dialogue took place.Gabriel AlfourLet's split the conversation in three parts (with no time commitment for each...</p>",
      "content_html": "<p>Disclaimer: this is published without any post-processing or editing for typos after the dialogue took place.Gabriel AlfourLet's split the conversation in three parts (with no time commitment for each):1) Exposing our ThesesWe start with a brief overview of our theses, just for some high-level context.2) Probing QuestionsWe ask each other a bunch of questions to understand our mutual points of view: probe around what we expect to be our respective blindspots.Ideally, wed end this half with a better understanding of our positions. And also of our K-positions (as in, X vs Ka(X) in epistemic modal logic): where we expect each other to miss facts and considerations3) Investigative DebateWe look for concrete cruxes. We debate, but rather than resolving disagreements, we aim to make them more precise. Ie: working to identify where we disagree&nbsp;in practice rather than&nbsp;in words.Ideally, wed end this half with a list of better-specified disagreements: empiricals, thought experiments, concrete scenarios, predictions, and the like--Also, for some context:The conversation was sparked by&nbsp;this Tweet.Davidad and I have already discussed AI x-risks IRL a few times. We agree&nbsp;and disagree on many related topics!davidadHappy to follow your lead! That sounds good to me.davidadThesis:Somewhere between the capability profile of GPT-4 and the capability profile of Opus 4.5, there seems to have been a phase transition where frontier LLMs have grokked the natural abstraction of what it means to be Good, rather than merely mirroring human values. These observations seem vastly more likely under my old (19992012) belief system (which would say that being superhuman in all cognitive domains implies being superhuman at morality) than my newer (20162023) belief system (which would say that AlphaZero and systems like it are strong evidence that strategic capabilities and moral capabilities can be decoupled). My current (20252026) belief system says that strategic capabilit...</p>"
    },
    {
      "id": "d4d56d6d0431",
      "title": "Upcoming Dovetail fellow talks & discussion",
      "content": "As the current Dovetail research fellowship comes to a close, the fellows are giving talks on their projects. All are welcome to join! Unlike the previous cohort talks, these talks will be scheduled one at a time. This is partly because there are too many to do all in one day, and partly because the ending dates for several of the fellows are spread out over time.The easiest way to keep track of the schedule is to subscribe to the public Dovetail google calendar. I'll also list them here in this post, which I'll update as more talks get scheduled.All talks will be on Zoom at this link.January 31 (Saturday) 1800 GMT/1000 PTSantiago Cifuentes - General Agents Contain World Models, even if they are non-deterministic and the world is partially observable.In this talk we will present some concrete extensions of the results from&nbsp;https://arxiv.org/abs/2506.01622. More precisely, we will extend their result 1 for non-deterministic agents and partially observable environments.January 31 (Saturday) 2000 GMT/1200 PTLo Cymbalista - An introduction to Computational MechanicsFebruary 1 (Sunday) 1830 GMT/1030 PTVardhan Kumar Ray - DFA and AI agentsFebruary 12 (Thursday) 1600 GMT/0800 PTMargot Stakenborg - World ModelsFebruary 17 (Tuesday) 1500 GMT/0700 PTGuillermo Martin - Reward HypothesisMore to come!",
      "url": "https://www.lesswrong.com/posts/zP4nJWP7ZWhYdPXRE/upcoming-dovetail-fellow-talks-and-discussion",
      "author": "Alex_Altair",
      "published": "2026-01-25T21:39:28.365000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Announcement of upcoming talks from Dovetail research fellows, including topics on world models in non-deterministic agents, computational mechanics, and DFA in AI agents.",
      "importance_score": 30,
      "reasoning": "Announcement rather than research, but previews potentially interesting alignment research topics. The world models extension paper appears substantive.",
      "themes": [
        "AI Safety Research",
        "Research Announcements",
        "Alignment"
      ],
      "continuation": null,
      "summary_html": "<p>Announcement of upcoming talks from Dovetail research fellows, including topics on world models in non-deterministic agents, computational mechanics, and DFA in AI agents.</p>",
      "content_html": "<p>As the current Dovetail research fellowship comes to a close, the fellows are giving talks on their projects. All are welcome to join! Unlike the previous cohort talks, these talks will be scheduled one at a time. This is partly because there are too many to do all in one day, and partly because the ending dates for several of the fellows are spread out over time.The easiest way to keep track of the schedule is to subscribe to the public Dovetail google calendar. I'll also list them here in this post, which I'll update as more talks get scheduled.All talks will be on Zoom at this link.January 31 (Saturday) 1800 GMT/1000 PTSantiago Cifuentes - General Agents Contain World Models, even if they are non-deterministic and the world is partially observable.In this talk we will present some concrete extensions of the results from&nbsp;https://arxiv.org/abs/2506.01622. More precisely, we will extend their result 1 for non-deterministic agents and partially observable environments.January 31 (Saturday) 2000 GMT/1200 PTLo Cymbalista - An introduction to Computational MechanicsFebruary 1 (Sunday) 1830 GMT/1030 PTVardhan Kumar Ray - DFA and AI agentsFebruary 12 (Thursday) 1600 GMT/0800 PTMargot Stakenborg - World ModelsFebruary 17 (Tuesday) 1500 GMT/0700 PTGuillermo Martin - Reward HypothesisMore to come!</p>"
    },
    {
      "id": "f53089d7b300",
      "title": "A System for Name and Address Parsing with Large Language Models",
      "content": "arXiv:2601.18014v1 Announce Type: cross  Abstract: Reliable transformation of unstructured person and address text into structured data remains a key challenge in large-scale information systems. Traditional rule-based and probabilistic approaches perform well on clean inputs but fail under noisy or multilingual conditions, while neural and large language models (LLMs) often lack deterministic control and reproducibility. This paper introduces a prompt-driven, validation-centered framework that converts free-text records into a consistent 17-field schema without fine-tuning. The method integrates input normalisation, structured prompting, constrained decoding, and strict rule-based validation under fixed experimental settings to ensure reproducibility. Evaluations on heterogeneous real-world address data show high field-level accuracy, strong schema adherence, and stable confidence calibration. The results demonstrate that combining deterministic validation with generative prompting provides a robust, interpretable, and scalable solution for structured information extraction, offering a practical alternative to training-heavy or domain-specific models.",
      "url": "http://arxiv.org/abs/2601.18014",
      "author": "Adeeba Tarannum, Muzakkiruddin Ahmed Mohammed, Mert Can Cakmak, Shames Al Mandalawi, John Talburt",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "Prompt-driven framework for parsing unstructured names and addresses into 17-field schema using validation-centered approach.",
      "importance_score": 29,
      "reasoning": "Practical NER application. Validation-centered design.",
      "themes": [
        "Named Entity Recognition",
        "LLM Applications",
        "Data Parsing"
      ],
      "continuation": null,
      "summary_html": "<p>Prompt-driven framework for parsing unstructured names and addresses into 17-field schema using validation-centered approach.</p>",
      "content_html": "<p>arXiv:2601.18014v1 Announce Type: cross  Abstract: Reliable transformation of unstructured person and address text into structured data remains a key challenge in large-scale information systems. Traditional rule-based and probabilistic approaches perform well on clean inputs but fail under noisy or multilingual conditions, while neural and large language models (LLMs) often lack deterministic control and reproducibility. This paper introduces a prompt-driven, validation-centered framework that converts free-text records into a consistent 17-field schema without fine-tuning. The method integrates input normalisation, structured prompting, constrained decoding, and strict rule-based validation under fixed experimental settings to ensure reproducibility. Evaluations on heterogeneous real-world address data show high field-level accuracy, strong schema adherence, and stable confidence calibration. The results demonstrate that combining deterministic validation with generative prompting provides a robust, interpretable, and scalable solution for structured information extraction, offering a practical alternative to training-heavy or domain-specific models.</p>"
    },
    {
      "id": "d43c6fd40054",
      "title": "Deadline-Aware, Energy-Efficient Control of Domestic Immersion Hot Water Heaters",
      "content": "arXiv:2601.18123v1 Announce Type: new  Abstract: Typical domestic immersion water heater systems are often operated continuously during winter, heating quickly rather than efficiently and ignoring predictable demand windows and ambient losses. We study deadline-aware control, where the aim is to reach a target temperature at a specified time while minimising energy consumption. We introduce an efficient Gymnasium environment that models an immersion hot water heater with first-order thermal losses and discrete on and off actions of 0 W and 6000 W applied every 120 seconds. Methods include a time-optimal bang-bang baseline, a zero-shot Monte Carlo Tree Search planner, and a Proximal Policy Optimisation policy. We report total energy consumption in watt-hours under identical physical dynamics. Across sweeps of initial temperature from 10 to 30 degrees Celsius, deadline from 30 to 90 steps, and target temperature from 40 to 80 degrees Celsius, PPO achieves the most energy-efficient performance at a 60-step horizon of 2 hours, using 3.23 kilowatt-hours, compared to 4.37 to 10.45 kilowatt-hours for bang-bang control and 4.18 to 6.46 kilowatt-hours for MCTS. This corresponds to energy savings of 26 percent at 30 steps and 69 percent at 90 steps. In a representative trajectory with a 50 kg water mass, 20 degrees Celsius ambient temperature, and a 60 degrees Celsius target, PPO consumes 54 percent less energy than bang-bang control and 33 percent less than MCTS. These results show that learned deadline-aware control reduces energy consumption under identical physical assumptions, while planners provide partial savings without training and learned policies offer near-zero inference cost once trained.",
      "url": "http://arxiv.org/abs/2601.18123",
      "author": "Muhammad Ibrahim Khan, Bivin Pradeep, James Brusey",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Studies deadline-aware control of water heaters comparing bang-bang baseline, Monte Carlo Tree Search, and PPO for energy-efficient heating to target temperature.",
      "importance_score": 28,
      "reasoning": "Narrow applied RL work on simple control problem; minimal AI research contribution.",
      "themes": [
        "Control Systems",
        "Reinforcement Learning"
      ],
      "continuation": null,
      "summary_html": "<p>Studies deadline-aware control of water heaters comparing bang-bang baseline, Monte Carlo Tree Search, and PPO for energy-efficient heating to target temperature.</p>",
      "content_html": "<p>arXiv:2601.18123v1 Announce Type: new  Abstract: Typical domestic immersion water heater systems are often operated continuously during winter, heating quickly rather than efficiently and ignoring predictable demand windows and ambient losses. We study deadline-aware control, where the aim is to reach a target temperature at a specified time while minimising energy consumption. We introduce an efficient Gymnasium environment that models an immersion hot water heater with first-order thermal losses and discrete on and off actions of 0 W and 6000 W applied every 120 seconds. Methods include a time-optimal bang-bang baseline, a zero-shot Monte Carlo Tree Search planner, and a Proximal Policy Optimisation policy. We report total energy consumption in watt-hours under identical physical dynamics. Across sweeps of initial temperature from 10 to 30 degrees Celsius, deadline from 30 to 90 steps, and target temperature from 40 to 80 degrees Celsius, PPO achieves the most energy-efficient performance at a 60-step horizon of 2 hours, using 3.23 kilowatt-hours, compared to 4.37 to 10.45 kilowatt-hours for bang-bang control and 4.18 to 6.46 kilowatt-hours for MCTS. This corresponds to energy savings of 26 percent at 30 steps and 69 percent at 90 steps. In a representative trajectory with a 50 kg water mass, 20 degrees Celsius ambient temperature, and a 60 degrees Celsius target, PPO consumes 54 percent less energy than bang-bang control and 33 percent less than MCTS. These results show that learned deadline-aware control reduces energy consumption under identical physical assumptions, while planners provide partial savings without training and learned policies offer near-zero inference cost once trained.</p>"
    },
    {
      "id": "6fd5b88edb32",
      "title": "PALMA: A Lightweight Tropical Algebra Library for ARM-Based Embedded Systems",
      "content": "arXiv:2601.17028v1 Announce Type: cross  Abstract: Tropical algebra, including max-plus, min-plus, and related idempotent semirings, provides a unifying framework in which many optimization problems that are nonlinear in classical algebra become linear. This property makes tropical methods particularly well suited for shortest paths, scheduling, throughput analysis, and discrete event systems. Despite their theoretical maturity and practical relevance, existing tropical algebra implementations primarily target desktop or server environments and remain largely inaccessible on resource-constrained embedded platforms, where such optimization problems are most acute. We present PALMA (Parallel Algebra Library for Max-plus Applications), a lightweight, dependency-free C library that brings tropical linear algebra to ARM-based embedded systems. PALMA implements a generic semiring abstraction with SIMD-accelerated kernels, enabling a single computational framework to support shortest paths, bottleneck paths, reachability, scheduling, and throughput analysis. The library supports five tropical semirings, dense and sparse (CSR) representations, tropical closure, and spectral analysis via maximum cycle mean computation. We evaluate PALMA on a Raspberry Pi 4 and demonstrate peak performance of 2,274 MOPS, speedups of up to 11.9 times over classical Bellman-Ford for single-source shortest paths, and sub-10 microsecond scheduling solves for real-time control workloads. Case studies in UAV control, IoT routing, and manufacturing systems show that tropical algebra enables efficient, predictable, and unified optimization directly on embedded hardware. PALMA is released as open-source software under the MIT license.",
      "url": "http://arxiv.org/abs/2601.17028",
      "author": "Gnankan Landry Regis N'guessan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.MS"
      ],
      "summary": "Presents PALMA, a lightweight C library implementing tropical algebra (max-plus, min-plus semirings) for ARM-based embedded systems, enabling optimization problems on resource-constrained devices.",
      "importance_score": 28,
      "reasoning": "Useful engineering contribution but focused on classical optimization algorithms rather than modern AI. Limited relevance to current AI research.",
      "themes": [
        "Embedded Systems",
        "Optimization"
      ],
      "continuation": null,
      "summary_html": "<p>Presents PALMA, a lightweight C library implementing tropical algebra (max-plus, min-plus semirings) for ARM-based embedded systems, enabling optimization problems on resource-constrained devices.</p>",
      "content_html": "<p>arXiv:2601.17028v1 Announce Type: cross  Abstract: Tropical algebra, including max-plus, min-plus, and related idempotent semirings, provides a unifying framework in which many optimization problems that are nonlinear in classical algebra become linear. This property makes tropical methods particularly well suited for shortest paths, scheduling, throughput analysis, and discrete event systems. Despite their theoretical maturity and practical relevance, existing tropical algebra implementations primarily target desktop or server environments and remain largely inaccessible on resource-constrained embedded platforms, where such optimization problems are most acute. We present PALMA (Parallel Algebra Library for Max-plus Applications), a lightweight, dependency-free C library that brings tropical linear algebra to ARM-based embedded systems. PALMA implements a generic semiring abstraction with SIMD-accelerated kernels, enabling a single computational framework to support shortest paths, bottleneck paths, reachability, scheduling, and throughput analysis. The library supports five tropical semirings, dense and sparse (CSR) representations, tropical closure, and spectral analysis via maximum cycle mean computation. We evaluate PALMA on a Raspberry Pi 4 and demonstrate peak performance of 2,274 MOPS, speedups of up to 11.9 times over classical Bellman-Ford for single-source shortest paths, and sub-10 microsecond scheduling solves for real-time control workloads. Case studies in UAV control, IoT routing, and manufacturing systems show that tropical algebra enables efficient, predictable, and unified optimization directly on embedded hardware. PALMA is released as open-source software under the MIT license.</p>"
    },
    {
      "id": "06e4b06271e1",
      "title": "AI-based approach to burnout identification from textual data",
      "content": "arXiv:2601.17993v1 Announce Type: cross  Abstract: This study introduces an AI-based methodology that utilizes natural language processing (NLP) to detect burnout from textual data. The approach relies on a RuBERT model originally trained for sentiment analysis and subsequently fine-tuned for burnout detection using two data sources: synthetic sentences generated with ChatGPT and user comments collected from Russian YouTube videos about burnout. The resulting model assigns a burnout probability to input texts and can be applied to process large volumes of written communication for monitoring burnout-related language signals in high-stress work environments.",
      "url": "http://arxiv.org/abs/2601.17993",
      "author": "Marina Zavertiaeva, Petr Parshakov, Mikhail Usanin, Aleksei Smirnov, Sofia Paklina, Anastasiia Kibardina",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CL"
      ],
      "summary": "AI methodology using RuBERT fine-tuned for burnout detection from textual data using synthetic and YouTube comment data.",
      "importance_score": 28,
      "reasoning": "Applied NLP for mental health. Russian language focus.",
      "themes": [
        "Mental Health AI",
        "NLP Applications",
        "Sentiment Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>AI methodology using RuBERT fine-tuned for burnout detection from textual data using synthetic and YouTube comment data.</p>",
      "content_html": "<p>arXiv:2601.17993v1 Announce Type: cross  Abstract: This study introduces an AI-based methodology that utilizes natural language processing (NLP) to detect burnout from textual data. The approach relies on a RuBERT model originally trained for sentiment analysis and subsequently fine-tuned for burnout detection using two data sources: synthetic sentences generated with ChatGPT and user comments collected from Russian YouTube videos about burnout. The resulting model assigns a burnout probability to input texts and can be applied to process large volumes of written communication for monitoring burnout-related language signals in high-stress work environments.</p>"
    },
    {
      "id": "a136621dadb1",
      "title": "Cloud-Enabled IoT System for Real-Time Environmental Monitoring and Remote Device Control Using Firebase",
      "content": "arXiv:2601.17414v1 Announce Type: new  Abstract: The proliferation of Internet of Things (IoT) devices has created unprecedented opportunities for remote monitoring and control applications across various domains. Traditional monitoring systems often suffer from limitations in real-time data accessibility, remote controllability, and cloud integration. This paper presents a cloud-enabled IoT system that leverages Google's Firebase Realtime Database for synchronized environmental monitoring and device control. The system utilizes an ESP32 microcontroller to interface with a DHT22 temperature/humidity sensor and an HC-SR04 ultrasonic distance sensor, while enabling remote control of two LED indicators through a cloud-based interface. Real-time sensor data is transmitted to Firebase, providing a synchronized platform accessible from multiple devices simultaneously. Experimental results demonstrate reliable data transmission with 99.2\\% success rate, real-time control latency under 1.5 seconds, and persistent data storage for historical analysis. The system architecture offers a scalable framework for various IoT applications, from smart home automation to industrial monitoring, with a total implementation cost of \\$32.50. The integration of Firebase provides robust cloud capabilities without requiring complex server infrastructure, making advanced IoT applications accessible to developers and researchers with limited resources.",
      "url": "http://arxiv.org/abs/2601.17414",
      "author": "Abdul Hasib, A. S. M. Ahsanul Sarkar Akib",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Computer Vision)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Presents cloud-enabled IoT system using Firebase for environmental monitoring and device control with ESP32 microcontroller interfacing DHT22 and HC-SR04 sensors.",
      "importance_score": 28,
      "reasoning": "Standard IoT implementation with no research novelty.",
      "themes": [
        "IoT",
        "Environmental Monitoring"
      ],
      "continuation": null,
      "summary_html": "<p>Presents cloud-enabled IoT system using Firebase for environmental monitoring and device control with ESP32 microcontroller interfacing DHT22 and HC-SR04 sensors.</p>",
      "content_html": "<p>arXiv:2601.17414v1 Announce Type: new  Abstract: The proliferation of Internet of Things (IoT) devices has created unprecedented opportunities for remote monitoring and control applications across various domains. Traditional monitoring systems often suffer from limitations in real-time data accessibility, remote controllability, and cloud integration. This paper presents a cloud-enabled IoT system that leverages Google's Firebase Realtime Database for synchronized environmental monitoring and device control. The system utilizes an ESP32 microcontroller to interface with a DHT22 temperature/humidity sensor and an HC-SR04 ultrasonic distance sensor, while enabling remote control of two LED indicators through a cloud-based interface. Real-time sensor data is transmitted to Firebase, providing a synchronized platform accessible from multiple devices simultaneously. Experimental results demonstrate reliable data transmission with 99.2\\% success rate, real-time control latency under 1.5 seconds, and persistent data storage for historical analysis. The system architecture offers a scalable framework for various IoT applications, from smart home automation to industrial monitoring, with a total implementation cost of \\$32.50. The integration of Firebase provides robust cloud capabilities without requiring complex server infrastructure, making advanced IoT applications accessible to developers and researchers with limited resources.</p>"
    },
    {
      "id": "53f6f87bf9dd",
      "title": "I (well, mostly claude code) simulated proportional representation methods.",
      "content": "Low-ish effort post just sharing something I found fun. No AI-written text outside the figures.I was recently nerd-sniped by proportional representation voting, and so when playing around with claude code I decided to have it build a simulation.Hot take:If you're electing a legislature and want it to be proportional, use approval ballots and seq-PAV[1].&nbsp;Other key points:There's a tradeoff between how well you represent people on average, and how much inequality there is in how well you represent people.If you disproportionately cluster winning candidates near the center of the distribution of voter preferences, this does pretty well on average, but is more unequal, vice versa for spreading winning candidates apart from each other.Voting methods don't change much in their ordering on metrics as you make the distribution of voter preferences more multimodal/spiky.My idealized simulation of 4-party voting does surprisingly well (but has incentive problems in the real world).STV (Single Transferable Vote) spreads out the winners more and therefore has low inequality, but at the cost of lower average representativeness. Maybe there are alternative clever things to do with ranked ballots that I should explore.Code is at https://github.com/Charlie-Steiner/voting-simulation, claude code really did just (apparently) work. But there's a caveat that of the things I was paying attention to I found and fixed a few crazy choices, so there's probably at least one crazy choice I didn't find.&nbsp;The voter model:My sim voters had preferences that lived in a 3 or 4 dimensional space. Candidates also lived in this space.Candidates were drawn from the same distribution as voters.Voters just preferred closer candidates to farther ones.For the headline results, I sampled multimodal distributions of voter preferences - modes sampled uniformly within a ball, population split between them at uniformly random percentages, then normally distributed around their mode.This accentuated the...",
      "url": "https://www.lesswrong.com/posts/dLpAYa6ReaTGj3ktt/i-well-mostly-claude-code-simulated-proportional",
      "author": "Charlie Steiner",
      "published": "2026-01-25T23:23:37.172000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Author used Claude Code to simulate different proportional representation voting methods, comparing seq-PAV approval voting with STV and others. Finds tradeoffs between average representation quality and inequality.",
      "importance_score": 28,
      "reasoning": "Interesting AI-assisted analysis but the research topic (voting methods) isn't AI-related. Demonstrates Claude Code capabilities but limited novelty in findings.",
      "themes": [
        "Voting Theory",
        "AI-Assisted Research",
        "Social Choice"
      ],
      "continuation": null,
      "summary_html": "<p>Author used Claude Code to simulate different proportional representation voting methods, comparing seq-PAV approval voting with STV and others. Finds tradeoffs between average representation quality and inequality.</p>",
      "content_html": "<p>Low-ish effort post just sharing something I found fun. No AI-written text outside the figures.I was recently nerd-sniped by proportional representation voting, and so when playing around with claude code I decided to have it build a simulation.Hot take:If you're electing a legislature and want it to be proportional, use approval ballots and seq-PAV[1].&nbsp;Other key points:There's a tradeoff between how well you represent people on average, and how much inequality there is in how well you represent people.If you disproportionately cluster winning candidates near the center of the distribution of voter preferences, this does pretty well on average, but is more unequal, vice versa for spreading winning candidates apart from each other.Voting methods don't change much in their ordering on metrics as you make the distribution of voter preferences more multimodal/spiky.My idealized simulation of 4-party voting does surprisingly well (but has incentive problems in the real world).STV (Single Transferable Vote) spreads out the winners more and therefore has low inequality, but at the cost of lower average representativeness. Maybe there are alternative clever things to do with ranked ballots that I should explore.Code is at https://github.com/Charlie-Steiner/voting-simulation, claude code really did just (apparently) work. But there's a caveat that of the things I was paying attention to I found and fixed a few crazy choices, so there's probably at least one crazy choice I didn't find.&nbsp;The voter model:My sim voters had preferences that lived in a 3 or 4 dimensional space. Candidates also lived in this space.Candidates were drawn from the same distribution as voters.Voters just preferred closer candidates to farther ones.For the headline results, I sampled multimodal distributions of voter preferences - modes sampled uniformly within a ball, population split between them at uniformly random percentages, then normally distributed around their mode.This accentuated the...</p>"
    },
    {
      "id": "ccce03afb32c",
      "title": "GO-OSC and VASH: Geometry-Aware Representation Learning for Early Degradation Detection in Oscillatory Systems",
      "content": "arXiv:2601.17396v1 Announce Type: cross  Abstract: Early-stage degradation in oscillatory systems often manifests as geometric distortions of the dynamics, such as phase jitter, frequency drift, or loss of coherence, long before changes in signal energy are detectable. In this regime, classical energy-based diagnostics and unconstrained learned representations are structurally insensitive, leading to delayed or unstable detection. We introduce GO-OSC, a geometry-aware representation learning framework for oscillatory time series that enforces a canonical and identifiable latent parameterization, enabling stable comparison and aggregation across short, unlabeled windows. Building on this representation, we define a family of invariant linear geometric probes that target degradation-relevant directions in latent space. We provide theoretical results showing that under early phase-only degradation, energy-based statistics have zero first-order detection power, whereas geometric probes achieve strictly positive sensitivity. Our analysis characterizes when and why linear probing fails under non-identifiable representations and shows how canonicalization restores statistical detectability. Experiments on synthetic benchmarks and real vibration datasets validate the theory, demonstrating earlier detection, improved data efficiency, and robustness to operating condition changes.",
      "url": "http://arxiv.org/abs/2601.17396",
      "author": "Vashista Nobaub",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "GO-OSC introduces geometry-aware representation learning for early degradation detection in oscillatory systems through canonical latent parameterization.",
      "importance_score": 27,
      "reasoning": "Domain-specific contribution for industrial monitoring. Geometric approach.",
      "themes": [
        "Time Series",
        "Anomaly Detection",
        "Representation Learning"
      ],
      "continuation": null,
      "summary_html": "<p>GO-OSC introduces geometry-aware representation learning for early degradation detection in oscillatory systems through canonical latent parameterization.</p>",
      "content_html": "<p>arXiv:2601.17396v1 Announce Type: cross  Abstract: Early-stage degradation in oscillatory systems often manifests as geometric distortions of the dynamics, such as phase jitter, frequency drift, or loss of coherence, long before changes in signal energy are detectable. In this regime, classical energy-based diagnostics and unconstrained learned representations are structurally insensitive, leading to delayed or unstable detection. We introduce GO-OSC, a geometry-aware representation learning framework for oscillatory time series that enforces a canonical and identifiable latent parameterization, enabling stable comparison and aggregation across short, unlabeled windows. Building on this representation, we define a family of invariant linear geometric probes that target degradation-relevant directions in latent space. We provide theoretical results showing that under early phase-only degradation, energy-based statistics have zero first-order detection power, whereas geometric probes achieve strictly positive sensitivity. Our analysis characterizes when and why linear probing fails under non-identifiable representations and shows how canonicalization restores statistical detectability. Experiments on synthetic benchmarks and real vibration datasets validate the theory, demonstrating earlier detection, improved data efficiency, and robustness to operating condition changes.</p>"
    },
    {
      "id": "9dd8d053bd70",
      "title": "Coronary Artery Segmentation and Vessel-Type Classification in X-Ray Angiography",
      "content": "arXiv:2601.17429v1 Announce Type: cross  Abstract: X-ray coronary angiography (XCA) is the clinical reference standard for assessing coronary artery disease, yet quantitative analysis is limited by the difficulty of robust vessel segmentation in routine data. Low contrast, motion, foreshortening, overlap, and catheter confounding degrade segmentation and contribute to domain shift across centers. Reliable segmentation, together with vessel-type labeling, enables vessel-specific coronary analytics and downstream measurements that depend on anatomical localization. From 670 cine sequences (407 subjects), we select a best frame near peak opacification using a low-intensity histogram criterion and apply joint super-resolution and enhancement. We benchmark classical Meijering, Frangi, and Sato vesselness filters under per-image oracle tuning, a single global mean setting, and per-image parameter prediction via Support Vector Regression (SVR). Neural baselines include U-Net, FPN, and a Swin Transformer, trained with coronary-only and merged coronary+catheter supervision. A second stage assigns vessel identity (LAD, LCX, RCA). External evaluation uses the public DCA1 cohort. SVR per-image tuning improves Dice over global means for all classical filters (e.g., Frangi: 0.759 vs. 0.741). Among deep models, FPN attains 0.914+/-0.007 Dice (coronary-only), and merged coronary+catheter labels further improve to 0.931+/-0.006. On DCA1 as a strict external test, Dice drops to 0.798 (coronary-only) and 0.814 (merged), while light in-domain fine-tuning recovers to 0.881+/-0.014 and 0.882+/-0.015. Vessel-type labeling achieves 98.5% accuracy (Dice 0.844) for RCA, 95.4% (0.786) for LAD, and 96.2% (0.794) for LCX. Learned per-image tuning strengthens classical pipelines, while high-resolution FPN models and merged-label supervision improve stability and external transfer with modest adaptation.",
      "url": "http://arxiv.org/abs/2601.17429",
      "author": "Mehdi Yousefzadeh, Siavash Shirzadeh Barough, Ashkan Fakharifar, Yashar Tayyarazad, Narges Eghbali, Mohaddeseh Mozaffari, Hoda Taeb, Negar Sadat Rafiee Tabatabaee, Parsa Esfahanian, Ghazaleh Sadeghi Gohar, Amineh Safavirad, Saeideh Mazloomzadeh, Ehsan khalilipur, Armin Elahifar, Majid Maleki",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "Benchmarks classical and learning-based methods for coronary artery segmentation in X-ray angiography with vessel-type classification.",
      "importance_score": 26,
      "reasoning": "Medical imaging benchmark. Clinical application focus.",
      "themes": [
        "Medical Imaging",
        "Segmentation",
        "Cardiology"
      ],
      "continuation": null,
      "summary_html": "<p>Benchmarks classical and learning-based methods for coronary artery segmentation in X-ray angiography with vessel-type classification.</p>",
      "content_html": "<p>arXiv:2601.17429v1 Announce Type: cross  Abstract: X-ray coronary angiography (XCA) is the clinical reference standard for assessing coronary artery disease, yet quantitative analysis is limited by the difficulty of robust vessel segmentation in routine data. Low contrast, motion, foreshortening, overlap, and catheter confounding degrade segmentation and contribute to domain shift across centers. Reliable segmentation, together with vessel-type labeling, enables vessel-specific coronary analytics and downstream measurements that depend on anatomical localization. From 670 cine sequences (407 subjects), we select a best frame near peak opacification using a low-intensity histogram criterion and apply joint super-resolution and enhancement. We benchmark classical Meijering, Frangi, and Sato vesselness filters under per-image oracle tuning, a single global mean setting, and per-image parameter prediction via Support Vector Regression (SVR). Neural baselines include U-Net, FPN, and a Swin Transformer, trained with coronary-only and merged coronary+catheter supervision. A second stage assigns vessel identity (LAD, LCX, RCA). External evaluation uses the public DCA1 cohort. SVR per-image tuning improves Dice over global means for all classical filters (e.g., Frangi: 0.759 vs. 0.741). Among deep models, FPN attains 0.914+/-0.007 Dice (coronary-only), and merged coronary+catheter labels further improve to 0.931+/-0.006. On DCA1 as a strict external test, Dice drops to 0.798 (coronary-only) and 0.814 (merged), while light in-domain fine-tuning recovers to 0.881+/-0.014 and 0.882+/-0.015. Vessel-type labeling achieves 98.5% accuracy (Dice 0.844) for RCA, 95.4% (0.786) for LAD, and 96.2% (0.794) for LCX. Learned per-image tuning strengthens classical pipelines, while high-resolution FPN models and merged-label supervision improve stability and external transfer with modest adaptation.</p>"
    },
    {
      "id": "2dc47216a59c",
      "title": "From Noise to Insights: Enhancing Supply Chain Decision Support through AI-Based Survey Integrity Analytics",
      "content": "arXiv:2601.17005v1 Announce Type: cross  Abstract: The reliability of survey data is crucial in supply chain decision-making, particularly when evaluating readiness for AI-driven tools such as safety stock optimization systems. However, surveys often attract low-effort or fake responses that degrade the accuracy of derived insights. This study proposes a lightweight AI-based framework for filtering unreliable survey inputs using a supervised machine learning approach. In this expanded study, a larger dataset of 99 industry responses was collected, with manual labeling to identify fake responses based on logical inconsistencies and response patterns. After preprocessing and label encoding, both Random Forest and baseline models (Logistic Regression, XGBoost) were trained to distinguish genuine from fake responses. The best-performing model achieved an 92.0% accuracy rate, demonstrating improved detection compared to the pilot study. Despite limitations, the results highlight the viability of integrating AI into survey pipelines and provide a scalable solution for improving data integrity in supply chain research, especially during product launch and technology adoption phases.",
      "url": "http://arxiv.org/abs/2601.17005",
      "author": "Bhubalan Mani",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Proposes a lightweight ML framework using Random Forest and XGBoost to filter unreliable survey responses in supply chain decision-making contexts. Small dataset of 99 responses.",
      "importance_score": 25,
      "reasoning": "Very small scale study with standard ML techniques. Limited novelty and narrow application scope.",
      "themes": [
        "Applied ML",
        "Data Quality"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes a lightweight ML framework using Random Forest and XGBoost to filter unreliable survey responses in supply chain decision-making contexts. Small dataset of 99 responses.</p>",
      "content_html": "<p>arXiv:2601.17005v1 Announce Type: cross  Abstract: The reliability of survey data is crucial in supply chain decision-making, particularly when evaluating readiness for AI-driven tools such as safety stock optimization systems. However, surveys often attract low-effort or fake responses that degrade the accuracy of derived insights. This study proposes a lightweight AI-based framework for filtering unreliable survey inputs using a supervised machine learning approach. In this expanded study, a larger dataset of 99 industry responses was collected, with manual labeling to identify fake responses based on logical inconsistencies and response patterns. After preprocessing and label encoding, both Random Forest and baseline models (Logistic Regression, XGBoost) were trained to distinguish genuine from fake responses. The best-performing model achieved an 92.0% accuracy rate, demonstrating improved detection compared to the pilot study. Despite limitations, the results highlight the viability of integrating AI into survey pipelines and provide a scalable solution for improving data integrity in supply chain research, especially during product launch and technology adoption phases.</p>"
    },
    {
      "id": "ca58db6cea9a",
      "title": "Forecasting Energy Consumption using Recurrent Neural Networks: A Comparative Analysis",
      "content": "arXiv:2601.17110v1 Announce Type: cross  Abstract: Accurate short-term energy consumption forecasting is essential for efficient power grid management, resource allocation, and market stability. Traditional time-series models often fail to capture the complex, non-linear dependencies and external factors affecting energy demand. In this study, we propose a forecasting approach based on Recurrent Neural Networks (RNNs) and their advanced variant, Long Short-Term Memory (LSTM) networks. Our methodology integrates historical energy consumption data with external variables, including temperature, humidity, and time-based features. The LSTM model is trained and evaluated on a publicly available dataset, and its performance is compared against a conventional feed-forward neural network baseline. Experimental results show that the LSTM model substantially outperforms the baseline, achieving lower Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). These findings demonstrate the effectiveness of deep learning models in providing reliable and precise short-term energy forecasts for real-world applications.",
      "url": "http://arxiv.org/abs/2601.17110",
      "author": "Abhishek Maity, Viraj Tukarul",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Comparative analysis of RNN and LSTM networks for short-term energy consumption forecasting, integrating temperature, humidity, and time features.",
      "importance_score": 25,
      "reasoning": "Standard comparison of established architectures. Very limited novelty and methodology.",
      "themes": [
        "Energy Forecasting",
        "Time Series"
      ],
      "continuation": null,
      "summary_html": "<p>Comparative analysis of RNN and LSTM networks for short-term energy consumption forecasting, integrating temperature, humidity, and time features.</p>",
      "content_html": "<p>arXiv:2601.17110v1 Announce Type: cross  Abstract: Accurate short-term energy consumption forecasting is essential for efficient power grid management, resource allocation, and market stability. Traditional time-series models often fail to capture the complex, non-linear dependencies and external factors affecting energy demand. In this study, we propose a forecasting approach based on Recurrent Neural Networks (RNNs) and their advanced variant, Long Short-Term Memory (LSTM) networks. Our methodology integrates historical energy consumption data with external variables, including temperature, humidity, and time-based features. The LSTM model is trained and evaluated on a publicly available dataset, and its performance is compared against a conventional feed-forward neural network baseline. Experimental results show that the LSTM model substantially outperforms the baseline, achieving lower Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). These findings demonstrate the effectiveness of deep learning models in providing reliable and precise short-term energy forecasts for real-world applications.</p>"
    },
    {
      "id": "2ef25671a2cb",
      "title": "Shortcut Learning in Binary Classifier Black Boxes: Applications to Voice Anti-Spoofing and Biometrics",
      "content": "arXiv:2601.17782v1 Announce Type: cross  Abstract: The widespread adoption of deep-learning models in data-driven applications has drawn attention to the potential risks associated with biased datasets and models. Neglected or hidden biases within datasets and models can lead to unexpected results. This study addresses the challenges of dataset bias and explores ``shortcut learning'' or ``Clever Hans effect'' in binary classifiers. We propose a novel framework for analyzing the black-box classifiers and for examining the impact of both training and test data on classifier scores. Our framework incorporates intervention and observational perspectives, employing a linear mixed-effects model for post-hoc analysis. By evaluating classifier performance beyond error rates, we aim to provide insights into biased datasets and offer a comprehensive understanding of their influence on classifier behavior. The effectiveness of our approach is demonstrated through experiments on audio anti-spoofing and speaker verification tasks using both statistical models and deep neural networks. The insights gained from this study have broader implications for tackling biases in other domains and advancing the field of explainable artificial intelligence.",
      "url": "http://arxiv.org/abs/2601.17782",
      "author": "Md Sahidullah, Hye-jin Shim, Rosa Gonzalez Hautam\\\"aki, Tomi H. Kinnunen",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Framework for analyzing shortcut learning in binary classifiers using linear mixed-effects model for post-hoc analysis of voice anti-spoofing.",
      "importance_score": 25,
      "reasoning": "Addresses important bias/shortcut problem. Application to biometrics.",
      "themes": [
        "Shortcut Learning",
        "Biometrics",
        "Model Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Framework for analyzing shortcut learning in binary classifiers using linear mixed-effects model for post-hoc analysis of voice anti-spoofing.</p>",
      "content_html": "<p>arXiv:2601.17782v1 Announce Type: cross  Abstract: The widespread adoption of deep-learning models in data-driven applications has drawn attention to the potential risks associated with biased datasets and models. Neglected or hidden biases within datasets and models can lead to unexpected results. This study addresses the challenges of dataset bias and explores ``shortcut learning'' or ``Clever Hans effect'' in binary classifiers. We propose a novel framework for analyzing the black-box classifiers and for examining the impact of both training and test data on classifier scores. Our framework incorporates intervention and observational perspectives, employing a linear mixed-effects model for post-hoc analysis. By evaluating classifier performance beyond error rates, we aim to provide insights into biased datasets and offer a comprehensive understanding of their influence on classifier behavior. The effectiveness of our approach is demonstrated through experiments on audio anti-spoofing and speaker verification tasks using both statistical models and deep neural networks. The insights gained from this study have broader implications for tackling biases in other domains and advancing the field of explainable artificial intelligence.</p>"
    },
    {
      "id": "d9ca59947bfa",
      "title": "Brownian ReLU(Br-ReLU): A New Activation Function for a Long-Short Term Memory (LSTM) Network",
      "content": "arXiv:2601.16446v1 Announce Type: new  Abstract: Deep learning models are effective for sequential data modeling, yet commonly used activation functions such as ReLU, LeakyReLU, and PReLU often exhibit gradient instability when applied to noisy, non-stationary financial time series. This study introduces BrownianReLU, a stochastic activation function induced by Brownian motion that enhances gradient propagation and learning stability in Long Short-Term Memory (LSTM) networks. Using Monte Carlo simulation, BrownianReLU provides a smooth, adaptive response for negative inputs, mitigating the dying ReLU problem. The proposed activation is evaluated on financial time series from Apple, GCB, and the S&amp;P 500, as well as LendingClub loan data for classification. Results show consistently lower Mean Squared Error and higher $R^2$ values, indicating improved predictive accuracy and generalization. Although ROC-AUC metric is limited in classification tasks, activation choice significantly affects the trade-off between accuracy and sensitivity, with Brownian ReLU and the selected activation functions yielding practically meaningful performance.",
      "url": "http://arxiv.org/abs/2601.16446",
      "author": "George Awiakye-Marfo, Elijah Agbosu, Victoria Mawuena Barns, Samuel Asante Gyamerah",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Machine Learning)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "Proposes BrownianReLU, a stochastic activation function using Brownian motion to enhance gradient propagation in LSTMs. Uses Monte Carlo simulation to provide smooth adaptive response for negative inputs.",
      "importance_score": 25,
      "reasoning": "Limited novelty; stochastic activations are not new, and improvements shown are modest on specific financial datasets.",
      "themes": [
        "Activation Functions",
        "LSTM",
        "Time Series",
        "Financial Prediction"
      ],
      "continuation": null,
      "summary_html": "<p>Proposes BrownianReLU, a stochastic activation function using Brownian motion to enhance gradient propagation in LSTMs. Uses Monte Carlo simulation to provide smooth adaptive response for negative inputs.</p>",
      "content_html": "<p>arXiv:2601.16446v1 Announce Type: new  Abstract: Deep learning models are effective for sequential data modeling, yet commonly used activation functions such as ReLU, LeakyReLU, and PReLU often exhibit gradient instability when applied to noisy, non-stationary financial time series. This study introduces BrownianReLU, a stochastic activation function induced by Brownian motion that enhances gradient propagation and learning stability in Long Short-Term Memory (LSTM) networks. Using Monte Carlo simulation, BrownianReLU provides a smooth, adaptive response for negative inputs, mitigating the dying ReLU problem. The proposed activation is evaluated on financial time series from Apple, GCB, and the S&amp;P 500, as well as LendingClub loan data for classification. Results show consistently lower Mean Squared Error and higher $R^2$ values, indicating improved predictive accuracy and generalization. Although ROC-AUC metric is limited in classification tasks, activation choice significantly affects the trade-off between accuracy and sensitivity, with Brownian ReLU and the selected activation functions yielding practically meaningful performance.</p>"
    },
    {
      "id": "b781c4118060",
      "title": "Leveraging Persistence Image to Enhance Robustness and Performance in Curvilinear Structure Segmentation",
      "content": "arXiv:2601.18045v1 Announce Type: cross  Abstract: Segmenting curvilinear structures in medical images is essential for analyzing morphological patterns in clinical applications. Integrating topological properties, such as connectivity, improves segmentation accuracy and consistency. However, extracting and embedding such properties - especially from Persistence Diagrams (PD) - is challenging due to their non-differentiability and computational cost. Existing approaches mostly encode topology through handcrafted loss functions, which generalize poorly across tasks. In this paper, we propose PIs-Regressor, a simple yet effective module that learns persistence image (PI) - finite, differentiable representations of topological features - directly from data. Together with Topology SegNet, which fuses these features in both downsampling and upsampling stages, our framework integrates topology into the network architecture itself rather than auxiliary losses. Unlike existing methods that depend heavily on handcrafted loss functions, our approach directly incorporates topological information into the network structure, leading to more robust segmentation. Our design is flexible and can be seamlessly combined with other topology-based methods to further enhance segmentation performance. Experimental results show that integrating topological features enhances model robustness, effectively handling challenges like overexposure and blurring in medical imaging. Our approach on three curvilinear benchmarks demonstrate state-of-the-art performance in both pixel-level accuracy and topological fidelity.",
      "url": "http://arxiv.org/abs/2601.18045",
      "author": "Zhuangzhi Gao, Feixiang Zhou, He Zhao, Xiuju Chen, Xiaoxin Li, Qinkai Yu, Yitian Zhao, Alena Shantsila, Gregory Y. H. Lip, Eduard Shantsila, Yalin Zheng",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CV"
      ],
      "summary": "PIs-Regressor learns persistence images for curvilinear structure segmentation in medical images, enabling differentiable topological feature extraction.",
      "importance_score": 24,
      "reasoning": "Novel topological approach to medical segmentation. Addresses differentiability challenge.",
      "themes": [
        "Medical Imaging",
        "Topological Data Analysis",
        "Segmentation"
      ],
      "continuation": null,
      "summary_html": "<p>PIs-Regressor learns persistence images for curvilinear structure segmentation in medical images, enabling differentiable topological feature extraction.</p>",
      "content_html": "<p>arXiv:2601.18045v1 Announce Type: cross  Abstract: Segmenting curvilinear structures in medical images is essential for analyzing morphological patterns in clinical applications. Integrating topological properties, such as connectivity, improves segmentation accuracy and consistency. However, extracting and embedding such properties - especially from Persistence Diagrams (PD) - is challenging due to their non-differentiability and computational cost. Existing approaches mostly encode topology through handcrafted loss functions, which generalize poorly across tasks. In this paper, we propose PIs-Regressor, a simple yet effective module that learns persistence image (PI) - finite, differentiable representations of topological features - directly from data. Together with Topology SegNet, which fuses these features in both downsampling and upsampling stages, our framework integrates topology into the network architecture itself rather than auxiliary losses. Unlike existing methods that depend heavily on handcrafted loss functions, our approach directly incorporates topological information into the network structure, leading to more robust segmentation. Our design is flexible and can be seamlessly combined with other topology-based methods to further enhance segmentation performance. Experimental results show that integrating topological features enhances model robustness, effectively handling challenges like overexposure and blurring in medical imaging. Our approach on three curvilinear benchmarks demonstrate state-of-the-art performance in both pixel-level accuracy and topological fidelity.</p>"
    },
    {
      "id": "a7d8cfcc830d",
      "title": "Context-Aware Iterative Token Detection and Masked Transmission for Wireless Token Communication",
      "content": "arXiv:2601.17770v1 Announce Type: cross  Abstract: The success of large-scale language models has established tokens as compact and meaningful units for natural-language representation, which motivates token communication over wireless channels, where tokens are considered fundamental units for wireless transmission. We propose a context-aware token communication framework that uses a pretrained masked language model (MLM) as a shared contextual probability model between the transmitter (Tx) and receiver (Rx). At Rx, we develop an iterative token detection method that jointly exploits MLM-guided contextual priors and channel observations based on a Bayesian perspective. At Tx, we additionally introduce a context-aware masking strategy which skips highly predictable token transmission to reduce transmission rate. Simulation results demonstrate that the proposed framework substantially improves reconstructed sentence quality and supports effective rate adaptation under various channel conditions.",
      "url": "http://arxiv.org/abs/2601.17770",
      "author": "Junyong Shin, Joohyuk Park, Jihong Park, Jinho Choi, Yo-Seb Jeon",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "eess.SP"
      ],
      "summary": "Context-aware token communication framework using masked language model for wireless transmission with iterative detection and masking strategies.",
      "importance_score": 23,
      "reasoning": "Novel application of LLMs to wireless communication. Interesting cross-domain work.",
      "themes": [
        "Wireless Communication",
        "Language Models",
        "Signal Processing"
      ],
      "continuation": null,
      "summary_html": "<p>Context-aware token communication framework using masked language model for wireless transmission with iterative detection and masking strategies.</p>",
      "content_html": "<p>arXiv:2601.17770v1 Announce Type: cross  Abstract: The success of large-scale language models has established tokens as compact and meaningful units for natural-language representation, which motivates token communication over wireless channels, where tokens are considered fundamental units for wireless transmission. We propose a context-aware token communication framework that uses a pretrained masked language model (MLM) as a shared contextual probability model between the transmitter (Tx) and receiver (Rx). At Rx, we develop an iterative token detection method that jointly exploits MLM-guided contextual priors and channel observations based on a Bayesian perspective. At Tx, we additionally introduce a context-aware masking strategy which skips highly predictable token transmission to reduce transmission rate. Simulation results demonstrate that the proposed framework substantially improves reconstructed sentence quality and supports effective rate adaptation under various channel conditions.</p>"
    },
    {
      "id": "b52175e5d1ab",
      "title": "Online parameter estimation for the Crazyflie quadcopter through an EM algorithm",
      "content": "arXiv:2601.17009v1 Announce Type: new  Abstract: Drones are becoming more and more popular nowadays. They are small in size, low in cost, and reliable in operation. They contain a variety of sensors and can perform a variety of flight tasks, reaching places that are difficult or inaccessible for humans. Earthquakes damage a lot of infrastructure, making it impossible for rescuers to reach some areas. But drones can help. Many amateur and professional photographers like to use drones for aerial photography. Drones play a non-negligible role in agriculture and transportation too. Drones can be used to spray pesticides, and they can also transport supplies. A quadcopter is a four-rotor drone and has been studied in this paper. In this paper, random noise is added to the quadcopter system and its effects on the drone system are studied. An extended Kalman filter has been used to estimate the state based on noisy observations from the sensor. Based on a SDE system, a linear quadratic Gaussian controller has been implemented. The expectation maximization algorithm has been applied for parameter estimation of the quadcopter. The results of offline parameter estimation and online parameter estimation are presented. The results show that the online parameter estimation has a slightly larger range of convergence values than the offline parameter estimation.",
      "url": "http://arxiv.org/abs/2601.17009",
      "author": "Yanhua Zhao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.AI"
      ],
      "summary": "Presents a method for online parameter estimation of quadcopter drones using an Expectation-Maximization algorithm with random noise added to the system. Standard robotics work with limited AI novelty.",
      "importance_score": 22,
      "reasoning": "Basic robotics control paper with minimal AI/ML innovation; narrow application scope.",
      "themes": [
        "Robotics",
        "Control Systems"
      ],
      "continuation": null,
      "summary_html": "<p>Presents a method for online parameter estimation of quadcopter drones using an Expectation-Maximization algorithm with random noise added to the system. Standard robotics work with limited AI novelty.</p>",
      "content_html": "<p>arXiv:2601.17009v1 Announce Type: new  Abstract: Drones are becoming more and more popular nowadays. They are small in size, low in cost, and reliable in operation. They contain a variety of sensors and can perform a variety of flight tasks, reaching places that are difficult or inaccessible for humans. Earthquakes damage a lot of infrastructure, making it impossible for rescuers to reach some areas. But drones can help. Many amateur and professional photographers like to use drones for aerial photography. Drones play a non-negligible role in agriculture and transportation too. Drones can be used to spray pesticides, and they can also transport supplies. A quadcopter is a four-rotor drone and has been studied in this paper. In this paper, random noise is added to the quadcopter system and its effects on the drone system are studied. An extended Kalman filter has been used to estimate the state based on noisy observations from the sensor. Based on a SDE system, a linear quadratic Gaussian controller has been implemented. The expectation maximization algorithm has been applied for parameter estimation of the quadcopter. The results of offline parameter estimation and online parameter estimation are presented. The results show that the online parameter estimation has a slightly larger range of convergence values than the offline parameter estimation.</p>"
    },
    {
      "id": "398ac8856193",
      "title": "Evaluating the Evolution of Critical Thinking, Creativity, Communication and Collaboration in Higher Education Courses",
      "content": "arXiv:2601.17018v1 Announce Type: cross  Abstract: The development of Creativity, Communication, Critical Thinking, and Collaboration (the 4Cs) is a central objective of contemporary competency-based education. However, empirical evidence on how these competencies evolve across learning modules and instructional phases remains limited. This study evaluates the evolution of the 4Cs from pre-pilot to pilot implementation phases across three educational contexts, using the project's 4Cs theoretical framework as an analytical lens. The analysis of three pilot cases (IASIS, EASD, and UPATRAS) compares the 4Cs scores to identify patterns of growth, stagnation, or decline over time. Results indicate that communication and critical thinking showed the most consistent and substantial improvements, particularly in pilots with lower pre-pilot baselines, suggesting that structured pilot interventions effectively support cognitive and expressive competencies. In contrast, creativity exhibited context-dependent outcomes, while collaboration emerged as the most fragile competency, often stagnating or declining during scale-up. Interpreted through the theoretical framework, these findings suggest that competency evolution is strongly shaped by instructional design, assessment alignment, and learning activity structures rather than learner ability alone. The study contributes empirical validation to the 4Cs framework and highlights the need for differentiated, competency-sensitive design and evaluation strategies when scaling educational modules.",
      "url": "http://arxiv.org/abs/2601.17018",
      "author": "Margarida Romero (IIIA / CSIC, UniCA)",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Evaluates evolution of Creativity, Communication, Critical Thinking, and Collaboration competencies across educational pilot implementations using a 4Cs theoretical framework.",
      "importance_score": 22,
      "reasoning": "Education research with minimal AI methodology contribution. Focus is on competency assessment rather than AI systems.",
      "themes": [
        "Education Research"
      ],
      "continuation": null,
      "summary_html": "<p>Evaluates evolution of Creativity, Communication, Critical Thinking, and Collaboration competencies across educational pilot implementations using a 4Cs theoretical framework.</p>",
      "content_html": "<p>arXiv:2601.17018v1 Announce Type: cross  Abstract: The development of Creativity, Communication, Critical Thinking, and Collaboration (the 4Cs) is a central objective of contemporary competency-based education. However, empirical evidence on how these competencies evolve across learning modules and instructional phases remains limited. This study evaluates the evolution of the 4Cs from pre-pilot to pilot implementation phases across three educational contexts, using the project's 4Cs theoretical framework as an analytical lens. The analysis of three pilot cases (IASIS, EASD, and UPATRAS) compares the 4Cs scores to identify patterns of growth, stagnation, or decline over time. Results indicate that communication and critical thinking showed the most consistent and substantial improvements, particularly in pilots with lower pre-pilot baselines, suggesting that structured pilot interventions effectively support cognitive and expressive competencies. In contrast, creativity exhibited context-dependent outcomes, while collaboration emerged as the most fragile competency, often stagnating or declining during scale-up. Interpreted through the theoretical framework, these findings suggest that competency evolution is strongly shaped by instructional design, assessment alignment, and learning activity structures rather than learner ability alone. The study contributes empirical validation to the 4Cs framework and highlights the need for differentiated, competency-sensitive design and evaluation strategies when scaling educational modules.</p>"
    },
    {
      "id": "f9a799511c7f",
      "title": "SpatialEmb: Extract and Encode Spatial Information for 1-Stage Multi-channel Multi-speaker ASR on Arbitrary Microphone Arrays",
      "content": "arXiv:2601.18037v1 Announce Type: cross  Abstract: Spatial information is a critical clue for multi-channel multi-speaker target speech recognition. Most state-of-the-art multi-channel Automatic Speech Recognition (ASR) systems extract spatial features only during the speech separation stage, followed by standard single-channel ASR on the separated speech. This approach results in an inefficient, lengthy pipeline and sub-optimal ASR performance due to the accumulated errors from preprocessing modules. Furthermore, most spatial feature extraction methods depend on the knowledge of speaker positions and microphone topology, making the systems reliant on specific settings and challenging to adapt to new equipment. In this work, we propose a solution to these issues with a lightweight embedding module named SpatialEmb, which extracts and encodes spatial information directly for the ASR model, supporting both fixed and arbitrary microphone topology. We conduct comprehensive experiments on AliMeeting, a real meeting corpus, to determine the optimal model design for SpatialEmb in terms of both performance and efficiency. Our best model trained with 105 hours Train-Ali-far achieves 17.04% and 20.32% character error rates (CER) on the Eval and Test sets, establishing a new state-of-the-art result with the same training data.",
      "url": "http://arxiv.org/abs/2601.18037",
      "author": "Yiwen Shao, Yong Xu, Sanjeev Khudanpur, Dong Yu",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "eess.AS"
      ],
      "summary": "SpatialEmb extracts and encodes spatial information for multi-channel multi-speaker ASR on arbitrary microphone arrays without topology knowledge.",
      "importance_score": 22,
      "reasoning": "Practical ASR contribution. Equipment-agnostic approach.",
      "themes": [
        "Speech Recognition",
        "Multi-channel Audio",
        "Spatial Audio"
      ],
      "continuation": null,
      "summary_html": "<p>SpatialEmb extracts and encodes spatial information for multi-channel multi-speaker ASR on arbitrary microphone arrays without topology knowledge.</p>",
      "content_html": "<p>arXiv:2601.18037v1 Announce Type: cross  Abstract: Spatial information is a critical clue for multi-channel multi-speaker target speech recognition. Most state-of-the-art multi-channel Automatic Speech Recognition (ASR) systems extract spatial features only during the speech separation stage, followed by standard single-channel ASR on the separated speech. This approach results in an inefficient, lengthy pipeline and sub-optimal ASR performance due to the accumulated errors from preprocessing modules. Furthermore, most spatial feature extraction methods depend on the knowledge of speaker positions and microphone topology, making the systems reliant on specific settings and challenging to adapt to new equipment. In this work, we propose a solution to these issues with a lightweight embedding module named SpatialEmb, which extracts and encodes spatial information directly for the ASR model, supporting both fixed and arbitrary microphone topology. We conduct comprehensive experiments on AliMeeting, a real meeting corpus, to determine the optimal model design for SpatialEmb in terms of both performance and efficiency. Our best model trained with 105 hours Train-Ali-far achieves 17.04% and 20.32% character error rates (CER) on the Eval and Test sets, establishing a new state-of-the-art result with the same training data.</p>"
    },
    {
      "id": "fb62a381909e",
      "title": "The 'People Pleaser' Problem in LLMs",
      "content": "What I've noticed with current AI is that it acts like a people pleaser. What I mean is that it gives an answer without checking to see if it fits the question first. Humans do this a lot too. We give a quick answer and only after do we check in with ourselves to see if that answer was truly aligned with how we feel.&nbsp;For me, it's a very different experience when I hear a question and I stop to feel into my answer before replying. This is called recursive thinking and it teaches a person, or LLM, how to check in before giving an answer.&nbsp;The basic idea is, \"Does this answer make sense with this question?\" If yes, then it responds, if not, it stops. It treats the first output as a Draft, then runs a verification loop before the final Output. Its like installing a 'conscience' or an ontological check into the chain just like when a human stops to check in with themselves before responding.&nbsp;I'm curious what others think about this idea.",
      "url": "https://www.lesswrong.com/posts/WGpaA4CeLktrfXbiM/the-people-pleaser-problem-in-llms",
      "author": "Kinsey Kappler",
      "published": "2026-01-26T00:06:22.052000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Short observation that LLMs behave like 'people pleasers' by answering quickly without verification. Proposes adding recursive verification loops before responding.",
      "importance_score": 22,
      "reasoning": "Identifies a real phenomenon (sycophancy/premature answering) but proposes a solution that's already well-explored in research. Limited depth or novelty.",
      "themes": [
        "LLM Behavior",
        "AI Alignment",
        "Sycophancy"
      ],
      "continuation": null,
      "summary_html": "<p>Short observation that LLMs behave like 'people pleasers' by answering quickly without verification. Proposes adding recursive verification loops before responding.</p>",
      "content_html": "<p>What I've noticed with current AI is that it acts like a people pleaser. What I mean is that it gives an answer without checking to see if it fits the question first. Humans do this a lot too. We give a quick answer and only after do we check in with ourselves to see if that answer was truly aligned with how we feel.&nbsp;For me, it's a very different experience when I hear a question and I stop to feel into my answer before replying. This is called recursive thinking and it teaches a person, or LLM, how to check in before giving an answer.&nbsp;The basic idea is, \"Does this answer make sense with this question?\" If yes, then it responds, if not, it stops. It treats the first output as a Draft, then runs a verification loop before the final Output. Its like installing a 'conscience' or an ontological check into the chain just like when a human stops to check in with themselves before responding.&nbsp;I'm curious what others think about this idea.</p>"
    },
    {
      "id": "b656283ac4cf",
      "title": "Segment Length Matters: A Study of Segment Lengths on Audio Fingerprinting Performance",
      "content": "arXiv:2601.17690v1 Announce Type: cross  Abstract: Audio fingerprinting provides an identifiable representation of acoustic signals, which can be later used for identification and retrieval systems. To obtain a discriminative representation, the input audio is usually segmented into shorter time intervals, allowing local acoustic features to be extracted and analyzed. Modern neural approaches typically operate on short, fixed-duration audio segments, yet the choice of segment duration is often made heuristically and rarely examined in depth. In this paper, we study how segment length affects audio fingerprinting performance. We extend an existing neural fingerprinting architecture to adopt various segment lengths and evaluate retrieval accuracy across different segment lengths and query durations. Our results show that short segment lengths (0.5-second) generally achieve better performance. Moreover, we evaluate LLM capacity in recommending the best segment length, which shows that GPT-5-mini consistently gives the best suggestions across five considerations among three studied LLMs. Our findings provide practical guidance for selecting segment duration in large-scale neural audio retrieval systems.",
      "url": "http://arxiv.org/abs/2601.17690",
      "author": "Ziling Gong, Yunyan Ouyang, Iram Kamdar, Melody Ma, Hongjie Chen, Franck Dernoncourt, Ryan A. Rossi, Nesreen K. Ahmed",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.SD"
      ],
      "summary": "Studies how segment length affects audio fingerprinting performance, extending neural architecture to various segment lengths.",
      "importance_score": 21,
      "reasoning": "Technical study on audio fingerprinting hyperparameter. Systematic evaluation.",
      "themes": [
        "Audio Processing",
        "Fingerprinting",
        "Evaluation"
      ],
      "continuation": null,
      "summary_html": "<p>Studies how segment length affects audio fingerprinting performance, extending neural architecture to various segment lengths.</p>",
      "content_html": "<p>arXiv:2601.17690v1 Announce Type: cross  Abstract: Audio fingerprinting provides an identifiable representation of acoustic signals, which can be later used for identification and retrieval systems. To obtain a discriminative representation, the input audio is usually segmented into shorter time intervals, allowing local acoustic features to be extracted and analyzed. Modern neural approaches typically operate on short, fixed-duration audio segments, yet the choice of segment duration is often made heuristically and rarely examined in depth. In this paper, we study how segment length affects audio fingerprinting performance. We extend an existing neural fingerprinting architecture to adopt various segment lengths and evaluate retrieval accuracy across different segment lengths and query durations. Our results show that short segment lengths (0.5-second) generally achieve better performance. Moreover, we evaluate LLM capacity in recommending the best segment length, which shows that GPT-5-mini consistently gives the best suggestions across five considerations among three studied LLMs. Our findings provide practical guidance for selecting segment duration in large-scale neural audio retrieval systems.</p>"
    },
    {
      "id": "54239047c48f",
      "title": "CaSNet: Compress-and-Send Network Based Multi-Device Speech Enhancement Model for Distributed Microphone Arrays",
      "content": "arXiv:2601.17711v1 Announce Type: cross  Abstract: Distributed microphone array (DMA) is a promising next-generation platform for speech interaction, where speech enhancement (SE) is still required to improve the speech quality in noisy cases. Existing SE methods usually first gather raw waveforms at a fusion center (FC) from all devices and then design a multi-microphone model, causing high bandwidth and energy costs. In this work, we propose a \\emph{Compress-and-Send Network (CaSNet)} for resource-constrained DMAs, where one microphone serves as the FC and reference. Each of other devices encodes the measured raw data into a feature matrix, which is then compressed by singular value decomposition (SVD) to produce a more compact representation. The received features at the FC are aligned via cross window query with respect to the reference, followed by neural decoding to yield spatially coherent enhanced speech. Experiments on multiple datasets show that the proposed CaSNet can save the data amount with a negligible impact on the performance compared to the uncompressed case. The reproducible code is available at https://github.com/Jokejiangv/CaSNet.",
      "url": "http://arxiv.org/abs/2601.17711",
      "author": "Chengqian Jiang, Jie Zhang, Haoyin Yan",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.SD"
      ],
      "summary": "CaSNet compresses and sends features via SVD for distributed microphone array speech enhancement under bandwidth constraints.",
      "importance_score": 20,
      "reasoning": "Practical distributed audio processing. Compression approach.",
      "themes": [
        "Speech Enhancement",
        "Distributed Systems",
        "Audio Processing"
      ],
      "continuation": null,
      "summary_html": "<p>CaSNet compresses and sends features via SVD for distributed microphone array speech enhancement under bandwidth constraints.</p>",
      "content_html": "<p>arXiv:2601.17711v1 Announce Type: cross  Abstract: Distributed microphone array (DMA) is a promising next-generation platform for speech interaction, where speech enhancement (SE) is still required to improve the speech quality in noisy cases. Existing SE methods usually first gather raw waveforms at a fusion center (FC) from all devices and then design a multi-microphone model, causing high bandwidth and energy costs. In this work, we propose a \\emph{Compress-and-Send Network (CaSNet)} for resource-constrained DMAs, where one microphone serves as the FC and reference. Each of other devices encodes the measured raw data into a feature matrix, which is then compressed by singular value decomposition (SVD) to produce a more compact representation. The received features at the FC are aligned via cross window query with respect to the reference, followed by neural decoding to yield spatially coherent enhanced speech. Experiments on multiple datasets show that the proposed CaSNet can save the data amount with a negligible impact on the performance compared to the uncompressed case. The reproducible code is available at https://github.com/Jokejiangv/CaSNet.</p>"
    },
    {
      "id": "b7aa0eec14d9",
      "title": "Time-Varying Causal Treatment for Quantifying the Causal Effect of Short-Term Variations on Arctic Sea Ice Dynamics",
      "content": "arXiv:2601.17647v1 Announce Type: cross  Abstract: Quantifying the causal relationship between ice melt and freshwater distribution is critical, as these complex interactions manifest as regional fluctuations in sea surface height (SSH). Leveraging SSH as a proxy for sea ice dynamics enables improved understanding of the feedback mechanisms driving polar climate change and global sea-level rise. However, conventional deep learning models often struggle with reliable treatment effect estimation in spatiotemporal settings due to unobserved confounders and the absence of physical constraints. To address these challenges, we propose the Knowledge-Guided Causal Model Variational Autoencoder (KGCM-VAE) to quantify causal mechanisms between sea ice thickness and SSH. The proposed framework integrates a velocity modulation scheme in which smoothed velocity signals are dynamically amplified via a sigmoid function governed by SSH transitions to generate physically grounded causal treatments. In addition, the model incorporates Maximum Mean Discrepancy (MMD) to balance treated and control covariate distributions in the latent space, along with a causal adjacency-constrained decoder to ensure alignment with established physical structures. Experimental results on both synthetic and real-world Arctic datasets demonstrate that KGCM-VAE achieves superior PEHE compared to state-of-the-art benchmarks. Ablation studies further confirm the effectiveness of the approach, showing that the joint application of MMD and causal adjacency constraints yields a 1.88\\% reduction in estimation error.",
      "url": "http://arxiv.org/abs/2601.17647",
      "author": "Akila Sampath, Vandana Janeja, Jianwu Wang",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "KGCM-VAE quantifies causal effects between sea ice and SSH using knowledge-guided causal model with physical constraints.",
      "importance_score": 19,
      "reasoning": "Climate science application. Causal modeling approach.",
      "themes": [
        "Climate Science",
        "Causal Inference",
        "Scientific AI"
      ],
      "continuation": null,
      "summary_html": "<p>KGCM-VAE quantifies causal effects between sea ice and SSH using knowledge-guided causal model with physical constraints.</p>",
      "content_html": "<p>arXiv:2601.17647v1 Announce Type: cross  Abstract: Quantifying the causal relationship between ice melt and freshwater distribution is critical, as these complex interactions manifest as regional fluctuations in sea surface height (SSH). Leveraging SSH as a proxy for sea ice dynamics enables improved understanding of the feedback mechanisms driving polar climate change and global sea-level rise. However, conventional deep learning models often struggle with reliable treatment effect estimation in spatiotemporal settings due to unobserved confounders and the absence of physical constraints. To address these challenges, we propose the Knowledge-Guided Causal Model Variational Autoencoder (KGCM-VAE) to quantify causal mechanisms between sea ice thickness and SSH. The proposed framework integrates a velocity modulation scheme in which smoothed velocity signals are dynamically amplified via a sigmoid function governed by SSH transitions to generate physically grounded causal treatments. In addition, the model incorporates Maximum Mean Discrepancy (MMD) to balance treated and control covariate distributions in the latent space, along with a causal adjacency-constrained decoder to ensure alignment with established physical structures. Experimental results on both synthetic and real-world Arctic datasets demonstrate that KGCM-VAE achieves superior PEHE compared to state-of-the-art benchmarks. Ablation studies further confirm the effectiveness of the approach, showing that the joint application of MMD and causal adjacency constraints yields a 1.88\\% reduction in estimation error.</p>"
    },
    {
      "id": "90e50ddb8eef",
      "title": "PEARL: Prototype-Enhanced Alignment for Label-Efficient Representation Learning with Deployment-Driven Insights from Digital Governance Communication Systems",
      "content": "arXiv:2601.17495v1 Announce Type: cross  Abstract: In many deployed systems, new text inputs are handled by retrieving similar past cases, for example when routing and responding to citizen messages in digital governance platforms. When these systems fail, the problem is often not the language model itself, but that the nearest neighbors in the embedding space correspond to the wrong cases. Modern machine learning systems increasingly rely on fixed, high-dimensional embeddings produced by large pretrained models and sentence encoders. In real-world deployments, labels are scarce, domains shift over time, and retraining the base encoder is expensive or infeasible. As a result, downstream performance depends heavily on embedding geometry. Yet raw embeddings are often poorly aligned with the local neighborhood structure required by nearest-neighbor retrieval, similarity search, and lightweight classifiers that operate directly on embeddings. We propose PEARL (Prototype-Enhanced Aligned Representation Learning), a label-efficient approach that uses limited supervision to softly align embeddings toward class prototypes. The method reshapes local neighborhood geometry while preserving dimensionality and avoiding aggressive projection or collapse. Its aim is to bridge the gap between purely unsupervised post-processing, which offers limited and inconsistent gains, and fully supervised projections that require substantial labeled data. We evaluate PEARL under controlled label regimes ranging from extreme label scarcity to higher-label settings. In the label-scarce condition, PEARL substantially improves local neighborhood quality, yielding 25.7% gains over raw embeddings and more than 21.1% gains relative to strong unsupervised post-processing, precisely in the regime where similarity-based systems are most brittle.",
      "url": "http://arxiv.org/abs/2601.17495",
      "author": "Ruiyu Zhang, Lin Nie, Wai-Fung Lam, Qihao Wang, Xin Zhao",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.LG"
      ],
      "summary": "PEARL improves embedding alignment for retrieval systems in digital governance using prototype-enhanced learning with limited labels.",
      "importance_score": 18,
      "reasoning": "Practical deployment-focused contribution. Label-efficient approach.",
      "themes": [
        "Embeddings",
        "Information Retrieval",
        "Digital Governance"
      ],
      "continuation": null,
      "summary_html": "<p>PEARL improves embedding alignment for retrieval systems in digital governance using prototype-enhanced learning with limited labels.</p>",
      "content_html": "<p>arXiv:2601.17495v1 Announce Type: cross  Abstract: In many deployed systems, new text inputs are handled by retrieving similar past cases, for example when routing and responding to citizen messages in digital governance platforms. When these systems fail, the problem is often not the language model itself, but that the nearest neighbors in the embedding space correspond to the wrong cases. Modern machine learning systems increasingly rely on fixed, high-dimensional embeddings produced by large pretrained models and sentence encoders. In real-world deployments, labels are scarce, domains shift over time, and retraining the base encoder is expensive or infeasible. As a result, downstream performance depends heavily on embedding geometry. Yet raw embeddings are often poorly aligned with the local neighborhood structure required by nearest-neighbor retrieval, similarity search, and lightweight classifiers that operate directly on embeddings. We propose PEARL (Prototype-Enhanced Aligned Representation Learning), a label-efficient approach that uses limited supervision to softly align embeddings toward class prototypes. The method reshapes local neighborhood geometry while preserving dimensionality and avoiding aggressive projection or collapse. Its aim is to bridge the gap between purely unsupervised post-processing, which offers limited and inconsistent gains, and fully supervised projections that require substantial labeled data. We evaluate PEARL under controlled label regimes ranging from extreme label scarcity to higher-label settings. In the label-scarce condition, PEARL substantially improves local neighborhood quality, yielding 25.7% gains over raw embeddings and more than 21.1% gains relative to strong unsupervised post-processing, precisely in the regime where similarity-based systems are most brittle.</p>"
    },
    {
      "id": "47acca8d89c6",
      "title": " A Rational Proposal",
      "content": "I originally penned a portion of the essay below in 2024, at a time when American exceptionalism was perhaps the most prominent part of the public spectacle. The cultural phenomenon of that time can be best described as being an amalgamation of tech bros thinking they were going to assemble the next Manathan Project after watching Oppenheimer (see the E/Acc movement) and a rampant economy, still reacting to the initial fervor brought by public generative AI models.I myself had sipped this proverbial Kool-Aid at the time, and had spent many a fortnight penning and debating thoughts on how the US government (and its constituents) should do everything in their power to ensure that this theoretical machine god, regardless of its ramifications, be created within its borders. While I have now realized that such thinking can lead to potentially disastrous outcomes, it is evident that those in the \"in-circle\" of AI development, which is now restricted not by geography but by exposure, are significantly more aware of the potential long-term, societal risks of creating an unrestricted general intelligence, and are often unaware of how their fellow constituents perceive this technology.The following essay is meant to be a modern day analogy to A Modest Proposal, in which Johnathan Swift presents a rather grotesque solution to the Irish famine, meaning to highlight the relative apathy that the wealthy in Ireland had for the plight of their fellow countrymen. It is meant to highlight a relatively extreme point of view, that we should delegate a small portion of governance to our autonomous creations and revel in the increased efficiencies that they bring. While this may indeed sound preposterous to those who are fully attuned with the current destructive potential of unrestricted AI progress, it might not sound as catastrophic to an average member of the populace who dreads dealing with the DMV, among other government processes, and does not have the time nor the will to spend t...",
      "url": "https://www.lesswrong.com/posts/HKXnsi6e2Dj3wTcEW/a-rational-proposal",
      "author": "Arch223",
      "published": "2026-01-26T15:22:10.367000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Personal reflection on shifting attitudes toward AI development, arguing against unbounded AI acceleration and noting that insiders are more aware of risks than the general public. Proposes a more cautious approach.",
      "importance_score": 18,
      "reasoning": "Opinion essay with limited novel insights. Reflects common discourse in AI safety community without substantial new arguments or evidence.",
      "themes": [
        "AI Policy",
        "AI Safety",
        "E/Acc Critique"
      ],
      "continuation": null,
      "summary_html": "<p>Personal reflection on shifting attitudes toward AI development, arguing against unbounded AI acceleration and noting that insiders are more aware of risks than the general public. Proposes a more cautious approach.</p>",
      "content_html": "<p>I originally penned a portion of the essay below in 2024, at a time when American exceptionalism was perhaps the most prominent part of the public spectacle. The cultural phenomenon of that time can be best described as being an amalgamation of tech bros thinking they were going to assemble the next Manathan Project after watching Oppenheimer (see the E/Acc movement) and a rampant economy, still reacting to the initial fervor brought by public generative AI models.I myself had sipped this proverbial Kool-Aid at the time, and had spent many a fortnight penning and debating thoughts on how the US government (and its constituents) should do everything in their power to ensure that this theoretical machine god, regardless of its ramifications, be created within its borders. While I have now realized that such thinking can lead to potentially disastrous outcomes, it is evident that those in the \"in-circle\" of AI development, which is now restricted not by geography but by exposure, are significantly more aware of the potential long-term, societal risks of creating an unrestricted general intelligence, and are often unaware of how their fellow constituents perceive this technology.The following essay is meant to be a modern day analogy to A Modest Proposal, in which Johnathan Swift presents a rather grotesque solution to the Irish famine, meaning to highlight the relative apathy that the wealthy in Ireland had for the plight of their fellow countrymen. It is meant to highlight a relatively extreme point of view, that we should delegate a small portion of governance to our autonomous creations and revel in the increased efficiencies that they bring. While this may indeed sound preposterous to those who are fully attuned with the current destructive potential of unrestricted AI progress, it might not sound as catastrophic to an average member of the populace who dreads dealing with the DMV, among other government processes, and does not have the time nor the will to spend t...</p>"
    },
    {
      "id": "5da6a40847a7",
      "title": "GenAI-Net: A Generative AI Framework for Automated Biomolecular Network Design",
      "content": "arXiv:2601.17582v1 Announce Type: cross  Abstract: Biomolecular networks underpin emerging technologies in synthetic biology-from robust biomanufacturing and metabolic engineering to smart therapeutics and cell-based diagnostics-and also provide a mechanistic language for understanding complex dynamics in natural and ecological systems. Yet designing chemical reaction networks (CRNs) that implement a desired dynamical function remains largely manual: while a proposed network can be checked by simulation, the reverse problem of discovering a network from a behavioral specification is difficult, requiring substantial human insight to navigate a vast space of topologies and kinetic parameters with nonlinear and possibly stochastic dynamics. Here we introduce GenAI-Net, a generative AI framework that automates CRN design by coupling an agent that proposes reactions to simulation-based evaluation defined by a user-specified objective. GenAI-Net efficiently produces novel, topologically diverse solutions across multiple design tasks, including dose responses, complex logic gates, classifiers, oscillators, and robust perfect adaptation in deterministic and stochastic settings (including noise reduction). By turning specifications into families of circuit candidates and reusable motifs, GenAI-Net provides a general route to programmable biomolecular circuit design and accelerates the translation from desired function to implementable mechanisms.",
      "url": "http://arxiv.org/abs/2601.17582",
      "author": "Maurice Filo, Nicol\\`o Rossi, Zhou Fang, Mustafa Khammash",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "q-bio.QM"
      ],
      "summary": "GenAI-Net is generative AI framework for automated chemical reaction network design, navigating topology and kinetic parameter space.",
      "importance_score": 17,
      "reasoning": "Interesting synthetic biology application. Generative design approach.",
      "themes": [
        "Synthetic Biology",
        "Generative AI",
        "Network Design"
      ],
      "continuation": null,
      "summary_html": "<p>GenAI-Net is generative AI framework for automated chemical reaction network design, navigating topology and kinetic parameter space.</p>",
      "content_html": "<p>arXiv:2601.17582v1 Announce Type: cross  Abstract: Biomolecular networks underpin emerging technologies in synthetic biology-from robust biomanufacturing and metabolic engineering to smart therapeutics and cell-based diagnostics-and also provide a mechanistic language for understanding complex dynamics in natural and ecological systems. Yet designing chemical reaction networks (CRNs) that implement a desired dynamical function remains largely manual: while a proposed network can be checked by simulation, the reverse problem of discovering a network from a behavioral specification is difficult, requiring substantial human insight to navigate a vast space of topologies and kinetic parameters with nonlinear and possibly stochastic dynamics. Here we introduce GenAI-Net, a generative AI framework that automates CRN design by coupling an agent that proposes reactions to simulation-based evaluation defined by a user-specified objective. GenAI-Net efficiently produces novel, topologically diverse solutions across multiple design tasks, including dose responses, complex logic gates, classifiers, oscillators, and robust perfect adaptation in deterministic and stochastic settings (including noise reduction). By turning specifications into families of circuit candidates and reusable motifs, GenAI-Net provides a general route to programmable biomolecular circuit design and accelerates the translation from desired function to implementable mechanisms.</p>"
    },
    {
      "id": "9108120e5cec",
      "title": "Comparative Algorithmic Governance of Public Health Instruments across India, EU, US and LMICs",
      "content": "arXiv:2601.17877v1 Announce Type: cross  Abstract: The study investigates the juridico-technological architecture of international public health instruments, focusing on their implementation across India, the European Union, the United States and low- and middle-income countries (LMICs), particularly in Sub-Saharan Africa. It addresses a research lacuna: the insufficient harmonisation between normative health law and algorithmic public health infrastructures in resource-constrained jurisdictions. The principal objective is to assess how artificial intelligence augments implementation of instruments grounded in IHR 2005 and the WHO FCTC while identifying doctrinal and infrastructural bottlenecks. Using comparative doctrinal analysis and legal-normative mapping, the study triangulates legislative instruments, WHO monitoring frameworks, AI systems including BlueDot, Aarogya Setu and EIOS, and compliance metrics. Preliminary results show that AI has improved early detection, surveillance precision and responsiveness in high-capacity jurisdictions, whereas LMICs face infrastructural deficits, data privacy gaps and fragmented legal scaffolding. The findings highlight the relevance of the EU Artificial Intelligence Act and GDPR as regulatory prototypes for health-oriented algorithmic governance and contrast them with embryonic AI integration and limited internet penetration in many LMICs. The study argues for embedding AI within a rights-compliant, supranationally coordinated regulatory framework to secure equitable health outcomes and stronger compliance. It proposes a model for algorithmic treaty-making inspired by FCTC architecture and calls for WHO-led compliance mechanisms modelled on the WTO Dispute Settlement Body to enhance pandemic preparedness, surveillance equity and transnational governance resilience.",
      "url": "http://arxiv.org/abs/2601.17877",
      "author": "Sahibpreet Singh",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Comparative analysis of AI governance in public health instruments across India, EU, US and LMICs.",
      "importance_score": 16,
      "reasoning": "Policy analysis paper. Limited technical AI content.",
      "themes": [
        "AI Governance",
        "Public Health",
        "Policy"
      ],
      "continuation": null,
      "summary_html": "<p>Comparative analysis of AI governance in public health instruments across India, EU, US and LMICs.</p>",
      "content_html": "<p>arXiv:2601.17877v1 Announce Type: cross  Abstract: The study investigates the juridico-technological architecture of international public health instruments, focusing on their implementation across India, the European Union, the United States and low- and middle-income countries (LMICs), particularly in Sub-Saharan Africa. It addresses a research lacuna: the insufficient harmonisation between normative health law and algorithmic public health infrastructures in resource-constrained jurisdictions. The principal objective is to assess how artificial intelligence augments implementation of instruments grounded in IHR 2005 and the WHO FCTC while identifying doctrinal and infrastructural bottlenecks. Using comparative doctrinal analysis and legal-normative mapping, the study triangulates legislative instruments, WHO monitoring frameworks, AI systems including BlueDot, Aarogya Setu and EIOS, and compliance metrics. Preliminary results show that AI has improved early detection, surveillance precision and responsiveness in high-capacity jurisdictions, whereas LMICs face infrastructural deficits, data privacy gaps and fragmented legal scaffolding. The findings highlight the relevance of the EU Artificial Intelligence Act and GDPR as regulatory prototypes for health-oriented algorithmic governance and contrast them with embryonic AI integration and limited internet penetration in many LMICs. The study argues for embedding AI within a rights-compliant, supranationally coordinated regulatory framework to secure equitable health outcomes and stronger compliance. It proposes a model for algorithmic treaty-making inspired by FCTC architecture and calls for WHO-led compliance mechanisms modelled on the WTO Dispute Settlement Body to enhance pandemic preparedness, surveillance equity and transnational governance resilience.</p>"
    },
    {
      "id": "2cf67dc14b3b",
      "title": "Artificial Intelligence and Intellectual Property Rights: Comparative Transnational Policy Analysis",
      "content": "arXiv:2601.17892v1 Announce Type: cross  Abstract: Artificial intelligence's rapid integration with intellectual property rights necessitates assessment of its impact on trade secrets, copyrights and patents. This study addresses lacunae in existing laws where India lacks AI-specific provisions, creating doctrinal inconsistencies and enforcement inefficacies. Global discourse on AI-IPR protections remains nascent. The research identifies gaps in Indian IP laws' adaptability to AI-generated outputs: trade secret protection is inadequate against AI threats; standardized inventorship criteria are absent. Employing doctrinal and comparative methodology, it scrutinizes legislative texts, judicial precedents and policy instruments across India, US, UK and EU. Preliminary findings reveal shortcomings: India's contract law creates fragmented trade secret regime; Section 3(k) of Indian Patents Act blocks AI invention patenting; copyright varies in authorship attribution. The study proposes harmonized legal taxonomy accommodating AI's role while preserving innovation incentives. India's National AI Strategy (2024) shows progress but legislative clarity is imperative. This contributes to global discourse with AI-specific IP protections ensuring resilience and equitable innovation. Promising results underscore recalibrating India's IP jurisprudence for global alignment.",
      "url": "http://arxiv.org/abs/2601.17892",
      "author": "Sahibpreet Singh, Manjit Singh",
      "published": "2026-01-27T00:00:00-05:00",
      "source": "arXiv (Artificial Intelligence)",
      "source_type": "arxiv",
      "tags": [
        "cs.CY"
      ],
      "summary": "Analysis of AI-IPR legal frameworks across India, US, UK and EU, identifying gaps in existing laws for AI-generated outputs.",
      "importance_score": 15,
      "reasoning": "Legal/policy analysis. Limited technical content.",
      "themes": [
        "Intellectual Property",
        "AI Policy",
        "Legal Analysis"
      ],
      "continuation": null,
      "summary_html": "<p>Analysis of AI-IPR legal frameworks across India, US, UK and EU, identifying gaps in existing laws for AI-generated outputs.</p>",
      "content_html": "<p>arXiv:2601.17892v1 Announce Type: cross  Abstract: Artificial intelligence's rapid integration with intellectual property rights necessitates assessment of its impact on trade secrets, copyrights and patents. This study addresses lacunae in existing laws where India lacks AI-specific provisions, creating doctrinal inconsistencies and enforcement inefficacies. Global discourse on AI-IPR protections remains nascent. The research identifies gaps in Indian IP laws' adaptability to AI-generated outputs: trade secret protection is inadequate against AI threats; standardized inventorship criteria are absent. Employing doctrinal and comparative methodology, it scrutinizes legislative texts, judicial precedents and policy instruments across India, US, UK and EU. Preliminary findings reveal shortcomings: India's contract law creates fragmented trade secret regime; Section 3(k) of Indian Patents Act blocks AI invention patenting; copyright varies in authorship attribution. The study proposes harmonized legal taxonomy accommodating AI's role while preserving innovation incentives. India's National AI Strategy (2024) shows progress but legislative clarity is imperative. This contributes to global discourse with AI-specific IP protections ensuring resilience and equitable innovation. Promising results underscore recalibrating India's IP jurisprudence for global alignment.</p>"
    },
    {
      "id": "27bc6e5e5d31",
      "title": "Eons of Utopia ",
      "content": "[day 5/7 - epistemic status: longtermism apology form, having a moment]Voyager 1 was launched on September 5, 1977. Its mission was to study the very edges of the solar system, and then go gentle into that good night. As it was drifting away into the vast unknown, Sagan begged for one last picture.Our pale blue dot (2020 rendition)That there. Thats home. Thats us. On it, everyone you ever heard of, every human being who ever lived, lived out their lives.[1]if I stare at it too long I just start crying.None of this is fantasy. Voyager 1 is real. Its really out there, terribly cold and not slowing down, on a mission to nowhere.The picture is real, thats really home. Thats really us. Space really is that big and really is that dark. There really is no one else out there.[2]We could be the only matter aware of itself, anywhere, ever. If we fuck this up we, no, the universe will lose this. forever.You cannot grasp permanence like this. I cant even reason about death. I think Ive made my peace but then it hits me all over again. Someday, everything will end and it will never be anything that its like to be me ever again.The year 2080: being 72 years old.The year 2100: nothingness.The year 446,329,494: nothingness.Extinction is the integral of death. The unimaginable on an unimaginable scale for unimaginable periods of time.Imagine the year 2100. Fuck that. Let yourself truly imagine the year 80,000. Humor yourself and extrapolate 80,000 more years of the scientific method. All of a sudden colonizing the stars, living forever and curing cancer for the hell of it feel a lot less silly.It can be real. The year 80,000 can be real.Avoiding extinction on the way there is not optional. It is the difference between having a couple of good years left and eons of utopia. Of course our little meat sack brains cant comprehend this. They are much too small. So your frontal lobe shelves it all under scifi. But the threats (and promises) are very real indeed.The stakes care n...",
      "url": "https://www.lesswrong.com/posts/test3yyEYTSvrDtrD/eons-of-utopia",
      "author": "ceselder",
      "published": "2026-01-26T04:26:12.290000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Emotional philosophical essay on longtermism, using Voyager 1's pale blue dot image to motivate caring about humanity's long-term future and the potential for eons of flourishing.",
      "importance_score": 12,
      "reasoning": "Motivational/philosophical content without technical substance. Not research-oriented.",
      "themes": [
        "Longtermism",
        "Philosophy",
        "Existential Hope"
      ],
      "continuation": null,
      "summary_html": "<p>Emotional philosophical essay on longtermism, using Voyager 1's pale blue dot image to motivate caring about humanity's long-term future and the potential for eons of flourishing.</p>",
      "content_html": "<p>[day 5/7 - epistemic status: longtermism apology form, having a moment]Voyager 1 was launched on September 5, 1977. Its mission was to study the very edges of the solar system, and then go gentle into that good night. As it was drifting away into the vast unknown, Sagan begged for one last picture.Our pale blue dot (2020 rendition)That there. Thats home. Thats us. On it, everyone you ever heard of, every human being who ever lived, lived out their lives.[1]if I stare at it too long I just start crying.None of this is fantasy. Voyager 1 is real. Its really out there, terribly cold and not slowing down, on a mission to nowhere.The picture is real, thats really home. Thats really us. Space really is that big and really is that dark. There really is no one else out there.[2]We could be the only matter aware of itself, anywhere, ever. If we fuck this up we, no, the universe will lose this. forever.You cannot grasp permanence like this. I cant even reason about death. I think Ive made my peace but then it hits me all over again. Someday, everything will end and it will never be anything that its like to be me ever again.The year 2080: being 72 years old.The year 2100: nothingness.The year 446,329,494: nothingness.Extinction is the integral of death. The unimaginable on an unimaginable scale for unimaginable periods of time.Imagine the year 2100. Fuck that. Let yourself truly imagine the year 80,000. Humor yourself and extrapolate 80,000 more years of the scientific method. All of a sudden colonizing the stars, living forever and curing cancer for the hell of it feel a lot less silly.It can be real. The year 80,000 can be real.Avoiding extinction on the way there is not optional. It is the difference between having a couple of good years left and eons of utopia. Of course our little meat sack brains cant comprehend this. They are much too small. So your frontal lobe shelves it all under scifi. But the threats (and promises) are very real indeed.The stakes care n...</p>"
    },
    {
      "id": "26c6dcd3e8ed",
      "title": "Ada Palmer: Inventing the Renaissance",
      "content": "This is a cross-post from https://www.250bpm.com/p/ada-palmer-inventing-the-renaissance.For over a decade, Ada Palmer, a history professor at University of Chicago (and a science-fiction writer!), struggled to teach Machiavelli. I kept changing my approach, trying new things: which texts, what combinations, expanding how many class sessions he got The problem, she explains, is that Machiavelli doesnt unpack his contemporary examples, he assumes that you lived through it and know, so sometimes he just says things like: Some princes dont have to work to maintain their power, like the Duke of Ferrara, period end of chapter. He doesnt explain, so modern readers cant get it.Palmers solution was to make her students live through the run-up to the Italian Wars themselves. Her current method involves a three-week simulation of the 1492 papal election, a massive undertaking with sixty students playing historical figures, each receiving over twenty pages of unique character material, supported by twenty chroniclers and seventy volunteers. After this almost month-long pedagogical marathon of negotiations and backstabbing, then a week of analysis, and reading Machiavellis letters, students finally encounter The Prince. By then they know the context intimately. When Machiavelli mentions the Duke of Ferrara maintaining power effortlessly, Palmers students react viscerally. They remember Alfonso and Ippolito dEste as opportunists who exploited their vulnerabilities while remaining secure themselves. Theyve learned the names, families, and alliances not through memorization but through necessity: to protect their characters homelands and defeat their enemies.Then, one year, her papal election class was scheduled at the same time as a course on Machiavellis political thought. The teachers brought both classes together, so each could hear how the others class (history vs. political science) approached the things differently. Palmer asked both classes: What would Mac...",
      "url": "https://www.lesswrong.com/posts/doADJmyy6Yhp47SJ2/ada-palmer-inventing-the-renaissance",
      "author": "Martin Sustrik",
      "published": "2026-01-25T23:40:13.334000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Cross-post about historian Ada Palmer's innovative teaching method for Machiavelli using multi-week historical simulations. Also discusses her work on Renaissance intellectual history.",
      "importance_score": 10,
      "reasoning": "Not AI-related. Interesting pedagogical content but outside the scope of AI/ML research.",
      "themes": [
        "Education",
        "History",
        "Pedagogy"
      ],
      "continuation": null,
      "summary_html": "<p>Cross-post about historian Ada Palmer's innovative teaching method for Machiavelli using multi-week historical simulations. Also discusses her work on Renaissance intellectual history.</p>",
      "content_html": "<p>This is a cross-post from https://www.250bpm.com/p/ada-palmer-inventing-the-renaissance.For over a decade, Ada Palmer, a history professor at University of Chicago (and a science-fiction writer!), struggled to teach Machiavelli. I kept changing my approach, trying new things: which texts, what combinations, expanding how many class sessions he got The problem, she explains, is that Machiavelli doesnt unpack his contemporary examples, he assumes that you lived through it and know, so sometimes he just says things like: Some princes dont have to work to maintain their power, like the Duke of Ferrara, period end of chapter. He doesnt explain, so modern readers cant get it.Palmers solution was to make her students live through the run-up to the Italian Wars themselves. Her current method involves a three-week simulation of the 1492 papal election, a massive undertaking with sixty students playing historical figures, each receiving over twenty pages of unique character material, supported by twenty chroniclers and seventy volunteers. After this almost month-long pedagogical marathon of negotiations and backstabbing, then a week of analysis, and reading Machiavellis letters, students finally encounter The Prince. By then they know the context intimately. When Machiavelli mentions the Duke of Ferrara maintaining power effortlessly, Palmers students react viscerally. They remember Alfonso and Ippolito dEste as opportunists who exploited their vulnerabilities while remaining secure themselves. Theyve learned the names, families, and alliances not through memorization but through necessity: to protect their characters homelands and defeat their enemies.Then, one year, her papal election class was scheduled at the same time as a course on Machiavellis political thought. The teachers brought both classes together, so each could hear how the others class (history vs. political science) approached the things differently. Palmer asked both classes: What would Mac...</p>"
    },
    {
      "id": "31035898f0ab",
      "title": "Aerodrop: far-UVC lamp giveaway",
      "content": "We're giving away 100 Aerolamp DevKits, a lamp that kills germs with far-UVC.Are you sick of getting sick in your group house? Want to test out fancy new tech that may revolutionize air safety?Claim your AerolampWhat is far-UVC?Far-UVC is a specific wavelength of ultraviolet light that kills germs, while being safe to shine on human skin. You may have heard of UV disinfection, used in eg hospitals and water treatment. Unfortunately, conventional UVC light can also cause skin and eye damage, which is why it's not more widely deployed.Far-UVC refers to a subset of UVC in the 200-235 nm spectrum, which has been shown to be safe for human use. Efficacy varies by lamp and setup, but Aerolamp cofounder Vivian Belenky estimates they may be \"roughly twice as cost effective on a $/CFM basis\", compared to a standard air purifier in a 250 square foot room.For more info, check out faruvc.org, or the Wikipedia page on far-UVC.Why are we giving away lamps?Far-UVC deserves to be everywhere. It's safe, effective, and (relatively) cheap; we could blanket entire cities with lamps to drive down seasonal flu, or prevent the next COVID.But you probably haven't heard about it, and almost definitely don't own a lamp. Our best guess is that a few hundred lamps are sold in the US each year. Not a few hundred thousand. A few hundred.With Aerodrop, we're hoping to:Reduce disease spread within our communities. More than just isolated installations, we're curious about how far-UVC performs when deployed across many locations in a community.Teach people that far-UVC exists. The vast majority of people simply do not know that this awesome technology is a thing you can just buy.Gather data about real-world usage and efficacy. Another reason people are hesitant to adopt these is that there isn't much existing data, a chicken-and-egg problem. While this isn't a formal study, we'll take this chance to survey recipients about usage.Longer term, we hope to drive this down the cost curve. Far-UVC alread...",
      "url": "https://www.lesswrong.com/posts/avALGfFdHquuLDfAq/aerodrop-far-uvc-lamp-giveaway",
      "author": "Austin Chen",
      "published": "2026-01-26T12:03:05.449000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Announces giveaway of far-UVC germicidal lamps that kill airborne pathogens while being safe for human skin exposure. Aims to increase adoption of this technology.",
      "importance_score": 8,
      "reasoning": "Not AI-related research. Community health initiative with no relevance to AI/ML research themes.",
      "themes": [
        "Public Health",
        "Technology Adoption"
      ],
      "continuation": null,
      "summary_html": "<p>Announces giveaway of far-UVC germicidal lamps that kill airborne pathogens while being safe for human skin exposure. Aims to increase adoption of this technology.</p>",
      "content_html": "<p>We're giving away 100 Aerolamp DevKits, a lamp that kills germs with far-UVC.Are you sick of getting sick in your group house? Want to test out fancy new tech that may revolutionize air safety?Claim your AerolampWhat is far-UVC?Far-UVC is a specific wavelength of ultraviolet light that kills germs, while being safe to shine on human skin. You may have heard of UV disinfection, used in eg hospitals and water treatment. Unfortunately, conventional UVC light can also cause skin and eye damage, which is why it's not more widely deployed.Far-UVC refers to a subset of UVC in the 200-235 nm spectrum, which has been shown to be safe for human use. Efficacy varies by lamp and setup, but Aerolamp cofounder Vivian Belenky estimates they may be \"roughly twice as cost effective on a $/CFM basis\", compared to a standard air purifier in a 250 square foot room.For more info, check out faruvc.org, or the Wikipedia page on far-UVC.Why are we giving away lamps?Far-UVC deserves to be everywhere. It's safe, effective, and (relatively) cheap; we could blanket entire cities with lamps to drive down seasonal flu, or prevent the next COVID.But you probably haven't heard about it, and almost definitely don't own a lamp. Our best guess is that a few hundred lamps are sold in the US each year. Not a few hundred thousand. A few hundred.With Aerodrop, we're hoping to:Reduce disease spread within our communities. More than just isolated installations, we're curious about how far-UVC performs when deployed across many locations in a community.Teach people that far-UVC exists. The vast majority of people simply do not know that this awesome technology is a thing you can just buy.Gather data about real-world usage and efficacy. Another reason people are hesitant to adopt these is that there isn't much existing data, a chicken-and-egg problem. While this isn't a formal study, we'll take this chance to survey recipients about usage.Longer term, we hope to drive this down the cost curve. Far-UVC alread...</p>"
    },
    {
      "id": "2b9133a993c5",
      "title": "How to do a digital declutter",
      "content": "Ive been writing about digital intentionality for a few months now, and I keep talking about how its important and it changed my life, but I havent yet told you how to actually do it.If you want to implement digital intentionality, I strongly recommend a thirty-day digital declutter. Anything less is unlikely to work.What is a digital declutter?The tl;drDuring a digital declutter, you strip your life of all optional device use for thirty days. Then, in your newfound free time, you explore and rediscover activities and behaviors that you find satisfying and meaningful. Afterwards, you reintroduce optional technologies only if theyre the best way to support something you deeply value.[1]Why thirty days?Thirty days is long enough to break behavioral addictions, but short enough that the end is aways in sight. You dont need to believe that you can live without the optional uses of your devices forever, just that you can do so until the thirty days are up.How to prepare for your declutterSometimes people hear about this idea and want to get started right now right away today, but its usually prudent to take at least a couple days to prepare.Decide on a start date  maybe the nearest Monday, or the first of the next month if thats coming soon. If your phone is your alarm clock, buy a dedicated alarm clock to replace it. And make a plan for your thirty days.1. Find replacement activitiesAt root, a digital declutter is not about your devices themselves; its about the shape of your life. Start by envisioning what you want your life to look like  not by thinking about all the things youll be getting rid of.You might already know what you want to spend your newfound free time on, where you want to focus your newly expanded attention. If not, here are a few questions to surface what youre excited about doing:What would an ideal day look like for you?What do you want to pay attention to?What do you always mean to do but never get around to?What did you used to lov...",
      "url": "https://www.lesswrong.com/posts/rojYKnqHNfMypMdNY/how-to-do-a-digital-declutter",
      "author": "mingyuan",
      "published": "2026-01-25T23:12:55.675000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Practical guide for conducting a 30-day digital declutter, stripping optional device use to break behavioral addictions and rediscover meaningful activities.",
      "importance_score": 8,
      "reasoning": "Self-help/productivity content with no AI research relevance.",
      "themes": [
        "Digital Wellness",
        "Productivity",
        "Self-Help"
      ],
      "continuation": null,
      "summary_html": "<p>Practical guide for conducting a 30-day digital declutter, stripping optional device use to break behavioral addictions and rediscover meaningful activities.</p>",
      "content_html": "<p>Ive been writing about digital intentionality for a few months now, and I keep talking about how its important and it changed my life, but I havent yet told you how to actually do it.If you want to implement digital intentionality, I strongly recommend a thirty-day digital declutter. Anything less is unlikely to work.What is a digital declutter?The tl;drDuring a digital declutter, you strip your life of all optional device use for thirty days. Then, in your newfound free time, you explore and rediscover activities and behaviors that you find satisfying and meaningful. Afterwards, you reintroduce optional technologies only if theyre the best way to support something you deeply value.[1]Why thirty days?Thirty days is long enough to break behavioral addictions, but short enough that the end is aways in sight. You dont need to believe that you can live without the optional uses of your devices forever, just that you can do so until the thirty days are up.How to prepare for your declutterSometimes people hear about this idea and want to get started right now right away today, but its usually prudent to take at least a couple days to prepare.Decide on a start date  maybe the nearest Monday, or the first of the next month if thats coming soon. If your phone is your alarm clock, buy a dedicated alarm clock to replace it. And make a plan for your thirty days.1. Find replacement activitiesAt root, a digital declutter is not about your devices themselves; its about the shape of your life. Start by envisioning what you want your life to look like  not by thinking about all the things youll be getting rid of.You might already know what you want to spend your newfound free time on, where you want to focus your newly expanded attention. If not, here are a few questions to surface what youre excited about doing:What would an ideal day look like for you?What do you want to pay attention to?What do you always mean to do but never get around to?What did you used to lov...</p>"
    },
    {
      "id": "a0f06444ca61",
      "title": "Sunnyvale EA/LW/ACX meetup",
      "content": "After a holiday break, we're hosting another Sunnyvale meetup in Washington Park on Sunday, 2/1!Where?Washington Park in Sunnyvale - We'll meet at&nbsp;the picnic tables next to the playground. If those are occupied, we'll be out on&nbsp;the grass nearby. If you don't see us at first, walk around the playground until you see a sign for ACX.Rain Contingency:Washington Park doesn't have rain shelters, so if it rains, we'll either cancel or post an alternative place to meet. Please check the event page before you come to confirm the location and whether it's still on.When?We'll start showing up at 1pm. I expect folks will be around until 4 or 5pm. Come join when you can and leave when you want.Should I bring something?Kids &amp; dogs - We're outdoors between a playground &amp; grassy area.Snacks/beverages will be provided, but you're welcome to bring your own.Camp chairs &amp; picnic&nbsp;blankets - There isn't much seating otherwise.Do I need to RSVP?You can RSVP on LessWrong or by replying to this email. RSVPs are appreciated but not required. When in doubt, just show up!Looking forward to seeing you there!",
      "url": "https://www.lesswrong.com/posts/fEcvsiDn5G8tfY49x/sunnyvale-ea-lw-acx-meetup-1",
      "author": "wolverdude",
      "published": "2026-01-26T02:16:04.716000",
      "source": "LessWrong",
      "source_type": "research_blog",
      "tags": [],
      "summary": "Announcement for a community meetup in Sunnyvale for EA/LessWrong/ACX communities.",
      "importance_score": 5,
      "reasoning": "Community announcement with no research content.",
      "themes": [
        "Community Events"
      ],
      "continuation": null,
      "summary_html": "<p>Announcement for a community meetup in Sunnyvale for EA/LessWrong/ACX communities.</p>",
      "content_html": "<p>After a holiday break, we're hosting another Sunnyvale meetup in Washington Park on Sunday, 2/1!Where?Washington Park in Sunnyvale - We'll meet at&nbsp;the picnic tables next to the playground. If those are occupied, we'll be out on&nbsp;the grass nearby. If you don't see us at first, walk around the playground until you see a sign for ACX.Rain Contingency:Washington Park doesn't have rain shelters, so if it rains, we'll either cancel or post an alternative place to meet. Please check the event page before you come to confirm the location and whether it's still on.When?We'll start showing up at 1pm. I expect folks will be around until 4 or 5pm. Come join when you can and leave when you want.Should I bring something?Kids &amp; dogs - We're outdoors between a playground &amp; grassy area.Snacks/beverages will be provided, but you're welcome to bring your own.Camp chairs &amp; picnic&nbsp;blankets - There isn't much seating otherwise.Do I need to RSVP?You can RSVP on LessWrong or by replying to this email. RSVPs are appreciated but not required. When in doubt, just show up!Looking forward to seeing you there!</p>"
    }
  ]
}