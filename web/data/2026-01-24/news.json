{
  "category": "news",
  "date": "2026-01-24",
  "category_summary": "**Inferact**, the company behind the widely-used **vLLM** inference library, [raised **$150M**](/?date=2026-01-24&category=news#item-697b656c752b) at **$800M valuation** from **a16z**, **Lightspeed**, and **Sequoia**—the week's largest AI infrastructure investment. **Alibaba's Qwen team** open-sourced **Qwen3-TTS**, a multilingual text-to-speech suite with voice cloning and design capabilities across 10 languages.\n\n**GitHub** [released the **Copilot SDK**](/?date=2026-01-24&category=news#item-51f63ffa1053) in technical preview, enabling developers to embed agentic workflows directly into applications. **Anthropic** [published its Economic Index](/?date=2026-01-24&category=news#item-fa743391f85a) revealing real-world Claude usage patterns, with code generation dominating both consumer and enterprise use cases. **OpenAI** [announced plans to test ads](/?date=2026-01-24&category=news#item-25c7bfbb3e92) in **ChatGPT** for free-tier users.\n\n- **Adobe** [launched **Firefly Foundry**](/?date=2026-01-24&category=news#item-dbf04830f3c4) for IP-safe generative AI models\n- **Tesla** [discontinued standalone Autopilot](/?date=2026-01-24&category=news#item-86303c044f6f), requiring **$99/month FSD subscription**\n- **IMF** [warned AI will impact](/?date=2026-01-24&category=news#item-4924d19ba69b) **60% of jobs** in advanced economies\n- Research paper [challenges whether AI agents can scale](/?date=2026-01-24&category=news#item-d766df08b753), sparking industry debate",
  "category_summary_html": "<p><strong>Inferact</strong>, the company behind the widely-used <strong>vLLM</strong> inference library, <a href=\"/?date=2026-01-24&amp;category=news#item-697b656c752b\" class=\"internal-link\" rel=\"noopener noreferrer\">raised <strong>$150M</strong></a> at <strong>$800M valuation</strong> from <strong>a16z</strong>, <strong>Lightspeed</strong>, and <strong>Sequoia</strong>—the week's largest AI infrastructure investment. <strong>Alibaba's Qwen team</strong> open-sourced <strong>Qwen3-TTS</strong>, a multilingual text-to-speech suite with voice cloning and design capabilities across 10 languages.</p>\n<p><strong>GitHub</strong> <a href=\"/?date=2026-01-24&amp;category=news#item-51f63ffa1053\" class=\"internal-link\" rel=\"noopener noreferrer\">released the <strong>Copilot SDK</strong></a> in technical preview, enabling developers to embed agentic workflows directly into applications. <strong>Anthropic</strong> <a href=\"/?date=2026-01-24&amp;category=news#item-fa743391f85a\" class=\"internal-link\" rel=\"noopener noreferrer\">published its Economic Index</a> revealing real-world Claude usage patterns, with code generation dominating both consumer and enterprise use cases. <strong>OpenAI</strong> <a href=\"/?date=2026-01-24&amp;category=news#item-25c7bfbb3e92\" class=\"internal-link\" rel=\"noopener noreferrer\">announced plans to test ads</a> in <strong>ChatGPT</strong> for free-tier users.</p>\n<ul>\n<li><strong>Adobe</strong> <a href=\"/?date=2026-01-24&amp;category=news#item-dbf04830f3c4\" class=\"internal-link\" rel=\"noopener noreferrer\">launched <strong>Firefly Foundry</strong></a> for IP-safe generative AI models</li>\n<li><strong>Tesla</strong> <a href=\"/?date=2026-01-24&amp;category=news#item-86303c044f6f\" class=\"internal-link\" rel=\"noopener noreferrer\">discontinued standalone Autopilot</a>, requiring <strong>$99/month FSD subscription</strong></li>\n<li><strong>IMF</strong> <a href=\"/?date=2026-01-24&amp;category=news#item-4924d19ba69b\" class=\"internal-link\" rel=\"noopener noreferrer\">warned AI will impact</a> <strong>60% of jobs</strong> in advanced economies</li>\n<li>Research paper <a href=\"/?date=2026-01-24&amp;category=news#item-d766df08b753\" class=\"internal-link\" rel=\"noopener noreferrer\">challenges whether AI agents can scale</a>, sparking industry debate</li>\n</ul>",
  "themes": [
    {
      "name": "AI Infrastructure & Funding",
      "description": "Major investment in inference optimization and developer platforms, led by Inferact's $150M raise for vLLM commercialization",
      "item_count": 4,
      "example_items": [],
      "importance": 85.0
    },
    {
      "name": "Agentic AI",
      "description": "GitHub SDK release, governance concerns, and research questioning agent scalability reflect maturing agent ecosystem",
      "item_count": 6,
      "example_items": [],
      "importance": 75.0
    },
    {
      "name": "Open Source Models",
      "description": "Qwen3-TTS release continues trend of major labs open-sourcing multimodal capabilities",
      "item_count": 2,
      "example_items": [],
      "importance": 78.0
    },
    {
      "name": "Enterprise AI Adoption",
      "description": "Reports on real usage patterns, IT modernization, and 100% AI-infused projects signal maturing enterprise deployment",
      "item_count": 5,
      "example_items": [],
      "importance": 65.0
    },
    {
      "name": "AI Business Models",
      "description": "OpenAI testing ads, Tesla's subscription shift, and Adobe's IP-safe platform reflect evolving monetization strategies",
      "item_count": 4,
      "example_items": [],
      "importance": 70.0
    },
    {
      "name": "Policy & Labor Impact",
      "description": "IMF warnings and UK policy positioning highlight growing attention to AI's economic and workforce implications",
      "item_count": 3,
      "example_items": [],
      "importance": 55.0
    }
  ],
  "total_items": 24,
  "items": [
    {
      "id": "697b656c752b",
      "title": "Andreessen-Backed Inferact Raises $150 Mn to Develop Next-Gen Commercial Inference Engine",
      "content": "Inferact, an AI startup founded by the creators of the open-source vLLM, has secured $150 million in seed funding, valuing the company at $800 million.&nbsp;\n\n\n\nThis funding round was spearheaded by venture capital firms Andreessen Horowitz (a16z) and Lightspeed, with support from Sequoia Capital, Altimeter Capital, Redpoint Ventures, and ZhenFund, the company announced on January 22.\n\n\n\nAccording to the company, vLLM is a key player at the intersection of models and hardware, collaborating with vendors to provide immediate support for new architectures and silicon. Used by various teams, it supports over 500 model architectures and 200 accelerator types, with a strong ecosystem of over 2,000 contributors.\n\n\n\nThe company aims to support the growth of vLLM by providing financial and developer resources to handle increasing model complexity, hardware diversity and deployment scale.\n\n\n\n“We see a future where serving AI becomes effortless. Today, deploying a frontier model at scale requires a dedicated infrastructure team. Tomorrow, it should be as simple as spinning up a serverless database. The complexity doesn&#8217;t disappear; it gets absorbed into the infrastructure we&#8217;re building,” Woosuk Kwon, co-founder of Inferact, posted on X.\n\n\n\nThe startup also plans to develop a next-generation commercial inference engine that works with existing providers to improve software performance and flexibility.\n\n\n\nInferact is led by the maintainers of the vLLM project, including Simon Mo, Kwon, Kaichao You, and Roger Wang. vLLM is the leading open-source inference engine and one of the largest open-source projects of any kind, used in production by companies like Meta, Google, Character AI, and many others.\n\n\n\nThe team plans to further enhance vLLM’s performance, deepen support for emerging model architectures, and expand coverage across advanced hardware. They believe the AI industry requires inference infrastructure that is not confined within proprietary limitations.\n\n\n\n“For a16z infra, investing in the vLLM community is an explicit bet that the future will bring incredible diversity of AI apps, agents, and workloads running on a variety of hardware platforms,” a16z said on X.&nbsp;Inferact is also hiring engineers and researchers to work at the frontier of inference, “where models meet hardware at scale,” Kwon said.\nThe post Andreessen-Backed Inferact Raises $150 Mn to Develop Next-Gen Commercial Inference Engine appeared first on Analytics India Magazine.",
      "url": "https://analyticsindiamag.com/ai-news-updates/andreessen-backed-inferact-raises-150-mn-to-develop-next-gen-commercial-inference-engine/",
      "author": "Smruthi Nadig",
      "published": "2026-01-23T06:31:28",
      "source": "Analytics India Magazine",
      "source_type": "rss",
      "tags": [
        "AI News",
        "a16z",
        "Andreessen Horowitz",
        "inferact",
        "vLLM"
      ],
      "summary": "Following yesterday's [Reddit](/?date=2026-01-23&category=reddit#item-90e29f8d2e88) discussion, Inferact, founded by creators of the widely-used open-source vLLM inference library, raised $150M seed funding at $800M valuation. Led by a16z and Lightspeed with Sequoia, Altimeter, and Redpoint participating, the company aims to develop commercial inference infrastructure supporting 500+ model architectures.",
      "importance_score": 88.0,
      "reasoning": "Major funding for critical AI infrastructure. vLLM is foundational to how many companies deploy LLMs, and this investment signals significant commercial opportunity in inference optimization.",
      "themes": [
        "AI Infrastructure",
        "Funding",
        "Open Source"
      ],
      "continuation": {
        "original_item_id": "90e29f8d2e88",
        "original_date": "2026-01-23",
        "original_category": "reddit",
        "original_title": "vLLM raising $150M confirms it: We have moved from the \"Throughput Era\" to the \"Latency(Cold Starts).\"",
        "continuation_type": "new_development",
        "should_demote": false,
        "reference_text": "Following yesterday's **Reddit** discussion"
      },
      "summary_html": "<p>Following yesterday's <a href=\"/?date=2026-01-23&amp;category=reddit#item-90e29f8d2e88\" class=\"internal-link\" rel=\"noopener noreferrer\">Reddit</a> discussion, Inferact, founded by creators of the widely-used open-source vLLM inference library, raised $150M seed funding at $800M valuation. Led by a16z and Lightspeed with Sequoia, Altimeter, and Redpoint participating, the company aims to develop commercial inference infrastructure supporting 500+ model architectures.</p>",
      "content_html": "<p>Inferact, an AI startup founded by the creators of the open-source vLLM, has secured $150 million in seed funding, valuing the company at $800 million.&nbsp;</p>\n<p>This funding round was spearheaded by venture capital firms Andreessen Horowitz (a16z) and Lightspeed, with support from Sequoia Capital, Altimeter Capital, Redpoint Ventures, and ZhenFund, the company announced on January 22.</p>\n<p>According to the company, vLLM is a key player at the intersection of models and hardware, collaborating with vendors to provide immediate support for new architectures and silicon. Used by various teams, it supports over 500 model architectures and 200 accelerator types, with a strong ecosystem of over 2,000 contributors.</p>\n<p>The company aims to support the growth of vLLM by providing financial and developer resources to handle increasing model complexity, hardware diversity and deployment scale.</p>\n<p>“We see a future where serving AI becomes effortless. Today, deploying a frontier model at scale requires a dedicated infrastructure team. Tomorrow, it should be as simple as spinning up a serverless database. The complexity doesn’t disappear; it gets absorbed into the infrastructure we’re building,” Woosuk Kwon, co-founder of Inferact, posted on X.</p>\n<p>The startup also plans to develop a next-generation commercial inference engine that works with existing providers to improve software performance and flexibility.</p>\n<p>Inferact is led by the maintainers of the vLLM project, including Simon Mo, Kwon, Kaichao You, and Roger Wang. vLLM is the leading open-source inference engine and one of the largest open-source projects of any kind, used in production by companies like Meta, Google, Character AI, and many others.</p>\n<p>The team plans to further enhance vLLM’s performance, deepen support for emerging model architectures, and expand coverage across advanced hardware. They believe the AI industry requires inference infrastructure that is not confined within proprietary limitations.</p>\n<p>“For a16z infra, investing in the vLLM community is an explicit bet that the future will bring incredible diversity of AI apps, agents, and workloads running on a variety of hardware platforms,” a16z said on X.&nbsp;Inferact is also hiring engineers and researchers to work at the frontier of inference, “where models meet hardware at scale,” Kwon said.</p>\n<p>The post Andreessen-Backed Inferact Raises $150 Mn to Develop Next-Gen Commercial Inference Engine appeared first on Analytics India Magazine.</p>"
    },
    {
      "id": "9af30a921107",
      "title": "Qwen Researchers Release Qwen3-TTS: an Open Multilingual TTS Suite with Real-Time Latency and Fine-Grained Voice Control",
      "content": "Alibaba Cloud’s Qwen team has open-sourced Qwen3-TTS, a family of multilingual text-to-speech models that target three core tasks in one stack, voice clone, voice design, and high quality speech generation. \n\n\n\nhttps://arxiv.org/pdf/2601.15621v1\n\n\nModel family and capabilities\n\n\n\nQwen3-TTS uses a 12Hz speech tokenizer and 2 language model sizes, 0.6B and 1.7B, packaged into 3 main tasks. The open release exposes 5 models, Qwen3-TTS-12Hz-0.6B-Base and Qwen3-TTS-12Hz-1.7B-Base for voice cloning and generic TTS, Qwen3-TTS-12Hz-0.6B-CustomVoice and Qwen3-TTS-12Hz-1.7B-CustomVoice for promptable preset speakers, and Qwen3-TTS-12Hz-1.7B-VoiceDesign for free form voice creation from natural language descriptions, along with the Qwen3-TTS-Tokenizer-12Hz codec.\n\n\n\nAll models support 10 languages, Chinese, English, Japanese, Korean, German, French, Russian, Portuguese, Spanish, and Italian. CustomVoice variants ship with 9 curated timbres, such as Vivian, a bright young Chinese female voice, Ryan, a dynamic English male voice, and Ono_Anna, a playful Japanese female voice, each with a short description that encodes timbre and speaking style. \n\n\n\nThe VoiceDesign model maps text instructions directly to new voices, for example &#8216;speak in a nervous teenage male voice with rising intonation&#8217; and can then be combined with the Base model by first generating a short reference clip and reusing it via create_voice_clone_prompt. \n\n\n\nhttps://arxiv.org/pdf/2601.15621v1\n\n\nArchitecture, tokenizer, and streaming path\n\n\n\nQwen3-TTS is a dual track language model, one track predicts discrete acoustic tokens from text, the other handles alignment and control signals. The system is trained on more than 5 million hours of multilingual speech in 3 pre training stages that move from general mapping, to high quality data, to long context support up to 32,768 tokens. \n\n\n\nA key component is the Qwen3-TTS-Tokenizer-12Hz codec. It operates at 12.5 frames per second, about 80 ms per token, and uses 16 quantizers with a 2048 entry codebook. On LibriSpeech test clean it reaches PESQ wideband 3.21, STOI 0.96, and UTMOS 4.16, outperforming SpeechTokenizer, XCodec, Mimi, FireredTTS 2 and other recent semantic tokenizers, while using a similar or lower frame rate. \n\n\n\nThe tokenizer is implemented as a pure left context streaming decoder, so it can emit waveforms as soon as enough tokens are available. With 4 tokens per packet, each streaming packet carries 320 ms of audio. The non-DiT decoder and BigVGAN free design reduces decode cost and simplifies batching. \n\n\n\nOn the language model side, the research team reports end to end streaming measurements on a single vLLM backend with torch.compile and CUDA Graph optimizations. For Qwen3-TTS-12Hz-0.6B-Base and Qwen3-TTS-12Hz-1.7B-Base at concurrency 1, the first packet latency is around 97 ms and 101 ms, with real time factors of 0.288 and 0.313 respectively. Even at concurrency 6, first packet latency stays around 299 ms and 333 ms.\n\n\n\nhttps://arxiv.org/pdf/2601.15621v1\n\n\nAlignment and control\n\n\n\nPost training uses a staged alignment pipeline. First, Direct Preference Optimization aligns generated speech with human preferences on multilingual data. Then GSPO with rule based rewards improves stability and prosody. A final speaker fine tuning stage on the Base model yields target speaker variants while preserving the core capabilities of the general model.\n\n\n\nInstruction following is implemented in a ChatML style format, where text instructions about style, emotion or tempo are prepended to the input. This same interface powers VoiceDesign, CustomVoice style prompts, and fine grained edits for cloned speakers.\n\n\n\nBenchmarks, zero shot cloning, and multilingual speech\n\n\n\nOn the Seed-TTS test set, Qwen3-TTS is evaluated as a zero-shot voice cloning system. The Qwen3-TTS-12Hz-1.7B-Base model reaches a Word Error Rate of 0.77 on test-zh and 1.24 on test-en. The research team highlights the 1.24 WER on test-en as state of the art among the compared systems, while the Chinese WER is close to, but not lower than, the best CosyVoice 3 score.\n\n\n\nhttps://arxiv.org/pdf/2601.15621v1\n\n\nOn a multilingual TTS test set covering 10 languages, Qwen3-TTS achieves the lowest WER in 6 languages, Chinese, English, Italian, French, Korean, and Russian, and competitive performance on the remaining 4 languages, while also obtaining the highest speaker similarity in all 10 languages compared to MiniMax-Speech and ElevenLabs Multilingual v2.\n\n\n\nCross-lingual evaluations show that Qwen3-TTS-12Hz-1.7B-Base reduces mixed error rate for several language pairs, such as zh-to-ko, where the error drops from 14.4 for CosyVoice3 to 4.82, about a 66 percent relative reduction.\n\n\n\nOn InstructTTSEval, the Qwen3TTS-12Hz-1.7B-VD VoiceDesign model sets new state of the art scores among open source models on Description-Speech Consistency and Response Precision in both Chinese and English, and is competitive with commercial systems like Hume and Gemini on several metrics.\n\n\n\nKey Takeaways\n\n\n\n\nFull open source multilingual TTS stack: Qwen3-TTS is an Apache 2.0 licensed suite that covers 3 tasks in one stack, high quality TTS, 3 second voice cloning, and instruction based voice design across 10 languages using the 12Hz tokenizer family.\n\n\n\nEfficient discrete codec and real time streaming: The Qwen3-TTS-Tokenizer-12Hz uses 16 codebooks at 12.5 frames per second, reaches strong PESQ, STOI and UTMOS scores, and supports packetized streaming with about 320 ms of audio per packet and sub 120 ms first packet latency for the 0.6B and 1.7B models in the reported setup.\n\n\n\nTask specific model variants: The release offers Base models for cloning and generic TTS, CustomVoice models with 9 predefined speakers and style prompts, and a VoiceDesign model that generates new voices directly from natural language descriptions which can then be reused by the Base model.\n\n\n\nStrong alignment and multilingual quality: A multi stage alignment pipeline with DPO, GSPO and speaker fine tuning gives Qwen3-TTS low word error rates and high speaker similarity, with lowest WER in 6 of 10 languages and the best speaker similarity in all 10 languages among the evaluated systems, and state of the art zero shot English cloning on Seed TTS.\n\n\n\n\n\n\n\n\nCheck out the Model Weights, Repo and Playground. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter. Wait! are you on telegram? now you can join us on telegram as well.\nThe post Qwen Researchers Release Qwen3-TTS: an Open Multilingual TTS Suite with Real-Time Latency and Fine-Grained Voice Control appeared first on MarkTechPost.",
      "url": "https://www.marktechpost.com/2026/01/22/qwen-researchers-release-qwen3-tts-an-open-multilingual-tts-suite-with-real-time-latency-and-fine-grained-voice-control/",
      "author": "Asif Razzaq",
      "published": "2026-01-23T06:26:31",
      "source": "MarkTechPost",
      "source_type": "rss",
      "tags": [
        "AI Shorts",
        "Applications",
        "Artificial Intelligence",
        "Audio Language Model",
        "Editors Pick",
        "Language Model",
        "Large Language Model",
        "New Releases",
        "Sound",
        "Staff",
        "Tech News",
        "Technology",
        "TTS",
        "Voice AI"
      ],
      "summary": "As first reported in [Reddit](/?date=2026-01-23&category=reddit#item-31730880210f) yesterday, Alibaba's Qwen team open-sourced Qwen3-TTS, a multilingual text-to-speech suite with 0.6B and 1.7B parameter models supporting 10 languages. Features include voice cloning, voice design from natural language descriptions, and real-time latency with fine-grained control.",
      "importance_score": 82.0,
      "reasoning": "Significant open-source release from major AI lab expanding multimodal capabilities. Voice cloning and design from text prompts represents frontier audio generation capabilities now publicly available.",
      "themes": [
        "Open Source",
        "Voice AI",
        "Model Release"
      ],
      "continuation": {
        "original_item_id": "31730880210f",
        "original_date": "2026-01-23",
        "original_category": "reddit",
        "original_title": "Qwen3-TTS, a series of powerful speech generation capabilities",
        "continuation_type": "rehash",
        "should_demote": true,
        "reference_text": "As first reported in **Reddit** yesterday"
      },
      "summary_html": "<p>As first reported in <a href=\"/?date=2026-01-23&amp;category=reddit#item-31730880210f\" class=\"internal-link\" rel=\"noopener noreferrer\">Reddit</a> yesterday, Alibaba's Qwen team open-sourced Qwen3-TTS, a multilingual text-to-speech suite with 0.6B and 1.7B parameter models supporting 10 languages. Features include voice cloning, voice design from natural language descriptions, and real-time latency with fine-grained control.</p>",
      "content_html": "<p>Alibaba Cloud’s Qwen team has open-sourced Qwen3-TTS, a family of multilingual text-to-speech models that target three core tasks in one stack, voice clone, voice design, and high quality speech generation.</p>\n<p>https://arxiv.org/pdf/2601.15621v1</p>\n<p>Model family and capabilities</p>\n<p>Qwen3-TTS uses a 12Hz speech tokenizer and 2 language model sizes, 0.6B and 1.7B, packaged into 3 main tasks. The open release exposes 5 models, Qwen3-TTS-12Hz-0.6B-Base and Qwen3-TTS-12Hz-1.7B-Base for voice cloning and generic TTS, Qwen3-TTS-12Hz-0.6B-CustomVoice and Qwen3-TTS-12Hz-1.7B-CustomVoice for promptable preset speakers, and Qwen3-TTS-12Hz-1.7B-VoiceDesign for free form voice creation from natural language descriptions, along with the Qwen3-TTS-Tokenizer-12Hz codec.</p>\n<p>All models support 10 languages, Chinese, English, Japanese, Korean, German, French, Russian, Portuguese, Spanish, and Italian. CustomVoice variants ship with 9 curated timbres, such as Vivian, a bright young Chinese female voice, Ryan, a dynamic English male voice, and Ono_Anna, a playful Japanese female voice, each with a short description that encodes timbre and speaking style.</p>\n<p>The VoiceDesign model maps text instructions directly to new voices, for example ‘speak in a nervous teenage male voice with rising intonation’ and can then be combined with the Base model by first generating a short reference clip and reusing it via create_voice_clone_prompt.</p>\n<p>https://arxiv.org/pdf/2601.15621v1</p>\n<p>Architecture, tokenizer, and streaming path</p>\n<p>Qwen3-TTS is a dual track language model, one track predicts discrete acoustic tokens from text, the other handles alignment and control signals. The system is trained on more than 5 million hours of multilingual speech in 3 pre training stages that move from general mapping, to high quality data, to long context support up to 32,768 tokens.</p>\n<p>A key component is the Qwen3-TTS-Tokenizer-12Hz codec. It operates at 12.5 frames per second, about 80 ms per token, and uses 16 quantizers with a 2048 entry codebook. On LibriSpeech test clean it reaches PESQ wideband 3.21, STOI 0.96, and UTMOS 4.16, outperforming SpeechTokenizer, XCodec, Mimi, FireredTTS 2 and other recent semantic tokenizers, while using a similar or lower frame rate.</p>\n<p>The tokenizer is implemented as a pure left context streaming decoder, so it can emit waveforms as soon as enough tokens are available. With 4 tokens per packet, each streaming packet carries 320 ms of audio. The non-DiT decoder and BigVGAN free design reduces decode cost and simplifies batching.</p>\n<p>On the language model side, the research team reports end to end streaming measurements on a single vLLM backend with torch.compile and CUDA Graph optimizations. For Qwen3-TTS-12Hz-0.6B-Base and Qwen3-TTS-12Hz-1.7B-Base at concurrency 1, the first packet latency is around 97 ms and 101 ms, with real time factors of 0.288 and 0.313 respectively. Even at concurrency 6, first packet latency stays around 299 ms and 333 ms.</p>\n<p>https://arxiv.org/pdf/2601.15621v1</p>\n<p>Alignment and control</p>\n<p>Post training uses a staged alignment pipeline. First, Direct Preference Optimization aligns generated speech with human preferences on multilingual data. Then GSPO with rule based rewards improves stability and prosody. A final speaker fine tuning stage on the Base model yields target speaker variants while preserving the core capabilities of the general model.</p>\n<p>Instruction following is implemented in a ChatML style format, where text instructions about style, emotion or tempo are prepended to the input. This same interface powers VoiceDesign, CustomVoice style prompts, and fine grained edits for cloned speakers.</p>\n<p>Benchmarks, zero shot cloning, and multilingual speech</p>\n<p>On the Seed-TTS test set, Qwen3-TTS is evaluated as a zero-shot voice cloning system. The Qwen3-TTS-12Hz-1.7B-Base model reaches a Word Error Rate of 0.77 on test-zh and 1.24 on test-en. The research team highlights the 1.24 WER on test-en as state of the art among the compared systems, while the Chinese WER is close to, but not lower than, the best CosyVoice 3 score.</p>\n<p>https://arxiv.org/pdf/2601.15621v1</p>\n<p>On a multilingual TTS test set covering 10 languages, Qwen3-TTS achieves the lowest WER in 6 languages, Chinese, English, Italian, French, Korean, and Russian, and competitive performance on the remaining 4 languages, while also obtaining the highest speaker similarity in all 10 languages compared to MiniMax-Speech and ElevenLabs Multilingual v2.</p>\n<p>Cross-lingual evaluations show that Qwen3-TTS-12Hz-1.7B-Base reduces mixed error rate for several language pairs, such as zh-to-ko, where the error drops from 14.4 for CosyVoice3 to 4.82, about a 66 percent relative reduction.</p>\n<p>On InstructTTSEval, the Qwen3TTS-12Hz-1.7B-VD VoiceDesign model sets new state of the art scores among open source models on Description-Speech Consistency and Response Precision in both Chinese and English, and is competitive with commercial systems like Hume and Gemini on several metrics.</p>\n<p>Key Takeaways</p>\n<p>Full open source multilingual TTS stack: Qwen3-TTS is an Apache 2.0 licensed suite that covers 3 tasks in one stack, high quality TTS, 3 second voice cloning, and instruction based voice design across 10 languages using the 12Hz tokenizer family.</p>\n<p>Efficient discrete codec and real time streaming: The Qwen3-TTS-Tokenizer-12Hz uses 16 codebooks at 12.5 frames per second, reaches strong PESQ, STOI and UTMOS scores, and supports packetized streaming with about 320 ms of audio per packet and sub 120 ms first packet latency for the 0.6B and 1.7B models in the reported setup.</p>\n<p>Task specific model variants: The release offers Base models for cloning and generic TTS, CustomVoice models with 9 predefined speakers and style prompts, and a VoiceDesign model that generates new voices directly from natural language descriptions which can then be reused by the Base model.</p>\n<p>Strong alignment and multilingual quality: A multi stage alignment pipeline with DPO, GSPO and speaker fine tuning gives Qwen3-TTS low word error rates and high speaker similarity, with lowest WER in 6 of 10 languages and the best speaker similarity in all 10 languages among the evaluated systems, and state of the art zero shot English cloning on Seed TTS.</p>\n<p>Check out the&nbsp;Model Weights,&nbsp;Repo&nbsp;and&nbsp;Playground.&nbsp;Also,&nbsp;feel free to follow us on&nbsp;Twitter&nbsp;and don’t forget to join our&nbsp;100k+ ML SubReddit&nbsp;and Subscribe to&nbsp;our Newsletter. Wait! are you on telegram?&nbsp;now you can join us on telegram as well.</p>\n<p>The post Qwen Researchers Release Qwen3-TTS: an Open Multilingual TTS Suite with Real-Time Latency and Fine-Grained Voice Control appeared first on MarkTechPost.</p>"
    },
    {
      "id": "51f63ffa1053",
      "title": "GitHub Introduces Copilot SDK to Embed AI Agents in Applications",
      "content": "GitHub has introduced the GitHub Copilot SDK in technical preview, allowing developers to embed Copilot’s agentic capabilities directly into their own applications.\n\n\n\nThe SDK exposes the same execution loop used by GitHub Copilot CLI, including planning, tool invocation, file editing, and command execution. According to GitHub, this is intended to reduce the complexity of building agent-based systems from scratch.\n\n\n\n“Building agentic workflows from scratch is hard,” said the chief product officer, Mario Rodriguez, in a blog post. “Even before you reach your actual product logic, you’ve already built a small platform.”\n\n\n\nGitHub said the Copilot SDK provides programmatic access to Copilot’s production-tested agent loop, removing the need for developers to design their own planners and runtimes. The SDK supports multiple AI models, custom tool definitions, MCP server integration, GitHub authentication, and real-time streaming.\n\n\n\nThe technical preview initially supports Node.js, Python, Go, and .NET. Developers can use an existing GitHub Copilot subscription or supply their own API key. The open repository includes setup instructions, starter examples, and SDK references for each language.\n\n\n\nGitHub recommends starting with a single task, such as updating files or running commands, and allowing Copilot to plan and execute steps while the host application provides tools and constraints. In an example shared by GitHub, it was revealed that developers can create a Copilot client, start a session using a specified model, and send prompts programmatically.\n\n\n\nThe company said the SDK builds directly on the capabilities of Copilot CLI, which already allows users to plan projects, modify files, run commands, and delegate tasks without leaving the terminal. Recent updates to Copilot CLI include persistent memory, multi-step workflows, full MCP support, and asynchronous task delegation.\n\n\n\n“The SDK takes the agentic power of Copilot CLI and makes it available in your favourite programming language,” Rodriguez wrote. “This makes it possible to integrate Copilot into any environment.”\n\n\n\nInternal GitHub teams have used the SDK to build tools such as YouTube chapter generators, summarisation tools, custom agent interfaces, and speech-to-command workflows, according to the company.\n\n\n\nGitHub positioned the Copilot SDK as an execution layer, with GitHub managing authentication, model access, and session handling, while developers control how those components are used within their applications.\nThe post GitHub Introduces Copilot SDK to Embed AI Agents in Applications appeared first on Analytics India Magazine.",
      "url": "https://analyticsindiamag.com/ai-news-updates/github-introduces-copilot-sdk-to-embed-ai-agents-in-applications/",
      "author": "Siddharth Jindal",
      "published": "2026-01-23T09:20:50",
      "source": "Analytics India Magazine",
      "source_type": "rss",
      "tags": [
        "AI News",
        "GitHub"
      ],
      "summary": "GitHub released the Copilot SDK in technical preview, enabling developers to embed Copilot's agentic execution loop—including planning, tool invocation, file editing, and command execution—directly into their applications. The SDK exposes the same runtime powering GitHub Copilot CLI.",
      "importance_score": 78.0,
      "reasoning": "Major platform move democratizing agentic AI development. Reduces complexity for building agent systems and could accelerate adoption of AI-powered development tools.",
      "themes": [
        "Agentic AI",
        "Developer Tools",
        "Platform"
      ],
      "continuation": null,
      "summary_html": "<p>GitHub released the Copilot SDK in technical preview, enabling developers to embed Copilot's agentic execution loop—including planning, tool invocation, file editing, and command execution—directly into their applications. The SDK exposes the same runtime powering GitHub Copilot CLI.</p>",
      "content_html": "<p>GitHub has introduced the GitHub Copilot SDK in technical preview, allowing developers to embed Copilot’s agentic capabilities directly into their own applications.</p>\n<p>The SDK exposes the same execution loop used by GitHub Copilot CLI, including planning, tool invocation, file editing, and command execution. According to GitHub, this is intended to reduce the complexity of building agent-based systems from scratch.</p>\n<p>“Building agentic workflows from scratch is hard,” said the chief product officer, Mario Rodriguez, in a blog post. “Even before you reach your actual product logic, you’ve already built a small platform.”</p>\n<p>GitHub said the Copilot SDK provides programmatic access to Copilot’s production-tested agent loop, removing the need for developers to design their own planners and runtimes. The SDK supports multiple AI models, custom tool definitions, MCP server integration, GitHub authentication, and real-time streaming.</p>\n<p>The technical preview initially supports Node.js, Python, Go, and .NET. Developers can use an existing GitHub Copilot subscription or supply their own API key. The open repository includes setup instructions, starter examples, and SDK references for each language.</p>\n<p>GitHub recommends starting with a single task, such as updating files or running commands, and allowing Copilot to plan and execute steps while the host application provides tools and constraints. In an example shared by GitHub, it was revealed that developers can create a Copilot client, start a session using a specified model, and send prompts programmatically.</p>\n<p>The company said the SDK builds directly on the capabilities of Copilot CLI, which already allows users to plan projects, modify files, run commands, and delegate tasks without leaving the terminal. Recent updates to Copilot CLI include persistent memory, multi-step workflows, full MCP support, and asynchronous task delegation.</p>\n<p>“The SDK takes the agentic power of Copilot CLI and makes it available in your favourite programming language,” Rodriguez wrote. “This makes it possible to integrate Copilot into any environment.”</p>\n<p>Internal GitHub teams have used the SDK to build tools such as YouTube chapter generators, summarisation tools, custom agent interfaces, and speech-to-command workflows, according to the company.</p>\n<p>GitHub positioned the Copilot SDK as an execution layer, with GitHub managing authentication, model access, and session handling, while developers control how those components are used within their applications.</p>\n<p>The post GitHub Introduces Copilot SDK to Embed AI Agents in Applications appeared first on Analytics India Magazine.</p>"
    },
    {
      "id": "fa743391f85a",
      "title": "Anthropic’s usage stats paint a detailed picture of AI success",
      "content": "Anthropic&#8217;s Economic Index offers a look at how organisations and individuals are actually using large language models. The report contains the company&#8217;s analysis of a million consumer interactions on Claude.ai, plus a million enterprise API calls, all dated from November 2025. The report notes that its figures are based on observations, rather than, for example, a sample of business decision-makers or generic survey.\n\n\n\nLimited use cases dominate\n\n\n\nUse of Anthropic&#8217;s AI tends to cluster around a relatively small number of tasks, with the ten most frequently-performed tasks accounting for almost a quarter of consumer interactions, and nearly a third of enterprise API traffic. There&#8217;s a focus on the use of Claude for code creation and modification, as readers might expect.\n\n\n\nThis concentration of use of AI as a software development tool has remained fairly constant over time, suggesting that the model&#8217;s value is largely based around these types of tasks, with no emerging use of Claude for other purposes of any empirical significance. This suggests that broad, general rollouts of AI are less likely to be successful than those focused on tasks where large language models are proven to be effective.\n\n\n\nAugmentation outperforms automation\n\n\n\nOn consumer platforms, collaborative use – where users iterate on queries to the AI over the course of a virtual conversation – is more common than using the AI to produce automated workflows. Enterprise API usage shows the opposite, as businesses attempt to gain savings through automating tasks. However, while Claude succeeds on shorter tasks, the observed quality of outcomes declines the more complex the task (or series of tasks) is, and the longer the required &#8216;thinking time&#8217; required.\n\n\n\nThis implies automation is most effective for routine, well-defined tasks that are simpler, require fewer logical steps, and where responses to queries can be quick. Tasks estimated to take humans several hours show significantly lower completion rates than shorter tasks. For longer tasks to succeed, users have to iterate and correct outputs.\n\n\n\nUsers breaking down large tasks into manageable steps and posing each separately (either interactively or via API) have improved success rates.\n\n\n\nThe company&#8217;s observations show most queries put to the LLMs are associated with white-collar roles (although poorer countries tend to use Claude in academic settings more commonly than, for instance, the US). For example, travel agents can lose complex planning tasks to the LLM and retain elements of their more transactional work, while some roles, such as property managers, show the opposite: routine administrative tasks can be handled by the AI, and tasks needing higher-judgement remain with the human professional..\n\n\n\nProductivity gains lessened by reliability\n\n\n\nThe report notes that claims of AI boosting annual labour productivity by 1.8% (over a decade) are likely best to be reduced to 1-1.2%, due to the need to factor in extra labour and costs. While a 1% efficiency gain over a decade is still economically meaningful, the need for activities such as validation, error handling, and reworking will lower success rates and therefore there should be a similar adjustment in the minds of a business&#8217;s decision-makers.\n\n\n\nPotential gains to an organisation deploying AI also depend on whether tasks given to the LLM complement or substitute work. In the latter case, the success of substituting an AI for tasks normally done by a human depends on how complex the work is.\n\n\n\nIt&#8217;s noteworthy that the report finds a near-perfect correlation between the sophistication of users&#8217; prompts to the LLM and successful outcomes. Thus, how people use AI shapes what it delivers.\n\n\n\nKey takeaways for leaders\n\n\n\n\nAI implementation delivers value fastest in specific, well-defined areas.\n\n\n\nComplementary systems (AI+human) outperform full automation for complex work.\n\n\n\nReliability and necessary extra work &#8216;around&#8217; the AI reduce predicted productivity gains.\n\n\n\nChanges to workforces&#8217; makeup depend on the mix of tasks and their complexity, not specific job roles.\n\n\n\n\n(Image source: &#8220;the virtual construction worker&#8221; by antjeverena is licensed under CC BY-NC-SA 2.0.)\n\n\n\n&nbsp;\n\n\n\n\n\n\n\n\n\n\n\nWant to learn more about AI and big data from industry leaders? Check out AI &amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.\n\n\n\nAI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.\nThe post Anthropic&#8217;s usage stats paint a detailed picture of AI success appeared first on AI News.",
      "url": "https://www.artificialintelligence-news.com/news/anthropic-report-economic-index-summary-key-points-2026/",
      "author": "AI News",
      "published": "2026-01-23T14:21:20",
      "source": "AI News",
      "source_type": "rss",
      "tags": [
        "Special Reports & Series",
        "World of Work",
        "anthropic",
        "claude",
        "operational deployment",
        "survey"
      ],
      "summary": "Anthropic published its Economic Index analyzing 1M consumer and 1M enterprise API interactions from November 2025. The report reveals usage clusters around limited tasks, with code creation dominating and top 10 tasks comprising nearly a quarter of consumer and a third of enterprise traffic.",
      "importance_score": 75.0,
      "reasoning": "First detailed empirical data on real-world LLM usage patterns from a major lab. Provides valuable insight into how frontier AI is actually being deployed.",
      "themes": [
        "Enterprise AI",
        "Research",
        "Usage Analytics"
      ],
      "continuation": null,
      "summary_html": "<p>Anthropic published its Economic Index analyzing 1M consumer and 1M enterprise API interactions from November 2025. The report reveals usage clusters around limited tasks, with code creation dominating and top 10 tasks comprising nearly a quarter of consumer and a third of enterprise traffic.</p>",
      "content_html": "<p>Anthropic’s Economic Index offers a look at how organisations and individuals are actually using large language models. The report contains the company’s analysis of a million consumer interactions on Claude.ai, plus a million enterprise API calls, all dated from November 2025. The report notes that its figures are based on observations, rather than, for example, a sample of business decision-makers or generic survey.</p>\n<p>Limited use cases dominate</p>\n<p>Use of Anthropic’s AI tends to cluster around a relatively small number of tasks, with the ten most frequently-performed tasks accounting for almost a quarter of consumer interactions, and nearly a third of enterprise API traffic. There’s a focus on the use of Claude for code creation and modification, as readers might expect.</p>\n<p>This concentration of use of AI as a software development tool has remained fairly constant over time, suggesting that the model’s value is largely based around these types of tasks, with no emerging use of Claude for other purposes of any empirical significance. This suggests that broad, general rollouts of AI are less likely to be successful than those focused on tasks where large language models are proven to be effective.</p>\n<p>Augmentation outperforms automation</p>\n<p>On consumer platforms, collaborative use – where users iterate on queries to the AI over the course of a virtual conversation – is more common than using the AI to produce automated workflows. Enterprise API usage shows the opposite, as businesses attempt to gain savings through automating tasks. However, while Claude succeeds on shorter tasks, the observed quality of outcomes declines the more complex the task (or series of tasks) is, and the longer the required ‘thinking time’ required.</p>\n<p>This implies automation is most effective for routine, well-defined tasks that are simpler, require fewer logical steps, and where responses to queries can be quick. Tasks estimated to take humans several hours show significantly lower completion rates than shorter tasks. For longer tasks to succeed, users have to iterate and correct outputs.</p>\n<p>Users breaking down large tasks into manageable steps and posing each separately (either interactively or via API) have improved success rates.</p>\n<p>The company’s observations show most queries put to the LLMs are associated with white-collar roles (although poorer countries tend to use Claude in academic settings more commonly than, for instance, the US). For example, travel agents can lose complex planning tasks to the LLM and retain elements of their more transactional work, while some roles, such as property managers, show the opposite: routine administrative tasks can be handled by the AI, and tasks needing higher-judgement remain with the human professional..</p>\n<p>Productivity gains lessened by reliability</p>\n<p>The report notes that claims of AI boosting annual labour productivity by 1.8% (over a decade) are likely best to be reduced to 1-1.2%, due to the need to factor in extra labour and costs. While a 1% efficiency gain over a decade is still economically meaningful, the need for activities such as validation, error handling, and reworking will lower success rates and therefore there should be a similar adjustment in the minds of a business’s decision-makers.</p>\n<p>Potential gains to an organisation deploying AI also depend on whether tasks given to the LLM complement or substitute work. In the latter case, the success of substituting an AI for tasks normally done by a human depends on how complex the work is.</p>\n<p>It’s noteworthy that the report finds a near-perfect correlation between the sophistication of users’ prompts to the LLM and successful outcomes. Thus, how people use AI shapes what it delivers.</p>\n<p>Key takeaways for leaders</p>\n<p>AI implementation delivers value fastest in specific, well-defined areas.</p>\n<p>Complementary systems (AI+human) outperform full automation for complex work.</p>\n<p>Reliability and necessary extra work ‘around’ the AI reduce predicted productivity gains.</p>\n<p>Changes to workforces’ makeup depend on the mix of tasks and their complexity, not specific job roles.</p>\n<p>(Image source: “the virtual construction worker” by antjeverena is licensed under CC BY-NC-SA 2.0.)</p>\n<p>&nbsp;</p>\n<p>Want to learn more about AI and big data from industry leaders? Check out AI &amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.</p>\n<p>AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.</p>\n<p>The post Anthropic’s usage stats paint a detailed picture of AI success appeared first on AI News.</p>"
    },
    {
      "id": "25c7bfbb3e92",
      "title": "Last Week in AI #333 - ChatGPT Ads, Zhipu+Huawei, Drama at Thinking Machines",
      "content": "OpenAI to test ads in ChatGPT as it burns through billionsRelated:ChatGPT to begin testing ads as generative AI competition heats upOpenAI will begin testing labeled banner ads in ChatGPT for logged&#8209;in users on the free tier and the $8/month ChatGPT Go plan, rolling out in the U.S. and other markets in the coming weeks. Ads will appear as blocked-off sections at the bottom of answers when there&#8217;s a &#8220;relevant sponsored product or service,&#8221; such as travel ads after a destination query; Plus, Pro, Business, and Enterprise users will not see ads. OpenAI says ads won&#8217;t influence model outputs and will be clearly separated from answers, with sensitive categories like health, mental health, and politics excluded. The company is also expanding ChatGPT Go globally after initial availability in India, while emphasizing that enterprise and subscription revenue remains &#8220;strong.&#8221;Privacy and transparency controls include not sharing user conversations with advertisers, providing only aggregated performance metrics (e.g., impressions, clicks), offering an explanation of &#8220;why this ad,&#8221; allowing users to dismiss ads, and enabling options to turn off personalization and clear data. Ads will not be served to users identified as minors or predicted under 18 by age&#8209;prediction models.The Drama at Thinking Machines, a New A.I. Start-Up, Is Riveting Silicon ValleyRelated:The Messy Human Drama That Dealt a Blow to One of AI&#8217;s Hottest StartupsThinking Machines Lab, a prominent AI start-up founded less than a year ago, is experiencing significant turmoil after CEO and co-founder Mira Murati fired chief technology officer Barret Zoph on January 14 following a contentious meeting. Zoph, along with fellow co-founders Luke Metz and Sam Schoenholz, had lobbied Murati to cede technical decision-making authority to Zoph and threatened to leave if changes were not made. OpenAI immediately rehired all three executives, and approximately nine additional Thinking Machines employees have since departed for OpenAI or received offers from Meta, which has reportedly offered hundreds of millions of dollars to recruit the start-up&#8217;s talent.The defections come as Thinking Machines struggles to establish itself despite raising $2 billion in funding at a $12 billion valuation last July. The company has lagged competitors in releasing products and failed to secure additional funding at its sought-after $50 billion valuation. The co-founders had urged Murati to sell the company&#8212;Meta had expressed acquisition interest and Murati had developed closer ties with Anthropic CEO Dario Amodei&#8212;but Murati preferred to remain independent. Zhipu AI breaks US chip reliance with first major model trained on Huawei stackZhipu AI announced that its new open-source image generation model, GLM-Image, was trained entirely on a domestic Huawei stack&#8212;marking a first for a &#8220;powerful&#8221; model developed without US chips. The full training pipeline, from data prep through final training, ran on Huawei Ascend Atlas 800T A2 servers with Ascend AI processors and the MindSpore ML framework. This demonstrates the feasibility of training state-of-the-art multimodal models on China&#8217;s local hardware and software amid US export controls. Zhipu positioned the work as a reference implementation for scaling domestic compute in AI development.Under the hood, GLM-Image uses a hybrid architecture combining autoregressive and diffusion components, enabling native multimodal capabilities across text, voice, image, and video. The design echoes approaches like Google DeepMind&#8217;s Nano Banana Pro, jointly generating high-fidelity images and coherent text. Sequoia to invest in Anthropic, breaking VC taboo on backing rivals: FTSequoia Capital is reportedly joining a massive new funding round for Anthropic, the maker of Claude, defying the traditional VC norm of not backing direct competitors in the same sector. Led by Singapore&#8217;s GIC and U.S. investor Coatue with $1.5 billion each, the round targets $25 billion or more at a $350 billion valuation&#8212;more than double Anthropic&#8217;s $170 billion figure from four months ago. Microsoft and Nvidia have committed up to $15 billion combined, with VCs and others expected to add $10 billion or more. This is notable because Sequoia already holds stakes in OpenAI and Elon Musk&#8217;s xAI, and follows prior reporting that OpenAI would restrict investor access to confidential info if they made &#8220;non-passive&#8221; investments in competitors&#8212;a policy Sam Altman described as industry standard.Other NewsToolsBlack Forest Labs Releases FLUX.2 [klein]: Compact Flow Models for Interactive Visual Intelligence. The team compresses the FLUX.2 design into 4B and 9B rectified flow transformers distilled for 4-step generation and editing, delivering sub-second, multi-reference text-to-image and image-editing on consumer GPUs, with larger Base checkpoints and FP8/NVFP4 quantized builds for research and lower&#8209;VRAM deployment.Google now offers free SAT practice exams, powered by Gemini. Students can request a free practice SAT from Gemini, which generates tests, scores responses, explains mistakes, highlights strengths and weaknesses, and uses vetted questions from partners like the Princeton Review.OpenAI is launching age prediction for ChatGPT accounts. A new system uses behavioral and account-level signals to estimate age and will require a selfie via Persona to correct mistaken underage classifications.Molmo2: Open Weights and Data for Vision-Language Models with Video Understanding and Grounding. These models and datasets, released with open weights, demonstrate strong video-language and grounding performance using new training methods and benchmarks while avoiding reliance on proprietary pretrained models.HeartMuLa: A Family of Open Sourced Music Foundation Models. The released models provide an open-source ecosystem&#8212;including an audio&#8209;text alignment model, a lyric transcriber, a low-frame-rate high&#8209;fidelity codec, and a multi&#8209;condition song generator&#8212;enabling controllable long&#8209;form music generation up to six minutes and reproducible research.BusinessMicrosoft Spending on Anthropic Approaches $500 Million a Year. Microsoft plans to integrate and sell Anthropic&#8217;s AI models through Azure&#8212;counting those sales toward cloud sales quotas&#8212;after investing up to $5 billion, while keeping a smaller revenue share on Anthropic sales than on OpenAI offerings.OpenAI CFO says annualized revenue crosses $20 billion in 2025. OpenAI Chief Financial Officer Sarah Friar said in a blog post on Sunday the company's annualized revenue has surpassed $20 billion in 2025, up from $6 billion in 2024 with growth closely tracking an expansion in computing capacity.Mark Zuckerberg says Meta is launching its own AI infrastructure initiative. Meta&#8217;s new initiative, Meta Compute, will expand datacenters, power, and supplier partnerships&#8212;aiming to add tens to hundreds of gigawatts of capacity this decade&#8212;and appoints three senior executives to oversee technical architecture, long-term capacity strategy, and government relations.Wikimedia Foundation announces new AI partnerships with Amazon, Meta, Microsoft, Perplexity, and others. The deals make Wikimedia Enterprise a paid distribution channel for large tech companies to access Wikipedia and other Wikimedia content at scale, creating a new revenue stream as its material is used by AI systems and services.Humans&amp;, a &#8216;human-centric&#8217; AI startup founded by Anthropic, xAI, Google alums, raised $480M seed round. Founded by ex-Anthropic, xAI, and Google staffers, the startup raised $480 million at a $4.48 billion valuation to build a human-centric messaging-style AI focused on collaboration, memory, and new training approaches.AI video startup Higgsfield hits $1.3 billion valuation with latest funding. AI video generation startup Higgsfield raised $80 million in new funding, valuing the company at over $1.3 billion, it told Reuters, as investors rush to develop the sector amid booming demand for the new technology.OpenAI invests in Sam Altman&#8217;s brain computer interface startup Merge Labs. The startup emerged from stealth with an $850 million valuation after a $250 million seed round led by OpenAI, and plans to develop noninvasive, molecule- and ultrasound-based brain-computer interfaces while collaborating with OpenAI on scientific foundation models.Shareholders sue Oracle over misleading statements related to $300 billion OpenAI data center build-out. Bondholders allege Oracle concealed plans for a much larger follow-up debt offering, causing the initial bonds to lose value when a $38 billion issuance followed the $18 billion sale.ResearchAgencyBench: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts. This benchmark evaluates 32 real-world scenarios comprising 138 long-horizon tasks (averaging ~1M tokens and ~90 tool calls each) to measure agents&#8217; multi-turn, tool-using, and context-maintenance capabilities using an automated user-simulation and Docker sandbox pipeline.Reasoning Models Generate Societies of Thought. The authors report improved problem-solving by producing multiple interacting agent-like reasoning streams that provide diverse perspectives and organized collaboration.The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models. The work identifies a dominant &#8220;Assistant Axis&#8221; in model activations that locates the default assistant persona, shows that shifts along this axis predict and enable persona drift during conversations, and demonstrates an activation-clamping method that reduces harmful or off-persona responses without hurting capability.Building Production-Ready Probes For Gemini. The paper evaluates practical techniques to build cost-effective, long&#8209;context&#8209;robust activation probes for detecting cyber&#8209;offensive prompts in Gemini 2.5 Flash, and reports deployment-ready recommendations and production results.Memory Bank Compression for Continual Adaptation of Large Language Models. A method compresses and optimizes external memory banks with learned codebooks so LLMs can continually adapt to new data while preserving previously learned performance.ConcernsAI&#8217;s Hacking Skills Are Approaching an &#8216;Inflection Point&#8217;. Researchers and startups warn that recent AI advances have made models significantly better at finding and exploiting complex software vulnerabilities, raising the risk that attackers could use them to discover zero-days faster than defenders.Anthropic&#8217;s CEO stuns Davos with Nvidia criticism. He warned that U.S. approval of high-performance Nvidia and AMD AI chips for China poses serious national-security risks, likening the move to arming a future &#8220;country of geniuses,&#8221; and criticized both the administration and Nvidia despite the company&#8217;s recent investment in Anthropic.Actors And Musicians Help Launch &#8220;Stealing Isn&#8217;t Innovation&#8221; Campaign To Protest Big Tech&#8217;s Use Of Copyrighted Works In AI Models. Backed by major industry groups and high-profile creators, the campaign urges courts and policymakers to require AI companies to obtain licenses for copyrighted works and stop using them without authorization.PolicySenate passes bill letting victims sue over Grok AI explicit images. The measure would create a federal civil right allowing people to sue for damages and restraining orders when AI tools generate sexually explicit images of them without consent.",
      "url": "https://lastweekin.ai/p/last-week-in-ai-333-chatgpt-ads-zhipuhuawei",
      "author": "Last Week in AI",
      "published": "2026-01-23T05:14:53",
      "source": "Last Week in AI",
      "source_type": "rss",
      "tags": [],
      "summary": "OpenAI will begin testing labeled banner ads in ChatGPT for free-tier and $8/month ChatGPT Go users in the US. Ads will appear as blocked sections at response bottoms for relevant queries, while Plus, Pro, Business, and Enterprise tiers remain ad-free.",
      "importance_score": 72.0,
      "reasoning": "Significant monetization shift for the leading consumer AI product. Indicates pressure to diversify revenue and could affect user experience and competitive dynamics.",
      "themes": [
        "Business Model",
        "OpenAI",
        "Consumer AI"
      ],
      "continuation": null,
      "summary_html": "<p>OpenAI will begin testing labeled banner ads in ChatGPT for free-tier and $8/month ChatGPT Go users in the US. Ads will appear as blocked sections at response bottoms for relevant queries, while Plus, Pro, Business, and Enterprise tiers remain ad-free.</p>",
      "content_html": "<p>OpenAI to test ads in ChatGPT as it burns through billionsRelated:ChatGPT to begin testing ads as generative AI competition heats upOpenAI will begin testing labeled banner ads in ChatGPT for logged‑in users on the free tier and the $8/month ChatGPT Go plan, rolling out in the U.S. and other markets in the coming weeks. Ads will appear as blocked-off sections at the bottom of answers when there’s a “relevant sponsored product or service,” such as travel ads after a destination query; Plus, Pro, Business, and Enterprise users will not see ads. OpenAI says ads won’t influence model outputs and will be clearly separated from answers, with sensitive categories like health, mental health, and politics excluded. The company is also expanding ChatGPT Go globally after initial availability in India, while emphasizing that enterprise and subscription revenue remains “strong.”Privacy and transparency controls include not sharing user conversations with advertisers, providing only aggregated performance metrics (e.g., impressions, clicks), offering an explanation of “why this ad,” allowing users to dismiss ads, and enabling options to turn off personalization and clear data. Ads will not be served to users identified as minors or predicted under 18 by age‑prediction models.The Drama at Thinking Machines, a New A.I. Start-Up, Is Riveting Silicon ValleyRelated:The Messy Human Drama That Dealt a Blow to One of AI’s Hottest StartupsThinking Machines Lab, a prominent AI start-up founded less than a year ago, is experiencing significant turmoil after CEO and co-founder Mira Murati fired chief technology officer Barret Zoph on January 14 following a contentious meeting. Zoph, along with fellow co-founders Luke Metz and Sam Schoenholz, had lobbied Murati to cede technical decision-making authority to Zoph and threatened to leave if changes were not made. OpenAI immediately rehired all three executives, and approximately nine additional Thinking Machines employees have since departed for OpenAI or received offers from Meta, which has reportedly offered hundreds of millions of dollars to recruit the start-up’s talent.The defections come as Thinking Machines struggles to establish itself despite raising $2 billion in funding at a $12 billion valuation last July. The company has lagged competitors in releasing products and failed to secure additional funding at its sought-after $50 billion valuation. The co-founders had urged Murati to sell the company—Meta had expressed acquisition interest and Murati had developed closer ties with Anthropic CEO Dario Amodei—but Murati preferred to remain independent. Zhipu AI breaks US chip reliance with first major model trained on Huawei stackZhipu AI announced that its new open-source image generation model, GLM-Image, was trained entirely on a domestic Huawei stack—marking a first for a “powerful” model developed without US chips. The full training pipeline, from data prep through final training, ran on Huawei Ascend Atlas 800T A2 servers with Ascend AI processors and the MindSpore ML framework. This demonstrates the feasibility of training state-of-the-art multimodal models on China’s local hardware and software amid US export controls. Zhipu positioned the work as a reference implementation for scaling domestic compute in AI development.Under the hood, GLM-Image uses a hybrid architecture combining autoregressive and diffusion components, enabling native multimodal capabilities across text, voice, image, and video. The design echoes approaches like Google DeepMind’s Nano Banana Pro, jointly generating high-fidelity images and coherent text. Sequoia to invest in Anthropic, breaking VC taboo on backing rivals: FTSequoia Capital is reportedly joining a massive new funding round for Anthropic, the maker of Claude, defying the traditional VC norm of not backing direct competitors in the same sector. Led by Singapore’s GIC and U.S. investor Coatue with $1.5 billion each, the round targets $25 billion or more at a $350 billion valuation—more than double Anthropic’s $170 billion figure from four months ago. Microsoft and Nvidia have committed up to $15 billion combined, with VCs and others expected to add $10 billion or more. This is notable because Sequoia already holds stakes in OpenAI and Elon Musk’s xAI, and follows prior reporting that OpenAI would restrict investor access to confidential info if they made “non-passive” investments in competitors—a policy Sam Altman described as industry standard.Other NewsToolsBlack Forest Labs Releases FLUX.2 [klein]: Compact Flow Models for Interactive Visual Intelligence. The team compresses the FLUX.2 design into 4B and 9B rectified flow transformers distilled for 4-step generation and editing, delivering sub-second, multi-reference text-to-image and image-editing on consumer GPUs, with larger Base checkpoints and FP8/NVFP4 quantized builds for research and lower‑VRAM deployment.Google now offers free SAT practice exams, powered by Gemini. Students can request a free practice SAT from Gemini, which generates tests, scores responses, explains mistakes, highlights strengths and weaknesses, and uses vetted questions from partners like the Princeton Review.OpenAI is launching age prediction for ChatGPT accounts. A new system uses behavioral and account-level signals to estimate age and will require a selfie via Persona to correct mistaken underage classifications.Molmo2: Open Weights and Data for Vision-Language Models with Video Understanding and Grounding. These models and datasets, released with open weights, demonstrate strong video-language and grounding performance using new training methods and benchmarks while avoiding reliance on proprietary pretrained models.HeartMuLa: A Family of Open Sourced Music Foundation Models. The released models provide an open-source ecosystem—including an audio‑text alignment model, a lyric transcriber, a low-frame-rate high‑fidelity codec, and a multi‑condition song generator—enabling controllable long‑form music generation up to six minutes and reproducible research.BusinessMicrosoft Spending on Anthropic Approaches $500 Million a Year. Microsoft plans to integrate and sell Anthropic’s AI models through Azure—counting those sales toward cloud sales quotas—after investing up to $5 billion, while keeping a smaller revenue share on Anthropic sales than on OpenAI offerings.OpenAI CFO says annualized revenue crosses $20 billion in 2025. OpenAI Chief Financial Officer Sarah Friar said in a blog post on Sunday the company's annualized revenue has surpassed $20 billion in 2025, up from $6 billion in 2024 with growth closely tracking an expansion in computing capacity.Mark Zuckerberg says Meta is launching its own AI infrastructure initiative. Meta’s new initiative, Meta Compute, will expand datacenters, power, and supplier partnerships—aiming to add tens to hundreds of gigawatts of capacity this decade—and appoints three senior executives to oversee technical architecture, long-term capacity strategy, and government relations.Wikimedia Foundation announces new AI partnerships with Amazon, Meta, Microsoft, Perplexity, and others. The deals make Wikimedia Enterprise a paid distribution channel for large tech companies to access Wikipedia and other Wikimedia content at scale, creating a new revenue stream as its material is used by AI systems and services.Humans&amp;, a ‘human-centric’ AI startup founded by Anthropic, xAI, Google alums, raised $480M seed round. Founded by ex-Anthropic, xAI, and Google staffers, the startup raised $480 million at a $4.48 billion valuation to build a human-centric messaging-style AI focused on collaboration, memory, and new training approaches.AI video startup Higgsfield hits $1.3 billion valuation with latest funding. AI video generation startup Higgsfield raised $80 million in new funding, valuing the company at over $1.3 billion, it told Reuters, as investors rush to develop the sector amid booming demand for the new technology.OpenAI invests in Sam Altman’s brain computer interface startup Merge Labs. The startup emerged from stealth with an $850 million valuation after a $250 million seed round led by OpenAI, and plans to develop noninvasive, molecule- and ultrasound-based brain-computer interfaces while collaborating with OpenAI on scientific foundation models.Shareholders sue Oracle over misleading statements related to $300 billion OpenAI data center build-out. Bondholders allege Oracle concealed plans for a much larger follow-up debt offering, causing the initial bonds to lose value when a $38 billion issuance followed the $18 billion sale.ResearchAgencyBench: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts. This benchmark evaluates 32 real-world scenarios comprising 138 long-horizon tasks (averaging ~1M tokens and ~90 tool calls each) to measure agents’ multi-turn, tool-using, and context-maintenance capabilities using an automated user-simulation and Docker sandbox pipeline.Reasoning Models Generate Societies of Thought. The authors report improved problem-solving by producing multiple interacting agent-like reasoning streams that provide diverse perspectives and organized collaboration.The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models. The work identifies a dominant “Assistant Axis” in model activations that locates the default assistant persona, shows that shifts along this axis predict and enable persona drift during conversations, and demonstrates an activation-clamping method that reduces harmful or off-persona responses without hurting capability.Building Production-Ready Probes For Gemini. The paper evaluates practical techniques to build cost-effective, long‑context‑robust activation probes for detecting cyber‑offensive prompts in Gemini 2.5 Flash, and reports deployment-ready recommendations and production results.Memory Bank Compression for Continual Adaptation of Large Language Models. A method compresses and optimizes external memory banks with learned codebooks so LLMs can continually adapt to new data while preserving previously learned performance.ConcernsAI’s Hacking Skills Are Approaching an ‘Inflection Point’. Researchers and startups warn that recent AI advances have made models significantly better at finding and exploiting complex software vulnerabilities, raising the risk that attackers could use them to discover zero-days faster than defenders.Anthropic’s CEO stuns Davos with Nvidia criticism. He warned that U.S. approval of high-performance Nvidia and AMD AI chips for China poses serious national-security risks, likening the move to arming a future “country of geniuses,” and criticized both the administration and Nvidia despite the company’s recent investment in Anthropic.Actors And Musicians Help Launch “Stealing Isn’t Innovation” Campaign To Protest Big Tech’s Use Of Copyrighted Works In AI Models. Backed by major industry groups and high-profile creators, the campaign urges courts and policymakers to require AI companies to obtain licenses for copyrighted works and stop using them without authorization.PolicySenate passes bill letting victims sue over Grok AI explicit images. The measure would create a federal civil right allowing people to sue for damages and restraining orders when AI tools generate sexually explicit images of them without consent.</p>"
    },
    {
      "id": "dbf04830f3c4",
      "title": "Adobe Launches Firefly Foundry to Safeguard IP Rights for Creative Artists",
      "content": "Adobe has unveiled Firefly Foundry, a platform for commercially safe AI models that are tuned to a company or IP owner’s unique, proprietary brand or franchise content. Those omni-models can generate high-fidelity images, video, audio, 3D and vector outputs with a complete understanding of a brand or franchise’s creative universe.\n\n\n\nAccording to the company, ​​Firefly Foundry helps the media and entertainment industry move faster while preserving artistry, authorship and ownership. It aims to empower studios and creatives to enhance storytelling by rapidly generating engaging short-form social content, enabling broader audience appeal through added characters and story arcs.&nbsp;\n\n\n\n“Integrating Firefly Foundry into our workflow builds on that legacy by giving our artists the freedom to push ideas further, while giving co-production, client, and distribution partners confidence in how generative AI is being used,” Jamie Byrne, co-founder, president and COO of Promise Advanced Imagination, announced.&nbsp;\n\n\n\nThe platform supports brands in creating immersive experiences beyond the screen, using digital displays and mobile apps to bring narratives to life in venues like theme parks. Directors and storyboard artists can benefit from advanced tools that facilitate idea development and accurately capture their vision during pre-production.&nbsp;\n\n\n\nOn set, filmmakers can fine-tune their creative choices in real-time, ensuring effective shot lists while efficiently processing dailies. In post-production, Firefly Foundry optimises workflows for editors and visual effects artists, enabling them to enhance scenes and finalise frames without costly reshoots.\n\n\n\nAdobe is actively forging partnerships with key industry leaders who are poised to embrace this pivotal moment in creative innovation. Their collaboration includes renowned talent agencies such as Creative Artists Agency, United Talent Agency, and William Morris Endeavor, as well as hybrid and AI-native film studios like B5 Studios and Promise Advanced Imagination.&nbsp;\n\n\n\nMoreover, Adobe is teaming up with esteemed design and visual effects studios like Cantina Creative, alongside visionary directors such as David Ayer, recognised for his work on Fast and Furious and Suicide Squad, and Jaume Collet-Serra, known for Black Adam and Jungle Cruise.\n\n\n\nBryan Lourd, CEO and co-chairman of Creative Artists Agency, noted, “Adobe is a… company that recognises the importance of protecting creators’ rights and intellectual property and is committed to building a responsible AI ecosystem.”\nThe post Adobe Launches Firefly Foundry to Safeguard IP Rights for Creative Artists appeared first on Analytics India Magazine.",
      "url": "https://analyticsindiamag.com/ai-news-updates/adobe-launches-firefly-foundry-to-safeguard-ip-rights-for-creative-artists/",
      "author": "Smruthi Nadig",
      "published": "2026-01-23T08:55:59",
      "source": "Analytics India Magazine",
      "source_type": "rss",
      "tags": [
        "AI News",
        "Adobe",
        "film studios adobe",
        "firefly foundry"
      ],
      "summary": "Adobe launched Firefly Foundry, a platform for creating commercially-safe AI models trained on proprietary brand/franchise content. The omni-models generate images, video, audio, 3D, and vector outputs while preserving IP rights and creative ownership.",
      "importance_score": 68.0,
      "reasoning": "Addresses major industry concern around AI-generated content and IP protection. Strategic move by Adobe to position as safe harbor for enterprise creative AI.",
      "themes": [
        "Creative AI",
        "Enterprise",
        "IP Rights"
      ],
      "continuation": null,
      "summary_html": "<p>Adobe launched Firefly Foundry, a platform for creating commercially-safe AI models trained on proprietary brand/franchise content. The omni-models generate images, video, audio, 3D, and vector outputs while preserving IP rights and creative ownership.</p>",
      "content_html": "<p>Adobe has unveiled Firefly Foundry, a platform for commercially safe AI models that are tuned to a company or IP owner’s unique, proprietary brand or franchise content. Those omni-models can generate high-fidelity images, video, audio, 3D and vector outputs with a complete understanding of a brand or franchise’s creative universe.</p>\n<p>According to the company, ​​Firefly Foundry helps the media and entertainment industry move faster while preserving artistry, authorship and ownership. It aims to empower studios and creatives to enhance storytelling by rapidly generating engaging short-form social content, enabling broader audience appeal through added characters and story arcs.&nbsp;</p>\n<p>“Integrating Firefly Foundry into our workflow builds on that legacy by giving our artists the freedom to push ideas further, while giving co-production, client, and distribution partners confidence in how generative AI is being used,” Jamie Byrne, co-founder, president and COO of Promise Advanced Imagination, announced.&nbsp;</p>\n<p>The platform supports brands in creating immersive experiences beyond the screen, using digital displays and mobile apps to bring narratives to life in venues like theme parks. Directors and storyboard artists can benefit from advanced tools that facilitate idea development and accurately capture their vision during pre-production.&nbsp;</p>\n<p>On set, filmmakers can fine-tune their creative choices in real-time, ensuring effective shot lists while efficiently processing dailies. In post-production, Firefly Foundry optimises workflows for editors and visual effects artists, enabling them to enhance scenes and finalise frames without costly reshoots.</p>\n<p>Adobe is actively forging partnerships with key industry leaders who are poised to embrace this pivotal moment in creative innovation. Their collaboration includes renowned talent agencies such as Creative Artists Agency, United Talent Agency, and William Morris Endeavor, as well as hybrid and AI-native film studios like B5 Studios and Promise Advanced Imagination.&nbsp;</p>\n<p>Moreover, Adobe is teaming up with esteemed design and visual effects studios like Cantina Creative, alongside visionary directors such as David Ayer, recognised for his work on Fast and Furious and Suicide Squad, and Jaume Collet-Serra, known for Black Adam and Jungle Cruise.</p>\n<p>Bryan Lourd, CEO and co-chairman of Creative Artists Agency, noted, “Adobe is a… company that recognises the importance of protecting creators’ rights and intellectual property and is committed to building a responsible AI ecosystem.”</p>\n<p>The post Adobe Launches Firefly Foundry to Safeguard IP Rights for Creative Artists appeared first on Analytics India Magazine.</p>"
    },
    {
      "id": "86303c044f6f",
      "title": "Tesla kills Autopilot, locks lane-keeping behind $99/month fee",
      "content": "Love it or hate it, Tesla has been responsible for helping to shape the tastes of automotive consumers over the past decade-plus. Over-the-air updates that add more features, an all-touchscreen human-machine interface, large castings, and hands-free driver assists were all introduced or popularized by Tesla's electric vehicles, prompting other automakers to copy them, mostly in the hopes of seeing the same stratospheric gains in their stock prices. But starting on Valentine's Day, if you want your Tesla to steer itself, you'll have to pay a $99 monthly subscription fee.\nTesla currently offers a pair of so-called \"level 2\" partially automated driver assist systems. Autopilot is the older of these, combining Tesla's adaptive cruise control (Tesla calls this TACC) and lane-keeping assist (Tesla calls this Autosteer). FSD is the newer system, meant to be more capable and for use on surface streets and divided-lane highways. Although the company and Tesla CEO Elon Musk regularly tout these systems' capabilities, both still require the human driver to provide situational awareness.\nBut Autopilot has been under fire from regulators and the courts. Multiple wrongful death lawsuits are in the works, and after a high-profile loss resulting in a $329 million judgment against Tesla, expect many of these suits to be settled. Both the federal government and California have investigated whether Tesla misled customers, and in December, an administrative law judge ruled that Tesla indeed engaged in deceptive marketing by implying that its cars could drive themselves. The judge suspended Tesla's license to sell cars in California, a decision that the California Department of Motor Vehicles stayed for 60 days.Read full article\nComments",
      "url": "https://arstechnica.com/cars/2026/01/tesla-wants-recurring-revenue-discontinues-autopilot-in-favor-of-fsd/",
      "author": "Jonathan M. Gitlin",
      "published": "2026-01-23T16:54:12",
      "source": "Ars Technica - All content",
      "source_type": "rss",
      "tags": [
        "Cars",
        "tesla autopilot",
        "Tesla FSD"
      ],
      "summary": "Tesla is discontinuing Autopilot as a standalone feature starting February 14, moving lane-keeping and steering assistance behind its Full Self-Driving subscription at $99/month. This consolidates Tesla's driver-assist offerings into a single paid tier.",
      "importance_score": 67.0,
      "reasoning": "Major business model change for the leading autonomous driving consumer product. Signals shift toward subscription revenue and could impact broader ADAS market expectations.",
      "themes": [
        "Autonomous Vehicles",
        "Business Model",
        "Consumer Tech"
      ],
      "continuation": null,
      "summary_html": "<p>Tesla is discontinuing Autopilot as a standalone feature starting February 14, moving lane-keeping and steering assistance behind its Full Self-Driving subscription at $99/month. This consolidates Tesla's driver-assist offerings into a single paid tier.</p>",
      "content_html": "<p>Love it or hate it, Tesla has been responsible for helping to shape the tastes of automotive consumers over the past decade-plus.&nbsp;Over-the-air updates that add more features, an all-touchscreen human-machine interface, large castings, and hands-free driver assists were all introduced or popularized by Tesla's electric vehicles,&nbsp;prompting other automakers to copy them, mostly in the hopes of seeing the same stratospheric gains in their stock prices.&nbsp;But starting on Valentine's Day, if you want your Tesla to steer itself, you'll have to pay a $99 monthly subscription fee.</p>\n<p>Tesla currently offers a pair of so-called \"level 2\" partially automated driver assist systems. Autopilot is the older of these, combining Tesla's adaptive cruise control (Tesla calls this TACC) and lane-keeping assist (Tesla calls this Autosteer). FSD is the newer system, meant to be more capable and for use on surface streets and divided-lane highways. Although the company and Tesla CEO Elon Musk regularly tout these systems' capabilities, both still require the human driver to provide situational awareness.</p>\n<p>But Autopilot has been under fire from regulators and the courts. Multiple wrongful death lawsuits are in the works, and after a high-profile loss resulting in a $329 million judgment against Tesla, expect many of these suits to be settled. Both the federal government and California have investigated whether Tesla misled customers, and in December, an administrative law judge ruled that Tesla indeed engaged in deceptive marketing by implying that its cars could drive themselves. The judge suspended Tesla's license to sell cars in California, a decision that the California Department of Motor Vehicles stayed for 60 days.Read full article</p>\n<p>Comments</p>"
    },
    {
      "id": "d766df08b753",
      "title": "The Math on AI Agents Doesn’t Add Up",
      "content": "A research paper suggests AI agents are mathematically doomed to fail. The industry doesn’t agree.",
      "url": "https://www.wired.com/story/ai-agents-math-doesnt-add-up/",
      "author": "Steven Levy",
      "published": "2026-01-23T16:00:00",
      "source": "Feed: Artificial Intelligence Latest",
      "source_type": "rss",
      "tags": [
        "Business",
        "Business / Tech Culture",
        "Backchannel - NL",
        "models",
        "artificial intelligence",
        "Silicon Valley",
        "research",
        "math",
        "Backchannel"
      ],
      "summary": "A research paper suggests AI agents are 'mathematically doomed to fail' due to fundamental limitations, though industry leaders dispute the findings. The paper raises questions about the scalability of agentic AI approaches.",
      "importance_score": 62.0,
      "reasoning": "Contrarian research challenging prevailing AI agent optimism. Important theoretical contribution to understanding agent limitations, though industry pushback suggests debate continues.",
      "themes": [
        "AI Agents",
        "Research",
        "AI Limitations"
      ],
      "continuation": null,
      "summary_html": "<p>A research paper suggests AI agents are 'mathematically doomed to fail' due to fundamental limitations, though industry leaders dispute the findings. The paper raises questions about the scalability of agentic AI approaches.</p>",
      "content_html": "<p>A research paper suggests AI agents are mathematically doomed to fail. The industry doesn’t agree.</p>"
    },
    {
      "id": "4924d19ba69b",
      "title": "Young will suffer most when AI ‘tsunami’ hits jobs, says head of IMF",
      "content": "Kristalina Georgieva says research suggests 60% of jobs in advanced economies will be affected, with many entry-level roles wiped outArtificial intelligence will be a “tsunami hitting the labour market”, with young people worst affected, the head of the International Monetary Fund warned the World Economic Forum on Friday.Kristalina Georgieva told delegates in Davos that the IMF’s own research suggested there would be a big transformation of demand for skills, as the technology becomes increasingly widespread. Continue reading...",
      "url": "https://www.theguardian.com/technology/2026/jan/23/ai-tsunami-labour-market-youth-employment-says-head-of-imf-davos",
      "author": "Graeme Wearden and Heather Stewart in Davos",
      "published": "2026-01-23T13:35:53",
      "source": "AI (artificial intelligence) | The Guardian",
      "source_type": "rss",
      "tags": [
        "AI (artificial intelligence)",
        "Work & careers",
        "Computing",
        "Money",
        "Economics",
        "Business",
        "Technology"
      ],
      "summary": "IMF head Kristalina Georgieva warned at Davos that AI will be a 'tsunami hitting the labour market,' with 60% of jobs in advanced economies affected. Young workers in entry-level roles will be disproportionately impacted.",
      "importance_score": 58.0,
      "reasoning": "High-profile policy voice amplifying AI workforce impact concerns. IMF's research-backed warning carries weight in global economic discussions.",
      "themes": [
        "Policy",
        "Labor Market",
        "Economic Impact"
      ],
      "continuation": null,
      "summary_html": "<p>IMF head Kristalina Georgieva warned at Davos that AI will be a 'tsunami hitting the labour market,' with 60% of jobs in advanced economies affected. Young workers in entry-level roles will be disproportionately impacted.</p>",
      "content_html": "<p>Kristalina Georgieva says research suggests 60% of jobs in advanced economies will be affected, with many entry-level roles wiped outArtificial intelligence will be a “tsunami hitting the labour market”, with young people worst affected, the head of the International Monetary Fund warned the World Economic Forum on Friday.Kristalina Georgieva told delegates in Davos that the IMF’s own research suggested there would be a big transformation of demand for skills, as the technology becomes increasingly widespread. Continue reading...</p>"
    },
    {
      "id": "9b36f7452cc2",
      "title": "Zoho Launches AI-native ERP Platform From Rural Tamil Nadu",
      "content": "Enterprise software firm Zoho has launched Zoho ERP, a comprehensive, AI-native enterprise resource planning platform built in India, positioning it as a homegrown alternative to global ERP solutions.\n\n\n\nThe company said Zoho ERP is designed to help fast-growing Indian businesses scale locally and globally without the rigid architectures, high costs, and consultant-heavy implementations associated with legacy ERP platforms.\n\n\n\nUnlike conventional ERP systems that add artificial intelligence as an external layer, Zoho ERP embeds AI across the platform. The solution includes AI-driven customisation, automation, predictive insights, anomaly detection and voice-based assistance through Ask Zia, along with end-to-end visibility across finance and operations.\n\n\n\n“With Zoho ERP, we have built a powerful, compliance-ready platform that serves as a strong homegrown alternative to global ERP solutions,” said Shailesh Davey, CEO and co-founder of Zoho Corp, in a statement. He added that the product was developed with talent from Kumbakonam, Tamil Nadu and that Zoho plans to drive future innovation from the region.&nbsp;\n\n\n\n“By creating opportunities for local youth, we are helping reverse talent drain and strengthen the regional economy while building swadeshi technology from rural India,” he said.\n\n\n\nSivaramakrishnan Iswaran, the global head of Finance and Operations Business Unit at Zoho and CEO of Zoho Payment Technologies, said the platform reflects how modern businesses operate. “Zoho ERP connects fintech, banking and business software, offering built-in local compliance, an intuitive role-based experience, and improved operational efficiency,” he said.\n\n\n\nZoho ERP integrates financial management, billing, spend management, supply chain, payroll and omnichannel commerce into a single platform. It also offers asset management, budgeting and continuous financial close, along with strong audit trails and financial controls. The system is compliant with GST and e-invoicing norms, supports revenue recognition under IFRS 15 and ASC 606, and includes payroll features tailored to Indian regulations, including EPF, ESI, TDS, Professional Tax, and Labour Welfare Fund requirements.\n\n\n\nThe initial release includes industry-specific capabilities for manufacturing, distribution, retail, and non-profit organisations, with more vertical-focused features planned. Manufacturing firms can manage the full production lifecycle, while distribution businesses can streamline inventory, dealer management, and field sales.\nThe post Zoho Launches AI-native ERP Platform From Rural Tamil Nadu appeared first on Analytics India Magazine.",
      "url": "https://analyticsindiamag.com/ai-news-updates/zoho-launches-ai-native-erp-platform-from-rural-tamil-nadu/",
      "author": "Pallavi Chakravorty",
      "published": "2026-01-23T10:43:09",
      "source": "Analytics India Magazine",
      "source_type": "rss",
      "tags": [
        "AI News"
      ],
      "summary": "Zoho launched an AI-native ERP platform designed for Indian businesses, embedding AI throughout rather than as an add-on layer. Features include AI-driven customization, automation, predictive insights, and voice assistance via Ask Zia.",
      "importance_score": 56.0,
      "reasoning": "Represents enterprise software shift toward AI-native architectures. Significant for emerging market enterprise AI adoption.",
      "themes": [
        "Enterprise AI",
        "ERP",
        "India Tech"
      ],
      "continuation": null,
      "summary_html": "<p>Zoho launched an AI-native ERP platform designed for Indian businesses, embedding AI throughout rather than as an add-on layer. Features include AI-driven customization, automation, predictive insights, and voice assistance via Ask Zia.</p>",
      "content_html": "<p>Enterprise software firm Zoho has launched Zoho ERP, a comprehensive, AI-native enterprise resource planning platform built in India, positioning it as a homegrown alternative to global ERP solutions.</p>\n<p>The company said Zoho ERP is designed to help fast-growing Indian businesses scale locally and globally without the rigid architectures, high costs, and consultant-heavy implementations associated with legacy ERP platforms.</p>\n<p>Unlike conventional ERP systems that add artificial intelligence as an external layer, Zoho ERP embeds AI across the platform. The solution includes AI-driven customisation, automation, predictive insights, anomaly detection and voice-based assistance through Ask Zia, along with end-to-end visibility across finance and operations.</p>\n<p>“With Zoho ERP, we have built a powerful, compliance-ready platform that serves as a strong homegrown alternative to global ERP solutions,” said Shailesh Davey, CEO and co-founder of Zoho Corp, in a statement. He added that the product was developed with talent from Kumbakonam, Tamil Nadu and that Zoho plans to drive future innovation from the region.&nbsp;</p>\n<p>“By creating opportunities for local youth, we are helping reverse talent drain and strengthen the regional economy while building swadeshi technology from rural India,” he said.</p>\n<p>Sivaramakrishnan Iswaran, the global head of Finance and Operations Business Unit at Zoho and CEO of Zoho Payment Technologies, said the platform reflects how modern businesses operate. “Zoho ERP connects fintech, banking and business software, offering built-in local compliance, an intuitive role-based experience, and improved operational efficiency,” he said.</p>\n<p>Zoho ERP integrates financial management, billing, spend management, supply chain, payroll and omnichannel commerce into a single platform. It also offers asset management, budgeting and continuous financial close, along with strong audit trails and financial controls. The system is compliant with GST and e-invoicing norms, supports revenue recognition under IFRS 15 and ASC 606, and includes payroll features tailored to Indian regulations, including EPF, ESI, TDS, Professional Tax, and Labour Welfare Fund requirements.</p>\n<p>The initial release includes industry-specific capabilities for manufacturing, distribution, retail, and non-profit organisations, with more vertical-focused features planned. Manufacturing firms can manage the full production lifecycle, while distribution businesses can streamline inventory, dealer management, and field sales.</p>\n<p>The post Zoho Launches AI-native ERP Platform From Rural Tamil Nadu appeared first on Analytics India Magazine.</p>"
    },
    {
      "id": "6e9706d78926",
      "title": "GitHub Releases Copilot-SDK to Embed Its Agentic Runtime in Any App",
      "content": "GitHub has opened up the internal agent runtime that powers GitHub Copilot CLI and exposed it as a programmable SDK. The GitHub Copilot-SDK, now in technical preview, lets you embed the same agentic execution loop into any application so the agent can plan, invoke tools, edit files, and run commands as part of your own workflows.\n\n\n\nWhat the GitHub Copilot SDK provides\n\n\n\nThe GitHub Copilot-SDK is a multi platform SDK for integrating the GitHub Copilot Agent into applications and services. It gives programmatic access to the execution loop that already powers GitHub Copilot CLI. Instead of building your own planner and tool loop for each project, you attach your logic to this existing runtime and treat it as an execution platform.\n\n\n\nThe GitHub Copilot-SDK exposes the same production tested runtime used by Copilot CLI, with support for multi model operation, multi step planning, tools, Model Context Protocol (MCP) integration, authentication, and streaming. This gives you the same agent behavior that Copilot uses in the terminal, but callable from your own code.\n\n\n\nAgentic execution loop as a runtime primitive\n\n\n\nThe core abstraction is the agentic execution loop. In Copilot CLI and in the SDK, interactions are not isolated prompts. The agent maintains state across turns, chooses plans, calls tools, executes commands, reads results, and repeats these steps until it reaches the goal that you provided. \n\n\n\nThe GitHub team describes the usual problems when you implement this loop yourself. You need to manage context across multiple turns, orchestrate external tools and commands, route calls across models, integrate MCP servers, and think through permiss developer, you concentrate on defining domain specific tools, describing tasks, and constraining what the agent can do.\n\n\n\nSupported languages and core API\n\n\n\nThe Copilot-SDK is available in 4 languages in this technical preview:\n\n\n\n\nNode.js and TypeScript, through the package @github/copilot-cli-sdk\n\n\n\nPython, through the package copilot\n\n\n\nGo, through the module github.com/github/copilot-cli-sdk-go\n\n\n\n.NET, through the package GitHub.Copilot.SDK\n\n\n\n\nAll SDKs expose a consistent API surface. According to the changelog, every language binding supports multi-turn conversations with session history, custom tool execution, and programmatic control over client and session life cycles.\n\n\n\nTools, MCP servers, and integration with existing systems\n\n\n\nA main feature of the Copilot agent is tool execution. Through the SDK you can register custom tools that the model can call during a conversation. The Copilot-CLI already exposes custom tool definitions and full MCP server integration, and the SDK reuses that capability. \n\n\n\nMCP gives a standard protocol for agents to connect to external systems such as internal APIs, document stores, or operations tools. When you integrate an MCP server, the Copilot agent can discover and call its operations in a structured way with consistent metadata rather than ad hoc prompt engineering.\n\n\n\nThe pattern is straightforward. You define a tool with a clear schema and effect, you expose it through the SDK, and the Copilot planner decides when and how to call it as part of the multi step plan.\n\n\n\nAuthentication, subscriptions, and streaming\n\n\n\nThe SDK integrates with GitHub authentication and Copilot subscriptions. You can either use an existing GitHub Copilot subscription or bring your own key when configuring the SDK. This is important when you embed the agent in enterprise environments where identity and access control are already standardized around GitHub.\n\n\n\nStreaming is part of the contract. Copilot-CLI already supports real time streaming in the terminal, and the SDK exposes streaming so that applications can receive responses incrementally. This allows you to build user interfaces that update progressively as the agent reasons and executes, without waiting for a full completion.\n\n\n\nRelationship to GitHub Copilot-CLI\n\n\n\nThe SDK is not a separate agent implementation. It is a layer on top of the existing Copilot CLI execution loop. It as a way to reuse the planning, tool use, and multi turn execution behavior of the CLI in any environment.\n\n\n\nCopilot-CLI itself continues to evolve. Recent updates add persistent memory, infinite sessions, and context compaction, support for explore and plan workflows with model selection per step, custom agents and agent skills, full MCP support, and asynchronous task delegation. The SDK benefits from this work, because it exposes that same behavior through language specific libraries.\n\n\n\nKey Takeaways\n\n\n\n\nGitHub Copilot-SDK exposes the same agentic execution loop that powers GitHub Copilot CLI, so applications can call a production tested planner that runs multi step workflows with tools and commands.\n\n\n\nThe SDK is available for Node.js, Python, Go, and .NET, and each language binding provides a similar abstraction around clients and sessions that manage multi turn conversations and tool use.\n\n\n\nDevelopers define domain specific tools and Model Context Protocol servers, then register them through the SDK, and the Copilot agent decides when and how to call them as part of the plan.\n\n\n\nThe runtime integrates with GitHub authentication and Copilot subscriptions, supports multiple AI models such as GPT based backends, and exposes real time streaming so applications can render partial responses incrementally.\n\n\n\n\n\n\n\n\nCheck out the GitHub Page. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter. Wait! are you on telegram? now you can join us on telegram as well.\nThe post GitHub Releases Copilot-SDK to Embed Its Agentic Runtime in Any App appeared first on MarkTechPost.",
      "url": "https://www.marktechpost.com/2026/01/23/github-releases-copilot-sdk-to-embed-its-agentic-runtime-in-any-app/",
      "author": "Michal Sutter",
      "published": "2026-01-23T22:43:33",
      "source": "MarkTechPost",
      "source_type": "rss",
      "tags": [
        "Agentic AI",
        "AI Agents",
        "Editors Pick",
        "New Releases",
        "Software Engineering",
        "Staff"
      ],
      "summary": "GitHub opened its internal agent runtime as a programmable SDK in technical preview, allowing embedding of the same agentic execution loop used by Copilot CLI into any application.",
      "importance_score": 55.0,
      "reasoning": "Duplicate coverage of GitHub SDK with additional technical detail. Important development but scoring lower as secondary source.",
      "themes": [
        "Agentic AI",
        "Developer Tools",
        "Platform"
      ],
      "continuation": null,
      "summary_html": "<p>GitHub opened its internal agent runtime as a programmable SDK in technical preview, allowing embedding of the same agentic execution loop used by Copilot CLI into any application.</p>",
      "content_html": "<p>GitHub has opened up the internal agent runtime that powers GitHub Copilot CLI and exposed it as a programmable SDK. The GitHub Copilot-SDK, now in technical preview, lets you embed the same agentic execution loop into any application so the agent can plan, invoke tools, edit files, and run commands as part of your own workflows.</p>\n<p>What the GitHub Copilot SDK provides</p>\n<p>The GitHub Copilot-SDK is a multi platform SDK for integrating the GitHub Copilot Agent into applications and services. It gives programmatic access to the execution loop that already powers GitHub Copilot CLI. Instead of building your own planner and tool loop for each project, you attach your logic to this existing runtime and treat it as an execution platform.</p>\n<p>The GitHub Copilot-SDK exposes the same production tested runtime used by Copilot CLI, with support for multi model operation, multi step planning, tools, Model Context Protocol (MCP) integration, authentication, and streaming. This gives you the same agent behavior that Copilot uses in the terminal, but callable from your own code.</p>\n<p>Agentic execution loop as a runtime primitive</p>\n<p>The core abstraction is the agentic execution loop. In Copilot CLI and in the SDK, interactions are not isolated prompts. The agent maintains state across turns, chooses plans, calls tools, executes commands, reads results, and repeats these steps until it reaches the goal that you provided.</p>\n<p>The GitHub team describes the usual problems when you implement this loop yourself. You need to manage context across multiple turns, orchestrate external tools and commands, route calls across models, integrate MCP servers, and think through permiss developer, you concentrate on defining domain specific tools, describing tasks, and constraining what the agent can do.</p>\n<p>Supported languages and core API</p>\n<p>The Copilot-SDK is available in 4 languages in this technical preview:</p>\n<p>Node.js and TypeScript, through the package @github/copilot-cli-sdk</p>\n<p>Python, through the package copilot</p>\n<p>Go, through the module github.com/github/copilot-cli-sdk-go</p>\n<p>.NET, through the package GitHub.Copilot.SDK</p>\n<p>All SDKs expose a consistent API surface. According to the changelog, every language binding supports multi-turn conversations with session history, custom tool execution, and programmatic control over client and session life cycles.</p>\n<p>Tools, MCP servers, and integration with existing systems</p>\n<p>A main feature of the Copilot agent is tool execution. Through the SDK you can register custom tools that the model can call during a conversation. The Copilot-CLI already exposes custom tool definitions and full MCP server integration, and the SDK reuses that capability.</p>\n<p>MCP gives a standard protocol for agents to connect to external systems such as internal APIs, document stores, or operations tools. When you integrate an MCP server, the Copilot agent can discover and call its operations in a structured way with consistent metadata rather than ad hoc prompt engineering.</p>\n<p>The pattern is straightforward. You define a tool with a clear schema and effect, you expose it through the SDK, and the Copilot planner decides when and how to call it as part of the multi step plan.</p>\n<p>Authentication, subscriptions, and streaming</p>\n<p>The SDK integrates with GitHub authentication and Copilot subscriptions. You can either use an existing GitHub Copilot subscription or bring your own key when configuring the SDK. This is important when you embed the agent in enterprise environments where identity and access control are already standardized around GitHub.</p>\n<p>Streaming is part of the contract. Copilot-CLI already supports real time streaming in the terminal, and the SDK exposes streaming so that applications can receive responses incrementally. This allows you to build user interfaces that update progressively as the agent reasons and executes, without waiting for a full completion.</p>\n<p>Relationship to GitHub Copilot-CLI</p>\n<p>The SDK is not a separate agent implementation. It is a layer on top of the existing Copilot CLI execution loop. It as a way to reuse the planning, tool use, and multi turn execution behavior of the CLI in any environment.</p>\n<p>Copilot-CLI itself continues to evolve. Recent updates add persistent memory, infinite sessions, and context compaction, support for explore and plan workflows with model selection per step, custom agents and agent skills, full MCP support, and asynchronous task delegation. The SDK benefits from this work, because it exposes that same behavior through language specific libraries.</p>\n<p>Key Takeaways</p>\n<p>GitHub Copilot-SDK exposes the same agentic execution loop that powers GitHub Copilot CLI, so applications can call a production tested planner that runs multi step workflows with tools and commands.</p>\n<p>The SDK is available for Node.js, Python, Go, and .NET, and each language binding provides a similar abstraction around clients and sessions that manage multi turn conversations and tool use.</p>\n<p>Developers define domain specific tools and Model Context Protocol servers, then register them through the SDK, and the Copilot agent decides when and how to call them as part of the plan.</p>\n<p>The runtime integrates with GitHub authentication and Copilot subscriptions, supports multiple AI models such as GPT based backends, and exposes real time streaming so applications can render partial responses incrementally.</p>\n<p>Check out the&nbsp;GitHub Page.&nbsp;Also,&nbsp;feel free to follow us on&nbsp;Twitter&nbsp;and don’t forget to join our&nbsp;100k+ ML SubReddit&nbsp;and Subscribe to&nbsp;our Newsletter. Wait! are you on telegram?&nbsp;now you can join us on telegram as well.</p>\n<p>The post GitHub Releases Copilot-SDK to Embed Its Agentic Runtime in Any App appeared first on MarkTechPost.</p>"
    },
    {
      "id": "57513b798d32",
      "title": "Enterprises Should Prioritize Governance Amid Agentic AI Boom",
      "content": "Executives from Accenture and Okta warned that the rapid adoption of autonomous AI agents is outpacing governance strategies.",
      "url": "https://aibusiness.com/agentic-ai/enterprises-should-prioritize-governance-amid-agentic-ai-boom",
      "author": "Scarlett Evans",
      "published": "2026-01-23T00:45:26",
      "source": "aibusiness",
      "source_type": "rss",
      "tags": [],
      "summary": "Executives from Accenture and Okta warned that rapid adoption of autonomous AI agents is outpacing enterprise governance strategies. Companies are urged to prioritize governance frameworks amid the agentic AI boom.",
      "importance_score": 52.0,
      "reasoning": "Timely governance discussion as agent deployment accelerates, but represents industry commentary rather than breakthrough news.",
      "themes": [
        "AI Governance",
        "Enterprise AI",
        "Agentic AI"
      ],
      "continuation": null,
      "summary_html": "<p>Executives from Accenture and Okta warned that rapid adoption of autonomous AI agents is outpacing enterprise governance strategies. Companies are urged to prioritize governance frameworks amid the agentic AI boom.</p>",
      "content_html": "<p>Executives from Accenture and Okta warned that the rapid adoption of autonomous AI agents is outpacing governance strategies.</p>"
    },
    {
      "id": "1bf79f5d243b",
      "title": "Mumbai to Host World’s First AI GCC Hub as Maharashtra & Supervity AI Sign Landmark MoU at Davos",
      "content": "The Maharashtra government and Supervity AI have signed a landmark MoU at the World Economic Forum Annual Meeting 2026 in Davos to establish the world’s first AI global capability centre (GCC) Hub in Mumbai.\n\n\n\nThe hub will function as a next-generation applied agentic AI R&amp;D and innovation centre, enabling global enterprises to transition from traditional offshore GCC models to AI-first operations powered by autonomous, policy-driven multi-agent AI systems.&nbsp;\n\n\n\nThe hub will be anchored in Mumbai’s central business district, the Bandra Kurla Complex (BKC), and will operate as a launchpad for multinational enterprises to design, test, deploy, and scale multi-agent AI employees across finance, procurement, compliance, supply chain, customer operations, and other core business functions.\n\n\n\nUnlike conventional GCCs that depend on human-intensive execution, Supervity AI’s GCC hub will focus on self-driving AI employees, operating under human-defined policies, governance frameworks, and enterprise-grade auditability.\n\n\n\nUnder the MoU, Supervity AI and the state government will jointly establish a dedicated agentic AI R&amp;D centre under the hub.\n\n\n\nThis will enable enterprises to safely deploy AI-driven operating models across front, middle, and back-office functions, develop AI-first operating frameworks aligned with global regulatory and compliance standards, and build a robust ecosystem of AI talent, solution partners, and enterprise adopters to support large-scale, responsible adoption of AI-first enterprise operations.\n\n\n\nAs part of the broader initiative, the state will support talent enablement and institutional partnerships, including the structured training of up to 25,000 forward-deployed AI engineers over time.&nbsp;\n\n\n\nSupervity AI also plans to establish four industry-focused AI GCC spoke centres across key nodes in Maharashtra, leveraging tier-2 city talent through a distributed hub-and-spoke model.\n\n\n\nThe collaboration will also explore the progressive adoption of AI-led operating models across 48 Maharashtra government departments, contributing to the creation of a state-level AI GCC framework supported by technology partners.\n\n\n\nCommenting on the partnership, Siva Moduga, co-founder and CEO, Supervity AI, said, “Enterprise operations are undergoing a structural shift. Traditional GBS and GCC models were designed for scale through human effort, whereas the next decade demands scale through AI execution with strong governance.”\nThe post Mumbai to Host World’s First AI GCC Hub as Maharashtra &#038; Supervity AI Sign Landmark MoU at Davos appeared first on Analytics India Magazine.",
      "url": "https://analyticsindiamag.com/ai-news-updates/mumbai-to-host-worlds-first-ai-gcc-hub-as-maharashtra-supervity-ai-sign-landmark-mou-at-davos/",
      "author": "Shalini Mondal",
      "published": "2026-01-23T11:28:24",
      "source": "Analytics India Magazine",
      "source_type": "rss",
      "tags": [
        "AI News",
        "GCC india"
      ],
      "summary": "Maharashtra and Supervity AI signed an MoU at Davos to establish the world's first AI Global Capability Centre Hub in Mumbai's BKC district. The hub will enable enterprises to transition to AI-first operations with multi-agent systems.",
      "importance_score": 50.0,
      "reasoning": "Notable regional AI infrastructure initiative, though primarily a government partnership announcement with uncertain implementation timeline.",
      "themes": [
        "India Tech",
        "AI Infrastructure",
        "Policy"
      ],
      "continuation": null,
      "summary_html": "<p>Maharashtra and Supervity AI signed an MoU at Davos to establish the world's first AI Global Capability Centre Hub in Mumbai's BKC district. The hub will enable enterprises to transition to AI-first operations with multi-agent systems.</p>",
      "content_html": "<p>The Maharashtra government and Supervity AI have signed a landmark MoU at the World Economic Forum Annual Meeting 2026 in Davos to establish the world’s first AI global capability centre (GCC) Hub in Mumbai.</p>\n<p>The hub will function as a next-generation applied agentic AI R&amp;D and innovation centre, enabling global enterprises to transition from traditional offshore GCC models to AI-first operations powered by autonomous, policy-driven multi-agent AI systems.&nbsp;</p>\n<p>The hub will be anchored in Mumbai’s central business district, the Bandra Kurla Complex (BKC), and will operate as a launchpad for multinational enterprises to design, test, deploy, and scale multi-agent AI employees across finance, procurement, compliance, supply chain, customer operations, and other core business functions.</p>\n<p>Unlike conventional GCCs that depend on human-intensive execution, Supervity AI’s GCC hub will focus on self-driving AI employees, operating under human-defined policies, governance frameworks, and enterprise-grade auditability.</p>\n<p>Under the MoU, Supervity AI and the state government will jointly establish a dedicated agentic AI R&amp;D centre under the hub.</p>\n<p>This will enable enterprises to safely deploy AI-driven operating models across front, middle, and back-office functions, develop AI-first operating frameworks aligned with global regulatory and compliance standards, and build a robust ecosystem of AI talent, solution partners, and enterprise adopters to support large-scale, responsible adoption of AI-first enterprise operations.</p>\n<p>As part of the broader initiative, the state will support talent enablement and institutional partnerships, including the structured training of up to 25,000 forward-deployed AI engineers over time.&nbsp;</p>\n<p>Supervity AI also plans to establish four industry-focused AI GCC spoke centres across key nodes in Maharashtra, leveraging tier-2 city talent through a distributed hub-and-spoke model.</p>\n<p>The collaboration will also explore the progressive adoption of AI-led operating models across 48 Maharashtra government departments, contributing to the creation of a state-level AI GCC framework supported by technology partners.</p>\n<p>Commenting on the partnership, Siva Moduga, co-founder and CEO, Supervity AI, said, “Enterprise operations are undergoing a structural shift. Traditional GBS and GCC models were designed for scale through human effort, whereas the next decade demands scale through AI execution with strong governance.”</p>\n<p>The post Mumbai to Host World’s First AI GCC Hub as Maharashtra &amp; Supervity AI Sign Landmark MoU at Davos appeared first on Analytics India Magazine.</p>"
    },
    {
      "id": "8423d318a684",
      "title": "Coforge Now Infuses AI in 100% Projects, Refuses to Reveal AI Revenue",
      "content": "For a mid-tier IT firm, Coforge’s performance is unusually strong, especially in a quarter that’s often relatively lukewarm. In Q3, the company outdid itself, all thanks to AI.\n\n\n\n“Almost 100% of the wins and new contracts being awarded to us are AI-infused,” CEO and executive director Sudhir Singh said during the earnings call. Not AI pilots, not strategy decks, but live projects tied to delivery and business outcomes.&nbsp;\n\n\n\nCoforge, he said, is “bringing the promise of AI to fruition, instead of just talking about agnostic.” It was a pointed remark in a season where everyone talked about AI-led revenue.\n\n\n\nThe numbers gave Singh room to be confident. Coforge grew 4.4% sequentially in constant currency terms, with revenue for the quarter ended December 2025 totalling ₹4,188 crore ($478 million). Order intake hit $593 million, helped by six large deals in what is usually a weak quarter.\n\n\n\nThe real anchor was the pipeline. The executable order book for the next twelve months rose to $1.72 billion, more than 30% higher than a year ago. Year-to-date dollar revenue growth now stands at 32.8%, an outlier in a market where most large firms are still struggling to cross 3–4%.\n\n\n\nMargins slipped, but not in a way that changed the tone. Free cash flow came in at 110%, far ahead of guidance. Net profit told a messier story. Profit fell 33% sequentially to ₹250 crore ($27.3 million), hit by a one-time ₹118 crore ($12.9 million) impact from labour code changes, but that is across the board for all firms.\n\n\n\nWhat Makes Coforge Stand Out?\n\n\n\nIn the earnings call, Singh talked about how two years ago, boards were asking how the company would adopt AI. Today, he said, that question is gone. Clients now want proof of impact, measurable gains, and operational change. “The age of AI experimentation is over,” he said. What matters now is whether firms can modernise foundations and deliver AI as part of one integrated transformation.\n\n\n\nThat framing explains how Coforge sees its edge in the business. The firm is not chasing client counts; it has about 600 clients and wants growth from depth, not breadth. Around 95% percent of revenue comes from repeat business. The top five clients grew 51% year-to-date. The top ten grew 47%.\n\n\n\nWhen it comes to hiring, rose by its headcount by 445 to 35,341. Attrition eased to 10.9%, among the lowest in the industry.\n\n\n\nWhen it comes to hiring AI-ready fresh graduates, Singh said that, unlike engineers from earlier generations, new freshers have never really relied on certifications to prove their value.&nbsp;\n\n\n\n“They come from an ecosystem in colleges globally, which is very hackathon-centric. They are used to being put into situations where they have to find a solution. Given how powerful AI is as a technology, that is the number one skill that you look for, and given the fact that the new cohort of engineers fresh from college has that in abundance, we have definitely not changed the talent catchment that we go after,” Singh explained.\n\n\n\nThe delivery examples were tightly chosen. At a European global bank, Coforge deployed autonomous agents across data silos to rework cash flow forecasting. At a global airline, it rebuilt the software life cycle using AI-led engineering. At a US financial services firm, its ForgeX platform, an integrated engineering and delivery service launched in November last year,&nbsp; has more than 20 domain-specific agents to govern automation.\n\n\n\nThe acquisition of Encora sits at the centre of that strategy. The quarter’s numbers do not include it yet. Once closed, Singh said, the combined firm will have a $2.5 billion revenue base across data, cloud, and AI engineering. Coforge has decided not to retire Encora’s $500 million debt through a QIP, opting instead for bank financing at mid-single-digit rates.\n\n\n\nThe Bigger Point: Positioning\n\n\n\nAcross Indian IT, AI strategies are now splitting into camps.&nbsp;\n\n\n\nTCS reported scale, with $1.8 billion in annualised AI revenue, though it still forms a small share of total business. HCLTech reported precision, with $146 million in advanced AI revenue, narrowly defined. Meanwhile, Infosys refused to publish a number, choosing instead to talk about 4,600 projects, 500 agents in production, and 28 million lines of AI-generated code.\n\n\n\nCoforge has chosen a fourth path. It did not publish an AI revenue line at all. Instead, Singh said almost every new deal is already AI-infused. AI is not a business unit for Coforge; it is the delivery model.\nThe post Coforge Now Infuses AI in 100% Projects, Refuses to Reveal AI Revenue appeared first on Analytics India Magazine.",
      "url": "https://analyticsindiamag.com/it-services/coforge-now-infuses-ai-in-100-projects-refuses-to-reveal-ai-revenue/",
      "author": "Mohit Pandey",
      "published": "2026-01-23T06:51:40",
      "source": "Analytics India Magazine",
      "source_type": "rss",
      "tags": [
        "IT Services"
      ],
      "summary": "Coforge CEO reported that 100% of new wins and contracts are now AI-infused, with Q3 revenue reaching ₹4,188 crore. The IT firm emphasized delivering actual AI business outcomes rather than pilots.",
      "importance_score": 48.0,
      "reasoning": "Interesting data point on enterprise AI adoption maturity, but primarily company earnings context rather than frontier AI news.",
      "themes": [
        "Enterprise AI",
        "IT Services",
        "India Tech"
      ],
      "continuation": null,
      "summary_html": "<p>Coforge CEO reported that 100% of new wins and contracts are now AI-infused, with Q3 revenue reaching ₹4,188 crore. The IT firm emphasized delivering actual AI business outcomes rather than pilots.</p>",
      "content_html": "<p>For a mid-tier IT firm, Coforge’s performance is unusually strong, especially in a quarter that’s often relatively lukewarm. In Q3, the company outdid itself, all thanks to AI.</p>\n<p>“Almost 100% of the wins and new contracts being awarded to us are AI-infused,” CEO and executive director Sudhir Singh said during the earnings call. Not AI pilots, not strategy decks, but live projects tied to delivery and business outcomes.&nbsp;</p>\n<p>Coforge, he said, is “bringing the promise of AI to fruition, instead of just talking about agnostic.” It was a pointed remark in a season where everyone talked about AI-led revenue.</p>\n<p>The numbers gave Singh room to be confident. Coforge grew 4.4% sequentially in constant currency terms, with revenue for the quarter ended December 2025 totalling ₹4,188 crore ($478 million). Order intake hit $593 million, helped by six large deals in what is usually a weak quarter.</p>\n<p>The real anchor was the pipeline. The executable order book for the next twelve months rose to $1.72 billion, more than 30% higher than a year ago. Year-to-date dollar revenue growth now stands at 32.8%, an outlier in a market where most large firms are still struggling to cross 3–4%.</p>\n<p>Margins slipped, but not in a way that changed the tone. Free cash flow came in at 110%, far ahead of guidance. Net profit told a messier story. Profit fell 33% sequentially to ₹250 crore ($27.3 million), hit by a one-time ₹118 crore ($12.9 million) impact from labour code changes, but that is across the board for all firms.</p>\n<p>What Makes Coforge Stand Out?</p>\n<p>In the earnings call, Singh talked about how two years ago, boards were asking how the company would adopt AI. Today, he said, that question is gone. Clients now want proof of impact, measurable gains, and operational change. “The age of AI experimentation is over,” he said. What matters now is whether firms can modernise foundations and deliver AI as part of one integrated transformation.</p>\n<p>That framing explains how Coforge sees its edge in the business. The firm is not chasing client counts; it has about 600 clients and wants growth from depth, not breadth. Around 95% percent of revenue comes from repeat business. The top five clients grew 51% year-to-date. The top ten grew 47%.</p>\n<p>When it comes to hiring, rose by its headcount by 445 to 35,341. Attrition eased to 10.9%, among the lowest in the industry.</p>\n<p>When it comes to hiring AI-ready fresh graduates, Singh said that, unlike engineers from earlier generations, new freshers have never really relied on certifications to prove their value.&nbsp;</p>\n<p>“They come from an ecosystem in colleges globally, which is very hackathon-centric. They are used to being put into situations where they have to find a solution. Given how powerful AI is as a technology, that is the number one skill that you look for, and given the fact that the new cohort of engineers fresh from college has that in abundance, we have definitely not changed the talent catchment that we go after,” Singh explained.</p>\n<p>The delivery examples were tightly chosen. At a European global bank, Coforge deployed autonomous agents across data silos to rework cash flow forecasting. At a global airline, it rebuilt the software life cycle using AI-led engineering. At a US financial services firm, its ForgeX platform, an integrated engineering and delivery service launched in November last year,&nbsp; has more than 20 domain-specific agents to govern automation.</p>\n<p>The acquisition of Encora sits at the centre of that strategy. The quarter’s numbers do not include it yet. Once closed, Singh said, the combined firm will have a $2.5 billion revenue base across data, cloud, and AI engineering. Coforge has decided not to retire Encora’s $500 million debt through a QIP, opting instead for bank financing at mid-single-digit rates.</p>\n<p>The Bigger Point: Positioning</p>\n<p>Across Indian IT, AI strategies are now splitting into camps.&nbsp;</p>\n<p>TCS reported scale, with $1.8 billion in annualised AI revenue, though it still forms a small share of total business. HCLTech reported precision, with $146 million in advanced AI revenue, narrowly defined. Meanwhile, Infosys refused to publish a number, choosing instead to talk about 4,600 projects, 500 agents in production, and 28 million lines of AI-generated code.</p>\n<p>Coforge has chosen a fourth path. It did not publish an AI revenue line at all. Instead, Singh said almost every new deal is already AI-infused. AI is not a business unit for Coforge; it is the delivery model.</p>\n<p>The post Coforge Now Infuses AI in 100% Projects, Refuses to Reveal AI Revenue appeared first on Analytics India Magazine.</p>"
    },
    {
      "id": "dbbb231ccdaf",
      "title": "Scaling without Slop",
      "content": "First off, a few major announcements:Yi Tay returns to the podcast today! If you enjoyed his insights on being a 10,000x Yolo Researcher, then you&#8217;ll love our catchup on Gemini&#8217;s IMO Gold and more.Welcome to the 80,000 AINews subscribers! We are doubling down on Substack, making Latent Space the one email subscription to keep up on a daily (AINews), weekly (LS Pod), and broader (LS Essays) basis. You can opt-in/out as needed.Latent Space is also turning into a podcast network! Our first new show, focused on AI For Science, will launch next week, inspired by our Chan-Zuckerberg pod! We also have a new physical space/studio at Kernel in SF!AI Engineer is growing! The first official AIE Europe is coming to London April 8-10, and both Super Early Bird tix and Speaker CFPs first deadline is Jan 31st.We are hiring across all platforms: AIE Head of Operations, AIE Marketing &amp; Community Manager, LS Researcher/Writer (or occasional Guest Writer!)At every AIE conference I run, I give myself the challenge of doing the shortest keynote for a &#8220;State of the Nation&#8221; type address. For AIE Code, I declared War on Slop.This was partially inspired by seeing the motivating factors behind products like Codemaps and Review, and partially a reaction to the &#8220;Canadian Girlfriend AI Coding&#8221; performative productivity porn that took over the timeline:tweetI didn&#8217;t expect Slop to then be picked up as word of the year by Merriam-Webster and the Economist and the American Dialect Society1, but clearly the theme of fighting Slop is resonating as generative AI rips the authenticity from creation, piles up open source maintainer workload, fills up academic conference submissions, taking up 20% of YouTube videos (earning millions per year) and running entire Instagram channels and the Apple App Store, slowly deadening the Internet.There are a few gut reactions to Slop that are reasonable:simply reject all AI-generated content, perhaps making exception for AI-assisted, perhaps requiring proof of human reviewseverely cut back on quantity to message and deliver qualityjust eat the steak and learn to enjoy the slop machineHowever, they feel variously dissatisfying in their general defeatism and pessimistic view of human taste being scalable.First off, I&#8217;ll reiterate the obvious point that plenty of Slop has been made by humans, both well-meaning and cynical, for centuries &#8212;&nbsp;AI does not have a monopoly on making Slop. However, AI does make it easy to scale thoughtless output and it is harder to signal intent, effort and quality &#8212; an emphasis of my recent writing retreat. If you creatively/skillfully wield AI as \"a new brush&#8221;, then AI Kino is very possible.But more importantly, if your solution to AI slop basically means you cut back on your own human output, that doesn&#8217;t solve the fact that AI slop will continue to far outpace human output, and therefore simply overwhelm you and your community by sheer brute force and our own recsys&#8217; inability to keep up with our tastes. Humanity slowly starves to death gorging on its own excrement spewed from artificial intestines.The most important problem in media now is scaling without slop, period, whether or not AI generated or entirely human-origin. Actually I lied, it&#8217;s not just a media problem: any act of creation and exercise of free will is is subject to the quality-quantity tradeoff, whether you&#8217;re building a new product or texting your adult kids. Any experienced creator will tell you that there can be very little relationship between effort and result - the thing you slaved on for a month gets overdone and incoherent, whereas the throwaway tweet of frustration done in 3 seconds gets viral and used as an example for decades to come. Sometimes -you- can&#8217;t tell what&#8217;s slop, sometimes one man&#8217;s slop is another man&#8217;s kino.The central problem to solve is the changing the slope of slop, not giving up on humans.edits welcomeThis is the problem I am working on now for both AI Engineer and Latent Space. The case studies of increasing quantity AND quality have been fascinating.Scaling AI EngineerAI Engineer grew from one event a year in 2023 and 2024 to 4 (AIE NYC, AIE WF, AIE Paris, AIE CODE) in 2025, and there will be at least 7 AIEs around the world in 2026.the new AIE websiteViewership did not just 3x, but more than 10x&#8217;ed:And anecdotally, quality has also improved:I remember a former 2024 speaker who is known for speaking his mind, and being privately pretty cynical about AIE, in 2025 coming back to me to say that conversations and talks felt a lot more authentic and serious this time around.I say this not as a brag, but I think there are a lot of conscious and subconscious decisions made that contribute toward building a leading IRL and online community for serious, grounded AI discussion without resorting to fearmongering or hyperbole.Slop has definitely crept in, but here we have kept closer to &#8220;Scaling Law X&#8221; than Scaling Law 0 and I&#8217;m happy about that.Scaling Latent SpaceLatent Space (now joined with AINews) has been a tougher beast. The value of media cycles often fit to Sonal Choksi&#8217;s McClusky Curve &#8212;&nbsp;flanked on the left by TBPN, and on the right by Dwarkesh. We did AMAZING as a podcast - regularly in the 30-50th ranks of the overall US Tech podcasts in Apple, and considered by many to be a top 3 AI podcast, being featured on the GPT5 launch, and featuring conversations with Greg Brockman and Fei-Fei Li and Mark Zuckerberg and Noam Brown and Bret Taylor and Chris Lattner and the Claude Code team and more household names to come. While our YouTube numbers are still wanting (pls like and subscribe! we started YouTube way, way too late in this game), audio subscribers are still incredibly strong, and Flightcast estimates us at about 1.5m all time unique listeners now.But we fell behind on writing, evidenced by 2025&#8217;s Agent Labs Thesis far underperforming the AI Engineer Reading List (which we&#8217;ve continued to maintain, but slowly left behind as less and less frontier knowledge is published).There&#8217;s only so much that one person can do. I am very inspired by creative networks that build a platform for multiple people to shine and contribute their talents, like Dropout TV and Morning Brew and SemiAnalysis. This is part of the movement that a16z has termed New Media, and perhaps unlike most on that list, I want to try to build a platform clearly bigger than me and hopefully bigger than the some of its parts.The game plan for 2026&#8217;s Latent Space is threefold:More shows, more hosts: The 1-2 hour interview podcast format is cool but Alessio and I can only do so much. We&#8217;ll be doing more education (the booming area of AI for Science is our next focus, with new hosts), but also entertainment (AI can be fun! and AI people are REALLY FUN). Most of our new investments will go into more YouTube and video-native formats.More formats: AINews joining Latent Space gives you a place for regular daily updates and commentary. TBA on where the future of AI News should be beyond just a newsletter&#8230; but ideas are welcomeMore writing: Writing is thinking, and good thinking powers everything great we have done with Latent Space. We will double down on this and, if you&#8217;re keen to help, join us as a researcher or writer full time, or even apply to guest post (we have always done very well serving as editors for guest posts)The Elements of Curation: Tuning High TasteThe common thread among AIE and LS is that we have to curate very well, and then scale one person&#8217;s curation to many, hopefully by crowdsourcing but also taking audience/community feedback very seriously. The most visible output of this is &#8220;saying no a lot&#8221;, and this is a lonely job saying no to friends and to sponsors, but even that is too broad a brush. There is no &#8220;school for curators&#8221;, no Maven or Udemy course for curating. You have to have a point of view, you have to know your audience better than they know themselves, and you have to have the freedom to make mistakes and survive making experiments with a high failure rate. Fortunately, we have enough backing and support (read: donations, partially from generous investors (who have been explicitly told we will never sell or sell out), but operating expenses actually come from Substack subscribers! thank you!) that we don&#8217;t have to couple this with any sort of business model. We just want to Make Good Shit at Scale.Welcome to 2026. It&#8217;s gonna be a fun ride.1where it was a runner-up last year, and coined 2 years ago perhaps by @deepfates",
      "url": "https://www.latent.space/p/2026",
      "author": "swyx (Shawn)",
      "published": "2026-01-23T18:16:58",
      "source": "Latent.Space",
      "source_type": "rss",
      "tags": [],
      "summary": "Latent Space newsletter announced podcast network expansion and referenced Gemini's IMO Gold achievement. The publication is launching an AI for Science focused show.",
      "importance_score": 45.0,
      "reasoning": "Mostly promotional content with brief Gemini reference. Limited new information on frontier developments.",
      "themes": [
        "Media",
        "AI Research",
        "Community"
      ],
      "continuation": null,
      "summary_html": "<p>Latent Space newsletter announced podcast network expansion and referenced Gemini's IMO Gold achievement. The publication is launching an AI for Science focused show.</p>",
      "content_html": "<p>First off, a few major announcements:Yi Tay returns to the podcast today! If you enjoyed his insights on being a 10,000x Yolo Researcher, then you’ll love our catchup on Gemini’s IMO Gold and more.Welcome to the 80,000 AINews subscribers! We are doubling down on Substack, making Latent Space the one email subscription to keep up on a daily (AINews), weekly (LS Pod), and broader (LS Essays) basis. You can opt-in/out as needed.Latent Space is also turning into a podcast network! Our first new show, focused on AI For Science, will launch next week, inspired by our Chan-Zuckerberg pod! We also have a new physical space/studio at Kernel in SF!AI Engineer is growing! The first official AIE Europe is coming to London April 8-10, and both Super Early Bird tix and Speaker CFPs first deadline is Jan 31st.We are hiring across all platforms: AIE Head of Operations, AIE Marketing &amp; Community Manager, LS Researcher/Writer (or occasional Guest Writer!)At every AIE conference I run, I give myself the challenge of doing the shortest keynote for a “State of the Nation” type address. For AIE Code, I declared War on Slop.This was partially inspired by seeing the motivating factors behind products like Codemaps and Review, and partially a reaction to the “Canadian Girlfriend AI Coding” performative productivity porn that took over the timeline:tweetI didn’t expect Slop to then be picked up as word of the year by Merriam-Webster and the Economist and the American Dialect Society1, but clearly the theme of fighting Slop is resonating as generative AI rips the authenticity from creation, piles up open source maintainer workload, fills up academic conference submissions, taking up 20% of YouTube videos (earning millions per year) and running entire Instagram channels and the Apple App Store, slowly deadening the Internet.There are a few gut reactions to Slop that are reasonable:simply reject all AI-generated content, perhaps making exception for AI-assisted, perhaps requiring proof of human reviewseverely cut back on quantity to message and deliver qualityjust eat the steak and learn to enjoy the slop machineHowever, they feel variously dissatisfying in their general defeatism and pessimistic view of human taste being scalable.First off, I’ll reiterate the obvious point that plenty of Slop has been made by humans, both well-meaning and cynical, for centuries —&nbsp;AI does not have a monopoly on making Slop. However, AI does make it easy to scale thoughtless output and it is harder to signal intent, effort and quality — an emphasis of my recent writing retreat. If you creatively/skillfully wield AI as \"a new brush”, then AI Kino is very possible.But more importantly, if your solution to AI slop basically means you cut back on your own human output, that doesn’t solve the fact that AI slop will continue to far outpace human output, and therefore simply overwhelm you and your community by sheer brute force and our own recsys’ inability to keep up with our tastes. Humanity slowly starves to death gorging on its own excrement spewed from artificial intestines.The most important problem in media now is scaling without slop, period, whether or not AI generated or entirely human-origin. Actually I lied, it’s not just a media problem: any act of creation and exercise of free will is is subject to the quality-quantity tradeoff, whether you’re building a new product or texting your adult kids. Any experienced creator will tell you that there can be very little relationship between effort and result - the thing you slaved on for a month gets overdone and incoherent, whereas the throwaway tweet of frustration done in 3 seconds gets viral and used as an example for decades to come. Sometimes -you- can’t tell what’s slop, sometimes one man’s slop is another man’s kino.The central problem to solve is the changing the slope of slop, not giving up on humans.edits welcomeThis is the problem I am working on now for both AI Engineer and Latent Space. The case studies of increasing quantity AND quality have been fascinating.Scaling AI EngineerAI Engineer grew from one event a year in 2023 and 2024 to 4 (AIE NYC, AIE WF, AIE Paris, AIE CODE) in 2025, and there will be at least 7 AIEs around the world in 2026.the new AIE websiteViewership did not just 3x, but more than 10x’ed:And anecdotally, quality has also improved:I remember a former 2024 speaker who is known for speaking his mind, and being privately pretty cynical about AIE, in 2025 coming back to me to say that conversations and talks felt a lot more authentic and serious this time around.I say this not as a brag, but I think there are a lot of conscious and subconscious decisions made that contribute toward building a leading IRL and online community for serious, grounded AI discussion without resorting to fearmongering or hyperbole.Slop has definitely crept in, but here we have kept closer to “Scaling Law X” than Scaling Law 0 and I’m happy about that.Scaling Latent SpaceLatent Space (now joined with AINews) has been a tougher beast. The value of media cycles often fit to Sonal Choksi’s McClusky Curve —&nbsp;flanked on the left by TBPN, and on the right by Dwarkesh. We did AMAZING as a podcast - regularly in the 30-50th ranks of the overall US Tech podcasts in Apple, and considered by many to be a top 3 AI podcast, being featured on the GPT5 launch, and featuring conversations with Greg Brockman and Fei-Fei Li and Mark Zuckerberg and Noam Brown and Bret Taylor and Chris Lattner and the Claude Code team and more household names to come. While our YouTube numbers are still wanting (pls like and subscribe! we started YouTube way, way too late in this game), audio subscribers are still incredibly strong, and Flightcast estimates us at about 1.5m all time unique listeners now.But we fell behind on writing, evidenced by 2025’s Agent Labs Thesis far underperforming the AI Engineer Reading List (which we’ve continued to maintain, but slowly left behind as less and less frontier knowledge is published).There’s only so much that one person can do. I am very inspired by creative networks that build a platform for multiple people to shine and contribute their talents, like Dropout TV and Morning Brew and SemiAnalysis. This is part of the movement that a16z has termed New Media, and perhaps unlike most on that list, I want to try to build a platform clearly bigger than me and hopefully bigger than the some of its parts.The game plan for 2026’s Latent Space is threefold:More shows, more hosts: The 1-2 hour interview podcast format is cool but Alessio and I can only do so much. We’ll be doing more education (the booming area of AI for Science is our next focus, with new hosts), but also entertainment (AI can be fun! and AI people are REALLY FUN). Most of our new investments will go into more YouTube and video-native formats.More formats: AINews joining Latent Space gives you a place for regular daily updates and commentary. TBA on where the future of AI News should be beyond just a newsletter… but ideas are welcomeMore writing: Writing is thinking, and good thinking powers everything great we have done with Latent Space. We will double down on this and, if you’re keen to help, join us as a researcher or writer full time, or even apply to guest post (we have always done very well serving as editors for guest posts)The Elements of Curation: Tuning High TasteThe common thread among AIE and LS is that we have to curate very well, and then scale one person’s curation to many, hopefully by crowdsourcing but also taking audience/community feedback very seriously. The most visible output of this is “saying no a lot”, and this is a lonely job saying no to friends and to sponsors, but even that is too broad a brush. There is no “school for curators”, no Maven or Udemy course for curating. You have to have a point of view, you have to know your audience better than they know themselves, and you have to have the freedom to make mistakes and survive making experiments with a high failure rate. Fortunately, we have enough backing and support (read: donations, partially from generous investors (who have been explicitly told we will never sell or sell out), but operating expenses actually come from Substack subscribers! thank you!) that we don’t have to couple this with any sort of business model. We just want to Make Good Shit at Scale.Welcome to 2026. It’s gonna be a fun ride.1where it was a runner-up last year, and coined 2 years ago perhaps by @deepfates</p>"
    },
    {
      "id": "951f504e9274",
      "title": "Ex-Google Executive Peeyush Ranjan Launches AI EdTech Startup Fermi.ai in India & USA",
      "content": "Former Google GM and VP Peeyush Ranjan has launched Fermi.ai, an AI-first edtech startup aimed at transforming high-school STEM education across India and the United States.&nbsp;\n\n\n\nHeadquartered in Singapore, the company is rolling out its learning platform through subsidiaries in both countries, beginning with mathematics, physics and chemistry.\n\n\n\nFermi.ai is built around what the company calls “productive struggle”, a learning philosophy that encourages students to work through mistakes and strengthen conceptual understanding rather than rely on shortcuts. The platform uses AI to analyse how a student arrives at an answer, identifying gaps in reasoning and offering step-by-step guidance instead of direct solutions.\n\n\n\n“Students today are getting answers faster than ever, but their understanding is getting weaker,” Ranjan said, who has also served as CTO of Flipkart and held leadership roles at Airbnb. “We built Fermi.ai to support thinking, not replace it, and to give educators visibility into struggles that usually stay hidden.”\n\n\n\nThe startup has emerged from Meraki Labs, where Ranjan partners with entrepreneur Mukesh Bansal, founder of Myntra. Bansal said Fermi.ai focuses on mapping a student’s thought process rather than solving problems for them. “It’s about showing students how they think, and helping teachers guide them back to mastery,” he noted.\n\n\n\nBansal also launched Nurix, which is another emerging AI startup focused on building AI-native consumer and internet products.\n\n\n\nFermi.ai’s platform is built around four core components: an adaptive real-time tutor that provides pedagogically guided hints, a stylus-first smart canvas designed for handwritten equations and diagrams, a concept-linked question bank aligned with exams such as AP, IB and JEE, and an analytics layer that pinpoints where student reasoning breaks down.\n\n\n\nBefore its public launch, the company conducted a three-month pilot with 79 students, covering over 15,000 concept tests. According to the startup, students who initially struggled showed an average improvement of 4.68 points by their final attempts, while heavy users demonstrated higher mastery gains and reduced dependence on hints.\n\n\n\nThe cloud-based platform is currently available for free at fermi.ai, with a dedicated pilot programme for educators launching in 2026.\nThe post Ex-Google Executive Peeyush Ranjan Launches AI EdTech Startup Fermi.ai in India &amp; USA appeared first on Analytics India Magazine.",
      "url": "https://analyticsindiamag.com/ai-news-updates/ex-google-executive-peeyush-ranjan-launches-ai-edtech-startup-fermi-ai-in-india-usa/",
      "author": "Merin Susan John",
      "published": "2026-01-23T12:04:00",
      "source": "Analytics India Magazine",
      "source_type": "rss",
      "tags": [
        "AI News"
      ],
      "summary": "Former Google VP Peeyush Ranjan launched Fermi.ai, an AI-first edtech startup targeting high-school STEM education in India and the US. The platform emphasizes 'productive struggle' over direct answers.",
      "importance_score": 45.0,
      "reasoning": "Notable founder pedigree but represents application-layer startup launch rather than frontier AI advancement.",
      "themes": [
        "EdTech",
        "Startup",
        "AI Applications"
      ],
      "continuation": null,
      "summary_html": "<p>Former Google VP Peeyush Ranjan launched Fermi.ai, an AI-first edtech startup targeting high-school STEM education in India and the US. The platform emphasizes 'productive struggle' over direct answers.</p>",
      "content_html": "<p>Former Google GM and VP Peeyush Ranjan has launched Fermi.ai, an AI-first edtech startup aimed at transforming high-school STEM education across India and the United States.&nbsp;</p>\n<p>Headquartered in Singapore, the company is rolling out its learning platform through subsidiaries in both countries, beginning with mathematics, physics and chemistry.</p>\n<p>Fermi.ai is built around what the company calls “productive struggle”, a learning philosophy that encourages students to work through mistakes and strengthen conceptual understanding rather than rely on shortcuts. The platform uses AI to analyse how a student arrives at an answer, identifying gaps in reasoning and offering step-by-step guidance instead of direct solutions.</p>\n<p>“Students today are getting answers faster than ever, but their understanding is getting weaker,” Ranjan said, who has also served as CTO of Flipkart and held leadership roles at Airbnb. “We built Fermi.ai to support thinking, not replace it, and to give educators visibility into struggles that usually stay hidden.”</p>\n<p>The startup has emerged from Meraki Labs, where Ranjan partners with entrepreneur Mukesh Bansal, founder of Myntra. Bansal said Fermi.ai focuses on mapping a student’s thought process rather than solving problems for them. “It’s about showing students how they think, and helping teachers guide them back to mastery,” he noted.</p>\n<p>Bansal also launched Nurix, which is another emerging AI startup focused on building AI-native consumer and internet products.</p>\n<p>Fermi.ai’s platform is built around four core components: an adaptive real-time tutor that provides pedagogically guided hints, a stylus-first smart canvas designed for handwritten equations and diagrams, a concept-linked question bank aligned with exams such as AP, IB and JEE, and an analytics layer that pinpoints where student reasoning breaks down.</p>\n<p>Before its public launch, the company conducted a three-month pilot with 79 students, covering over 15,000 concept tests. According to the startup, students who initially struggled showed an average improvement of 4.68 points by their final attempts, while heavy users demonstrated higher mastery gains and reduced dependence on hints.</p>\n<p>The cloud-based platform is currently available for free at fermi.ai, with a dedicated pilot programme for educators launching in 2026.</p>\n<p>The post Ex-Google Executive Peeyush Ranjan Launches AI EdTech Startup Fermi.ai in India &amp; USA appeared first on Analytics India Magazine.</p>"
    },
    {
      "id": "e91b156dd52e",
      "title": "CitiusTech Partners with Ventra Health to Build Agentic AI Revenue Intelligence Platform",
      "content": "Healthcare technology services firm CitiusTech has partnered with Ventra Health to develop an agentic AI-powered revenue intelligence platform to improve revenue cycle management for healthcare providers.\n\n\n\nThe platform, branded vCision, uses AI-driven automation and adaptive models to identify revenue leakage, reduce claim denials, and improve reimbursement outcomes across complex billing workflows.&nbsp;\n\n\n\nThe companies said early deployments have shown a 19% improvement in first-pass payment rates and a 26% reduction in initial denial rates, along with faster recovery of delayed reimbursements.\n\n\n\nUnder the partnership, CitiusTech will support the engineering, data, and AI development of the platform, bringing its capabilities in healthcare technology, generative AI, and intelligent automation. Ventra Health is also setting up a new GCC, focused on engineering, data, and platform delivery to scale AI solutions across its operations.\n\n\n\nThe vCision platform is designed to help revenue cycle teams improve processing accuracy, anticipate changing reimbursement behaviour, and adapt to evolving payer guidelines. It also integrates real-time training and education for operational staff and extends Ventra’s enterprise analytics platform, vSight, launched in late 2023.\n\n\n\nRajan Kohli, CEO of CitiusTech, said the collaboration is focused on embedding AI-driven intelligence into revenue operations to improve financial predictability and reduce revenue loss. Ventra Health CEO Steven Huddleston said the platform will enable faster, more informed decision-making as reimbursement requirements continue to shift.\n\n\n\nVentra Health provides revenue cycle management services to facility-based physician groups across specialties including anaesthesia, emergency medicine, hospital medicine, pathology, and radiology.\nThe post CitiusTech Partners with Ventra Health to Build Agentic AI Revenue Intelligence Platform appeared first on Analytics India Magazine.",
      "url": "https://analyticsindiamag.com/ai-news-updates/citiustech-partners-with-ventra-health-to-build-agentic-ai-revenue-intelligence-platform/",
      "author": "Merin Susan John",
      "published": "2026-01-23T12:26:08",
      "source": "Analytics India Magazine",
      "source_type": "rss",
      "tags": [
        "AI News"
      ],
      "summary": "CitiusTech and Ventra Health partnered to build vCision, an agentic AI revenue intelligence platform for healthcare providers. Early deployments showed 19% improvement in first-pass payment rates.",
      "importance_score": 44.0,
      "reasoning": "Specialized healthcare AI application with measurable results, but represents incremental industry adoption rather than breakthrough.",
      "themes": [
        "Healthcare AI",
        "Agentic AI",
        "Enterprise"
      ],
      "continuation": null,
      "summary_html": "<p>CitiusTech and Ventra Health partnered to build vCision, an agentic AI revenue intelligence platform for healthcare providers. Early deployments showed 19% improvement in first-pass payment rates.</p>",
      "content_html": "<p>Healthcare technology services firm CitiusTech has partnered with Ventra Health to develop an agentic AI-powered revenue intelligence platform to improve revenue cycle management for healthcare providers.</p>\n<p>The platform, branded vCision, uses AI-driven automation and adaptive models to identify revenue leakage, reduce claim denials, and improve reimbursement outcomes across complex billing workflows.&nbsp;</p>\n<p>The companies said early deployments have shown a 19% improvement in first-pass payment rates and a 26% reduction in initial denial rates, along with faster recovery of delayed reimbursements.</p>\n<p>Under the partnership, CitiusTech will support the engineering, data, and AI development of the platform, bringing its capabilities in healthcare technology, generative AI, and intelligent automation. Ventra Health is also setting up a new GCC, focused on engineering, data, and platform delivery to scale AI solutions across its operations.</p>\n<p>The vCision platform is designed to help revenue cycle teams improve processing accuracy, anticipate changing reimbursement behaviour, and adapt to evolving payer guidelines. It also integrates real-time training and education for operational staff and extends Ventra’s enterprise analytics platform, vSight, launched in late 2023.</p>\n<p>Rajan Kohli, CEO of CitiusTech, said the collaboration is focused on embedding AI-driven intelligence into revenue operations to improve financial predictability and reduce revenue loss. Ventra Health CEO Steven Huddleston said the platform will enable faster, more informed decision-making as reimbursement requirements continue to shift.</p>\n<p>Ventra Health provides revenue cycle management services to facility-based physician groups across specialties including anaesthesia, emergency medicine, hospital medicine, pathology, and radiology.</p>\n<p>The post CitiusTech Partners with Ventra Health to Build Agentic AI Revenue Intelligence Platform appeared first on Analytics India Magazine.</p>"
    },
    {
      "id": "7b35ff22a60f",
      "title": "Why Mphasis CEO Believes AI Can No Longer Be ‘Lipstick’ on Legacy IT",
      "content": "After decades of layering new software on top of ageing enterprise systems, companies are running into the limits of legacy technology, believes Mphasis CEO Nitin Rakesh.In a detailed post-earnings interaction, Rakesh said the IT services firm is positioning its NeoIP platform—enabling agentic AI-led IT operations and observability—to help enterprises rethink how they modernise and operate long-standing core systems, using AI to extract intelligence and drive change, rather than simply automate around legacy constraints.\n\n\n\nRakesh traced the challenge back to the evolution of enterprise computing. Early software automated manual record-keeping in sectors such as banking and insurance. While the digital and cloud era improved reach and experience, core systems, many built in the 1970s and 1980s and still running on mainframes, largely remained untouched.\n\n\n\nEnterprises, he added, have continued to add layers without fundamentally transforming systems of record. “We keep putting lipstick on the same thing,” he said in the Q3 earnings call press meet.\n\n\n\nThat model, Rakesh argued, has increasingly become unsustainable as real-time payments, instant onboarding and always-on digital experiences put pressure on systems never designed for such speed or scale.\n\n\n\nModernising By Shrinking the Core\n\n\n\nRather than advocating wholesale replacement of core systems, Mphasis focuses on extracting business intelligence from legacy platforms using data and AI to drive customer and operational experiences. This approach progressively reduces the complexity of the core until it becomes feasible to modernise.\n\n\n\nEnterprises, Rakesh noted, often lack up-to-date documentation of how their systems actually work. Over decades of changes, the most accurate representation of business logic is not on paper anymore; it’s the code itself.AI, he argued, makes it possible to relearn that logic far faster than traditional manual methods.\n\n\n\nRakesh cited the case of a large modernisation programme involving tens of millions of lines of legacy code. Where conventional approaches would have taken several years just to reverse-engineer business rules, Mphasis’ AI-assisted techniques compressed that phase by roughly 80%, completing it in a matter of months through iterative analysis.\n\n\n\nBeyond “Break-Fix”\n\n\n\nRakesh said the same approach is extending into IT operations. Traditional “break-fix” models, where systems are repaired only after failures occur, are increasingly misaligned with AI-era expectations.\n\n\n\n“Even your dumb car has a yellow light that tells you something is going wrong,” he said. “But our smart IT operations don’t do that even today.”\n\n\n\nThe goal, he said, is to move operations toward more predictive and preventive models, where incidents are anticipated and addressed earlier, reducing downtime and manual intervention over time.\n\n\n\nResetting Pricing And Delivery Models\n\n\n\nThese changes are also reshaping how Mphasis structures commercial engagements.&nbsp;\n\n\n\nRakesh said traditional IT services pricing, based on headcount, effort and long timelines, is gradually giving way to outcome-oriented models, particularly in large modernisation and operations deals. Historically, legacy modernisation programmes were priced over six to seven years based on estimated effort, often costing several dollars per line of code.By re-engineering delivery using AI-assisted approaches, Mphasis is now committing to outcomes over shorter timeframes and at lower unit economics, Rakesh asserted.\n\n\n\n“What the client cares about is the outcome,” Rakesh said, adding that customers are increasingly indifferent to how many people or tools are deployed at different stages, as long as delivery risk, timelines and results are clear.\n\n\n\nHe described this as “savings-led transformation”, where efficiencies in existing systems free up the budget for reinvestment rather than simply cutting spending.\n\n\n\nTalent, Hiring And the Changing Pyramid\n\n\n\nThe shift toward AI-assisted delivery is also influencing workforce strategy. Rakesh said Mphasis has moved away from traditional campus hiring over the past two years, instead engaging candidates through internal programmes and hackathons focused on live projects and emerging technologies.\n\n\n\nThe most important attributes the company looks for, he said, are “learnability” and “technical skills”.Hiring continues across experience levels based on project needs, including a higher intake of junior talent in the US. In the December quarter, the company reported a headcount of 31,272—an increase of 463 over the previous quarter.\n\n\n\nOver time, Rakesh said the workforce structure could evolve toward a more fluid, diamond-shaped model rather than a classic pyramid, moving from junior-heavy structures to agile teams dominated by mid-level specialists. However, he emphasised that such changes will take several years and require alignment with customers.\n\n\n\nDeal Momentum And AI Infusion\n\n\n\nDuring Q3, Mphasis secured $428 million worth of new deal wins, with 62% of them being AI-led.\n\n\n\nResponding to questions on deal wins, Rakesh said most recent engagements include elements of AI-led delivery, spanning modernisation, operations and software lifecycle transformation. Some deals require a three-to-six-month ramp-up before revenues flow, while others convert more quickly.\n\n\n\nResponding to a question from AIM on disclosing AI revenue, Rakesh said the more relevant measure for him is how many customer engagements are being impacted by what the company is building, rather than carving out AI as a separate revenue line.\n\n\n\n“What’s important to me is, are we bundling services and software together in how many engagements?” he said. “The metric I gave was that clients representing almost 50% of our revenue today are on some form of a NeoIP engagement. That does not mean 50% of revenues are on that engagement alone.”\n\n\n\nThe CEO, however, emphasised that the company cannot continue to deliver without an AI-led approach. Otherwise, clients, he added, will either figure out how to do it with the same vendor, with another provider, or on their own.\n\n\n\n“That’s why the right approach should be whether I’m able to infuse this in every engagement, every customer,” he said.Giving an AI revenue breakdown, he argued, risks confusion, where strong growth in a reported AI bucket alongside slower overall growth could be misread as revenue deflation.\n\n\n\nPartners And Investors\n\n\n\nRakesh said that the NeoIP platform has been built largely through internal development and ecosystem partnerships rather than large acquisitions, with hyperscalers and model providers acting as technology enablers.\n\n\n\nHe also addressed recent stake sales by Blackstone, which sold around a 9.5% stake in Mphasis through a ₹4,600-plus crore block deal during the quarter. While Blackstone is no longer a majority shareholder, Rakesh said the focus remains on execution and customer relevance rather than changes in the shareholding structure.“This is not the beginning of the end,” he said. “This is the end of the beginning.”\n\n\n\nLooking ahead, Rakesh said Mphasis is entering a new phase, with investments made over the past several years beginning to show tangible opportunity. “Talk is cheap,” he said. “Executing this is really hard.”&nbsp;\n\n\n\nMphasis reported a 2.6% quarter-on-quarter and 12.4% year-on-year increase in revenue in the third quarter of FY26 to ₹4,002.6 crore.Net profit after the exceptional item related to the labour law change declined 5.7% quarter-on-quarter to ₹442.2 crore.Its shares declined 2.32% on Friday, ending the day at Rs 2,745 apiece.\n\n\n\n\nThe post Why Mphasis CEO Believes AI Can No Longer Be ‘Lipstick’ on Legacy IT appeared first on Analytics India Magazine.",
      "url": "https://analyticsindiamag.com/it-services/why-mphasis-ceo-believes-ai-can-no-longer-be-lipstick-on-legacy-it/",
      "author": "C P Balasubramanyam",
      "published": "2026-01-23T12:38:05",
      "source": "Analytics India Magazine",
      "source_type": "rss",
      "tags": [
        "IT Services",
        "AI",
        "enterprise ai",
        "Hiring",
        "Indian IT",
        "Mphasis",
        "Workforce"
      ],
      "summary": "Mphasis CEO Nitin Rakesh argued that AI can no longer be superficial additions to legacy IT systems, positioning the company's NeoIP platform for agentic AI-led modernization of core enterprise systems.",
      "importance_score": 42.0,
      "reasoning": "Executive perspective on AI integration challenges, but primarily company positioning commentary.",
      "themes": [
        "Enterprise AI",
        "IT Services",
        "Legacy Systems"
      ],
      "continuation": null,
      "summary_html": "<p>Mphasis CEO Nitin Rakesh argued that AI can no longer be superficial additions to legacy IT systems, positioning the company's NeoIP platform for agentic AI-led modernization of core enterprise systems.</p>",
      "content_html": "<p>After decades of layering new software on top of ageing enterprise systems, companies are running into the limits of legacy technology, believes Mphasis CEO Nitin Rakesh.In a detailed post-earnings interaction, Rakesh said the IT services firm is positioning its NeoIP platform—enabling agentic AI-led IT operations and observability—to help enterprises rethink how they modernise and operate long-standing core systems, using AI to extract intelligence and drive change, rather than simply automate around legacy constraints.</p>\n<p>Rakesh traced the challenge back to the evolution of enterprise computing. Early software automated manual record-keeping in sectors such as banking and insurance. While the digital and cloud era improved reach and experience, core systems, many built in the 1970s and 1980s and still running on mainframes, largely remained untouched.</p>\n<p>Enterprises, he added, have continued to add layers without fundamentally transforming systems of record. “We keep putting lipstick on the same thing,” he said in the Q3 earnings call press meet.</p>\n<p>That model, Rakesh argued, has increasingly become unsustainable as real-time payments, instant onboarding and always-on digital experiences put pressure on systems never designed for such speed or scale.</p>\n<p>Modernising By Shrinking the Core</p>\n<p>Rather than advocating wholesale replacement of core systems, Mphasis focuses on extracting business intelligence from legacy platforms using data and AI to drive customer and operational experiences. This approach progressively reduces the complexity of the core until it becomes feasible to modernise.</p>\n<p>Enterprises, Rakesh noted, often lack up-to-date documentation of how their systems actually work. Over decades of changes, the most accurate representation of business logic is not on paper anymore; it’s the code itself.AI, he argued, makes it possible to relearn that logic far faster than traditional manual methods.</p>\n<p>Rakesh cited the case of a large modernisation programme involving tens of millions of lines of legacy code. Where conventional approaches would have taken several years just to reverse-engineer business rules, Mphasis’ AI-assisted techniques compressed that phase by roughly 80%, completing it in a matter of months through iterative analysis.</p>\n<p>Beyond “Break-Fix”</p>\n<p>Rakesh said the same approach is extending into IT operations. Traditional “break-fix” models, where systems are repaired only after failures occur, are increasingly misaligned with AI-era expectations.</p>\n<p>“Even your dumb car has a yellow light that tells you something is going wrong,” he said. “But our smart IT operations don’t do that even today.”</p>\n<p>The goal, he said, is to move operations toward more predictive and preventive models, where incidents are anticipated and addressed earlier, reducing downtime and manual intervention over time.</p>\n<p>Resetting Pricing And Delivery Models</p>\n<p>These changes are also reshaping how Mphasis structures commercial engagements.&nbsp;</p>\n<p>Rakesh said traditional IT services pricing, based on headcount, effort and long timelines, is gradually giving way to outcome-oriented models, particularly in large modernisation and operations deals. Historically, legacy modernisation programmes were priced over six to seven years based on estimated effort, often costing several dollars per line of code.By re-engineering delivery using AI-assisted approaches, Mphasis is now committing to outcomes over shorter timeframes and at lower unit economics, Rakesh asserted.</p>\n<p>“What the client cares about is the outcome,” Rakesh said, adding that customers are increasingly indifferent to how many people or tools are deployed at different stages, as long as delivery risk, timelines and results are clear.</p>\n<p>He described this as “savings-led transformation”, where efficiencies in existing systems free up the budget for reinvestment rather than simply cutting spending.</p>\n<p>Talent, Hiring And the Changing Pyramid</p>\n<p>The shift toward AI-assisted delivery is also influencing workforce strategy. Rakesh said Mphasis has moved away from traditional campus hiring over the past two years, instead engaging candidates through internal programmes and hackathons focused on live projects and emerging technologies.</p>\n<p>The most important attributes the company looks for, he said, are “learnability” and “technical skills”.Hiring continues across experience levels based on project needs, including a higher intake of junior talent in the US. In the December quarter, the company reported a headcount of 31,272—an increase of 463 over the previous quarter.</p>\n<p>Over time, Rakesh said the workforce structure could evolve toward a more fluid, diamond-shaped model rather than a classic pyramid, moving from junior-heavy structures to agile teams dominated by mid-level specialists. However, he emphasised that such changes will take several years and require alignment with customers.</p>\n<p>Deal Momentum And AI Infusion</p>\n<p>During Q3, Mphasis secured $428 million worth of new deal wins, with 62% of them being AI-led.</p>\n<p>Responding to questions on deal wins, Rakesh said most recent engagements include elements of AI-led delivery, spanning modernisation, operations and software lifecycle transformation. Some deals require a three-to-six-month ramp-up before revenues flow, while others convert more quickly.</p>\n<p>Responding to a question from AIM on disclosing AI revenue, Rakesh said the more relevant measure for him is how many customer engagements are being impacted by what the company is building, rather than carving out AI as a separate revenue line.</p>\n<p>“What’s important to me is, are we bundling services and software together in how many engagements?” he said. “The metric I gave was that clients representing almost 50% of our revenue today are on some form of a NeoIP engagement. That does not mean 50% of revenues are on that engagement alone.”</p>\n<p>The CEO, however, emphasised that the company cannot continue to deliver without an AI-led approach. Otherwise, clients, he added, will either figure out how to do it with the same vendor, with another provider, or on their own.</p>\n<p>“That’s why the right approach should be whether I’m able to infuse this in every engagement, every customer,” he said.Giving an AI revenue breakdown, he argued, risks confusion, where strong growth in a reported AI bucket alongside slower overall growth could be misread as revenue deflation.</p>\n<p>Partners And Investors</p>\n<p>Rakesh said that the NeoIP platform has been built largely through internal development and ecosystem partnerships rather than large acquisitions, with hyperscalers and model providers acting as technology enablers.</p>\n<p>He also addressed recent stake sales by Blackstone, which sold around a 9.5% stake in Mphasis through a ₹4,600-plus crore block deal during the quarter. While Blackstone is no longer a majority shareholder, Rakesh said the focus remains on execution and customer relevance rather than changes in the shareholding structure.“This is not the beginning of the end,” he said. “This is the end of the beginning.”</p>\n<p>Looking ahead, Rakesh said Mphasis is entering a new phase, with investments made over the past several years beginning to show tangible opportunity. “Talk is cheap,” he said. “Executing this is really hard.”&nbsp;</p>\n<p>Mphasis reported a 2.6% quarter-on-quarter and 12.4% year-on-year increase in revenue in the third quarter of FY26 to ₹4,002.6 crore.Net profit after the exceptional item related to the labour law change declined 5.7% quarter-on-quarter to ₹442.2 crore.Its shares declined 2.32% on Friday, ending the day at Rs 2,745 apiece.</p>\n<p>The post Why Mphasis CEO Believes AI Can No Longer Be ‘Lipstick’ on Legacy IT appeared first on Analytics India Magazine.</p>"
    },
    {
      "id": "f6a309719760",
      "title": "VoiceRun Raises $5.5M for Full-Stack Voice AI Platform",
      "content": "The startup positions its AI agent development platform as meeting rising transparency and reliability standards.",
      "url": "https://aibusiness.com/agentic-ai/voicerun-startup-full-stack-voice-ai-platform",
      "author": "Scarlett Evans",
      "published": "2026-01-23T01:12:05",
      "source": "aibusiness",
      "source_type": "rss",
      "tags": [],
      "summary": "VoiceRun raised $5.5M for its full-stack voice AI agent development platform, positioning itself around transparency and reliability standards.",
      "importance_score": 40.0,
      "reasoning": "Small seed-stage funding round for niche voice AI startup. Limited broader significance.",
      "themes": [
        "Voice AI",
        "Funding",
        "Startup"
      ],
      "continuation": null,
      "summary_html": "<p>VoiceRun raised $5.5M for its full-stack voice AI agent development platform, positioning itself around transparency and reliability standards.</p>",
      "content_html": "<p>The startup positions its AI agent development platform as meeting rising transparency and reliability standards.</p>"
    },
    {
      "id": "d3b8876d62b9",
      "title": "Google Photos Tests ‘Me Meme’ Feature to Turn Selfies Into AI memes",
      "content": "Google Photos is stepping up its use of generative AI with the introduction of Me Meme, a new experimental feature rolling out on Android and iOS in the US that lets users turn themselves into memes. The concept is straightforward: Me Meme allows users to “turn themselves into a meme” with AI.&nbsp;\n\n\n\nTo begin with, users can either choose a meme template from Google Photos’ built-in presets or upload a reference image of their own. They then select a selfie or portrait in which their face is clearly visible. Google recommends using a well-lit, front-facing photo that is sharp and in focus for the best results. Before generating the meme, users can make small adjustments to the source image.&nbsp;\n\n\n\nOnce the meme is created, it can be saved to the photo library, regenerated, or shared directly. Google also provides tools to compare the original image with the AI-generated version, as well as an option to submit feedback on the output.&nbsp;\n\n\n\nUnlike the standalone Gemini app, which already allows users to generate images and memes through text prompts, Google Photos is positioning Me Meme as a more guided and accessible experience. By embedding the feature directly within the Create tab, Google appears to be targeting casual users who may be reluctant to experiment with prompts or switch between apps.&nbsp;\n\n\n\nThe name ‘Me Meme’ itself seems deliberately designed for virality, reflecting Google Photos’ broader effort to reframe the Create tab as a hub for playful, shareable AI tools. Me Meme now sits alongside features such as Create with AI, Photo to video, Remix, Collage, Highlight video, Cinematic photo, and Animation.&nbsp;\n\n\n\nFor now, Me Meme is labelled as an experimental feature and is rolling out gradually. It was not visible on all devices tested, and Google has yet to share details on when it may expand beyond the US or move out of the testing phase.&nbsp;\n\n\n\nGoogle Photos was launched in May 2015 as a standalone spin-off from Google+ Photos (which itself was the successor to Picasa). In 2021, Google ended the free unlimited storage policy, moving to a shared 15 GB storage limit across Google Drive, Gmail, and Photos. Last year, a significant integration with AI, including features like Magic Editor, Ask Photos (Gemini-powered search), was initiated.&nbsp;\nThe post Google Photos Tests ‘Me Meme’ Feature to Turn Selfies Into AI memes appeared first on Analytics India Magazine.",
      "url": "https://analyticsindiamag.com/ai-news-updates/google-photos-tests-me-meme-feature-to-turn-selfies-into-ai-memes/",
      "author": "Pallavi Chakravorty",
      "published": "2026-01-23T09:15:50",
      "source": "Analytics India Magazine",
      "source_type": "rss",
      "tags": [
        "AI News"
      ],
      "summary": "Google Photos is testing 'Me Meme,' a feature allowing US users on Android and iOS to transform selfies into AI-generated memes using templates or custom reference images.",
      "importance_score": 40.0,
      "reasoning": "Consumer feature addition using existing generative AI capabilities. Incremental product update.",
      "themes": [
        "Consumer AI",
        "Google",
        "Image Generation"
      ],
      "continuation": null,
      "summary_html": "<p>Google Photos is testing 'Me Meme,' a feature allowing US users on Android and iOS to transform selfies into AI-generated memes using templates or custom reference images.</p>",
      "content_html": "<p>Google Photos is stepping up its use of generative AI with the introduction of Me Meme, a new experimental feature rolling out on Android and iOS in the US that lets users turn themselves into memes. The concept is straightforward: Me Meme allows users to “turn themselves into a meme” with AI.&nbsp;</p>\n<p>To begin with, users can either choose a meme template from Google Photos’ built-in presets or upload a reference image of their own. They then select a selfie or portrait in which their face is clearly visible. Google recommends using a well-lit, front-facing photo that is sharp and in focus for the best results. Before generating the meme, users can make small adjustments to the source image.&nbsp;</p>\n<p>Once the meme is created, it can be saved to the photo library, regenerated, or shared directly. Google also provides tools to compare the original image with the AI-generated version, as well as an option to submit feedback on the output.&nbsp;</p>\n<p>Unlike the standalone Gemini app, which already allows users to generate images and memes through text prompts, Google Photos is positioning Me Meme as a more guided and accessible experience. By embedding the feature directly within the Create tab, Google appears to be targeting casual users who may be reluctant to experiment with prompts or switch between apps.&nbsp;</p>\n<p>The name ‘Me Meme’ itself seems deliberately designed for virality, reflecting Google Photos’ broader effort to reframe the Create tab as a hub for playful, shareable AI tools. Me Meme now sits alongside features such as Create with AI, Photo to video, Remix, Collage, Highlight video, Cinematic photo, and Animation.&nbsp;</p>\n<p>For now, Me Meme is labelled as an experimental feature and is rolling out gradually. It was not visible on all devices tested, and Google has yet to share details on when it may expand beyond the US or move out of the testing phase.&nbsp;</p>\n<p>Google Photos was launched in May 2015 as a standalone spin-off from Google+ Photos (which itself was the successor to Picasa). In 2021, Google ended the free unlimited storage policy, moving to a shared 15 GB storage limit across Google Drive, Gmail, and Photos. Last year, a significant integration with AI, including features like Magic Editor, Ask Photos (Gemini-powered search), was initiated.&nbsp;</p>\n<p>The post Google Photos Tests ‘Me Meme’ Feature to Turn Selfies Into AI memes appeared first on Analytics India Magazine.</p>"
    },
    {
      "id": "da08c29a976e",
      "title": "‘I’m picking winners’: UK business secretary takes activist approach to economic growth",
      "content": "AI evangelist Peter Kyle wants to scale up businesses, attract overseas investors and look out for UK’s poorer regionsThe UK business secretary, Peter Kyle, has said he is “betting big” and “picking winners” as the government takes direct stakes in growing businesses to boost economic growth.Speaking at the World Economic Forum in Davos, where he and the chancellor, Rachel Reeves, have been talking up Britain’s prospects, Kyle said ministers were taking an “activist” approach to industrial policy. Continue reading...",
      "url": "https://www.theguardian.com/business/2026/jan/23/peter-kyle-uk-business-secretary-activist-approach-economic-growth",
      "author": "Heather Stewart in Davos",
      "published": "2026-01-23T07:00:11",
      "source": "AI (artificial intelligence) | The Guardian",
      "source_type": "rss",
      "tags": [
        "Economic growth (GDP)",
        "Davos 2026",
        "Peter Kyle",
        "Davos",
        "Labour",
        "AI (artificial intelligence)",
        "Octopus Energy",
        "Economic policy",
        "Economics",
        "Computing",
        "Technology",
        "Politics",
        "UK news",
        "Business"
      ],
      "summary": "UK Business Secretary Peter Kyle described government as 'picking winners' and taking an activist approach to AI and economic growth at Davos, with direct stakes in growing businesses.",
      "importance_score": 38.0,
      "reasoning": "UK policy positioning but lacks specific AI policy announcements or investments.",
      "themes": [
        "Policy",
        "UK",
        "Economic Policy"
      ],
      "continuation": null,
      "summary_html": "<p>UK Business Secretary Peter Kyle described government as 'picking winners' and taking an activist approach to AI and economic growth at Davos, with direct stakes in growing businesses.</p>",
      "content_html": "<p>AI evangelist Peter Kyle wants to scale up businesses, attract overseas investors and look out for UK’s poorer regionsThe UK business secretary, Peter Kyle, has said he is “betting big” and “picking winners” as the government takes direct stakes in growing businesses to boost economic growth.Speaking at the World Economic Forum in Davos, where he and the chancellor, Rachel Reeves, have been talking up Britain’s prospects, Kyle said ministers were taking an “activist” approach to industrial policy. Continue reading...</p>"
    },
    {
      "id": "f9164636e51c",
      "title": "How an AI Agent Chooses What to Do Under Tokens, Latency, and Tool-Call Budget Constraints?",
      "content": "In this tutorial, we build a cost-aware planning agent that deliberately balances output quality against real-world constraints such as token usage, latency, and tool-call budgets. We design the agent to generate multiple candidate actions, estimate their expected costs and benefits, and then select an execution plan that maximizes value while staying within strict budgets. With this, we demonstrate how agentic systems can move beyond “always use the LLM” behavior and instead reason explicitly about trade-offs, efficiency, and resource awareness, which is critical for deploying agents reliably in constrained environments. Check out the FULL CODES here.\n\n\n\nCopy CodeCopiedUse a different Browserimport os, time, math, json, random\nfrom dataclasses import dataclass, field\nfrom typing import List, Dict, Optional, Tuple, Any\nfrom getpass import getpass\n\n\nUSE_OPENAI = True\n\n\nif USE_OPENAI:\n   if not os.getenv(\"OPENAI_API_KEY\"):\n       os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OPENAI_API_KEY (hidden): \").strip()\n   try:\n       from openai import OpenAI\n       client = OpenAI()\n   except Exception as e:\n       print(\"OpenAI SDK import failed. Falling back to offline mode.\\nError:\", e)\n       USE_OPENAI = False\n\n\n\nWe set up the execution environment and securely load the OpenAI API key at runtime without hardcoding it. We also initialize the client so the agent gracefully falls back to offline mode if the API is unavailable. Check out the FULL CODES here.\n\n\n\nCopy CodeCopiedUse a different Browserdef approx_tokens(text: str) -> int:\n   return max(1, math.ceil(len(text) / 4))\n\n\n@dataclass\nclass Budget:\n   max_tokens: int\n   max_latency_ms: int\n   max_tool_calls: int\n\n\n@dataclass\nclass Spend:\n   tokens: int = 0\n   latency_ms: int = 0\n   tool_calls: int = 0\n\n\n   def within(self, b: Budget) -> bool:\n       return (self.tokens &lt;= b.max_tokens and\n               self.latency_ms &lt;= b.max_latency_ms and\n               self.tool_calls &lt;= b.max_tool_calls)\n\n\n   def add(self, other: \"Spend\") -> \"Spend\":\n       return Spend(\n           tokens=self.tokens + other.tokens,\n           latency_ms=self.latency_ms + other.latency_ms,\n           tool_calls=self.tool_calls + other.tool_calls\n       )\n\n\n\nWe define the core budgeting abstractions that enable the agent to reason explicitly about costs. We model token usage, latency, and tool calls as first-class quantities and provide utility methods to accumulate and validate spend. It gives us a clean foundation for enforcing constraints throughout planning and execution. Check out the FULL CODES here.\n\n\n\nCopy CodeCopiedUse a different Browser@dataclass\nclass StepOption:\n   name: str\n   description: str\n   est_spend: Spend\n   est_value: float\n   executor: str\n   payload: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass PlanCandidate:\n   steps: List[StepOption]\n   spend: Spend\n   value: float\n   rationale: str = \"\"\n\n\ndef llm_text(prompt: str, *, model: str = \"gpt-5\", effort: str = \"low\") -> str:\n   if not USE_OPENAI:\n       return \"\"\n   t0 = time.time()\n   resp = client.responses.create(\n       model=model,\n       reasoning={\"effort\": effort},\n       input=prompt,\n   )\n   _ = (time.time() - t0)\n   return resp.output_text or \"\"\n\n\n\nWe introduce the data structures that represent individual action choices and full plan candidates. We also define a lightweight LLM wrapper that standardizes how text is generated and measured. This separation allows the planner to reason about actions abstractly without being tightly coupled to execution details. Check out the FULL CODES here.\n\n\n\nCopy CodeCopiedUse a different Browserdef generate_step_options(task: str) -> List[StepOption]:\n   base = [\n       StepOption(\n           name=\"Clarify deliverables (local)\",\n           description=\"Extract deliverable checklist + acceptance criteria from the task.\",\n           est_spend=Spend(tokens=60, latency_ms=20, tool_calls=0),\n           est_value=6.0,\n           executor=\"local\",\n       ),\n       StepOption(\n           name=\"Outline plan (LLM)\",\n           description=\"Create a structured outline with sections, constraints, and assumptions.\",\n           est_spend=Spend(tokens=600, latency_ms=1200, tool_calls=1),\n           est_value=10.0,\n           executor=\"llm\",\n           payload={\"prompt_kind\":\"outline\"}\n       ),\n       StepOption(\n           name=\"Outline plan (local)\",\n           description=\"Create a rough outline using templates (no LLM).\",\n           est_spend=Spend(tokens=120, latency_ms=40, tool_calls=0),\n           est_value=5.5,\n           executor=\"local\",\n       ),\n       StepOption(\n           name=\"Risk register (LLM)\",\n           description=\"Generate risks, mitigations, owners, and severity.\",\n           est_spend=Spend(tokens=700, latency_ms=1400, tool_calls=1),\n           est_value=9.0,\n           executor=\"llm\",\n           payload={\"prompt_kind\":\"risks\"}\n       ),\n       StepOption(\n           name=\"Risk register (local)\",\n           description=\"Generate a standard risk register from a reusable template.\",\n           est_spend=Spend(tokens=160, latency_ms=60, tool_calls=0),\n           est_value=5.0,\n           executor=\"local\",\n       ),\n       StepOption(\n           name=\"Timeline (LLM)\",\n           description=\"Draft a realistic milestone timeline with dependencies.\",\n           est_spend=Spend(tokens=650, latency_ms=1300, tool_calls=1),\n           est_value=8.5,\n           executor=\"llm\",\n           payload={\"prompt_kind\":\"timeline\"}\n       ),\n       StepOption(\n           name=\"Timeline (local)\",\n           description=\"Draft a simple timeline from a generic milestone template.\",\n           est_spend=Spend(tokens=150, latency_ms=60, tool_calls=0),\n           est_value=4.8,\n           executor=\"local\",\n       ),\n       StepOption(\n           name=\"Quality pass (LLM)\",\n           description=\"Rewrite for clarity, consistency, and formatting.\",\n           est_spend=Spend(tokens=900, latency_ms=1600, tool_calls=1),\n           est_value=8.0,\n           executor=\"llm\",\n           payload={\"prompt_kind\":\"polish\"}\n       ),\n       StepOption(\n           name=\"Quality pass (local)\",\n           description=\"Light formatting + consistency checks without LLM.\",\n           est_spend=Spend(tokens=120, latency_ms=50, tool_calls=0),\n           est_value=3.5,\n           executor=\"local\",\n       ),\n   ]\n\n\n   if USE_OPENAI:\n       meta_prompt = f\"\"\"\nYou are a planning assistant. For the task below, propose 3-5 OPTIONAL extra steps that improve quality,\nlike checks, validations, or stakeholder tailoring. Keep each step short.\n\n\nTASK:\n{task}\n\n\nReturn JSON list with fields: name, description, est_value(1-10).\n\"\"\"\n       txt = llm_text(meta_prompt, model=\"gpt-5\", effort=\"low\")\n       try:\n           items = json.loads(txt.strip())\n           for it in items[:5]:\n               base.append(\n                   StepOption(\n                       name=str(it.get(\"name\",\"Extra step (local)\"))[:60],\n                       description=str(it.get(\"description\",\"\"))[:200],\n                       est_spend=Spend(tokens=120, latency_ms=60, tool_calls=0),\n                       est_value=float(it.get(\"est_value\", 5.0)),\n                       executor=\"local\",\n                   )\n               )\n       except Exception:\n           pass\n\n\n   return base\n\n\n\nWe focus on generating a diverse set of candidate steps, including both LLM-based and local alternatives with different cost–quality trade-offs. We optionally use the model itself to suggest additional low-cost improvements while still controlling their impact on the budget. By doing so, we enrich the action space without losing efficiency. Check out the FULL CODES here.\n\n\n\nCopy CodeCopiedUse a different Browserdef plan_under_budget(\n   options: List[StepOption],\n   budget: Budget,\n   *,\n   max_steps: int = 6,\n   beam_width: int = 12,\n   diversity_penalty: float = 0.2\n) -> PlanCandidate:\n   def redundancy_cost(chosen: List[StepOption], new: StepOption) -> float:\n       key_new = new.name.split(\"(\")[0].strip().lower()\n       overlap = 0\n       for s in chosen:\n           key_s = s.name.split(\"(\")[0].strip().lower()\n           if key_s == key_new:\n               overlap += 1\n       return overlap * diversity_penalty\n\n\n   beams: List[PlanCandidate] = [PlanCandidate(steps=[], spend=Spend(), value=0.0, rationale=\"\")]\n\n\n   for _ in range(max_steps):\n       expanded: List[PlanCandidate] = []\n       for cand in beams:\n           for opt in options:\n               if opt in cand.steps:\n                   continue\n               new_spend = cand.spend.add(opt.est_spend)\n               if not new_spend.within(budget):\n                   continue\n               new_value = cand.value + opt.est_value - redundancy_cost(cand.steps, opt)\n               expanded.append(\n                   PlanCandidate(\n                       steps=cand.steps + [opt],\n                       spend=new_spend,\n                       value=new_value,\n                       rationale=cand.rationale\n                   )\n               )\n       if not expanded:\n           break\n       expanded.sort(key=lambda c: c.value, reverse=True)\n       beams = expanded[:beam_width]\n\n\n   best = max(beams, key=lambda c: c.value)\n   return best\n\n\n\nWe implement the budget-constrained planning logic that searches for the highest-value combination of steps under strict limits. We apply a beam-style search with redundancy penalties to avoid wasteful action overlap. This is where the agent truly becomes cost-aware by optimizing value subject to constraints. Check out the FULL CODES here.\n\n\n\nCopy CodeCopiedUse a different Browserdef run_local_step(task: str, step: StepOption, working: Dict[str, Any]) -> str:\n   name = step.name.lower()\n   if \"clarify deliverables\" in name:\n       return (\n           \"Deliverables checklist:\\n\"\n           \"- Executive summary\\n- Scope &amp; assumptions\\n- Workplan + milestones\\n\"\n           \"- Risk register (risk, impact, likelihood, mitigation, owner)\\n\"\n           \"- Next steps + data needed\\n\"\n       )\n   if \"outline plan\" in name:\n       return (\n           \"Outline:\\n1) Context &amp; objective\\n2) Scope\\n3) Approach\\n4) Timeline\\n5) Risks\\n6) Next steps\\n\"\n       )\n   if \"risk register\" in name:\n       return (\n           \"Risk register (template):\\n\"\n           \"1) Data access delays | High | Mitigation: agree data list + owners\\n\"\n           \"2) Stakeholder alignment | Med | Mitigation: weekly review\\n\"\n           \"3) Tooling constraints | Med | Mitigation: phased rollout\\n\"\n       )\n   if \"timeline\" in name:\n       return (\n           \"Timeline (template):\\n\"\n           \"Week 1: discovery + requirements\\nWeek 2: prototype + feedback\\n\"\n           \"Week 3: pilot + metrics\\nWeek 4: rollout + handover\\n\"\n       )\n   if \"quality pass\" in name:\n       draft = working.get(\"draft\", \"\")\n       return \"Light quality pass done (headings normalized, bullets aligned).\\n\" + draft\n   return f\"Completed: {step.name}\\n\"\n\n\ndef run_llm_step(task: str, step: StepOption, working: Dict[str, Any]) -> str:\n   kind = step.payload.get(\"prompt_kind\", \"generic\")\n   context = working.get(\"draft\", \"\")\n   prompts = {\n       \"outline\": f\"Create a crisp, structured outline for the task below.\\nTASK:\\n{task}\\nReturn a numbered outline.\",\n       \"risks\": f\"Create a risk register for the task below. Include: Risk | Impact | Likelihood | Mitigation | Owner.\\nTASK:\\n{task}\",\n       \"timeline\": f\"Create a realistic milestone timeline with dependencies for the task below.\\nTASK:\\n{task}\",\n       \"polish\": f\"Rewrite and polish the following draft for clarity and consistency.\\nDRAFT:\\n{context}\",\n       \"generic\": f\"Help with this step: {step.description}\\nTASK:\\n{task}\\nCURRENT:\\n{context}\",\n   }\n   return llm_text(prompts.get(kind, prompts[\"generic\"]), model=\"gpt-5\", effort=\"low\")\n\n\ndef execute_plan(task: str, plan: PlanCandidate) -> Tuple[str, Spend]:\n   working = {\"draft\": \"\"}\n   actual = Spend()\n\n\n   for i, step in enumerate(plan.steps, 1):\n       t0 = time.time()\n       if step.executor == \"llm\" and USE_OPENAI:\n           out = run_llm_step(task, step, working)\n           tool_calls = 1\n       else:\n           out = run_local_step(task, step, working)\n           tool_calls = 0\n\n\n       dt_ms = int((time.time() - t0) * 1000)\n       tok = approx_tokens(out)\n\n\n       actual = actual.add(Spend(tokens=tok, latency_ms=dt_ms, tool_calls=tool_calls))\n       working[\"draft\"] += f\"\\n\\n### Step {i}: {step.name}\\n{out}\\n\"\n\n\n   return working[\"draft\"].strip(), actual\n\n\nTASK = \"Draft a 1-page project proposal for a logistics dashboard + fleet optimization pilot, including scope, timeline, and risks.\"\nBUDGET = Budget(\n   max_tokens=2200,\n   max_latency_ms=3500,\n   max_tool_calls=2\n)\n\n\noptions = generate_step_options(TASK)\nbest_plan = plan_under_budget(options, BUDGET, max_steps=6, beam_width=14)\n\n\nprint(\"=== SELECTED PLAN (budget-aware) ===\")\nfor s in best_plan.steps:\n   print(f\"- {s.name} | est_spend={s.est_spend} | est_value={s.est_value}\")\nprint(\"\\nEstimated spend:\", best_plan.spend)\nprint(\"Budget:\", BUDGET)\n\n\nprint(\"\\n=== EXECUTING PLAN ===\")\ndraft, actual = execute_plan(TASK, best_plan)\n\n\nprint(\"\\n=== OUTPUT DRAFT ===\\n\")\nprint(draft[:6000])\n\n\nprint(\"\\n=== ACTUAL SPEND (approx) ===\")\nprint(actual)\nprint(\"\\nWithin budget?\", actual.within(BUDGET))\n\n\n\nWe execute the selected plan and track actual resource usage step by step. We dynamically choose between local and LLM execution paths and aggregate the final output into a coherent draft. By comparing estimated and actual spend, we demonstrate how planning assumptions can be validated and refined in practice.\n\n\n\nIn conclusion, we demonstrated how a cost-aware planning agent can reason about its resource consumption and adapt its behavior in real time. We executed only the steps that fit within predefined budgets and tracked actual spend to validate the planning assumptions, closing the loop between estimation and execution. Also, we highlighted how agentic AI systems can become more practical, controllable, and scalable by treating cost, latency, and tool usage as first-class decision variables rather than afterthoughts.\n\n\n\n\n\n\n\nCheck out the FULL CODES here. Also, feel free to follow us on Twitter and don’t forget to join our 100k+ ML SubReddit and Subscribe to our Newsletter. Wait! are you on telegram? now you can join us on telegram as well.\nThe post How an AI Agent Chooses What to Do Under Tokens, Latency, and Tool-Call Budget Constraints? appeared first on MarkTechPost.",
      "url": "https://www.marktechpost.com/2026/01/23/how-an-ai-agent-chooses-what-to-do-under-tokens-latency-and-tool-call-budget-constraints/",
      "author": "Asif Razzaq",
      "published": "2026-01-23T21:30:26",
      "source": "MarkTechPost",
      "source_type": "rss",
      "tags": [
        "Agentic AI",
        "AI Agents",
        "AI Infrastructure",
        "Artificial Intelligence",
        "Editors Pick",
        "Technology",
        "Tutorials"
      ],
      "summary": "Technical tutorial demonstrating how to build cost-aware AI agents that balance token usage, latency, and tool-call budget constraints through explicit trade-off reasoning.",
      "importance_score": 35.0,
      "reasoning": "Educational technical content rather than news. Useful for practitioners but not frontier advancement.",
      "themes": [
        "Agentic AI",
        "Tutorial",
        "AI Engineering"
      ],
      "continuation": null,
      "summary_html": "<p>Technical tutorial demonstrating how to build cost-aware AI agents that balance token usage, latency, and tool-call budget constraints through explicit trade-off reasoning.</p>",
      "content_html": "<p>In this tutorial, we build a cost-aware planning agent that deliberately balances output quality against real-world constraints such as token usage, latency, and tool-call budgets. We design the agent to generate multiple candidate actions, estimate their expected costs and benefits, and then select an execution plan that maximizes value while staying within strict budgets. With this, we demonstrate how agentic systems can move beyond “always use the LLM” behavior and instead reason explicitly about trade-offs, efficiency, and resource awareness, which is critical for deploying agents reliably in constrained environments. Check out the&nbsp;FULL CODES here.</p>\n<p>Copy CodeCopiedUse a different Browserimport os, time, math, json, random</p>\n<p>from dataclasses import dataclass, field</p>\n<p>from typing import List, Dict, Optional, Tuple, Any</p>\n<p>from getpass import getpass</p>\n<p>USE_OPENAI = True</p>\n<p>if USE_OPENAI:</p>\n<p>if not os.getenv(\"OPENAI_API_KEY\"):</p>\n<p>os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OPENAI_API_KEY (hidden): \").strip()</p>\n<p>try:</p>\n<p>from openai import OpenAI</p>\n<p>client = OpenAI()</p>\n<p>except Exception as e:</p>\n<p>print(\"OpenAI SDK import failed. Falling back to offline mode.\\nError:\", e)</p>\n<p>USE_OPENAI = False</p>\n<p>We set up the execution environment and securely load the OpenAI API key at runtime without hardcoding it. We also initialize the client so the agent gracefully falls back to offline mode if the API is unavailable. Check out the&nbsp;FULL CODES here.</p>\n<p>Copy CodeCopiedUse a different Browserdef approx_tokens(text: str) -&gt; int:</p>\n<p>return max(1, math.ceil(len(text) / 4))</p>\n<p>@dataclass</p>\n<p>class Budget:</p>\n<p>max_tokens: int</p>\n<p>max_latency_ms: int</p>\n<p>max_tool_calls: int</p>\n<p>@dataclass</p>\n<p>class Spend:</p>\n<p>tokens: int = 0</p>\n<p>latency_ms: int = 0</p>\n<p>tool_calls: int = 0</p>\n<p>def within(self, b: Budget) -&gt; bool:</p>\n<p>return (self.tokens &lt;= b.max_tokens and</p>\n<p>self.latency_ms &lt;= b.max_latency_ms and</p>\n<p>self.tool_calls &lt;= b.max_tool_calls)</p>\n<p>def add(self, other: \"Spend\") -&gt; \"Spend\":</p>\n<p>return Spend(</p>\n<p>tokens=self.tokens + other.tokens,</p>\n<p>latency_ms=self.latency_ms + other.latency_ms,</p>\n<p>tool_calls=self.tool_calls + other.tool_calls</p>\n<p>)</p>\n<p>We define the core budgeting abstractions that enable the agent to reason explicitly about costs. We model token usage, latency, and tool calls as first-class quantities and provide utility methods to accumulate and validate spend. It gives us a clean foundation for enforcing constraints throughout planning and execution. Check out the&nbsp;FULL CODES here.</p>\n<p>Copy CodeCopiedUse a different Browser@dataclass</p>\n<p>class StepOption:</p>\n<p>name: str</p>\n<p>description: str</p>\n<p>est_spend: Spend</p>\n<p>est_value: float</p>\n<p>executor: str</p>\n<p>payload: Dict[str, Any] = field(default_factory=dict)</p>\n<p>@dataclass</p>\n<p>class PlanCandidate:</p>\n<p>steps: List[StepOption]</p>\n<p>spend: Spend</p>\n<p>value: float</p>\n<p>rationale: str = \"\"</p>\n<p>def llm_text(prompt: str, *, model: str = \"gpt-5\", effort: str = \"low\") -&gt; str:</p>\n<p>if not USE_OPENAI:</p>\n<p>return \"\"</p>\n<p>t0 = time.time()</p>\n<p>resp = client.responses.create(</p>\n<p>model=model,</p>\n<p>reasoning={\"effort\": effort},</p>\n<p>input=prompt,</p>\n<p>)</p>\n<p>_ = (time.time() - t0)</p>\n<p>return resp.output_text or \"\"</p>\n<p>We introduce the data structures that represent individual action choices and full plan candidates. We also define a lightweight LLM wrapper that standardizes how text is generated and measured. This separation allows the planner to reason about actions abstractly without being tightly coupled to execution details. Check out the&nbsp;FULL CODES here.</p>\n<p>Copy CodeCopiedUse a different Browserdef generate_step_options(task: str) -&gt; List[StepOption]:</p>\n<p>base = [</p>\n<p>StepOption(</p>\n<p>name=\"Clarify deliverables (local)\",</p>\n<p>description=\"Extract deliverable checklist + acceptance criteria from the task.\",</p>\n<p>est_spend=Spend(tokens=60, latency_ms=20, tool_calls=0),</p>\n<p>est_value=6.0,</p>\n<p>executor=\"local\",</p>\n<p>),</p>\n<p>StepOption(</p>\n<p>name=\"Outline plan (LLM)\",</p>\n<p>description=\"Create a structured outline with sections, constraints, and assumptions.\",</p>\n<p>est_spend=Spend(tokens=600, latency_ms=1200, tool_calls=1),</p>\n<p>est_value=10.0,</p>\n<p>executor=\"llm\",</p>\n<p>payload={\"prompt_kind\":\"outline\"}</p>\n<p>),</p>\n<p>StepOption(</p>\n<p>name=\"Outline plan (local)\",</p>\n<p>description=\"Create a rough outline using templates (no LLM).\",</p>\n<p>est_spend=Spend(tokens=120, latency_ms=40, tool_calls=0),</p>\n<p>est_value=5.5,</p>\n<p>executor=\"local\",</p>\n<p>),</p>\n<p>StepOption(</p>\n<p>name=\"Risk register (LLM)\",</p>\n<p>description=\"Generate risks, mitigations, owners, and severity.\",</p>\n<p>est_spend=Spend(tokens=700, latency_ms=1400, tool_calls=1),</p>\n<p>est_value=9.0,</p>\n<p>executor=\"llm\",</p>\n<p>payload={\"prompt_kind\":\"risks\"}</p>\n<p>),</p>\n<p>StepOption(</p>\n<p>name=\"Risk register (local)\",</p>\n<p>description=\"Generate a standard risk register from a reusable template.\",</p>\n<p>est_spend=Spend(tokens=160, latency_ms=60, tool_calls=0),</p>\n<p>est_value=5.0,</p>\n<p>executor=\"local\",</p>\n<p>),</p>\n<p>StepOption(</p>\n<p>name=\"Timeline (LLM)\",</p>\n<p>description=\"Draft a realistic milestone timeline with dependencies.\",</p>\n<p>est_spend=Spend(tokens=650, latency_ms=1300, tool_calls=1),</p>\n<p>est_value=8.5,</p>\n<p>executor=\"llm\",</p>\n<p>payload={\"prompt_kind\":\"timeline\"}</p>\n<p>),</p>\n<p>StepOption(</p>\n<p>name=\"Timeline (local)\",</p>\n<p>description=\"Draft a simple timeline from a generic milestone template.\",</p>\n<p>est_spend=Spend(tokens=150, latency_ms=60, tool_calls=0),</p>\n<p>est_value=4.8,</p>\n<p>executor=\"local\",</p>\n<p>),</p>\n<p>StepOption(</p>\n<p>name=\"Quality pass (LLM)\",</p>\n<p>description=\"Rewrite for clarity, consistency, and formatting.\",</p>\n<p>est_spend=Spend(tokens=900, latency_ms=1600, tool_calls=1),</p>\n<p>est_value=8.0,</p>\n<p>executor=\"llm\",</p>\n<p>payload={\"prompt_kind\":\"polish\"}</p>\n<p>),</p>\n<p>StepOption(</p>\n<p>name=\"Quality pass (local)\",</p>\n<p>description=\"Light formatting + consistency checks without LLM.\",</p>\n<p>est_spend=Spend(tokens=120, latency_ms=50, tool_calls=0),</p>\n<p>est_value=3.5,</p>\n<p>executor=\"local\",</p>\n<p>),</p>\n<p>]</p>\n<p>if USE_OPENAI:</p>\n<p>meta_prompt = f\"\"\"</p>\n<p>You are a planning assistant. For the task below, propose 3-5 OPTIONAL extra steps that improve quality,</p>\n<p>like checks, validations, or stakeholder tailoring. Keep each step short.</p>\n<p>TASK:</p>\n<p>{task}</p>\n<p>Return JSON list with fields: name, description, est_value(1-10).</p>\n<p>\"\"\"</p>\n<p>txt = llm_text(meta_prompt, model=\"gpt-5\", effort=\"low\")</p>\n<p>try:</p>\n<p>items = json.loads(txt.strip())</p>\n<p>for it in items[:5]:</p>\n<p>base.append(</p>\n<p>StepOption(</p>\n<p>name=str(it.get(\"name\",\"Extra step (local)\"))[:60],</p>\n<p>description=str(it.get(\"description\",\"\"))[:200],</p>\n<p>est_spend=Spend(tokens=120, latency_ms=60, tool_calls=0),</p>\n<p>est_value=float(it.get(\"est_value\", 5.0)),</p>\n<p>executor=\"local\",</p>\n<p>)</p>\n<p>)</p>\n<p>except Exception:</p>\n<p>pass</p>\n<p>return base</p>\n<p>We focus on generating a diverse set of candidate steps, including both LLM-based and local alternatives with different cost–quality trade-offs. We optionally use the model itself to suggest additional low-cost improvements while still controlling their impact on the budget. By doing so, we enrich the action space without losing efficiency. Check out the&nbsp;FULL CODES here.</p>\n<p>Copy CodeCopiedUse a different Browserdef plan_under_budget(</p>\n<p>options: List[StepOption],</p>\n<p>budget: Budget,</p>\n<p>*,</p>\n<p>max_steps: int = 6,</p>\n<p>beam_width: int = 12,</p>\n<p>diversity_penalty: float = 0.2</p>\n<p>) -&gt; PlanCandidate:</p>\n<p>def redundancy_cost(chosen: List[StepOption], new: StepOption) -&gt; float:</p>\n<p>key_new = new.name.split(\"(\")[0].strip().lower()</p>\n<p>overlap = 0</p>\n<p>for s in chosen:</p>\n<p>key_s = s.name.split(\"(\")[0].strip().lower()</p>\n<p>if key_s == key_new:</p>\n<p>overlap += 1</p>\n<p>return overlap * diversity_penalty</p>\n<p>beams: List[PlanCandidate] = [PlanCandidate(steps=[], spend=Spend(), value=0.0, rationale=\"\")]</p>\n<p>for _ in range(max_steps):</p>\n<p>expanded: List[PlanCandidate] = []</p>\n<p>for cand in beams:</p>\n<p>for opt in options:</p>\n<p>if opt in cand.steps:</p>\n<p>continue</p>\n<p>new_spend = cand.spend.add(opt.est_spend)</p>\n<p>if not new_spend.within(budget):</p>\n<p>continue</p>\n<p>new_value = cand.value + opt.est_value - redundancy_cost(cand.steps, opt)</p>\n<p>expanded.append(</p>\n<p>PlanCandidate(</p>\n<p>steps=cand.steps + [opt],</p>\n<p>spend=new_spend,</p>\n<p>value=new_value,</p>\n<p>rationale=cand.rationale</p>\n<p>)</p>\n<p>)</p>\n<p>if not expanded:</p>\n<p>break</p>\n<p>expanded.sort(key=lambda c: c.value, reverse=True)</p>\n<p>beams = expanded[:beam_width]</p>\n<p>best = max(beams, key=lambda c: c.value)</p>\n<p>return best</p>\n<p>We implement the budget-constrained planning logic that searches for the highest-value combination of steps under strict limits. We apply a beam-style search with redundancy penalties to avoid wasteful action overlap. This is where the agent truly becomes cost-aware by optimizing value subject to constraints. Check out the&nbsp;FULL CODES here.</p>\n<p>Copy CodeCopiedUse a different Browserdef run_local_step(task: str, step: StepOption, working: Dict[str, Any]) -&gt; str:</p>\n<p>name = step.name.lower()</p>\n<p>if \"clarify deliverables\" in name:</p>\n<p>return (</p>\n<p>\"Deliverables checklist:\\n\"</p>\n<p>\"- Executive summary\\n- Scope &amp; assumptions\\n- Workplan + milestones\\n\"</p>\n<p>\"- Risk register (risk, impact, likelihood, mitigation, owner)\\n\"</p>\n<p>\"- Next steps + data needed\\n\"</p>\n<p>)</p>\n<p>if \"outline plan\" in name:</p>\n<p>return (</p>\n<p>\"Outline:\\n1) Context &amp; objective\\n2) Scope\\n3) Approach\\n4) Timeline\\n5) Risks\\n6) Next steps\\n\"</p>\n<p>)</p>\n<p>if \"risk register\" in name:</p>\n<p>return (</p>\n<p>\"Risk register (template):\\n\"</p>\n<p>\"1) Data access delays | High | Mitigation: agree data list + owners\\n\"</p>\n<p>\"2) Stakeholder alignment | Med | Mitigation: weekly review\\n\"</p>\n<p>\"3) Tooling constraints | Med | Mitigation: phased rollout\\n\"</p>\n<p>)</p>\n<p>if \"timeline\" in name:</p>\n<p>return (</p>\n<p>\"Timeline (template):\\n\"</p>\n<p>\"Week 1: discovery + requirements\\nWeek 2: prototype + feedback\\n\"</p>\n<p>\"Week 3: pilot + metrics\\nWeek 4: rollout + handover\\n\"</p>\n<p>)</p>\n<p>if \"quality pass\" in name:</p>\n<p>draft = working.get(\"draft\", \"\")</p>\n<p>return \"Light quality pass done (headings normalized, bullets aligned).\\n\" + draft</p>\n<p>return f\"Completed: {step.name}\\n\"</p>\n<p>def run_llm_step(task: str, step: StepOption, working: Dict[str, Any]) -&gt; str:</p>\n<p>kind = step.payload.get(\"prompt_kind\", \"generic\")</p>\n<p>context = working.get(\"draft\", \"\")</p>\n<p>prompts = {</p>\n<p>\"outline\": f\"Create a crisp, structured outline for the task below.\\nTASK:\\n{task}\\nReturn a numbered outline.\",</p>\n<p>\"risks\": f\"Create a risk register for the task below. Include: Risk | Impact | Likelihood | Mitigation | Owner.\\nTASK:\\n{task}\",</p>\n<p>\"timeline\": f\"Create a realistic milestone timeline with dependencies for the task below.\\nTASK:\\n{task}\",</p>\n<p>\"polish\": f\"Rewrite and polish the following draft for clarity and consistency.\\nDRAFT:\\n{context}\",</p>\n<p>\"generic\": f\"Help with this step: {step.description}\\nTASK:\\n{task}\\nCURRENT:\\n{context}\",</p>\n<p>}</p>\n<p>return llm_text(prompts.get(kind, prompts[\"generic\"]), model=\"gpt-5\", effort=\"low\")</p>\n<p>def execute_plan(task: str, plan: PlanCandidate) -&gt; Tuple[str, Spend]:</p>\n<p>working = {\"draft\": \"\"}</p>\n<p>actual = Spend()</p>\n<p>for i, step in enumerate(plan.steps, 1):</p>\n<p>t0 = time.time()</p>\n<p>if step.executor == \"llm\" and USE_OPENAI:</p>\n<p>out = run_llm_step(task, step, working)</p>\n<p>tool_calls = 1</p>\n<p>else:</p>\n<p>out = run_local_step(task, step, working)</p>\n<p>tool_calls = 0</p>\n<p>dt_ms = int((time.time() - t0) * 1000)</p>\n<p>tok = approx_tokens(out)</p>\n<p>actual = actual.add(Spend(tokens=tok, latency_ms=dt_ms, tool_calls=tool_calls))</p>\n<p>working[\"draft\"] += f\"\\n\\n### Step {i}: {step.name}\\n{out}\\n\"</p>\n<p>return working[\"draft\"].strip(), actual</p>\n<p>TASK = \"Draft a 1-page project proposal for a logistics dashboard + fleet optimization pilot, including scope, timeline, and risks.\"</p>\n<p>BUDGET = Budget(</p>\n<p>max_tokens=2200,</p>\n<p>max_latency_ms=3500,</p>\n<p>max_tool_calls=2</p>\n<p>)</p>\n<p>options = generate_step_options(TASK)</p>\n<p>best_plan = plan_under_budget(options, BUDGET, max_steps=6, beam_width=14)</p>\n<p>print(\"=== SELECTED PLAN (budget-aware) ===\")</p>\n<p>for s in best_plan.steps:</p>\n<p>print(f\"- {s.name} | est_spend={s.est_spend} | est_value={s.est_value}\")</p>\n<p>print(\"\\nEstimated spend:\", best_plan.spend)</p>\n<p>print(\"Budget:\", BUDGET)</p>\n<p>print(\"\\n=== EXECUTING PLAN ===\")</p>\n<p>draft, actual = execute_plan(TASK, best_plan)</p>\n<p>print(\"\\n=== OUTPUT DRAFT ===\\n\")</p>\n<p>print(draft[:6000])</p>\n<p>print(\"\\n=== ACTUAL SPEND (approx) ===\")</p>\n<p>print(actual)</p>\n<p>print(\"\\nWithin budget?\", actual.within(BUDGET))</p>\n<p>We execute the selected plan and track actual resource usage step by step. We dynamically choose between local and LLM execution paths and aggregate the final output into a coherent draft. By comparing estimated and actual spend, we demonstrate how planning assumptions can be validated and refined in practice.</p>\n<p>In conclusion, we demonstrated how a cost-aware planning agent can reason about its resource consumption and adapt its behavior in real time. We executed only the steps that fit within predefined budgets and tracked actual spend to validate the planning assumptions, closing the loop between estimation and execution. Also, we highlighted how agentic AI systems can become more practical, controllable, and scalable by treating cost, latency, and tool usage as first-class decision variables rather than afterthoughts.</p>\n<p>Check out the&nbsp;FULL CODES here.&nbsp;Also,&nbsp;feel free to follow us on&nbsp;Twitter&nbsp;and don’t forget to join our&nbsp;100k+ ML SubReddit&nbsp;and Subscribe to&nbsp;our Newsletter. Wait! are you on telegram?&nbsp;now you can join us on telegram as well.</p>\n<p>The post How an AI Agent Chooses What to Do Under Tokens, Latency, and Tool-Call Budget Constraints? appeared first on MarkTechPost.</p>"
    },
    {
      "id": "4fe800fee1d0",
      "title": "Defensive AI and how machine learning strengthens cyber defense",
      "content": "Cyber threats don&#8217;t follow predictable patterns, forcing security teams to rethink how protection works at scale. Defensive AI is emerging as a practical response, combining machine learning with human oversight.\n\n\n\nCybersecurity rarely fails because teams lack tools. It fails because threats move faster than detection can keep pace. As digital systems expand, attackers adapt in real time while static defences fall behind. This reality explains why AI security explained has become a central topic in modern cyber defense conversations.\n\n\n\n\n\n\n\nWhy cyber defense needs machine learning now\n\n\n\nAttack techniques today are fluid. Phishing messages change wording in hours. Malware alters behaviour to avoid detection. Rule-based security struggles in this environment.\n\n\n\nMachine learning fills this void by learning how systems are expected to behave. In other words, it does not wait for a recognised pattern but searches for something that does not seem to fit. The is important when a threat is either new or camouflaged.\n\n\n\nFor security teams, this change reduces blind spots. Machine learning processes data volumes that no human team could review manually. It connects subtle signals in networks, endpoints and cloud services.\n\n\n\nYou see the benefit when response times shrink. Early detection limits damage. Faster containment protects data and continuity. In global environments, that speed often determines whether an incident stays manageable.\n\n\n\n\n\n\n\nHow defensive AI identifies threats in real time\n\n\n\nMachine learning models are interested in behaviour and not in assumptions. Models learn by observing how users and applications interact. When activity breaks from expected patterns, alerts surface. This approach works even when the threat has never appeared before. Zero-day attacks really become visible because behaviour, not history, triggers concern.\n\n\n\nCommon detection techniques include:\n\n\n\n\nBehavioural base-lining to spot unusual activity\n\n\n\nAnomaly detection in network and application traffic\n\n\n\nClassification models trained on diverse threat patterns\n\n\n\n\n\n\n\n\nReal-time analysis is essential. Modern attacks spread quickly in interconnected systems. Machine learning continuously evaluates streaming data, letting security teams react before damage escalates.\n\n\n\nThis ability proves especially valuable in cloud environments. Resources change constantly. Traditional perimeter defences lose relevance. Behaviour-based monitoring adapts as systems evolve.\n\n\n\n\n\n\n\nEmbedding defense across the AI security lifecycle\n\n\n\nEffective cyber defense does not start at deployment. It begins earlier and continues throughout a system&#8217;s lifespan.\n\n\n\nMachine learning technology evaluates development configurations and dependencies during development. High-risk configuration items and exposed services are identified before deployment to production. That makes them less exposed in the long run.\n\n\n\nOnce systems go live, monitoring shifts to runtime behaviour. Access requests, inference activity and data flows receive constant attention. Unusual patterns prompt investigation.\n\n\n\nPost-deployment oversight remains critical. Use patterns change. Models age. Defensive AI detects drift that may signal misuse or emerging vulnerabilities.\n\n\n\nThe lifecycle view reduces fragmentation. Security becomes consistent in stages not reactive after incidents occur. Over time, that consistency builds operational confidence.\n\n\n\n\n\n\n\nDefensive AI in complex enterprise environments\n\n\n\nEnterprise infrastructure rarely exists in one place. Cloud platforms, remote work and third-party services increase complexity.\n\n\n\nDefensive AI addresses this by correlating signals in environments. Isolated alerts become connected stories. Security teams gain context instead of noise.\n\n\n\nMachine learning also helps prioritise risk. Not every alert requires immediate action. By scoring threats based on behaviour and impact, AI reduces alert fatigue.\n\n\n\nThis prioritisation improves efficiency. Analysts spend time where it matters most. Routine anomalies are monitored and not escalated.\n\n\n\nAs organisations operate in regions, consistency becomes vital. Defensive AI applies the same analytical standards globally. That uniformity supports reliable protection without slowing operations.\n\n\n\n\n\n\n\nHuman judgement in an AI-driven defense model\n\n\n\nDefensive AI is most effective when paired with human expertise. Automation deals with speed and volume. Human judgement and accountability are provided by humans. The ensures there is no blind trust in systems unaware of what is happening in the real world.\n\n\n\nSecurity specialists are involved in model training and testing. Human judgement is used to decide which behaviours are most significant. Context is always important for interpretation, particularly when business dynamics, roles and geographic considerations apply.\n\n\n\nExplainability is also a factor in trust. It is necessary to know the reason a warning was issued. Modern defensive systems are increasingly providing a reason for a decision, letting analysts review the results and make decisions with confidence not hesitation.\n\n\n\nThe combination produces stronger results. AI points out potential dangers early, in large spaces. Humans make decisions about actions, focus on impact and mitigate effects. AI and humans create a robust defense system.\n\n\n\nIn light of the increasingly adaptable nature of threats in cyberspace, this synergy has become imperative. The role of defensive AI in supporting the underlying foundation through analysis has been made possible through human oversight.\n\n\n\n\n\n\n\nConclusions\n\n\n\nCybersecurity exists in a reality that is defined by speed, scale and continuous change. The static nature of cyber-defense makes it inadequate in this reality, as attack vectors change faster than static cyber-defense measures can keep pace.\n\n\n\nDefensive AI represents a useful evolution. Machine learning improves detection, reduces response time and helps build resistance in complex systems by recognising nuanced patterns of human behaviour.\n\n\n\nBut when paired with experienced human monitoring, defensive AI goes beyond automation. It can become an assured means of protecting contemporary digital infrastructure, facilitating stable security operations that don&#8217;t diminish responsibility or decision-making.\n\n\n\nImage source: Unsplash\nThe post Defensive AI and how machine learning strengthens cyber defense appeared first on AI News.",
      "url": "https://www.artificialintelligence-news.com/news/defensive-ai-and-how-machine-learning-strengthens-cyber-defense/",
      "author": "Bazoom",
      "published": "2026-01-23T10:15:58",
      "source": "AI News",
      "source_type": "rss",
      "tags": [
        "Artificial Intelligence",
        "Sponsored Content"
      ],
      "summary": "Overview of defensive AI and machine learning applications in cybersecurity, discussing how ML helps security teams respond to evolving threats at scale.",
      "importance_score": 32.0,
      "reasoning": "General educational content on AI cybersecurity applications. Appears to be sponsored content without significant news value.",
      "themes": [
        "Cybersecurity",
        "AI Applications",
        "Sponsored"
      ],
      "continuation": null,
      "summary_html": "<p>Overview of defensive AI and machine learning applications in cybersecurity, discussing how ML helps security teams respond to evolving threats at scale.</p>",
      "content_html": "<p>Cyber threats don’t follow predictable patterns, forcing security teams to rethink how protection works at scale. Defensive AI is emerging as a practical response, combining machine learning with human oversight.</p>\n<p>Cybersecurity rarely fails because teams lack tools. It fails because threats move faster than detection can keep pace. As digital systems expand, attackers adapt in real time while static defences fall behind. This reality explains why AI security explained has become a central topic in modern cyber defense conversations.</p>\n<p>Why cyber defense needs machine learning now</p>\n<p>Attack techniques today are fluid. Phishing messages change wording in hours. Malware alters behaviour to avoid detection. Rule-based security struggles in this environment.</p>\n<p>Machine learning fills this void by learning how systems are expected to behave. In other words, it does not wait for a recognised pattern but searches for something that does not seem to fit. The is important when a threat is either new or camouflaged.</p>\n<p>For security teams, this change reduces blind spots. Machine learning processes data volumes that no human team could review manually. It connects subtle signals in networks, endpoints and cloud services.</p>\n<p>You see the benefit when response times shrink. Early detection limits damage. Faster containment protects data and continuity. In global environments, that speed often determines whether an incident stays manageable.</p>\n<p>How defensive AI identifies threats in real time</p>\n<p>Machine learning models are interested in behaviour and not in assumptions. Models learn by observing how users and applications interact. When activity breaks from expected patterns, alerts surface. This approach works even when the threat has never appeared before. Zero-day attacks really become visible because behaviour, not history, triggers concern.</p>\n<p>Common detection techniques include:</p>\n<p>Behavioural base-lining to spot unusual activity</p>\n<p>Anomaly detection in network and application traffic</p>\n<p>Classification models trained on diverse threat patterns</p>\n<p>Real-time analysis is essential. Modern attacks spread quickly in interconnected systems. Machine learning continuously evaluates streaming data, letting security teams react before damage escalates.</p>\n<p>This ability proves especially valuable in cloud environments. Resources change constantly. Traditional perimeter defences lose relevance. Behaviour-based monitoring adapts as systems evolve.</p>\n<p>Embedding defense across the AI security lifecycle</p>\n<p>Effective cyber defense does not start at deployment. It begins earlier and continues throughout a system’s lifespan.</p>\n<p>Machine learning technology evaluates development configurations and dependencies during development. High-risk configuration items and exposed services are identified before deployment to production. That makes them less exposed in the long run.</p>\n<p>Once systems go live, monitoring shifts to runtime behaviour. Access requests, inference activity and data flows receive constant attention. Unusual patterns prompt investigation.</p>\n<p>Post-deployment oversight remains critical. Use patterns change. Models age. Defensive AI detects drift that may signal misuse or emerging vulnerabilities.</p>\n<p>The lifecycle view reduces fragmentation. Security becomes consistent in stages not reactive after incidents occur. Over time, that consistency builds operational confidence.</p>\n<p>Defensive AI in complex enterprise environments</p>\n<p>Enterprise infrastructure rarely exists in one place. Cloud platforms, remote work and third-party services increase complexity.</p>\n<p>Defensive AI addresses this by correlating signals in environments. Isolated alerts become connected stories. Security teams gain context instead of noise.</p>\n<p>Machine learning also helps prioritise risk. Not every alert requires immediate action. By scoring threats based on behaviour and impact, AI reduces alert fatigue.</p>\n<p>This prioritisation improves efficiency. Analysts spend time where it matters most. Routine anomalies are monitored and not escalated.</p>\n<p>As organisations operate in regions, consistency becomes vital. Defensive AI applies the same analytical standards globally. That uniformity supports reliable protection without slowing operations.</p>\n<p>Human judgement in an AI-driven defense model</p>\n<p>Defensive AI is most effective when paired with human expertise. Automation deals with speed and volume. Human judgement and accountability are provided by humans. The ensures there is no blind trust in systems unaware of what is happening in the real world.</p>\n<p>Security specialists are involved in model training and testing. Human judgement is used to decide which behaviours are most significant. Context is always important for interpretation, particularly when business dynamics, roles and geographic considerations apply.</p>\n<p>Explainability is also a factor in trust. It is necessary to know the reason a warning was issued. Modern defensive systems are increasingly providing a reason for a decision, letting analysts review the results and make decisions with confidence not hesitation.</p>\n<p>The combination produces stronger results. AI points out potential dangers early, in large spaces. Humans make decisions about actions, focus on impact and mitigate effects. AI and humans create a robust defense system.</p>\n<p>In light of the increasingly adaptable nature of threats in cyberspace, this synergy has become imperative. The role of defensive AI in supporting the underlying foundation through analysis has been made possible through human oversight.</p>\n<p>Conclusions</p>\n<p>Cybersecurity exists in a reality that is defined by speed, scale and continuous change. The static nature of cyber-defense makes it inadequate in this reality, as attack vectors change faster than static cyber-defense measures can keep pace.</p>\n<p>Defensive AI represents a useful evolution. Machine learning improves detection, reduces response time and helps build resistance in complex systems by recognising nuanced patterns of human behaviour.</p>\n<p>But when paired with experienced human monitoring, defensive AI goes beyond automation. It can become an assured means of protecting contemporary digital infrastructure, facilitating stable security operations that don’t diminish responsibility or decision-making.</p>\n<p>Image source: Unsplash</p>\n<p>The post Defensive AI and how machine learning strengthens cyber defense appeared first on AI News.</p>"
    },
    {
      "id": "83bb8703589a",
      "title": "‘Uncanny Valley’: Donald Trump’s Davos Drama, AI Midterms, and ChatGPT’s Last Resort",
      "content": "On this episode of Uncanny Valley, our hosts unpack the news from Davos, where Trump and major AI companies shared the stage at the World Economic Forum.",
      "url": "https://www.wired.com/story/uncanny-valley-podcast-trump-davos-ice-ai-midterms-chatgpt-ads/",
      "author": "Brian Barrett, Zoë Schiffer, Leah Feiger",
      "published": "2026-01-23T22:26:01",
      "source": "Feed: Artificial Intelligence Latest",
      "source_type": "rss",
      "tags": [
        "Politics",
        "Politics / Politics News",
        "Uncanny Valley Podcast",
        "podcasts",
        "Donald Trump",
        "politics",
        "Europe",
        "artificial intelligence",
        "Immigration and Customs Enforcement",
        "elections",
        "ChatGPT",
        "OpenAI",
        "Uncanny Valley"
      ],
      "summary": "Uncanny Valley podcast episode covering Trump at Davos, AI midterms implications, and ChatGPT's advertising plans.",
      "importance_score": 30.0,
      "reasoning": "Podcast episode aggregating existing news rather than breaking new developments.",
      "themes": [
        "Podcast",
        "Politics",
        "Media"
      ],
      "continuation": null,
      "summary_html": "<p>Uncanny Valley podcast episode covering Trump at Davos, AI midterms implications, and ChatGPT's advertising plans.</p>",
      "content_html": "<p>On this episode of Uncanny Valley, our hosts unpack the news from Davos, where Trump and major AI companies shared the stage at the World Economic Forum.</p>"
    }
  ]
}