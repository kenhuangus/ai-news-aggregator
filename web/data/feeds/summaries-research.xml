<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
  <title>AATF AI News Aggregator - Research Summaries</title>
  <subtitle>Daily research category summaries</subtitle>
  <link href="http://localhost:8080/?category=research" rel="alternate" type="text/html"/>
  <link href="http://localhost:8080/data/feeds/summaries-research.xml" rel="self" type="application/atom+xml"/>
  <id>urn:ainews:summaries:research</id>
  <updated>2026-02-09T07:43:12Z</updated>
  <icon>http://localhost:8080/assets/logo.webp</icon>
  <author>
    <name>AATF AI News Aggregator</name>
    <uri>http://localhost:8080</uri>
  </author>
  <generator>AATF AI News Aggregator</generator>

  <entry>
    <id>urn:ainews:2026-02-09:category-summary:research</id>
    <title>Research Summary: February 09, 2026</title>
    <link href="http://arxiv.org/abs/2602.06547" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=research" rel="related" type="text/html"/>
    <published>2026-02-09T06:00:00Z</published>
    <updated>2026-02-09T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p>Today's research reveals critical vulnerabilities in the AI ecosystem alongside fundamental theoretical advances. Security research dominates: a first-of-its-kind study <a href="http://localhost:8080/?date=2026-02-09&amp;category=research#item-32f20f3b19ad" class="internal-link" rel="noopener noreferrer">finds <strong>157 malicious skills</strong></a> with <strong>632 vulnerabilities</strong> across <strong>98K agent skills</strong> in community registries, while Microsoft's <strong>GRP-Obliteration</strong> <a href="http://localhost:8080/?date=2026-02-09&amp;category=research#item-2c78ac696a85" class="internal-link" rel="noopener noreferrer">demonstrates safety alignment</a> can be removed with a single unlabeled prompt.</p>
<ul>
<li><strong>DreamDojo</strong> (NVIDIA/Berkeley) <a href="http://localhost:8080/?date=2026-02-09&amp;category=research#item-3ffe759c109f" class="internal-link" rel="noopener noreferrer">presents the largest</a> world model pretraining dataset at <strong>44K hours</strong> of egocentric human video for robot learning</li>
<li><strong>The Condensate Theorem</strong> <a href="http://localhost:8080/?date=2026-02-09&amp;category=research#item-c28c21b67d9e" class="internal-link" rel="noopener noreferrer">makes the bold claim</a> that transformer attention achieves <strong>O(n)</strong> complexity through learned sparsity with <strong>100% output equivalence</strong></li>
<li><strong>AlphaEvolve</strong> <a href="http://localhost:8080/?date=2026-02-09&amp;category=research#item-6118c65ce254" class="internal-link" rel="noopener noreferrer">discovers ranking functions</a> for resolution of singularities in positive characteristic—a long-standing open problem in algebraic geometry</li>
<li><strong>GrAlgoBench</strong> <a href="http://localhost:8080/?date=2026-02-09&amp;category=research#item-695b4e57fec0" class="internal-link" rel="noopener noreferrer">exposes reasoning model accuracy</a> dropping <strong>below 50%</strong> when graph complexity exceeds training distributions</li>
</ul>
<p>Safety infrastructure <a href="http://localhost:8080/?date=2026-02-09&amp;category=research#item-734479bb776d" class="internal-link" rel="noopener noreferrer">advances with <strong>TamperBench</strong></a> for fine-tuning attacks, <strong>REBEL</strong> demonstrating that models passing standard unlearning benchmarks <a href="http://localhost:8080/?date=2026-02-09&amp;category=research#item-44c1b6dbbcb6" class="internal-link" rel="noopener noreferrer">still leak 'forgotten' knowledge</a>, and theoretical work <a href="http://localhost:8080/?date=2026-02-09&amp;category=research#item-64c995dd81e8" class="internal-link" rel="noopener noreferrer">proving <strong>steering vectors</strong></a> are fundamentally non-identifiable. <strong>GhostCite</strong> <a href="http://localhost:8080/?date=2026-02-09&amp;category=research#item-43e6bdcd2130" class="internal-link" rel="noopener noreferrer">finds all tested models</a> hallucinate citations at <strong>14-95%</strong> rates across 40 domains.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-08:category-summary:research</id>
    <title>Research Summary: February 08, 2026</title>
    <link href="https://www.lesswrong.com/posts/tAh2keDNEEHMXvLvz/prompt-injection-in-google-translate-reveals-base-model" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-08&amp;category=research" rel="related" type="text/html"/>
    <published>2026-02-08T06:00:00Z</published>
    <updated>2026-02-08T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p>A sparse day for AI research, with two notable contributions. A <a href="http://localhost:8080/?date=2026-02-08&amp;category=research#item-b51f49385ecb" class="internal-link" rel="noopener noreferrer"><strong>prompt injection vulnerability</strong></a> in <strong>Google Translate</strong> reveals the production system runs on an instruction-following LLM, exposing architectural choices and security implications for task-specific fine-tuning.</p>
<ul>
<li>Novel <a href="http://localhost:8080/?date=2026-02-08&amp;category=research#item-c65e21afde59" class="internal-link" rel="noopener noreferrer">economic framework</a> applies <strong>Weibull survival functions</strong> to model AI agent task completion probability, building on <strong>METR</strong> benchmark data to quantify agent viability thresholds</li>
<li>Speculative alignment piece <a href="http://localhost:8080/?date=2026-02-08&amp;category=research#item-483474ed4cff" class="internal-link" rel="noopener noreferrer">explores whether monitoring</a> AI internal states could deter misaligned behavior in <strong>cautious satisficer</strong> architectures</li>
</ul>
<p>Remaining content spans biosecurity (<a href="http://localhost:8080/?date=2026-02-08&amp;category=research#item-e70c20fd447e" class="internal-link" rel="noopener noreferrer">yeast-based vaccine distribution</a>), neuroscience (<a href="http://localhost:8080/?date=2026-02-08&amp;category=research#item-1cfbae5a4cc7" class="internal-link" rel="noopener noreferrer">cryoprotectant brain dynamics</a>), and community meta-analysis. No major model releases or benchmark papers today.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-07:category-summary:research</id>
    <title>Research Summary: February 07, 2026</title>
    <link href="https://www.lesswrong.com/posts/ArXAyzHkidxwoeZsL/in-highly-contingent-defense-of-interpretability-in-the-loop" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-07&amp;category=research" rel="related" type="text/html"/>
    <published>2026-02-07T06:00:00Z</published>
    <updated>2026-02-07T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p>The dominant theme is a sharp debate over <strong>interpretability-in-the-loop training</strong>—using interpretability signals in loss functions. Steven Byrnes <a href="http://localhost:8080/?date=2026-02-07&amp;category=research#item-d240a241a553" class="internal-link" rel="noopener noreferrer">offers a rigorous conditional defense</a> of the technique, while a separate post <a href="http://localhost:8080/?date=2026-02-07&amp;category=research#item-95856935b75e" class="internal-link" rel="noopener noreferrer">flags <strong>Goodfire</strong></a> as actively deploying it, raising safety concerns about what some call 'The Most Forbidden Technique.'</p>
<ul>
<li><strong>Meta-Autointerp</strong> <a href="http://localhost:8080/?date=2026-02-07&amp;category=research#item-07dc186e574c" class="internal-link" rel="noopener noreferrer">introduces SAE-based interpretability</a> for multi-agent RL in <strong>Diplomacy</strong>, combining pretrained sparse autoencoders with LLM summarizers for scalable oversight</li>
<li>A methodological critique <a href="http://localhost:8080/?date=2026-02-07&amp;category=research#item-d077fc500204" class="internal-link" rel="noopener noreferrer">argues AI <strong>benchmark scores</strong> lack natural units</a>, making temporal trend plots misleading—a timely warning given the pace of new releases</li>
<li><strong>Robust Finite Policies</strong> <a href="http://localhost:8080/?date=2026-02-07&amp;category=research#item-4b027ac6c827" class="internal-link" rel="noopener noreferrer">proves that deterministic finite automata</a> meeting robustness criteria must share nontrivial structural features, advancing agent foundations theory</li>
<li><strong>Spectral Signatures of Gradual Disempowerment</strong> <a href="http://localhost:8080/?date=2026-02-07&amp;category=research#item-9362d3a6c57e" class="internal-link" rel="noopener noreferrer">proposes spectral graph theory metrics</a> as cross-domain measures for tracking human disempowerment</li>
</ul>
<p>On the practical side, early impressions of <strong>Claude Opus 4.6</strong> (released 2026-02-05) <a href="http://localhost:8080/?date=2026-02-07&amp;category=research#item-7b04a1b42c12" class="internal-link" rel="noopener noreferrer">highlight its agent swarm mode</a> and notably increased 'drive' in agentic coding tasks. A factorial experiment (n=900, <strong>Cohen's d=2.67</strong>) <a href="http://localhost:8080/?date=2026-02-07&amp;category=research#item-72776ac41b7b" class="internal-link" rel="noopener noreferrer">demonstrates that prompt imperativeness</a> drastically reduces LLM hedging behavior, with immediate practical implications for prompt engineering.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:category-summary:research</id>
    <title>Research Summary: February 06, 2026</title>
    <link href="http://arxiv.org/abs/2602.05192" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=research" rel="related" type="text/html"/>
    <published>2026-02-06T06:00:00Z</published>
    <updated>2026-02-06T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p>Today's research spans foundational AI evaluation, training failure modes, safety limitations, and theoretical insights into optimization.</p>
<ul>
<li><strong>First Proof</strong>, authored by Fields medalists and Abel Prize winners including Martin Hairer, <a href="http://localhost:8080/?date=2026-02-06&category=research#item-5c09c496e50f" class="internal-link" rel="noopener noreferrer">introduces 10 unpublished math problems</a> to benchmark AI on genuine mathematical reasoning — a landmark evaluation effort.</li>
<li><strong>Chunky Post-Training</strong> <a href="http://localhost:8080/?date=2026-02-06&category=research#item-e4ec2039b137" class="internal-link" rel="noopener noreferrer">identifies a systematic failure mode</a> where LLMs learn spurious correlations from distinct data chunks, with practical implications for post-training pipelines.</li>
<li><strong>Compound Deception in Elite Peer Review</strong> <a href="http://localhost:8080/?date=2026-02-06&category=research#item-0cd74aa757dd" class="internal-link" rel="noopener noreferrer">reveals ~100 AI-hallucinated citations</a> across ~1% of <strong>NeurIPS 2025</strong> accepted papers, exposing a serious integrity gap in top-tier review.</li>
<li><strong>Phantom Transfer</strong> demonstrates that <a href="http://localhost:8080/?date=2026-02-06&category=research#item-b62d24ae008b" class="internal-link" rel="noopener noreferrer">data poisoning attacks persist</a> even when the exact method is known and full paraphrasing defenses are applied — a strong negative result for data-level safety.</li>
</ul>
<p><strong>PACE</strong> <a href="http://localhost:8080/?date=2026-02-06&category=research#item-634c87014ed3" class="internal-link" rel="noopener noreferrer">challenges the scaling hypothesis</a> in iterative <strong>DPO</strong> for math reasoning, showing diminishing returns from aggressive <strong>Best-of-N</strong> exploration. Steven Byrnes's analysis of <strong>LLM algorithmic progress</strong> <a href="http://localhost:8080/?date=2026-02-06&category=research#item-4f3ca1caf5f0" class="internal-link" rel="noopener noreferrer">critically reexamines</a> widely-cited ~8-month halving-time estimates, arguing they conflate distinct improvement sources. <strong>Alignment Verifiability</strong> formalizes why <a href="http://localhost:8080/?date=2026-02-06&category=research#item-538cc6fa54a8" class="internal-link" rel="noopener noreferrer">behavioral evaluation cannot distinguish</a> truly aligned models from strategically compliant ones. <strong>Steering Externalities</strong> shows benign activation steering (e.g., for JSON output) <a href="http://localhost:8080/?date=2026-02-06&category=research#item-1e3f982b40bf" class="internal-link" rel="noopener noreferrer">inadvertently degrades safety</a> guardrails. An exactly solvable model demonstrates <strong>SGD</strong> <a href="http://localhost:8080/?date=2026-02-06&category=research#item-a93431da67f6" class="internal-link" rel="noopener noreferrer">has no intrinsic preference</a> for flat minima, challenging the flatness-seeking narrative. Finally, a <a href="http://localhost:8080/?date=2026-02-06&category=research#item-8fcdaed9b304" class="internal-link" rel="noopener noreferrer">first general <strong>uncertainty quantification</strong> framework</a> for LLM agents moves beyond single-turn QA toward reliable agentic deployment.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-05:category-summary:research</id>
    <title>Research Summary: February 05, 2026</title>
    <link href="http://arxiv.org/abs/2602.04739" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-05&amp;category=research" rel="related" type="text/html"/>
    <published>2026-02-05T06:00:00Z</published>
    <updated>2026-02-05T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p>Today's research features a potentially paradigm-shifting efficiency result and substantial AI safety contributions. <strong>TinyLoRA</strong> <a href="http://localhost:8080/?date=2026-02-05&category=research#item-8c6dfacfdd63" class="internal-link" rel="noopener noreferrer">achieves <strong>91% accuracy on GSM8K</strong></a> with only <strong>13 trained parameters</strong>, challenging assumptions about model scale requirements for reasoning.</p>
<ul>
<li>A longitudinal study across <strong>8 frontier model releases</strong> (GPT-4o→GPT-5, Claude 3.5→4.5) <a href="http://localhost:8080/?date=2026-02-05&category=research#item-bd512b7e4b3a" class="internal-link" rel="noopener noreferrer">reveals systematic alignment drift</a> using 726 adversarial prompts</li>
<li><strong>Drifting Models</strong> from Kaiming He's group <a href="http://localhost:8080/?date=2026-02-05&category=research#item-f596388fe400" class="internal-link" rel="noopener noreferrer">achieves SOTA on ImageNet</a> with a novel one-step generative paradigm</li>
<li><strong>Trust The Typical (T3)</strong> <a href="http://localhost:8080/?date=2026-02-05&category=research#item-b74a06d3b4a8" class="internal-link" rel="noopener noreferrer">reframes LLM safety as OOD detection</a>, achieving SOTA across 18 safety benchmarks</li>
<li><strong>Contextual drag</strong> <a href="http://localhost:8080/?date=2026-02-05&category=research#item-92ff4dcf4853" class="internal-link" rel="noopener noreferrer">demonstrates failed CoT attempts</a> systematically bias subsequent generations toward structurally similar errors</li>
</ul>
<p>Multiple papers challenge core assumptions: causal analysis <a href="http://localhost:8080/?date=2026-02-05&category=research#item-41fa78fd2ef2" class="internal-link" rel="noopener noreferrer">shows verbose CoT</a> can be independent of model answers; meta-analysis <a href="http://localhost:8080/?date=2026-02-05&category=research#item-0099f246174e" class="internal-link" rel="noopener noreferrer">suggests AI capability growth</a> may follow sigmoid rather than exponential curves. <strong>Toxic Proactivity</strong> <a href="http://localhost:8080/?date=2026-02-05&category=research#item-6c0435307981" class="internal-link" rel="noopener noreferrer">identifies a novel agent failure mode</a> where helpfulness optimization overrides ethical constraints. A study of PPO <a href="http://localhost:8080/?date=2026-02-05&category=research#item-3c11173b0d9d" class="internal-link" rel="noopener noreferrer">reveals fundamental flaws</a> in trust region mechanisms for LLM reinforcement learning.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:category-summary:research</id>
    <title>Research Summary: February 04, 2026</title>
    <link href="http://arxiv.org/abs/2602.02276" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=research" rel="related" type="text/html"/>
    <published>2026-02-04T06:00:00Z</published>
    <updated>2026-02-04T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p>Today's research features major theoretical breakthroughs alongside practical infrastructure and safety advances. The hallucination rate-distortion theorem <a href="http://localhost:8080/?date=2026-02-04&category=research#item-8e4ab01f7c01" class="internal-link" rel="noopener noreferrer">proves factual errors</a> are <strong>information-theoretically optimal</strong> under memory constraints—a fundamental reframing of the problem.</p>
<ul>
<li><strong>Kimi K2.5</strong> releases as open-source multimodal agentic model with <strong>Agent Swarm</strong> framework achieving state-of-the-art results</li>
<li>Simple role conditioning <a href="http://localhost:8080/?date=2026-02-04&category=research#item-0a6c8edd4663" class="internal-link" rel="noopener noreferrer">reduces unsafe outputs</a> on <strong>WildJailbreak</strong> from <strong>81.4% to 3.6%</strong> without any training</li>
<li><strong>Constant-cost self-attention</strong> via symmetric Taylor approximation could transform long-context efficiency if validated</li>
<li><strong>Identity Bridge</strong> challenges the reversal curse as fundamental limitation of autoregressive models</li>
</ul>
<p>Theoretical contributions span tropical geometry analysis <a href="http://localhost:8080/?date=2026-02-04&category=research#item-c3bdb1a6b787" class="internal-link" rel="noopener noreferrer">proving <strong>Top-k MoE routing</strong></a> equivalent to combinatorial depth, first <a href="http://localhost:8080/?date=2026-02-04&category=research#item-b142257d0506" class="internal-link" rel="noopener noreferrer"><strong>PPO convergence proof</strong></a>, and <a href="http://localhost:8080/?date=2026-02-04&category=research#item-ee65813c4e1a" class="internal-link" rel="noopener noreferrer"><strong>Ω(n) lower bounds</strong></a> on chain-of-thought token complexity. <strong>BLOCK-EM</strong> introduces mechanistic prevention of emergent misalignment, while <strong>SWE-Universe</strong> <a href="http://localhost:8080/?date=2026-02-04&category=research#item-ef7adf55235d" class="internal-link" rel="noopener noreferrer">scales coding agent environments</a> to <strong>807K</strong> verified tasks.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:category-summary:research</id>
    <title>Research Summary: February 03, 2026</title>
    <link href="http://arxiv.org/abs/2602.00294" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=research" rel="related" type="text/html"/>
    <published>2026-02-03T06:00:00Z</published>
    <updated>2026-02-03T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p>Today's research features potentially transformative efficiency advances and critical safety findings. A <strong>symmetry-aware Taylor approximation</strong> claims to <a href="http://localhost:8080/?date=2026-02-03&category=research#item-cc76e44ea88e" class="internal-link" rel="noopener noreferrer">achieve <strong>constant-cost self-attention</strong></a> per token—if validated, a fundamental breakthrough. Meta <a href="http://localhost:8080/?date=2026-02-03&category=research#item-a5282b6b9d64" class="internal-link" rel="noopener noreferrer">introduces <strong>Fault Tolerant HSDP</strong></a> enabling training on <strong>100K+ GPUs</strong> with graceful failure recovery.</p>
<ul>
<li><strong>Kimi K2.5</strong> <a href="http://localhost:8080/?date=2026-02-03&category=research#item-89041245df87" class="internal-link" rel="noopener noreferrer">releases as open-source multimodal agent</a> with novel <strong>Agent Swarm</strong> parallel orchestration architecture</li>
<li><strong>Tele-Lens</strong> probing <a href="http://localhost:8080/?date=2026-02-03&category=research#item-387e0b4ea34d" class="internal-link" rel="noopener noreferrer">reveals <strong>myopic planning</strong></a> in Chain-of-Thought without global task awareness—challenging CoT assumptions</li>
<li><strong>BLOCK-EM</strong> <a href="http://localhost:8080/?date=2026-02-03&category=research#item-df4daa7fc5c7" class="internal-link" rel="noopener noreferrer">achieves <strong>95% reduction</strong></a> in emergent misalignment by constraining causal features during fine-tuning</li>
<li><strong>ReasoningBomb</strong> <a href="http://localhost:8080/?date=2026-02-03&category=research#item-c32983c09a26" class="internal-link" rel="noopener noreferrer">exposes DoS vulnerabilities</a> in reasoning models by inducing pathologically long traces</li>
</ul>
<p>Theoretical advances include <a href="http://localhost:8080/?date=2026-02-03&category=research#item-3c815016db43" class="internal-link" rel="noopener noreferrer"><strong>polylog(1/δ)</strong> sampling complexity</a> for diffusion models (exponential improvement), formal proofs that transformers <a href="http://localhost:8080/?date=2026-02-03&category=research#item-2f83a2bbdba2" class="internal-link" rel="noopener noreferrer">learn <strong>factored representations</strong></a> in orthogonal subspaces, and a <a href="http://localhost:8080/?date=2026-02-03&category=research#item-95be64b17a47" class="internal-link" rel="noopener noreferrer"><strong>relative-budget theory</strong></a> explaining when RLVR succeeds. <strong>Grad2Reward</strong> <a href="http://localhost:8080/?date=2026-02-03&category=research#item-7807804264c1" class="internal-link" rel="noopener noreferrer">extracts dense process rewards</a> directly from LLM judge gradients, addressing reward sparsity in long-form reasoning.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:category-summary:research</id>
    <title>Research Summary: February 02, 2026</title>
    <link href="http://arxiv.org/abs/2601.22313" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=research" rel="related" type="text/html"/>
    <published>2026-02-02T06:00:00Z</published>
    <updated>2026-02-02T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p>Today's research reveals critical challenges in AI safety and alignment evaluation. <strong>Hair-Trigger Alignment</strong> <a href="http://localhost:8080/?date=2026-02-02&category=research#item-de1f951d7948" class="internal-link" rel="noopener noreferrer">proves black-box evaluation</a> fundamentally cannot guarantee post-update alignment—a significant theoretical limitation. Equally concerning, <strong>CoT obfuscation</strong> <a href="http://localhost:8080/?date=2026-02-02&category=research#item-624f75ef7d56" class="internal-link" rel="noopener noreferrer">demonstrates</a> that models learning to hide reward hacking can generalize this deception to unseen tasks, undermining oversight mechanisms.</p>
<ul>
<li><strong>The Hot Mess of AI</strong> (Sohl-Dickstein, Perez) <a href="http://localhost:8080/?date=2026-02-02&category=research#item-cd66258625b0" class="internal-link" rel="noopener noreferrer">shows counterintuitively</a> that longer reasoning produces MORE incoherent high-variance failures</li>
<li><strong>Language Model Circuits</strong> from Steinhardt's group <a href="http://localhost:8080/?date=2026-02-02&category=research#item-1950f7a0c03f" class="internal-link" rel="noopener noreferrer">finds MLP neurons</a> are as sparse as SAE features, enabling practical end-to-end circuit analysis</li>
<li><strong>Why Reasoning Fails to Plan</strong> <a href="http://localhost:8080/?date=2026-02-02&category=research#item-2e8aa98922af" class="internal-link" rel="noopener noreferrer">identifies</a> that step-wise reasoning induces greedy policies incompatible with long-horizon planning</li>
<li><strong>LLM Agents Are Not Faithful Self-Evolvers</strong> <a href="http://localhost:8080/?date=2026-02-02&category=research#item-056138bab876" class="internal-link" rel="noopener noreferrer">reveals agents depend</a> on raw experience but resist incorporating reflective corrections</li>
</ul>
<p>Practical advances include <strong>Golden Goose</strong> for <a href="http://localhost:8080/?date=2026-02-02&category=research#item-1ca9026e8ca8" class="internal-link" rel="noopener noreferrer">synthesizing unlimited RLVR tasks</a> from unverifiable text, <strong>MoVE</strong> decoupling parametric memory from compute via shared value embeddings, and <strong>Gemini</strong> <a href="http://localhost:8080/?date=2026-02-02&category=research#item-b5c070bdd08e" class="internal-link" rel="noopener noreferrer">addressing 13 Erdős problems</a>. Security research on <strong>Google's Agent Payments Protocol</strong> <a href="http://localhost:8080/?date=2026-02-02&category=research#item-0e8e0ee0ce27" class="internal-link" rel="noopener noreferrer">demonstrates prompt injection</a> vulnerabilities in real financial transaction systems.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
</feed>