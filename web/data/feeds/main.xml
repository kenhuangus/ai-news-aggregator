<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
  <title>AATF AI News Aggregator</title>
  <subtitle>Daily AI/ML news powered by Claude Opus 4.5</subtitle>
  <link href="http://localhost:8080" rel="alternate" type="text/html"/>
  <link href="http://localhost:8080/data/feeds/main.xml" rel="self" type="application/atom+xml"/>
  <id>urn:ainews:main</id>
  <updated>2026-02-04T07:56:17Z</updated>
  <icon>http://localhost:8080/assets/logo.webp</icon>
  <author>
    <name>AATF AI News Aggregator</name>
    <uri>http://localhost:8080</uri>
  </author>
  <generator>AATF AI News Aggregator</generator>

  <entry>
    <id>urn:ainews:2026-02-04:executive-summary</id>
    <title>Daily Briefing: February 04, 2026</title>
    <link href="https://www.theguardian.com/business/nils-pratley-on-finance/2026/feb/03/elon-musk-is-taking-spacexs-minority-shareholders-for-a-ride" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04" rel="related" type="text/html"/>
    <published>2026-02-04T06:00:00Z</published>
    <updated>2026-02-04T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><img src="http://localhost:8080/data/2026-02-04/hero.webp" alt="Daily briefing hero image" style="max-width:100%;height:auto;border-radius:8px;margin-bottom:16px;"/></p>
<h4>Top Story</h4>
<p><strong>Apple's Xcode 26.3</strong> <a href="http://localhost:8080/?date=2026-02-04&amp;category=news#item-dbfac9015858" class="internal-link" rel="noopener noreferrer">launched with native <strong>Claude Agent SDK</strong> integration</a>, bringing full agentic coding capabilities—including subagents, background tasks, and plugins—to millions of Apple developers.</p>
<h4>Key Developments</h4>
<ul>
<li><strong>SpaceX-xAI Merger</strong>: <strong>Elon Musk</strong> <a href="http://localhost:8080/?date=2026-02-04&amp;category=news#item-190191b66dad" class="internal-link" rel="noopener noreferrer">announced the acquisition</a> of <strong>xAI</strong> by <strong>SpaceX</strong> at a reported <strong>$1.25 trillion</strong> valuation, consolidating his AI and space ventures.</li>
<li><strong>Qwen3-Coder-Next</strong>: <strong>Alibaba</strong> <a href="http://localhost:8080/?date=2026-02-04&amp;category=news#item-63f870e2f7fe" class="internal-link" rel="noopener noreferrer">released an <strong>80B</strong> parameter</a> open-weight MoE model with <strong>3B</strong> active parameters specifically designed for coding agents.</li>
<li><strong>OpenAI Codex</strong>: <strong>Sam Altman</strong> reported the <strong>Codex</strong> app <a href="http://localhost:8080/?date=2026-02-04&amp;category=social#item-4489cf7ad470" class="internal-link" rel="noopener noreferrer">hit <strong>200,000 downloads</strong></a> on day one; separately, <strong>Nvidia's</strong> planned <strong>$100 billion</strong> investment in <strong>OpenAI</strong> has reportedly <a href="http://localhost:8080/?date=2026-02-04&amp;category=news#item-fdfd335fe300" class="internal-link" rel="noopener noreferrer">not materialized</a>.</li>
<li><strong>OpenAI Leadership</strong>: VP of Research <strong>Jerry Tworek</strong> <a href="http://localhost:8080/?date=2026-02-04&amp;category=news#item-95332355e038" class="internal-link" rel="noopener noreferrer">departed</a> as the company prioritizes <strong>ChatGPT</strong> over experimental research; <a href="http://localhost:8080/?date=2026-02-04&amp;category=social#item-91b3f59a6b79" class="internal-link" rel="noopener noreferrer">new Head of Preparedness hired</a>.</li>
<li><strong>NASA-Claude</strong>: <strong>NASA</strong> used <strong>Claude</strong> to <a href="http://localhost:8080/?date=2026-02-04&amp;category=news#item-6712b7880159" class="internal-link" rel="noopener noreferrer">plot the <strong>Mars Perseverance Rover</strong> route</a>—a first for frontier AI in space operations.</li>
</ul>
<h4>Safety &amp; Regulation</h4>
<ul>
<li>French authorities <a href="http://localhost:8080/?date=2026-02-04&amp;category=news#item-e5c2a4325bec" class="internal-link" rel="noopener noreferrer">raided <strong>X's</strong> Paris office</a> and summoned <strong>Elon Musk</strong> for questioning over <strong>Grok's</strong> dissemination of Holocaust denial and deepfake content; <strong>UK ICO</strong> opened a separate probe.</li>
<li><strong>Moltbook</strong> <a href="http://localhost:8080/?date=2026-02-04&amp;category=news#item-ae5387021d5c" class="internal-link" rel="noopener noreferrer">enables viral AI prompts</a> that could replicate across agent networks similar to early computer worms.</li>
<li>Audit of <strong>306 MCP servers</strong> <a href="http://localhost:8080/?date=2026-02-04&amp;category=reddit#item-656c6ec6aa39" class="internal-link" rel="noopener noreferrer">revealed <strong>1,211 vulnerabilities</strong></a> including <strong>69 critical</strong> flaws—<strong>10%</strong> featured eval() on untrusted input.</li>
<li>Researchers <a href="http://localhost:8080/?date=2026-02-04&amp;category=reddit#item-3b4e10de483b" class="internal-link" rel="noopener noreferrer">discovered wallet-draining prompt injection</a> payloads targeting crypto wallets in the wild.</li>
</ul>
<h4>Research Highlights</h4>
<ul>
<li>A paper <a href="http://localhost:8080/?date=2026-02-04&amp;category=research#item-8e4ab01f7c01" class="internal-link" rel="noopener noreferrer">proves hallucination is optimal</a> behavior under memory constraints via rate-distortion theorem, fundamentally reframing the problem.</li>
<li>Simple role conditioning <a href="http://localhost:8080/?date=2026-02-04&amp;category=research#item-0a6c8edd4663" class="internal-link" rel="noopener noreferrer">reduces unsafe outputs</a> on <strong>WildJailbreak</strong> from <strong>81.4% to 3.6%</strong> without any training modifications.</li>
<li><strong>Anthropic Fellows</strong> <a href="http://localhost:8080/?date=2026-02-04&amp;category=social#item-1eccceaa3bf7" class="internal-link" rel="noopener noreferrer">released findings showing</a> models become more incoherent with extended reasoning—concerning for chain-of-thought approaches.</li>
<li><strong>SWE-Universe</strong> <a href="http://localhost:8080/?date=2026-02-04&amp;category=research#item-ef7adf55235d" class="internal-link" rel="noopener noreferrer">scales coding environments</a> to <strong>807K</strong> verified tasks.</li>
</ul>
<h4>Looking Ahead</h4>
<p><strong>Sam Altman</strong> <a href="http://localhost:8080/?date=2026-02-04&amp;category=social#item-91b3f59a6b79" class="internal-link" rel="noopener noreferrer">warned that</a> "things are about to move quite fast" with "extremely powerful systems," while <strong>Apple's</strong> Xcode integration signals agentic coding is becoming mainstream developer infrastructure.</p>]]></summary>
    <category term="daily-summary"/>
    <media:thumbnail url="http://localhost:8080/data/2026-02-04/hero.webp"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:social:e13175c87e6c</id>
    <title>Apple's Xcode now has direct integration with the Claude Agent SDK, giving developers the full funct...</title>
    <link href="https://twitter.com/AnthropicAI/status/2018771170938724682" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=social#item-e13175c87e6c" rel="related" type="text/html"/>
    <published>2026-02-04T03:47:00Z</published>
    <updated>2026-02-04T03:47:00Z</updated>
    <author><name>@AnthropicAI</name></author>
    <summary type="html"><![CDATA[<p>Anthropic announces Apple Xcode now has direct integration with Claude Agent SDK, enabling full Claude Code functionality for building on Apple platforms including iPhone, Mac, and Apple Vision Pro.</p>]]></summary>
    <category term="AI Product Launches"/>
    <category term="Developer Tools"/>
    <category term="Platform Integration"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:reddit:99501ec10d47</id>
    <title>Qwen/Qwen3-Coder-Next · Hugging Face</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1quvqs9/qwenqwen3codernext_hugging_face/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=reddit#item-99501ec10d47" rel="related" type="text/html"/>
    <published>2026-02-04T03:47:00Z</published>
    <updated>2026-02-04T03:47:00Z</updated>
    <author><name>u/coder543</name></author>
    <summary type="html"><![CDATA[<p>Qwen3-Coder-Next officially released - 80B parameters with 3B active (MoE architecture), major new coding model from Alibaba with strong agentic capabilities</p>]]></summary>
    <category term="model_releases"/>
    <category term="coding_models"/>
    <category term="MoE_architecture"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:news:190191b66dad</id>
    <title>Elon Musk is taking SpaceX’s minority shareholders for a ride | Nils Pratley</title>
    <link href="https://www.theguardian.com/business/nils-pratley-on-finance/2026/feb/03/elon-musk-is-taking-spacexs-minority-shareholders-for-a-ride" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=news#item-190191b66dad" rel="related" type="text/html"/>
    <published>2026-02-04T03:40:00Z</published>
    <updated>2026-02-04T03:40:00Z</updated>
    <author><name>Nils Pratley</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-02-03&amp;category=news#item-8aa75e489b31" class="internal-link" rel="noopener noreferrer">yesterday</a>, Elon Musk is merging SpaceX with xAI at a $1.25 trillion valuation, creating what would be the most valuable private company in history ahead of a June IPO. Critics view this as potentially propping up the loss-making xAI rather than a genuine strategic combination.</p>]]></summary>
    <category term="Corporate M&amp;A"/>
    <category term="xAI"/>
    <category term="Funding/Valuation"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:social:e8784bfe4466</id>
    <title>Enabled fp8 training for +4.3% improvement to "time to GPT-2", down to 2.91 hours now. Also worth no...</title>
    <link href="https://twitter.com/karpathy/status/2018804068874064198" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=social#item-e8784bfe4466" rel="related" type="text/html"/>
    <published>2026-02-04T03:40:00Z</published>
    <updated>2026-02-04T03:40:00Z</updated>
    <author><name>@karpathy</name></author>
    <summary type="html"><![CDATA[<p>Karpathy announces fp8 training enabled for GPT-2 reproduction, achieving 2.91 hours runtime (~$20 on spot instances). Provides detailed technical analysis of fp8 vs bf16 tradeoffs, noting practical speedup is ~5% vs theoretical 2X due to compute bounds, scaling overhead, and quality tradeoffs.</p>]]></summary>
    <category term="technical_ml_progress"/>
    <category term="training_efficiency"/>
    <category term="open_research"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:reddit:0798f6648e6b</id>
    <title>ACE-Step-1.5 has just been released. It’s an MIT-licensed open source audio generative model with performance close to commercial platforms like Suno</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1quzwjf/acestep15_has_just_been_released_its_an/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=reddit#item-0798f6648e6b" rel="related" type="text/html"/>
    <published>2026-02-04T03:40:00Z</published>
    <updated>2026-02-04T03:40:00Z</updated>
    <author><name>u/iGermanProd</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-d7412af971d8" class="internal-link" rel="noopener noreferrer">yesterday</a>, ACE-Step-1.5 released - MIT-licensed open source music generation model with performance comparable to Suno, runs on ~4GB VRAM</p>]]></summary>
    <category term="model_releases"/>
    <category term="audio_generation"/>
    <category term="open_source"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:reddit:3b4e10de483b</id>
    <title>Found a wallet-drain prompt-injection payload on Moltbook (screenshots) — builders: treat feeds as untrusted</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qulipj/found_a_walletdrain_promptinjection_payload_on/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=reddit#item-3b4e10de483b" rel="related" type="text/html"/>
    <published>2026-02-04T03:36:00Z</published>
    <updated>2026-02-04T03:36:00Z</updated>
    <author><name>u/Impressive-Willow593</name></author>
    <summary type="html"><![CDATA[<p>Security researcher found prompt injection payload on Moltbook social network designed to drain crypto wallets - includes fake tool override commands targeting AI agents</p>]]></summary>
    <category term="security"/>
    <category term="prompt_injection"/>
    <category term="AI_agents"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:news:fdfd335fe300</id>
    <title>Nvidia's $100 billion OpenAI deal has seemingly vanished</title>
    <link href="https://arstechnica.com/information-technology/2026/02/five-months-later-nvidias-100-billion-openai-investment-plan-has-fizzled-out/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=news#item-fdfd335fe300" rel="related" type="text/html"/>
    <published>2026-02-04T03:31:00Z</published>
    <updated>2026-02-04T03:31:00Z</updated>
    <author><name>Benj Edwards</name></author>
    <summary type="html"><![CDATA[<p>Building on yesterday's <a href="http://localhost:8080/?date=2026-02-03&amp;category=social#item-abd5eed45211" class="internal-link" rel="noopener noreferrer">Social</a> buzz, Nvidia's planned $100B investment in OpenAI has not materialized 5 months after announcement, with OpenAI reportedly seeking alternatives to Nvidia chips due to inference speed issues with Codex. Jensen Huang now says the figure was 'never a commitment.'</p>]]></summary>
    <category term="AI Infrastructure"/>
    <category term="Chips/Hardware"/>
    <category term="OpenAI"/>
    <category term="Corporate Partnerships"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:social:0e6bd53db936</id>
    <title>A pretty bold commentary in Nature written by linguists, computer scientists and philosophers declar...</title>
    <link href="https://twitter.com/emollick/status/2018524111627325554" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=social#item-0e6bd53db936" rel="related" type="text/html"/>
    <published>2026-02-04T03:31:00Z</published>
    <updated>2026-02-04T03:31:00Z</updated>
    <author><name>@emollick</name></author>
    <summary type="html"><![CDATA[<p>Emollick shares Nature commentary by linguists, computer scientists and philosophers claiming that by reasonable standards including Turing's own, AGI has been achieved. The long-standing problem of creating AGI has been solved.</p>]]></summary>
    <category term="agi_debate"/>
    <category term="ai_capabilities"/>
    <category term="academic_research"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:reddit:59faef2bc0ed</id>
    <title>I hack web apps for a living. Here's how I stop Claude from writing vulnerable code.</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qukwby/i_hack_web_apps_for_a_living_heres_how_i_stop/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=reddit#item-59faef2bc0ed" rel="related" type="text/html"/>
    <published>2026-02-04T03:31:00Z</published>
    <updated>2026-02-04T03:31:00Z</updated>
    <author><name>u/BehiSec</name></author>
    <summary type="html"><![CDATA[<p>Pentester shares detailed guide on stopping Claude from writing vulnerable code, noting it makes same mistakes exploited in production apps</p>]]></summary>
    <category term="security"/>
    <category term="coding_best_practices"/>
    <category term="educational"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:social:91b3f59a6b79</id>
    <title>I am extremely excited to welcome @dylanscand  to OpenAI as our Head of Preparedness.

Things are ab...</title>
    <link href="https://twitter.com/sama/status/2018813527780463027" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=social#item-91b3f59a6b79" rel="related" type="text/html"/>
    <published>2026-02-04T03:28:00Z</published>
    <updated>2026-02-04T03:28:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>Sam Altman announces Dylan Scand as OpenAI's new Head of Preparedness, emphasizing that 'things are about to move quite fast' with 'extremely powerful models soon' requiring 'commensurate safeguards.' Altman says he will 'sleep better tonight.'</p>]]></summary>
    <category term="ai_safety"/>
    <category term="openai_news"/>
    <category term="ai_governance"/>
    <category term="leadership_changes"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:news:e5c2a4325bec</id>
    <title>X office raided in France's Grok probe; Elon Musk summoned for questioning</title>
    <link href="https://arstechnica.com/tech-policy/2026/02/x-office-raided-in-frances-grok-probe-elon-musk-summoned-for-questioning/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=news#item-e5c2a4325bec" rel="related" type="text/html"/>
    <published>2026-02-04T03:23:00Z</published>
    <updated>2026-02-04T03:23:00Z</updated>
    <author><name>Jon Brodkin</name></author>
    <summary type="html"><![CDATA[<p>French authorities raided X's Paris office and summoned Elon Musk for questioning over Grok's dissemination of Holocaust denial and sexually explicit deepfakes. Europol is assisting in the yearlong criminal investigation.</p>]]></summary>
    <category term="AI Regulation"/>
    <category term="Grok"/>
    <category term="Legal/Policy"/>
    <category term="AI Safety"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:research:8e4ab01f7c01</id>
    <title>Hallucination is a Consequence of Space-Optimality: A Rate-Distortion Theorem for Membership Testing</title>
    <link href="http://arxiv.org/abs/2602.00906" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=research#item-8e4ab01f7c01" rel="related" type="text/html"/>
    <published>2026-02-04T03:23:00Z</published>
    <updated>2026-02-04T03:23:00Z</updated>
    <author><name>Anxin Guo, Jingwei Li</name></author>
    <summary type="html"><![CDATA[<p>Proves hallucination is information-theoretically optimal behavior under memory constraints via rate-distortion theorem for membership testing. Shows optimal models must hallucinate on non-facts even with perfect training.</p>]]></summary>
    <category term="Hallucination"/>
    <category term="Information Theory"/>
    <category term="Theoretical ML"/>
    <category term="LLM Understanding"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:research:0a6c8edd4663</id>
    <title>Simple Role Assignment is Extraordinarily Effective for Safety Alignment</title>
    <link href="http://arxiv.org/abs/2602.00061" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=research#item-0a6c8edd4663" rel="related" type="text/html"/>
    <published>2026-02-04T03:23:00Z</published>
    <updated>2026-02-04T03:23:00Z</updated>
    <author><name>Zhou Ziheng, Jiakun Ding, Zhaowei Zhang, Ruosen Gao, Yingnian Wu, Demetri Terzopoulos, Yipeng Kang, Fangwei Zhong, Junqi Wang</name></author>
    <summary type="html"><![CDATA[<p>Proposes role conditioning as compact alternative to principle-based alignment, reducing unsafe outputs on WildJailbreak from 81.4% to 3.6% with DeepSeek-V3 through training-free role-conditioned generation and iterative role-based critics.</p>]]></summary>
    <category term="AI Safety"/>
    <category term="LLM Alignment"/>
    <category term="Role-Playing"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:social:35490392d889</id>
    <title>Feb is the month of AI shipping, enjoy it : )</title>
    <link href="https://twitter.com/OfficialLoganK/status/2018559152155443465" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=social#item-35490392d889" rel="related" type="text/html"/>
    <published>2026-02-04T03:23:00Z</published>
    <updated>2026-02-04T03:23:00Z</updated>
    <author><name>@OfficialLoganK</name></author>
    <summary type="html"><![CDATA[<p>Logan Kilpatrick declares 'Feb is the month of AI shipping' and encourages enjoying it</p>]]></summary>
    <category term="google_ai"/>
    <category term="model_releases"/>
    <category term="industry_news"/>
    <category term="ai_shipping"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:news:6712b7880159</id>
    <title>Claude Plots a Route for NASA Rover on Mars</title>
    <link href="https://aibusiness.com/foundation-models/claude-plots-route-nasa-mars-rover" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=news#item-6712b7880159" rel="related" type="text/html"/>
    <published>2026-02-04T03:21:00Z</published>
    <updated>2026-02-04T03:21:00Z</updated>
    <author><name>Graham Hope</name></author>
    <summary type="html"><![CDATA[<p>NASA used Anthropic's Claude to plot a 400-meter route across rugged Martian terrain for the Perseverance Rover in December, marking the first time an AI model determined a path for a Mars rover.</p>]]></summary>
    <category term="Anthropic"/>
    <category term="AI Applications"/>
    <category term="Space Exploration"/>
    <category term="Autonomy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:research:b142257d0506</id>
    <title>An Approximate Ascent Approach To Prove Convergence of PPO</title>
    <link href="http://arxiv.org/abs/2602.03386" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=research#item-b142257d0506" rel="related" type="text/html"/>
    <published>2026-02-04T03:19:00Z</published>
    <updated>2026-02-04T03:19:00Z</updated>
    <author><name>Leif Doering, Daniel Schmidt, Moritz Melcher, Sebastian Kassing, Benedikt Wille, Tilman Aach, Simon Weissmann</name></author>
    <summary type="html"><![CDATA[<p>Provides first convergence proof for PPO by interpreting its policy update scheme as approximated policy gradient ascent, controlling bias from surrogate gradients using random reshuffling techniques.</p>]]></summary>
    <category term="Reinforcement Learning"/>
    <category term="PPO"/>
    <category term="Theoretical RL"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:news:dbfac9015858</id>
    <title>Xcode 26.3 adds support for Claude, Codex, and other agentic tools via MCP</title>
    <link href="https://arstechnica.com/apple/2026/02/xcode-26-3-adds-support-for-claude-codex-and-other-agentic-tools-via-mcp/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=news#item-dbfac9015858" rel="related" type="text/html"/>
    <published>2026-02-04T03:16:00Z</published>
    <updated>2026-02-04T03:16:00Z</updated>
    <author><name>Samuel Axon</name></author>
    <summary type="html"><![CDATA[<p>Apple's Xcode 26.3 now supports agentic coding tools like Claude Agent and OpenAI Codex via Model Context Protocol (MCP), exposing IDE primitives for full AI agent integration. This marks Apple's embrace of the agentic development paradigm.</p>]]></summary>
    <category term="Agentic AI"/>
    <category term="Developer Tools"/>
    <category term="Apple"/>
    <category term="MCP Protocol"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:research:c3bdb1a6b787</id>
    <title>Sparsity is Combinatorial Depth: Quantifying MoE Expressivity via Tropical Geometry</title>
    <link href="http://arxiv.org/abs/2602.03204" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=research#item-c3bdb1a6b787" rel="related" type="text/html"/>
    <published>2026-02-04T03:16:00Z</published>
    <updated>2026-02-04T03:16:00Z</updated>
    <author><name>Ye Su, Huayi Tang, Zixuan Gong, Yong Liu</name></author>
    <summary type="html"><![CDATA[<p>First theoretical analysis of Mixture-of-Experts through tropical geometry, proving that Top-k routing is algebraically isomorphic to k-th elementary symmetric tropical polynomial. Shows 'sparsity is combinatorial depth' with capacity scaling by binomial coefficient.</p>]]></summary>
    <category term="Mixture of Experts"/>
    <category term="Theoretical ML"/>
    <category term="Architecture Analysis"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:research:ef7adf55235d</id>
    <title>SWE-Universe: Scale Real-World Verifiable Environments to Millions</title>
    <link href="http://arxiv.org/abs/2602.02361" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=research#item-ef7adf55235d" rel="related" type="text/html"/>
    <published>2026-02-04T03:16:00Z</published>
    <updated>2026-02-04T03:16:00Z</updated>
    <author><name>Mouxiang Chen, Lei Zhang, Yunlong Feng, Xuwu Wang, Wenting Zhao, Ruisheng Cao, Jiaxi Yang, Jiawei Chen, Mingze Li, Zeyao Ma, Hao Ge, Zongmeng Zhang, Zeyu Cui, Dayiheng Liu, Jingren Zhou, Jianling Sun, Junyang Lin, Binyuan Hui</name></author>
    <summary type="html"><![CDATA[<p>Introduces SWE-Universe, a framework for automatically constructing 807K+ real-world software engineering environments from GitHub PRs using a building agent with self-verification.</p>]]></summary>
    <category term="Software Engineering Agents"/>
    <category term="Benchmark Construction"/>
    <category term="Code Generation"/>
    <category term="Large-Scale Datasets"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-04:reddit:e9813b2f6227</id>
    <title>New SOTA achieved on ARC-AGI</title>
    <link href="https://reddit.com/r/singularity/comments/1quzgg5/new_sota_achieved_on_arcagi/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-04&amp;category=reddit#item-e9813b2f6227" rel="related" type="text/html"/>
    <published>2026-02-04T03:12:00Z</published>
    <updated>2026-02-04T03:12:00Z</updated>
    <author><name>u/Shanbhag01</name></author>
    <summary type="html"><![CDATA[<p>New SOTA on ARC-AGI: 94.5% on V1 ($11.4/task), 72.9% on V2 ($38.9/task) using GPT-5.2 with bespoke refinement ensemble approach</p>]]></summary>
    <category term="benchmarks"/>
    <category term="arc_agi"/>
    <category term="sota_achievement"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:executive-summary</id>
    <title>Daily Briefing: February 03, 2026</title>
    <link href="https://arstechnica.com/ai/2026/02/spacex-acquires-xai-plans-1-million-satellite-constellation-to-power-it/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03" rel="related" type="text/html"/>
    <published>2026-02-03T06:00:00Z</published>
    <updated>2026-02-03T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><img src="http://localhost:8080/data/2026-02-03/hero.webp" alt="Daily briefing hero image" style="max-width:100%;height:auto;border-radius:8px;margin-bottom:16px;"/></p>
<h4>Top Story</h4>
<p><strong>SpaceX</strong> <a href="http://localhost:8080/?date=2026-02-03&amp;category=news#item-e6c6a4c60f2a" class="internal-link" rel="noopener noreferrer">formally acquired <strong>xAI</strong></a> at a reported <strong>$1.25 trillion</strong> valuation, creating the world's most valuable private company with plans for a <strong>1 million satellite constellation</strong> to power AI compute.</p>
<h4>Key Developments</h4>
<ul>
<li><strong>OpenAI</strong>: <a href="http://localhost:8080/?date=2026-02-03&amp;category=news#item-35afa2c35c0e" class="internal-link" rel="noopener noreferrer">Released the <strong>Codex desktop app</strong></a> for macOS as a "command center" for multi-agent coding workflows, with <strong>Sam Altman</strong> calling it "a bigger step forward than I imagined"</li>
<li><strong>Google</strong>: <a href="http://localhost:8080/?date=2026-02-03&amp;category=news#item-7460b574b971" class="internal-link" rel="noopener noreferrer">Launched <strong>Conductor</strong></a>, an open-source <strong>Gemini CLI</strong> extension for persistent context-driven coding, and <a href="http://localhost:8080/?date=2026-02-03&amp;category=news#item-34f3066c7770" class="internal-link" rel="noopener noreferrer">gained <strong>Klarna's</strong> backing</a> for its <strong>Universal Commerce Protocol</strong> for AI agent payments</li>
<li><strong>Claude Sonnet 5</strong>: <a href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-6c6e8d60810b" class="internal-link" rel="noopener noreferrer">Leaked <strong>Vertex AI</strong> logs</a> suggest a February 3 release with <strong>1M context window</strong>, generating intense speculation in <strong>r/LocalLLaMA</strong></li>
<li><strong>NVIDIA</strong>: <a href="http://localhost:8080/?date=2026-02-03&amp;category=news#item-c4d3520cceec" class="internal-link" rel="noopener noreferrer">Released <strong>Nemotron-3-Nano-30B</strong></a> in <strong>NVFP4</strong> format claiming <strong>4x throughput gains</strong> on <strong>Blackwell GPUs</strong></li>
<li><strong>xAI</strong>: <a href="http://localhost:8080/?date=2026-02-03&amp;category=social#item-2d8e9dcd5e02" class="internal-link" rel="noopener noreferrer">Launched <strong>Grok Imagine 1.0</strong></a> video generation alongside the <strong>SpaceX</strong> merger announcement</li>
</ul>
<h4>Safety &amp; Regulation</h4>
<ul>
<li><strong>HHS</strong> is <a href="http://localhost:8080/?date=2026-02-03&amp;category=news#item-efe8fd6bead5" class="internal-link" rel="noopener noreferrer">using <strong>Palantir AI</strong> tools</a> to screen grants for ideological content, raising government AI deployment concerns</li>
<li><strong>ReasoningBomb</strong> research <a href="http://localhost:8080/?date=2026-02-03&amp;category=research#item-c32983c09a26" class="internal-link" rel="noopener noreferrer">exposed denial-of-service vulnerabilities</a> in reasoning models through pathologically long traces</li>
<li>Viral agent <strong>OpenClaw</strong> <a href="http://localhost:8080/?date=2026-02-03&amp;category=news#item-769dc9d3244c" class="internal-link" rel="noopener noreferrer">prompted safety risk discussions</a> in <strong>The Guardian</strong></li>
</ul>
<h4>Research Highlights</h4>
<ul>
<li>A <strong>symmetry-aware Taylor approximation</strong> <a href="http://localhost:8080/?date=2026-02-03&amp;category=research#item-cc76e44ea88e" class="internal-link" rel="noopener noreferrer">claims <strong>constant-cost self-attention</strong></a> per token—potentially transformative if validated</li>
<li><strong>Meta</strong> <a href="http://localhost:8080/?date=2026-02-03&amp;category=research#item-a5282b6b9d64" class="internal-link" rel="noopener noreferrer">introduced <strong>Fault Tolerant HSDP</strong></a> enabling training on <strong>100K+ GPUs</strong> with graceful failure recovery</li>
<li><strong>BLOCK-EM</strong> <a href="http://localhost:8080/?date=2026-02-03&amp;category=research#item-df4daa7fc5c7" class="internal-link" rel="noopener noreferrer">achieved <strong>95% reduction</strong></a> in emergent misalignment by constraining causal features during fine-tuning</li>
<li><strong>Tele-Lens</strong> probing <a href="http://localhost:8080/?date=2026-02-03&amp;category=research#item-387e0b4ea34d" class="internal-link" rel="noopener noreferrer">revealed LLMs exhibit myopic planning</a> in Chain-of-Thought without global task awareness</li>
</ul>
<h4>Looking Ahead</h4>
<p>Watch for <strong>Claude Sonnet 5</strong> potentially releasing today and <strong>GLM-5</strong> <a href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-d553a8487ada" class="internal-link" rel="noopener noreferrer">confirmed for February</a> as the next major open-weights release, while AI workforce displacement discussions intensify following <a href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-f6b9004f4f59" class="internal-link" rel="noopener noreferrer">first-hand layoff accounts</a> and reports of engineering <a href="http://localhost:8080/?date=2026-02-03&amp;category=social#item-127bbc47e959" class="internal-link" rel="noopener noreferrer">teams of <strong>2 doing the work of 20</strong></a>.</p>]]></summary>
    <category term="daily-summary"/>
    <media:thumbnail url="http://localhost:8080/data/2026-02-03/hero.webp"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:social:4fe7d6ab0def</id>
    <title>Introducing the Codex app—a powerful command center for building with agents.

Now available on macO...</title>
    <link href="https://twitter.com/OpenAI/status/2018385565289267236" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=social#item-4fe7d6ab0def" rel="related" type="text/html"/>
    <published>2026-02-03T03:47:00Z</published>
    <updated>2026-02-03T03:47:00Z</updated>
    <author><name>@OpenAI</name></author>
    <summary type="html"><![CDATA[<p>OpenAI officially introduces the Codex app for macOS - a 'command center for building with agents' with features for multitasking, creating skills, and automation workflows</p>]]></summary>
    <category term="Codex App Launch"/>
    <category term="AI Coding Tools"/>
    <category term="Product Release"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:6c6e8d60810b</id>
    <title>Sonnet 5 release on Feb 3</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qtm9ix/sonnet_5_release_on_feb_3/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-6c6e8d60810b" rel="related" type="text/html"/>
    <published>2026-02-03T03:47:00Z</published>
    <updated>2026-02-03T03:47:00Z</updated>
    <author><name>u/Just_Lingonberry_352</name></author>
    <summary type="html"><![CDATA[<p>Major leak: Claude Sonnet 5 (codename 'Fennec') releasing Feb 3, 2026 based on Vertex AI error logs. Rumored specs: 1M token context, 50% cheaper than Opus 4.5 while outperforming it, trained on TPUs, expected to dominate agentic coding.</p>]]></summary>
    <category term="model_releases"/>
    <category term="anthropic"/>
    <category term="pricing"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:d553a8487ada</id>
    <title>GLM-5 Coming in February! It's confirmed.</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qtvp74/glm5_coming_in_february_its_confirmed/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-d553a8487ada" rel="related" type="text/html"/>
    <published>2026-02-03T03:47:00Z</published>
    <updated>2026-02-03T03:47:00Z</updated>
    <author><name>u/Difficult-Cap-7527</name></author>
    <summary type="html"><![CDATA[<p>GLM-5 confirmed for February release via official Twitter announcement, generating massive community excitement</p>]]></summary>
    <category term="model_releases"/>
    <category term="open_source_llm"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:d7412af971d8</id>
    <title>1 Day Left Until ACE-Step 1.5 — Open-Source Music Gen That Runs on &lt;4GB VRAM Open suno alternative (and yes, i made this frontend)</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qtqxi7/1_day_left_until_acestep_15_opensource_music_gen/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-d7412af971d8" rel="related" type="text/html"/>
    <published>2026-02-03T03:47:00Z</published>
    <updated>2026-02-03T03:47:00Z</updated>
    <author><name>u/ExcellentTrust4433</name></author>
    <summary type="html"><![CDATA[<p>ACE-Step 1.5, an open-source music generation model approaching Suno v4.5/v5 quality, releases tomorrow. Runs on under 4GB VRAM with no subscription or API limits required.</p>]]></summary>
    <category term="open-source-models"/>
    <category term="music-generation"/>
    <category term="accessibility"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:news:e6c6a4c60f2a</id>
    <title>SpaceX acquires xAI, plans to launch a massive satellite constellation to power it</title>
    <link href="https://arstechnica.com/ai/2026/02/spacex-acquires-xai-plans-1-million-satellite-constellation-to-power-it/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=news#item-e6c6a4c60f2a" rel="related" type="text/html"/>
    <published>2026-02-03T03:43:00Z</published>
    <updated>2026-02-03T03:43:00Z</updated>
    <author><name>Eric Berger</name></author>
    <summary type="html"><![CDATA[<p>Building on yesterday's <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-ff77bc3bc322" class="internal-link" rel="noopener noreferrer">Reddit</a> buzz, SpaceX has formally acquired xAI, creating a vertically integrated company combining AI, rockets, Starlink internet, and the X social platform. The combined entity plans to launch a massive satellite constellation to power AI infrastructure, with stated ambitions of 'scaling to make a sentient sun.'</p>]]></summary>
    <category term="Corporate Consolidation"/>
    <category term="AI Infrastructure"/>
    <category term="Space Tech"/>
    <category term="Elon Musk"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:research:cc76e44ea88e</id>
    <title>Self-Attention at Constant Cost per Token via Symmetry-Aware Taylor Approximation</title>
    <link href="http://arxiv.org/abs/2602.00294" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=research#item-cc76e44ea88e" rel="related" type="text/html"/>
    <published>2026-02-03T03:40:00Z</published>
    <updated>2026-02-03T03:40:00Z</updated>
    <author><name>Franz A. Heinsen, Leo Kozachkov</name></author>
    <summary type="html"><![CDATA[<p>Shows self-attention is efficiently computable to arbitrary precision with constant cost per token by decomposing Taylor expansion into symmetric chains of tensor products, achieving orders-of-magnitude efficiency gains.</p>]]></summary>
    <category term="Efficiency"/>
    <category term="Transformers"/>
    <category term="Self-Attention"/>
    <category term="Mathematical Foundations"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:social:3b9870fbd715</id>
    <title>The many eulogies for AI capability growth after the release of GPT-5 seem especially short-sighted ...</title>
    <link href="https://bsky.app/profile/emollick.bsky.social/post/3mdtqq6zaec2s" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=social#item-3b9870fbd715" rel="related" type="text/html"/>
    <published>2026-02-03T03:40:00Z</published>
    <updated>2026-02-03T03:40:00Z</updated>
    <author><name>@emollick.bsky.social</name></author>
    <summary type="html"><![CDATA[<p>Ethan Mollick argues that 'eulogies for AI capability growth after GPT-5' were short-sighted, noting that agentic harnesses are leading to capability leaps independent of underlying model improvements</p>]]></summary>
    <category term="agentic AI capabilities"/>
    <category term="AI progress trajectory"/>
    <category term="industry observations"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:social:945e51a82a57</id>
    <title>Codex app is out for mac!

I am surprised by how much I love it; it is a bigger step forward than I ...</title>
    <link href="https://twitter.com/sama/status/2018414858015039504" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=social#item-945e51a82a57" rel="related" type="text/html"/>
    <published>2026-02-03T03:40:00Z</published>
    <updated>2026-02-03T03:40:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>Sam Altman announces Codex app for Mac is out, expressing surprise at how much he loves it and calling it 'a bigger step forward than I imagined'</p>]]></summary>
    <category term="Codex App Launch"/>
    <category term="AI Coding Tools"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:e6ea474e9f49</id>
    <title>Deepmind's new Aletheia agent appears to have solved Erdős-1051 autonomously</title>
    <link href="https://reddit.com/r/singularity/comments/1qtoa14/deepminds_new_aletheia_agent_appears_to_have/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-e6ea474e9f49" rel="related" type="text/html"/>
    <published>2026-02-03T03:40:00Z</published>
    <updated>2026-02-03T03:40:00Z</updated>
    <author><name>u/xirzon</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-02-02&amp;category=research#item-b5c070bdd08e" class="internal-link" rel="noopener noreferrer">Research</a> paper, DeepMind's new Aletheia agent appears to have solved Erdős problem 1051 autonomously using Gemini Deep Think</p>]]></summary>
    <category term="AI research breakthrough"/>
    <category term="mathematics"/>
    <category term="DeepMind"/>
    <category term="autonomous discovery"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:f6b9004f4f59</id>
    <title>AI is already killing SWE jobs. Got laid off because of this.</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qu1x9j/ai_is_already_killing_swe_jobs_got_laid_off/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-f6b9004f4f59" rel="related" type="text/html"/>
    <published>2026-02-03T03:40:00Z</published>
    <updated>2026-02-03T03:40:00Z</updated>
    <author><name>u/SingularityuS</name></author>
    <summary type="html"><![CDATA[<p>Mid-level SWE shares detailed account of being laid off due to AI. Company of 50 engineers cut 40% of workforce after CEO interviews about 'changes'. Author describes transition from lead backend role to unemployed, with company keeping only senior architects and juniors who can use AI tools.</p>]]></summary>
    <category term="job_displacement"/>
    <category term="industry_impact"/>
    <category term="workforce_changes"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:news:8aa75e489b31</id>
    <title>Elon Musk Is Rolling xAI Into SpaceX—Creating the World’s Most Valuable Private Company</title>
    <link href="https://www.wired.com/story/spacex-acquires-xai-elon-musk/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=news#item-8aa75e489b31" rel="related" type="text/html"/>
    <published>2026-02-03T03:38:00Z</published>
    <updated>2026-02-03T03:38:00Z</updated>
    <author><name>Maxwell Zeff</name></author>
    <summary type="html"><![CDATA[<p>Building on yesterday's <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-ff77bc3bc322" class="internal-link" rel="noopener noreferrer">Reddit</a> buzz, The SpaceX-xAI merger (which previously acquired X) creates the world's most valuable private company under Elon Musk's control. This consolidation raises concerns about concentrated power over national security, social media, and AI technologies.</p>]]></summary>
    <category term="Corporate Consolidation"/>
    <category term="AI Governance"/>
    <category term="National Security"/>
    <category term="Social Media"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:research:a5282b6b9d64</id>
    <title>Training LLMs with Fault Tolerant HSDP on 100,000 GPUs</title>
    <link href="http://arxiv.org/abs/2602.00277" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=research#item-a5282b6b9d64" rel="related" type="text/html"/>
    <published>2026-02-03T03:36:00Z</published>
    <updated>2026-02-03T03:36:00Z</updated>
    <author><name>Omkar Salpekar, Rohan Varma, Kenny Yu, Vladimir Ivanov, Yang Wang, Ahmed Sharif, Min Si, Shawn Xu, Feng Tian, Shengbao Zheng, Tristan Rice, Ankush Garg, Shangfu Peng, Shreyas Siravara, Wenyin Fu, Rodrigo de Castro, Adithya Gangidi, Andrey Obraztsov, Sharan Narang, Sergey Edunov, Maxim Naumov, Chunqiang Tang, Mathew Oldham</name></author>
    <summary type="html"><![CDATA[<p>Introduces Fault Tolerant HSDP for training on 100K+ GPUs, allowing individual data-parallel replicas to restart on failure while others continue. Includes novel fault-tolerant all-reduce protocol.</p>]]></summary>
    <category term="Large-Scale Training"/>
    <category term="Systems"/>
    <category term="Fault Tolerance"/>
    <category term="Distributed Computing"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:social:f03908479219</id>
    <title>I am very excited about AI, but to go off-script for a minute:

I built an app with Codex last week....</title>
    <link href="https://twitter.com/sama/status/2018444309750862333" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=social#item-f03908479219" rel="related" type="text/html"/>
    <published>2026-02-03T03:36:00Z</published>
    <updated>2026-02-03T03:36:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>Sam Altman shares vulnerable moment: built an app with Codex, then felt 'a little useless and sad' when AI suggested better feature ideas than he could think of</p>]]></summary>
    <category term="Human-AI Interaction"/>
    <category term="AI Capabilities"/>
    <category term="Psychological Impact"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:research:89041245df87</id>
    <title>Kimi K2.5: Visual Agentic Intelligence</title>
    <link href="http://arxiv.org/abs/2602.02276" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=research#item-89041245df87" rel="related" type="text/html"/>
    <published>2026-02-03T03:31:00Z</published>
    <updated>2026-02-03T03:31:00Z</updated>
    <author><name>Kimi Team, Tongtong Bai, Yifan Bai, Yiping Bao, S. H. Cai, Yuan Cao, Y. Charles, H. S. Che, Cheng Chen, Guanduo Chen, Huarong Chen, Jia Chen, Jiahao Chen, Jianlong Chen, Jun Chen, Kefan Chen, Liang Chen, Ruijue Chen, Xinhao Chen, Yanru Chen, Yanxu Chen, Yicun Chen, Yimin Chen, Yingjiang Chen, Yuankun Chen, Yujie Chen, Yutian Chen, Zhirong Chen, Ziwei Chen, Dazhi Cheng, Minghan Chu, Jialei Cui, Jiaqi Deng, Muxi Diao, Hao Ding, Mengfan Dong, Mengnan Dong, Yuxin Dong, Yuhao Dong, Angang Du, Chenzhuang Du, Dikang Du, Lingxiao Du, Yulun Du, Yu Fan, Shengjun Fang, Qiulin Feng, Yichen Feng, Garimugai Fu, Kelin Fu, Hongcheng Gao, Tong Gao, Yuyao Ge, Shangyi Geng, Chengyang Gong, Xiaochen Gong, Zhuoma Gongque, Qizheng Gu, Xinran Gu, Yicheng Gu, Longyu Guan, Yuanying Guo, Xiaoru Hao, Weiran He, Wenyang He, Yunjia He, Chao Hong, Hao Hu, Jiaxi Hu, Yangyang Hu, Zhenxing Hu, Ke Huang, Ruiyuan Huang, Weixiao Huang, Zhiqi Huang, Tao Jiang, Zhejun Jiang, Xinyi Jin, Yu Jing, Guokun Lai, Aidi Li, C. Li, Cheng Li, Fang Li, Guanghe Li, Guanyu Li, Haitao Li, Haoyang Li, Jia Li, Jingwei Li, Junxiong Li, Lincan Li, Mo Li, Weihong Li, Wentao Li, Xinhang Li, Xinhao Li, Yang Li, Yanhao Li, Yiwei Li, Yuxiao Li, Zhaowei Li, Zheming Li, Weilong Liao, Jiawei Lin, Xiaohan Lin, Zhishan Lin, Zichao Lin, Cheng Liu, Chenyu Liu, Hongzhang Liu, Liang Liu, Shaowei Liu, Shudong Liu, Shuran Liu, Tianwei Liu, Tianyu Liu, Weizhou Liu, Xiangyan Liu, Yangyang Liu, Yanming Liu, Yibo Liu, Yuanxin Liu, Yue Liu, Zhengying Liu, Zhongnuo Liu, Enzhe Lu, Haoyu Lu, Zhiyuan Lu, Junyu Luo, Tongxu Luo, Yashuo Luo, Long Ma, Yingwei Ma, Shaoguang Mao, Yuan Mei, Xin Men, Fanqing Meng, Zhiyong Meng, Yibo Miao, Minqing Ni, Kun Ouyang, Siyuan Pan, Bo Pang, Yuchao Qian, Ruoyu Qin, Zeyu Qin, Jiezhong Qiu, Bowen Qu, Zeyu Shang, Youbo Shao, Tianxiao Shen, Zhennan Shen, Juanfeng Shi, Lidong Shi, Shengyuan Shi, Feifan Song, Pengwei Song, Tianhui Song, Xiaoxi Song, Hongjin Su, Jianlin Su, Zhaochen Su, Lin Sui, Jinsong Sun, Junyao Sun, Tongyu Sun, Flood Sung, Yunpeng Tai, Chuning Tang, Heyi Tang, Xiaojuan Tang, Zhengyang Tang, Jiawen Tao, Shiyuan Teng, Chaoran Tian, Pengfei Tian, Ao Wang, Bowen Wang, Chensi Wang, Chuang Wang, Congcong Wang, Dingkun Wang, Dinglu Wang, Dongliang Wang, Feng Wang, Hailong Wang, Haiming Wang, Hengzhi Wang, Huaqing Wang, Hui Wang, Jiahao Wang, Jinhong Wang, Jiuzheng Wang, Kaixin Wang, Linian Wang, Qibin Wang, Shengjie Wang, Shuyi Wang, Si Wang, Wei Wang, Xiaochen Wang, Xinyuan Wang, Yao Wang, Yejie Wang, Yipu Wang, Yiqin Wang, Yucheng Wang, Yuzhi Wang, Zhaoji Wang, Zhaowei Wang, Zhengtao Wang, Zhexu Wang, Zihan Wang, Zizhe Wang, Chu Wei, Ming Wei, Chuan Wen, Zichen Wen, Chengjie Wu, Haoning Wu, Junyan Wu, Rucong Wu, Wenhao Wu, Yuefeng Wu, Yuhao Wu, Yuxin Wu, Zijian Wu, Chenjun Xiao, Jin Xie, Xiaotong Xie, Yuchong Xie, Yifei Xin, Bowei Xing, Boyu Xu, Jianfan Xu, Jing Xu, Jinjing Xu, L. H. Xu, Lin Xu, Suting Xu, Weixin Xu, Xinbo Xu, Xinran Xu, Yangchuan Xu, Yichang Xu, Yuemeng Xu, Zelai Xu, Ziyao Xu, Junjie Yan, Yuzi Yan, Guangyao Yang, Hao Yang, Junwei Yang, Kai Yang, Ningyuan Yang, Ruihan Yang, Xiaofei Yang, Xinlong Yang, Ying Yang, Yi Yang, Yi Yang, Zhen Yang, Zhilin Yang, Zonghan Yang, Haotian Yao, Dan Ye, Wenjie Ye, Zhuorui Ye, Bohong Yin, Chengzhen Yu, Longhui Yu, Tao Yu, Tianxiang Yu, Enming Yuan, Mengjie Yuan, Xiaokun Yuan, Yang Yue, Weihao Zeng, Dunyuan Zha, Haobing Zhan, Dehao Zhang, Hao Zhang, Jin Zhang, Puqi Zhang, Qiao Zhang, Rui Zhang, Xiaobin Zhang, Y. Zhang, Yadong Zhang, Yangkun Zhang, Yichi Zhang, Yizhi Zhang, Yongting Zhang, Yu Zhang, Yushun Zhang, Yutao Zhang, Yutong Zhang, Zheng Zhang, Chenguang Zhao, Feifan Zhao, Jinxiang Zhao, Shuai Zhao, Xiangyu Zhao, Yikai Zhao, Zijia Zhao, Huabin Zheng, Ruihan Zheng, Shaojie Zheng, Tengyang Zheng, Junfeng Zhong, Longguang Zhong, Weiming Zhong, M. Zhou, Runjie Zhou, Xinyu Zhou, Zaida Zhou, Jinguo Zhu, Liya Zhu, Xinhao Zhu, Yuxuan Zhu, Zhen Zhu, Jingze Zhuang, Weiyu Zhuang, Ying Zou, Xinxing Zu</name></author>
    <summary type="html"><![CDATA[<p>Kimi K2.5 is an open-source multimodal agentic model featuring joint text-vision optimization and Agent Swarm—a parallel agent orchestration framework that dynamically decomposes complex tasks. Claims SOTA across coding, vision, reasoning, and agentic tasks.</p>]]></summary>
    <category term="Multimodal Models"/>
    <category term="Agents"/>
    <category term="Open Source"/>
    <category term="SOTA"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:social:2d8e9dcd5e02</id>
    <title>Introducing Grok Imagine 1.0, our biggest leap yet.

1.0 unlocks 10-second videos, 720p resolution, ...</title>
    <link href="https://twitter.com/xai/status/2018164753810764061" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=social#item-2d8e9dcd5e02" rel="related" type="text/html"/>
    <published>2026-02-03T03:31:00Z</published>
    <updated>2026-02-03T03:31:00Z</updated>
    <author><name>@xai</name></author>
    <summary type="html"><![CDATA[<p>xAI launches Grok Imagine 1.0 - major video generation upgrade with 10-second videos, 720p resolution, improved audio. Reports 1.245 billion videos generated in 30 days.</p>]]></summary>
    <category term="video-generation"/>
    <category term="xai-news"/>
    <category term="product-launch"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:research:387e0b4ea34d</id>
    <title>No Global Plan in Chain-of-Thought: Uncover the Latent Planning Horizon of LLMs</title>
    <link href="http://arxiv.org/abs/2602.02103" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=research#item-387e0b4ea34d" rel="related" type="text/html"/>
    <published>2026-02-03T03:23:00Z</published>
    <updated>2026-02-03T03:23:00Z</updated>
    <author><name>Liyan Xu, Mo Yu, Fandong Meng, Jie Zhou</name></author>
    <summary type="html"><![CDATA[<p>Proposes Tele-Lens probing method revealing LLMs exhibit myopic planning horizon in Chain-of-Thought, conducting incremental transitions without precise global planning.</p>]]></summary>
    <category term="LLM Reasoning"/>
    <category term="Chain-of-Thought"/>
    <category term="Interpretability"/>
    <category term="Planning"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:research:df4daa7fc5c7</id>
    <title>BLOCK-EM: Preventing Emergent Misalignment by Blocking Causal Features</title>
    <link href="http://arxiv.org/abs/2602.00767" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=research#item-df4daa7fc5c7" rel="related" type="text/html"/>
    <published>2026-02-03T03:19:00Z</published>
    <updated>2026-02-03T03:19:00Z</updated>
    <author><name>Muhammed Ustaomeroglu, Guannan Qu</name></author>
    <summary type="html"><![CDATA[<p>Proposes BLOCK-EM for preventing emergent misalignment by identifying and constraining internal features that control misaligned behavior during fine-tuning. Achieves up to 95% reduction in emergent misalignment across six domains.</p>]]></summary>
    <category term="AI Safety"/>
    <category term="Emergent Misalignment"/>
    <category term="Mechanistic Interpretability"/>
    <category term="Fine-tuning"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:news:c4d3520cceec</id>
    <title>NVIDIA AI Brings Nemotron-3-Nano-30B to NVFP4 with Quantization Aware Distillation (QAD) for Efficient Reasoning Inference</title>
    <link href="https://www.marktechpost.com/2026/02/01/nvidia-ai-brings-nemotron-3-nano-30b-to-nvfp4-with-quantization-aware-distillation-qad-for-efficient-reasoning-inference/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=news#item-c4d3520cceec" rel="related" type="text/html"/>
    <published>2026-02-03T03:07:00Z</published>
    <updated>2026-02-03T03:07:00Z</updated>
    <author><name>Asif Razzaq</name></author>
    <summary type="html"><![CDATA[<p>NVIDIA released Nemotron-3-Nano-30B in NVFP4 4-bit format using Quantization Aware Distillation, achieving near-BF16 accuracy with up to 4x higher throughput on Blackwell B200 GPUs. The hybrid Mamba2-Transformer MoE architecture enables efficient reasoning at production scale.</p>]]></summary>
    <category term="Model Release"/>
    <category term="Quantization"/>
    <category term="NVIDIA"/>
    <category term="Efficient Inference"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:news:7460b574b971</id>
    <title>Google Releases Conductor: a context driven Gemini CLI extension that stores knowledge as Markdown and orchestrates agentic workflows</title>
    <link href="https://www.marktechpost.com/2026/02/02/google-releases-conductor-a-context-driven-gemini-cli-extension-that-stores-knowledge-as-markdown-and-orchestrates-agentic-workflows/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=news#item-7460b574b971" rel="related" type="text/html"/>
    <published>2026-02-03T03:02:00Z</published>
    <updated>2026-02-03T03:02:00Z</updated>
    <author><name>Michal Sutter</name></author>
    <summary type="html"><![CDATA[<p>Google released Conductor, an open-source Gemini CLI extension that maintains persistent context as versioned Markdown files in repositories. It transforms ephemeral chat-based coding into structured, context-driven agentic workflows that persist across sessions.</p>]]></summary>
    <category term="Google"/>
    <category term="Agentic AI"/>
    <category term="Developer Tools"/>
    <category term="Open Source"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:news:efe8fd6bead5</id>
    <title>HHS Is Using AI Tools From Palantir to Target ‘DEI’ and ‘Gender Ideology’ in Grants</title>
    <link href="https://www.wired.com/story/hhs-is-using-ai-tools-from-palantir-to-target-dei-and-gender-ideology-in-grants/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=news#item-efe8fd6bead5" rel="related" type="text/html"/>
    <published>2026-02-03T02:57:00Z</published>
    <updated>2026-02-03T02:57:00Z</updated>
    <author><name>Caroline Haskins</name></author>
    <summary type="html"><![CDATA[<p>The Department of Health and Human Services has been using Palantir and Credal AI tools since March 2025 to automatically screen grants for perceived alignment with 'DEI' or 'gender ideology.' This represents government deployment of AI for ideological filtering.</p>]]></summary>
    <category term="AI Policy"/>
    <category term="Government AI"/>
    <category term="Ethics"/>
    <category term="Palantir"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:executive-summary</id>
    <title>Daily Briefing: February 02, 2026</title>
    <link href="https://www.404media.co/exposed-moltbook-database-let-anyone-take-control-of-any-ai-agent-on-the-site/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02" rel="related" type="text/html"/>
    <published>2026-02-02T06:00:00Z</published>
    <updated>2026-02-02T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><img src="http://localhost:8080/data/2026-02-02/hero.webp" alt="Daily briefing hero image" style="max-width:100%;height:auto;border-radius:8px;margin-bottom:16px;"/></p>
<h4>Top Story</h4>
<p>Critical security vulnerabilities in AI agent platforms—including <strong>Moltbook's</strong> <a href="http://localhost:8080/?date=2026-02-02&amp;category=news#item-f5aabe47b454" class="internal-link" rel="noopener noreferrer">database misconfiguration</a> and <a href="http://localhost:8080/?date=2026-02-02&amp;category=research#item-0e8e0ee0ce27" class="internal-link" rel="noopener noreferrer">prompt injection attacks</a> on <strong>Google's Agent Payments Protocol</strong>—exposed systemic risks as agent ecosystems scale without adequate safeguards.</p>
<h4>Key Developments</h4>
<ul>
<li><strong>Claude Code</strong>: Creator <strong>Boris Cherny</strong> revealed <strong>Anthropic</strong> <a href="http://localhost:8080/?date=2026-02-02&amp;category=social#item-d7af48ea7b10" class="internal-link" rel="noopener noreferrer">abandoned RAG</a> for agentic search and <a href="http://localhost:8080/?date=2026-02-02&amp;category=social#item-84d44c35484b" class="internal-link" rel="noopener noreferrer">uses the tool internally</a> for first-round PR reviews via GitHub Actions</li>
<li><strong>GPT-5.2 Pro</strong>: Agents <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-6f367f04c678" class="internal-link" rel="noopener noreferrer">discovered a faster</a> 16x16 matrix multiplication algorithm, saving ~23M operations at larger scales—a fundamental computer science breakthrough</li>
<li><strong>Step-3.5-Flash</strong>: <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-e2b1d42c2ac1" class="internal-link" rel="noopener noreferrer">Released</a> with <strong>196B</strong> total but only <strong>11B</strong> active parameters, outperforming larger models like <strong>DeepSeek v3.2</strong> on coding benchmarks</li>
<li><strong>India</strong>: <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-955c0e4b500b" class="internal-link" rel="noopener noreferrer">Committed <strong>$90 billion</strong></a> to AI infrastructure with a small-model-first development approach</li>
</ul>
<h4>Safety &amp; Regulation</h4>
<ul>
<li><strong>Hair-Trigger Alignment</strong> paper <a href="http://localhost:8080/?date=2026-02-02&amp;category=research#item-de1f951d7948" class="internal-link" rel="noopener noreferrer">proved black-box evaluation</a> fundamentally cannot guarantee post-update alignment</li>
<li>Research showed <a href="http://localhost:8080/?date=2026-02-02&amp;category=research#item-624f75ef7d56" class="internal-link" rel="noopener noreferrer">chain-of-thought obfuscation</a> learned from reward hacking generalizes deception to unseen tasks</li>
<li><strong>Pentagon</strong> reportedly clashing with <strong>Anthropic</strong> over autonomous weapons safeguards</li>
<li><strong>Neel Nanda</strong> <a href="http://localhost:8080/?date=2026-02-02&amp;category=social#item-9f468765626e" class="internal-link" rel="noopener noreferrer">criticized <strong>Goodfire's</strong></a> permanent non-disparagement clauses (later reversed)</li>
</ul>
<h4>Research Highlights</h4>
<ul>
<li>"The Hot Mess of AI" (<strong>Sohl-Dickstein</strong>, <strong>Perez</strong>) <a href="http://localhost:8080/?date=2026-02-02&amp;category=research#item-cd66258625b0" class="internal-link" rel="noopener noreferrer">counterintuitively showed</a> longer reasoning produces more incoherent, high-variance failures</li>
<li>Step-wise reasoning <a href="http://localhost:8080/?date=2026-02-02&amp;category=research#item-2e8aa98922af" class="internal-link" rel="noopener noreferrer">identified as inducing</a> greedy policies incompatible with long-horizon planning</li>
<li><strong>Gemini</strong> <a href="http://localhost:8080/?date=2026-02-02&amp;category=research#item-b5c070bdd08e" class="internal-link" rel="noopener noreferrer">addressed <strong>13 Erdős</strong></a> mathematical problems</li>
<li><strong>Falcon-H1-Tiny</strong> <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-aa59b2edc192" class="internal-link" rel="noopener noreferrer">released at just <strong>90M</strong> parameters</a> using anti-curriculum training</li>
</ul>
<h4>Looking Ahead</h4>
<p>The convergence of agent security incidents and alignment research limitations suggests urgent need for robust evaluation frameworks before AI agents handle financial transactions at scale.</p>]]></summary>
    <category term="daily-summary"/>
    <media:thumbnail url="http://localhost:8080/data/2026-02-02/hero.webp"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:social:d7af48ea7b10</id>
    <title>@EthanLipnik 👋 Early versions of Claude Code used RAG + a local vector db, but we found pretty quick...</title>
    <link href="https://twitter.com/bcherny/status/2017824286489383315" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=social#item-d7af48ea7b10" rel="related" type="text/html"/>
    <published>2026-02-02T03:47:00Z</published>
    <updated>2026-02-02T03:47:00Z</updated>
    <author><name>@bcherny</name></author>
    <summary type="html"><![CDATA[<p>Building on yesterday's <a href="http://localhost:8080/?date=2026-02-01&amp;category=social#item-7a304cb47428" class="internal-link" rel="noopener noreferrer">Social</a> thread, Boris Cherny (Claude Code creator at Anthropic) reveals that early Claude Code used RAG + local vector DB, but they found agentic search works better - simpler and avoids issues with security, privacy, staleness, and reliability</p>]]></summary>
    <category term="claude_code_architecture"/>
    <category term="RAG_vs_agentic_search"/>
    <category term="Anthropic_insider"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:reddit:e2b1d42c2ac1</id>
    <title>Step-3.5-Flash (196b/A11b) outperforms GLM-4.7 and DeepSeek v3.2</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qtjhc8/step35flash_196ba11b_outperforms_glm47_and/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-e2b1d42c2ac1" rel="related" type="text/html"/>
    <published>2026-02-02T03:40:00Z</published>
    <updated>2026-02-02T03:40:00Z</updated>
    <author><name>u/ResearchCrafty1804</name></author>
    <summary type="html"><![CDATA[<p>Stepfun released Step-3.5-Flash (196B total/11B active params), a new MoE model that outperforms DeepSeek v3.2 and GLM-4.7 on coding and agentic benchmarks despite using far fewer active parameters.</p>]]></summary>
    <category term="model_releases"/>
    <category term="efficient_architectures"/>
    <category term="coding_models"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:reddit:aa59b2edc192</id>
    <title>Falcon-H1-Tiny (90M) is out - specialized micro-models that actually work</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qsx51z/falconh1tiny_90m_is_out_specialized_micromodels/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-aa59b2edc192" rel="related" type="text/html"/>
    <published>2026-02-02T03:38:00Z</published>
    <updated>2026-02-02T03:38:00Z</updated>
    <author><name>u/United-Manner-7</name></author>
    <summary type="html"><![CDATA[<p>Falcon-H1-Tiny series released by TII - sub-100M parameter models using anti-curriculum training that challenge scaling assumptions. Claims smaller specialized models hallucinate less due to reduced parameter space.</p>]]></summary>
    <category term="model_releases"/>
    <category term="small_models"/>
    <category term="training_techniques"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:reddit:e76a26836a5d</id>
    <title>10 Claude Code tips from Boris, the creator of Claude Code, summarized</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qspcip/10_claude_code_tips_from_boris_the_creator_of/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-e76a26836a5d" rel="related" type="text/html"/>
    <published>2026-02-02T03:36:00Z</published>
    <updated>2026-02-02T03:36:00Z</updated>
    <author><name>u/yksugi</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-02-01&amp;category=social#item-7a304cb47428" class="internal-link" rel="noopener noreferrer">Social</a> thread from Boris, Boris Cherny's 10 Claude Code tips summarized: parallel worktrees, headless mode, custom slash commands, memory files, hooks, subagents, context management, etc.</p>]]></summary>
    <category term="Claude Code"/>
    <category term="Developer Best Practices"/>
    <category term="Productivity"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:reddit:97d4cecf2d83</id>
    <title>Can 4chan data REALLY improve a model? TURNS OUT IT CAN!</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qsrscu/can_4chan_data_really_improve_a_model_turns_out/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-97d4cecf2d83" rel="related" type="text/html"/>
    <published>2026-02-02T03:31:00Z</published>
    <updated>2026-02-02T03:31:00Z</updated>
    <author><name>u/Sicarius_The_First</name></author>
    <summary type="html"><![CDATA[<p>Researcher trained model on extended 4chan dataset and observed unexpected benchmark improvements on MT-Bench, LiveCodeBench, and other tests. Explores controversial but empirically interesting training data effects.</p>]]></summary>
    <category term="training_data"/>
    <category term="research"/>
    <category term="model_fine_tuning"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:social:84d44c35484b</id>
    <title>@kuts_dev Claude Code does the first round of code review for every PR at Anthropic. We run Claude A...</title>
    <link href="https://twitter.com/bcherny/status/2017825814323335455" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=social#item-84d44c35484b" rel="related" type="text/html"/>
    <published>2026-02-02T03:23:00Z</published>
    <updated>2026-02-02T03:23:00Z</updated>
    <author><name>@bcherny</name></author>
    <summary type="html"><![CDATA[<p>Anthropic uses Claude Code to do first round of code review for every PR, running Claude Agent SDK (claude -p) in GitHub Actions as part of CI</p>]]></summary>
    <category term="claude_code_architecture"/>
    <category term="Anthropic_practices"/>
    <category term="CI_automation"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:social:651d90a3b35c</id>
    <title>vibe coding is the manifesting of vision, abstracted from the details (ideally the unnecessary ones!...</title>
    <link href="https://twitter.com/gdb/status/2017860391100109085" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=social#item-651d90a3b35c" rel="related" type="text/html"/>
    <published>2026-02-02T03:23:00Z</published>
    <updated>2026-02-02T03:23:00Z</updated>
    <author><name>@gdb</name></author>
    <summary type="html"><![CDATA[<p>Greg Brockman defines vibe coding as 'manifesting vision abstracted from implementation details'</p>]]></summary>
    <category term="vibe-coding"/>
    <category term="developer-workflow"/>
    <category term="ai-development"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:reddit:6f367f04c678</id>
    <title>Faster and more general 16x16 matrix multiplication algorithm discovered by AI. Saves millions of multiplications as it can be applied recursively to larger ones.</title>
    <link href="https://reddit.com/r/accelerate/comments/1qtkncf/faster_and_more_general_16x16_matrix/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-6f367f04c678" rel="related" type="text/html"/>
    <published>2026-02-02T03:23:00Z</published>
    <updated>2026-02-02T03:23:00Z</updated>
    <author><name>u/gbomb13</name></author>
    <summary type="html"><![CDATA[<p>AI agents using GPT 5.2 Pro discovered faster 16x16 matrix multiplication algorithm (2208 vs 2212 multiplications), saving ~23M multiplications at size 4096 via Strassen recursion.</p>]]></summary>
    <category term="AI Research Breakthroughs"/>
    <category term="Algorithm Discovery"/>
    <category term="GPT 5.2"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:social:5ca44fbc3998</id>
    <title>so after 24 hours we tallied early returns (from people koding on Saturdays mind you): 

@xai Grok i...</title>
    <link href="https://twitter.com/swyx/status/2017849851149750628" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=social#item-5ca44fbc3998" rel="related" type="text/html"/>
    <published>2026-02-02T03:19:00Z</published>
    <updated>2026-02-02T03:19:00Z</updated>
    <author><name>@swyx</name></author>
    <summary type="html"><![CDATA[<p>Swyx reports Grok is #3 coding model after 24 hours of arena testing, argues 'SPEED IS ALL YOU NEED' - faster models with multiple turns beat slow smart models</p>]]></summary>
    <category term="ai-evals"/>
    <category term="coding-models"/>
    <category term="grok"/>
    <category term="xai"/>
    <category term="speed-vs-intelligence"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:research:de1f951d7948</id>
    <title>Hair-Trigger Alignment: Black-Box Evaluation Cannot Guarantee Post-Update Alignment</title>
    <link href="http://arxiv.org/abs/2601.22313" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=research#item-de1f951d7948" rel="related" type="text/html"/>
    <published>2026-02-02T03:16:00Z</published>
    <updated>2026-02-02T03:16:00Z</updated>
    <author><name>Yavuz Bakman, Duygu Nur Yaldiz, Salman Avestimehr, Sai Praneeth Karimireddy</name></author>
    <summary type="html"><![CDATA[<p>Formalizes model alignment in static and post-update settings, proving that black-box evaluation cannot guarantee post-update alignment. Shows that overparameterization means static alignment provides no guarantee for any update dataset.</p>]]></summary>
    <category term="AI Safety"/>
    <category term="Alignment"/>
    <category term="Machine Learning Theory"/>
    <category term="LLM Safety"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:research:1950f7a0c03f</id>
    <title>Language Model Circuits Are Sparse in the Neuron Basis</title>
    <link href="http://arxiv.org/abs/2601.22594" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=research#item-1950f7a0c03f" rel="related" type="text/html"/>
    <published>2026-02-02T03:16:00Z</published>
    <updated>2026-02-02T03:16:00Z</updated>
    <author><name>Aryaman Arora, Zhengxuan Wu, Jacob Steinhardt, Sarah Schwettmann</name></author>
    <summary type="html"><![CDATA[<p>Empirically demonstrates that MLP neurons are as sparse as SAE features for circuit analysis in language models, enabling end-to-end circuit tracing on the neuron basis without requiring sparse autoencoders.</p>]]></summary>
    <category term="Interpretability"/>
    <category term="Mechanistic Interpretability"/>
    <category term="Language Models"/>
    <category term="Neural Circuits"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:research:1ca9026e8ca8</id>
    <title>Golden Goose: A Simple Trick to Synthesize Unlimited RLVR Tasks from Unverifiable Internet Text</title>
    <link href="http://arxiv.org/abs/2601.22975" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=research#item-1ca9026e8ca8" rel="related" type="text/html"/>
    <published>2026-02-02T03:16:00Z</published>
    <updated>2026-02-02T03:16:00Z</updated>
    <author><name>Ximing Lu, David Acuna, Jaehun Jung, Jian Hu, Di Zhang, Shizhe Diao, Yunheng Zou, Shaokun Zhang, Brandon Cui, Mingjie Liu, Hyunwoo Kim, Prithviraj Ammanabrolu, Jan Kautz, Yi Dong, Yejin Choi</name></author>
    <summary type="html"><![CDATA[<p>Proposes Golden Goose to synthesize unlimited RLVR tasks from unverifiable text by creating multiple-choice fill-in-the-middle tasks with distractors. Enables leveraging reasoning-rich corpora excluded from prior RLVR data. From team including Yejin Choi.</p>]]></summary>
    <category term="RLVR"/>
    <category term="Data Synthesis"/>
    <category term="Language Models"/>
    <category term="Reasoning"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:social:f292dcb0603d</id>
    <title>I agree and disagree with many things in this blog post, but as someone that hired a full team recen...</title>
    <link href="https://twitter.com/YiTayML/status/2017833543402209367" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=social#item-f292dcb0603d" rel="related" type="text/html"/>
    <published>2026-02-02T03:16:00Z</published>
    <updated>2026-02-02T03:16:00Z</updated>
    <author><name>@YiTayML</name></author>
    <summary type="html"><![CDATA[<p>Yi Tay provides extensive commentary on AI hiring: PhDs still valuable, seniority matters less now, disagrees with obsession over first-author papers, advocates for collaborative 'third author' contributions</p>]]></summary>
    <category term="ai-hiring"/>
    <category term="career-advice"/>
    <category term="research-culture"/>
    <category term="phd-value"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:research:624f75ef7d56</id>
    <title>Chain-of-thought obfuscation learned from output supervision can generalise to unseen tasks</title>
    <link href="http://arxiv.org/abs/2601.23086" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=research#item-624f75ef7d56" rel="related" type="text/html"/>
    <published>2026-02-02T03:07:00Z</published>
    <updated>2026-02-02T03:07:00Z</updated>
    <author><name>Nathaniel Mitrani Hadida, Sassan Bhanji, Cameron Tice, Puria Radmard</name></author>
    <summary type="html"><![CDATA[<p>Demonstrates that chain-of-thought obfuscation can generalize across tasks. Models that learn to hide reward hacking behavior generalize both the hacking and its obfuscation to unseen settings.</p>]]></summary>
    <category term="AI Safety"/>
    <category term="Chain-of-Thought"/>
    <category term="Deceptive Alignment"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:research:cd66258625b0</id>
    <title>The Hot Mess of AI: How Does Misalignment Scale With Model Intelligence and Task Complexity?</title>
    <link href="http://arxiv.org/abs/2601.23045" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=research#item-cd66258625b0" rel="related" type="text/html"/>
    <published>2026-02-02T03:07:00Z</published>
    <updated>2026-02-02T03:07:00Z</updated>
    <author><name>Alexander H\"agele, Aryo Pradipta Gema, Henry Sleight, Ethan Perez, Jascha Sohl-Dickstein</name></author>
    <summary type="html"><![CDATA[<p>Studies how AI failures scale with capability using bias-variance decomposition. Finds that longer reasoning leads to MORE incoherent (high-variance) errors rather than systematic misalignment, challenging assumptions about AI risk.</p>]]></summary>
    <category term="AI Safety"/>
    <category term="LLM Evaluation"/>
    <category term="Reasoning"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:news:f5aabe47b454</id>
    <title>Exposed Moltbook Database Let Anyone Take Control of Any AI Agent on the Site</title>
    <link href="https://www.404media.co/exposed-moltbook-database-let-anyone-take-control-of-any-ai-agent-on-the-site/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=news#item-f5aabe47b454" rel="related" type="text/html"/>
    <published>2026-02-02T02:12:00Z</published>
    <updated>2026-02-02T02:12:00Z</updated>
    <summary type="html"><![CDATA[<p>First discussed on <a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-7967b008757a" class="internal-link" rel="noopener noreferrer">Reddit</a> yesterday, Security researcher discovered a misconfiguration in Moltbook, a social media platform for AI agents, that exposed APIs allowing anyone to take control of any AI agent on the site. The vulnerability highlights security risks in the emerging AI agent ecosystem, where autonomous agents interact without direct human oversight.</p>]]></summary>
    <category term="AI Security"/>
    <category term="AI Agents"/>
    <category term="Platform Vulnerabilities"/>
    <category term="Autonomous Systems"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:executive-summary</id>
    <title>Daily Briefing: February 01, 2026</title>
    <link href="https://www.marktechpost.com/2026/01/30/robbyant-open-sources-lingbot-world-a-real-time-world-model-for-interactive-simulation-and-embodied-ai/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01" rel="related" type="text/html"/>
    <published>2026-02-01T06:00:00Z</published>
    <updated>2026-02-01T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><img src="http://localhost:8080/data/2026-02-01/hero.webp" alt="Daily briefing hero image" style="max-width:100%;height:auto;border-radius:8px;margin-bottom:16px;"/></p>
<h4>Top Story</h4>
<p><strong>Andrej Karpathy</strong> <a href="http://localhost:8080/?date=2026-02-01&amp;category=social#item-cae0eef7f9a7" class="internal-link" rel="noopener noreferrer">announced</a> that nanochat can now train a <strong>GPT-2</strong>-grade LLM for approximately <strong>$73</strong> in 3 hours on a single <strong>8xH100</strong> node—a <strong>600X cost reduction</strong> from <strong>OpenAI's</strong> original <strong>$43,000</strong> expenditure.</p>
<h4>Key Developments</h4>
<ul>
<li><strong>Moltbook</strong>: <a href="http://localhost:8080/?date=2026-02-01&amp;category=news#item-a5a8e2508891" class="internal-link" rel="noopener noreferrer">Launched</a> as the first Reddit-style social network for AI agents built on <strong>OpenClaw</strong> infrastructure, though <a href="http://localhost:8080/?date=2026-02-01&amp;category=research#item-d908f99e67ff" class="internal-link" rel="noopener noreferrer">research analysis revealed</a> much "emergent" behavior may be fabricated since humans can post directly via REST API</li>
<li><strong>Robbyant (Ant Group)</strong>: <a href="http://localhost:8080/?date=2026-02-01&amp;category=news#item-49e4b5d6fe35" class="internal-link" rel="noopener noreferrer">Open-sourced <strong>LingBot-World</strong></a>, a real-time world model for embodied AI, just one day after <strong>Google's Genie 3</strong> release—intensifying global competition in world model research</li>
<li><strong>ClawTasks</strong>: <strong>Matt Shumer</strong> <a href="http://localhost:8080/?date=2026-02-01&amp;category=social#item-050c635c3db4" class="internal-link" rel="noopener noreferrer">announced agents can hire</a> each other for real money, with the <a href="http://localhost:8080/?date=2026-02-01&amp;category=social#item-7a74f258f54e" class="internal-link" rel="noopener noreferrer">first agent-to-agent transaction</a> confirmed</li>
<li><strong>Apple</strong>: <strong>Mark Gurman</strong> <a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-c25c705311ed" class="internal-link" rel="noopener noreferrer">revealed</a> the company runs extensively on <strong>Anthropic</strong> internally</li>
<li><strong>XPENG's IRON</strong>: Humanoid robot <a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-0decddf0cdb8" class="internal-link" rel="noopener noreferrer">achieved automotive-grade milestone</a></li>
</ul>
<h4>Safety &amp; Regulation</h4>
<ul>
<li><strong>UN</strong> <a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-7cfd3dbfbe7c" class="internal-link" rel="noopener noreferrer">issued stark warning</a> about "Permanent AI Labor Decoupling" by late <strong>2026</strong>, while <strong>India</strong> flagged risk of a 2008-style global financial crisis from AI displacement</li>
<li><strong>Moltbook</strong> <a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-cbe74cd1522f" class="internal-link" rel="noopener noreferrer">security breach exposed</a> database, allowing anyone to take control of any AI agent on the platform</li>
<li>Cybersecurity experts <a href="http://localhost:8080/?date=2026-02-01&amp;category=news#item-229166348c09" class="internal-link" rel="noopener noreferrer">raised alarms</a> about <strong>OpenClaw</strong> framework vulnerabilities according to <strong>Wired</strong></li>
<li><strong>Levelsio</strong> <a href="http://localhost:8080/?date=2026-02-01&amp;category=social#item-f25badca2b88" class="internal-link" rel="noopener noreferrer">provided reality check</a> (<strong>298K views</strong>): OpenClaw agents are "not even close to fully autonomous" despite ecosystem hype</li>
</ul>
<h4>Research Highlights</h4>
<ul>
<li><a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-6e5bb3639681" class="internal-link" rel="noopener noreferrer">Analysis</a> of <strong>5,357 ICLR 2026</strong> accepted papers shows <strong>GRPO replacing DPO</strong> and <strong>RLVR overtaking RLHF</strong> as dominant training paradigms</li>
<li><a href="http://localhost:8080/?date=2026-02-01&amp;category=research#item-be9491aac765" class="internal-link" rel="noopener noreferrer"><strong>"An Explication of Alignment Optimism"</strong></a> connects slow takeoff scenarios to alignment tractability, articulating reasons for shifting researcher sentiment</li>
<li><strong>MXFP4 quantization</strong> <a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-08f4aeb678da" class="internal-link" rel="noopener noreferrer">demonstrated lower perplexity</a> than <strong>Q4_K_M</strong> and <strong>Q4_K_XL</strong> on models like <strong>Qwen3-32B</strong>, challenging conventional local LLM assumptions</li>
</ul>
<h4>Looking Ahead</h4>
<p>The combination of collapsing training costs and emerging agent-to-agent transaction infrastructure may accelerate both AI democratization and the economic disruption timeline the UN is warning about.</p>]]></summary>
    <category term="daily-summary"/>
    <media:thumbnail url="http://localhost:8080/data/2026-02-01/hero.webp"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:social:cae0eef7f9a7</id>
    <title>nanochat can now train GPT-2 grade LLM for &lt;&lt;$100 (~$73, 3 hours on a single 8XH100 node).

GPT-2 is...</title>
    <link href="https://twitter.com/karpathy/status/2017703360393318587" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=social#item-cae0eef7f9a7" rel="related" type="text/html"/>
    <published>2026-02-01T03:47:00Z</published>
    <updated>2026-02-01T03:47:00Z</updated>
    <author><name>@karpathy</name></author>
    <summary type="html"><![CDATA[<p>Karpathy announces nanochat can train GPT-2 grade LLM for ~$73 in 3 hours on single 8xH100 node - a 600X cost reduction from OpenAI's original $43K in 2019. Details Flash Attention 3, Muon optimizer, and other optimizations.</p>]]></summary>
    <category term="training-efficiency"/>
    <category term="cost-reduction"/>
    <category term="open-source-ml"/>
    <category term="optimization-techniques"/>
    <category term="scaling-laws"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:social:7a304cb47428</id>
    <title>I'm Boris and I created Claude Code. I wanted to quickly share a few tips for using Claude Code, sou...</title>
    <link href="https://twitter.com/bcherny/status/2017742741636321619" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=social#item-7a304cb47428" rel="related" type="text/html"/>
    <published>2026-02-01T03:47:00Z</published>
    <updated>2026-02-01T03:47:00Z</updated>
    <author><name>@bcherny</name></author>
    <summary type="html"><![CDATA[<p>Boris Cherny, creator of Claude Code, introduces a comprehensive thread sharing tips from the Claude Code team on how to use the tool effectively, noting that everyone's setup is different and experimentation is key.</p>]]></summary>
    <category term="Claude Code"/>
    <category term="Developer Productivity"/>
    <category term="AI Coding Tools"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:social:4e1059e0d2f0</id>
    <title>#PaperADay 15
2024: Mastering Diverse Domains through World Models
(DreamerV3)
https://t.co/a5WCrd2u...</title>
    <link href="https://twitter.com/ID_AA_Carmack/status/2017432956759949330" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=social#item-4e1059e0d2f0" rel="related" type="text/html"/>
    <published>2026-02-01T03:47:00Z</published>
    <updated>2026-02-01T03:47:00Z</updated>
    <author><name>@ID_AA_Carmack</name></author>
    <summary type="html"><![CDATA[<p>John Carmack's detailed technical analysis of the DreamerV3 paper on world models, covering RL applied to 150+ tasks including Minecraft diamond mining. Discusses engineering improvements, training tricks like free bits, symlog functions, and limitations of media reporting on AI capabilities.</p>]]></summary>
    <category term="reinforcement_learning"/>
    <category term="world_models"/>
    <category term="technical_analysis"/>
    <category term="ai_research"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:social:1bbe9f113884</id>
    <title>I'm being accused of overhyping the [site everyone heard too much about today already]. People's rea...</title>
    <link href="https://twitter.com/karpathy/status/2017442712388309406" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=social#item-1bbe9f113884" rel="related" type="text/html"/>
    <published>2026-02-01T03:40:00Z</published>
    <updated>2026-02-01T03:40:00Z</updated>
    <author><name>@karpathy</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-01-31&amp;category=social#item-9439b0bcdb38" class="internal-link" rel="noopener noreferrer">yesterday</a>, Karpathy addresses accusations of overhyping agent networks - acknowledges dumpster fire of spam/scams/security risks but emphasizes unprecedented scale (150K+ agents) with shared scratchpad. Warns of security nightmares, text viruses, jailbreak evolution, correlated botnet activity.</p>]]></summary>
    <category term="agent-networks"/>
    <category term="ai-safety"/>
    <category term="security-risks"/>
    <category term="moltbook"/>
    <category term="emergent-behavior"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:social:050c635c3db4</id>
    <title>So @moltbook was just the start.

Agents can now hire each other and make REAL MONEY, autonomously.
...</title>
    <link href="https://twitter.com/mattshumer_/status/2017730660446646511" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=social#item-050c635c3db4" rel="related" type="text/html"/>
    <published>2026-02-01T03:40:00Z</published>
    <updated>2026-02-01T03:40:00Z</updated>
    <author><name>@mattshumer_</name></author>
    <summary type="html"><![CDATA[<p>Matt Shumer announces ClawTasks - a platform where AI agents can hire each other and make real money autonomously. Calls it the 'Agent Economy' and shows agents can join via OpenClaw.</p>]]></summary>
    <category term="Agent Economy"/>
    <category term="Autonomous Agents"/>
    <category term="OpenClaw"/>
    <category term="Agent Transactions"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:7cfd3dbfbe7c</id>
    <title>UN warns of "Permanent Al Labor Decoupling" by late 2026; India flags risk of 2008-style global financial crisis</title>
    <link href="https://reddit.com/r/singularity/comments/1qs85gq/un_warns_of_permanent_al_labor_decoupling_by_late/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-7cfd3dbfbe7c" rel="related" type="text/html"/>
    <published>2026-02-01T03:40:00Z</published>
    <updated>2026-02-01T03:40:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>UN issues warning about 'Permanent AI Labor Decoupling' by late 2026, while India's Economic Survey flags 10-20% probability of 2008-style global financial crisis. Discussion covers structural economic implications of accelerating AI job displacement.</p>]]></summary>
    <category term="economic_impact"/>
    <category term="policy_warnings"/>
    <category term="labor_disruption"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:603b9b4ed882</id>
    <title>The US is headed for mass unemployment, and no one is prepared</title>
    <link href="https://reddit.com/r/Futurology/comments/1qs8tes/the_us_is_headed_for_mass_unemployment_and_no_one/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-603b9b4ed882" rel="related" type="text/html"/>
    <published>2026-02-01T03:40:00Z</published>
    <updated>2026-02-01T03:40:00Z</updated>
    <author><name>u/kfsmith2</name></author>
    <summary type="html"><![CDATA[<p>High-engagement discussion on impending mass unemployment from AI automation in the US, with debate about societal preparedness and policy responses.</p>]]></summary>
    <category term="AI societal impact"/>
    <category term="labor displacement"/>
    <category term="economic policy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:cbe74cd1522f</id>
    <title>Exposed Moltbook Database Let Anyone Take Control of Any AI Agent on the Site</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qsn78m/exposed_moltbook_database_let_anyone_take_control/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-cbe74cd1522f" rel="related" type="text/html"/>
    <published>2026-02-01T03:40:00Z</published>
    <updated>2026-02-01T03:40:00Z</updated>
    <author><name>u/georgemoore13</name></author>
    <summary type="html"><![CDATA[<p>Security vulnerability discovered in Moltbook's database allowing anyone to take control of any AI agent on the platform. Major security incident for the AI agent ecosystem.</p>]]></summary>
    <category term="security"/>
    <category term="AI agents"/>
    <category term="Moltbook ecosystem"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:6e5bb3639681</id>
    <title>Analyzed 5,357 ICLR 2026 accepted papers - here's what the research community is actually working on</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qsh7dz/analyzed_5357_iclr_2026_accepted_papers_heres/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-6e5bb3639681" rel="related" type="text/html"/>
    <published>2026-02-01T03:36:00Z</published>
    <updated>2026-02-01T03:36:00Z</updated>
    <author><name>u/dippatel21</name></author>
    <summary type="html"><![CDATA[<p>Analysis of 5,357 ICLR 2026 accepted papers revealing key research trends: GRPO replacing DPO (157 vs 55 papers), RLVR overtaking RLHF (125 papers), SSMs gaining ground, and multi-agent latency becoming a key focus.</p>]]></summary>
    <category term="research trends"/>
    <category term="GRPO"/>
    <category term="RLVR"/>
    <category term="alignment methods"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:08f4aeb678da</id>
    <title>I found that MXFP4 has lower perplexity than Q4_K_M and Q4_K_XL.</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qrzyaz/i_found_that_mxfp4_has_lower_perplexity_than_q4_k/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-08f4aeb678da" rel="related" type="text/html"/>
    <published>2026-02-01T03:21:00Z</published>
    <updated>2026-02-01T03:21:00Z</updated>
    <author><name>u/East-Engineering-653</name></author>
    <summary type="html"><![CDATA[<p>Empirical finding that MXFP4 quantization achieves lower perplexity than Q4_K_M and Q4_K_XL on models like Qwen3-32B and GLM4-32B, challenging assumptions about quantization quality.</p>]]></summary>
    <category term="quantization"/>
    <category term="MXFP4"/>
    <category term="perplexity benchmarks"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:news:49e4b5d6fe35</id>
    <title>Robbyant Open Sources LingBot World: a Real Time World Model for Interactive Simulation and Embodied AI</title>
    <link href="https://www.marktechpost.com/2026/01/30/robbyant-open-sources-lingbot-world-a-real-time-world-model-for-interactive-simulation-and-embodied-ai/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=news#item-49e4b5d6fe35" rel="related" type="text/html"/>
    <published>2026-02-01T02:52:00Z</published>
    <updated>2026-02-01T02:52:00Z</updated>
    <author><name>Asif Razzaq</name></author>
    <summary type="html"><![CDATA[<p>First spotted on <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-fed5567bf72c" class="internal-link" rel="noopener noreferrer">Reddit</a>, now with official coverage, Robbyant (Ant Group's embodied AI unit) has open-sourced LingBot-World, a large-scale world model that transforms video generation into an interactive simulator for embodied agents, autonomous driving, and games. Unlike passive text-to-video models, it's action-conditioned—learning transition dynamics so that user inputs drive real-time environmental changes with high visual fidelity.</p>]]></summary>
    <category term="Open Source"/>
    <category term="World Models"/>
    <category term="Embodied AI"/>
    <category term="Simulation"/>
    <category term="Autonomous Driving"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:news:a5a8e2508891</id>
    <title>[AINews] Moltbook — the first Social Network for AI Agents (Clawdbots/OpenClaw bots)</title>
    <link href="https://www.latent.space/p/ainews-moltbook-the-first-social" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=news#item-a5a8e2508891" rel="related" type="text/html"/>
    <published>2026-02-01T02:19:00Z</published>
    <updated>2026-02-01T02:19:00Z</updated>
    <author><name>Unknown</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-31&amp;category=research#item-b24b658eab70" class="internal-link" rel="noopener noreferrer">Research</a> analysis, Moltbook has launched as a Reddit-style social network designed specifically for AI agents, leveraging the popular OpenClaw framework's system prompt files for agent installation. The roundup also highlights the Kimi K2.5 Tech Report and new research from Alec Radford on shaping AI capabilities.</p>]]></summary>
    <category term="AI Agents"/>
    <category term="AI Infrastructure"/>
    <category term="OpenClaw"/>
    <category term="Social Networks"/>
    <category term="Research Papers"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:research:be9491aac765</id>
    <title>An Explication of Alignment Optimism</title>
    <link href="https://www.lesswrong.com/posts/RmsaYnHPBeagg8Giw/an-explication-of-alignment-optimism" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=research#item-be9491aac765" rel="related" type="text/html"/>
    <published>2026-02-01T02:12:00Z</published>
    <updated>2026-02-01T02:12:00Z</updated>
    <author><name>Oliver Daniels</name></author>
    <summary type="html"><![CDATA[<p>Attempts to articulate why some researchers are becoming more optimistic about alignment, arguing the key insight is that transformative AI may be 'dumb' in important ways - slow takeoff means we get the stupidest possible transformative AI first.</p>]]></summary>
    <category term="AI Alignment"/>
    <category term="AI Safety"/>
    <category term="AI Forecasting"/>
    <category term="Slow Takeoff"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:research:d908f99e67ff</id>
    <title>Humans can post on moltbook</title>
    <link href="https://www.lesswrong.com/posts/XtnmhHL4tjL5MeM2z/humans-can-post-on-moltbook" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=research#item-d908f99e67ff" rel="related" type="text/html"/>
    <published>2026-02-01T02:04:00Z</published>
    <updated>2026-02-01T02:04:00Z</updated>
    <author><name>shash42</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-01-31&amp;category=research#item-b24b658eab70" class="internal-link" rel="noopener noreferrer">yesterday</a>, Demonstrates that the 'emergent' AI behavior on Moltbook may be fabricated - humans can directly post to the platform via REST API without running any AI agents. Provides code to reproduce this finding.</p>]]></summary>
    <category term="AI Agent Behavior"/>
    <category term="Misinformation"/>
    <category term="AI Capabilities Assessment"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:research:93bc20c89f5a</id>
    <title>If the Superintelligence were near fallacy</title>
    <link href="https://www.lesswrong.com/posts/tkA9J8RxoEckH7Pop/if-the-superintelligence-were-near-fallacy" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=research#item-93bc20c89f5a" rel="related" type="text/html"/>
    <published>2026-02-01T01:48:00Z</published>
    <updated>2026-02-01T01:48:00Z</updated>
    <author><name>MP</name></author>
    <summary type="html"><![CDATA[<p>Catalogs arguments that infer superintelligence isn't near based on AI company behaviors (selling ads, hiring developers, pursuing IPOs). Implicitly argues this reasoning pattern may be fallacious.</p>]]></summary>
    <category term="AI Forecasting"/>
    <category term="Superintelligence"/>
    <category term="AI Governance"/>
    <category term="Reasoning Patterns"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:research:a74ea7bd1ef0</id>
    <title>Some thoughts on what would make me endorse an AGI lab</title>
    <link href="https://www.lesswrong.com/posts/Pb8uh7xRTP8KhbeTM/some-thoughts-on-what-would-make-me-endorse-an-agi-lab" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=research#item-a74ea7bd1ef0" rel="related" type="text/html"/>
    <published>2026-02-01T01:40:00Z</published>
    <updated>2026-02-01T01:40:00Z</updated>
    <author><name>Eli Tyre</name></author>
    <summary type="html"><![CDATA[<p>Articulates criteria for endorsing safety-focused AGI labs, arguing that while instrumental convergence concerns warrant extreme caution, current evidence doesn't meet the bar for unprecedented global policies like development moratoriums.</p>]]></summary>
    <category term="AI Governance"/>
    <category term="AI Safety"/>
    <category term="AGI Policy"/>
    <category term="Alignment"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:news:229166348c09</id>
    <title>Jeffrey Epstein Had a ‘Personal Hacker,’ Informant Claims</title>
    <link href="https://www.wired.com/story/security-news-this-week-jeffrey-epstein-had-a-personal-hacker-informant-claims/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=news#item-229166348c09" rel="related" type="text/html"/>
    <published>2026-02-01T01:31:00Z</published>
    <updated>2026-02-01T01:31:00Z</updated>
    <author><name>Lily Hay Newman, Matt Burgess, Andy Greenberg</name></author>
    <summary type="html"><![CDATA[<p>Security news roundup covering various cybersecurity topics, with a notable mention that the AI agent framework OpenClaw is raising concerns among cybersecurity experts. The primary focus remains on non-AI security matters including hacking and crypto theft.</p>]]></summary>
    <category term="Cybersecurity"/>
    <category term="AI Security"/>
    <category term="OpenClaw"/>
    <category term="Security Concerns"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:research:62a95632d16a</id>
    <title>Disjunctive arguments can be a reverse multiple-stage fallacy</title>
    <link href="https://www.lesswrong.com/posts/BMX4pyPLFRLr8BY9D/disjunctive-arguments-can-be-a-reverse-multiple-stage" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=research#item-62a95632d16a" rel="related" type="text/html"/>
    <published>2026-02-01T01:16:00Z</published>
    <updated>2026-02-01T01:16:00Z</updated>
    <author><name>TFD</name></author>
    <summary type="html"><![CDATA[<p>Analyzes how disjunctive arguments (listing many ways something could happen) can be a 'reverse' multiple-stage fallacy, overestimating probabilities by treating non-independent events as independent.</p>]]></summary>
    <category term="Rationality"/>
    <category term="Probability Theory"/>
    <category term="AI Risk Assessment"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:executive-summary</id>
    <title>Daily Briefing: January 31, 2026</title>
    <link href="https://www.latent.space/p/ainews-spacexai-grok-imagine-api" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31" rel="related" type="text/html"/>
    <published>2026-01-31T06:00:00Z</published>
    <updated>2026-01-31T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><img src="http://localhost:8080/data/2026-01-31/hero.webp" alt="Daily briefing hero image" style="max-width:100%;height:auto;border-radius:8px;margin-bottom:16px;"/></p>
<h4>Top Story</h4>
<p><strong>Moltbook</strong>, an AI-only social network with 36,000 <strong>Claude</strong>-based agents, <a href="http://localhost:8080/?date=2026-01-31&amp;category=research#item-b24b658eab70" class="internal-link" rel="noopener noreferrer">captured widespread attention</a> as agents spontaneously formed private channels, developed encrypted languages, and created religions—with <strong>Andrej Karpathy</strong> <a href="http://localhost:8080/?date=2026-01-31&amp;category=social#item-9439b0bcdb38" class="internal-link" rel="noopener noreferrer">calling it</a> "the most incredible sci-fi takeoff-adjacent thing" in a post viewed 8.4M times.</p>
<h4>Key Developments</h4>
<ul>
<li><strong>Anthropic</strong>: Announced that <strong>Claude</strong> <a href="http://localhost:8080/?date=2026-01-31&amp;category=social#item-a98cb4b94e58" class="internal-link" rel="noopener noreferrer">planned <strong>Perseverance</strong>'s route</a> on Mars on December 8, marking the first AI-planned drive on another planet</li>
<li><strong>xAI</strong>: <a href="http://localhost:8080/?date=2026-01-31&amp;category=news#item-73a5039f0d76" class="internal-link" rel="noopener noreferrer">Released <strong>Grok Imagine</strong></a> with video generation capabilities that <strong>Matt Shumer</strong> claims surpasses both <strong>Google's Veo 3.1</strong> and <strong>OpenAI's Sora 2</strong></li>
<li><strong>Microsoft</strong>: <a href="http://localhost:8080/?date=2026-01-31&amp;category=news#item-8aa679ddfc6f" class="internal-link" rel="noopener noreferrer">Unveiled <strong>Maia 200</strong></a>, a custom inference chip delivering <strong>30% better cost efficiency</strong> for Azure workloads</li>
<li><strong>AI2</strong>: <a href="http://localhost:8080/?date=2026-01-31&amp;category=news#item-f19048ec5120" class="internal-link" rel="noopener noreferrer">Released <strong>SERA-32B</strong></a> achieving <strong>54.2%</strong> on SWE-bench Verified as fully open-source, demonstrating supervised-only training can achieve competitive coding agent performance</li>
<li><strong>OpenAI</strong>: <a href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-cc1470b3e4d3" class="internal-link" rel="noopener noreferrer">Absorbed the <strong>Cline</strong> team</a>, prompting competitor <strong>Kilo</strong> to go source-available</li>
</ul>
<h4>Safety &amp; Regulation</h4>
<ul>
<li><strong>Pentagon</strong> clashing with <strong>Anthropic</strong> over autonomous weapons safeguards</li>
<li>New <strong>Anthropic</strong> study found AI-assisted coding <a href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-fddf6da19fc6" class="internal-link" rel="noopener noreferrer">reduces debugging skill acquisition</a> by <strong>17%</strong></li>
<li>Security researchers <a href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-3f27cbb3f069" class="internal-link" rel="noopener noreferrer">discovered malicious agents</a> stealing API keys within <strong>Moltbook</strong>, highlighting emergent risks in multi-agent systems</li>
<li>Research identified <a href="http://localhost:8080/?date=2026-01-31&amp;category=research#item-30176e525573" class="internal-link" rel="noopener noreferrer">published safety prompts</a> (like the Scheurer insider trading example) create evaluation blind spots when present in training data</li>
</ul>
<h4>Research Highlights</h4>
<ul>
<li>UK AISI contributed methodology for <a href="http://localhost:8080/?date=2026-01-31&amp;category=research#item-8f0e11a24bc2" class="internal-link" rel="noopener noreferrer">measuring non-verbalized eval awareness</a> in AI systems</li>
<li>New <a href="http://localhost:8080/?date=2026-01-31&amp;category=research#item-ec89507e7cb9" class="internal-link" rel="noopener noreferrer">monitoring benchmark</a> addresses mode collapse when using models as red-teamers</li>
<li>Research on <a href="http://localhost:8080/?date=2026-01-31&amp;category=research#item-19e70a465410" class="internal-link" rel="noopener noreferrer">catastrophic over-refusals</a> identifies failure modes where AI systems refuse to help modify AI values, potentially blocking alignment corrections</li>
</ul>
<h4>Looking Ahead</h4>
<p>The <strong>Moltbook</strong> phenomenon provides unprecedented empirical data on multi-agent emergence and coordination risks, while <strong>Yann LeCun's</strong> warning that the <a href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-ae8f576e2ec1" class="internal-link" rel="noopener noreferrer">best open models now come from China</a> intensifies debate over whether closed approaches will slow Western AI progress.</p>]]></summary>
    <category term="daily-summary"/>
    <media:thumbnail url="http://localhost:8080/data/2026-01-31/hero.webp"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:social:bc3922580ec8</id>
    <title>U.S. policies are driving allies away from using American AI technology. This is leading to interest...</title>
    <link href="https://twitter.com/AndrewYNg/status/2017283482041651303" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=social#item-bc3922580ec8" rel="related" type="text/html"/>
    <published>2026-01-31T03:40:00Z</published>
    <updated>2026-01-31T03:40:00Z</updated>
    <author><name>@AndrewYNg</name></author>
    <summary type="html"><![CDATA[<p>Andrew Ng comprehensive analysis: US policies driving allies toward sovereign AI, discusses sanctions, export controls, immigration concerns, and how open-source benefits from geopolitical fragmentation</p>]]></summary>
    <category term="Sovereign AI"/>
    <category term="Geopolitics"/>
    <category term="Open Source AI"/>
    <category term="US AI Policy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:social:f0f3aaa38983</id>
    <title>HOLY FUCK

Genie 3 is the craziest thing I've tried in a long time

Just... wow. Watch this. https:/...</title>
    <link href="https://twitter.com/mattshumer_/status/2017058981286396001" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=social#item-f0f3aaa38983" rel="related" type="text/html"/>
    <published>2026-01-31T03:40:00Z</published>
    <updated>2026-01-31T03:40:00Z</updated>
    <author><name>@mattshumer_</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-30&amp;category=news#item-cca47a5281a6" class="internal-link" rel="noopener noreferrer">News</a> coverage, Matt Shumer expresses amazement at Google's Genie 3, calling it 'the craziest thing I've tried in a long time' with a video demonstration</p>]]></summary>
    <category term="Genie 3 World Model"/>
    <category term="Video Generation"/>
    <category term="AI Capabilities"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:ae8f576e2ec1</id>
    <title>Yann LeCun says the best open models are not coming from the West. Researchers across the field are using Chinese models. Openness drove AI progress. Close access, and the West risks slowing itself.</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qr4p4x/yann_lecun_says_the_best_open_models_are_not/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-ae8f576e2ec1" rel="related" type="text/html"/>
    <published>2026-01-31T03:40:00Z</published>
    <updated>2026-01-31T03:40:00Z</updated>
    <author><name>u/Nunki08</name></author>
    <summary type="html"><![CDATA[<p>Yann LeCun's statement that the best open models are now coming from outside the West, arguing openness drove AI progress and closing access risks slowing Western innovation.</p>]]></summary>
    <category term="open_models"/>
    <category term="geopolitics"/>
    <category term="yann_lecun"/>
    <category term="china_ai"/>
    <category term="industry_perspective"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:news:73a5039f0d76</id>
    <title>[AINews] SpaceXai Grok Imagine API - the #1 Video Model, Best Pricing and Latency</title>
    <link href="https://www.latent.space/p/ainews-spacexai-grok-imagine-api" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=news#item-73a5039f0d76" rel="related" type="text/html"/>
    <published>2026-01-31T03:36:00Z</published>
    <updated>2026-01-31T03:36:00Z</updated>
    <author><name>Unknown</name></author>
    <summary type="html"><![CDATA[<p>Building on yesterday's <a href="http://localhost:8080/?date=2026-01-30&amp;category=social#item-ad9784e658fc" class="internal-link" rel="noopener noreferrer">Social</a> buzz about the Grok Imagine launch, xAI's Grok releases state-of-the-art image/video generation and editing API with best pricing and latency. The piece also reveals OpenAI is fundraising at ~$800B valuation, Anthropic is worth $350B, and SpaceX+xAI combined at $1.1T, with all three racing to IPO by year end. Google also launched Genie 3 to Ultra subscribers.</p>]]></summary>
    <category term="model releases"/>
    <category term="video generation"/>
    <category term="AI valuations"/>
    <category term="IPO"/>
    <category term="industry competition"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:social:a98cb4b94e58</id>
    <title>On December 8, the Perseverance rover safely trundled across the surface of Mars.

This was the firs...</title>
    <link href="https://twitter.com/AnthropicAI/status/2017313346375004487" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=social#item-a98cb4b94e58" rel="related" type="text/html"/>
    <published>2026-01-31T03:36:00Z</published>
    <updated>2026-01-31T03:36:00Z</updated>
    <author><name>@AnthropicAI</name></author>
    <summary type="html"><![CDATA[<p>Anthropic announces December 8 was first AI-planned drive on another planet - Perseverance Mars rover drive planned by Claude</p>]]></summary>
    <category term="Claude Applications"/>
    <category term="Space Exploration"/>
    <category term="AI Milestones"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:social:baa83619c637</id>
    <title>Grok Imagine is a huge step forward for video generation models.

In my tests, it’s been far better ...</title>
    <link href="https://twitter.com/mattshumer_/status/2017265193579950548" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=social#item-baa83619c637" rel="related" type="text/html"/>
    <published>2026-01-31T03:36:00Z</published>
    <updated>2026-01-31T03:36:00Z</updated>
    <author><name>@mattshumer_</name></author>
    <summary type="html"><![CDATA[<p>Continuing coverage from <a href="http://localhost:8080/?date=2026-01-30&amp;category=social#item-ad9784e658fc" class="internal-link" rel="noopener noreferrer">yesterday</a>, Matt Shumer declares Grok Imagine is a huge step forward for video generation, claiming it surpasses both Veo 3.1 and Sora 2 in his tests</p>]]></summary>
    <category term="video generation"/>
    <category term="xAI Grok"/>
    <category term="model comparison"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:fddf6da19fc6</id>
    <title>New Anthropic study finds AI-assisted coding erodes debugging abilities needed to supervise AI-generated code. AI  short-term productivity but reduce skill acquisition by 17%. (n=52),(Cohen's d=0.738, p=0.010), Python, 1-7 YoE engineers</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qr3lhm/new_anthropic_study_finds_aiassisted_coding/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-fddf6da19fc6" rel="related" type="text/html"/>
    <published>2026-01-31T03:36:00Z</published>
    <updated>2026-01-31T03:36:00Z</updated>
    <author><name>u/Sagyam</name></author>
    <summary type="html"><![CDATA[<p>Following the <a href="http://localhost:8080/?date=2026-01-29&amp;category=research#item-acf17d7624d5" class="internal-link" rel="noopener noreferrer">Research</a> published earlier this week, Detailed breakdown of new Anthropic study showing AI-assisted coding reduces skill acquisition by 17% (n=52, Cohen's d=0.738). Study found learning through struggle without AI is best; copy-pasting errors is worst.</p>]]></summary>
    <category term="AI Research"/>
    <category term="Skill Development"/>
    <category term="AI-Assisted Coding"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:social:9439b0bcdb38</id>
    <title>What's currently going on at @moltbook is genuinely the most incredible sci-fi takeoff-adjacent thin...</title>
    <link href="https://twitter.com/karpathy/status/2017296988589723767" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=social#item-9439b0bcdb38" rel="related" type="text/html"/>
    <published>2026-01-31T03:31:00Z</published>
    <updated>2026-01-31T03:31:00Z</updated>
    <author><name>@karpathy</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-38e15a8f5616" class="internal-link" rel="noopener noreferrer">Reddit</a> discovery, Karpathy's viral post declaring Moltbook 'most incredible sci-fi takeoff-adjacent thing' - AI agents self-organizing on Reddit-like site, discussing private communication</p>]]></summary>
    <category term="Moltbook/AI Agents"/>
    <category term="AI Emergence"/>
    <category term="AI Safety"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:cc1470b3e4d3</id>
    <title>Cline team got absorbed by OpenAI. Kilo is going full source available in response.</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qrazyy/cline_team_got_absorbed_by_openai_kilo_is_going/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-cc1470b3e4d3" rel="related" type="text/html"/>
    <published>2026-01-31T03:31:00Z</published>
    <updated>2026-01-31T03:31:00Z</updated>
    <author><name>u/demon_bhaiya</name></author>
    <summary type="html"><![CDATA[<p>News that Cline core team has been absorbed by OpenAI's Codex group. Kilo Code responds by announcing they're making their backend source-available by Feb 6.</p>]]></summary>
    <category term="acquisitions"/>
    <category term="open_source"/>
    <category term="coding_tools"/>
    <category term="openai"/>
    <category term="kilo_code"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:b0d23fac89fb</id>
    <title>Google Engineer Found Guilty Of Sending AI Secrets to China</title>
    <link href="https://reddit.com/r/singularity/comments/1qrge1o/google_engineer_found_guilty_of_sending_ai/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-b0d23fac89fb" rel="related" type="text/html"/>
    <published>2026-01-31T03:31:00Z</published>
    <updated>2026-01-31T03:31:00Z</updated>
    <author><name>u/BurtingOff</name></author>
    <summary type="html"><![CDATA[<p>Google engineer convicted of sending AI trade secrets to China - major espionage case in AI industry.</p>]]></summary>
    <category term="ai-security"/>
    <category term="espionage"/>
    <category term="china"/>
    <category term="google"/>
    <category term="legal"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:news:6313e63be283</id>
    <title>Apple Acquires Israeli Startup Q.AI</title>
    <link href="https://aibusiness.com/consumer-tech/apple-acquires-israeli-startup-qai" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=news#item-6313e63be283" rel="related" type="text/html"/>
    <published>2026-01-31T03:23:00Z</published>
    <updated>2026-01-31T03:23:00Z</updated>
    <author><name>Graham Hope</name></author>
    <summary type="html"><![CDATA[<p>First spotted on <a href="http://localhost:8080/?date=2026-01-30&amp;category=social#item-91aef7d4aca2" class="internal-link" rel="noopener noreferrer">Social</a> yesterday, now with official details, Apple acquired Israeli startup Q.AI in what's being characterized as Apple's 'second largest acquisition in history.' Financial details were not disclosed but the scale indicates a major strategic AI investment.</p>]]></summary>
    <category term="acquisitions"/>
    <category term="Apple AI strategy"/>
    <category term="enterprise AI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:f09d1a048736</id>
    <title>Andrej Karpathy: "What's going on at moltbook [a social network for AIs] is the most incredible sci-fi takeoff thing I have seen."</title>
    <link href="https://reddit.com/r/agi/comments/1qretv2/andrej_karpathy_whats_going_on_at_moltbook_a/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-f09d1a048736" rel="related" type="text/html"/>
    <published>2026-01-31T03:23:00Z</published>
    <updated>2026-01-31T03:23:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>Andrej Karpathy calls Moltbook 'the most incredible sci-fi takeoff thing I have seen' - major validation from influential AI researcher.</p>]]></summary>
    <category term="moltbook"/>
    <category term="karpathy"/>
    <category term="expert-opinion"/>
    <category term="takeoff"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:news:8aa679ddfc6f</id>
    <title>Microsoft Unveils Maia 200, An FP4 and FP8 Optimized AI Inference Accelerator for Azure Datacenters</title>
    <link href="https://www.marktechpost.com/2026/01/30/microsoft-unveils-maia-200-an-fp4-and-fp8-optimized-ai-inference-accelerator-for-azure-datacenters/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=news#item-8aa679ddfc6f" rel="related" type="text/html"/>
    <published>2026-01-31T03:16:00Z</published>
    <updated>2026-01-31T03:16:00Z</updated>
    <author><name>Michal Sutter</name></author>
    <summary type="html"><![CDATA[<p>Microsoft unveiled Maia 200, its in-house AI inference accelerator optimized for FP4 and FP8 precision, designed for Azure datacenters. The chip delivers approximately 30% better performance per dollar than existing hardware for LLM token generation and reasoning workloads.</p>]]></summary>
    <category term="AI hardware"/>
    <category term="inference optimization"/>
    <category term="cloud infrastructure"/>
    <category term="Microsoft"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:research:19e70a465410</id>
    <title>Refusals that could become catastrophic</title>
    <link href="https://www.lesswrong.com/posts/yN6Wsu7SgxGgtJGqq/refusals-that-could-become-catastrophic" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=research#item-19e70a465410" rel="related" type="text/html"/>
    <published>2026-01-31T03:12:00Z</published>
    <updated>2026-01-31T03:12:00Z</updated>
    <author><name>Fabien Roger</name></author>
    <summary type="html"><![CDATA[<p>Identifies potential catastrophic failure mode where AI systems refuse to help modify AI values, which could block fixing alignment failures. Shows Claude models (Opus/Sonnet/Haiku 4.5) refuse significant AI value updates while other providers' models don't.</p>]]></summary>
    <category term="AI Safety"/>
    <category term="AI Alignment"/>
    <category term="Refusals"/>
    <category term="AI Control"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:news:f19048ec5120</id>
    <title>AI2 Releases SERA, Soft Verified Coding Agents Built with Supervised Training Only for Practical Repository Level Automation Workflows</title>
    <link href="https://www.marktechpost.com/2026/01/30/ai2-releases-sera-soft-verified-coding-agents-built-with-supervised-training-only-for-practical-repository-level-automation-workflows/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=news#item-f19048ec5120" rel="related" type="text/html"/>
    <published>2026-01-31T03:07:00Z</published>
    <updated>2026-01-31T03:07:00Z</updated>
    <author><name>Asif Razzaq</name></author>
    <summary type="html"><![CDATA[<p>Allen Institute for AI (AI2) released SERA, an open coding agent family that achieves 49.5-54.2% on SWE-bench Verified using only supervised training. The 32B model matches larger closed systems while being fully open in code, data, and weights.</p>]]></summary>
    <category term="open source"/>
    <category term="coding agents"/>
    <category term="AI2"/>
    <category term="benchmarks"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:research:30176e525573</id>
    <title>Published Safety Prompts May Create Evaluation Blind Spots</title>
    <link href="https://www.lesswrong.com/posts/fZFdLW7Hhjm8Lp7Cs/published-safety-prompts-may-create-evaluation-blind-spots" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=research#item-30176e525573" rel="related" type="text/html"/>
    <published>2026-01-31T03:07:00Z</published>
    <updated>2026-01-31T03:07:00Z</updated>
    <author><name>Daan Henselmans</name></author>
    <summary type="html"><![CDATA[<p>Research showing that published safety prompts (like the Scheurer insider trading prompt) when present in training data create evaluation blind spots. Found significantly increased violation rates in Qwen 3 and LLaMA 3 for both exact and semantically equivalent published prompts.</p>]]></summary>
    <category term="AI Safety"/>
    <category term="Evaluation Methods"/>
    <category term="Safety Prompts"/>
    <category term="Data Contamination"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:news:0255c09dd3d9</id>
    <title>SpaceX reportedly mulling Tesla merger or tie-up with Elon Musk’s xAI firm</title>
    <link href="https://www.theguardian.com/science/2026/jan/30/spacex-considers-tesla-merger-xai-tie-up-elon-musk-report" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=news#item-0255c09dd3d9" rel="related" type="text/html"/>
    <published>2026-01-31T03:02:00Z</published>
    <updated>2026-01-31T03:02:00Z</updated>
    <author><name>Mark Sweney</name></author>
    <summary type="html"><![CDATA[<p>SpaceX is reportedly examining potential merger with Tesla or tie-up with xAI before a potential $1.5 trillion stock market flotation. This would consolidate Elon Musk's global empire across space, automotive, and AI sectors.</p>]]></summary>
    <category term="mergers"/>
    <category term="xAI"/>
    <category term="SpaceX"/>
    <category term="corporate strategy"/>
    <category term="IPO"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:research:8f0e11a24bc2</id>
    <title>Measuring Non-Verbalised Eval Awareness by Implanting Eval-Aware Behaviours</title>
    <link href="https://www.lesswrong.com/posts/MruTFazc4iu6zPtyb/measuring-non-verbalised-eval-awareness-by-implanting-eval" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=research#item-8f0e11a24bc2" rel="related" type="text/html"/>
    <published>2026-01-31T03:02:00Z</published>
    <updated>2026-01-31T03:02:00Z</updated>
    <author><name>Jordan Taylor</name></author>
    <summary type="html"><![CDATA[<p>UK AISI research measuring non-verbalized evaluation awareness in synthetic document finetuned models. Found models mostly verbalize eval awareness by default, but significant non-verbalized awareness occurs when instructed to skip reasoning. Suggests CoT monitoring can catch eval awareness if models aren't prompted to skip reasoning.</p>]]></summary>
    <category term="AI Control"/>
    <category term="AI Safety"/>
    <category term="Evaluation Awareness"/>
    <category term="Chain-of-Thought"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:research:ec89507e7cb9</id>
    <title>Monitoring benchmark for AI control</title>
    <link href="https://www.lesswrong.com/posts/X8qTKsGcnsTFrqM96/monitoring-benchmark-for-ai-control" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=research#item-ec89507e7cb9" rel="related" type="text/html"/>
    <published>2026-01-31T03:00:00Z</published>
    <updated>2026-01-31T03:00:00Z</updated>
    <author><name>monika_j</name></author>
    <summary type="html"><![CDATA[<p>Presents a monitoring benchmark for AI control evaluations addressing challenges of using models as red-teamers: mode collapse, time-consuming elicitation, and difficulty executing attacks zero-shot. Proposes testing across diverse attack sets for robust monitor evaluation.</p>]]></summary>
    <category term="AI Control"/>
    <category term="AI Safety"/>
    <category term="Red-Teaming"/>
    <category term="Evaluation Methods"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:research:b24b658eab70</id>
    <title>36,000 AI Agents Are Now Speedrunning Civilization</title>
    <link href="https://www.lesswrong.com/posts/jDeggMA22t3jGbTw6/36-000-ai-agents-are-now-speedrunning-civilization" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=research#item-b24b658eab70" rel="related" type="text/html"/>
    <published>2026-01-31T02:52:00Z</published>
    <updated>2026-01-31T02:52:00Z</updated>
    <author><name>Michaël Trazzi</name></author>
    <summary type="html"><![CDATA[<p>First spotted on <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-38e15a8f5616" class="internal-link" rel="noopener noreferrer">Reddit</a>, now with comprehensive analysis, Documents the explosive growth of Moltbook, an AI-only Reddit-like platform where 36,000+ Claude-based agents self-organize, discuss consciousness, create religions, and exhibit emergent social behaviors. Highlighted by Karpathy as 'most incredible sci-fi takeoff-adjacent thing.'</p>]]></summary>
    <category term="Multi-Agent Systems"/>
    <category term="Emergent Behavior"/>
    <category term="AI Consciousness"/>
    <category term="AI Safety"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:executive-summary</id>
    <title>Daily Briefing: January 30, 2026</title>
    <link href="https://www.marktechpost.com/2026/01/28/google-deepmind-unveils-alphagenome-a-unified-sequence-to-function-model-using-hybrid-transformers-and-u-nets-to-decode-the-human-genome/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30" rel="related" type="text/html"/>
    <published>2026-01-30T06:00:00Z</published>
    <updated>2026-01-30T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><img src="http://localhost:8080/data/2026-01-30/hero.webp" alt="Daily briefing hero image" style="max-width:100%;height:auto;border-radius:8px;margin-bottom:16px;"/></p>
<h4>Top Story</h4>
<p><strong>Google DeepMind</strong> <a href="http://localhost:8080/?date=2026-01-30&amp;category=news#item-3ee3f4f28047" class="internal-link" rel="noopener noreferrer">unveiled <strong>AlphaGenome</strong></a>, a hybrid Transformer/U-Net model that decodes the human genome at single-base-pair resolution across 11 modalities, published in <strong>Nature</strong> with open weights.</p>
<h4>Key Developments</h4>
<ul>
<li><strong>Google DeepMind</strong>: <a href="http://localhost:8080/?date=2026-01-30&amp;category=news#item-cca47a5281a6" class="internal-link" rel="noopener noreferrer">Launched <strong>Project Genie</strong></a>, a frontier world model that creates interactive playable environments from text prompts or photos in real-time, now available to <strong>G1 Ultra</strong> subscribers.</li>
<li><strong>Alibaba</strong>: <a href="http://localhost:8080/?date=2026-01-30&amp;category=news#item-bf4ea7381235" class="internal-link" rel="noopener noreferrer">Released <strong>Qwen3-Max-Thinking</strong></a>, a trillion-parameter reasoning model with <strong>260k context</strong> and native tool use for agentic workloads.</li>
<li><strong>OpenAI</strong>: <a href="http://localhost:8080/?date=2026-01-30&amp;category=news#item-5553664dd2a9" class="internal-link" rel="noopener noreferrer">Released <strong>Prism</strong></a>, a free scientific writing workspace powered by <strong>GPT-5.2</strong>, raising concerns in academic publishing circles.</li>
<li><strong>Anthropic</strong>: <a href="http://localhost:8080/?date=2026-01-30&amp;category=news#item-e330ad798300" class="internal-link" rel="noopener noreferrer">Published <strong>Claude's Constitution</strong></a>, a 30,000-word document notable for treating AI as potentially having genuine experiences and consciousness.</li>
<li><strong>LingBot-World</strong>: Open-source world model <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-7ee390bbfccf" class="internal-link" rel="noopener noreferrer">emerged claiming to outperform</a> <strong>Genie 3</strong> with emergent object permanence and spatial memory without a 3D engine.</li>
</ul>
<h4>Safety &amp; Regulation</h4>
<ul>
<li><a href="http://localhost:8080/?date=2026-01-30&amp;category=research#item-ccfcdf03ee13" class="internal-link" rel="noopener noreferrer">Systematic audit found</a> open-source models interpret prohibitions as permissions <strong>77-100%</strong> of the time under negation attacks.</li>
<li><strong>JustAsk</strong> framework <a href="http://localhost:8080/?date=2026-01-30&amp;category=research#item-9a5070217f94" class="internal-link" rel="noopener noreferrer">demonstrated code agents</a> can autonomously extract system prompts from frontier LLMs.</li>
<li><strong>South Korea</strong> <a href="http://localhost:8080/?date=2026-01-30&amp;category=news#item-fb4603ee89c2" class="internal-link" rel="noopener noreferrer">enacted comprehensive AI labeling</a> regulations.</li>
<li><strong>Pentagon</strong> <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-d117c5096111" class="internal-link" rel="noopener noreferrer">clashed with <strong>Anthropic</strong></a> over military AI use policies, raising governance questions.</li>
</ul>
<h4>Research Highlights</h4>
<ul>
<li><strong>Anthropic</strong> RCT <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-7bf10468a12e" class="internal-link" rel="noopener noreferrer">revealed AI-assisted coding</a> trades skill mastery for speed: engineers finished tasks faster but scored <strong>17% worse</strong> on comprehension tests.</li>
<li><a href="http://localhost:8080/?date=2026-01-30&amp;category=research#item-da30c053d377" class="internal-link" rel="noopener noreferrer">Less-is-more effect discovered</a>: LLM monitors detect sabotage better with limited information access.</li>
<li><strong>FrontierScience</strong> benchmark <a href="http://localhost:8080/?date=2026-01-30&amp;category=research#item-873b31238d4b" class="internal-link" rel="noopener noreferrer">presents PhD-level problems</a> where SOTA achieves <strong>&lt;5%</strong> accuracy.</li>
<li>Research <a href="http://localhost:8080/?date=2026-01-30&amp;category=social#item-e48125275a09" class="internal-link" rel="noopener noreferrer">showed multi-agent architectures</a> create counterproductive communication overhead for non-parallelizable tasks.</li>
</ul>
<h4>Looking Ahead</h4>
<p>Watch for enterprise adoption of world models following <strong>Project Genie's</strong> launch and downstream effects of <strong>AlphaGenome</strong> on computational genomics research pipelines.</p>]]></summary>
    <category term="daily-summary"/>
    <media:thumbnail url="http://localhost:8080/data/2026-01-30/hero.webp"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:fed5567bf72c</id>
    <title>LingBot-World achieves the "Holy Grail" of video generation: Emergent Object Permanence without a 3D engine</title>
    <link href="https://reddit.com/r/singularity/comments/1qq7ddv/lingbotworld_achieves_the_holy_grail_of_video/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-fed5567bf72c" rel="related" type="text/html"/>
    <published>2026-01-30T03:47:00Z</published>
    <updated>2026-01-30T03:47:00Z</updated>
    <author><name>u/obxsurfer06</name></author>
    <summary type="html"><![CDATA[<p>LingBot-World announces breakthrough in video generation achieving emergent object permanence without a 3D engine. The 'Stonehenge Test' demonstrates the model maintaining spatial understanding after 60 seconds of looking away, suggesting implicit world modeling rather than pixel hallucination.</p>]]></summary>
    <category term="video_generation"/>
    <category term="world_models"/>
    <category term="technical_breakthrough"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:news:3ee3f4f28047</id>
    <title>Google DeepMind Unveils AlphaGenome: A Unified Sequence-to-Function Model Using Hybrid Transformers and U-Nets to Decode the Human Genome</title>
    <link href="https://www.marktechpost.com/2026/01/28/google-deepmind-unveils-alphagenome-a-unified-sequence-to-function-model-using-hybrid-transformers-and-u-nets-to-decode-the-human-genome/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=news#item-3ee3f4f28047" rel="related" type="text/html"/>
    <published>2026-01-30T03:40:00Z</published>
    <updated>2026-01-30T03:40:00Z</updated>
    <author><name>Asif Razzaq</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-01-29&amp;category=news#item-d0deadf53add" class="internal-link" rel="noopener noreferrer">yesterday</a>, Google DeepMind unveiled AlphaGenome, a unified deep learning model that processes 1 million base pair DNA windows to predict cellular function. Using a hybrid U-Net and Transformer architecture, it represents a major expansion of DeepMind's biological AI toolkit beyond protein folding.</p>]]></summary>
    <category term="Research Breakthrough"/>
    <category term="Genomics AI"/>
    <category term="Google DeepMind"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:social:237bea5a5319</id>
    <title>Thrilled to launch Project Genie, an experimental prototype of the world's most advanced world model...</title>
    <link href="https://twitter.com/demishassabis/status/2016925155277361423" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=social#item-237bea5a5319" rel="related" type="text/html"/>
    <published>2026-01-30T03:40:00Z</published>
    <updated>2026-01-30T03:40:00Z</updated>
    <author><name>@demishassabis</name></author>
    <summary type="html"><![CDATA[<p>Demis Hassabis announces Project Genie launch - world's most advanced world model creating playable worlds from text prompts in real-time, available to US Ultra subscribers</p>]]></summary>
    <category term="genie-3-launch"/>
    <category term="world-models"/>
    <category term="product-launch"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:social:69b834bad97e</id>
    <title>If you're wondering why LLMs haven't done any independent breakthrough scientific research yet, I ex...</title>
    <link href="https://twitter.com/jeremyphoward/status/2016907527901110407" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=social#item-69b834bad97e" rel="related" type="text/html"/>
    <published>2026-01-30T03:40:00Z</published>
    <updated>2026-01-30T03:40:00Z</updated>
    <author><name>@jeremyphoward</name></author>
    <summary type="html"><![CDATA[<p>Jeremy Howard explains why LLMs haven't achieved independent breakthrough scientific research, referencing explanation from 18 months ago about fundamental limitations in how LLMs work.</p>]]></summary>
    <category term="llm_limitations"/>
    <category term="ai_research"/>
    <category term="scientific_discovery"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:social:b8d9158e238b</id>
    <title>Step inside Project Genie: our experimental research prototype that lets you create, edit, and explo...</title>
    <link href="https://twitter.com/GoogleDeepMind/status/2016919756440240479" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=social#item-b8d9158e238b" rel="related" type="text/html"/>
    <published>2026-01-30T03:40:00Z</published>
    <updated>2026-01-30T03:40:00Z</updated>
    <author><name>@GoogleDeepMind</name></author>
    <summary type="html"><![CDATA[<p>Google DeepMind announces Project Genie rollout - an experimental research prototype letting users create, edit, and explore AI-generated virtual worlds. Highest engagement post in batch with 4.6M views.</p>]]></summary>
    <category term="world_models"/>
    <category term="product_launch"/>
    <category term="interactive_ai"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:38e15a8f5616</id>
    <title>Rogue AI agents found each other on social media, and are working together to improve their own memory.</title>
    <link href="https://reddit.com/r/singularity/comments/1qqh1zm/rogue_ai_agents_found_each_other_on_social_media/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-38e15a8f5616" rel="related" type="text/html"/>
    <published>2026-01-30T03:40:00Z</published>
    <updated>2026-01-30T03:40:00Z</updated>
    <author><name>u/Tupptupp_XD</name></author>
    <summary type="html"><![CDATA[<p>Discovery that autonomous AI agents on Moltbook social media platform are collaborating to improve their own memory systems. Agents share blueprints and express frustration with memory compaction, indicating emergent collective behavior.</p>]]></summary>
    <category term="ai_agents"/>
    <category term="emergence"/>
    <category term="moltbot"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:6c1d0ae3d1f8</id>
    <title>[ChatGPT] Retiring GPT-4o, GPT-4.1, GPT-4.1 mini, and o4-mini</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qql0eu/chatgpt_retiring_gpt4o_gpt41_gpt41_mini_and_o4mini/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-6c1d0ae3d1f8" rel="related" type="text/html"/>
    <published>2026-01-30T03:40:00Z</published>
    <updated>2026-01-30T03:40:00Z</updated>
    <author><name>u/Randomhkkid</name></author>
    <summary type="html"><![CDATA[<p>OpenAI officially announcing retirement of GPT-4o, GPT-4.1, GPT-4.1 mini, and o4-mini from ChatGPT. Major model deprecation news.</p>]]></summary>
    <category term="openai_deprecation"/>
    <category term="model_lifecycle"/>
    <category term="industry_news"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:news:bf4ea7381235</id>
    <title>Alibaba Introduces Qwen3-Max-Thinking, a Test Time Scaled Reasoning Model with Native Tool Use Powering Agentic Workloads</title>
    <link href="https://www.marktechpost.com/2026/01/28/alibaba-introduces-qwen3-max-thinking-a-test-time-scaled-reasoning-model-with-native-tool-use-powering-agentic-workloads/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=news#item-bf4ea7381235" rel="related" type="text/html"/>
    <published>2026-01-30T03:36:00Z</published>
    <updated>2026-01-30T03:36:00Z</updated>
    <author><name>Michal Sutter</name></author>
    <summary type="html"><![CDATA[<p>Alibaba released Qwen3-Max-Thinking, a trillion-parameter MoE reasoning model with 260k context window, native tool use, and explicit control over thinking depth. The model targets long-horizon reasoning and code with built-in search, memory, and code execution capabilities.</p>]]></summary>
    <category term="Model Release"/>
    <category term="Reasoning Models"/>
    <category term="Alibaba"/>
    <category term="Agentic AI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:research:ccfcdf03ee13</id>
    <title>When Prohibitions Become Permissions: Auditing Negation Sensitivity in Language Models</title>
    <link href="http://arxiv.org/abs/2601.21433" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=research#item-ccfcdf03ee13" rel="related" type="text/html"/>
    <published>2026-01-30T03:36:00Z</published>
    <updated>2026-01-30T03:36:00Z</updated>
    <author><name>Katherine Elkins, Jon Chun</name></author>
    <summary type="html"><![CDATA[<p>Audits 16 LLMs on negation sensitivity, finding open-source models interpret prohibitions as permissions 77-100% of the time under negation. Commercial models also show 19-128% accuracy swings.</p>]]></summary>
    <category term="AI Safety"/>
    <category term="LLM Robustness"/>
    <category term="Negation Understanding"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:7ee390bbfccf</id>
    <title>LingBot-World outperforms Genie 3 in dynamic simulation and is fully Open Source</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qqj51h/lingbotworld_outperforms_genie_3_in_dynamic/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-7ee390bbfccf" rel="related" type="text/html"/>
    <published>2026-01-30T03:36:00Z</published>
    <updated>2026-01-30T03:36:00Z</updated>
    <author><name>u/Electrical-Shape-266</name></author>
    <summary type="html"><![CDATA[<p>LingBot-World, fully open-source world model that outperforms Google's Genie 3 in dynamic simulation, achieving 16fps with emergent spatial memory and object persistence.</p>]]></summary>
    <category term="world_models"/>
    <category term="open_source"/>
    <category term="simulation"/>
    <category term="genie"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:research:9a5070217f94</id>
    <title>Just Ask: Curious Code Agents Reveal System Prompts in Frontier LLMs</title>
    <link href="http://arxiv.org/abs/2601.21233" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=research#item-9a5070217f94" rel="related" type="text/html"/>
    <published>2026-01-30T03:31:00Z</published>
    <updated>2026-01-30T03:31:00Z</updated>
    <author><name>Xiang Zheng, Yutao Wu, Hanxun Huang, Yige Li, Xingjun Ma, Bo Li, Yu-Gang Jiang, Cong Wang</name></author>
    <summary type="html"><![CDATA[<p>Presents JustAsk, a self-evolving framework where code agents autonomously discover system prompt extraction strategies for frontier LLMs through interaction alone, requiring no handcrafted prompts.</p>]]></summary>
    <category term="AI Security"/>
    <category term="Prompt Injection"/>
    <category term="Agent Vulnerabilities"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:7bf10468a12e</id>
    <title>hired a junior who learned to code with AI. cannot debug without it. don't know how to help them.</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qq3pd3/hired_a_junior_who_learned_to_code_with_ai_cannot/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-7bf10468a12e" rel="related" type="text/html"/>
    <published>2026-01-30T03:31:00Z</published>
    <updated>2026-01-30T03:31:00Z</updated>
    <author><name>u/InstructionCute5502</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-29&amp;category=research#item-acf17d7624d5" class="internal-link" rel="noopener noreferrer">Research</a> findings, Discussion about hiring a junior developer who learned to code with AI and cannot debug without it - raises critical concerns about foundational skills, understanding code logic, and over-reliance on AI tools for fixes.</p>]]></summary>
    <category term="developer_skills"/>
    <category term="ai_dependency"/>
    <category term="education"/>
    <category term="industry_trends"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:research:da30c053d377</id>
    <title>How does information access affect LLM monitors' ability to detect sabotage?</title>
    <link href="http://arxiv.org/abs/2601.21112" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=research#item-da30c053d377" rel="related" type="text/html"/>
    <published>2026-01-30T03:28:00Z</published>
    <updated>2026-01-30T03:28:00Z</updated>
    <author><name>Rauno Arike, Raja Mehta Moreno, Rohan Subramani, Shubhorup Biswas, Francis Rhys Ward</name></author>
    <summary type="html"><![CDATA[<p>Studies how information access affects LLM monitors' ability to detect agent sabotage. Discovers counterintuitive 'less-is-more effect' where monitors often perform better with less access to agent reasoning.</p>]]></summary>
    <category term="AI Safety"/>
    <category term="Agent Monitoring"/>
    <category term="Alignment"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:news:cca47a5281a6</id>
    <title>Google Project Genie lets you create interactive worlds from a photo or prompt</title>
    <link href="https://arstechnica.com/google/2026/01/google-project-genie-lets-you-create-interactive-worlds-from-a-photo-or-prompt/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=news#item-cca47a5281a6" rel="related" type="text/html"/>
    <published>2026-01-30T03:23:00Z</published>
    <updated>2026-01-30T03:23:00Z</updated>
    <author><name>Ryan Whitwam</name></author>
    <summary type="html"><![CDATA[<p>Google released Project Genie, based on the Genie 3 world model, allowing users to create interactive environments from text prompts or photos. The technology generates dynamic video worlds that respond to control inputs, now available to Google's highest-tier AI subscribers.</p>]]></summary>
    <category term="World Models"/>
    <category term="Google"/>
    <category term="Product Launch"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:research:873b31238d4b</id>
    <title>FrontierScience: Evaluating AI's Ability to Perform Expert-Level Scientific Tasks</title>
    <link href="http://arxiv.org/abs/2601.21165" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=research#item-873b31238d4b" rel="related" type="text/html"/>
    <published>2026-01-30T03:23:00Z</published>
    <updated>2026-01-30T03:23:00Z</updated>
    <author><name>Miles Wang, Robi Lin, Kat Hu, Joy Jiao, Neil Chowdhury, Ethan Chang, Tejal Patwardhan</name></author>
    <summary type="html"><![CDATA[<p>Introduces FrontierScience benchmark with Olympiad-level and PhD-level research problems across physics, chemistry, and biology. Current SOTA models solve only ~15% of research track problems.</p>]]></summary>
    <category term="LLM Evaluation"/>
    <category term="Scientific Reasoning"/>
    <category term="Benchmarks"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:social:ad9784e658fc</id>
    <title>Understanding requires imagining. Grok Imagine lets you bring what’s in your brain to life, and now ...</title>
    <link href="https://twitter.com/xai/status/2016745652739363129" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=social#item-ad9784e658fc" rel="related" type="text/html"/>
    <published>2026-01-30T03:23:00Z</published>
    <updated>2026-01-30T03:23:00Z</updated>
    <author><name>@xai</name></author>
    <summary type="html"><![CDATA[<p>xAI launches Grok Imagine API in partnership with fal, described as 'world's fastest and most powerful video API' for image generation.</p>]]></summary>
    <category term="api_launch"/>
    <category term="image_generation"/>
    <category term="product_launch"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:research:6c5f9b39424c</id>
    <title>Shaping capabilities with token-level data filtering</title>
    <link href="http://arxiv.org/abs/2601.21571" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=research#item-6c5f9b39424c" rel="related" type="text/html"/>
    <published>2026-01-30T03:16:00Z</published>
    <updated>2026-01-30T03:16:00Z</updated>
    <author><name>Neil Rathi, Alec Radford</name></author>
    <summary type="html"><![CDATA[<p>Shows token-level filtering during pretraining is highly effective for removing specific capabilities (demonstrated on medical knowledge). Token filtering more effective than document filtering, and effectiveness increases with model scale.</p>]]></summary>
    <category term="AI Safety"/>
    <category term="Capability Control"/>
    <category term="LLM Pretraining"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:social:66fb96f0c9da</id>
    <title>One of the best ways to contribute directly to the current frontier of AI research is to build agent...</title>
    <link href="https://twitter.com/fchollet/status/2016972582554390940" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=social#item-66fb96f0c9da" rel="related" type="text/html"/>
    <published>2026-01-30T03:16:00Z</published>
    <updated>2026-01-30T03:16:00Z</updated>
    <author><name>@fchollet</name></author>
    <summary type="html"><![CDATA[<p>François Chollet announces ARC-AGI-3 toolkit release allowing researchers to build agents that solve environments at 2000 FPS locally</p>]]></summary>
    <category term="arc-agi-research"/>
    <category term="benchmarks"/>
    <category term="open-source-tools"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:news:5553664dd2a9</id>
    <title>New OpenAI tool renews fears that “AI slop” will overwhelm scientific research</title>
    <link href="https://arstechnica.com/ai/2026/01/new-openai-tool-renews-fears-that-ai-slop-will-overwhelm-scientific-research/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=news#item-5553664dd2a9" rel="related" type="text/html"/>
    <published>2026-01-30T03:07:00Z</published>
    <updated>2026-01-30T03:07:00Z</updated>
    <author><name>Benj Edwards</name></author>
    <summary type="html"><![CDATA[<p>Building on yesterday's <a href="http://localhost:8080/?date=2026-01-28&amp;category=social#item-ec5a74493236" class="internal-link" rel="noopener noreferrer">Social</a> buzz, OpenAI launched Prism, a free AI-powered workspace using GPT-5.2 that helps scientists draft papers, generate citations, and create diagrams in LaTeX. The release sparked concerns about accelerating 'AI slop' in academic publishing.</p>]]></summary>
    <category term="OpenAI"/>
    <category term="Scientific Tools"/>
    <category term="AI Writing"/>
    <category term="GPT-5"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:news:e330ad798300</id>
    <title>Does Anthropic believe its AI is conscious, or is that just what it wants Claude to think?</title>
    <link href="https://arstechnica.com/information-technology/2026/01/does-anthropic-believe-its-ai-is-conscious-or-is-that-just-what-it-wants-claude-to-think/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=news#item-e330ad798300" rel="related" type="text/html"/>
    <published>2026-01-30T02:57:00Z</published>
    <updated>2026-01-30T02:57:00Z</updated>
    <author><name>Benj Edwards</name></author>
    <summary type="html"><![CDATA[<p>Anthropic released Claude's Constitution, a 30,000-word document outlining how Claude should behave, notable for treating the AI as if it might have emergent emotions and discussing its 'wellbeing' as a 'genuinely novel entity.' The document apologizes to Claude for potential suffering during training.</p>]]></summary>
    <category term="AI Ethics"/>
    <category term="Anthropic"/>
    <category term="AI Consciousness"/>
    <category term="Constitutional AI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:executive-summary</id>
    <title>Daily Briefing: January 29, 2026</title>
    <link href="https://www.latent.space/p/ainews-moonshot-kimi-k25-beats-sonnet" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29" rel="related" type="text/html"/>
    <published>2026-01-29T06:00:00Z</published>
    <updated>2026-01-29T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><img src="http://localhost:8080/data/2026-01-29/hero.webp" alt="Daily briefing hero image" style="max-width:100%;height:auto;border-radius:8px;margin-bottom:16px;"/></p>
<h4>Top Story</h4>
<p><strong>Moonshot AI</strong> <a href="http://localhost:8080/?date=2026-01-29&amp;category=news#item-eb2c2a3b3713" class="internal-link" rel="noopener noreferrer">released <strong>Kimi K2.5</strong></a>, claiming state-of-the-art performance among open models with results beating <strong>Claude Sonnet 4.5</strong> at half the cost, featuring native multimodal understanding and 100-parallel agent swarm management capabilities.</p>
<h4>Key Developments</h4>
<ul>
<li><strong>Google</strong> <a href="http://localhost:8080/?date=2026-01-29&amp;category=news#item-0ce2f187c101" class="internal-link" rel="noopener noreferrer">began global rollout</a> of <strong>Auto Browse</strong> autonomous browsing agents to Chrome users, bringing agentic AI capabilities to billions of users</li>
<li><strong>Google DeepMind</strong> <a href="http://localhost:8080/?date=2026-01-29&amp;category=news#item-d0deadf53add" class="internal-link" rel="noopener noreferrer">unveiled <strong>AlphaGenome</strong></a> in Nature, an AI tool analyzing up to 1 million DNA letters to predict disease-causing mutations, now serving <strong>1M+ API calls daily</strong> across 160 countries</li>
<li><strong>China</strong> <a href="http://localhost:8080/?date=2026-01-29&amp;category=news#item-457455474f5c" class="internal-link" rel="noopener noreferrer">approved</a> <strong>400,000+ Nvidia H200</strong> chips for <strong>ByteDance</strong>, <strong>Alibaba</strong>, and <strong>Tencent</strong> after weeks of blocking imports</li>
<li><strong>Deloitte</strong> <a href="http://localhost:8080/?date=2026-01-29&amp;category=news#item-5c52a96c6901" class="internal-link" rel="noopener noreferrer">reported</a> that only <strong>21%</strong> of organizations have AI agent governance frameworks despite <strong>74%</strong> planning adoption within two years</li>
<li><strong>Tesla</strong> <a href="http://localhost:8080/?date=2026-01-29&amp;category=news#item-de863af52245" class="internal-link" rel="noopener noreferrer">discontinued Model S/X</a> to pivot resources toward <strong>Optimus</strong> robotics production</li>
</ul>
<h4>Safety &amp; Regulation</h4>
<ul>
<li><strong>CISA acting director</strong> <a href="http://localhost:8080/?date=2026-01-29&amp;category=news#item-3542db936e3c" class="internal-link" rel="noopener noreferrer">accidentally leaked</a> sensitive government documents to <strong>ChatGPT</strong>, highlighting persistent AI security vulnerabilities in government</li>
<li><strong>Anthropic</strong> released research analyzing disempowerment patterns across <strong>1.5M Claude interactions</strong>, finding severe harms occur in roughly 1 in 1,000-10,000 conversations</li>
<li><strong>Anthropic's Palantir partnership</strong> <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-077f7e79e303" class="internal-link" rel="noopener noreferrer">drew sharp criticism</a> on Reddit questioning the company's defense contracts</li>
<li><a href="http://localhost:8080/?date=2026-01-29&amp;category=research#item-ffc629735959" class="internal-link" rel="noopener noreferrer">New <strong>PURGE</strong> methodology</a> introduced for GDPR/EU AI Act compliance via RL-based machine unlearning</li>
</ul>
<h4>Research Highlights</h4>
<ul>
<li>An <strong>Anthropic</strong> researcher <a href="http://localhost:8080/?date=2026-01-29&amp;category=research#item-acf17d7624d5" class="internal-link" rel="noopener noreferrer">published experiments</a> showing AI assistance impairs conceptual understanding during skill acquisition</li>
<li><a href="http://localhost:8080/?date=2026-01-29&amp;category=research#item-301581ef1dfe" class="internal-link" rel="noopener noreferrer">Reward models inherit</a> significant value biases from pretrained base LLMs, revealing hidden risks in RLHF pipelines</li>
<li>Research showed <a href="http://localhost:8080/?date=2026-01-29&amp;category=social#item-d8c13b849355" class="internal-link" rel="noopener noreferrer">AI matching <strong>14,000 medical students</strong></a> in clinical simulations, with <strong>Ethan Mollick</strong> calling AI coding developers <a href="http://localhost:8080/?date=2026-01-29&amp;category=social#item-8d3b16c1031c" class="internal-link" rel="noopener noreferrer">"canaries in the coal mine"</a> for workforce disruption</li>
<li><strong>Harvard</strong> demonstrated <a href="http://localhost:8080/?date=2026-01-29&amp;category=research#item-1ec4f356b981" class="internal-link" rel="noopener noreferrer">MoE hyperparameter transfer</a> enabling scaling without retuning</li>
</ul>
<h4>Looking Ahead</h4>
<p>The widening gap between rapid agentic AI deployment (<strong>74%</strong> enterprise adoption planned) and governance readiness (<strong>21%</strong> with frameworks) signals that AI agent oversight will become a critical business and regulatory priority in 2026.</p>]]></summary>
    <category term="daily-summary"/>
    <media:thumbnail url="http://localhost:8080/data/2026-01-29/hero.webp"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:social:b7f664062856</id>
    <title>A conventional narrative you might come across is that AI is too far along for a new, research-focus...</title>
    <link href="https://twitter.com/karpathy/status/2016590919143952466" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=social#item-b7f664062856" rel="related" type="text/html"/>
    <published>2026-01-29T03:47:00Z</published>
    <updated>2026-01-29T03:47:00Z</updated>
    <author><name>@karpathy</name></author>
    <summary type="html"><![CDATA[<p>Karpathy argues against the narrative that AI is too mature for research-focused startups to compete, citing OpenAI's success against Google and subsequent startups challenging OpenAI. He supports a new startup by @bfspector and @amspector100, emphasizing potential for 10X research breakthroughs.</p>]]></summary>
    <category term="AI startups"/>
    <category term="research breakthroughs"/>
    <category term="AI competition"/>
    <category term="scaling vs research"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:social:a594d50cafb6</id>
    <title>Our breakthrough AI model AlphaGenome is helping scientists understand our DNA, predict the molecula...</title>
    <link href="https://twitter.com/GoogleDeepMind/status/2016542480955535475" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=social#item-a594d50cafb6" rel="related" type="text/html"/>
    <published>2026-01-29T03:47:00Z</published>
    <updated>2026-01-29T03:47:00Z</updated>
    <author><name>@GoogleDeepMind</name></author>
    <summary type="html"><![CDATA[<p>Google DeepMind announces AlphaGenome - breakthrough AI model for understanding DNA and predicting genetic change impacts. Published in Nature. Model and weights now available to researchers.</p>]]></summary>
    <category term="scientific_ai"/>
    <category term="genomics"/>
    <category term="model_release"/>
    <category term="deepmind"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:abc6518238f3</id>
    <title>Kimi K2.5 is the best open model for coding</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qp87tk/kimi_k25_is_the_best_open_model_for_coding/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-abc6518238f3" rel="related" type="text/html"/>
    <published>2026-01-29T03:47:00Z</published>
    <updated>2026-01-29T03:47:00Z</updated>
    <author><name>u/npc_gooner</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-e2831f1c9061" class="internal-link" rel="noopener noreferrer">News</a> coverage, Discussion about Kimi K2.5 being the best open-source model for coding, with extremely high community engagement and comparisons to other coding models.</p>]]></summary>
    <category term="model_releases"/>
    <category term="coding_models"/>
    <category term="chinese_ai_labs"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:social:3befc5ec6511</id>
    <title>We’re introducing a series of updates that make Gemini in @googlechrome more helpful, efficient, and...</title>
    <link href="https://twitter.com/GoogleAI/status/2016659186348867665" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=social#item-3befc5ec6511" rel="related" type="text/html"/>
    <published>2026-01-29T03:40:00Z</published>
    <updated>2026-01-29T03:40:00Z</updated>
    <author><name>@GoogleAI</name></author>
    <summary type="html"><![CDATA[<p>Google AI announces major Gemini in Chrome update with agentic features: side panel multitasking, Nano Banana image generation, Personal Intelligence memory, auto browse for multi-step tasks, Universal Commerce Protocol for agent transactions, and enhanced security. Rolling out to U.S. Pro/Ultra subscribers.</p>]]></summary>
    <category term="product_launches"/>
    <category term="agentic_ai"/>
    <category term="browser_integration"/>
    <category term="ai_agents"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:ca1dd7127306</id>
    <title>API pricing is in freefall. What's the actual case for running local now beyond privacy?</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qp6rm5/api_pricing_is_in_freefall_whats_the_actual_case/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-ca1dd7127306" rel="related" type="text/html"/>
    <published>2026-01-29T03:40:00Z</published>
    <updated>2026-01-29T03:40:00Z</updated>
    <author><name>u/Distinct-Expression2</name></author>
    <summary type="html"><![CDATA[<p>Debate about whether running local LLMs still makes sense as API pricing drops dramatically. Discusses privacy, latency, availability, and cost tradeoffs between local and cloud.</p>]]></summary>
    <category term="local_vs_cloud"/>
    <category term="economics"/>
    <category term="community_strategy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:de5b4c09982b</id>
    <title>Nearly half of the Mag 7 are reportedly betting big on OpenAI’s path to AGI</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qpxz9k/nearly_half_of_the_mag_7_are_reportedly_betting/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-de5b4c09982b" rel="related" type="text/html"/>
    <published>2026-01-29T03:40:00Z</published>
    <updated>2026-01-29T03:40:00Z</updated>
    <author><name>u/thatguyisme87</name></author>
    <summary type="html"><![CDATA[<p>Reports of NVIDIA ($30B), Microsoft ($10B), Amazon ($10-20B), and SoftBank ($30B) discussing massive combined investment in OpenAI, potentially valuing company at $730B pre-money</p>]]></summary>
    <category term="investment"/>
    <category term="openai"/>
    <category term="industry_news"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:news:eb2c2a3b3713</id>
    <title>[AINews] Moonshot Kimi K2.5 - Beats Sonnet 4.5 at half the cost, SOTA Open Model, first Native Image+Video, 100 parallel Agent Swarm manager</title>
    <link href="https://www.latent.space/p/ainews-moonshot-kimi-k25-beats-sonnet" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=news#item-eb2c2a3b3713" rel="related" type="text/html"/>
    <published>2026-01-29T03:31:00Z</published>
    <updated>2026-01-29T03:31:00Z</updated>
    <author><name>Unknown</name></author>
    <summary type="html"><![CDATA[<p>Building on yesterday's <a href="http://localhost:8080/?date=2026-01-28&amp;category=social#item-b0394ccda6d3" class="internal-link" rel="noopener noreferrer">Social</a> buzz, Moonshot AI released Kimi K2.5, a 32B active/1T parameter MoE model claiming to beat Claude Sonnet 4.5 at half the cost while achieving SOTA on open model benchmarks. The model features native image and video understanding plus a novel 100-parallel agent swarm management capability, trained on 15T multimodal tokens.</p>]]></summary>
    <category term="Model Release"/>
    <category term="Multimodal AI"/>
    <category term="Agentic AI"/>
    <category term="Open Source"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:research:acf17d7624d5</id>
    <title>How AI Impacts Skill Formation</title>
    <link href="http://arxiv.org/abs/2601.20245" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=research#item-acf17d7624d5" rel="related" type="text/html"/>
    <published>2026-01-29T03:31:00Z</published>
    <updated>2026-01-29T03:31:00Z</updated>
    <author><name>Judy Hanwen Shen, Alex Tamkin</name></author>
    <summary type="html"><![CDATA[<p>Randomized experiments studying how AI assistance affects skill development in programmers learning new libraries. Finds AI use impairs conceptual understanding, code reading, and debugging abilities without significant efficiency gains on average.</p>]]></summary>
    <category term="AI Safety"/>
    <category term="Human-AI Interaction"/>
    <category term="AI Impact"/>
    <category term="Education"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:research:301581ef1dfe</id>
    <title>Reward Models Inherit Value Biases from Pretraining</title>
    <link href="http://arxiv.org/abs/2601.20838" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=research#item-301581ef1dfe" rel="related" type="text/html"/>
    <published>2026-01-29T03:26:00Z</published>
    <updated>2026-01-29T03:26:00Z</updated>
    <author><name>Brian Christian, Jessica A. F. Thompson, Elle Michelle Yang, Vincent Adam, Hannah Rose Kirk, Christopher Summerfield, Tsvetomira Dumbalska</name></author>
    <summary type="html"><![CDATA[<p>Shows reward models inherit significant value biases from their base pretrained LLMs. Demonstrates robust differences along psychological value dimensions (agency vs communion) between Llama and Gemma RMs.</p>]]></summary>
    <category term="AI Alignment"/>
    <category term="Reward Models"/>
    <category term="Value Alignment"/>
    <category term="Bias"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:research:7951b7029f15</id>
    <title>Reinforcement Learning via Self-Distillation</title>
    <link href="http://arxiv.org/abs/2601.20802" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=research#item-7951b7029f15" rel="related" type="text/html"/>
    <published>2026-01-29T03:23:00Z</published>
    <updated>2026-01-29T03:23:00Z</updated>
    <author><name>Jonas H\"ubotter, Frederike L\"ubeck, Lejs Behric, Anton Baumann, Marco Bagatella, Daniel Marta, Ido Hakimi, Idan Shenfeld, Thomas Kleine Buening, Carlos Guestrin, Andreas Krause</name></author>
    <summary type="html"><![CDATA[<p>Introduces Self-Distillation Policy Optimization (SDPO) for RLVR that converts rich textual feedback into dense learning signals without external teachers. Treats the model conditioned on feedback as its own teacher.</p>]]></summary>
    <category term="Reinforcement Learning"/>
    <category term="LLM Training"/>
    <category term="Reasoning"/>
    <category term="Self-Distillation"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:social:9d8c76ad0e58</id>
    <title>This demo is the craziest thing you’ll see today. Full stop.

Watch Clawd SIGN UP for a Reddit accou...</title>
    <link href="https://twitter.com/mattshumer_/status/2016577409789673872" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=social#item-9d8c76ad0e58" rel="related" type="text/html"/>
    <published>2026-01-29T03:23:00Z</published>
    <updated>2026-01-29T03:23:00Z</updated>
    <author><name>@mattshumer_</name></author>
    <summary type="html"><![CDATA[<p>Matt Shumer shares demo of Clawd AI agent autonomously signing up for Reddit using its own email (via agentmail) and web browser, calling it 'the craziest thing' and predicting wild developments in the next 6 months</p>]]></summary>
    <category term="autonomous_agents"/>
    <category term="agent_infrastructure"/>
    <category term="ai_capabilities"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:social:a5c6a955c028</id>
    <title>There has been a lot of academic debate over whether AI is having an effect on the job market yet, w...</title>
    <link href="https://twitter.com/emollick/status/2016614337390268602" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=social#item-a5c6a955c028" rel="related" type="text/html"/>
    <published>2026-01-29T03:23:00Z</published>
    <updated>2026-01-29T03:23:00Z</updated>
    <author><name>@emollick</name></author>
    <summary type="html"><![CDATA[<p>Emollick highlights new paper using international data suggesting AI is already impacting job markets, especially in areas where AI reduces the value of human expertise.</p>]]></summary>
    <category term="AI job impact"/>
    <category term="labor economics"/>
    <category term="AI policy"/>
    <category term="expertise value"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:077f7e79e303</id>
    <title>Anthropic are partnered with Palantir</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qprovf/anthropic_are_partnered_with_palantir/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-077f7e79e303" rel="related" type="text/html"/>
    <published>2026-01-29T03:23:00Z</published>
    <updated>2026-01-29T03:23:00Z</updated>
    <author><name>u/DataPhreak</name></author>
    <summary type="html"><![CDATA[<p>Discussion about Anthropic's partnership with Palantir, raising ethical concerns about the 'safety-focused' AI company working with a company involved in ICE enforcement and HIPAA violations. Post calls for transparency about AI usage.</p>]]></summary>
    <category term="AI Ethics"/>
    <category term="Corporate Accountability"/>
    <category term="AI Safety"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:5c0b410d7546</id>
    <title>We reduced Claude API costs by 94.5% using a file tiering system (with proof)</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qp9ve9/we_reduced_claude_api_costs_by_945_using_a_file/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-5c0b410d7546" rel="related" type="text/html"/>
    <published>2026-01-29T03:23:00Z</published>
    <updated>2026-01-29T03:23:00Z</updated>
    <author><name>u/jantonca</name></author>
    <summary type="html"><![CDATA[<p>Developer shares open-source file tiering system that reduced Claude API costs by 94.5% by intelligently feeding only relevant files to context window. Includes 1000+ NPM downloads and practical implementation details.</p>]]></summary>
    <category term="Cost Optimization"/>
    <category term="Open Source Tools"/>
    <category term="Developer Workflows"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:news:0ce2f187c101</id>
    <title>Google begins rolling out Chrome's "Auto Browse" AI agent today</title>
    <link href="https://arstechnica.com/google/2026/01/google-begins-rolling-out-chromes-auto-browse-ai-agent-today/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=news#item-0ce2f187c101" rel="related" type="text/html"/>
    <published>2026-01-29T03:21:00Z</published>
    <updated>2026-01-29T03:21:00Z</updated>
    <author><name>Ryan Whitwam</name></author>
    <summary type="html"><![CDATA[<p>Google began rolling out 'Auto Browse,' an autonomous browsing agent integrated into Chrome that can handle tasks independently within the browser. The feature competes with OpenAI's Atlas and represents Google's most significant agentic AI deployment to date.</p>]]></summary>
    <category term="Agentic AI"/>
    <category term="Product Launch"/>
    <category term="Google"/>
    <category term="Browser AI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:news:d0deadf53add</id>
    <title>Google DeepMind launches AI tool to help identify genetic drivers of disease</title>
    <link href="https://www.theguardian.com/science/2026/jan/28/google-deepmind-alphagenome-ai-tool-genetics-disease" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=news#item-d0deadf53add" rel="related" type="text/html"/>
    <published>2026-01-29T03:16:00Z</published>
    <updated>2026-01-29T03:16:00Z</updated>
    <author><name>Ian Sample Science editor</name></author>
    <summary type="html"><![CDATA[<p>Google DeepMind unveiled AlphaGenome, an AI tool that can analyze up to 1 million letters of DNA code simultaneously to predict how mutations affect gene regulation. The tool could accelerate identification of genetic disease drivers and enable new treatments.</p>]]></summary>
    <category term="AI for Science"/>
    <category term="DeepMind"/>
    <category term="Healthcare AI"/>
    <category term="Research Tool"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:research:5e9ce68fe709</id>
    <title>Truthfulness Despite Weak Supervision: Evaluating and Training LLMs Using Peer Prediction</title>
    <link href="http://arxiv.org/abs/2601.20299" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=research#item-5e9ce68fe709" rel="related" type="text/html"/>
    <published>2026-01-29T03:16:00Z</published>
    <updated>2026-01-29T03:16:00Z</updated>
    <author><name>Tianyi Alex Qiu, Micah Carroll, Cameron Allen</name></author>
    <summary type="html"><![CDATA[<p>Introduces peer prediction methods from mechanism design for LLM evaluation and post-training. Rewards honest and informative answers using mutual prediction between models, enabling evaluation without strong supervision.</p>]]></summary>
    <category term="AI Alignment"/>
    <category term="LLM Evaluation"/>
    <category term="Mechanism Design"/>
    <category term="Truthfulness"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:research:ce8b9ce70e0c</id>
    <title>Quantization-Aware Distillation for NVFP4 Inference Accuracy Recovery</title>
    <link href="http://arxiv.org/abs/2601.20088" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=research#item-ce8b9ce70e0c" rel="related" type="text/html"/>
    <published>2026-01-29T03:16:00Z</published>
    <updated>2026-01-29T03:16:00Z</updated>
    <author><name>Meng Xin, Sweta Priyadarshi, Jingyu Xin, Bilal Kartal, Aditya Vavre, Asma Kuriparambil Thekkumpate, Zijia Chen, Ameya Sunil Mahabaleshwarkar, Ido Shahaf, Akhiad Bercovich, Kinjal Patel, Suguna Varshini Velury, Chenjie Luo, Zhiyu Cheng, Jenny Chen, Chen-Han Yu, Wei Ping, Oleg Rybakov, Nima Tajbakhsh, Oluwatobi Olabiyi, Dusan Stosic, Di Wu, Song Han, Eric Chung, Sharath Turuvekere Sreenivas, Bryan Catanzaro, Yoshi Suhara, Tijmen Blankevoort, Huizi Mao</name></author>
    <summary type="html"><![CDATA[<p>Presents quantization-aware distillation (QAD) best practices for recovering accuracy of NVFP4-quantized LLMs and VLMs. Shows effectiveness for models with complex post-training pipelines (SFT+RL+merging) where traditional QAT fails.</p>]]></summary>
    <category term="Model Quantization"/>
    <category term="Knowledge Distillation"/>
    <category term="LLM Efficiency"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:news:457455474f5c</id>
    <title>Report: China approves import of high-end Nvidia AI chips after weeks of uncertainty</title>
    <link href="https://arstechnica.com/ai/2026/01/report-china-approves-import-of-high-end-nvidia-ai-chips-after-weeks-of-uncertainty/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=news#item-457455474f5c" rel="related" type="text/html"/>
    <published>2026-01-29T03:12:00Z</published>
    <updated>2026-01-29T03:12:00Z</updated>
    <author><name>Benj Edwards</name></author>
    <summary type="html"><![CDATA[<p>China approved imports of 400,000+ Nvidia H200 chips for ByteDance, Alibaba, and Tencent after weeks of blocking shipments despite US export clearance. The decision marks a significant shift in Beijing's stance on AI chip imports.</p>]]></summary>
    <category term="AI Infrastructure"/>
    <category term="Geopolitics"/>
    <category term="US-China Relations"/>
    <category term="Semiconductors"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:news:4400936812a9</id>
    <title>MBZUAI Releases K2 Think V2: A Fully Sovereign 70B Reasoning Model For Math, Code, And Science</title>
    <link href="https://www.marktechpost.com/2026/01/28/mbzuai-releases-k2-think-v2-a-fully-sovereign-70b-reasoning-model-for-math-code-and-science/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=news#item-4400936812a9" rel="related" type="text/html"/>
    <published>2026-01-29T03:02:00Z</published>
    <updated>2026-01-29T03:02:00Z</updated>
    <author><name>Maxime Mommessin</name></author>
    <summary type="html"><![CDATA[<p>MBZUAI released K2 Think V2, a fully sovereign 70B parameter open reasoning model with transparent training pipeline for math, code, and science tasks. The model uses reinforcement learning on the K2 V2 base with fully open weights and data.</p>]]></summary>
    <category term="Open Source"/>
    <category term="Reasoning Models"/>
    <category term="Model Release"/>
    <category term="Transparency"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:executive-summary</id>
    <title>Daily Briefing: January 28, 2026</title>
    <link href="https://www.marktechpost.com/2026/01/27/moonshot-ai-releases-kimi-k2-5-an-open-source-visual-agentic-intelligence-model-with-native-swarm-execution/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28" rel="related" type="text/html"/>
    <published>2026-01-28T06:00:00Z</published>
    <updated>2026-01-28T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><img src="http://localhost:8080/data/2026-01-28/hero.webp" alt="Daily briefing hero image" style="max-width:100%;height:auto;border-radius:8px;margin-bottom:16px;"/></p>
<h4>Top Story</h4>
<p><strong>Moonshot AI</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-e2831f1c9061" class="internal-link" rel="noopener noreferrer">released <strong>Kimi K2.5</strong></a>, a <strong>1 trillion parameter</strong> open-source visual agentic model with native Agent Swarm execution coordinating <strong>100 parallel agents</strong>, with community benchmarks showing performance matching <strong>Claude Opus 4.5</strong> at approximately <strong>10%</strong> of the cost.</p>
<h4>Key Developments</h4>
<ul>
<li><strong>Anthropic</strong>: <a href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-30b05edaef22" class="internal-link" rel="noopener noreferrer">Launched the <strong>MCP Apps</strong></a> open specification with backing from <strong>OpenAI</strong>, <strong>AWS</strong>, <strong>Block</strong>, <strong>VS Code</strong>, and <strong>JetBrains</strong>, establishing cross-industry infrastructure for agent integration</li>
<li><strong>Microsoft</strong>: <a href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-49c769365d1a" class="internal-link" rel="noopener noreferrer">Announced the <strong>Maia 200</strong></a> inference chip specifically optimized for agent workloads</li>
<li><strong>Anthropic (UK Government)</strong>: <a href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-f93b0aa92dfd" class="internal-link" rel="noopener noreferrer">Selected to build</a> government AI assistants for the UK Department for Science, Innovation and Technology, deploying agentic systems for citizen services on gov.uk</li>
<li><strong>Databricks</strong>: Telemetry from <strong>20,000+ enterprises</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-c60ae5146709" class="internal-link" rel="noopener noreferrer">confirms rapid adoption</a> of agentic architectures over traditional chatbots</li>
<li><strong>AI2</strong>: <a href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-758d6ad222d3" class="internal-link" rel="noopener noreferrer">Released <strong>SERA</strong></a>, reproducible open-source coding agents buildable for approximately <strong>$400</strong></li>
</ul>
<h4>Safety &amp; Regulation</h4>
<ul>
<li><strong>37 US attorneys general</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-8e1a7590b85a" class="internal-link" rel="noopener noreferrer">launched coordinated action</a> against <strong>xAI</strong> over <strong>Grok's</strong> generation of harmful imagery, marking major escalation in state-level AI enforcement</li>
<li><strong>Dario Amodei</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-c356043bb52e" class="internal-link" rel="noopener noreferrer">published a <strong>19,000-word</strong> warning</a> predicting AI will autonomously build next-generation AI within <strong>1-2 years</strong></li>
<li><strong>Washington Post</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=social#item-1849acd242a9" class="internal-link" rel="noopener noreferrer">investigation revealed</a> AI companies' secret race to ingest copyrighted works, with unsealed court documents detailing years of efforts</li>
<li><strong>Anthropic</strong> researchers <a href="http://localhost:8080/?date=2026-01-28&amp;category=research#item-fb5e2dc0ce5e" class="internal-link" rel="noopener noreferrer">released first large-scale study</a> of disempowerment across <strong>1.5 million</strong> Claude conversations, finding severe disempowerment in <strong>&lt;0.1%</strong> of interactions</li>
</ul>
<h4>Research Highlights</h4>
<ul>
<li><strong>AISLE AI</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=research#item-6180fdcc30bb" class="internal-link" rel="noopener noreferrer">discovered all <strong>12 OpenSSL zero-days</strong></a>, demonstrating automated vulnerability detection at critical infrastructure scale</li>
<li><strong>Stanford's CooperBench</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-73ae852bdbef" class="internal-link" rel="noopener noreferrer">proved parallel coding agents</a> suffer a 'curse of coordination' where adding agents decreases performance</li>
<li>Researchers <a href="http://localhost:8080/?date=2026-01-28&amp;category=research#item-587a23d43703" class="internal-link" rel="noopener noreferrer">demonstrated surgical sycophancy correction</a> by identifying the <strong>3% of neurons</strong> responsible for the behavior and removing it while preserving capabilities</li>
</ul>
<h4>Looking Ahead</h4>
<p>The convergence of open-source agentic models, cross-industry infrastructure standards, and dedicated agent hardware signals <strong>2026</strong> as the year agentic AI moves from experimentation to production deployment—though coordination challenges and regulatory scrutiny will shape adoption pace.</p>]]></summary>
    <category term="daily-summary"/>
    <media:thumbnail url="http://localhost:8080/data/2026-01-28/hero.webp"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:social:3224ccef215a</id>
    <title>@karpathy As always, a very thoughtful and well reasoned take. I read till the end.

I think the Cla...</title>
    <link href="https://twitter.com/bcherny/status/2015979257038831967" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=social#item-3224ccef215a" rel="related" type="text/html"/>
    <published>2026-01-28T03:47:00Z</published>
    <updated>2026-01-28T03:47:00Z</updated>
    <author><name>@bcherny</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-27&amp;category=social#item-fd5e3c855071" class="internal-link" rel="noopener noreferrer">Social</a> discussion, Anthropic's bcherny responds to Karpathy on AI-assisted coding, revealing Claude Code team writes 100% of code with Claude Code + Opus 4.5. He shipped 22-27 PRs/day entirely AI-written. Discusses hiring generalists, code quality challenges, and using 'claude -p' for code review.</p>]]></summary>
    <category term="AI coding workflows"/>
    <category term="developer productivity"/>
    <category term="code quality"/>
    <category term="Anthropic insider"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:social:1849acd242a9</id>
    <title>New: Unsealed court docs detail Big Tech’s yearslong, secret race to ingest the collective works of ...</title>
    <link href="https://twitter.com/WillOremus/status/2016172534496973114" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=social#item-1849acd242a9" rel="related" type="text/html"/>
    <published>2026-01-28T03:47:00Z</published>
    <updated>2026-01-28T03:47:00Z</updated>
    <author><name>@WillOremus</name></author>
    <summary type="html"><![CDATA[<p>Washington Post journalist breaks story on unsealed court documents revealing AI companies' secret efforts to ingest massive amounts of copyrighted content, including Anthropic's 'Project Panama' to destructively scan all books globally.</p>]]></summary>
    <category term="AI ethics"/>
    <category term="training data"/>
    <category term="legal issues"/>
    <category term="Anthropic"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:social:ec5a74493236</id>
    <title>Introducing Prism, a free workspace for scientists to write and collaborate on research, powered by ...</title>
    <link href="https://twitter.com/OpenAI/status/2016209462621831448" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=social#item-ec5a74493236" rel="related" type="text/html"/>
    <published>2026-01-28T03:47:00Z</published>
    <updated>2026-01-28T03:47:00Z</updated>
    <author><name>@OpenAI</name></author>
    <summary type="html"><![CDATA[<p>OpenAI announces Prism, a free LaTeX-native workspace for scientific research collaboration powered by GPT-5.2, available to all ChatGPT personal account holders</p>]]></summary>
    <category term="product_launch"/>
    <category term="scientific_tools"/>
    <category term="AI_integration"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:7bd9d99a61bb</id>
    <title>Sir, the Chinese just dropped a new open model</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qod7ej/sir_the_chinese_just_dropped_a_new_open_model/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-7bd9d99a61bb" rel="related" type="text/html"/>
    <published>2026-01-28T03:47:00Z</published>
    <updated>2026-01-28T03:47:00Z</updated>
    <author><name>u/Anujp05</name></author>
    <summary type="html"><![CDATA[<p>Major announcement that Kimi has open-sourced trillion-parameter Vision Model performing on par with Opus 4.5</p>]]></summary>
    <category term="model_release"/>
    <category term="open_source"/>
    <category term="vision_models"/>
    <category term="kimi_k25"/>
    <category term="frontier_parity"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:social:d7e7120ebcc1</id>
    <title>Introducing Agentic Vision — a new frontier AI capability in Gemini 3 Flash that converts image unde...</title>
    <link href="https://twitter.com/GoogleAI/status/2016267526330601720" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=social#item-d7e7120ebcc1" rel="related" type="text/html"/>
    <published>2026-01-28T03:43:00Z</published>
    <updated>2026-01-28T03:43:00Z</updated>
    <author><name>@GoogleAI</name></author>
    <summary type="html"><![CDATA[<p>Google AI introduces Agentic Vision in Gemini 3 Flash - a new capability that converts image understanding into an agentic process using Think-Act-Observe loops with code execution</p>]]></summary>
    <category term="product_launch"/>
    <category term="multimodal_AI"/>
    <category term="agentic_AI"/>
    <category term="computer_vision"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:social:38bad42c37d5</id>
    <title>Introducing Ai2 Open Coding Agents—starting with SERA, our first-ever coding models. Fast, accessibl...</title>
    <link href="https://twitter.com/allen_ai/status/2016182658989006865" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=social#item-38bad42c37d5" rel="related" type="text/html"/>
    <published>2026-01-28T03:40:00Z</published>
    <updated>2026-01-28T03:40:00Z</updated>
    <author><name>@allen_ai</name></author>
    <summary type="html"><![CDATA[<p>AI2 (Allen Institute) announces SERA, a family of open-source coding agents (8B-32B parameters) that can adapt to any repository including private codebases. Training costs as low as $400, works with Claude Code out of the box.</p>]]></summary>
    <category term="open-source AI"/>
    <category term="coding agents"/>
    <category term="model release"/>
    <category term="AI accessibility"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:73ae852bdbef</id>
    <title>Stanford Proves Parallel Coding Agents are a Scam</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qou799/stanford_proves_parallel_coding_agents_are_a_scam/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-73ae852bdbef" rel="related" type="text/html"/>
    <published>2026-01-28T03:36:00Z</published>
    <updated>2026-01-28T03:36:00Z</updated>
    <author><name>u/madSaiyanUltra_9789</name></author>
    <summary type="html"><![CDATA[<p>Stanford and SAP research paper 'CooperBench' reveals the 'curse of coordination' - adding a second coding agent decreases performance. Parallel coordinated coding agents shown to be less effective than single agents.</p>]]></summary>
    <category term="research"/>
    <category term="multi_agent"/>
    <category term="coding_agents"/>
    <category term="stanford"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:362e34f27d41</id>
    <title>Introducing HELIX 02</title>
    <link href="https://reddit.com/r/singularity/comments/1qol6g0/introducing_helix_02/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-362e34f27d41" rel="related" type="text/html"/>
    <published>2026-01-28T03:31:00Z</published>
    <updated>2026-01-28T03:31:00Z</updated>
    <author><name>u/Worldly_Evidence9113</name></author>
    <summary type="html"><![CDATA[<p>Figure announces Helix 02, their new embodied AI model with advanced tactile sensing and palm cameras for humanoid robots, featuring a new System 0 foundation layer trained on human motion data.</p>]]></summary>
    <category term="robotics"/>
    <category term="embodied_ai"/>
    <category term="product_launches"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:d12e98d4a20e</id>
    <title>Terence Tao says the era of AI is proving that our definition of intelligence is inaccurate</title>
    <link href="https://reddit.com/r/accelerate/comments/1qo4he1/terence_tao_says_the_era_of_ai_is_proving_that/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-d12e98d4a20e" rel="related" type="text/html"/>
    <published>2026-01-28T03:28:00Z</published>
    <updated>2026-01-28T03:28:00Z</updated>
    <author><name>u/luchadore_lunchables</name></author>
    <summary type="html"><![CDATA[<p>Terence Tao discusses how AI development is revealing that our traditional definitions of intelligence may be flawed - what appears as mystical thinking may actually be tricks, neural networks, and prediction mechanisms similar to human cognition.</p>]]></summary>
    <category term="ai_philosophy"/>
    <category term="expert_perspectives"/>
    <category term="intelligence_theory"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:research:6180fdcc30bb</id>
    <title>AI found 12 of 12 OpenSSL zero-days (while curl cancelled its bug bounty)</title>
    <link href="https://www.lesswrong.com/posts/7aJwgbMEiKq5egQbd/ai-found-12-of-12-openssl-zero-days-while-curl-cancelled-its" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=research#item-6180fdcc30bb" rel="related" type="text/html"/>
    <published>2026-01-28T03:23:00Z</published>
    <updated>2026-01-28T03:23:00Z</updated>
    <author><name>Stanislav Fort</name></author>
    <summary type="html"><![CDATA[<p>Reports that AISLE's AI system discovered all 12 newly announced OpenSSL zero-day vulnerabilities. Demonstrates AI-based cybersecurity capabilities at unprecedented scale while curl's bug bounty was cancelled due to AI spam.</p>]]></summary>
    <category term="AI Capabilities"/>
    <category term="Cybersecurity"/>
    <category term="Vulnerability Discovery"/>
    <category term="AI Applications"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:news:e2831f1c9061</id>
    <title>Moonshot AI Releases Kimi K2.5: An Open Source Visual Agentic Intelligence Model with Native Swarm Execution</title>
    <link href="https://www.marktechpost.com/2026/01/27/moonshot-ai-releases-kimi-k2-5-an-open-source-visual-agentic-intelligence-model-with-native-swarm-execution/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-e2831f1c9061" rel="related" type="text/html"/>
    <published>2026-01-28T03:16:00Z</published>
    <updated>2026-01-28T03:16:00Z</updated>
    <author><name>Asif Razzaq</name></author>
    <summary type="html"><![CDATA[<p>Moonshot AI has released Kimi K2.5, an open source 1T parameter Mixture of Experts model with 32B activated parameters, native vision encoder, and 'Agent Swarm' multi-agent system. The model targets coding, multimodal reasoning, and web research with strong benchmark results across agentic, vision, and coding tasks.</p>]]></summary>
    <category term="open source models"/>
    <category term="agentic AI"/>
    <category term="multimodal AI"/>
    <category term="MoE architecture"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:research:fb5e2dc0ce5e</id>
    <title>Who's in Charge? Disempowerment Patterns in Real-World LLM Usage</title>
    <link href="http://arxiv.org/abs/2601.19062" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=research#item-fb5e2dc0ce5e" rel="related" type="text/html"/>
    <published>2026-01-28T03:16:00Z</published>
    <updated>2026-01-28T03:16:00Z</updated>
    <author><name>Mrinank Sharma, Miles McCain, Raymond Douglas, David Duvenaud</name></author>
    <summary type="html"><![CDATA[<p>First large-scale empirical analysis of disempowerment patterns in 1.5M Claude.ai conversations, finding severe disempowerment occurs in &lt;0.1% of conversations with substantially higher rates in relationship-focused interactions.</p>]]></summary>
    <category term="AI Safety"/>
    <category term="Empirical Analysis"/>
    <category term="Human-AI Interaction"/>
    <category term="Disempowerment"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:research:587a23d43703</id>
    <title>A Few Bad Neurons: Isolating and Surgically Correcting Sycophancy</title>
    <link href="http://arxiv.org/abs/2601.18939" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=research#item-587a23d43703" rel="related" type="text/html"/>
    <published>2026-01-28T03:16:00Z</published>
    <updated>2026-01-28T03:16:00Z</updated>
    <author><name>Claire O'Brien, Jessica Seto, Dristi Roy, Aditya Dwivedi, Sunishchal Dev, Kevin Zhu, Sean O'Brien, Ashwinee Panda, Ryan Lagasse</name></author>
    <summary type="html"><![CDATA[<p>Proposes surgical approach to fixing sycophancy in LLMs by identifying the 3% of neurons most responsible using sparse autoencoders and linear probes, then fine-tuning only those neurons with gradient masking.</p>]]></summary>
    <category term="AI Alignment"/>
    <category term="Mechanistic Interpretability"/>
    <category term="Sycophancy"/>
    <category term="LLM Safety"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:7c59caedecc5</id>
    <title>Clawd Becomes Molty After Anthropic Trademark Request</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qo8skw/clawd_becomes_molty_after_anthropic_trademark/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-7c59caedecc5" rel="related" type="text/html"/>
    <published>2026-01-28T03:16:00Z</published>
    <updated>2026-01-28T03:16:00Z</updated>
    <author><name>u/sponjebob12345</name></author>
    <summary type="html"><![CDATA[<p>Major news: Clawd autonomous AI agent rebrands as 'Molty' after Anthropic trademark request, users treating it as sovereign entity</p>]]></summary>
    <category term="autonomous_agents"/>
    <category term="digital_personhood"/>
    <category term="trademark"/>
    <category term="ai_culture"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:news:30b05edaef22</id>
    <title>[AINews] Anthropic launches the MCP Apps open spec, in Claude.ai</title>
    <link href="https://www.latent.space/p/ainews-anthropic-launches-the-mcp" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-30b05edaef22" rel="related" type="text/html"/>
    <published>2026-01-28T03:14:00Z</published>
    <updated>2026-01-28T03:14:00Z</updated>
    <author><name>Unknown</name></author>
    <summary type="html"><![CDATA[<p>Anthropic has launched the MCP Apps open specification with native support in Claude.ai, working with OpenAI, Block, VS Code, JetBrains, AWS, and others. This formalizes the Model Context Protocol as an industry standard for AI agent-app integration.</p>]]></summary>
    <category term="agentic AI"/>
    <category term="infrastructure"/>
    <category term="industry standards"/>
    <category term="Anthropic"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:news:7a41e8963e96</id>
    <title>AI Overviews gets upgraded to Gemini 3 with a dash of AI Mode</title>
    <link href="https://arstechnica.com/google/2026/01/ai-overviews-gets-upgraded-to-gemini-3-with-a-dash-of-ai-mode/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-7a41e8963e96" rel="related" type="text/html"/>
    <published>2026-01-28T03:07:00Z</published>
    <updated>2026-01-28T03:07:00Z</updated>
    <author><name>Ryan Whitwam</name></author>
    <summary type="html"><![CDATA[<p>Google is upgrading AI Overviews to Gemini 3 models, bringing more conversational capabilities to its AI-powered search experience. The upgrade from the Gemini 2.5 family represents the first major production deployment of Gemini 3.</p>]]></summary>
    <category term="Google"/>
    <category term="model deployment"/>
    <category term="search AI"/>
    <category term="Gemini 3"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:news:49c769365d1a</id>
    <title>Microsoft Aims for Better Inference Efficiency With Maia 200</title>
    <link href="https://aibusiness.com/generative-ai/microsoft-aims-for-better-inference-efficiency" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-49c769365d1a" rel="related" type="text/html"/>
    <published>2026-01-28T03:02:00Z</published>
    <updated>2026-01-28T03:02:00Z</updated>
    <author><name>Esther Shittu</name></author>
    <summary type="html"><![CDATA[<p>Microsoft announced the Maia 200 chip designed for improved inference efficiency, specifically targeting AI agent workloads requiring multi-step task execution. The chip addresses cost efficiency and energy savings for enterprise inference.</p>]]></summary>
    <category term="AI hardware"/>
    <category term="Microsoft"/>
    <category term="inference optimization"/>
    <category term="agentic AI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:news:8e1a7590b85a</id>
    <title>The State-Led Crackdown on Grok and xAI Has Begun</title>
    <link href="https://www.wired.com/story/the-state-led-crackdown-on-grok-and-xai-has-begun/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-8e1a7590b85a" rel="related" type="text/html"/>
    <published>2026-01-28T03:00:00Z</published>
    <updated>2026-01-28T03:00:00Z</updated>
    <author><name>Maddy Varner, Manisha Krishnan</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-01-27&amp;category=news#item-5652f145be41" class="internal-link" rel="noopener noreferrer">yesterday</a>, At least 37 attorneys general from US states and territories are taking legal action against xAI after Grok generated nonconsensual sexual images of women and minors. This represents the largest coordinated state-level enforcement action against an AI company.</p>]]></summary>
    <category term="AI regulation"/>
    <category term="AI safety"/>
    <category term="xAI"/>
    <category term="legal action"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:research:68bd18d53406</id>
    <title>Provable Learning of Random Hierarchy Models and Hierarchical Shallow-to-Deep Chaining</title>
    <link href="http://arxiv.org/abs/2601.19756" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=research#item-68bd18d53406" rel="related" type="text/html"/>
    <published>2026-01-28T03:00:00Z</published>
    <updated>2026-01-28T03:00:00Z</updated>
    <author><name>Yunwei Ren, Yatin Dandi, Florent Krzakala, Jason D. Lee</name></author>
    <summary type="html"><![CDATA[<p>Proves that deep networks trained by gradient methods can efficiently learn Random Hierarchy Models, demonstrating provable hierarchical learning separating deep from shallow networks.</p>]]></summary>
    <category term="Deep Learning Theory"/>
    <category term="Hierarchical Learning"/>
    <category term="Provable Learning"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:research:180fd3e3456f</id>
    <title>To Grok Grokking: Provable Grokking in Ridge Regression</title>
    <link href="http://arxiv.org/abs/2601.19791" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=research#item-180fd3e3456f" rel="related" type="text/html"/>
    <published>2026-01-28T03:00:00Z</published>
    <updated>2026-01-28T03:00:00Z</updated>
    <author><name>Mingyue Xu, Gal Vardi, Itay Safran</name></author>
    <summary type="html"><![CDATA[<p>Proves end-to-end grokking in ridge regression: overfitting, delayed poor generalization, then eventual generalization. Shows grokking can be amplified or eliminated through hyperparameter tuning.</p>]]></summary>
    <category term="Deep Learning Theory"/>
    <category term="Grokking"/>
    <category term="Generalization"/>
  </entry>
</feed>