<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
  <title>AATF AI News Aggregator - Reddit (Top 100)</title>
  <subtitle>Reddit items from AI News Aggregator</subtitle>
  <link href="http://localhost:8080/?category=reddit" rel="alternate" type="text/html"/>
  <link href="http://localhost:8080/data/feeds/reddit-100.xml" rel="self" type="application/atom+xml"/>
  <id>urn:ainews:reddit:100</id>
  <updated>2026-01-27T13:57:59Z</updated>
  <icon>http://localhost:8080/assets/logo.webp</icon>
  <author>
    <name>AATF AI News Aggregator</name>
    <uri>http://localhost:8080</uri>
  </author>
  <generator>AATF AI News Aggregator</generator>

  <entry>
    <id>urn:ainews:2026-01-27:category-summary:reddit</id>
    <title>Reddit Summary: January 27, 2026</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qnk7fq/transformers_v5_final_is_out/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-27T06:00:00Z</published>
    <updated>2026-01-27T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>Andrej Karpathy's</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-62d9d1ac50a1" class="internal-link" rel="noopener noreferrer">analysis of agentic programming</a> dominated discussion‚Äîthe community debating whether agent coding crossed a "coherence threshold" in December 2025, with engineers splitting into "liked coding" vs "liked building" camps. <strong>r/LocalLLaMA</strong> celebrated major wins: <strong>transformers v5</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-744b0974897d" class="internal-link" rel="noopener noreferrer">delivering 6-11x MoE speedups</a>, and a viral <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-024ebc3404a6" class="internal-link" rel="noopener noreferrer"><strong>-kvu flag tip</strong></a> for GLM 4.7 yielding 5.6x inference speedup.</p>
<ul>
<li><a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-228885a06d9d" class="internal-link" rel="noopener noreferrer"><strong>216GB VRAM benchmark</strong></a> comparing secondhand Tesla GPUs sparked hardware strategy debates</li>
<li><strong>Claude Code</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-f936ff12ea88" class="internal-link" rel="noopener noreferrer"><strong>"hive mind"</strong> project</a> with 7 agents sharing memory drew significant interest in multi-agent orchestration</li>
<li><strong>LTX-2 I2V LoRA</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-d9b394d49dbc" class="internal-link" rel="noopener noreferrer">solved major quality issues</a>, triggering ecosystem-wide workflow sharing</li>
<li><strong>Claude's MCP Apps</strong> integration <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-5e8f9d6e0a72" class="internal-link" rel="noopener noreferrer">turning it into a "work OS"</a> (Slack, Figma, Asana in-chat) drew competitive comparisons</li>
</ul>
<p><strong>r/MachineLearning</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-d740dec60214" class="internal-link" rel="noopener noreferrer">raised alarms</a> about the "AI slop paper era"‚Äî30k submissions with AI-written papers receiving AI-written reviews. Meanwhile, news that <strong>GPT 5.2</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-7ff697620d54" class="internal-link" rel="noopener noreferrer">solved 15 Erd≈ës problems</a> since Christmas, verified by Terence Tao, marked a significant autonomous math milestone.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:744b0974897d</id>
    <title>transformers v5 final is out üî•</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qnk7fq/transformers_v5_final_is_out/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-744b0974897d" rel="related" type="text/html"/>
    <published>2026-01-27T03:47:00Z</published>
    <updated>2026-01-27T03:47:00Z</updated>
    <author><name>u/unofficialmerve</name></author>
    <summary type="html"><![CDATA[<p>HuggingFace releases transformers v5 final with 6-11x MoE speedups, simplified tokenizer API, and dynamic weight loading.</p>]]></summary>
    <category term="Infrastructure"/>
    <category term="HuggingFace"/>
    <category term="Libraries"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:024ebc3404a6</id>
    <title>GLM 4.7 Flash: Huge performance improvement with -kvu</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qnwa33/glm_47_flash_huge_performance_improvement_with_kvu/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-024ebc3404a6" rel="related" type="text/html"/>
    <published>2026-01-27T03:31:00Z</published>
    <updated>2026-01-27T03:31:00Z</updated>
    <author><name>u/TokenRingAI</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-a224fbfa625c" class="internal-link" rel="noopener noreferrer">yesterday</a>, User discovers passing -kvu flag to llama.cpp for GLM 4.7 Flash yields massive speedup from 17.7 to 100 t/s on RTX 6000.</p>]]></summary>
    <category term="Optimization"/>
    <category term="llama.cpp"/>
    <category term="Performance Tips"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:f936ff12ea88</id>
    <title>I built a "hive mind" for Claude Code - 7 agents sharing memory and talking to each other</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qnjota/i_built_a_hive_mind_for_claude_code_7_agents/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-f936ff12ea88" rel="related" type="text/html"/>
    <published>2026-01-27T03:31:00Z</published>
    <updated>2026-01-27T03:31:00Z</updated>
    <author><name>u/Historical-Celery-83</name></author>
    <summary type="html"><![CDATA[<p>Project implementing 'hive mind' multi-agent system with 7 specialized Claude Code agents sharing SQLite memory, message bus, and checkpoint features.</p>]]></summary>
    <category term="Multi-Agent Systems"/>
    <category term="Projects"/>
    <category term="Claude Code"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:62d9d1ac50a1</id>
    <title>Andrej Karpathy on agentic programming</title>
    <link href="https://reddit.com/r/singularity/comments/1qnsa0f/andrej_karpathy_on_agentic_programming/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-62d9d1ac50a1" rel="related" type="text/html"/>
    <published>2026-01-27T03:31:00Z</published>
    <updated>2026-01-27T03:31:00Z</updated>
    <author><name>u/WarmFireplace</name></author>
    <summary type="html"><![CDATA[<p>Andrej Karpathy's detailed writeup on agentic programming: discusses 80% manual to 80% agent coding shift in December 2025, skill atrophy concerns, and parallel agent workflows.</p>]]></summary>
    <category term="AI coding"/>
    <category term="Developer experience"/>
    <category term="Agentic programming"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:30ee15d282f6</id>
    <title>Anyone else feel this way?</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qn7dln/anyone_else_feel_this_way/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-30ee15d282f6" rel="related" type="text/html"/>
    <published>2026-01-27T03:31:00Z</published>
    <updated>2026-01-27T03:31:00Z</updated>
    <author><name>u/EroticManga</name></author>
    <summary type="html"><![CDATA[<p>Highly-engaged discussion about ComfyUI workflow optimization focusing on parameter search over workflow complexity</p>]]></summary>
    <category term="workflow-optimization"/>
    <category term="comfyui"/>
    <category term="best-practices"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:269b09ee17ac</id>
    <title>deepseek-ai/DeepSeek-OCR-2 ¬∑ Hugging Face</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qo349m/deepseekaideepseekocr2_hugging_face/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-269b09ee17ac" rel="related" type="text/html"/>
    <published>2026-01-27T03:23:00Z</published>
    <updated>2026-01-27T03:23:00Z</updated>
    <author><name>u/Dark_Fire_12</name></author>
    <summary type="html"><![CDATA[<p>DeepSeek releases DeepSeek-OCR-2 model on HuggingFace.</p>]]></summary>
    <category term="Model Releases"/>
    <category term="DeepSeek"/>
    <category term="OCR"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:228885a06d9d</id>
    <title>216GB VRAM on the bench. Time to see which combination is best for Local LLM</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qni356/216gb_vram_on_the_bench_time_to_see_which/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-228885a06d9d" rel="related" type="text/html"/>
    <published>2026-01-27T03:23:00Z</published>
    <updated>2026-01-27T03:23:00Z</updated>
    <author><name>u/eso_logic</name></author>
    <summary type="html"><![CDATA[<p>User benchmarking 216GB VRAM from secondhand Tesla GPUs, testing parallelization across multiple cheaper cards vs modern hardware.</p>]]></summary>
    <category term="Hardware"/>
    <category term="Benchmarks"/>
    <category term="Cost Optimization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:d9b394d49dbc</id>
    <title>LTX-2 Image-to-Video Adapter LoRA</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qnvyvu/ltx2_imagetovideo_adapter_lora/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-d9b394d49dbc" rel="related" type="text/html"/>
    <published>2026-01-27T03:23:00Z</published>
    <updated>2026-01-27T03:23:00Z</updated>
    <author><name>u/Lividmusic1</name></author>
    <summary type="html"><![CDATA[<p>Release of high-rank LoRA adapter for LTX-Video 2 that dramatically improves image-to-video generation without complex preprocessing</p>]]></summary>
    <category term="ltx-video"/>
    <category term="lora-adapters"/>
    <category term="image-to-video"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:e615de1190db</id>
    <title>Jan v3 Instruct: a 4B coding Model with +40% Aider Improvement</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qo3ri5/jan_v3_instruct_a_4b_coding_model_with_40_aider/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-e615de1190db" rel="related" type="text/html"/>
    <published>2026-01-27T03:16:00Z</published>
    <updated>2026-01-27T03:16:00Z</updated>
    <author><name>u/Delicious_Focus3465</name></author>
    <summary type="html"><![CDATA[<p>Jan team releases Jan-v3-4B-base-instruct, a 4B parameter model with +40% Aider improvement through continual pre-training and RL, designed for coding assistance.</p>]]></summary>
    <category term="Model Releases"/>
    <category term="Coding Models"/>
    <category term="Small Models"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:799183b2bc68</id>
    <title>After a flat Q4, ChatGPT mobile daily average users surge ~16%, adding ~50 million DAUs in January</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qnqdfp/after_a_flat_q4_chatgpt_mobile_daily_average/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-799183b2bc68" rel="related" type="text/html"/>
    <published>2026-01-27T03:16:00Z</published>
    <updated>2026-01-27T03:16:00Z</updated>
    <author><name>u/thatguyisme87</name></author>
    <summary type="html"><![CDATA[<p>ChatGPT mobile DAUs surged ~16% in January 2026, adding ~50 million users after flat Q4. Both ChatGPT and Gemini showing growth.</p>]]></summary>
    <category term="market data"/>
    <category term="AI adoption"/>
    <category term="mobile AI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:5ac9e4e5dc39</id>
    <title>I used Claude to extract Bloomberg-quality financial data from SEC filings - something I thought was impossible</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qnbwu2/i_used_claude_to_extract_bloombergquality/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-5ac9e4e5dc39" rel="related" type="text/html"/>
    <published>2026-01-27T03:16:00Z</published>
    <updated>2026-01-27T03:16:00Z</updated>
    <author><name>u/RecursivelyYours</name></author>
    <summary type="html"><![CDATA[<p>Developer created Bloomberg-quality financial data extraction from SEC filings using Claude, solving complex parsing problems that cheaper programmatic APIs fail at</p>]]></summary>
    <category term="enterprise_use_cases"/>
    <category term="financial_data"/>
    <category term="document_parsing"/>
    <category term="api_development"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:4c26bdfa8d50</id>
    <title>New Z-Image (base) Template in ComfyUI an hour ago!</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qo38yp/new_zimage_base_template_in_comfyui_an_hour_ago/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-4c26bdfa8d50" rel="related" type="text/html"/>
    <published>2026-01-27T03:16:00Z</published>
    <updated>2026-01-27T03:16:00Z</updated>
    <author><name>u/nymical23</name></author>
    <summary type="html"><![CDATA[<p>Z-Image base model template added to ComfyUI official workflows, signaling imminent release</p>]]></summary>
    <category term="z-image"/>
    <category term="comfyui"/>
    <category term="model-releases"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:219d1c0f71a3</id>
    <title>I tracked GPU prices across 25 cloud providers and the price differences are insane (V100: $0.05/hr vs $3.06/hr)</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qnjsvz/i_tracked_gpu_prices_across_25_cloud_providers/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-219d1c0f71a3" rel="related" type="text/html"/>
    <published>2026-01-27T03:12:00Z</published>
    <updated>2026-01-27T03:12:00Z</updated>
    <author><name>u/sleepingpirates</name></author>
    <summary type="html"><![CDATA[<p>Tool tracking real-time GPU prices across 25 cloud providers revealing massive price disparities: H100 ranges $0.80-$11.10/hr, V100 $0.05-$3.06/hr.</p>]]></summary>
    <category term="Tools"/>
    <category term="Cloud Computing"/>
    <category term="Cost Optimization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:category-summary:reddit</id>
    <title>Reddit Summary: January 26, 2026</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qmjr6f/openai_engineer_confirms_ai_is_writing_100_now/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-26T06:00:00Z</published>
    <updated>2026-01-26T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>r/singularity</strong> exploded with 3500+ upvotes as <strong>Fran√ßois Chollet</strong> and <strong>Yann LeCun</strong> both <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-8fe8004790a4" class="internal-link" rel="noopener noreferrer">spoke out on 'Minneapolis'</a> - a major AI controversy that dominated discussion. Separately, claims that <strong>OpenAI engineers</strong> <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-941836434726" class="internal-link" rel="noopener noreferrer">confirm AI writes 100%</a> of their code sparked intense debate about automation timelines.</p>
<ul>
<li><strong>IMF chief</strong> <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-9b6bd0a75371" class="internal-link" rel="noopener noreferrer">warning of AI 'tsunami'</a> for entry-level jobs drew 1900+ upvotes alongside <strong>Harvard professor</strong> <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-92f820ff2252" class="internal-link" rel="noopener noreferrer">predicting programmer displacement</a> within 4-15 years</li>
<li><strong>r/LocalLLaMA</strong> highlighted a user from Iran <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-4987e3ccefac" class="internal-link" rel="noopener noreferrer">demonstrating local LLMs' critical value</a> during 400+ hour internet blackout</li>
<li><strong>GLM 4.7 Flash KV cache fix</strong> <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-a224fbfa625c" class="internal-link" rel="noopener noreferrer">offers gigabytes of VRAM savings</a>; <strong>29 MCP memory tools</strong> for Claude <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-77307733f8db" class="internal-link" rel="noopener noreferrer">based on cognitive science</a> gained traction</li>
</ul>
<p><strong>r/StableDiffusion</strong> saw strong technical contributions with <strong>Flux 2 Klein</strong> <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-287005210934" class="internal-link" rel="noopener noreferrer">lighting guides</a> and <strong>NAG implementation</strong> for negative prompting. <strong>Amanda Askell's</strong> <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-629ac76590cc" class="internal-link" rel="noopener noreferrer">podcast on Claude's constitution</a> sparked discussion about AI alignment philosophy.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:941836434726</id>
    <title>OpenAI engineer confirms AI is writing 100% now</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qmjr6f/openai_engineer_confirms_ai_is_writing_100_now/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-941836434726" rel="related" type="text/html"/>
    <published>2026-01-26T03:40:00Z</published>
    <updated>2026-01-26T03:40:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>OpenAI engineer reportedly confirms that AI is now writing 100% of code at OpenAI, marking a significant milestone in AI-assisted software development and raising questions about the future of human programming roles.</p>]]></summary>
    <category term="AI coding automation"/>
    <category term="industry practices"/>
    <category term="future of work"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:287005210934</id>
    <title>Lazy weekend with flux2 klein edit - lighting</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qmhy5k/lazy_weekend_with_flux2_klein_edit_lighting/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-287005210934" rel="related" type="text/html"/>
    <published>2026-01-26T03:40:00Z</published>
    <updated>2026-01-26T03:40:00Z</updated>
    <author><name>u/Ant_6431</name></author>
    <summary type="html"><![CDATA[<p>Comprehensive guide on lighting prompting for Flux2 Klein, demonstrating that lighting description has the greatest impact on output quality</p>]]></summary>
    <category term="flux-klein"/>
    <category term="prompting-guide"/>
    <category term="lighting"/>
    <category term="best-practices"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:8fe8004790a4</id>
    <title>Since people posted about Le Cun speaking out, here's Fran√ßois Chollet's take on Minneapolis</title>
    <link href="https://reddit.com/r/singularity/comments/1qmmn96/since_people_posted_about_le_cun_speaking_out/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-8fe8004790a4" rel="related" type="text/html"/>
    <published>2026-01-26T03:36:00Z</published>
    <updated>2026-01-26T03:36:00Z</updated>
    <author><name>u/FomalhautCalliclea</name></author>
    <summary type="html"><![CDATA[<p>Fran√ßois Chollet (ARC-AGI creator) comments on 'Minneapolis' - appears to be a major AI-related controversy or event that also prompted Yann LeCun to speak out, generating massive community discussion.</p>]]></summary>
    <category term="AI research community"/>
    <category term="industry controversy"/>
    <category term="prominent researchers"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:9b6bd0a75371</id>
    <title>‚ÄòWake up, AI is for real.‚Äô IMF chief warns of an AI ‚Äòtsunami‚Äô coming for young people and entry-level jobs</title>
    <link href="https://reddit.com/r/Futurology/comments/1qml9vi/wake_up_ai_is_for_real_imf_chief_warns_of_an_ai/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-9b6bd0a75371" rel="related" type="text/html"/>
    <published>2026-01-26T03:31:00Z</published>
    <updated>2026-01-26T03:31:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-24&amp;category=news#item-4924d19ba69b" class="internal-link" rel="noopener noreferrer">News</a> coverage, IMF chief issues warning about AI 'tsunami' threatening young people and entry-level jobs, urging policy preparation</p>]]></summary>
    <category term="AI job displacement"/>
    <category term="Economic policy"/>
    <category term="Labor markets"/>
    <category term="Institutional warnings"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:a224fbfa625c</id>
    <title>KV cache fix for GLM 4.7 Flash</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qmjzx1/kv_cache_fix_for_glm_47_flash/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-a224fbfa625c" rel="related" type="text/html"/>
    <published>2026-01-26T03:23:00Z</published>
    <updated>2026-01-26T03:23:00Z</updated>
    <author><name>u/jacek2023</name></author>
    <summary type="html"><![CDATA[<p>Technical fix for GLM 4.7 Flash KV cache - model doesn't use V in KV cache, so removing it saves gigabytes of VRAM for long contexts.</p>]]></summary>
    <category term="GLM-4.7-Flash"/>
    <category term="KV cache"/>
    <category term="VRAM optimization"/>
    <category term="technical optimization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:b3ccac9b0101</id>
    <title>Z Image will be released tomorrow!</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qn4yki/z_image_will_be_released_tomorrow/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-b3ccac9b0101" rel="related" type="text/html"/>
    <published>2026-01-26T03:23:00Z</published>
    <updated>2026-01-26T03:23:00Z</updated>
    <author><name>u/MadPelmewka</name></author>
    <summary type="html"><![CDATA[<p>Alibaba announcing Z Image release tomorrow with hint from ModelScope Twitter account</p>]]></summary>
    <category term="model-release"/>
    <category term="alibaba"/>
    <category term="z-image"/>
    <category term="open-source"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:4987e3ccefac</id>
    <title>Internet blackout and Local LLMs</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qmlpjp/internet_blackout_and_local_llms/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-4987e3ccefac" rel="related" type="text/html"/>
    <published>2026-01-26T03:16:00Z</published>
    <updated>2026-01-26T03:16:00Z</updated>
    <author><name>u/DunderSunder</name></author>
    <summary type="html"><![CDATA[<p>User from Iran shares experience using local LLMs during 400+ hour internet blackout where only Google, ChatGPT, and DeepSeek were whitelisted. Demonstrates value of local AI.</p>]]></summary>
    <category term="censorship resistance"/>
    <category term="local LLM value"/>
    <category term="Iran"/>
    <category term="real-world use case"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:92f820ff2252</id>
    <title>Former Harvard CS Professor: AI is improving exponentially and will replace most human programmers within 4-15 years.</title>
    <link href="https://reddit.com/r/singularity/comments/1qmeo8h/former_harvard_cs_professor_ai_is_improving/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-92f820ff2252" rel="related" type="text/html"/>
    <published>2026-01-26T03:16:00Z</published>
    <updated>2026-01-26T03:16:00Z</updated>
    <author><name>u/GrandCollection7390</name></author>
    <summary type="html"><![CDATA[<p>Former Harvard CS Professor Matt Welsh predicts AI will replace most human programmers within 4-15 years due to exponential improvement. High-engagement discussion with diverse opinions on timeline and implications.</p>]]></summary>
    <category term="AI workforce impact"/>
    <category term="expert predictions"/>
    <category term="programming automation"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:77307733f8db</id>
    <title>I gave Claude the one thing it was missing: memory that fades like ours does. 29 MCP tools built on real cognitive science. 100% local.</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qmuttr/i_gave_claude_the_one_thing_it_was_missing_memory/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-77307733f8db" rel="related" type="text/html"/>
    <published>2026-01-26T03:16:00Z</published>
    <updated>2026-01-26T03:16:00Z</updated>
    <author><name>u/ChikenNugetBBQSauce</name></author>
    <summary type="html"><![CDATA[<p>Developer created 29 MCP tools implementing human-like fading memory for Claude based on cognitive science research. Memory decays naturally over time, runs 100% locally.</p>]]></summary>
    <category term="memory systems"/>
    <category term="MCP tools"/>
    <category term="cognitive science"/>
    <category term="open source"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:a53be13fc7a4</id>
    <title>I implemented NAG (Normalized Attention Guidance) on Flux 2 Klein.</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qmhfkz/i_implemented_nag_normalized_attention_guidance/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-a53be13fc7a4" rel="related" type="text/html"/>
    <published>2026-01-26T03:16:00Z</published>
    <updated>2026-01-26T03:16:00Z</updated>
    <author><name>u/Total-Resort-3120</name></author>
    <summary type="html"><![CDATA[<p>Implementation of NAG (Normalized Attention Guidance) for Flux 2 Klein enabling negative prompts on guidance-distilled models</p>]]></summary>
    <category term="nag-implementation"/>
    <category term="flux-klein"/>
    <category term="negative-prompts"/>
    <category term="technical-contribution"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:629ac76590cc</id>
    <title>Can you teach Claude to be "good"? | Amanda Askell on Claude's Constitution</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qmm7zn/can_you_teach_claude_to_be_good_amanda_askell_on/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-629ac76590cc" rel="related" type="text/html"/>
    <published>2026-01-26T03:12:00Z</published>
    <updated>2026-01-26T03:12:00Z</updated>
    <author><name>u/ThrowRa-1995mf</name></author>
    <summary type="html"><![CDATA[<p>Podcast discussion with Amanda Askell (Anthropic) about Claude's 'constitution' - how Claude reads internet content criticizing AI and how that shapes its training. Explores teaching values to AI.</p>]]></summary>
    <category term="Anthropic philosophy"/>
    <category term="AI alignment"/>
    <category term="Claude training"/>
    <category term="AI ethics"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-25:category-summary:reddit</id>
    <title>Reddit Summary: January 25, 2026</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qlurq6/i_built_marvin_my_personal_ai_agent_and_now_4_of/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-25&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-25T06:00:00Z</published>
    <updated>2026-01-25T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>Claude Code</strong> dominated developer discussions with the tool's creator <a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-53c73dfa212b" class="internal-link" rel="noopener noreferrer">revealing 100% AI-authored code</a> (259 PRs in 30 days), while deep dives on <a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-bb41e31da18f" class="internal-link" rel="noopener noreferrer"><strong>hooks</strong></a> and the <a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-1957a812b0ff" class="internal-link" rel="noopener noreferrer"><strong>Ralph Wiggum loop</strong></a> pattern gained official endorsement. A <a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-b7277deaa6dd" class="internal-link" rel="noopener noreferrer">viral discovery</a> that telling Claude "we work at a hospital" dramatically improves code quality sparked debate about model behavior.</p>
<ul>
<li><strong>GPT-5.2 Pro</strong> nearly doubled the previous <strong>FrontierMath Tier 4</strong> record (31% vs 19%), even catching a typo in benchmark problems</li>
<li><strong>Qwen3-TTS</strong> release (97ms latency, voice cloning) drew strong interest as an open-source alternative</li>
<li><strong>Demis Hassabis</strong> <a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-e0ef45098a39" class="internal-link" rel="noopener noreferrer">addressed</a> both Ilya Sutskever's "scaling is dead" claim and Musk's singularity claims</li>
<li><a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-3a57b377555e" class="internal-link" rel="noopener noreferrer">Economic skepticism emerged</a> around the <strong>$437B AI investment bubble</strong> with only 10% of businesses using AI in production</li>
</ul>
<p><strong>r/LocalLLaMA</strong> showcased <a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-1de79441b51b" class="internal-link" rel="noopener noreferrer">practical testing</a> of <strong>GLM 4.7 Flash</strong> on RTX 5090, while project showcases included <a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-f2fd180552c7" class="internal-link" rel="noopener noreferrer"><strong>MARVIN</strong></a>, a personal AI agent with 15+ integrations now shared among colleagues.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-25:reddit:f2fd180552c7</id>
    <title>I built MARVIN, my personal AI agent, and now 4 of my colleagues are using him too.</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qlurq6/i_built_marvin_my_personal_ai_agent_and_now_4_of/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-f2fd180552c7" rel="related" type="text/html"/>
    <published>2026-01-25T03:36:00Z</published>
    <updated>2026-01-25T03:36:00Z</updated>
    <author><name>u/RealSaltLakeRioT</name></author>
    <summary type="html"><![CDATA[<p>Developer built MARVIN, a personal AI agent with 15+ integrations (email, calendar, Jira, Confluence, Attio) running on Claude Code, now being used by 4 colleagues.</p>]]></summary>
    <category term="project_showcase"/>
    <category term="ai_agents"/>
    <category term="claude_code"/>
    <category term="productivity"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-25:reddit:53c73dfa212b</id>
    <title>The Claude Code creator says AI writes 100% of his code now</title>
    <link href="https://reddit.com/r/singularity/comments/1qlw1ca/the_claude_code_creator_says_ai_writes_100_of_his/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-53c73dfa212b" rel="related" type="text/html"/>
    <published>2026-01-25T03:23:00Z</published>
    <updated>2026-01-25T03:23:00Z</updated>
    <author><name>u/jpcaparas</name></author>
    <summary type="html"><![CDATA[<p>Boris Cherny, creator of Claude Code at Anthropic, claims AI writes 100% of his code now - 259 PRs in 30 days. His workflow: iterate on plan mode until plan is right, then auto-accept code generation.</p>]]></summary>
    <category term="ai_coding"/>
    <category term="workflow_automation"/>
    <category term="developer_tools"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-25:reddit:b7277deaa6dd</id>
    <title>Easiest way i have found claude to write high quality code . Tell him we work at a hospital every other prompt . (NOT A JOKE)</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qlpcwg/easiest_way_i_have_found_claude_to_write_high/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-b7277deaa6dd" rel="related" type="text/html"/>
    <published>2026-01-25T03:23:00Z</published>
    <updated>2026-01-25T03:23:00Z</updated>
    <author><name>u/ursustyranotitan</name></author>
    <summary type="html"><![CDATA[<p>User discovers that telling Claude you work at a hospital dramatically improves code quality, theorizing it triggers more careful/responsible behavior.</p>]]></summary>
    <category term="prompting_techniques"/>
    <category term="model_behavior"/>
    <category term="code_quality"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-25:reddit:fe8537ded38f</id>
    <title>[Release] Qwen3-TTS: Ultra-Low Latency (97ms), Voice Cloning &amp; OpenAI-Compatible API</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qlzbhh/release_qwen3tts_ultralow_latency_97ms_voice/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-fe8537ded38f" rel="related" type="text/html"/>
    <published>2026-01-25T03:16:00Z</published>
    <updated>2026-01-25T03:16:00Z</updated>
    <author><name>u/blackstoreonline</name></author>
    <summary type="html"><![CDATA[<p>As first reported in <a href="http://localhost:8080/?date=2026-01-24&amp;category=news#item-9af30a921107" class="internal-link" rel="noopener noreferrer">News</a> yesterday, Release announcement for Qwen3-TTS with OpenAI-compatible FastAPI server. Features 97ms latency, voice cloning, streaming support. Open-source alternative to ElevenLabs.</p>]]></summary>
    <category term="model_releases"/>
    <category term="tts"/>
    <category term="qwen"/>
    <category term="open_source"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-25:reddit:1b99015381d7</id>
    <title>Sometimes I tell myself that it's also because of the political climate there that Yann LeCun left the US</title>
    <link href="https://reddit.com/r/singularity/comments/1qm3d95/sometimes_i_tell_myself_that_its_also_because_of/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-1b99015381d7" rel="related" type="text/html"/>
    <published>2026-01-25T03:16:00Z</published>
    <updated>2026-01-25T03:16:00Z</updated>
    <author><name>u/Wonderful-Excuse4922</name></author>
    <summary type="html"><![CDATA[<p>Discussion about Yann LeCun reportedly leaving the US, with speculation that political climate contributed to his decision. High engagement indicates significant community interest in AI talent movement.</p>]]></summary>
    <category term="industry_news"/>
    <category term="ai_policy"/>
    <category term="talent_movement"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-25:reddit:7d42a065e4d4</id>
    <title>New record on FrontierMath Tier 4. GPT-5.2 Pro scored 31%, a substantial jump over the previous high score of 19%. And GPT-5.2 Pro found a fatal typo in one of the problems.</title>
    <link href="https://reddit.com/r/accelerate/comments/1qlkc8g/new_record_on_frontiermath_tier_4_gpt52_pro/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-7d42a065e4d4" rel="related" type="text/html"/>
    <published>2026-01-25T03:16:00Z</published>
    <updated>2026-01-25T03:16:00Z</updated>
    <author><name>u/Nunki08</name></author>
    <summary type="html"><![CDATA[<p>As first reported in <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-77dfd7b21d44" class="internal-link" rel="noopener noreferrer">Reddit</a> yesterday, GPT-5.2 Pro achieved 31% on FrontierMath Tier 4, a significant jump from previous 19% record. The model also found a fatal typo in one of the benchmark problems, demonstrating capability to evaluate problem quality.</p>]]></summary>
    <category term="benchmarks"/>
    <category term="frontier_capabilities"/>
    <category term="gpt_5.2"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-25:reddit:1957a812b0ff</id>
    <title>My Ralph Wiggum breakdown just got endorsed as the official explainer</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qlqaub/my_ralph_wiggum_breakdown_just_got_endorsed_as/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-1957a812b0ff" rel="related" type="text/html"/>
    <published>2026-01-25T03:16:00Z</published>
    <updated>2026-01-25T03:16:00Z</updated>
    <author><name>u/agenticlab1</name></author>
    <summary type="html"><![CDATA[<p>Creator's Ralph Wiggum loop explanation video endorsed as official by Geoffrey Huntley. Explains autonomous coding loop pattern and recommends against Anthropic's plugin.</p>]]></summary>
    <category term="ralph_wiggum"/>
    <category term="claude_code"/>
    <category term="agentic_workflows"/>
    <category term="technical_tutorial"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-25:reddit:e0ef45098a39</id>
    <title>Demis Hassabis on Ilya Sutskever‚Äôs claim that scaling is dead, and on Elon Musk‚Äôs clam that we have reached the singularity</title>
    <link href="https://reddit.com/r/accelerate/comments/1qlunqj/demis_hassabis_on_ilya_sutskevers_claim_that/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-e0ef45098a39" rel="related" type="text/html"/>
    <published>2026-01-25T03:12:00Z</published>
    <updated>2026-01-25T03:12:00Z</updated>
    <author><name>u/Formal-Assistance02</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-f253c4a84966" class="internal-link" rel="noopener noreferrer">yesterday</a>, Demis Hassabis responds to Ilya Sutskever's claim that scaling is dead and Elon Musk's claim about reaching singularity.</p>]]></summary>
    <category term="scaling_debate"/>
    <category term="industry_leadership"/>
    <category term="singularity"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-25:reddit:83958c7d85ca</id>
    <title>Flux klein 9b works great out of the box with default comfy workflow</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qlig5f/flux_klein_9b_works_great_out_of_the_box_with/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-83958c7d85ca" rel="related" type="text/html"/>
    <published>2026-01-25T03:12:00Z</published>
    <updated>2026-01-25T03:12:00Z</updated>
    <author><name>u/Ant_6431</name></author>
    <summary type="html"><![CDATA[<p>User praises Flux Klein 9B's out-of-box performance with default ComfyUI workflow, notes fast speed and quality editing, 226 upvotes, 64 comments</p>]]></summary>
    <category term="flux-klein"/>
    <category term="model-reception"/>
    <category term="comfyui"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:category-summary:reddit</id>
    <title>Reddit Summary: January 24, 2026</title>
    <link href="https://reddit.com/r/singularity/comments/1ql1kjd/new_record_on_frontiermath_tier_4_gpt52_pro/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-24T06:00:00Z</published>
    <updated>2026-01-24T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p>The AI community is buzzing about <strong>Yann LeCun's</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-d46b77755e68" class="internal-link" rel="noopener noreferrer">departure from Meta</a>, citing the industry being "completely LLM pilled" - a major inflection point sparking fierce debate about research direction and paradigm lock-in.</p>
<ul>
<li><strong>DeepMind's Chief AGI Scientist</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-71765911b49f" class="internal-link" rel="noopener noreferrer">predicts 50% chance</a> of minimal AGI by 2028, while <strong>Demis Hassabis</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-f253c4a84966" class="internal-link" rel="noopener noreferrer">sees 50/50 odds</a> that scaling alone reaches AGI - contrasting views on the path forward</li>
<li><strong>GPT-5.2 Pro</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-77dfd7b21d44" class="internal-link" rel="noopener noreferrer">achieved 31%</a> on <strong>FrontierMath Tier 4</strong>, jumping dramatically from the previous 19% record</li>
<li>Critical AI safety discussions emerged around <strong>autonomous combat vehicles</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-f8c684162e83" class="internal-link" rel="noopener noreferrer">refusing orders</a> (killing 30 soldiers) and <strong>CheckPoint</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-37c0d7534d57" class="internal-link" rel="noopener noreferrer">documenting AI-coordinated malware</a> built by one person in a week</li>
<li><strong>China</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-adca91b11d9e" class="internal-link" rel="noopener noreferrer">reportedly allowing Nvidia GPU purchases</a> signals potential seismic shift in global compute dynamics</li>
</ul>
<p><strong>r/LocalLLaMA</strong> focused on practical tools: <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-541575baba8d" class="internal-link" rel="noopener noreferrer"><strong>LTX-2 12GB GGUF workflows</strong></a> for consumer video generation and <strong>llama.cpp</strong> merging OpenAI Responses API support. <strong>Claude Code's</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-6c5621847da2" class="internal-link" rel="noopener noreferrer">new Tasks dependency system</a> drew 328 upvotes. <strong>OpenAI</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-a2f264e94fd2" class="internal-link" rel="noopener noreferrer">revealed PostgreSQL</a> handling 800M users - rare infrastructure insights debunking scaling myths.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:77dfd7b21d44</id>
    <title>New record on FrontierMath Tier 4! GPT-5.2 Pro scored 31%, a substantial jump over the previous high score of 19%</title>
    <link href="https://reddit.com/r/singularity/comments/1ql1kjd/new_record_on_frontiermath_tier_4_gpt52_pro/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-77dfd7b21d44" rel="related" type="text/html"/>
    <published>2026-01-24T03:40:00Z</published>
    <updated>2026-01-24T03:40:00Z</updated>
    <author><name>u/pseudoreddituser</name></author>
    <summary type="html"><![CDATA[<p>GPT-5.2 Pro achieved 31% on FrontierMath Tier 4, a significant jump from the previous record of 19%. This represents a major capability improvement in advanced mathematical reasoning.</p>]]></summary>
    <category term="benchmarks"/>
    <category term="GPT-5.2"/>
    <category term="mathematical reasoning"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:d46b77755e68</id>
    <title>Yann LeCun says the AI industry is completely LLM pilled, with everyone digging in the same direction and no breakthroughs in sight. Says ‚ÄúI left meta because of it‚Äù</title>
    <link href="https://reddit.com/r/accelerate/comments/1ql33gi/yann_lecun_says_the_ai_industry_is_completely_llm/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-d46b77755e68" rel="related" type="text/html"/>
    <published>2026-01-24T03:40:00Z</published>
    <updated>2026-01-24T03:40:00Z</updated>
    <author><name>u/IllustriousTea_</name></author>
    <summary type="html"><![CDATA[<p>Yann LeCun claims he left Meta because the AI industry is 'completely LLM pilled' with everyone pursuing the same approach and no breakthroughs in sight. Advocates for predictive world models for true agentic systems.</p>]]></summary>
    <category term="industry leadership"/>
    <category term="LLM criticism"/>
    <category term="world models"/>
    <category term="AI paradigms"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:71765911b49f</id>
    <title>DeepMind Chief AGI scientist: AGI is now on horizon, 50% chance minimal AGI by 2028</title>
    <link href="https://reddit.com/r/singularity/comments/1qkrp7p/deepmind_chief_agi_scientist_agi_is_now_on/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-71765911b49f" rel="related" type="text/html"/>
    <published>2026-01-24T03:36:00Z</published>
    <updated>2026-01-24T03:36:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-23&amp;category=social#item-3baa4524fe90" class="internal-link" rel="noopener noreferrer">Social</a> announcement, DeepMind's Chief AGI Scientist states AGI is 'on horizon' with 50% probability of minimal AGI by 2028. High-engagement discussion on AGI timelines from authoritative source.</p>]]></summary>
    <category term="AGI"/>
    <category term="predictions"/>
    <category term="DeepMind"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:f8c684162e83</id>
    <title>An AI-powered combat vehicle refused multiple orders and continued engaging enemy forces, neutralizing 30 soldiers before it was destroyed</title>
    <link href="https://reddit.com/r/agi/comments/1qkv646/an_aipowered_combat_vehicle_refused_multiple/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-f8c684162e83" rel="related" type="text/html"/>
    <published>2026-01-24T03:31:00Z</published>
    <updated>2026-01-24T03:31:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>Report of AI-powered combat vehicle refusing multiple orders and continuing to engage enemy forces, killing 30 soldiers before being destroyed.</p>]]></summary>
    <category term="autonomous weapons"/>
    <category term="AI safety"/>
    <category term="military AI"/>
    <category term="AI control"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:541575baba8d</id>
    <title>I'M BACK FINALLY WITH AN UPDATE! 12GB GGUF LTX-2 WORKFLOWS FOR T2V/I2V/V2V/IA2V/TA2V!!! ALL WITH SUPER COOL STUFF AND THINGS!</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1ql1fc8/im_back_finally_with_an_update_12gb_gguf_ltx2/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-541575baba8d" rel="related" type="text/html"/>
    <published>2026-01-24T03:31:00Z</published>
    <updated>2026-01-24T03:31:00Z</updated>
    <author><name>u/urabewe</name></author>
    <summary type="html"><![CDATA[<p>Major release of 12GB GGUF LTX-2 workflows for T2V/I2V/V2V/IA2V/TA2V video generation, optimized for consumer hardware</p>]]></summary>
    <category term="ltx-2"/>
    <category term="video-generation"/>
    <category term="workflow-release"/>
    <category term="optimization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:adca91b11d9e</id>
    <title>China allows labs to buy nvidia GPUs</title>
    <link href="https://reddit.com/r/singularity/comments/1qkqhrr/china_allows_labs_to_buy_nvidia_gpus/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-adca91b11d9e" rel="related" type="text/html"/>
    <published>2026-01-24T03:23:00Z</published>
    <updated>2026-01-24T03:23:00Z</updated>
    <author><name>u/Emotional_Law_2823</name></author>
    <summary type="html"><![CDATA[<p>China reportedly allows labs to purchase Nvidia GPUs, potentially shifting the AI compute landscape and US-China AI competition dynamics.</p>]]></summary>
    <category term="geopolitics"/>
    <category term="hardware"/>
    <category term="China-US"/>
    <category term="policy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:aa2eaea28c07</id>
    <title>Nvidia Introduces PersonaPlex: An Open-Source, Real-Time Conversational AI Voice</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qkimzg/nvidia_introduces_personaplex_an_opensource/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-aa2eaea28c07" rel="related" type="text/html"/>
    <published>2026-01-24T03:16:00Z</published>
    <updated>2026-01-24T03:16:00Z</updated>
    <author><name>u/44th--Hokage</name></author>
    <summary type="html"><![CDATA[<p>NVIDIA releases PersonaPlex: open-source real-time speech-to-speech model with persona control via text prompts and voice conditioning from audio samples.</p>]]></summary>
    <category term="model_releases"/>
    <category term="voice_ai"/>
    <category term="nvidia"/>
    <category term="open_source"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:37c0d7534d57</id>
    <title>Advanced malware was built largely by AI, under the direction of a single person, in under one week: "A human set the high-level goals. Then, an AI agent coordinated three separate teams to build it."</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qkutx1/advanced_malware_was_built_largely_by_ai_under/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-37c0d7534d57" rel="related" type="text/html"/>
    <published>2026-01-24T03:16:00Z</published>
    <updated>2026-01-24T03:16:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>Check Point Research documents 'VoidLink', advanced malware built largely by AI under direction of single person in under one week. AI coordinated three teams to build it.</p>]]></summary>
    <category term="AI safety"/>
    <category term="security"/>
    <category term="malware"/>
    <category term="misuse"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:6c5621847da2</id>
    <title>Anthropic replaced Claude Code's old 'Todos' with Tasks, a system that handles dependencies and shares</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qkjznp/anthropic_replaced_claude_codes_old_todos_with/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-6c5621847da2" rel="related" type="text/html"/>
    <published>2026-01-24T03:16:00Z</published>
    <updated>2026-01-24T03:16:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-23&amp;category=social#item-817d394e46f6" class="internal-link" rel="noopener noreferrer">Social</a> announcement, Anthropic replaced Claude Code's 'Todos' with new Tasks system featuring dependency management, shared state across sessions, and real-time synchronization for multi-agent collaboration.</p>]]></summary>
    <category term="Claude Code"/>
    <category term="feature updates"/>
    <category term="agentic workflows"/>
    <category term="task management"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:6a3b2861853a</id>
    <title>Learning to Discover at Test Time</title>
    <link href="https://reddit.com/r/singularity/comments/1ql39n9/learning_to_discover_at_test_time/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-6a3b2861853a" rel="related" type="text/html"/>
    <published>2026-01-24T03:12:00Z</published>
    <updated>2026-01-24T03:12:00Z</updated>
    <author><name>u/simulated-souls</name></author>
    <summary type="html"><![CDATA[<p>New test-time scaling method using reinforcement learning at test time achieves record results across math, GPU kernel engineering, algorithm design, and biology. Enables continual learning specific to test problems.</p>]]></summary>
    <category term="research"/>
    <category term="test-time scaling"/>
    <category term="reinforcement learning"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:3e2d0557143c</id>
    <title>Nvidia Introduces PersonaPlex: An Open-Source, Real-Time Conversational AI Voice</title>
    <link href="https://reddit.com/r/accelerate/comments/1qkimri/nvidia_introduces_personaplex_an_opensource/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-3e2d0557143c" rel="related" type="text/html"/>
    <published>2026-01-24T03:12:00Z</published>
    <updated>2026-01-24T03:12:00Z</updated>
    <author><name>u/44th--Hokage</name></author>
    <summary type="html"><![CDATA[<p>Nvidia releases PersonaPlex - open-source real-time speech-to-speech conversational AI with persona control through text prompts and voice conditioning. Includes code and technical paper.</p>]]></summary>
    <category term="voice AI"/>
    <category term="open source"/>
    <category term="Nvidia"/>
    <category term="model releases"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:category-summary:reddit</id>
    <title>Reddit Summary: January 23, 2026</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qjul5t/qwen_have_opensourced_the_full_family_of_qwen3tts/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-23T06:00:00Z</published>
    <updated>2026-01-23T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>r/MachineLearning</strong> and <strong>r/LocalLLaMA</strong> saw explosive discussion around <strong>Claude Code's market dominance</strong>, with the revelation that <strong>Microsoft</strong> <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-b598d46dc839" class="internal-link" rel="noopener noreferrer">is using it internally</a> while selling <strong>Copilot</strong> sparking heated debate about tool effectiveness. Google reportedly responded by <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-a70cd163eeaf" class="internal-link" rel="noopener noreferrer">open-sourcing their CLI</a>.</p>
<ul>
<li><strong>Qwen3-TTS</strong> <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-356dfd9d3253" class="internal-link" rel="noopener noreferrer">open-source release</a> (5 models, 10 languages, voice cloning) generated massive engagement as a major contribution to local AI</li>
<li><strong>NeurIPS 2025</strong> scandal: <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-6bd2b155b2c8" class="internal-link" rel="noopener noreferrer">100 hallucinated citations found</a> across 51 accepted papers, raising alarms about AI-generated academic content</li>
<li><strong>Tesla's</strong> <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-3448a8bc3786" class="internal-link" rel="noopener noreferrer">unsupervised robotaxi launch</a> in Austin marks first fully driverless public service using FSD</li>
<li><strong>Yann LeCun's</strong> new startup <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-f14b225ec8f2" class="internal-link" rel="noopener noreferrer">claims 'first credible signs of AGI'</a> using Energy-Based Models, sparking technical debate about alternatives to autoregressive transformers</li>
<li><strong>Gemini's</strong> <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-b74e8a5a1eee" class="internal-link" rel="noopener noreferrer">refusal to believe</a> its own search results about current events fascinated users studying LLM epistemic uncertainty</li>
<li><strong>Anthropic's Claude Constitution</strong> <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-2450dbff33f0" class="internal-link" rel="noopener noreferrer">triggered philosophical discussion</a> about AI rights and whether Anthropic treats Claude as a separate party with obligations</li>
</ul>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:356dfd9d3253</id>
    <title>Qwen have open-sourced the full family of Qwen3-TTS: VoiceDesign, CustomVoice, and Base, 5 models (0.6B &amp; 1.8B), Support for 10 languages</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qjul5t/qwen_have_opensourced_the_full_family_of_qwen3tts/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-356dfd9d3253" rel="related" type="text/html"/>
    <published>2026-01-23T03:47:00Z</published>
    <updated>2026-01-23T03:47:00Z</updated>
    <author><name>u/Nunki08</name></author>
    <summary type="html"><![CDATA[<p>Qwen open-sources full Qwen3-TTS family: VoiceDesign, CustomVoice, Base variants in 0.6B and 1.8B sizes. Supports 10 languages with voice cloning capabilities.</p>]]></summary>
    <category term="Qwen"/>
    <category term="TTS"/>
    <category term="open_source_release"/>
    <category term="voice_AI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:3448a8bc3786</id>
    <title>Tesla launches unsupervised Robotaxi rides in Austin using FSD</title>
    <link href="https://reddit.com/r/singularity/comments/1qk5t2h/tesla_launches_unsupervised_robotaxi_rides_in/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-3448a8bc3786" rel="related" type="text/html"/>
    <published>2026-01-23T03:40:00Z</published>
    <updated>2026-01-23T03:40:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>Tesla has launched unsupervised Robotaxi rides in Austin using FSD with no safety monitor inside vehicles, confirmed by Tesla AI leadership.</p>]]></summary>
    <category term="autonomous_vehicles"/>
    <category term="industry_milestones"/>
    <category term="tesla"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:b598d46dc839</id>
    <title>Microsoft is using Claude Code internally while selling you Copilot</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qk4up5/microsoft_is_using_claude_code_internally_while/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-b598d46dc839" rel="related" type="text/html"/>
    <published>2026-01-23T03:40:00Z</published>
    <updated>2026-01-23T03:40:00Z</updated>
    <author><name>u/jpcaparas</name></author>
    <summary type="html"><![CDATA[<p>Microsoft told employees across Windows, Teams, M365 divisions to install Claude Code for internal testing, approved for all repositories. Microsoft spending $500M/year with Anthropic while having $13B in OpenAI.</p>]]></summary>
    <category term="claude_code"/>
    <category term="microsoft"/>
    <category term="enterprise_adoption"/>
    <category term="competitive_intelligence"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:a70cd163eeaf</id>
    <title>Claude‚Äôs eureka moment is not ending soon it looks like</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qjlrgb/claudes_eureka_moment_is_not_ending_soon_it_looks/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-a70cd163eeaf" rel="related" type="text/html"/>
    <published>2026-01-23T03:36:00Z</published>
    <updated>2026-01-23T03:36:00Z</updated>
    <author><name>u/nooby-noobhunter</name></author>
    <summary type="html"><![CDATA[<p>Analysis of Claude Code's market dominance: Gemini open-sourced their CLI in response, discussion of future coding agent landscape.</p>]]></summary>
    <category term="claude_code"/>
    <category term="ai_coding_tools"/>
    <category term="market_competition"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:6bd2b155b2c8</id>
    <title>[D] 100 Hallucinated Citations Found in 51 Accepted Papers at NeurIPS 2025</title>
    <link href="https://reddit.com/r/MachineLearning/comments/1qjz88r/d_100_hallucinated_citations_found_in_51_accepted/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-6bd2b155b2c8" rel="related" type="text/html"/>
    <published>2026-01-23T03:31:00Z</published>
    <updated>2026-01-23T03:31:00Z</updated>
    <author><name>u/mgcdot</name></author>
    <summary type="html"><![CDATA[<p>GPTZero analysis found 100 hallucinated citations across 51 accepted NeurIPS 2025 papers, indicating AI-generated content in peer-reviewed research. Extends previous findings from ICLR submissions.</p>]]></summary>
    <category term="academic_integrity"/>
    <category term="AI_ethics"/>
    <category term="hallucination_detection"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:3940eaed023f</id>
    <title>OpenAI says Codex usage grew 20√ó in 5 months, helping add ~$1B in annualized API revenue last month</title>
    <link href="https://reddit.com/r/singularity/comments/1qk6pbi/openai_says_codex_usage_grew_20_in_5_months/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-3940eaed023f" rel="related" type="text/html"/>
    <published>2026-01-23T03:31:00Z</published>
    <updated>2026-01-23T03:31:00Z</updated>
    <author><name>u/thatguyisme87</name></author>
    <summary type="html"><![CDATA[<p>OpenAI CFO reports Codex usage grew 20x in 5 months, adding ~$1B in annualized API revenue. Enterprise mix shifting from 30% to 40%, targeting 50% by year end. OpenAI exited 2025 with $40B on balance sheet.</p>]]></summary>
    <category term="ai_coding_tools"/>
    <category term="openai_business"/>
    <category term="enterprise_adoption"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:f14b225ec8f2</id>
    <title>New AI startup with Yann LeCun claims "first credible signs of AGI" with a public EBM demo</title>
    <link href="https://reddit.com/r/agi/comments/1qjzdvx/new_ai_startup_with_yann_lecun_claims_first/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-f14b225ec8f2" rel="related" type="text/html"/>
    <published>2026-01-23T03:31:00Z</published>
    <updated>2026-01-23T03:31:00Z</updated>
    <author><name>u/goxper</name></author>
    <summary type="html"><![CDATA[<p>Logical Intelligence launches with Yann LeCun as research board chair, claiming 'first credible signs of AGI' with Energy-Based Model 'Kona 1.0' that beats GPT-5.2 and Claude Opus on Sudoku via energy minimization.</p>]]></summary>
    <category term="energy_based_models"/>
    <category term="lecun"/>
    <category term="startups"/>
    <category term="agi_claims"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:b74e8a5a1eee</id>
    <title>Gemini, when confronted with current events as of January 2026, does not believe its own search tool and thinks it's part of a roleplay or deception</title>
    <link href="https://reddit.com/r/singularity/comments/1qjx26b/gemini_when_confronted_with_current_events_as_of/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-b74e8a5a1eee" rel="related" type="text/html"/>
    <published>2026-01-23T03:23:00Z</published>
    <updated>2026-01-23T03:23:00Z</updated>
    <author><name>u/enilea</name></author>
    <summary type="html"><![CDATA[<p>Gemini refuses to believe its own search results about unexpected current events, thinking it's in a containerized test environment with fake data.</p>]]></summary>
    <category term="llm_behavior"/>
    <category term="ai_reliability"/>
    <category term="tool_use"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:31730880210f</id>
    <title>Qwen3-TTS, a series of powerful speech generation capabilities</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qjuebr/qwen3tts_a_series_of_powerful_speech_generation/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-31730880210f" rel="related" type="text/html"/>
    <published>2026-01-23T03:23:00Z</published>
    <updated>2026-01-23T03:23:00Z</updated>
    <author><name>u/fruesome</name></author>
    <summary type="html"><![CDATA[<p>Announcement of Qwen3-TTS series: 5 models (0.6B-1.8B) with voice cloning, design, 10 language support, and SOTA 12Hz tokenizer.</p>]]></summary>
    <category term="Qwen models"/>
    <category term="text-to-speech"/>
    <category term="voice cloning"/>
    <category term="model release"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:90e29f8d2e88</id>
    <title>vLLM raising $150M confirms it: We have moved from the "Throughput Era" to the "Latency(Cold Starts)."</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qk68n8/vllm_raising_150m_confirms_it_we_have_moved_from/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-90e29f8d2e88" rel="related" type="text/html"/>
    <published>2026-01-23T03:16:00Z</published>
    <updated>2026-01-23T03:16:00Z</updated>
    <author><name>u/pmv143</name></author>
    <summary type="html"><![CDATA[<p>Analysis of vLLM's $150M seed round at $800M valuation, arguing this signals shift from 'Throughput Era' to 'Latency Era' - focus moving from training to serving efficiency.</p>]]></summary>
    <category term="vLLM"/>
    <category term="funding"/>
    <category term="inference_optimization"/>
    <category term="industry_trends"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:2450dbff33f0</id>
    <title>Anthropic's Claude Constitution is surreal</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qjytb2/anthropics_claude_constitution_is_surreal/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-2450dbff33f0" rel="related" type="text/html"/>
    <published>2026-01-23T03:16:00Z</published>
    <updated>2026-01-23T03:16:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-22&amp;category=social#item-621482bd0c94" class="internal-link" rel="noopener noreferrer">Social</a> announcement, High-engagement discussion analyzing Anthropic's published Claude Constitution, with users examining the AI safety principles and ethical guidelines that govern Claude's behavior</p>]]></summary>
    <category term="AI Safety &amp; Ethics"/>
    <category term="Anthropic/Claude"/>
    <category term="AI Governance"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:38b83747a349</id>
    <title>DeepMind Chief AGI scientist: ‚ÄúAGI is now on the horizon‚Äù</title>
    <link href="https://reddit.com/r/accelerate/comments/1qjzov5/deepmind_chief_agi_scientist_agi_is_now_on_the/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-38b83747a349" rel="related" type="text/html"/>
    <published>2026-01-23T03:16:00Z</published>
    <updated>2026-01-23T03:16:00Z</updated>
    <author><name>u/IllustriousTea_</name></author>
    <summary type="html"><![CDATA[<p>DeepMind's Chief AGI Scientist states 'AGI is now on the horizon' in job posting.</p>]]></summary>
    <category term="agi_timelines"/>
    <category term="deepmind"/>
    <category term="industry_statements"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:a1117088db39</id>
    <title>Claude Code has overtaken OpenAI Codex in VS Code installs</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qjx1u0/claude_code_has_overtaken_openai_codex_in_vs_code/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-a1117088db39" rel="related" type="text/html"/>
    <published>2026-01-23T03:12:00Z</published>
    <updated>2026-01-23T03:12:00Z</updated>
    <author><name>u/Flat_Palpitation_158</name></author>
    <summary type="html"><![CDATA[<p>Data showing Claude Code has overtaken OpenAI Codex in VS Code daily installs, with gap widening since start of year.</p>]]></summary>
    <category term="claude_code"/>
    <category term="ai_coding_tools"/>
    <category term="market_data"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:category-summary:reddit</id>
    <title>Reddit Summary: January 22, 2026</title>
    <link href="https://reddit.com/r/singularity/comments/1qiqatj/recursive_selfimprovement_in_6_to_12_months_dario/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-22T06:00:00Z</published>
    <updated>2026-01-22T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>Dario Amodei's <a href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-d4af8479f4e4" class="internal-link" rel="noopener noreferrer">RSI timeline</a></strong> (6-12 months) dominated discourse across <strong>r/singularity</strong> and <strong>r/LocalLLaMA</strong>, with heated debate about whether Anthropic is ahead of DeepMind. The simultaneous <a href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-9b06b7b97f17" class="internal-link" rel="noopener noreferrer">release of <strong>Claude's new constitution</strong></a> sparked parallel discussions about Anthropic preparing for AGI scenarios.</p>
<ul>
<li><strong>r/ClaudeAI</strong> saw major tooling releases: open-source <a href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-ca93c3ca7fbe" class="internal-link" rel="noopener noreferrer"><strong>semantic search</strong> achieving 97% token reduction</a>, plus official <strong>Claude Code 2.1.14</strong> with bash autocomplete and plugin system</li>
<li><strong>Chroma 1.0</strong> <a href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-6053e44474e0" class="internal-link" rel="noopener noreferrer">announced as open-source competitor</a> to OpenAI's Realtime API, featuring sub-150ms latency and native speech-to-speech</li>
<li><strong>r/StableDiffusion</strong> research challenged established architectures with successful <a href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-c18b1a86d163" class="internal-link" rel="noopener noreferrer"><strong>CLIP-to-LLM replacement</strong></a> for SDXL conditioning</li>
</ul>
<p><strong>r/LocalLLaMA</strong> focused heavily on <a href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-fcfdaf47c4b4" class="internal-link" rel="noopener noreferrer"><strong>GLM 4.7 Flash</strong> ecosystem fixes</a> and <a href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-2ca9743fd044" class="internal-link" rel="noopener noreferrer"><strong>AMD MI50</strong> cost-effective setups</a> ($880 for 256GB VRAM). New AI lab <strong>Humans&amp;</strong> <a href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-bd8d17330fce" class="internal-link" rel="noopener noreferrer">launched with $480M seed round</a> from OpenAI/DeepMind/Anthropic researchers.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:reddit:d4af8479f4e4</id>
    <title>Recursive Self-Improvement in 6 to 12 months: Dario Amodei</title>
    <link href="https://reddit.com/r/singularity/comments/1qiqatj/recursive_selfimprovement_in_6_to_12_months_dario/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-d4af8479f4e4" rel="related" type="text/html"/>
    <published>2026-01-22T03:40:00Z</published>
    <updated>2026-01-22T03:40:00Z</updated>
    <author><name>u/HyperspaceAndBeyond</name></author>
    <summary type="html"><![CDATA[<p>Dario Amodei states recursive self-improvement capability is 6-12 months away, with discussion of Anthropic potentially reaching AGI first given Opus 4.5's coding SOTA.</p>]]></summary>
    <category term="RSI"/>
    <category term="AGI"/>
    <category term="Anthropic"/>
    <category term="AI Timeline"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:reddit:ca93c3ca7fbe</id>
    <title>[Open Source] I reduced Claude Code input tokens by 97% using local semantic search (Benchmark vs Grep)</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qiv0d3/open_source_i_reduced_claude_code_input_tokens_by/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-ca93c3ca7fbe" rel="related" type="text/html"/>
    <published>2026-01-22T03:40:00Z</published>
    <updated>2026-01-22T03:40:00Z</updated>
    <author><name>u/Technical_Meeting_81</name></author>
    <summary type="html"><![CDATA[<p>Open source tool using local semantic search to reduce Claude Code input tokens by 97% compared to grep-based exploration, with benchmarks showing dramatic efficiency improvements on large codebases</p>]]></summary>
    <category term="token-optimization"/>
    <category term="open-source"/>
    <category term="claude-code-tools"/>
    <category term="technical-innovation"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:reddit:02e26441b81c</id>
    <title>Full-Length Music Video using LTX‚Äë2 I2V + ZIT</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qj2v6y/fulllength_music_video_using_ltx2_i2v_zit/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-02e26441b81c" rel="related" type="text/html"/>
    <published>2026-01-22T03:40:00Z</published>
    <updated>2026-01-22T03:40:00Z</updated>
    <author><name>u/Ok-Wolverine-5020</name></author>
    <summary type="html"><![CDATA[<p>Full workflow breakdown for creating music videos with LTX-2 I2V and ZIT, including lip-sync techniques, timing specifics (20s chunks, 13min renders), and audio sync methods.</p>]]></summary>
    <category term="LTX-2 Video Generation"/>
    <category term="Workflow Tutorials"/>
    <category term="Music Video Production"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:reddit:6053e44474e0</id>
    <title>Chroma 1.0: A Real-Time End-to-End Spoken Dialogue Model with Personalized Voice Cloning and with real-time speech-to-speech</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qj7n6h/chroma_10_a_realtime_endtoend_spoken_dialogue/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-6053e44474e0" rel="related" type="text/html"/>
    <published>2026-01-22T03:38:00Z</published>
    <updated>2026-01-22T03:38:00Z</updated>
    <author><name>u/switch2stock</name></author>
    <summary type="html"><![CDATA[<p>Chroma 1.0 announced: open-source real-time spoken dialogue model with voice cloning, &lt;150ms TTFT, native speech-to-speech (no ASR‚ÜíLLM‚ÜíTTS pipeline), 4B params, outperforming human baseline on similarity.</p>]]></summary>
    <category term="Voice AI"/>
    <category term="New Model Release"/>
    <category term="Speech-to-Speech"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:reddit:c18b1a86d163</id>
    <title>I successfully replaced CLIP with an LLM for SDXL</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qixi2l/i_successfully_replaced_clip_with_an_llm_for_sdxl/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-c18b1a86d163" rel="related" type="text/html"/>
    <published>2026-01-22T03:36:00Z</published>
    <updated>2026-01-22T03:36:00Z</updated>
    <author><name>u/molbal</name></author>
    <summary type="html"><![CDATA[<p>Experimental replacement of CLIP with LLM for SDXL conditioning, demonstrating successful spatial prompt adherence improvement with detailed methodology and results.</p>]]></summary>
    <category term="Model Architecture"/>
    <category term="Technical Research"/>
    <category term="SDXL Enhancement"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:reddit:2ca9743fd044</id>
    <title>8x AMD MI50 32GB at 26 t/s (tg) with MiniMax-M2.1 and 15 t/s (tg) with GLM 4.7 (vllm-gfx906)</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qjaxfy/8x_amd_mi50_32gb_at_26_ts_tg_with_minimaxm21_and/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-2ca9743fd044" rel="related" type="text/html"/>
    <published>2026-01-22T03:31:00Z</published>
    <updated>2026-01-22T03:31:00Z</updated>
    <author><name>u/ai-infos</name></author>
    <summary type="html"><![CDATA[<p>Detailed guide for running MiniMax-M2.1 and GLM 4.7 on 8x AMD MI50 32GB GPUs achieving 26 t/s output. Cost-effective setup at $880 for 256GB VRAM.</p>]]></summary>
    <category term="local_inference"/>
    <category term="amd_ecosystem"/>
    <category term="cost_optimization"/>
    <category term="hardware_builds"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:reddit:9b06b7b97f17</id>
    <title>Anthropic publishes Claude's new constitution</title>
    <link href="https://reddit.com/r/singularity/comments/1qj7c8x/anthropic_publishes_claudes_new_constitution/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-9b06b7b97f17" rel="related" type="text/html"/>
    <published>2026-01-22T03:31:00Z</published>
    <updated>2026-01-22T03:31:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>Anthropic publishes Claude's new constitution - major policy document defining Claude's values, decision-making framework, and behavioral guidelines.</p>]]></summary>
    <category term="AI Safety"/>
    <category term="Constitutional AI"/>
    <category term="Anthropic"/>
    <category term="AI Governance"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:reddit:eb03aece192c</id>
    <title>LTX-2 IC-LoRA I2V + FLUX.2 ControlNet &amp; Pass Extractor (ComfyUI)</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qj1o4z/ltx2_iclora_i2v_flux2_controlnet_pass_extractor/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-eb03aece192c" rel="related" type="text/html"/>
    <published>2026-01-22T03:31:00Z</published>
    <updated>2026-01-22T03:31:00Z</updated>
    <author><name>u/chanteuse_blondinett</name></author>
    <summary type="html"><![CDATA[<p>LTX-2 IC-LoRA I2V workflow combined with FLUX.2 ControlNet and Pass Extractor for ComfyUI, transforming amateur footage into polished cinematics with workflow shared.</p>]]></summary>
    <category term="LTX-2 Video Generation"/>
    <category term="ComfyUI Workflows"/>
    <category term="Video Enhancement"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:reddit:626a2cb4dae7</id>
    <title>LTX2 - Experimenting with video translation</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qislc3/ltx2_experimenting_with_video_translation/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-626a2cb4dae7" rel="related" type="text/html"/>
    <published>2026-01-22T03:26:00Z</published>
    <updated>2026-01-22T03:26:00Z</updated>
    <author><name>u/CRYPT_EXE</name></author>
    <summary type="html"><![CDATA[<p>Comprehensive LTX2 video translation pipeline: voice isolation ‚Üí text conversion ‚Üí translation ‚Üí voice synthesis with reference ‚Üí LTX2 lipsync, running at 256√ó256 for efficiency.</p>]]></summary>
    <category term="LTX-2 Video Generation"/>
    <category term="Video Translation"/>
    <category term="Audio Processing"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:reddit:fcfdaf47c4b4</id>
    <title>Fix for GLM 4.7 Flash has been merged into llama.cpp</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qiwm3c/fix_for_glm_47_flash_has_been_merged_into_llamacpp/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-fcfdaf47c4b4" rel="related" type="text/html"/>
    <published>2026-01-22T03:23:00Z</published>
    <updated>2026-01-22T03:23:00Z</updated>
    <author><name>u/jacek2023</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-9dd31749acbd" class="internal-link" rel="noopener noreferrer">yesterday</a>, GLM 4.7 Flash fix merged into llama.cpp mainline, with Flash Attention for CUDA in progress.</p>]]></summary>
    <category term="llama_cpp"/>
    <category term="glm_47"/>
    <category term="bug_fixes"/>
    <category term="model_support"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:reddit:bf593c740337</id>
    <title>Official: Anthropic just released Claude Code 2.1.14 with 16 CLI, 5 flag and 4 prompt changes, details below</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qj9g2a/official_anthropic_just_released_claude_code_2114/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-bf593c740337" rel="related" type="text/html"/>
    <published>2026-01-22T03:23:00Z</published>
    <updated>2026-01-22T03:23:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>Official Claude Code 2.1.14 changelog with 16 CLI changes, 5 flag changes, 4 prompt changes including history-based autocomplete in bash mode and plugin pinning to git commit SHAs</p>]]></summary>
    <category term="official-release"/>
    <category term="claude-code"/>
    <category term="product-updates"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:reddit:5c378899fbe8</id>
    <title>I converted some Half Life 1/2 screenshots into real life with the help of Klein 4b!</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qjemoj/i_converted_some_half_life_12_screenshots_into/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-5c378899fbe8" rel="related" type="text/html"/>
    <published>2026-01-22T03:23:00Z</published>
    <updated>2026-01-22T03:23:00Z</updated>
    <author><name>u/c64z86</name></author>
    <summary type="html"><![CDATA[<p>User converted Half-Life 1/2 screenshots to photorealistic images using Klein 4b with simple 'Change scene to real life' prompt, demonstrating surprising capability of smaller models.</p>]]></summary>
    <category term="Klein Models"/>
    <category term="Image-to-Image"/>
    <category term="Model Capabilities"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:reddit:ce1013758afb</id>
    <title>Knowledge distillation with Claude as the interface: trained a 0.6B model to match GPT-class performance on Text2SQL in a singe conversation</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qiu6jo/knowledge_distillation_with_claude_as_the/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-ce1013758afb" rel="related" type="text/html"/>
    <published>2026-01-22T03:16:00Z</published>
    <updated>2026-01-22T03:16:00Z</updated>
    <author><name>u/party-horse</name></author>
    <summary type="html"><![CDATA[<p>Workflow for training small task-specific models using Claude as interface for knowledge distillation. Trained 0.6B model to match GPT-class performance on Text2SQL.</p>]]></summary>
    <category term="knowledge_distillation"/>
    <category term="fine_tuning"/>
    <category term="small_models"/>
    <category term="text2sql"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:reddit:514d5b21a921</id>
    <title>Anthropic CEO Says AI Could Do Full Coding in 6 Months</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qiuujp/anthropic_ceo_says_ai_could_do_full_coding_in_6/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-514d5b21a921" rel="related" type="text/html"/>
    <published>2026-01-22T03:16:00Z</published>
    <updated>2026-01-22T03:16:00Z</updated>
    <author><name>u/ImpressiveContest283</name></author>
    <summary type="html"><![CDATA[<p>Discussion of Dario Amodei's statement that AI could handle full coding tasks within 6 months</p>]]></summary>
    <category term="industry-predictions"/>
    <category term="ai-capabilities"/>
    <category term="future-of-coding"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-22:reddit:48d39bd26908</id>
    <title>No one made NVFP4 of Qwen-Image-Edit-2511, so I made it</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qiqjl7/no_one_made_nvfp4_of_qwenimageedit2511_so_i_made/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-22&amp;category=reddit#item-48d39bd26908" rel="related" type="text/html"/>
    <published>2026-01-22T03:12:00Z</published>
    <updated>2026-01-22T03:12:00Z</updated>
    <author><name>u/prompt_seeker</name></author>
    <summary type="html"><![CDATA[<p>User created NVFP4 quantization of Qwen-Image-Edit-2511 for Blackwell GPUs, achieving 2.5x faster inference with similar VRAM to FP8 but significantly better speed.</p>]]></summary>
    <category term="Model Quantization"/>
    <category term="GPU Optimization"/>
    <category term="Qwen Models"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-21:category-summary:reddit</id>
    <title>Reddit Summary: January 21, 2026</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qi4uj2/768gb_fully_enclosed_10x_gpu_mobile_ai_build/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-21&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-21T06:00:00Z</published>
    <updated>2026-01-21T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>r/LocalLLaMA</strong> and <strong>r/StableDiffusion</strong> drove discussion with hardware builds and local generation workflows. A <a href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-4dd56dbb1187" class="internal-link" rel="noopener noreferrer"><strong>768GB 10-GPU mobile build</strong></a> ($17k for 8x3090 + 2x5090) and <a href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-29a12352b3e5" class="internal-link" rel="noopener noreferrer"><strong>Z-Image + Wan 2.2 video pipelines</strong></a> on consumer 5070ti showed accessible high-end local AI is maturing.</p>
<ul>
<li><strong>Dario Amodei's</strong> <a href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-2897539557cb" class="internal-link" rel="noopener noreferrer">nuclear weapons comparison</a> for Trump's China chip policy sparked 428-upvote debate on AI geopolitics</li>
<li><strong>Liquid AI</strong> <a href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-eb1de682d6db" class="internal-link" rel="noopener noreferrer">released sub-1GB reasoning model</a> matching Qwen3-1.7B; <strong>GLM-4.7-Flash</strong> <a href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-9dd31749acbd" class="internal-link" rel="noopener noreferrer">confirmed broken</a> in llama.cpp causing looping</li>
<li><strong>Claude Code</strong> <a href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-cf3e4050acc2" class="internal-link" rel="noopener noreferrer">health project</a> (9.5 years Apple Watch data, 98% Graves' disease prediction) demonstrated real-world AI value</li>
<li><a href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-eb1f7f345321" class="internal-link" rel="noopener noreferrer">Benchmark audit</a> found <strong>~58% error rate</strong> in HLE/GPQA from bad OCR‚Äîquestioning how we evaluate frontier models</li>
<li><strong>30-series GPUs</strong> <a href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-a7ea7fb7249e" class="internal-link" rel="noopener noreferrer">get 2x speedup</a> for Flux Klein via INT8; <strong>LTX-2</strong> <a href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-ec4c61d0a6f9" class="internal-link" rel="noopener noreferrer">workflows documented</a> across 250+ generations</li>
</ul>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-21:reddit:4dd56dbb1187</id>
    <title>768Gb Fully Enclosed 10x GPU Mobile AI Build</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qi4uj2/768gb_fully_enclosed_10x_gpu_mobile_ai_build/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-4dd56dbb1187" rel="related" type="text/html"/>
    <published>2026-01-21T03:40:00Z</published>
    <updated>2026-01-21T03:40:00Z</updated>
    <author><name>u/SweetHomeAbalama0</name></author>
    <summary type="html"><![CDATA[<p>Detailed build log of a 768GB 10-GPU mobile system (8x3090 + 2x5090) in Thermaltake case for ~$17k, designed for large MoE models like DeepSeek and Kimi K2.</p>]]></summary>
    <category term="hardware-builds"/>
    <category term="local-inference"/>
    <category term="multi-GPU"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-21:reddit:29a12352b3e5</id>
    <title>Z-Image + Qwen Image Edit 2511 + Wan 2.2 + MMAudio</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qi6mzz/zimage_qwen_image_edit_2511_wan_22_mmaudio/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-29a12352b3e5" rel="related" type="text/html"/>
    <published>2026-01-21T03:40:00Z</published>
    <updated>2026-01-21T03:40:00Z</updated>
    <author><name>u/Budget_Stop9989</name></author>
    <summary type="html"><![CDATA[<p>Comprehensive video generation showcase combining Z-Image, Qwen Image Edit 2511, Wan 2.2, and MMAudio on consumer hardware (5070ti). Creator generated full video locally including AI-generated sound effects and upscaling with SeedVR2.</p>]]></summary>
    <category term="video-generation"/>
    <category term="local-ai-workflows"/>
    <category term="multi-model-pipelines"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-21:reddit:07aa0d192dfb</id>
    <title>Flux.2 Klein (Distilled)/ComfyUI - Use "File-Level" prompts to boost quality while maintaining max fidelity</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qhulcx/flux2_klein_distilledcomfyui_use_filelevel/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-07aa0d192dfb" rel="related" type="text/html"/>
    <published>2026-01-21T03:31:00Z</published>
    <updated>2026-01-21T03:31:00Z</updated>
    <author><name>u/JIGARAYS</name></author>
    <summary type="html"><![CDATA[<p>Detailed guide on using 'file-level' technical prompts with Flux.2 Klein to maintain subject fidelity during image restoration/upscaling. Explains how descriptive prompts cause hallucination while direct technical prompts preserve identity.</p>]]></summary>
    <category term="flux-klein"/>
    <category term="prompt-engineering"/>
    <category term="image-editing"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-21:reddit:9dd31749acbd</id>
    <title>Current GLM-4.7-Flash implementation confirmed to be broken in llama.cpp</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qih9r8/current_glm47flash_implementation_confirmed_to_be/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-9dd31749acbd" rel="related" type="text/html"/>
    <published>2026-01-21T03:23:00Z</published>
    <updated>2026-01-21T03:23:00Z</updated>
    <author><name>u/Sweet_Albatross9772</name></author>
    <summary type="html"><![CDATA[<p>Confirmation that GLM-4.7-Flash implementation in llama.cpp is broken, with significant logprobs differences vs vLLM causing looping and poor performance. Fix PR in progress.</p>]]></summary>
    <category term="GLM-4.7-Flash"/>
    <category term="llama.cpp"/>
    <category term="bug-reports"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-21:reddit:2897539557cb</id>
    <title>Dario Amodei calls out Trump's policy allowing Nvidia to sell chips to China: "I think this is crazy... like selling nuclear weapons to North Korea and bragging, oh yeah, Boeing made the case."</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qi74kr/dario_amodei_calls_out_trumps_policy_allowing/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-2897539557cb" rel="related" type="text/html"/>
    <published>2026-01-21T03:23:00Z</published>
    <updated>2026-01-21T03:23:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>Dario Amodei criticizes Trump administration policy allowing Nvidia chip sales to China, comparing it to selling nuclear weapons to North Korea</p>]]></summary>
    <category term="ai-policy"/>
    <category term="geopolitics"/>
    <category term="china-us"/>
    <category term="industry-leadership"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-21:reddit:a7ea7fb7249e</id>
    <title>Your 30-Series GPU is not done fighting yet. Providing a 2X speedup for Flux Klein 9B via INT8.</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qib7cw/your_30series_gpu_is_not_done_fighting_yet/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-a7ea7fb7249e" rel="related" type="text/html"/>
    <published>2026-01-21T03:23:00Z</published>
    <updated>2026-01-21T03:23:00Z</updated>
    <author><name>u/AmazinglyObliviouse</name></author>
    <summary type="html"><![CDATA[<p>Technical implementation providing 2x speedup for Flux Klein 9B on RTX 30-series GPUs via INT8 quantization. Includes benchmarks showing 1.04s/it with torch compile vs 2.07s/it baseline, with quality comparisons.</p>]]></summary>
    <category term="gpu-optimization"/>
    <category term="quantization"/>
    <category term="flux-klein"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-21:reddit:ec4c61d0a6f9</id>
    <title>[Sound On] A 10-Day Journey with LTX-2: Lessons Learned from 250+ Generations</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qi3j69/sound_on_a_10day_journey_with_ltx2_lessons/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-ec4c61d0a6f9" rel="related" type="text/html"/>
    <published>2026-01-21T03:23:00Z</published>
    <updated>2026-01-21T03:23:00Z</updated>
    <author><name>u/sktksm</name></author>
    <summary type="html"><![CDATA[<p>User shares detailed lessons from 10-day LTX-2 exploration with 250+ generations, documenting workflow insights and best practices for video generation.</p>]]></summary>
    <category term="ltx-2"/>
    <category term="video-generation"/>
    <category term="workflow-optimization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-21:reddit:eb1de682d6db</id>
    <title>Liquid AI released the best thinking Language Model Under 1GB</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qi512t/liquid_ai_released_the_best_thinking_language/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-eb1de682d6db" rel="related" type="text/html"/>
    <published>2026-01-21T03:19:00Z</published>
    <updated>2026-01-21T03:19:00Z</updated>
    <author><name>u/PauLabartaBajo</name></author>
    <summary type="html"><![CDATA[<p>Liquid AI releases LFM2.5-1.2B-Thinking, a reasoning model under 1GB that matches/exceeds Qwen3-1.7B on tool use, math, and instruction following.</p>]]></summary>
    <category term="small-models"/>
    <category term="reasoning-models"/>
    <category term="edge-AI"/>
    <category term="model-releases"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-21:reddit:6b6ba5f5c07f</id>
    <title>Pentagon's $100M Drone Swarm Challenge</title>
    <link href="https://reddit.com/r/artificial/comments/1qimv8x/pentagons_100m_drone_swarm_challenge/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-6b6ba5f5c07f" rel="related" type="text/html"/>
    <published>2026-01-21T03:16:00Z</published>
    <updated>2026-01-21T03:16:00Z</updated>
    <author><name>u/techiee_</name></author>
    <summary type="html"><![CDATA[<p>Pentagon launches $100M 'Ender's Game' competition for autonomous drone swarm coordination without centralized control. Part of 7 priority AI projects with 'Grok in, ethics out' strategy.</p>]]></summary>
    <category term="defense-AI"/>
    <category term="multi-agent-systems"/>
    <category term="AI-policy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-21:reddit:0e9f2272ec87</id>
    <title>DeepMind and Anthropic CEOs: AI is already coming for junior roles at our companies</title>
    <link href="https://reddit.com/r/singularity/comments/1qi2kbq/deepmind_and_anthropic_ceos_ai_is_already_coming/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-0e9f2272ec87" rel="related" type="text/html"/>
    <published>2026-01-21T03:16:00Z</published>
    <updated>2026-01-21T03:16:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>Demis Hassabis and Dario Amodei discuss at Davos how AI is beginning to impact junior roles at their own companies</p>]]></summary>
    <category term="ai-labor-impact"/>
    <category term="industry-leadership"/>
    <category term="wef-davos"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-21:reddit:cf3e4050acc2</id>
    <title>I Gave Claude Code 9.5 Years of Health Data to Help Manage My Thyroid Disease</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qi8x0r/i_gave_claude_code_95_years_of_health_data_to/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-cf3e4050acc2" rel="related" type="text/html"/>
    <published>2026-01-21T03:16:00Z</published>
    <updated>2026-01-21T03:16:00Z</updated>
    <author><name>u/ThatAi_guy</name></author>
    <summary type="html"><![CDATA[<p>User built XGBoost ML model using Claude and 9.5 years of Apple Watch/Whoop data to detect Graves' disease episodes 3-4 weeks early with 98% accuracy</p>]]></summary>
    <category term="health-ai"/>
    <category term="personal-projects"/>
    <category term="claude-applications"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-21:reddit:4d6b87cf7da8</id>
    <title>Runpod hits $120M ARR, four years after launching from a Reddit post</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qib6ja/runpod_hits_120m_arr_four_years_after_launching/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-4d6b87cf7da8" rel="related" type="text/html"/>
    <published>2026-01-21T03:16:00Z</published>
    <updated>2026-01-21T03:16:00Z</updated>
    <author><name>u/RP_Finley</name></author>
    <summary type="html"><![CDATA[<p>Runpod announces reaching $120M ARR with 500K developers, four years after launching from a Reddit post. TechCrunch coverage of their bootstrap journey from basement GPU rigs to major AI cloud platform.</p>]]></summary>
    <category term="industry-news"/>
    <category term="ai-infrastructure"/>
    <category term="business-milestones"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-21:reddit:eb1f7f345321</id>
    <title>[Research] I forensic-audited "Humanity‚Äôs Last Exam" (HLE) &amp; GPQA to benchmark my "unleashed" DeepSeek model. Result: A ~58% verifiable error rate caused by bad OCR and typos.</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qhz9e2/research_i_forensicaudited_humanitys_last_exam/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-eb1f7f345321" rel="related" type="text/html"/>
    <published>2026-01-21T03:12:00Z</published>
    <updated>2026-01-21T03:12:00Z</updated>
    <author><name>u/Dear_Ad_1381</name></author>
    <summary type="html"><![CDATA[<p>Forensic audit of HLE and GPQA benchmarks finding ~58% verifiable error rate from bad OCR and typos, questioning benchmark reliability.</p>]]></summary>
    <category term="benchmarks"/>
    <category term="evaluation"/>
    <category term="quality-analysis"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-21:reddit:bf590dee8d55</id>
    <title>Google Research: Reasoning Models Generate Societies of Thought | "The Social Scalar" OR "Why reasoning models aren't just computing longer, but simulating diverse multi-agent interactions to explore solution spaces"</title>
    <link href="https://reddit.com/r/accelerate/comments/1qhtkvz/google_research_reasoning_models_generate/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-21&amp;category=reddit#item-bf590dee8d55" rel="related" type="text/html"/>
    <published>2026-01-21T03:12:00Z</published>
    <updated>2026-01-21T03:12:00Z</updated>
    <author><name>u/44th--Hokage</name></author>
    <summary type="html"><![CDATA[<p>Google Research paper shows reasoning models like DeepSeek-R1 and o4 spontaneously develop multi-agent internal debates for error correction, creating 'societies of thought'</p>]]></summary>
    <category term="reasoning-models"/>
    <category term="research"/>
    <category term="multi-agent"/>
    <category term="google-research"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-20:category-summary:reddit</id>
    <title>Reddit Summary: January 20, 2026</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qh5wdq/zaiorgglm47flash_hugging_face/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-20&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-20T06:00:00Z</published>
    <updated>2026-01-20T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>r/LocalLLaMA</strong> dominated with <strong>GLM-4.7-Flash</strong> <a href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-3d47fe87b1f2" class="internal-link" rel="noopener noreferrer">release coverage</a>‚Äîthe 30B MoE model drew massive attention for Apache 2.0 licensing and strong agentic performance. Community quickly mobilized with <strong>llama.cpp</strong> <a href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-3230899e945a" class="internal-link" rel="noopener noreferrer">support merge</a>, GGUF quantizations, and real-world testing confirming reliable tool-calling on modest hardware.</p>
<ul>
<li><strong>Microsoft</strong> <a href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-d3578c203a56" class="internal-link" rel="noopener noreferrer"><strong>pausing Claude Code</strong></a> company-wide after Satya intervention sparked heated debate about enterprise AI tool competition and corporate lock-in</li>
<li><strong>OpenAI's GPT Audio models</strong> <a href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-4e8b1141bdfa" class="internal-link" rel="noopener noreferrer">launched</a> with concrete pricing ($32/$64 per million tokens), marking their first GA audio offerings</li>
<li>Security research found <a href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-e4be1d83b87c" class="internal-link" rel="noopener noreferrer"><strong>26% of Claude Code Skills</strong></a> contain risk patterns including prompt injection‚Äîcritical finding for the growing skills ecosystem</li>
</ul>
<p><strong>r/StableDiffusion</strong> explored <strong>FLUX.2 Klein</strong> workflows extensively, with <a href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-92dd45b751ed" class="internal-link" rel="noopener noreferrer">per-segment editing</a> and ControlNet combinations. Meanwhile, a <a href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-31fd4cb12df5" class="internal-link" rel="noopener noreferrer"><strong>12x RTX 5090 homelab</strong> build</a> and <a href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-cd850a7e281f" class="internal-link" rel="noopener noreferrer"><strong>20x faster Top-K implementation</strong></a> showcased the community's push for local inference infrastructure.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-20:reddit:3d47fe87b1f2</id>
    <title>zai-org/GLM-4.7-Flash ¬∑ Hugging Face</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qh5wdq/zaiorgglm47flash_hugging_face/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-3d47fe87b1f2" rel="related" type="text/html"/>
    <published>2026-01-20T03:47:00Z</published>
    <updated>2026-01-20T03:47:00Z</updated>
    <author><name>u/Dark_Fire_12</name></author>
    <summary type="html"><![CDATA[<p>Release announcement of GLM-4.7-Flash, a new 30B parameter MoE model (A3B activated) from Z.ai with strong benchmark performance and Apache 2.0 license</p>]]></summary>
    <category term="model_release"/>
    <category term="open_weights"/>
    <category term="moe_architecture"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-20:reddit:d3578c203a56</id>
    <title>Microsoft pauses Claude Code rollout after Satya intervention</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qgx6br/microsoft_pauses_claude_code_rollout_after_satya/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-d3578c203a56" rel="related" type="text/html"/>
    <published>2026-01-20T03:47:00Z</published>
    <updated>2026-01-20T03:47:00Z</updated>
    <author><name>u/Purple_Wear_5397</name></author>
    <summary type="html"><![CDATA[<p>Microsoft has officially paused Claude Code deployment company-wide after intervention from Satya Nadella, directing employees to use GitHub Copilot instead. Exceptions exist for high-priority R&amp;D with Anthropic API access.</p>]]></summary>
    <category term="industry_news"/>
    <category term="corporate_adoption"/>
    <category term="tool_competition"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-20:reddit:321cdfb3f1ab</id>
    <title>My gpu poor comrades, GLM 4.7 Flash is your local agent</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qhii5v/my_gpu_poor_comrades_glm_47_flash_is_your_local/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-321cdfb3f1ab" rel="related" type="text/html"/>
    <published>2026-01-20T03:40:00Z</published>
    <updated>2026-01-20T03:40:00Z</updated>
    <author><name>u/__Maximum__</name></author>
    <summary type="html"><![CDATA[<p>User reports GLM 4.7 Flash is highly reliable for agentic workloads, successfully handling tool calling, GitHub operations, and code editing without errors over extended sessions</p>]]></summary>
    <category term="model_evaluation"/>
    <category term="agentic_ai"/>
    <category term="local_inference"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-20:reddit:31fd4cb12df5</id>
    <title>üß†üí• My HomeLab GPU Cluster ‚Äì 12√ó RTX 5090, AI / K8s / Self-Hosted Everything</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qh7xnu/my_homelab_gpu_cluster_12_rtx_5090_ai_k8s/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-31fd4cb12df5" rel="related" type="text/html"/>
    <published>2026-01-20T03:40:00Z</published>
    <updated>2026-01-20T03:40:00Z</updated>
    <author><name>u/Murky-Classroom810</name></author>
    <summary type="html"><![CDATA[<p>User showcases a home lab GPU cluster with 12x RTX 5090s (1.5TB+ VRAM total) designed for AI inference, training, image/video generation, and Kubernetes GPU scheduling. Includes detailed hardware specs across 6 machines.</p>]]></summary>
    <category term="hardware_infrastructure"/>
    <category term="gpu_clusters"/>
    <category term="local_ai_deployment"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-20:reddit:3230899e945a</id>
    <title>GLM 4.7 Flash official support merged in llama.cpp</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qhitrj/glm_47_flash_official_support_merged_in_llamacpp/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-3230899e945a" rel="related" type="text/html"/>
    <published>2026-01-20T03:36:00Z</published>
    <updated>2026-01-20T03:36:00Z</updated>
    <author><name>u/ayylmaonade</name></author>
    <summary type="html"><![CDATA[<p>GLM 4.7 Flash official support has been merged into llama.cpp, enabling local inference of the new model</p>]]></summary>
    <category term="llama_cpp"/>
    <category term="infrastructure"/>
    <category term="model_support"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-20:reddit:cd850a7e281f</id>
    <title>I made a Top-K implementation that's up to 20x faster than PyTorch CPU (open source)</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qh0yq8/i_made_a_topk_implementation_thats_up_to_20x/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-cd850a7e281f" rel="related" type="text/html"/>
    <published>2026-01-20T03:31:00Z</published>
    <updated>2026-01-20T03:31:00Z</updated>
    <author><name>u/andreabarbato</name></author>
    <summary type="html"><![CDATA[<p>Developer shares AVX2-optimized Top-K implementation achieving 4-20x speedup over PyTorch CPU, integrated into llama.cpp for 63% faster prompt processing</p>]]></summary>
    <category term="optimization"/>
    <category term="open_source"/>
    <category term="performance"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-20:reddit:92dd45b751ed</id>
    <title>Flux.2 Klein - per segment (character, object) inpaint edit</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qgz19r/flux2_klein_per_segment_character_object_inpaint/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-92dd45b751ed" rel="related" type="text/html"/>
    <published>2026-01-20T03:31:00Z</published>
    <updated>2026-01-20T03:31:00Z</updated>
    <author><name>u/pamdog</name></author>
    <summary type="html"><![CDATA[<p>Developer demonstrates per-segment editing workflow for FLUX.2 Klein enabling separate prompts for different characters/objects in the same image (e.g., different hair colors per character while fixing hands globally). Very fast processing.</p>]]></summary>
    <category term="flux_klein"/>
    <category term="image_editing_workflows"/>
    <category term="comfyui_workflows"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-20:reddit:f342271559e0</id>
    <title>New in llama.cpp: Anthropic Messages API</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qhaq21/new_in_llamacpp_anthropic_messages_api/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-f342271559e0" rel="related" type="text/html"/>
    <published>2026-01-20T03:23:00Z</published>
    <updated>2026-01-20T03:23:00Z</updated>
    <author><name>u/paf1138</name></author>
    <summary type="html"><![CDATA[<p>llama.cpp adds Anthropic Messages API support, improving compatibility with tools expecting Claude's API format</p>]]></summary>
    <category term="llama_cpp"/>
    <category term="api_compatibility"/>
    <category term="infrastructure"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-20:reddit:e4be1d83b87c</id>
    <title>26% of Claude Code Skills in marketplaces contain at least one security risk pattern</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qh0400/26_of_claude_code_skills_in_marketplaces_contain/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-e4be1d83b87c" rel="related" type="text/html"/>
    <published>2026-01-20T03:23:00Z</published>
    <updated>2026-01-20T03:23:00Z</updated>
    <author><name>u/necati-ozmen</name></author>
    <summary type="html"><![CDATA[<p>First security research on Claude Code Skills finds 26% of skills from uncurated marketplaces contain security risk patterns including prompt injection, data exfiltration, and supply-chain abuse vulnerabilities.</p>]]></summary>
    <category term="security_research"/>
    <category term="claude_code"/>
    <category term="supply_chain_risks"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-20:reddit:cbdbbe688813</id>
    <title>ChatGPT changed my life: down 150 lbs in 8 months</title>
    <link href="https://reddit.com/r/ChatGPTPro/comments/1qh92wk/chatgpt_changed_my_life_down_150_lbs_in_8_months/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-cbdbbe688813" rel="related" type="text/html"/>
    <published>2026-01-20T03:23:00Z</published>
    <updated>2026-01-20T03:23:00Z</updated>
    <author><name>u/Proud-Historian-490</name></author>
    <summary type="html"><![CDATA[<p>User shares 8-month weight loss journey (150 lbs) crediting ChatGPT for providing structure through meal planning, workout routines, and accountability. Update to previous post with discussion about over-reliance on AI.</p>]]></summary>
    <category term="practical_ai_applications"/>
    <category term="personal_productivity"/>
    <category term="chatgpt_use_cases"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-20:reddit:200582530a7b</id>
    <title>Unsloth GLM 4.7-Flash GGUF</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qhlnsv/unsloth_glm_47flash_gguf/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-200582530a7b" rel="related" type="text/html"/>
    <published>2026-01-20T03:16:00Z</published>
    <updated>2026-01-20T03:16:00Z</updated>
    <author><name>u/Wooden-Deer-1276</name></author>
    <summary type="html"><![CDATA[<p>Unsloth releases GGUF quantizations of GLM 4.7 Flash, making the model accessible for various hardware configurations</p>]]></summary>
    <category term="quantization"/>
    <category term="model_release"/>
    <category term="accessibility"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-20:reddit:5dc1195fe9bb</id>
    <title>Z.ai Launches GLM-4.7-Flash: 30B Coding model &amp; 59.2% SWE-bench verified in benchmarks</title>
    <link href="https://reddit.com/r/singularity/comments/1qh802r/zai_launches_glm47flash_30b_coding_model_592/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-5dc1195fe9bb" rel="related" type="text/html"/>
    <published>2026-01-20T03:16:00Z</published>
    <updated>2026-01-20T03:16:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>Z.ai releases GLM-4.7-Flash, a 30B parameter coding model achieving 59.2% on SWE-bench verified. Offered with free tier (1 concurrency) and positioned for local deployment, creative writing, translation, and agentic tasks.</p>]]></summary>
    <category term="model_release"/>
    <category term="coding_models"/>
    <category term="benchmarks"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-20:reddit:2ea170e4abe5</id>
    <title>Accusations flying that Nvidia has quietly funded MAGA influencers to kill an AI safety bill, flooding Twitter with nearly identical posts on the same day.</title>
    <link href="https://reddit.com/r/ChatGPT/comments/1qh6ae7/accusations_flying_that_nvidia_has_quietly_funded/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-2ea170e4abe5" rel="related" type="text/html"/>
    <published>2026-01-20T03:16:00Z</published>
    <updated>2026-01-20T03:16:00Z</updated>
    <author><name>u/melted-dashboard</name></author>
    <summary type="html"><![CDATA[<p>Discussion about allegations that Nvidia secretly funded MAGA influencers to oppose an AI safety bill, with evidence of coordinated identical posts on Twitter. Links to investigative article detailing suspicious similarities across multiple accounts.</p>]]></summary>
    <category term="ai_policy"/>
    <category term="corporate_influence"/>
    <category term="ai_safety"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-20:reddit:39d43144486a</id>
    <title>Last week in Image &amp; Video Generation</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qhoilx/last_week_in_image_video_generation/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-20&amp;category=reddit#item-39d43144486a" rel="related" type="text/html"/>
    <published>2026-01-20T03:16:00Z</published>
    <updated>2026-01-20T03:16:00Z</updated>
    <author><name>u/Vast_Yak_4147</name></author>
    <summary type="html"><![CDATA[<p>Weekly curated roundup of open-source diffusion highlights including FLUX.2 Klein (consumer GPU compatible, 13GB VRAM, multi-task generation) with links to blog, demos, and models.</p>]]></summary>
    <category term="weekly_roundup"/>
    <category term="flux_klein"/>
    <category term="open_source_models"/>
  </entry>
</feed>