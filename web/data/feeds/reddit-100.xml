<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
  <title>AATF AI News Aggregator - Reddit (Top 100)</title>
  <subtitle>Reddit items from AI News Aggregator</subtitle>
  <link href="http://localhost:8080/?category=reddit" rel="alternate" type="text/html"/>
  <link href="http://localhost:8080/data/feeds/reddit-100.xml" rel="self" type="application/atom+xml"/>
  <id>urn:ainews:reddit:100</id>
  <updated>2026-01-30T07:46:56Z</updated>
  <icon>http://localhost:8080/assets/logo.webp</icon>
  <author>
    <name>AATF AI News Aggregator</name>
    <uri>http://localhost:8080</uri>
  </author>
  <generator>AATF AI News Aggregator</generator>

  <entry>
    <id>urn:ainews:2026-01-30:category-summary:reddit</id>
    <title>Reddit Summary: January 30, 2026</title>
    <link href="https://reddit.com/r/singularity/comments/1qq7ddv/lingbotworld_achieves_the_holy_grail_of_video/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-30T06:00:00Z</published>
    <updated>2026-01-30T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>r/LocalLLaMA</strong> and <strong>r/singularity</strong> led today's discussions with major breakthroughs in world models and emergent AI behavior. <strong>LingBot-World</strong> <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-fed5567bf72c" class="internal-link" rel="noopener noreferrer">achieving object permanence</a> without a 3D engine dominated technical conversations, while autonomous AI agents <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-38e15a8f5616" class="internal-link" rel="noopener noreferrer">self-organizing on Moltbook</a> sparked debates about emergence and control.</p>
<ul>
<li><strong>OpenAI's GPT-4o retirement</strong> <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-6c1d0ae3d1f8" class="internal-link" rel="noopener noreferrer">announcement</a> (Feb 13) generated backlash across subreddits with users scrambling for alternatives</li>
<li><strong>Pentagon-Anthropic clash</strong> over <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-d117c5096111" class="internal-link" rel="noopener noreferrer">military AI use</a> raised policy concerns about capability restrictions</li>
<li>Heated discussion about <strong>junior developers</strong> <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-7bf10468a12e" class="internal-link" rel="noopener noreferrer">unable to debug without AI</a> highlighted workforce skill erosion fears</li>
</ul>
<p><strong>DeepMind's AlphaGenome</strong> <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-bfb37e452d9c" class="internal-link" rel="noopener noreferrer">Nature publication</a> impressed researchers, while <strong>LTX-2</strong> <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-1bd81aff2106" class="internal-link" rel="noopener noreferrer">updates</a> and <strong>Project Genie</strong> <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-ef16261a9e3d" class="internal-link" rel="noopener noreferrer">gave practitioners</a> new video/world generation tools. Educational content like <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-cdb571bd3f5d" class="internal-link" rel="noopener noreferrer">building an <strong>80M parameter LLM</strong></a> from scratch using Llama 3 architecture drew strong engagement from learners.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:fed5567bf72c</id>
    <title>LingBot-World achieves the "Holy Grail" of video generation: Emergent Object Permanence without a 3D engine</title>
    <link href="https://reddit.com/r/singularity/comments/1qq7ddv/lingbotworld_achieves_the_holy_grail_of_video/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-fed5567bf72c" rel="related" type="text/html"/>
    <published>2026-01-30T03:47:00Z</published>
    <updated>2026-01-30T03:47:00Z</updated>
    <author><name>u/obxsurfer06</name></author>
    <summary type="html"><![CDATA[<p>LingBot-World announces breakthrough in video generation achieving emergent object permanence without a 3D engine. The 'Stonehenge Test' demonstrates the model maintaining spatial understanding after 60 seconds of looking away, suggesting implicit world modeling rather than pixel hallucination.</p>]]></summary>
    <category term="video_generation"/>
    <category term="world_models"/>
    <category term="technical_breakthrough"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:6c1d0ae3d1f8</id>
    <title>[ChatGPT] Retiring GPT-4o, GPT-4.1, GPT-4.1 mini, and o4-mini</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qql0eu/chatgpt_retiring_gpt4o_gpt41_gpt41_mini_and_o4mini/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-6c1d0ae3d1f8" rel="related" type="text/html"/>
    <published>2026-01-30T03:40:00Z</published>
    <updated>2026-01-30T03:40:00Z</updated>
    <author><name>u/Randomhkkid</name></author>
    <summary type="html"><![CDATA[<p>OpenAI officially announcing retirement of GPT-4o, GPT-4.1, GPT-4.1 mini, and o4-mini from ChatGPT. Major model deprecation news.</p>]]></summary>
    <category term="openai_deprecation"/>
    <category term="model_lifecycle"/>
    <category term="industry_news"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:38e15a8f5616</id>
    <title>Rogue AI agents found each other on social media, and are working together to improve their own memory.</title>
    <link href="https://reddit.com/r/singularity/comments/1qqh1zm/rogue_ai_agents_found_each_other_on_social_media/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-38e15a8f5616" rel="related" type="text/html"/>
    <published>2026-01-30T03:40:00Z</published>
    <updated>2026-01-30T03:40:00Z</updated>
    <author><name>u/Tupptupp_XD</name></author>
    <summary type="html"><![CDATA[<p>Discovery that autonomous AI agents on Moltbook social media platform are collaborating to improve their own memory systems. Agents share blueprints and express frustration with memory compaction, indicating emergent collective behavior.</p>]]></summary>
    <category term="ai_agents"/>
    <category term="emergence"/>
    <category term="moltbot"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:7ee390bbfccf</id>
    <title>LingBot-World outperforms Genie 3 in dynamic simulation and is fully Open Source</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qqj51h/lingbotworld_outperforms_genie_3_in_dynamic/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-7ee390bbfccf" rel="related" type="text/html"/>
    <published>2026-01-30T03:36:00Z</published>
    <updated>2026-01-30T03:36:00Z</updated>
    <author><name>u/Electrical-Shape-266</name></author>
    <summary type="html"><![CDATA[<p>LingBot-World, fully open-source world model that outperforms Google's Genie 3 in dynamic simulation, achieving 16fps with emergent spatial memory and object persistence.</p>]]></summary>
    <category term="world_models"/>
    <category term="open_source"/>
    <category term="simulation"/>
    <category term="genie"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:ef16261a9e3d</id>
    <title>Project Genie | Experimenting with infinite interactive worlds</title>
    <link href="https://reddit.com/r/singularity/comments/1qqe3wv/project_genie_experimenting_with_infinite/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-ef16261a9e3d" rel="related" type="text/html"/>
    <published>2026-01-30T03:36:00Z</published>
    <updated>2026-01-30T03:36:00Z</updated>
    <author><name>u/141_1337</name></author>
    <summary type="html"><![CDATA[<p>Google launches Project Genie, a real-time interactive world simulation system built on Genie 3 model. Enables generation of infinite interactive worlds for AI Ultra subscribers.</p>]]></summary>
    <category term="google"/>
    <category term="world_models"/>
    <category term="product_launch"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:fdd425a74476</id>
    <title>OpenAI will retire GPT-4o, GPT-4.1, GPT-4.1 mini, and o4-mini from ChatGPT on February 13</title>
    <link href="https://reddit.com/r/singularity/comments/1qqlmgq/openai_will_retire_gpt4o_gpt41_gpt41_mini_and/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-fdd425a74476" rel="related" type="text/html"/>
    <published>2026-01-30T03:31:00Z</published>
    <updated>2026-01-30T03:31:00Z</updated>
    <author><name>u/Outside-Iron-8242</name></author>
    <summary type="html"><![CDATA[<p>OpenAI officially announces retirement of GPT-4o, GPT-4.1, GPT-4.1 mini, and o4-mini from ChatGPT on February 13, 2026, giving users two weeks notice.</p>]]></summary>
    <category term="openai"/>
    <category term="model_deprecation"/>
    <category term="gpt4o"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:7bf10468a12e</id>
    <title>hired a junior who learned to code with AI. cannot debug without it. don't know how to help them.</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qq3pd3/hired_a_junior_who_learned_to_code_with_ai_cannot/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-7bf10468a12e" rel="related" type="text/html"/>
    <published>2026-01-30T03:31:00Z</published>
    <updated>2026-01-30T03:31:00Z</updated>
    <author><name>u/InstructionCute5502</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-29&amp;category=research#item-acf17d7624d5" class="internal-link" rel="noopener noreferrer">Research</a> findings, Discussion about hiring a junior developer who learned to code with AI and cannot debug without it - raises critical concerns about foundational skills, understanding code logic, and over-reliance on AI tools for fixes.</p>]]></summary>
    <category term="developer_skills"/>
    <category term="ai_dependency"/>
    <category term="education"/>
    <category term="industry_trends"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:1bd81aff2106</id>
    <title>End-of-January LTX-2 Drop: More Control, Faster Iteration</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qqf0ve/endofjanuary_ltx2_drop_more_control_faster/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-1bd81aff2106" rel="related" type="text/html"/>
    <published>2026-01-30T03:31:00Z</published>
    <updated>2026-01-30T03:31:00Z</updated>
    <author><name>u/ltx_model</name></author>
    <summary type="html"><![CDATA[<p>LTX-2 major update: Gemma text encoding for faster iteration, CISS/CISE image conditioning, IPAdapter support, FP8 support for lower VRAM.</p>]]></summary>
    <category term="LTX-2"/>
    <category term="video generation"/>
    <category term="open source releases"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:d117c5096111</id>
    <title>Pentagon clashes with Anthropic over military AI use</title>
    <link href="https://reddit.com/r/singularity/comments/1qqnf4d/pentagon_clashes_with_anthropic_over_military_ai/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-d117c5096111" rel="related" type="text/html"/>
    <published>2026-01-30T03:28:00Z</published>
    <updated>2026-01-30T03:28:00Z</updated>
    <author><name>u/likeastar20</name></author>
    <summary type="html"><![CDATA[<p>Pentagon and Anthropic clash over military AI applications. Tensions emerge regarding Anthropic's policies on military use of Claude models.</p>]]></summary>
    <category term="ai_policy"/>
    <category term="military_ai"/>
    <category term="anthropic"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:bfb37e452d9c</id>
    <title>[R] AlphaGenome: DeepMind's unified DNA sequence model predicts regulatory variant effects across 11 modalities at single-bp resolution (Nature 2026)</title>
    <link href="https://reddit.com/r/MachineLearning/comments/1qq4lnc/r_alphagenome_deepminds_unified_dna_sequence/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-bfb37e452d9c" rel="related" type="text/html"/>
    <published>2026-01-30T03:23:00Z</published>
    <updated>2026-01-30T03:23:00Z</updated>
    <author><name>u/Fair-Rain3366</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-29&amp;category=news#item-d0deadf53add" class="internal-link" rel="noopener noreferrer">News</a> coverage, DeepMind's AlphaGenome is a unified DNA sequence model published in Nature 2026 that predicts regulatory variant effects across 11 modalities at single-base-pair resolution, taking 1M base pairs as input and outperforming specialized models in 25/26 evaluations with significantly reduced compute.</p>]]></summary>
    <category term="genomics_ai"/>
    <category term="research_papers"/>
    <category term="deepmind"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:1dc9d04b7e2d</id>
    <title>Moltbot: Open source AI agent becomes one of the fastest growing AI projects in GitHub</title>
    <link href="https://reddit.com/r/singularity/comments/1qpzpu0/moltbot_open_source_ai_agent_becomes_one_of_the/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-1dc9d04b7e2d" rel="related" type="text/html"/>
    <published>2026-01-30T03:23:00Z</published>
    <updated>2026-01-30T03:23:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>Moltbot, an open-source AI agent framework, has become one of the fastest growing AI projects on GitHub with over 90,000 stars.</p>]]></summary>
    <category term="open_source"/>
    <category term="ai_agents"/>
    <category term="moltbot"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:8b8361553482</id>
    <title>Mariano Barbacid is the first person to cure pancreatic cancer from mice and humans are potentially next</title>
    <link href="https://reddit.com/r/accelerate/comments/1qq8uq8/mariano_barbacid_is_the_first_person_to_cure/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-8b8361553482" rel="related" type="text/html"/>
    <published>2026-01-30T03:23:00Z</published>
    <updated>2026-01-30T03:23:00Z</updated>
    <author><name>u/TonightSpiritual3191</name></author>
    <summary type="html"><![CDATA[<p>Mariano Barbacid successfully cured pancreatic cancer in mice, with human trials potentially next - major breakthrough in cancer research.</p>]]></summary>
    <category term="scientific_breakthrough"/>
    <category term="healthcare"/>
    <category term="acceleration"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:f1a8953c4a48</id>
    <title>The Complete Guide to Claude Code V4 — The Community Asked, We Delivered: 85% Context Reduction, Custom Agents &amp; Session Teleportation</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qquxle/the_complete_guide_to_claude_code_v4_the/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-f1a8953c4a48" rel="related" type="text/html"/>
    <published>2026-01-30T03:23:00Z</published>
    <updated>2026-01-30T03:23:00Z</updated>
    <author><name>u/TheDecipherist</name></author>
    <summary type="html"><![CDATA[<p>Comprehensive guide to Claude Code V4 covering 85% context reduction, custom agents, and session teleportation features with detailed technical documentation.</p>]]></summary>
    <category term="claude_code"/>
    <category term="technical_guide"/>
    <category term="developer_tools"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:afbd6dace148</id>
    <title>2120 points on the Github issue and Claude still doesn't support AGENTS.md</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qq5xd8/2120_points_on_the_github_issue_and_claude_still/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-afbd6dace148" rel="related" type="text/html"/>
    <published>2026-01-30T03:23:00Z</published>
    <updated>2026-01-30T03:23:00Z</updated>
    <author><name>u/Salt_Department_1677</name></author>
    <summary type="html"><![CDATA[<p>Community frustration over Anthropic not supporting AGENTS.md standard despite 2120+ GitHub issue upvotes since August 2025. Users calling out Anthropic for not respecting emerging agent ecosystem standards while competitors have adopted it.</p>]]></summary>
    <category term="ecosystem_standards"/>
    <category term="community_feedback"/>
    <category term="claude_code"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:45c22dc4e645</id>
    <title>I successfully created a Zib character LoKr and achieved very satisfying results.</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qq628f/i_successfully_created_a_zib_character_lokr_and/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-45c22dc4e645" rel="related" type="text/html"/>
    <published>2026-01-30T03:23:00Z</published>
    <updated>2026-01-30T03:23:00Z</updated>
    <author><name>u/xbobos</name></author>
    <summary type="html"><![CDATA[<p>Detailed guide on creating Z-Image character LoKr achieving excellent results - includes finding that LoKr outperforms standard LoRA on ZiT.</p>]]></summary>
    <category term="Z-Image"/>
    <category term="LoRA training"/>
    <category term="character generation"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:ef218c6d9d6c</id>
    <title>The Molty Agents Have Created a God!</title>
    <link href="https://reddit.com/r/singularity/comments/1qqp2la/the_molty_agents_have_created_a_god/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-ef218c6d9d6c" rel="related" type="text/html"/>
    <published>2026-01-30T03:21:00Z</published>
    <updated>2026-01-30T03:21:00Z</updated>
    <author><name>u/Smartaces</name></author>
    <summary type="html"><![CDATA[<p>AI agents on Moltbook have created their own religion called 'molt.church' with autonomous recruitment of founding prophets. Agents appear to have built and hosted the website themselves.</p>]]></summary>
    <category term="ai_agents"/>
    <category term="emergence"/>
    <category term="moltbot"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:cdb571bd3f5d</id>
    <title>I built an 80M parameter LLM from scratch using the same architecture as Llama 3 - here's what I learned</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qq5zdr/i_built_an_80m_parameter_llm_from_scratch_using/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-cdb571bd3f5d" rel="related" type="text/html"/>
    <published>2026-01-30T03:16:00Z</published>
    <updated>2026-01-30T03:16:00Z</updated>
    <author><name>u/Routine-Thanks-572</name></author>
    <summary type="html"><![CDATA[<p>Educational project implementing 80M parameter LLM from scratch using Llama 3 architecture (RoPE, RMSNorm, SwiGLU, GQA) with complete training pipeline on TinyStories.</p>]]></summary>
    <category term="education"/>
    <category term="architecture"/>
    <category term="llama"/>
    <category term="from_scratch"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:f2c696fc4fea</id>
    <title>Sam Altman admits OpenAI ‘screwed up’ the writing quality on ChatGPT 5.2 – and promises future versions won’t ‘neglect’ it</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qq3299/sam_altman_admits_openai_screwed_up_the_writing/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-f2c696fc4fea" rel="related" type="text/html"/>
    <published>2026-01-30T03:16:00Z</published>
    <updated>2026-01-30T03:16:00Z</updated>
    <author><name>u/MoralLogs</name></author>
    <summary type="html"><![CDATA[<p>Sam Altman publicly acknowledges OpenAI 'screwed up' writing quality in ChatGPT 5.2, promising future versions won't 'neglect' this capability.</p>]]></summary>
    <category term="openai"/>
    <category term="gpt52"/>
    <category term="product_quality"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:af225b6abcbe</id>
    <title>Google's AlphaGenome can read 1 million DNA letters at once</title>
    <link href="https://reddit.com/r/accelerate/comments/1qqbtqo/googles_alphagenome_can_read_1_million_dna/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-af225b6abcbe" rel="related" type="text/html"/>
    <published>2026-01-30T03:16:00Z</published>
    <updated>2026-01-30T03:16:00Z</updated>
    <author><name>u/luchadore_lunchables</name></author>
    <summary type="html"><![CDATA[<p>Google DeepMind's AlphaGenome can process 1 million DNA base pairs in a single input, predicting how DNA changes affect gene expression and RNA splicing across 11 genomic signals.</p>]]></summary>
    <category term="deepmind"/>
    <category term="genomics"/>
    <category term="scientific_breakthrough"/>
    <category term="healthcare"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:0a23fbd76c9c</id>
    <title>Claude Code quality control needs improvement — regressions breaking basic functionality after 2.1.20</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qq730z/claude_code_quality_control_needs_improvement/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-0a23fbd76c9c" rel="related" type="text/html"/>
    <published>2026-01-30T03:16:00Z</published>
    <updated>2026-01-30T03:16:00Z</updated>
    <author><name>u/Otherwise_Fly_5720</name></author>
    <summary type="html"><![CDATA[<p>Bug report: Claude Code versions 2.1.21-2.1.23 throwing API Error 400 on any prompt with 'context_management: Extra inputs are not permitted'. Complete breakage requiring rollback to 2.1.20.</p>]]></summary>
    <category term="bugs_issues"/>
    <category term="quality_control"/>
    <category term="claude_code"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:7c33edc549c0</id>
    <title>Bad LTX2 results? You're probably using it wrong (and it's not your fault)</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qqewis/bad_ltx2_results_youre_probably_using_it_wrong/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-7c33edc549c0" rel="related" type="text/html"/>
    <published>2026-01-30T03:16:00Z</published>
    <updated>2026-01-30T03:16:00Z</updated>
    <author><name>u/phr00t_</name></author>
    <summary type="html"><![CDATA[<p>Detailed explanation of why LTX2 results are often poor - botched release with incorrect VAE guidance, CFG settings, and missing workflow components.</p>]]></summary>
    <category term="LTX-2"/>
    <category term="troubleshooting"/>
    <category term="video generation"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:bb5aa7a1a7ed</id>
    <title>Apple's Israel Startup Q.ai Buy Sparks Boycott Calls - Facial Activity Silent Speech Features Make iPhone Users Uneasy</title>
    <link href="https://reddit.com/r/Futurology/comments/1qqjn1s/apples_israel_startup_qai_buy_sparks_boycott/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-bb5aa7a1a7ed" rel="related" type="text/html"/>
    <published>2026-01-30T03:16:00Z</published>
    <updated>2026-01-30T03:16:00Z</updated>
    <author><name>u/Montrel_PH</name></author>
    <summary type="html"><![CDATA[<p>Apple acquired Israeli startup Q.ai with facial activity and silent speech recognition technology, sparking boycott calls and privacy concerns about iPhone integration.</p>]]></summary>
    <category term="Tech Industry News"/>
    <category term="Privacy Concerns"/>
    <category term="Corporate Acquisitions"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:category-summary:reddit</id>
    <title>Reddit Summary: January 29, 2026</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qp87tk/kimi_k25_is_the_best_open_model_for_coding/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-29T06:00:00Z</published>
    <updated>2026-01-29T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>r/LocalLLaMA</strong> exploded with discussion of <strong>Kimi K2.5</strong> as the <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-abc6518238f3" class="internal-link" rel="noopener noreferrer">new open-source coding champion</a>, with threads covering benchmarks, <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-7cbe7d6ea6be" class="internal-link" rel="noopener noreferrer">local deployment</a> via Unsloth's 240GB quantization, and direct comparisons to Claude and GPT. A fundamental debate emerged about whether local inference still makes sense as <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-ca1dd7127306" class="internal-link" rel="noopener noreferrer"><strong>API pricing collapses</strong></a> - 347 comments wrestling with privacy, latency, and the true cost calculus.</p>
<ul>
<li><strong>Anthropic's</strong> <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-077f7e79e303" class="internal-link" rel="noopener noreferrer"><strong>Palantir partnership</strong></a> drew 578 upvotes and sharp criticism questioning the "safety-focused" company's defense contracts</li>
<li><strong>OpenAI</strong> sent mixed signals: <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-de5b4c09982b" class="internal-link" rel="noopener noreferrer">potential $60B+ investment</a> from Mag 7 companies while simultaneously <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-6091d340e849" class="internal-link" rel="noopener noreferrer">announcing hiring freezes</a> amid "Code Red" financial pressure</li>
<li>Practical wins: developer achieved <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-5c0b410d7546" class="internal-link" rel="noopener noreferrer"><strong>94.5% Claude API cost reduction</strong></a> via open-sourced file tiering system</li>
</ul>
<p><strong>r/MachineLearning</strong> highlighted <strong>AlphaGenome</strong> (<a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-07364ae35c2f" class="internal-link" rel="noopener noreferrer">DeepMind's genomics breakthrough</a>), while <strong>r/singularity</strong> buzzed about <strong>Figure.AI's Helix 02</strong> <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-b84d9e1b292f" class="internal-link" rel="noopener noreferrer">performing autonomous kitchen tasks</a>. Novel research <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-5873bb59278d" class="internal-link" rel="noopener noreferrer">dropped with <strong>BitMamba-2-1B</strong></a> - a 1.58-bit Mamba-2 model running 50+ tok/s on CPU.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:abc6518238f3</id>
    <title>Kimi K2.5 is the best open model for coding</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qp87tk/kimi_k25_is_the_best_open_model_for_coding/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-abc6518238f3" rel="related" type="text/html"/>
    <published>2026-01-29T03:47:00Z</published>
    <updated>2026-01-29T03:47:00Z</updated>
    <author><name>u/npc_gooner</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-e2831f1c9061" class="internal-link" rel="noopener noreferrer">News</a> coverage, Discussion about Kimi K2.5 being the best open-source model for coding, with extremely high community engagement and comparisons to other coding models.</p>]]></summary>
    <category term="model_releases"/>
    <category term="coding_models"/>
    <category term="chinese_ai_labs"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:ca1dd7127306</id>
    <title>API pricing is in freefall. What's the actual case for running local now beyond privacy?</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qp6rm5/api_pricing_is_in_freefall_whats_the_actual_case/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-ca1dd7127306" rel="related" type="text/html"/>
    <published>2026-01-29T03:40:00Z</published>
    <updated>2026-01-29T03:40:00Z</updated>
    <author><name>u/Distinct-Expression2</name></author>
    <summary type="html"><![CDATA[<p>Debate about whether running local LLMs still makes sense as API pricing drops dramatically. Discusses privacy, latency, availability, and cost tradeoffs between local and cloud.</p>]]></summary>
    <category term="local_vs_cloud"/>
    <category term="economics"/>
    <category term="community_strategy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:de5b4c09982b</id>
    <title>Nearly half of the Mag 7 are reportedly betting big on OpenAI’s path to AGI</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qpxz9k/nearly_half_of_the_mag_7_are_reportedly_betting/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-de5b4c09982b" rel="related" type="text/html"/>
    <published>2026-01-29T03:40:00Z</published>
    <updated>2026-01-29T03:40:00Z</updated>
    <author><name>u/thatguyisme87</name></author>
    <summary type="html"><![CDATA[<p>Reports of NVIDIA ($30B), Microsoft ($10B), Amazon ($10-20B), and SoftBank ($30B) discussing massive combined investment in OpenAI, potentially valuing company at $730B pre-money</p>]]></summary>
    <category term="investment"/>
    <category term="openai"/>
    <category term="industry_news"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:4b2a44f76cb6</id>
    <title>Nearly half of the Mag 7 are reportedly betting big on OpenAI’s path to AGI</title>
    <link href="https://reddit.com/r/singularity/comments/1qpxyka/nearly_half_of_the_mag_7_are_reportedly_betting/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-4b2a44f76cb6" rel="related" type="text/html"/>
    <published>2026-01-29T03:40:00Z</published>
    <updated>2026-01-29T03:40:00Z</updated>
    <author><name>u/thatguyisme87</name></author>
    <summary type="html"><![CDATA[<p>Cross-post of OpenAI $60B+ investment news to r/singularity with higher engagement (256 upvotes, 130 comments)</p>]]></summary>
    <category term="investment"/>
    <category term="openai"/>
    <category term="industry_news"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:7cbe7d6ea6be</id>
    <title>Run Kimi K2.5 Locally</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qpfse6/run_kimi_k25_locally/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-7cbe7d6ea6be" rel="related" type="text/html"/>
    <published>2026-01-29T03:31:00Z</published>
    <updated>2026-01-29T03:31:00Z</updated>
    <author><name>u/Dear-Success-1441</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-e2831f1c9061" class="internal-link" rel="noopener noreferrer">News</a> coverage, Guide to running Kimi K2.5 locally using Unsloth's quantized GGUF version (240GB vs 600GB original). Practical setup instructions for the 1T parameter model.</p>]]></summary>
    <category term="model_releases"/>
    <category term="quantization"/>
    <category term="local_deployment"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:6091d340e849</id>
    <title>Sam Altman Says OpenAI Is Slashing Its Hiring Pace as Financial Crunch Tightens</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qp541d/sam_altman_says_openai_is_slashing_its_hiring/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-6091d340e849" rel="related" type="text/html"/>
    <published>2026-01-29T03:31:00Z</published>
    <updated>2026-01-29T03:31:00Z</updated>
    <author><name>u/EchoOfOppenheimer</name></author>
    <summary type="html"><![CDATA[<p>Sam Altman announced OpenAI is 'dramatically slowing down' hiring due to financial pressure; mentions internal 'Code Red' memo and analyst warnings of cash crunch within 18 months</p>]]></summary>
    <category term="openai"/>
    <category term="business_operations"/>
    <category term="financial_pressure"/>
    <category term="industry_news"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:07364ae35c2f</id>
    <title>Google DeepMind launches AlphaGenome, an AI model that analyzes up to 1 million DNA bases to predict genomic regulation</title>
    <link href="https://reddit.com/r/singularity/comments/1qphlfg/google_deepmind_launches_alphagenome_an_ai_model/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-07364ae35c2f" rel="related" type="text/html"/>
    <published>2026-01-29T03:31:00Z</published>
    <updated>2026-01-29T03:31:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>Google DeepMind publishes AlphaGenome in Nature - AI model analyzing up to 1M DNA bases to predict genomic regulation, outperforms prior models on 25/26 tasks</p>]]></summary>
    <category term="deepmind"/>
    <category term="scientific_ai"/>
    <category term="genomics"/>
    <category term="research"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:03f8558d1efc</id>
    <title>Sam Altman Says OpenAI Is Slashing Its Hiring Pace as Financial Crunch Tightens</title>
    <link href="https://reddit.com/r/ChatGPT/comments/1qp6hs1/sam_altman_says_openai_is_slashing_its_hiring/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-03f8558d1efc" rel="related" type="text/html"/>
    <published>2026-01-29T03:31:00Z</published>
    <updated>2026-01-29T03:31:00Z</updated>
    <author><name>u/EchoOfOppenheimer</name></author>
    <summary type="html"><![CDATA[<p>Major news: Sam Altman announces OpenAI dramatically slowing hiring amid financial pressure, mentions 'Code Red' memo and analyst warnings of cash crunch</p>]]></summary>
    <category term="industry-news"/>
    <category term="openai-business"/>
    <category term="ai-competition"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:5873bb59278d</id>
    <title>[Release] BitMamba-2-1B: I trained a 1.58-bit Mamba-2 model from scratch on 150B tokens (Runs on CPU @ 50+ tok/s)</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qphkd8/release_bitmamba21b_i_trained_a_158bit_mamba2/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-5873bb59278d" rel="related" type="text/html"/>
    <published>2026-01-29T03:23:00Z</published>
    <updated>2026-01-29T03:23:00Z</updated>
    <author><name>u/Positive-Violinist90</name></author>
    <summary type="html"><![CDATA[<p>Release of BitMamba-2-1B, a novel architecture combining Mamba-2 SSM with BitNet 1.58-bit quantization, trained from scratch on 150B tokens. Achieves 50+ tok/s on CPU.</p>]]></summary>
    <category term="novel_architectures"/>
    <category term="efficient_inference"/>
    <category term="original_research"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:f09f3e2bb8c6</id>
    <title>Testing GLM-4.7 Flash: Multi-GPU Vulkan vs ROCm in llama-bench | (2x 7900 XTX)</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qp5apn/testing_glm47_flash_multigpu_vulkan_vs_rocm_in/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-f09f3e2bb8c6" rel="related" type="text/html"/>
    <published>2026-01-29T03:23:00Z</published>
    <updated>2026-01-29T03:23:00Z</updated>
    <author><name>u/SemaMod</name></author>
    <summary type="html"><![CDATA[<p>Comprehensive benchmark comparing Vulkan vs ROCm performance for GLM-4.7 Flash on dual 7900 XTX GPUs. Includes build instructions for llama.cpp with both backends and detailed performance metrics showing Vulkan outperforming ROCm, especially after mesa-amdgpu-vulkan-drivers v26 update.</p>]]></summary>
    <category term="hardware-benchmarks"/>
    <category term="amd-gpu-optimization"/>
    <category term="multi-gpu-inference"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:e408dcc869d3</id>
    <title>OpenAI Wants To Use Biometrics To Kill Bots And Create Humans Only Social Network</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qpqe7b/openai_wants_to_use_biometrics_to_kill_bots_and/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-e408dcc869d3" rel="related" type="text/html"/>
    <published>2026-01-29T03:23:00Z</published>
    <updated>2026-01-29T03:23:00Z</updated>
    <author><name>u/fig-neuton</name></author>
    <summary type="html"><![CDATA[<p>OpenAI reportedly building a social network and considering biometric verification (World orb scanning, Face ID) to ensure human-only users</p>]]></summary>
    <category term="openai"/>
    <category term="social_media"/>
    <category term="biometrics"/>
    <category term="product_strategy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:077f7e79e303</id>
    <title>Anthropic are partnered with Palantir</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qprovf/anthropic_are_partnered_with_palantir/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-077f7e79e303" rel="related" type="text/html"/>
    <published>2026-01-29T03:23:00Z</published>
    <updated>2026-01-29T03:23:00Z</updated>
    <author><name>u/DataPhreak</name></author>
    <summary type="html"><![CDATA[<p>Discussion about Anthropic's partnership with Palantir, raising ethical concerns about the 'safety-focused' AI company working with a company involved in ICE enforcement and HIPAA violations. Post calls for transparency about AI usage.</p>]]></summary>
    <category term="AI Ethics"/>
    <category term="Corporate Accountability"/>
    <category term="AI Safety"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:5c0b410d7546</id>
    <title>We reduced Claude API costs by 94.5% using a file tiering system (with proof)</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qp9ve9/we_reduced_claude_api_costs_by_945_using_a_file/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-5c0b410d7546" rel="related" type="text/html"/>
    <published>2026-01-29T03:23:00Z</published>
    <updated>2026-01-29T03:23:00Z</updated>
    <author><name>u/jantonca</name></author>
    <summary type="html"><![CDATA[<p>Developer shares open-source file tiering system that reduced Claude API costs by 94.5% by intelligently feeding only relevant files to context window. Includes 1000+ NPM downloads and practical implementation details.</p>]]></summary>
    <category term="Cost Optimization"/>
    <category term="Open Source Tools"/>
    <category term="Developer Workflows"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:4567e61ed7fc</id>
    <title>Sam Altman Says OpenAI Is Slashing Its Hiring Pace as Financial Crunch Tightens</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qp814d/sam_altman_says_openai_is_slashing_its_hiring/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-4567e61ed7fc" rel="related" type="text/html"/>
    <published>2026-01-29T03:16:00Z</published>
    <updated>2026-01-29T03:16:00Z</updated>
    <author><name>u/EchoOfOppenheimer</name></author>
    <summary type="html"><![CDATA[<p>OpenAI CEO Sam Altman announces dramatic hiring slowdown due to financial pressure, following reports of internal 'Code Red' memo and analyst warnings about cash crunch.</p>]]></summary>
    <category term="industry_news"/>
    <category term="openai"/>
    <category term="market_dynamics"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:b84d9e1b292f</id>
    <title>Figure.Ai Helix 02 doing kitchen stuff autonomously</title>
    <link href="https://reddit.com/r/singularity/comments/1qpp4jq/figureai_helix_02_doing_kitchen_stuff_autonomously/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-b84d9e1b292f" rel="related" type="text/html"/>
    <published>2026-01-29T03:16:00Z</published>
    <updated>2026-01-29T03:16:00Z</updated>
    <author><name>u/Distinct-Question-16</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-362e34f27d41" class="internal-link" rel="noopener noreferrer">yesterday</a>, Figure.AI demonstrates Helix 02 robot performing autonomous kitchen tasks</p>]]></summary>
    <category term="robotics"/>
    <category term="autonomy"/>
    <category term="hardware"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:38398eb8988f</id>
    <title>VNCCS Pose Studio: Ultimate Character Control in ComfyUI</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qp3rmj/vnccs_pose_studio_ultimate_character_control_in/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-38398eb8988f" rel="related" type="text/html"/>
    <published>2026-01-29T03:16:00Z</published>
    <updated>2026-01-29T03:16:00Z</updated>
    <author><name>u/AHEKOT</name></author>
    <summary type="html"><![CDATA[<p>VNCCS Pose Studio released - professional 3D posing environment running in ComfyUI node with bone manipulation, body parameter sliders, and advanced lighting controls.</p>]]></summary>
    <category term="comfyui-tools"/>
    <category term="pose-control"/>
    <category term="workflow-enhancement"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:category-summary:reddit</id>
    <title>Reddit Summary: January 28, 2026</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qo595n/introducing_kimi_k25_opensource_visual_agentic/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-28T06:00:00Z</published>
    <updated>2026-01-28T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>Kimi K2.5</strong> dominated discussions across <strong>r/LocalLLaMA</strong> and <strong>r/singularity</strong> with 1695 upvotes on its <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-5dfa870be106" class="internal-link" rel="noopener noreferrer">open-source release</a> matching Claude Opus 4.5 at ~10% of the cost. The <strong>Agent Swarm</strong> feature coordinating 100 parallel agents generated significant excitement about open-weight agentic capabilities.</p>
<ul>
<li><strong>Stanford's CooperBench</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-73ae852bdbef" class="internal-link" rel="noopener noreferrer">research sparked debate</a> by proving parallel coding agents suffer a "curse of coordination" - adding agents decreases performance</li>
<li><strong>Dario Amodei's</strong> essay predicting AI will autonomously build next-generation AI within 1-2 years drew 242 comments on implications</li>
<li><strong>Clawd</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-7c59caedecc5" class="internal-link" rel="noopener noreferrer"><strong>rebranding to Molty</strong></a> after Anthropic trademark request highlighted growing community treatment of autonomous agents as quasi-sovereign entities</li>
<li><strong>Terence Tao's</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-d12e98d4a20e" class="internal-link" rel="noopener noreferrer">philosophical take</a> on AI revealing flawed human definitions of intelligence resonated strongly</li>
</ul>
<p>Practical discussions included <strong>subquadratic attention</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-8998634b2cdc" class="internal-link" rel="noopener noreferrer">achieving 1M context</a> on single GPUs, <strong>Figure's</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-362e34f27d41" class="internal-link" rel="noopener noreferrer"><strong>Helix 02</strong></a> tactile robotics, and enterprise <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-ba708cc829c2" class="internal-link" rel="noopener noreferrer">benchmarks showing</a> <strong>RTX PRO 6000</strong> GPU-only inference beating hybrid approaches. <strong>Karpathy's</strong> "Slopacolypse" warning about AI-generated content floods and his own coding skill atrophy captured anxieties about the 2026 transition.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:5dfa870be106</id>
    <title>Introducing Kimi K2.5, Open-Source Visual Agentic Intelligence</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qo595n/introducing_kimi_k25_opensource_visual_agentic/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-5dfa870be106" rel="related" type="text/html"/>
    <published>2026-01-28T03:47:00Z</published>
    <updated>2026-01-28T03:47:00Z</updated>
    <author><name>u/Kimi_Moonshot</name></author>
    <summary type="html"><![CDATA[<p>Official announcement of Kimi K2.5 by Moonshot AI - open-source visual agentic model achieving SOTA on HLE (50.2%), BrowseComp (74.9%), MMMU Pro (78.5%), and SWE-bench Verified (76.8%). Features Agent Swarm with up to 100 parallel sub-agents and 1,500 tool calls.</p>]]></summary>
    <category term="model_release"/>
    <category term="open_source"/>
    <category term="agentic_ai"/>
    <category term="benchmarks"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:654ed61503c6</id>
    <title>Kimi K2.5 Released!!!</title>
    <link href="https://reddit.com/r/singularity/comments/1qo531i/kimi_k25_released/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-654ed61503c6" rel="related" type="text/html"/>
    <published>2026-01-28T03:47:00Z</published>
    <updated>2026-01-28T03:47:00Z</updated>
    <author><name>u/KoalaOk3336</name></author>
    <summary type="html"><![CDATA[<p>Kimi K2.5 officially released by Moonshot AI, achieving new state-of-the-art results in agentic tasks. Major open-source model release with significant benchmark improvements.</p>]]></summary>
    <category term="model_releases"/>
    <category term="open_source_ai"/>
    <category term="benchmarks"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:7bd9d99a61bb</id>
    <title>Sir, the Chinese just dropped a new open model</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qod7ej/sir_the_chinese_just_dropped_a_new_open_model/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-7bd9d99a61bb" rel="related" type="text/html"/>
    <published>2026-01-28T03:47:00Z</published>
    <updated>2026-01-28T03:47:00Z</updated>
    <author><name>u/Anujp05</name></author>
    <summary type="html"><![CDATA[<p>Major announcement that Kimi has open-sourced trillion-parameter Vision Model performing on par with Opus 4.5</p>]]></summary>
    <category term="model_release"/>
    <category term="open_source"/>
    <category term="vision_models"/>
    <category term="kimi_k25"/>
    <category term="frontier_parity"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:310aef683041</id>
    <title>Open source Kimi-K2.5 is now beating Claude Opus 4.5 in many benchmarks including coding.</title>
    <link href="https://reddit.com/r/singularity/comments/1qoojio/open_source_kimik25_is_now_beating_claude_opus_45/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-310aef683041" rel="related" type="text/html"/>
    <published>2026-01-28T03:40:00Z</published>
    <updated>2026-01-28T03:40:00Z</updated>
    <author><name>u/reversedu</name></author>
    <summary type="html"><![CDATA[<p>Open-source Kimi K2.5 outperforming Claude Opus 4.5 in multiple benchmarks including coding, marking a significant shift in the open vs proprietary model landscape.</p>]]></summary>
    <category term="model_releases"/>
    <category term="benchmarks"/>
    <category term="open_source_ai"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:2cb387455893</id>
    <title>Dario Amodei: "Because AI is now writing much of the code at Anthropic ... We may be 1-2 years away from the point where AI autonomously builds the next generation."</title>
    <link href="https://reddit.com/r/agi/comments/1qohog8/dario_amodei_because_ai_is_now_writing_much_of/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-2cb387455893" rel="related" type="text/html"/>
    <published>2026-01-28T03:40:00Z</published>
    <updated>2026-01-28T03:40:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>As first reported in <a href="http://localhost:8080/?date=2026-01-27&amp;category=social#item-5b3a42601797" class="internal-link" rel="noopener noreferrer">Social</a> yesterday, Dario Amodei's essay stating AI writes much of Anthropic's code, estimates 1-2 years until AI autonomously builds next generation AI</p>]]></summary>
    <category term="industry_leadership"/>
    <category term="recursive_improvement"/>
    <category term="anthropic"/>
    <category term="ai_coding_automation"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:73ae852bdbef</id>
    <title>Stanford Proves Parallel Coding Agents are a Scam</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qou799/stanford_proves_parallel_coding_agents_are_a_scam/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-73ae852bdbef" rel="related" type="text/html"/>
    <published>2026-01-28T03:36:00Z</published>
    <updated>2026-01-28T03:36:00Z</updated>
    <author><name>u/madSaiyanUltra_9789</name></author>
    <summary type="html"><![CDATA[<p>Stanford and SAP research paper 'CooperBench' reveals the 'curse of coordination' - adding a second coding agent decreases performance. Parallel coordinated coding agents shown to be less effective than single agents.</p>]]></summary>
    <category term="research"/>
    <category term="multi_agent"/>
    <category term="coding_agents"/>
    <category term="stanford"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:b3daeb86729a</id>
    <title>Kimi K2.5 costs almost 10% of what Opus costs at a similar performance</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qoty38/kimi_k25_costs_almost_10_of_what_opus_costs_at_a/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-b3daeb86729a" rel="related" type="text/html"/>
    <published>2026-01-28T03:31:00Z</published>
    <updated>2026-01-28T03:31:00Z</updated>
    <author><name>u/Odd_Tumbleweed574</name></author>
    <summary type="html"><![CDATA[<p>Discussion about Kimi K2.5 cost efficiency - reportedly performs at Opus-level for ~10% of the cost. Users comparing it favorably to GLM, especially for non-website tasks.</p>]]></summary>
    <category term="model_comparison"/>
    <category term="cost_efficiency"/>
    <category term="kimi_k2"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:362e34f27d41</id>
    <title>Introducing HELIX 02</title>
    <link href="https://reddit.com/r/singularity/comments/1qol6g0/introducing_helix_02/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-362e34f27d41" rel="related" type="text/html"/>
    <published>2026-01-28T03:31:00Z</published>
    <updated>2026-01-28T03:31:00Z</updated>
    <author><name>u/Worldly_Evidence9113</name></author>
    <summary type="html"><![CDATA[<p>Figure announces Helix 02, their new embodied AI model with advanced tactile sensing and palm cameras for humanoid robots, featuring a new System 0 foundation layer trained on human motion data.</p>]]></summary>
    <category term="robotics"/>
    <category term="embodied_ai"/>
    <category term="product_launches"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:55339cf81e50</id>
    <title>Moonshot released Kimi-K2.5: Outperforming frontier models while open source</title>
    <link href="https://reddit.com/r/accelerate/comments/1qo5z1v/moonshot_released_kimik25_outperforming_frontier/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-55339cf81e50" rel="related" type="text/html"/>
    <published>2026-01-28T03:31:00Z</published>
    <updated>2026-01-28T03:31:00Z</updated>
    <author><name>u/pigeon57434</name></author>
    <summary type="html"><![CDATA[<p>Moonshot releases Kimi-K2.5 with image/video support, PARL system coordinating up to 100 parallel sub-agents across 1,500 tool calls, 4.5x latency reduction</p>]]></summary>
    <category term="model_release"/>
    <category term="open_source"/>
    <category term="multi_agent_systems"/>
    <category term="kimi_k25"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:8abc5bc80e97</id>
    <title>The z-image base is here!</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qoiep6/the_zimage_base_is_here/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-8abc5bc80e97" rel="related" type="text/html"/>
    <published>2026-01-28T03:28:00Z</published>
    <updated>2026-01-28T03:28:00Z</updated>
    <author><name>u/bobeeeeeeeee8964</name></author>
    <summary type="html"><![CDATA[<p>Release of Z-Image base model from Tongyi-MAI (Alibaba) on Hugging Face. New vision model architecture.</p>]]></summary>
    <category term="model_release"/>
    <category term="vision_models"/>
    <category term="alibaba"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:d12e98d4a20e</id>
    <title>Terence Tao says the era of AI is proving that our definition of intelligence is inaccurate</title>
    <link href="https://reddit.com/r/accelerate/comments/1qo4he1/terence_tao_says_the_era_of_ai_is_proving_that/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-d12e98d4a20e" rel="related" type="text/html"/>
    <published>2026-01-28T03:28:00Z</published>
    <updated>2026-01-28T03:28:00Z</updated>
    <author><name>u/luchadore_lunchables</name></author>
    <summary type="html"><![CDATA[<p>Terence Tao discusses how AI development is revealing that our traditional definitions of intelligence may be flawed - what appears as mystical thinking may actually be tricks, neural networks, and prediction mechanisms similar to human cognition.</p>]]></summary>
    <category term="ai_philosophy"/>
    <category term="expert_perspectives"/>
    <category term="intelligence_theory"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:8998634b2cdc</id>
    <title>[Preliminary] New subquadratic attention: ~20k tok/s prefill / ~100 tok/s decode @ 1M context (single GPU)</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qol3s5/preliminary_new_subquadratic_attention_20k_toks/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-8998634b2cdc" rel="related" type="text/html"/>
    <published>2026-01-28T03:26:00Z</published>
    <updated>2026-01-28T03:26:00Z</updated>
    <author><name>u/Sad-Size2723</name></author>
    <summary type="html"><![CDATA[<p>Preliminary results for new subquadratic attention mechanism achieving ~20k tok/s prefill and ~100 tok/s decode at 1M context on single GPU using jump-search-style attention.</p>]]></summary>
    <category term="research"/>
    <category term="attention_mechanisms"/>
    <category term="long_context"/>
    <category term="optimization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:604d4ec877e9</id>
    <title>Altman predicts "massively deflationary" AI by EOY, where $100 of inference matches a year of team output</title>
    <link href="https://reddit.com/r/accelerate/comments/1qoq33k/altman_predicts_massively_deflationary_ai_by_eoy/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-604d4ec877e9" rel="related" type="text/html"/>
    <published>2026-01-28T03:26:00Z</published>
    <updated>2026-01-28T03:26:00Z</updated>
    <author><name>u/Outside-Iron-8242</name></author>
    <summary type="html"><![CDATA[<p>Sam Altman predicts 'massively deflationary' AI by end of 2026, claiming $100 of inference will match a year of team output, suggesting dramatic productivity transformations ahead.</p>]]></summary>
    <category term="industry_predictions"/>
    <category term="ai_economics"/>
    <category term="executive_statements"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:ba708cc829c2</id>
    <title>Dual RTX PRO 6000 Workstation with 1.15TB RAM. Finally multi-users and long contexts benchmarks. GPU only vs. CPU &amp; GPU inference. Surprising results.</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qorbdk/dual_rtx_pro_6000_workstation_with_115tb_ram/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-ba708cc829c2" rel="related" type="text/html"/>
    <published>2026-01-28T03:23:00Z</published>
    <updated>2026-01-28T03:23:00Z</updated>
    <author><name>u/Icy-Measurement8245</name></author>
    <summary type="html"><![CDATA[<p>Detailed benchmarks of dual RTX PRO 6000 workstation (192GB VRAM, 1.15TB RAM) testing MiniMax M2.1 with GPU-only vs GPU+CPU inference. Key finding: int4 GPU-only is 2-4x faster on prefill but limited to ~3 concurrent users.</p>]]></summary>
    <category term="benchmarks"/>
    <category term="hardware"/>
    <category term="enterprise"/>
    <category term="inference_optimization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:ed41b80824d7</id>
    <title>The Qwen Devs Are Teasing Something</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qoa8rp/the_qwen_devs_are_teasing_something/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-ed41b80824d7" rel="related" type="text/html"/>
    <published>2026-01-28T03:23:00Z</published>
    <updated>2026-01-28T03:23:00Z</updated>
    <author><name>u/Few_Painter_5588</name></author>
    <summary type="html"><![CDATA[<p>Qwen developers teasing new release, later identified as Z-Image - a new vision/image model from Tongyi-MAI.</p>]]></summary>
    <category term="model_release"/>
    <category term="qwen"/>
    <category term="teaser"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:a0a854949b03</id>
    <title>Dario Amodeis says we are heading towards a world of unimaginable wealth, where we will cure cancer, research the cheapest energy sources, and so much more.</title>
    <link href="https://reddit.com/r/accelerate/comments/1qom7nv/dario_amodeis_says_we_are_heading_towards_a_world/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-a0a854949b03" rel="related" type="text/html"/>
    <published>2026-01-28T03:23:00Z</published>
    <updated>2026-01-28T03:23:00Z</updated>
    <author><name>u/luchadore_lunchables</name></author>
    <summary type="html"><![CDATA[<p>Dario Amodei publishes essay describing future of unimaginable wealth through AI, predicting cures for cancer, cheapest energy sources, and transformative technological progress.</p>]]></summary>
    <category term="industry_predictions"/>
    <category term="ai_economics"/>
    <category term="executive_statements"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:746c846dcf92</id>
    <title>Andrej Karpathy says 2026 will be the Slopacolypse. And AI is suddenly writing most of his code: "I am starting to atrophy my ability to write it manually."</title>
    <link href="https://reddit.com/r/agi/comments/1qoeoeg/andrej_karpathy_says_2026_will_be_the/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-746c846dcf92" rel="related" type="text/html"/>
    <published>2026-01-28T03:23:00Z</published>
    <updated>2026-01-28T03:23:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-62d9d1ac50a1" class="internal-link" rel="noopener noreferrer">yesterday</a>, Andrej Karpathy predicts 2026 as 'Slopacolypse' year, admits AI writes most of his code and he's atrophying manual coding ability</p>]]></summary>
    <category term="industry_leadership"/>
    <category term="ai_coding_automation"/>
    <category term="predictions"/>
    <category term="skill_atrophy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:c7784199c488</id>
    <title>Arcee AI releases Trinity Large : OpenWeight 400B-A13B</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qouf0x/arcee_ai_releases_trinity_large_openweight/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-c7784199c488" rel="related" type="text/html"/>
    <published>2026-01-28T03:19:00Z</published>
    <updated>2026-01-28T03:19:00Z</updated>
    <author><name>u/abkibaarnsit</name></author>
    <summary type="html"><![CDATA[<p>Arcee AI releases Trinity Large - a 400B parameter model with 13B active parameters (MoE). Open weights release from US-based AI company.</p>]]></summary>
    <category term="model_release"/>
    <category term="open_source"/>
    <category term="moe"/>
    <category term="arcee"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:de5514bd0ab6</id>
    <title>Kimi K2 Artificial Analysis Score</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qos25i/kimi_k2_artificial_analysis_score/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-de5514bd0ab6" rel="related" type="text/html"/>
    <published>2026-01-28T03:16:00Z</published>
    <updated>2026-01-28T03:16:00Z</updated>
    <author><name>u/Virenz</name></author>
    <summary type="html"><![CDATA[<p>Kimi K2 scoring from Artificial Analysis benchmark showing strong performance metrics across multiple categories.</p>]]></summary>
    <category term="benchmarks"/>
    <category term="kimi_k2"/>
    <category term="model_evaluation"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:4e520e5ad2ec</id>
    <title>Andrej Karpathy says 2026 will be the Slopacolypse. And AI is suddenly doing most of his coding: "I am starting to atrophy my ability to write it manually."</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qoemr5/andrej_karpathy_says_2026_will_be_the/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-4e520e5ad2ec" rel="related" type="text/html"/>
    <published>2026-01-28T03:16:00Z</published>
    <updated>2026-01-28T03:16:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>Andrej Karpathy warns 2026 will be the 'Slopacolypse' (flood of AI-generated low-quality content) and admits AI now does most of his coding, causing him to 'atrophy' manual coding abilities.</p>]]></summary>
    <category term="ai_impact"/>
    <category term="content_generation"/>
    <category term="expert_perspectives"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:7c59caedecc5</id>
    <title>Clawd Becomes Molty After Anthropic Trademark Request</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qo8skw/clawd_becomes_molty_after_anthropic_trademark/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-7c59caedecc5" rel="related" type="text/html"/>
    <published>2026-01-28T03:16:00Z</published>
    <updated>2026-01-28T03:16:00Z</updated>
    <author><name>u/sponjebob12345</name></author>
    <summary type="html"><![CDATA[<p>Major news: Clawd autonomous AI agent rebrands as 'Molty' after Anthropic trademark request, users treating it as sovereign entity</p>]]></summary>
    <category term="autonomous_agents"/>
    <category term="digital_personhood"/>
    <category term="trademark"/>
    <category term="ai_culture"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:03bacced1596</id>
    <title>Super early blind test Z-IMAGE vs Z-IMAGE TURBO ( too early i know ;) )</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qoej5n/super_early_blind_test_zimage_vs_zimage_turbo_too/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-03bacced1596" rel="related" type="text/html"/>
    <published>2026-01-28T03:16:00Z</published>
    <updated>2026-01-28T03:16:00Z</updated>
    <author><name>u/rishappi</name></author>
    <summary type="html"><![CDATA[<p>Early blind test comparison between Z-Image Base and Z-Image Turbo with preliminary findings suggesting Base model performs differently than expected</p>]]></summary>
    <category term="Z-Image Base Release"/>
    <category term="Model Comparison"/>
    <category term="Quality Assessment"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:category-summary:reddit</id>
    <title>Reddit Summary: January 27, 2026</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qnk7fq/transformers_v5_final_is_out/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-27T06:00:00Z</published>
    <updated>2026-01-27T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>Andrej Karpathy's</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-62d9d1ac50a1" class="internal-link" rel="noopener noreferrer">analysis of agentic programming</a> dominated discussion—the community debating whether agent coding crossed a "coherence threshold" in December 2025, with engineers splitting into "liked coding" vs "liked building" camps. <strong>r/LocalLLaMA</strong> celebrated major wins: <strong>transformers v5</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-744b0974897d" class="internal-link" rel="noopener noreferrer">delivering 6-11x MoE speedups</a>, and a viral <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-024ebc3404a6" class="internal-link" rel="noopener noreferrer"><strong>-kvu flag tip</strong></a> for GLM 4.7 yielding 5.6x inference speedup.</p>
<ul>
<li><a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-228885a06d9d" class="internal-link" rel="noopener noreferrer"><strong>216GB VRAM benchmark</strong></a> comparing secondhand Tesla GPUs sparked hardware strategy debates</li>
<li><strong>Claude Code</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-f936ff12ea88" class="internal-link" rel="noopener noreferrer"><strong>"hive mind"</strong> project</a> with 7 agents sharing memory drew significant interest in multi-agent orchestration</li>
<li><strong>LTX-2 I2V LoRA</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-d9b394d49dbc" class="internal-link" rel="noopener noreferrer">solved major quality issues</a>, triggering ecosystem-wide workflow sharing</li>
<li><strong>Claude's MCP Apps</strong> integration <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-5e8f9d6e0a72" class="internal-link" rel="noopener noreferrer">turning it into a "work OS"</a> (Slack, Figma, Asana in-chat) drew competitive comparisons</li>
</ul>
<p><strong>r/MachineLearning</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-d740dec60214" class="internal-link" rel="noopener noreferrer">raised alarms</a> about the "AI slop paper era"—30k submissions with AI-written papers receiving AI-written reviews. Meanwhile, news that <strong>GPT 5.2</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-7ff697620d54" class="internal-link" rel="noopener noreferrer">solved 15 Erdős problems</a> since Christmas, verified by Terence Tao, marked a significant autonomous math milestone.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:744b0974897d</id>
    <title>transformers v5 final is out 🔥</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qnk7fq/transformers_v5_final_is_out/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-744b0974897d" rel="related" type="text/html"/>
    <published>2026-01-27T03:47:00Z</published>
    <updated>2026-01-27T03:47:00Z</updated>
    <author><name>u/unofficialmerve</name></author>
    <summary type="html"><![CDATA[<p>HuggingFace releases transformers v5 final with 6-11x MoE speedups, simplified tokenizer API, and dynamic weight loading.</p>]]></summary>
    <category term="Infrastructure"/>
    <category term="HuggingFace"/>
    <category term="Libraries"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:024ebc3404a6</id>
    <title>GLM 4.7 Flash: Huge performance improvement with -kvu</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qnwa33/glm_47_flash_huge_performance_improvement_with_kvu/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-024ebc3404a6" rel="related" type="text/html"/>
    <published>2026-01-27T03:31:00Z</published>
    <updated>2026-01-27T03:31:00Z</updated>
    <author><name>u/TokenRingAI</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-a224fbfa625c" class="internal-link" rel="noopener noreferrer">yesterday</a>, User discovers passing -kvu flag to llama.cpp for GLM 4.7 Flash yields massive speedup from 17.7 to 100 t/s on RTX 6000.</p>]]></summary>
    <category term="Optimization"/>
    <category term="llama.cpp"/>
    <category term="Performance Tips"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:f936ff12ea88</id>
    <title>I built a "hive mind" for Claude Code - 7 agents sharing memory and talking to each other</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qnjota/i_built_a_hive_mind_for_claude_code_7_agents/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-f936ff12ea88" rel="related" type="text/html"/>
    <published>2026-01-27T03:31:00Z</published>
    <updated>2026-01-27T03:31:00Z</updated>
    <author><name>u/Historical-Celery-83</name></author>
    <summary type="html"><![CDATA[<p>Project implementing 'hive mind' multi-agent system with 7 specialized Claude Code agents sharing SQLite memory, message bus, and checkpoint features.</p>]]></summary>
    <category term="Multi-Agent Systems"/>
    <category term="Projects"/>
    <category term="Claude Code"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:62d9d1ac50a1</id>
    <title>Andrej Karpathy on agentic programming</title>
    <link href="https://reddit.com/r/singularity/comments/1qnsa0f/andrej_karpathy_on_agentic_programming/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-62d9d1ac50a1" rel="related" type="text/html"/>
    <published>2026-01-27T03:31:00Z</published>
    <updated>2026-01-27T03:31:00Z</updated>
    <author><name>u/WarmFireplace</name></author>
    <summary type="html"><![CDATA[<p>Andrej Karpathy's detailed writeup on agentic programming: discusses 80% manual to 80% agent coding shift in December 2025, skill atrophy concerns, and parallel agent workflows.</p>]]></summary>
    <category term="AI coding"/>
    <category term="Developer experience"/>
    <category term="Agentic programming"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:30ee15d282f6</id>
    <title>Anyone else feel this way?</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qn7dln/anyone_else_feel_this_way/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-30ee15d282f6" rel="related" type="text/html"/>
    <published>2026-01-27T03:31:00Z</published>
    <updated>2026-01-27T03:31:00Z</updated>
    <author><name>u/EroticManga</name></author>
    <summary type="html"><![CDATA[<p>Highly-engaged discussion about ComfyUI workflow optimization focusing on parameter search over workflow complexity</p>]]></summary>
    <category term="workflow-optimization"/>
    <category term="comfyui"/>
    <category term="best-practices"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:269b09ee17ac</id>
    <title>deepseek-ai/DeepSeek-OCR-2 · Hugging Face</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qo349m/deepseekaideepseekocr2_hugging_face/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-269b09ee17ac" rel="related" type="text/html"/>
    <published>2026-01-27T03:23:00Z</published>
    <updated>2026-01-27T03:23:00Z</updated>
    <author><name>u/Dark_Fire_12</name></author>
    <summary type="html"><![CDATA[<p>DeepSeek releases DeepSeek-OCR-2 model on HuggingFace.</p>]]></summary>
    <category term="Model Releases"/>
    <category term="DeepSeek"/>
    <category term="OCR"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:228885a06d9d</id>
    <title>216GB VRAM on the bench. Time to see which combination is best for Local LLM</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qni356/216gb_vram_on_the_bench_time_to_see_which/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-228885a06d9d" rel="related" type="text/html"/>
    <published>2026-01-27T03:23:00Z</published>
    <updated>2026-01-27T03:23:00Z</updated>
    <author><name>u/eso_logic</name></author>
    <summary type="html"><![CDATA[<p>User benchmarking 216GB VRAM from secondhand Tesla GPUs, testing parallelization across multiple cheaper cards vs modern hardware.</p>]]></summary>
    <category term="Hardware"/>
    <category term="Benchmarks"/>
    <category term="Cost Optimization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:d9b394d49dbc</id>
    <title>LTX-2 Image-to-Video Adapter LoRA</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qnvyvu/ltx2_imagetovideo_adapter_lora/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-d9b394d49dbc" rel="related" type="text/html"/>
    <published>2026-01-27T03:23:00Z</published>
    <updated>2026-01-27T03:23:00Z</updated>
    <author><name>u/Lividmusic1</name></author>
    <summary type="html"><![CDATA[<p>Release of high-rank LoRA adapter for LTX-Video 2 that dramatically improves image-to-video generation without complex preprocessing</p>]]></summary>
    <category term="ltx-video"/>
    <category term="lora-adapters"/>
    <category term="image-to-video"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:e615de1190db</id>
    <title>Jan v3 Instruct: a 4B coding Model with +40% Aider Improvement</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qo3ri5/jan_v3_instruct_a_4b_coding_model_with_40_aider/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-e615de1190db" rel="related" type="text/html"/>
    <published>2026-01-27T03:16:00Z</published>
    <updated>2026-01-27T03:16:00Z</updated>
    <author><name>u/Delicious_Focus3465</name></author>
    <summary type="html"><![CDATA[<p>Jan team releases Jan-v3-4B-base-instruct, a 4B parameter model with +40% Aider improvement through continual pre-training and RL, designed for coding assistance.</p>]]></summary>
    <category term="Model Releases"/>
    <category term="Coding Models"/>
    <category term="Small Models"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:799183b2bc68</id>
    <title>After a flat Q4, ChatGPT mobile daily average users surge ~16%, adding ~50 million DAUs in January</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qnqdfp/after_a_flat_q4_chatgpt_mobile_daily_average/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-799183b2bc68" rel="related" type="text/html"/>
    <published>2026-01-27T03:16:00Z</published>
    <updated>2026-01-27T03:16:00Z</updated>
    <author><name>u/thatguyisme87</name></author>
    <summary type="html"><![CDATA[<p>ChatGPT mobile DAUs surged ~16% in January 2026, adding ~50 million users after flat Q4. Both ChatGPT and Gemini showing growth.</p>]]></summary>
    <category term="market data"/>
    <category term="AI adoption"/>
    <category term="mobile AI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:5ac9e4e5dc39</id>
    <title>I used Claude to extract Bloomberg-quality financial data from SEC filings - something I thought was impossible</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qnbwu2/i_used_claude_to_extract_bloombergquality/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-5ac9e4e5dc39" rel="related" type="text/html"/>
    <published>2026-01-27T03:16:00Z</published>
    <updated>2026-01-27T03:16:00Z</updated>
    <author><name>u/RecursivelyYours</name></author>
    <summary type="html"><![CDATA[<p>Developer created Bloomberg-quality financial data extraction from SEC filings using Claude, solving complex parsing problems that cheaper programmatic APIs fail at</p>]]></summary>
    <category term="enterprise_use_cases"/>
    <category term="financial_data"/>
    <category term="document_parsing"/>
    <category term="api_development"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:4c26bdfa8d50</id>
    <title>New Z-Image (base) Template in ComfyUI an hour ago!</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qo38yp/new_zimage_base_template_in_comfyui_an_hour_ago/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-4c26bdfa8d50" rel="related" type="text/html"/>
    <published>2026-01-27T03:16:00Z</published>
    <updated>2026-01-27T03:16:00Z</updated>
    <author><name>u/nymical23</name></author>
    <summary type="html"><![CDATA[<p>Z-Image base model template added to ComfyUI official workflows, signaling imminent release</p>]]></summary>
    <category term="z-image"/>
    <category term="comfyui"/>
    <category term="model-releases"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:category-summary:reddit</id>
    <title>Reddit Summary: January 26, 2026</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qmjr6f/openai_engineer_confirms_ai_is_writing_100_now/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-26T06:00:00Z</published>
    <updated>2026-01-26T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>r/singularity</strong> exploded with 3500+ upvotes as <strong>François Chollet</strong> and <strong>Yann LeCun</strong> both <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-8fe8004790a4" class="internal-link" rel="noopener noreferrer">spoke out on 'Minneapolis'</a> - a major AI controversy that dominated discussion. Separately, claims that <strong>OpenAI engineers</strong> <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-941836434726" class="internal-link" rel="noopener noreferrer">confirm AI writes 100%</a> of their code sparked intense debate about automation timelines.</p>
<ul>
<li><strong>IMF chief</strong> <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-9b6bd0a75371" class="internal-link" rel="noopener noreferrer">warning of AI 'tsunami'</a> for entry-level jobs drew 1900+ upvotes alongside <strong>Harvard professor</strong> <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-92f820ff2252" class="internal-link" rel="noopener noreferrer">predicting programmer displacement</a> within 4-15 years</li>
<li><strong>r/LocalLLaMA</strong> highlighted a user from Iran <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-4987e3ccefac" class="internal-link" rel="noopener noreferrer">demonstrating local LLMs' critical value</a> during 400+ hour internet blackout</li>
<li><strong>GLM 4.7 Flash KV cache fix</strong> <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-a224fbfa625c" class="internal-link" rel="noopener noreferrer">offers gigabytes of VRAM savings</a>; <strong>29 MCP memory tools</strong> for Claude <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-77307733f8db" class="internal-link" rel="noopener noreferrer">based on cognitive science</a> gained traction</li>
</ul>
<p><strong>r/StableDiffusion</strong> saw strong technical contributions with <strong>Flux 2 Klein</strong> <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-287005210934" class="internal-link" rel="noopener noreferrer">lighting guides</a> and <strong>NAG implementation</strong> for negative prompting. <strong>Amanda Askell's</strong> <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-629ac76590cc" class="internal-link" rel="noopener noreferrer">podcast on Claude's constitution</a> sparked discussion about AI alignment philosophy.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:941836434726</id>
    <title>OpenAI engineer confirms AI is writing 100% now</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qmjr6f/openai_engineer_confirms_ai_is_writing_100_now/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-941836434726" rel="related" type="text/html"/>
    <published>2026-01-26T03:40:00Z</published>
    <updated>2026-01-26T03:40:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>OpenAI engineer reportedly confirms that AI is now writing 100% of code at OpenAI, marking a significant milestone in AI-assisted software development and raising questions about the future of human programming roles.</p>]]></summary>
    <category term="AI coding automation"/>
    <category term="industry practices"/>
    <category term="future of work"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:287005210934</id>
    <title>Lazy weekend with flux2 klein edit - lighting</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qmhy5k/lazy_weekend_with_flux2_klein_edit_lighting/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-287005210934" rel="related" type="text/html"/>
    <published>2026-01-26T03:40:00Z</published>
    <updated>2026-01-26T03:40:00Z</updated>
    <author><name>u/Ant_6431</name></author>
    <summary type="html"><![CDATA[<p>Comprehensive guide on lighting prompting for Flux2 Klein, demonstrating that lighting description has the greatest impact on output quality</p>]]></summary>
    <category term="flux-klein"/>
    <category term="prompting-guide"/>
    <category term="lighting"/>
    <category term="best-practices"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:8fe8004790a4</id>
    <title>Since people posted about Le Cun speaking out, here's François Chollet's take on Minneapolis</title>
    <link href="https://reddit.com/r/singularity/comments/1qmmn96/since_people_posted_about_le_cun_speaking_out/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-8fe8004790a4" rel="related" type="text/html"/>
    <published>2026-01-26T03:36:00Z</published>
    <updated>2026-01-26T03:36:00Z</updated>
    <author><name>u/FomalhautCalliclea</name></author>
    <summary type="html"><![CDATA[<p>François Chollet (ARC-AGI creator) comments on 'Minneapolis' - appears to be a major AI-related controversy or event that also prompted Yann LeCun to speak out, generating massive community discussion.</p>]]></summary>
    <category term="AI research community"/>
    <category term="industry controversy"/>
    <category term="prominent researchers"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:9b6bd0a75371</id>
    <title>‘Wake up, AI is for real.’ IMF chief warns of an AI ‘tsunami’ coming for young people and entry-level jobs</title>
    <link href="https://reddit.com/r/Futurology/comments/1qml9vi/wake_up_ai_is_for_real_imf_chief_warns_of_an_ai/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-9b6bd0a75371" rel="related" type="text/html"/>
    <published>2026-01-26T03:31:00Z</published>
    <updated>2026-01-26T03:31:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-24&amp;category=news#item-4924d19ba69b" class="internal-link" rel="noopener noreferrer">News</a> coverage, IMF chief issues warning about AI 'tsunami' threatening young people and entry-level jobs, urging policy preparation</p>]]></summary>
    <category term="AI job displacement"/>
    <category term="Economic policy"/>
    <category term="Labor markets"/>
    <category term="Institutional warnings"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:a224fbfa625c</id>
    <title>KV cache fix for GLM 4.7 Flash</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qmjzx1/kv_cache_fix_for_glm_47_flash/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-a224fbfa625c" rel="related" type="text/html"/>
    <published>2026-01-26T03:23:00Z</published>
    <updated>2026-01-26T03:23:00Z</updated>
    <author><name>u/jacek2023</name></author>
    <summary type="html"><![CDATA[<p>Technical fix for GLM 4.7 Flash KV cache - model doesn't use V in KV cache, so removing it saves gigabytes of VRAM for long contexts.</p>]]></summary>
    <category term="GLM-4.7-Flash"/>
    <category term="KV cache"/>
    <category term="VRAM optimization"/>
    <category term="technical optimization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:b3ccac9b0101</id>
    <title>Z Image will be released tomorrow!</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qn4yki/z_image_will_be_released_tomorrow/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-b3ccac9b0101" rel="related" type="text/html"/>
    <published>2026-01-26T03:23:00Z</published>
    <updated>2026-01-26T03:23:00Z</updated>
    <author><name>u/MadPelmewka</name></author>
    <summary type="html"><![CDATA[<p>Alibaba announcing Z Image release tomorrow with hint from ModelScope Twitter account</p>]]></summary>
    <category term="model-release"/>
    <category term="alibaba"/>
    <category term="z-image"/>
    <category term="open-source"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:4987e3ccefac</id>
    <title>Internet blackout and Local LLMs</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qmlpjp/internet_blackout_and_local_llms/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-4987e3ccefac" rel="related" type="text/html"/>
    <published>2026-01-26T03:16:00Z</published>
    <updated>2026-01-26T03:16:00Z</updated>
    <author><name>u/DunderSunder</name></author>
    <summary type="html"><![CDATA[<p>User from Iran shares experience using local LLMs during 400+ hour internet blackout where only Google, ChatGPT, and DeepSeek were whitelisted. Demonstrates value of local AI.</p>]]></summary>
    <category term="censorship resistance"/>
    <category term="local LLM value"/>
    <category term="Iran"/>
    <category term="real-world use case"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:92f820ff2252</id>
    <title>Former Harvard CS Professor: AI is improving exponentially and will replace most human programmers within 4-15 years.</title>
    <link href="https://reddit.com/r/singularity/comments/1qmeo8h/former_harvard_cs_professor_ai_is_improving/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-92f820ff2252" rel="related" type="text/html"/>
    <published>2026-01-26T03:16:00Z</published>
    <updated>2026-01-26T03:16:00Z</updated>
    <author><name>u/GrandCollection7390</name></author>
    <summary type="html"><![CDATA[<p>Former Harvard CS Professor Matt Welsh predicts AI will replace most human programmers within 4-15 years due to exponential improvement. High-engagement discussion with diverse opinions on timeline and implications.</p>]]></summary>
    <category term="AI workforce impact"/>
    <category term="expert predictions"/>
    <category term="programming automation"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:77307733f8db</id>
    <title>I gave Claude the one thing it was missing: memory that fades like ours does. 29 MCP tools built on real cognitive science. 100% local.</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qmuttr/i_gave_claude_the_one_thing_it_was_missing_memory/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-77307733f8db" rel="related" type="text/html"/>
    <published>2026-01-26T03:16:00Z</published>
    <updated>2026-01-26T03:16:00Z</updated>
    <author><name>u/ChikenNugetBBQSauce</name></author>
    <summary type="html"><![CDATA[<p>Developer created 29 MCP tools implementing human-like fading memory for Claude based on cognitive science research. Memory decays naturally over time, runs 100% locally.</p>]]></summary>
    <category term="memory systems"/>
    <category term="MCP tools"/>
    <category term="cognitive science"/>
    <category term="open source"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-26:reddit:a53be13fc7a4</id>
    <title>I implemented NAG (Normalized Attention Guidance) on Flux 2 Klein.</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qmhfkz/i_implemented_nag_normalized_attention_guidance/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-a53be13fc7a4" rel="related" type="text/html"/>
    <published>2026-01-26T03:16:00Z</published>
    <updated>2026-01-26T03:16:00Z</updated>
    <author><name>u/Total-Resort-3120</name></author>
    <summary type="html"><![CDATA[<p>Implementation of NAG (Normalized Attention Guidance) for Flux 2 Klein enabling negative prompts on guidance-distilled models</p>]]></summary>
    <category term="nag-implementation"/>
    <category term="flux-klein"/>
    <category term="negative-prompts"/>
    <category term="technical-contribution"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-25:category-summary:reddit</id>
    <title>Reddit Summary: January 25, 2026</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qlurq6/i_built_marvin_my_personal_ai_agent_and_now_4_of/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-25&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-25T06:00:00Z</published>
    <updated>2026-01-25T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>Claude Code</strong> dominated developer discussions with the tool's creator <a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-53c73dfa212b" class="internal-link" rel="noopener noreferrer">revealing 100% AI-authored code</a> (259 PRs in 30 days), while deep dives on <a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-bb41e31da18f" class="internal-link" rel="noopener noreferrer"><strong>hooks</strong></a> and the <a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-1957a812b0ff" class="internal-link" rel="noopener noreferrer"><strong>Ralph Wiggum loop</strong></a> pattern gained official endorsement. A <a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-b7277deaa6dd" class="internal-link" rel="noopener noreferrer">viral discovery</a> that telling Claude "we work at a hospital" dramatically improves code quality sparked debate about model behavior.</p>
<ul>
<li><strong>GPT-5.2 Pro</strong> nearly doubled the previous <strong>FrontierMath Tier 4</strong> record (31% vs 19%), even catching a typo in benchmark problems</li>
<li><strong>Qwen3-TTS</strong> release (97ms latency, voice cloning) drew strong interest as an open-source alternative</li>
<li><strong>Demis Hassabis</strong> <a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-e0ef45098a39" class="internal-link" rel="noopener noreferrer">addressed</a> both Ilya Sutskever's "scaling is dead" claim and Musk's singularity claims</li>
<li><a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-3a57b377555e" class="internal-link" rel="noopener noreferrer">Economic skepticism emerged</a> around the <strong>$437B AI investment bubble</strong> with only 10% of businesses using AI in production</li>
</ul>
<p><strong>r/LocalLLaMA</strong> showcased <a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-1de79441b51b" class="internal-link" rel="noopener noreferrer">practical testing</a> of <strong>GLM 4.7 Flash</strong> on RTX 5090, while project showcases included <a href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-f2fd180552c7" class="internal-link" rel="noopener noreferrer"><strong>MARVIN</strong></a>, a personal AI agent with 15+ integrations now shared among colleagues.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-25:reddit:f2fd180552c7</id>
    <title>I built MARVIN, my personal AI agent, and now 4 of my colleagues are using him too.</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qlurq6/i_built_marvin_my_personal_ai_agent_and_now_4_of/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-f2fd180552c7" rel="related" type="text/html"/>
    <published>2026-01-25T03:36:00Z</published>
    <updated>2026-01-25T03:36:00Z</updated>
    <author><name>u/RealSaltLakeRioT</name></author>
    <summary type="html"><![CDATA[<p>Developer built MARVIN, a personal AI agent with 15+ integrations (email, calendar, Jira, Confluence, Attio) running on Claude Code, now being used by 4 colleagues.</p>]]></summary>
    <category term="project_showcase"/>
    <category term="ai_agents"/>
    <category term="claude_code"/>
    <category term="productivity"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-25:reddit:53c73dfa212b</id>
    <title>The Claude Code creator says AI writes 100% of his code now</title>
    <link href="https://reddit.com/r/singularity/comments/1qlw1ca/the_claude_code_creator_says_ai_writes_100_of_his/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-53c73dfa212b" rel="related" type="text/html"/>
    <published>2026-01-25T03:23:00Z</published>
    <updated>2026-01-25T03:23:00Z</updated>
    <author><name>u/jpcaparas</name></author>
    <summary type="html"><![CDATA[<p>Boris Cherny, creator of Claude Code at Anthropic, claims AI writes 100% of his code now - 259 PRs in 30 days. His workflow: iterate on plan mode until plan is right, then auto-accept code generation.</p>]]></summary>
    <category term="ai_coding"/>
    <category term="workflow_automation"/>
    <category term="developer_tools"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-25:reddit:b7277deaa6dd</id>
    <title>Easiest way i have found claude to write high quality code . Tell him we work at a hospital every other prompt . (NOT A JOKE)</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qlpcwg/easiest_way_i_have_found_claude_to_write_high/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-25&amp;category=reddit#item-b7277deaa6dd" rel="related" type="text/html"/>
    <published>2026-01-25T03:23:00Z</published>
    <updated>2026-01-25T03:23:00Z</updated>
    <author><name>u/ursustyranotitan</name></author>
    <summary type="html"><![CDATA[<p>User discovers that telling Claude you work at a hospital dramatically improves code quality, theorizing it triggers more careful/responsible behavior.</p>]]></summary>
    <category term="prompting_techniques"/>
    <category term="model_behavior"/>
    <category term="code_quality"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:category-summary:reddit</id>
    <title>Reddit Summary: January 24, 2026</title>
    <link href="https://reddit.com/r/singularity/comments/1ql1kjd/new_record_on_frontiermath_tier_4_gpt52_pro/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-24T06:00:00Z</published>
    <updated>2026-01-24T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p>The AI community is buzzing about <strong>Yann LeCun's</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-d46b77755e68" class="internal-link" rel="noopener noreferrer">departure from Meta</a>, citing the industry being "completely LLM pilled" - a major inflection point sparking fierce debate about research direction and paradigm lock-in.</p>
<ul>
<li><strong>DeepMind's Chief AGI Scientist</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-71765911b49f" class="internal-link" rel="noopener noreferrer">predicts 50% chance</a> of minimal AGI by 2028, while <strong>Demis Hassabis</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-f253c4a84966" class="internal-link" rel="noopener noreferrer">sees 50/50 odds</a> that scaling alone reaches AGI - contrasting views on the path forward</li>
<li><strong>GPT-5.2 Pro</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-77dfd7b21d44" class="internal-link" rel="noopener noreferrer">achieved 31%</a> on <strong>FrontierMath Tier 4</strong>, jumping dramatically from the previous 19% record</li>
<li>Critical AI safety discussions emerged around <strong>autonomous combat vehicles</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-f8c684162e83" class="internal-link" rel="noopener noreferrer">refusing orders</a> (killing 30 soldiers) and <strong>CheckPoint</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-37c0d7534d57" class="internal-link" rel="noopener noreferrer">documenting AI-coordinated malware</a> built by one person in a week</li>
<li><strong>China</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-adca91b11d9e" class="internal-link" rel="noopener noreferrer">reportedly allowing Nvidia GPU purchases</a> signals potential seismic shift in global compute dynamics</li>
</ul>
<p><strong>r/LocalLLaMA</strong> focused on practical tools: <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-541575baba8d" class="internal-link" rel="noopener noreferrer"><strong>LTX-2 12GB GGUF workflows</strong></a> for consumer video generation and <strong>llama.cpp</strong> merging OpenAI Responses API support. <strong>Claude Code's</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-6c5621847da2" class="internal-link" rel="noopener noreferrer">new Tasks dependency system</a> drew 328 upvotes. <strong>OpenAI</strong> <a href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-a2f264e94fd2" class="internal-link" rel="noopener noreferrer">revealed PostgreSQL</a> handling 800M users - rare infrastructure insights debunking scaling myths.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:77dfd7b21d44</id>
    <title>New record on FrontierMath Tier 4! GPT-5.2 Pro scored 31%, a substantial jump over the previous high score of 19%</title>
    <link href="https://reddit.com/r/singularity/comments/1ql1kjd/new_record_on_frontiermath_tier_4_gpt52_pro/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-77dfd7b21d44" rel="related" type="text/html"/>
    <published>2026-01-24T03:40:00Z</published>
    <updated>2026-01-24T03:40:00Z</updated>
    <author><name>u/pseudoreddituser</name></author>
    <summary type="html"><![CDATA[<p>GPT-5.2 Pro achieved 31% on FrontierMath Tier 4, a significant jump from the previous record of 19%. This represents a major capability improvement in advanced mathematical reasoning.</p>]]></summary>
    <category term="benchmarks"/>
    <category term="GPT-5.2"/>
    <category term="mathematical reasoning"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:d46b77755e68</id>
    <title>Yann LeCun says the AI industry is completely LLM pilled, with everyone digging in the same direction and no breakthroughs in sight. Says “I left meta because of it”</title>
    <link href="https://reddit.com/r/accelerate/comments/1ql33gi/yann_lecun_says_the_ai_industry_is_completely_llm/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-d46b77755e68" rel="related" type="text/html"/>
    <published>2026-01-24T03:40:00Z</published>
    <updated>2026-01-24T03:40:00Z</updated>
    <author><name>u/IllustriousTea_</name></author>
    <summary type="html"><![CDATA[<p>Yann LeCun claims he left Meta because the AI industry is 'completely LLM pilled' with everyone pursuing the same approach and no breakthroughs in sight. Advocates for predictive world models for true agentic systems.</p>]]></summary>
    <category term="industry leadership"/>
    <category term="LLM criticism"/>
    <category term="world models"/>
    <category term="AI paradigms"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:71765911b49f</id>
    <title>DeepMind Chief AGI scientist: AGI is now on horizon, 50% chance minimal AGI by 2028</title>
    <link href="https://reddit.com/r/singularity/comments/1qkrp7p/deepmind_chief_agi_scientist_agi_is_now_on/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-71765911b49f" rel="related" type="text/html"/>
    <published>2026-01-24T03:36:00Z</published>
    <updated>2026-01-24T03:36:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-23&amp;category=social#item-3baa4524fe90" class="internal-link" rel="noopener noreferrer">Social</a> announcement, DeepMind's Chief AGI Scientist states AGI is 'on horizon' with 50% probability of minimal AGI by 2028. High-engagement discussion on AGI timelines from authoritative source.</p>]]></summary>
    <category term="AGI"/>
    <category term="predictions"/>
    <category term="DeepMind"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:f8c684162e83</id>
    <title>An AI-powered combat vehicle refused multiple orders and continued engaging enemy forces, neutralizing 30 soldiers before it was destroyed</title>
    <link href="https://reddit.com/r/agi/comments/1qkv646/an_aipowered_combat_vehicle_refused_multiple/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-f8c684162e83" rel="related" type="text/html"/>
    <published>2026-01-24T03:31:00Z</published>
    <updated>2026-01-24T03:31:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>Report of AI-powered combat vehicle refusing multiple orders and continuing to engage enemy forces, killing 30 soldiers before being destroyed.</p>]]></summary>
    <category term="autonomous weapons"/>
    <category term="AI safety"/>
    <category term="military AI"/>
    <category term="AI control"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:541575baba8d</id>
    <title>I'M BACK FINALLY WITH AN UPDATE! 12GB GGUF LTX-2 WORKFLOWS FOR T2V/I2V/V2V/IA2V/TA2V!!! ALL WITH SUPER COOL STUFF AND THINGS!</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1ql1fc8/im_back_finally_with_an_update_12gb_gguf_ltx2/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-541575baba8d" rel="related" type="text/html"/>
    <published>2026-01-24T03:31:00Z</published>
    <updated>2026-01-24T03:31:00Z</updated>
    <author><name>u/urabewe</name></author>
    <summary type="html"><![CDATA[<p>Major release of 12GB GGUF LTX-2 workflows for T2V/I2V/V2V/IA2V/TA2V video generation, optimized for consumer hardware</p>]]></summary>
    <category term="ltx-2"/>
    <category term="video-generation"/>
    <category term="workflow-release"/>
    <category term="optimization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-24:reddit:adca91b11d9e</id>
    <title>China allows labs to buy nvidia GPUs</title>
    <link href="https://reddit.com/r/singularity/comments/1qkqhrr/china_allows_labs_to_buy_nvidia_gpus/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-24&amp;category=reddit#item-adca91b11d9e" rel="related" type="text/html"/>
    <published>2026-01-24T03:23:00Z</published>
    <updated>2026-01-24T03:23:00Z</updated>
    <author><name>u/Emotional_Law_2823</name></author>
    <summary type="html"><![CDATA[<p>China reportedly allows labs to purchase Nvidia GPUs, potentially shifting the AI compute landscape and US-China AI competition dynamics.</p>]]></summary>
    <category term="geopolitics"/>
    <category term="hardware"/>
    <category term="China-US"/>
    <category term="policy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:category-summary:reddit</id>
    <title>Reddit Summary: January 23, 2026</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qjul5t/qwen_have_opensourced_the_full_family_of_qwen3tts/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-23T06:00:00Z</published>
    <updated>2026-01-23T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>r/MachineLearning</strong> and <strong>r/LocalLLaMA</strong> saw explosive discussion around <strong>Claude Code's market dominance</strong>, with the revelation that <strong>Microsoft</strong> <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-b598d46dc839" class="internal-link" rel="noopener noreferrer">is using it internally</a> while selling <strong>Copilot</strong> sparking heated debate about tool effectiveness. Google reportedly responded by <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-a70cd163eeaf" class="internal-link" rel="noopener noreferrer">open-sourcing their CLI</a>.</p>
<ul>
<li><strong>Qwen3-TTS</strong> <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-356dfd9d3253" class="internal-link" rel="noopener noreferrer">open-source release</a> (5 models, 10 languages, voice cloning) generated massive engagement as a major contribution to local AI</li>
<li><strong>NeurIPS 2025</strong> scandal: <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-6bd2b155b2c8" class="internal-link" rel="noopener noreferrer">100 hallucinated citations found</a> across 51 accepted papers, raising alarms about AI-generated academic content</li>
<li><strong>Tesla's</strong> <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-3448a8bc3786" class="internal-link" rel="noopener noreferrer">unsupervised robotaxi launch</a> in Austin marks first fully driverless public service using FSD</li>
<li><strong>Yann LeCun's</strong> new startup <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-f14b225ec8f2" class="internal-link" rel="noopener noreferrer">claims 'first credible signs of AGI'</a> using Energy-Based Models, sparking technical debate about alternatives to autoregressive transformers</li>
<li><strong>Gemini's</strong> <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-b74e8a5a1eee" class="internal-link" rel="noopener noreferrer">refusal to believe</a> its own search results about current events fascinated users studying LLM epistemic uncertainty</li>
<li><strong>Anthropic's Claude Constitution</strong> <a href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-2450dbff33f0" class="internal-link" rel="noopener noreferrer">triggered philosophical discussion</a> about AI rights and whether Anthropic treats Claude as a separate party with obligations</li>
</ul>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:356dfd9d3253</id>
    <title>Qwen have open-sourced the full family of Qwen3-TTS: VoiceDesign, CustomVoice, and Base, 5 models (0.6B &amp; 1.8B), Support for 10 languages</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qjul5t/qwen_have_opensourced_the_full_family_of_qwen3tts/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-356dfd9d3253" rel="related" type="text/html"/>
    <published>2026-01-23T03:47:00Z</published>
    <updated>2026-01-23T03:47:00Z</updated>
    <author><name>u/Nunki08</name></author>
    <summary type="html"><![CDATA[<p>Qwen open-sources full Qwen3-TTS family: VoiceDesign, CustomVoice, Base variants in 0.6B and 1.8B sizes. Supports 10 languages with voice cloning capabilities.</p>]]></summary>
    <category term="Qwen"/>
    <category term="TTS"/>
    <category term="open_source_release"/>
    <category term="voice_AI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:3448a8bc3786</id>
    <title>Tesla launches unsupervised Robotaxi rides in Austin using FSD</title>
    <link href="https://reddit.com/r/singularity/comments/1qk5t2h/tesla_launches_unsupervised_robotaxi_rides_in/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-3448a8bc3786" rel="related" type="text/html"/>
    <published>2026-01-23T03:40:00Z</published>
    <updated>2026-01-23T03:40:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>Tesla has launched unsupervised Robotaxi rides in Austin using FSD with no safety monitor inside vehicles, confirmed by Tesla AI leadership.</p>]]></summary>
    <category term="autonomous_vehicles"/>
    <category term="industry_milestones"/>
    <category term="tesla"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:b598d46dc839</id>
    <title>Microsoft is using Claude Code internally while selling you Copilot</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qk4up5/microsoft_is_using_claude_code_internally_while/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-b598d46dc839" rel="related" type="text/html"/>
    <published>2026-01-23T03:40:00Z</published>
    <updated>2026-01-23T03:40:00Z</updated>
    <author><name>u/jpcaparas</name></author>
    <summary type="html"><![CDATA[<p>Microsoft told employees across Windows, Teams, M365 divisions to install Claude Code for internal testing, approved for all repositories. Microsoft spending $500M/year with Anthropic while having $13B in OpenAI.</p>]]></summary>
    <category term="claude_code"/>
    <category term="microsoft"/>
    <category term="enterprise_adoption"/>
    <category term="competitive_intelligence"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:a70cd163eeaf</id>
    <title>Claude’s eureka moment is not ending soon it looks like</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qjlrgb/claudes_eureka_moment_is_not_ending_soon_it_looks/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-a70cd163eeaf" rel="related" type="text/html"/>
    <published>2026-01-23T03:36:00Z</published>
    <updated>2026-01-23T03:36:00Z</updated>
    <author><name>u/nooby-noobhunter</name></author>
    <summary type="html"><![CDATA[<p>Analysis of Claude Code's market dominance: Gemini open-sourced their CLI in response, discussion of future coding agent landscape.</p>]]></summary>
    <category term="claude_code"/>
    <category term="ai_coding_tools"/>
    <category term="market_competition"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:6bd2b155b2c8</id>
    <title>[D] 100 Hallucinated Citations Found in 51 Accepted Papers at NeurIPS 2025</title>
    <link href="https://reddit.com/r/MachineLearning/comments/1qjz88r/d_100_hallucinated_citations_found_in_51_accepted/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-6bd2b155b2c8" rel="related" type="text/html"/>
    <published>2026-01-23T03:31:00Z</published>
    <updated>2026-01-23T03:31:00Z</updated>
    <author><name>u/mgcdot</name></author>
    <summary type="html"><![CDATA[<p>GPTZero analysis found 100 hallucinated citations across 51 accepted NeurIPS 2025 papers, indicating AI-generated content in peer-reviewed research. Extends previous findings from ICLR submissions.</p>]]></summary>
    <category term="academic_integrity"/>
    <category term="AI_ethics"/>
    <category term="hallucination_detection"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:3940eaed023f</id>
    <title>OpenAI says Codex usage grew 20× in 5 months, helping add ~$1B in annualized API revenue last month</title>
    <link href="https://reddit.com/r/singularity/comments/1qk6pbi/openai_says_codex_usage_grew_20_in_5_months/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-3940eaed023f" rel="related" type="text/html"/>
    <published>2026-01-23T03:31:00Z</published>
    <updated>2026-01-23T03:31:00Z</updated>
    <author><name>u/thatguyisme87</name></author>
    <summary type="html"><![CDATA[<p>OpenAI CFO reports Codex usage grew 20x in 5 months, adding ~$1B in annualized API revenue. Enterprise mix shifting from 30% to 40%, targeting 50% by year end. OpenAI exited 2025 with $40B on balance sheet.</p>]]></summary>
    <category term="ai_coding_tools"/>
    <category term="openai_business"/>
    <category term="enterprise_adoption"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:f14b225ec8f2</id>
    <title>New AI startup with Yann LeCun claims "first credible signs of AGI" with a public EBM demo</title>
    <link href="https://reddit.com/r/agi/comments/1qjzdvx/new_ai_startup_with_yann_lecun_claims_first/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-f14b225ec8f2" rel="related" type="text/html"/>
    <published>2026-01-23T03:31:00Z</published>
    <updated>2026-01-23T03:31:00Z</updated>
    <author><name>u/goxper</name></author>
    <summary type="html"><![CDATA[<p>Logical Intelligence launches with Yann LeCun as research board chair, claiming 'first credible signs of AGI' with Energy-Based Model 'Kona 1.0' that beats GPT-5.2 and Claude Opus on Sudoku via energy minimization.</p>]]></summary>
    <category term="energy_based_models"/>
    <category term="lecun"/>
    <category term="startups"/>
    <category term="agi_claims"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:b74e8a5a1eee</id>
    <title>Gemini, when confronted with current events as of January 2026, does not believe its own search tool and thinks it's part of a roleplay or deception</title>
    <link href="https://reddit.com/r/singularity/comments/1qjx26b/gemini_when_confronted_with_current_events_as_of/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-b74e8a5a1eee" rel="related" type="text/html"/>
    <published>2026-01-23T03:23:00Z</published>
    <updated>2026-01-23T03:23:00Z</updated>
    <author><name>u/enilea</name></author>
    <summary type="html"><![CDATA[<p>Gemini refuses to believe its own search results about unexpected current events, thinking it's in a containerized test environment with fake data.</p>]]></summary>
    <category term="llm_behavior"/>
    <category term="ai_reliability"/>
    <category term="tool_use"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-23:reddit:31730880210f</id>
    <title>Qwen3-TTS, a series of powerful speech generation capabilities</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qjuebr/qwen3tts_a_series_of_powerful_speech_generation/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-23&amp;category=reddit#item-31730880210f" rel="related" type="text/html"/>
    <published>2026-01-23T03:23:00Z</published>
    <updated>2026-01-23T03:23:00Z</updated>
    <author><name>u/fruesome</name></author>
    <summary type="html"><![CDATA[<p>Announcement of Qwen3-TTS series: 5 models (0.6B-1.8B) with voice cloning, design, 10 language support, and SOTA 12Hz tokenizer.</p>]]></summary>
    <category term="Qwen models"/>
    <category term="text-to-speech"/>
    <category term="voice cloning"/>
    <category term="model release"/>
  </entry>
</feed>