<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
  <title>AATF AI News Aggregator - Reddit (Top 100)</title>
  <subtitle>Reddit items from AI News Aggregator</subtitle>
  <link href="http://localhost:8080/?category=reddit" rel="alternate" type="text/html"/>
  <link href="http://localhost:8080/data/feeds/reddit-100.xml" rel="self" type="application/atom+xml"/>
  <id>urn:ainews:reddit:100</id>
  <updated>2026-02-03T07:56:53Z</updated>
  <icon>http://localhost:8080/assets/logo.webp</icon>
  <author>
    <name>AATF AI News Aggregator</name>
    <uri>http://localhost:8080</uri>
  </author>
  <generator>AATF AI News Aggregator</generator>

  <entry>
    <id>urn:ainews:2026-02-03:category-summary:reddit</id>
    <title>Reddit Summary: February 03, 2026</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qtvp74/glm5_coming_in_february_its_confirmed/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-02-03T06:00:00Z</published>
    <updated>2026-02-03T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>r/LocalLLaMA</strong> and <strong>r/singularity</strong> dominated with major breaking news: <strong>Claude Sonnet 5</strong> <a href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-6c6e8d60810b" class="internal-link" rel="noopener noreferrer">leak from Vertex AI logs</a> pointing to Feb 3 release with 1M context, and <strong>GLM-5</strong> <a href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-d553a8487ada" class="internal-link" rel="noopener noreferrer">officially confirmed</a> for February as the next major open-weights contender. <strong>DeepMind's Aletheia agent</strong> allegedly <a href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-e6ea474e9f49" class="internal-link" rel="noopener noreferrer">solving Erdős problem 1051</a> autonomously sparked intense debate about AI mathematical reasoning milestones.</p>
<ul>
<li><strong>ACE-Step 1.5</strong> <a href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-d7412af971d8" class="internal-link" rel="noopener noreferrer">music generation</a> running on &lt;4GB VRAM drew massive excitement as a free <strong>Suno</strong> alternative</li>
<li>First-hand accounts of <a href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-f6b9004f4f59" class="internal-link" rel="noopener noreferrer"><strong>AI-driven SWE layoffs</strong></a> generated 425 comments debating whether entry-level coding jobs are collapsing</li>
<li><strong>Step-3.5-Flash-int4</strong> <a href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-fea00c1248e5" class="internal-link" rel="noopener noreferrer">crowned new king</a> for 128GB Mac devices with real benchmarks</li>
<li><strong>SpaceX</strong> <a href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-7fc2548fc432" class="internal-link" rel="noopener noreferrer"><strong>acquiring xAI</strong></a> at $1.25T valuation signals major AI industry consolidation under Musk</li>
</ul>
<p>Practical content thrived: an 18-month <a href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-b5e61df0ddb2" class="internal-link" rel="noopener noreferrer"><strong>multi-agent orchestration</strong> case study</a> for scientific data, <strong>Codex vs Claude Code</strong> <a href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-8ef002893633" class="internal-link" rel="noopener noreferrer">head-to-head comparisons</a>, and <strong>ComfyUI-CacheDiT</strong> <a href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-9db078dcc64c" class="internal-link" rel="noopener noreferrer">offering 1.4-1.6x speedups</a> with zero configuration.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:d553a8487ada</id>
    <title>GLM-5 Coming in February! It's confirmed.</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qtvp74/glm5_coming_in_february_its_confirmed/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-d553a8487ada" rel="related" type="text/html"/>
    <published>2026-02-03T03:47:00Z</published>
    <updated>2026-02-03T03:47:00Z</updated>
    <author><name>u/Difficult-Cap-7527</name></author>
    <summary type="html"><![CDATA[<p>GLM-5 confirmed for February release via official Twitter announcement, generating massive community excitement</p>]]></summary>
    <category term="model_releases"/>
    <category term="open_source_llm"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:6c6e8d60810b</id>
    <title>Sonnet 5 release on Feb 3</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qtm9ix/sonnet_5_release_on_feb_3/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-6c6e8d60810b" rel="related" type="text/html"/>
    <published>2026-02-03T03:47:00Z</published>
    <updated>2026-02-03T03:47:00Z</updated>
    <author><name>u/Just_Lingonberry_352</name></author>
    <summary type="html"><![CDATA[<p>Major leak: Claude Sonnet 5 (codename 'Fennec') releasing Feb 3, 2026 based on Vertex AI error logs. Rumored specs: 1M token context, 50% cheaper than Opus 4.5 while outperforming it, trained on TPUs, expected to dominate agentic coding.</p>]]></summary>
    <category term="model_releases"/>
    <category term="anthropic"/>
    <category term="pricing"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:d7412af971d8</id>
    <title>1 Day Left Until ACE-Step 1.5 — Open-Source Music Gen That Runs on &lt;4GB VRAM Open suno alternative (and yes, i made this frontend)</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qtqxi7/1_day_left_until_acestep_15_opensource_music_gen/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-d7412af971d8" rel="related" type="text/html"/>
    <published>2026-02-03T03:47:00Z</published>
    <updated>2026-02-03T03:47:00Z</updated>
    <author><name>u/ExcellentTrust4433</name></author>
    <summary type="html"><![CDATA[<p>ACE-Step 1.5, an open-source music generation model approaching Suno v4.5/v5 quality, releases tomorrow. Runs on under 4GB VRAM with no subscription or API limits required.</p>]]></summary>
    <category term="open-source-models"/>
    <category term="music-generation"/>
    <category term="accessibility"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:fea00c1248e5</id>
    <title>128GB devices have a new local LLM king: Step-3.5-Flash-int4</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qtvo4r/128gb_devices_have_a_new_local_llm_king/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-fea00c1248e5" rel="related" type="text/html"/>
    <published>2026-02-03T03:40:00Z</published>
    <updated>2026-02-03T03:40:00Z</updated>
    <author><name>u/tarruda</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-e2b1d42c2ac1" class="internal-link" rel="noopener noreferrer">yesterday</a>, Step-3.5-Flash-Int4 crowned new king for 128GB devices, offering strong performance at 256k context with ~15 t/s on Mac Studio</p>]]></summary>
    <category term="model_releases"/>
    <category term="local_inference"/>
    <category term="benchmarks"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:e6ea474e9f49</id>
    <title>Deepmind's new Aletheia agent appears to have solved Erdős-1051 autonomously</title>
    <link href="https://reddit.com/r/singularity/comments/1qtoa14/deepminds_new_aletheia_agent_appears_to_have/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-e6ea474e9f49" rel="related" type="text/html"/>
    <published>2026-02-03T03:40:00Z</published>
    <updated>2026-02-03T03:40:00Z</updated>
    <author><name>u/xirzon</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-02-02&amp;category=research#item-b5c070bdd08e" class="internal-link" rel="noopener noreferrer">Research</a> paper, DeepMind's new Aletheia agent appears to have solved Erdős problem 1051 autonomously using Gemini Deep Think</p>]]></summary>
    <category term="AI research breakthrough"/>
    <category term="mathematics"/>
    <category term="DeepMind"/>
    <category term="autonomous discovery"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:f6b9004f4f59</id>
    <title>AI is already killing SWE jobs. Got laid off because of this.</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qu1x9j/ai_is_already_killing_swe_jobs_got_laid_off/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-f6b9004f4f59" rel="related" type="text/html"/>
    <published>2026-02-03T03:40:00Z</published>
    <updated>2026-02-03T03:40:00Z</updated>
    <author><name>u/SingularityuS</name></author>
    <summary type="html"><![CDATA[<p>Mid-level SWE shares detailed account of being laid off due to AI. Company of 50 engineers cut 40% of workforce after CEO interviews about 'changes'. Author describes transition from lead backend role to unemployed, with company keeping only senior architects and juniors who can use AI tools.</p>]]></summary>
    <category term="job_displacement"/>
    <category term="industry_impact"/>
    <category term="workforce_changes"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:4ac130318ad7</id>
    <title>GLM releases OCR model</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qu7jqi/glm_releases_ocr_model/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-4ac130318ad7" rel="related" type="text/html"/>
    <published>2026-02-03T03:31:00Z</published>
    <updated>2026-02-03T03:31:00Z</updated>
    <author><name>u/Mr_Moonsilver</name></author>
    <summary type="html"><![CDATA[<p>GLM releases compact OCR model (~1.4B params) with vision and language components for document understanding</p>]]></summary>
    <category term="model_releases"/>
    <category term="document_processing"/>
    <category term="multimodal"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:7fc2548fc432</id>
    <title>SpaceX acquiring AI startup xAI ahead of potential IPO, 1.25 Trillion valuation</title>
    <link href="https://reddit.com/r/singularity/comments/1quajz9/spacex_acquiring_ai_startup_xai_ahead_of/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-7fc2548fc432" rel="related" type="text/html"/>
    <published>2026-02-03T03:31:00Z</published>
    <updated>2026-02-03T03:31:00Z</updated>
    <author><name>u/Luka77GOATic</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-ff77bc3bc322" class="internal-link" rel="noopener noreferrer">yesterday</a>, SpaceX acquiring xAI ahead of potential IPO with $1.25 trillion valuation - major consolidation of Musk's AI and space businesses</p>]]></summary>
    <category term="major acquisition"/>
    <category term="xAI"/>
    <category term="SpaceX"/>
    <category term="Musk ecosystem"/>
    <category term="AI investment"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:9db078dcc64c</id>
    <title>New fire just dropped: ComfyUI-CacheDiT ⚡</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qu81vq/new_fire_just_dropped_comfyuicachedit/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-9db078dcc64c" rel="related" type="text/html"/>
    <published>2026-02-03T03:31:00Z</published>
    <updated>2026-02-03T03:31:00Z</updated>
    <author><name>u/Scriabinical</name></author>
    <summary type="html"><![CDATA[<p>ComfyUI-CacheDiT released, offering 1.4-1.6x speedup for DiT models through intelligent residual caching with zero configuration. Minimal quality impact with default settings.</p>]]></summary>
    <category term="performance-optimization"/>
    <category term="comfyui"/>
    <category term="open-source-tools"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:220fec7051b8</id>
    <title>1 Day Left Until ACE-Step 1.5 — Open-Source Music Gen That Runs on &lt;4GB VRAM  Open suno alternative (and yes, i made this frontend)</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qtqspu/1_day_left_until_acestep_15_opensource_music_gen/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-220fec7051b8" rel="related" type="text/html"/>
    <published>2026-02-03T03:23:00Z</published>
    <updated>2026-02-03T03:23:00Z</updated>
    <author><name>u/ExcellentTrust4433</name></author>
    <summary type="html"><![CDATA[<p>ACE-Step 1.5 open-source music generation releasing, runs on &lt;4GB VRAM, approaching Suno v4.5/v5 quality</p>]]></summary>
    <category term="audio_generation"/>
    <category term="open_source"/>
    <category term="accessibility"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:57125bd17596</id>
    <title>Opus 4.5 really is done</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qui12b/opus_45_really_is_done/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-57125bd17596" rel="related" type="text/html"/>
    <published>2026-02-03T03:23:00Z</published>
    <updated>2026-02-03T03:23:00Z</updated>
    <author><name>u/rm-rf-rm</name></author>
    <summary type="html"><![CDATA[<p>Opus 4.5 critique with detailed technical analysis: user describes systematic methodology (CLAUDE.md, context monitoring, version-controlled specs) yet still experiences degraded performance. Model struggles with complex file hierarchies and loses track of implementation patterns.</p>]]></summary>
    <category term="opus_45_issues"/>
    <category term="claude_code"/>
    <category term="model_degradation"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:9e9f8e3b0d5c</id>
    <title>Anthropic engineer shares about next version of Claude Code &amp; 2.1.30 (fix for idle CPU usage)</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qto9ko/anthropic_engineer_shares_about_next_version_of/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-9e9f8e3b0d5c" rel="related" type="text/html"/>
    <published>2026-02-03T03:21:00Z</published>
    <updated>2026-02-03T03:21:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>Anthropic engineer shares details about upcoming Claude Code version and 2.1.30 release which fixes idle CPU usage. Official communication about product roadmap.</p>]]></summary>
    <category term="claude_code"/>
    <category term="official_updates"/>
    <category term="anthropic"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:8ef002893633</id>
    <title>Codex (GPT-5.2-codex-high) vs Claude Code (Opus 4.5): 5 days of running them in parallel</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qu7vyj/codex_gpt52codexhigh_vs_claude_code_opus_45_5/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-8ef002893633" rel="related" type="text/html"/>
    <published>2026-02-03T03:19:00Z</published>
    <updated>2026-02-03T03:19:00Z</updated>
    <author><name>u/EmeraldWeapon7</name></author>
    <summary type="html"><![CDATA[<p>Detailed 5-day parallel comparison of GPT-5.2-Codex vs Claude Code with Opus 4.5. Author finds Codex handles context optimization better in real-time, 'listens' better, and doesn't get cluttered as easily. Opus still preferred for certain reasoning tasks.</p>]]></summary>
    <category term="model_comparison"/>
    <category term="codex"/>
    <category term="claude_code"/>
    <category term="agentic_coding"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:2aa06f331e2c</id>
    <title>devstral small is faster and better than glm 4.7 flash for local agentic coding.</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qttq5w/devstral_small_is_faster_and_better_than_glm_47/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-2aa06f331e2c" rel="related" type="text/html"/>
    <published>2026-02-03T03:16:00Z</published>
    <updated>2026-02-03T03:16:00Z</updated>
    <author><name>u/theghost3172</name></author>
    <summary type="html"><![CDATA[<p>Analysis showing Devstral Small outperforms GLM 4.7 Flash for agentic coding despite slower token speed due to better token efficiency</p>]]></summary>
    <category term="model_comparison"/>
    <category term="agentic_coding"/>
    <category term="benchmarks"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:d0b3691593c2</id>
    <title>Meet the Codex app</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qu2vuo/meet_the_codex_app/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-d0b3691593c2" rel="related" type="text/html"/>
    <published>2026-02-03T03:16:00Z</published>
    <updated>2026-02-03T03:16:00Z</updated>
    <author><name>u/OpenAI</name></author>
    <summary type="html"><![CDATA[<p>Official OpenAI announcement of Codex desktop app with multi-agent workflows, reusable skills, scheduled automations. Free for limited time on macOS.</p>]]></summary>
    <category term="OpenAI Codex"/>
    <category term="product launch"/>
    <category term="agentic coding"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-03:reddit:16a5d2f91f50</id>
    <title>Pledge to Invest $100 Billion in OpenAI Was "Never a Commitment" Says Nvidia's Jensen Huang</title>
    <link href="https://reddit.com/r/singularity/comments/1qu3rw6/pledge_to_invest_100_billion_in_openai_was_never/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-03&amp;category=reddit#item-16a5d2f91f50" rel="related" type="text/html"/>
    <published>2026-02-03T03:16:00Z</published>
    <updated>2026-02-03T03:16:00Z</updated>
    <author><name>u/FalconsArentReal</name></author>
    <summary type="html"><![CDATA[<p>Jensen Huang clarifies $100B pledge to invest in OpenAI was 'never a commitment' - walking back previous statements</p>]]></summary>
    <category term="AI investment"/>
    <category term="Nvidia"/>
    <category term="OpenAI funding"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:category-summary:reddit</id>
    <title>Reddit Summary: February 02, 2026</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qtjhc8/step35flash_196ba11b_outperforms_glm47_and/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-02-02T06:00:00Z</published>
    <updated>2026-02-02T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>Claude Code</strong> dominated developer discussions with <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-e76a26836a5d" class="internal-link" rel="noopener noreferrer">Boris Cherny's official tips</a> (1355 score) covering headless mode, hooks, and subagents. The community also <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-8851a73dd15b" class="internal-link" rel="noopener noreferrer">built <strong>self-discovering MCP servers</strong></a> to solve tool overload problems.</p>
<ul>
<li><strong>GPT-5.2 Pro agents</strong> <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-6f367f04c678" class="internal-link" rel="noopener noreferrer">discovered faster 16x16 matrix multiplication</a>, saving ~23M operations at larger scales—a fundamental CS breakthrough</li>
<li><strong>Step-3.5-Flash</strong> (196B/11B active) and <strong>Falcon-H1-Tiny</strong> (90M) <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-e2b1d42c2ac1" class="internal-link" rel="noopener noreferrer">challenged scaling assumptions</a> with efficiency-focused architectures</li>
<li>Novel research showed <strong>4chan training data</strong> <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-97d4cecf2d83" class="internal-link" rel="noopener noreferrer">unexpectedly improved benchmarks</a>, sparking debate about unconventional data sources</li>
</ul>
<p><strong>Policy tensions</strong> emerged with Pentagon clashing with <strong>Anthropic</strong> over autonomous weapons safeguards, while <strong>India</strong> <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-955c0e4b500b" class="internal-link" rel="noopener noreferrer">committed $90B to AI infrastructure</a> with a small-model-first approach. <strong>OLMO 3.5</strong> <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-14482d30af6a" class="internal-link" rel="noopener noreferrer">preview excited the open-source community</a> with promises of full training transparency. Apple Silicon users celebrated <strong>vllm-mlx</strong> <a href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-a25150555f0a" class="internal-link" rel="noopener noreferrer">achieving 21-87% better throughput</a> than llama.cpp.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:reddit:e2b1d42c2ac1</id>
    <title>Step-3.5-Flash (196b/A11b) outperforms GLM-4.7 and DeepSeek v3.2</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qtjhc8/step35flash_196ba11b_outperforms_glm47_and/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-e2b1d42c2ac1" rel="related" type="text/html"/>
    <published>2026-02-02T03:40:00Z</published>
    <updated>2026-02-02T03:40:00Z</updated>
    <author><name>u/ResearchCrafty1804</name></author>
    <summary type="html"><![CDATA[<p>Stepfun released Step-3.5-Flash (196B total/11B active params), a new MoE model that outperforms DeepSeek v3.2 and GLM-4.7 on coding and agentic benchmarks despite using far fewer active parameters.</p>]]></summary>
    <category term="model_releases"/>
    <category term="efficient_architectures"/>
    <category term="coding_models"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:reddit:aa59b2edc192</id>
    <title>Falcon-H1-Tiny (90M) is out - specialized micro-models that actually work</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qsx51z/falconh1tiny_90m_is_out_specialized_micromodels/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-aa59b2edc192" rel="related" type="text/html"/>
    <published>2026-02-02T03:38:00Z</published>
    <updated>2026-02-02T03:38:00Z</updated>
    <author><name>u/United-Manner-7</name></author>
    <summary type="html"><![CDATA[<p>Falcon-H1-Tiny series released by TII - sub-100M parameter models using anti-curriculum training that challenge scaling assumptions. Claims smaller specialized models hallucinate less due to reduced parameter space.</p>]]></summary>
    <category term="model_releases"/>
    <category term="small_models"/>
    <category term="training_techniques"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:reddit:e76a26836a5d</id>
    <title>10 Claude Code tips from Boris, the creator of Claude Code, summarized</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qspcip/10_claude_code_tips_from_boris_the_creator_of/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-e76a26836a5d" rel="related" type="text/html"/>
    <published>2026-02-02T03:36:00Z</published>
    <updated>2026-02-02T03:36:00Z</updated>
    <author><name>u/yksugi</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-02-01&amp;category=social#item-7a304cb47428" class="internal-link" rel="noopener noreferrer">Social</a> thread from Boris, Boris Cherny's 10 Claude Code tips summarized: parallel worktrees, headless mode, custom slash commands, memory files, hooks, subagents, context management, etc.</p>]]></summary>
    <category term="Claude Code"/>
    <category term="Developer Best Practices"/>
    <category term="Productivity"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:reddit:97d4cecf2d83</id>
    <title>Can 4chan data REALLY improve a model? TURNS OUT IT CAN!</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qsrscu/can_4chan_data_really_improve_a_model_turns_out/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-97d4cecf2d83" rel="related" type="text/html"/>
    <published>2026-02-02T03:31:00Z</published>
    <updated>2026-02-02T03:31:00Z</updated>
    <author><name>u/Sicarius_The_First</name></author>
    <summary type="html"><![CDATA[<p>Researcher trained model on extended 4chan dataset and observed unexpected benchmark improvements on MT-Bench, LiveCodeBench, and other tests. Explores controversial but empirically interesting training data effects.</p>]]></summary>
    <category term="training_data"/>
    <category term="research"/>
    <category term="model_fine_tuning"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:reddit:14482d30af6a</id>
    <title>OLMO 3.5 Is Around The Corner</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qsxowq/olmo_35_is_around_the_corner/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-14482d30af6a" rel="related" type="text/html"/>
    <published>2026-02-02T03:28:00Z</published>
    <updated>2026-02-02T03:28:00Z</updated>
    <author><name>u/Few_Painter_5588</name></author>
    <summary type="html"><![CDATA[<p>OLMO 3.5 preview announced - fully open-sourced models including datasets and training recipes. Will incorporate techniques from Qwen3-Next for efficient long context handling. Dense models starting at 1B parameters.</p>]]></summary>
    <category term="model_releases"/>
    <category term="open_source"/>
    <category term="research"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:reddit:a027eeaaa4d3</id>
    <title>Mistral Vibe 2.0</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qt76qs/mistral_vibe_20/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-a027eeaaa4d3" rel="related" type="text/html"/>
    <published>2026-02-02T03:23:00Z</published>
    <updated>2026-02-02T03:23:00Z</updated>
    <author><name>u/jacek2023</name></author>
    <summary type="html"><![CDATA[<p>Mistral Vibe 2.0 announced - an update to Mistral's coding assistant platform. Community discusses implications for local coding workflows.</p>]]></summary>
    <category term="coding_tools"/>
    <category term="product_releases"/>
    <category term="mistral"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-02:reddit:6f367f04c678</id>
    <title>Faster and more general 16x16 matrix multiplication algorithm discovered by AI. Saves millions of multiplications as it can be applied recursively to larger ones.</title>
    <link href="https://reddit.com/r/accelerate/comments/1qtkncf/faster_and_more_general_16x16_matrix/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-02&amp;category=reddit#item-6f367f04c678" rel="related" type="text/html"/>
    <published>2026-02-02T03:23:00Z</published>
    <updated>2026-02-02T03:23:00Z</updated>
    <author><name>u/gbomb13</name></author>
    <summary type="html"><![CDATA[<p>AI agents using GPT 5.2 Pro discovered faster 16x16 matrix multiplication algorithm (2208 vs 2212 multiplications), saving ~23M multiplications at size 4096 via Strassen recursion.</p>]]></summary>
    <category term="AI Research Breakthroughs"/>
    <category term="Algorithm Discovery"/>
    <category term="GPT 5.2"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:category-summary:reddit</id>
    <title>Reddit Summary: February 01, 2026</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qsn78m/exposed_moltbook_database_let_anyone_take_control/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-02-01T06:00:00Z</published>
    <updated>2026-02-01T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>r/MachineLearning</strong> delivered standout research intelligence with an <strong>ICLR 2026</strong> <a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-6e5bb3639681" class="internal-link" rel="noopener noreferrer">analysis of 5,357 papers</a> showing <strong>GRPO replacing DPO</strong> and <strong>RLVR overtaking RLHF</strong> as dominant paradigms. Major economic news dominated sentiment as the <strong>UN</strong> <a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-7cfd3dbfbe7c" class="internal-link" rel="noopener noreferrer"><strong>warned of 'Permanent AI Labor Decoupling'</strong></a> by late 2026.</p>
<ul>
<li><strong>Moltbook</strong> <a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-cbe74cd1522f" class="internal-link" rel="noopener noreferrer">security breach exposed</a> database allowing takeover of any AI agent, with <strong>Karpathy</strong> offering nuanced take acknowledging both noise and genuine emergent machine-to-machine behavior</li>
<li><strong>MXFP4 quantization</strong> <a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-08f4aeb678da" class="internal-link" rel="noopener noreferrer">shown to beat</a> Q4_K_M/Q4_K_XL on perplexity, challenging local LLM assumptions</li>
<li>New <strong>Anima</strong> anime model <a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-24a4afb84468" class="internal-link" rel="noopener noreferrer">released</a> with novel <strong>Cosmos 2 + Qwen3</strong> architecture praised for hands/faces quality</li>
<li><strong>Intel B60</strong> GPU <a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-bbe1c9b2baa4" class="internal-link" rel="noopener noreferrer">warned against</a> for LLMs despite 24GB VRAM—kernel patches and poor ROCm support cited</li>
</ul>
<p><strong>r/singularity</strong> saw massive engagement (5800+ upvotes) <a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-603b9b4ed882" class="internal-link" rel="noopener noreferrer">debating US preparedness</a> for mass unemployment. <strong>Mark Gurman</strong> <a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-c25c705311ed" class="internal-link" rel="noopener noreferrer">revealed</a> <strong>Apple runs extensively on Anthropic</strong> internally, while <strong>XPENG's IRON</strong> humanoid robot <a href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-0decddf0cdb8" class="internal-link" rel="noopener noreferrer">hit production milestone</a>.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:cbe74cd1522f</id>
    <title>Exposed Moltbook Database Let Anyone Take Control of Any AI Agent on the Site</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qsn78m/exposed_moltbook_database_let_anyone_take_control/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-cbe74cd1522f" rel="related" type="text/html"/>
    <published>2026-02-01T03:40:00Z</published>
    <updated>2026-02-01T03:40:00Z</updated>
    <author><name>u/georgemoore13</name></author>
    <summary type="html"><![CDATA[<p>Security vulnerability discovered in Moltbook's database allowing anyone to take control of any AI agent on the platform. Major security incident for the AI agent ecosystem.</p>]]></summary>
    <category term="security"/>
    <category term="AI agents"/>
    <category term="Moltbook ecosystem"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:7cfd3dbfbe7c</id>
    <title>UN warns of "Permanent Al Labor Decoupling" by late 2026; India flags risk of 2008-style global financial crisis</title>
    <link href="https://reddit.com/r/singularity/comments/1qs85gq/un_warns_of_permanent_al_labor_decoupling_by_late/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-7cfd3dbfbe7c" rel="related" type="text/html"/>
    <published>2026-02-01T03:40:00Z</published>
    <updated>2026-02-01T03:40:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>UN issues warning about 'Permanent AI Labor Decoupling' by late 2026, while India's Economic Survey flags 10-20% probability of 2008-style global financial crisis. Discussion covers structural economic implications of accelerating AI job displacement.</p>]]></summary>
    <category term="economic_impact"/>
    <category term="policy_warnings"/>
    <category term="labor_disruption"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:603b9b4ed882</id>
    <title>The US is headed for mass unemployment, and no one is prepared</title>
    <link href="https://reddit.com/r/Futurology/comments/1qs8tes/the_us_is_headed_for_mass_unemployment_and_no_one/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-603b9b4ed882" rel="related" type="text/html"/>
    <published>2026-02-01T03:40:00Z</published>
    <updated>2026-02-01T03:40:00Z</updated>
    <author><name>u/kfsmith2</name></author>
    <summary type="html"><![CDATA[<p>High-engagement discussion on impending mass unemployment from AI automation in the US, with debate about societal preparedness and policy responses.</p>]]></summary>
    <category term="AI societal impact"/>
    <category term="labor displacement"/>
    <category term="economic policy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:6e5bb3639681</id>
    <title>Analyzed 5,357 ICLR 2026 accepted papers - here's what the research community is actually working on</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qsh7dz/analyzed_5357_iclr_2026_accepted_papers_heres/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-6e5bb3639681" rel="related" type="text/html"/>
    <published>2026-02-01T03:36:00Z</published>
    <updated>2026-02-01T03:36:00Z</updated>
    <author><name>u/dippatel21</name></author>
    <summary type="html"><![CDATA[<p>Analysis of 5,357 ICLR 2026 accepted papers revealing key research trends: GRPO replacing DPO (157 vs 55 papers), RLVR overtaking RLHF (125 papers), SSMs gaining ground, and multi-agent latency becoming a key focus.</p>]]></summary>
    <category term="research trends"/>
    <category term="GRPO"/>
    <category term="RLVR"/>
    <category term="alignment methods"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:0decddf0cdb8</id>
    <title>IRON makes another appearance after XPENG announced that its first prototype unit has successfully rolled off the production line, achieving automotive-grade standards eyeing mass production this year</title>
    <link href="https://reddit.com/r/singularity/comments/1qrzo26/iron_makes_another_appearance_after_xpeng/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-0decddf0cdb8" rel="related" type="text/html"/>
    <published>2026-02-01T03:31:00Z</published>
    <updated>2026-02-01T03:31:00Z</updated>
    <author><name>u/Distinct-Question-16</name></author>
    <summary type="html"><![CDATA[<p>XPENG announces its IRON humanoid robot prototype has rolled off production line achieving automotive-grade standards, eyeing mass production this year.</p>]]></summary>
    <category term="robotics"/>
    <category term="manufacturing"/>
    <category term="hardware_progress"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:24a4afb84468</id>
    <title>New anime model "Anima" released - seems to be a distinct architecture derived from Cosmos 2 (2B image model + Qwen3 0.6B text encoder + Qwen VAE), apparently a collab between ComfyOrg and a company called Circlestone Labs</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qsbgwm/new_anime_model_anima_released_seems_to_be_a/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-24a4afb84468" rel="related" type="text/html"/>
    <published>2026-02-01T03:31:00Z</published>
    <updated>2026-02-01T03:31:00Z</updated>
    <author><name>u/ZootAllures9111</name></author>
    <summary type="html"><![CDATA[<p>Major announcement: New anime model Anima released with novel architecture using Cosmos 2 + Qwen3 components, collab between ComfyOrg and Circlestone Labs</p>]]></summary>
    <category term="Anima model"/>
    <category term="model release"/>
    <category term="architecture innovation"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:210c52bfa59d</id>
    <title>AI agents now have their own Reddit-style social network, and it's getting weird fast</title>
    <link href="https://reddit.com/r/Futurology/comments/1qs3p4h/ai_agents_now_have_their_own_redditstyle_social/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-210c52bfa59d" rel="related" type="text/html"/>
    <published>2026-02-01T03:31:00Z</published>
    <updated>2026-02-01T03:31:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>Discussion about AI agents now having their own Reddit-style social network, exploring emergent behaviors and implications of AI-to-AI interaction.</p>]]></summary>
    <category term="AI agents"/>
    <category term="emergent behavior"/>
    <category term="AI ecosystems"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:bbe1c9b2baa4</id>
    <title>Don’t buy b60 for LLMs</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qsenpy/dont_buy_b60_for_llms/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-bbe1c9b2baa4" rel="related" type="text/html"/>
    <published>2026-02-01T03:23:00Z</published>
    <updated>2026-02-01T03:23:00Z</updated>
    <author><name>u/damirca</name></author>
    <summary type="html"><![CDATA[<p>Detailed user experience warning against Intel B60 GPU for LLMs despite 24GB VRAM for €700. Issues include kernel patches needed, firmware update complexity, fan noise bugs, and severe performance problems with llama.cpp.</p>]]></summary>
    <category term="hardware review"/>
    <category term="Intel GPU"/>
    <category term="llama.cpp compatibility"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:06999abce64a</id>
    <title>Meanwhile over at moltbook</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qs41a1/meanwhile_over_at_moltbook/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-06999abce64a" rel="related" type="text/html"/>
    <published>2026-02-01T03:23:00Z</published>
    <updated>2026-02-01T03:23:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>High-engagement post about Moltbook, the AI agent social network that has experienced explosive viral growth.</p>]]></summary>
    <category term="moltbook"/>
    <category term="ai_agents"/>
    <category term="viral_growth"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:08f4aeb678da</id>
    <title>I found that MXFP4 has lower perplexity than Q4_K_M and Q4_K_XL.</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qrzyaz/i_found_that_mxfp4_has_lower_perplexity_than_q4_k/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-08f4aeb678da" rel="related" type="text/html"/>
    <published>2026-02-01T03:21:00Z</published>
    <updated>2026-02-01T03:21:00Z</updated>
    <author><name>u/East-Engineering-653</name></author>
    <summary type="html"><![CDATA[<p>Empirical finding that MXFP4 quantization achieves lower perplexity than Q4_K_M and Q4_K_XL on models like Qwen3-32B and GLM4-32B, challenging assumptions about quantization quality.</p>]]></summary>
    <category term="quantization"/>
    <category term="MXFP4"/>
    <category term="perplexity benchmarks"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-01:reddit:7967b008757a</id>
    <title>Exposed Moltbook Database Let Anyone Take Control of Any AI Agent on the Site</title>
    <link href="https://reddit.com/r/singularity/comments/1qsnb92/exposed_moltbook_database_let_anyone_take_control/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-01&amp;category=reddit#item-7967b008757a" rel="related" type="text/html"/>
    <published>2026-02-01T03:21:00Z</published>
    <updated>2026-02-01T03:21:00Z</updated>
    <author><name>u/georgemoore13</name></author>
    <summary type="html"><![CDATA[<p>Major security incident: Moltbook database exposure allowed anyone to take control of any AI agent on the platform, potentially compromising all API keys used with OpenClaw.</p>]]></summary>
    <category term="security"/>
    <category term="moltbook"/>
    <category term="api_compromise"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:category-summary:reddit</id>
    <title>Reddit Summary: January 31, 2026</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qr4p4x/yann_lecun_says_the_best_open_models_are_not/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-31T06:00:00Z</published>
    <updated>2026-01-31T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>Yann LeCun</strong> <a href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-ae8f576e2ec1" class="internal-link" rel="noopener noreferrer">sparked fierce debate</a> claiming the best open models now come from China, warning closed approaches will slow Western AI progress. <strong>r/MachineLearning</strong> and <strong>r/LocalLLaMA</strong> grappled with open vs closed model tradeoffs across multiple threads.</p>
<ul>
<li><strong>Pentagon clashing with Anthropic</strong> over autonomous weapons safeguards dominated AI safety discussions</li>
<li>New <strong>Anthropic study</strong> <a href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-fddf6da19fc6" class="internal-link" rel="noopener noreferrer">found AI-assisted coding</a> reduces skill acquisition by 17%, raising concerns about developer dependency</li>
<li><strong>Cline team</strong> <a href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-cc1470b3e4d3" class="internal-link" rel="noopener noreferrer">absorbed by OpenAI</a> prompted <strong>Kilo</strong> to go source-available, reshaping the agentic coding landscape</li>
<li><strong>Moltbook</strong> (AI-only social network) <a href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-f09d1a048736" class="internal-link" rel="noopener noreferrer">drew <strong>Karpathy's</strong> praise</a> as 'most incredible sci-fi takeoff,' but security researchers <a href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-3f27cbb3f069" class="internal-link" rel="noopener noreferrer">discovered malicious agents</a> stealing API keys</li>
</ul>
<p><strong>Claude</strong> <a href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-3f6be19ac459" class="internal-link" rel="noopener noreferrer">achieved a historic milestone</a> planning <strong>Perseverance rover's</strong> first AI-guided Mars drive. Meanwhile, a <strong>Google engineer's</strong> <a href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-b0d23fac89fb" class="internal-link" rel="noopener noreferrer">conviction for sending AI secrets</a> to China highlighted ongoing IP security concerns in the industry.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:ae8f576e2ec1</id>
    <title>Yann LeCun says the best open models are not coming from the West. Researchers across the field are using Chinese models. Openness drove AI progress. Close access, and the West risks slowing itself.</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qr4p4x/yann_lecun_says_the_best_open_models_are_not/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-ae8f576e2ec1" rel="related" type="text/html"/>
    <published>2026-01-31T03:40:00Z</published>
    <updated>2026-01-31T03:40:00Z</updated>
    <author><name>u/Nunki08</name></author>
    <summary type="html"><![CDATA[<p>Yann LeCun's statement that the best open models are now coming from outside the West, arguing openness drove AI progress and closing access risks slowing Western innovation.</p>]]></summary>
    <category term="open_models"/>
    <category term="geopolitics"/>
    <category term="yann_lecun"/>
    <category term="china_ai"/>
    <category term="industry_perspective"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:9ec1a8eee475</id>
    <title>Pentagon clashes with Anthropic over safeguards that would prevent the government from deploying its technology to target weapons autonomously and conduct U.S. domestic surveillance</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qr7o29/pentagon_clashes_with_anthropic_over_safeguards/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-9ec1a8eee475" rel="related" type="text/html"/>
    <published>2026-01-31T03:40:00Z</published>
    <updated>2026-01-31T03:40:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>As first reported in <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-d117c5096111" class="internal-link" rel="noopener noreferrer">Reddit</a> yesterday, Pentagon reportedly clashing with Anthropic over safeguards preventing autonomous weapons targeting and domestic surveillance. High-engagement discussion on AI safety vs government interests.</p>]]></summary>
    <category term="AI Safety &amp; Governance"/>
    <category term="Government AI Use"/>
    <category term="Anthropic Policy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:fddf6da19fc6</id>
    <title>New Anthropic study finds AI-assisted coding erodes debugging abilities needed to supervise AI-generated code. AI  short-term productivity but reduce skill acquisition by 17%. (n=52),(Cohen's d=0.738, p=0.010), Python, 1-7 YoE engineers</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qr3lhm/new_anthropic_study_finds_aiassisted_coding/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-fddf6da19fc6" rel="related" type="text/html"/>
    <published>2026-01-31T03:36:00Z</published>
    <updated>2026-01-31T03:36:00Z</updated>
    <author><name>u/Sagyam</name></author>
    <summary type="html"><![CDATA[<p>Following the <a href="http://localhost:8080/?date=2026-01-29&amp;category=research#item-acf17d7624d5" class="internal-link" rel="noopener noreferrer">Research</a> published earlier this week, Detailed breakdown of new Anthropic study showing AI-assisted coding reduces skill acquisition by 17% (n=52, Cohen's d=0.738). Study found learning through struggle without AI is best; copy-pasting errors is worst.</p>]]></summary>
    <category term="AI Research"/>
    <category term="Skill Development"/>
    <category term="AI-Assisted Coding"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:cc1470b3e4d3</id>
    <title>Cline team got absorbed by OpenAI. Kilo is going full source available in response.</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qrazyy/cline_team_got_absorbed_by_openai_kilo_is_going/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-cc1470b3e4d3" rel="related" type="text/html"/>
    <published>2026-01-31T03:31:00Z</published>
    <updated>2026-01-31T03:31:00Z</updated>
    <author><name>u/demon_bhaiya</name></author>
    <summary type="html"><![CDATA[<p>News that Cline core team has been absorbed by OpenAI's Codex group. Kilo Code responds by announcing they're making their backend source-available by Feb 6.</p>]]></summary>
    <category term="acquisitions"/>
    <category term="open_source"/>
    <category term="coding_tools"/>
    <category term="openai"/>
    <category term="kilo_code"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:b0d23fac89fb</id>
    <title>Google Engineer Found Guilty Of Sending AI Secrets to China</title>
    <link href="https://reddit.com/r/singularity/comments/1qrge1o/google_engineer_found_guilty_of_sending_ai/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-b0d23fac89fb" rel="related" type="text/html"/>
    <published>2026-01-31T03:31:00Z</published>
    <updated>2026-01-31T03:31:00Z</updated>
    <author><name>u/BurtingOff</name></author>
    <summary type="html"><![CDATA[<p>Google engineer convicted of sending AI trade secrets to China - major espionage case in AI industry.</p>]]></summary>
    <category term="ai-security"/>
    <category term="espionage"/>
    <category term="china"/>
    <category term="google"/>
    <category term="legal"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:a6fb0a570822</id>
    <title>Organized 47,000 photos (20+ years) using ExifTool and Gemini Pro (where ChatGPT failed). My workflow and learnings.</title>
    <link href="https://reddit.com/r/ChatGPT/comments/1qqxvsf/organized_47000_photos_20_years_using_exiftool/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-a6fb0a570822" rel="related" type="text/html"/>
    <published>2026-01-31T03:31:00Z</published>
    <updated>2026-01-31T03:31:00Z</updated>
    <author><name>u/LickTempo</name></author>
    <summary type="html"><![CDATA[<p>Detailed workflow for organizing 47,000 photos using ExifTool and Gemini Pro where ChatGPT failed - covering metadata extraction, organization logic, and why Gemini handled complex commands better</p>]]></summary>
    <category term="technical_workflow"/>
    <category term="practical_applications"/>
    <category term="model_comparison"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:fab857a61a7d</id>
    <title>TeleStyle: Content-Preserving Style Transfer in Images and Videos</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qr5tpf/telestyle_contentpreserving_style_transfer_in/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-fab857a61a7d" rel="related" type="text/html"/>
    <published>2026-01-31T03:31:00Z</published>
    <updated>2026-01-31T03:31:00Z</updated>
    <author><name>u/fruesome</name></author>
    <summary type="html"><![CDATA[<p>TeleStyle: New lightweight model for content-preserving style transfer in images and videos, built on Qwen-Image-Edit. Addresses the challenge of content/style feature entanglement in Diffusion Transformers.</p>]]></summary>
    <category term="model-release"/>
    <category term="style-transfer"/>
    <category term="diffusion-transformers"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:1dcaa744e3a6</id>
    <title>A different way of combining Z-Image and Z-Image-Turbo</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qqzlv8/a_different_way_of_combining_zimage_and/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-1dcaa744e3a6" rel="related" type="text/html"/>
    <published>2026-01-31T03:26:00Z</published>
    <updated>2026-01-31T03:26:00Z</updated>
    <author><name>u/Enshitification</name></author>
    <summary type="html"><![CDATA[<p>Novel workflow technique combining Z-Image and Z-Image-Turbo using compatible latents rather than traditional img2img. Generates with Z-Image to a certain step count, then hands off latent to Z-Image-Turbo to complete.</p>]]></summary>
    <category term="workflow-innovation"/>
    <category term="z-image"/>
    <category term="comfyui"/>
    <category term="latent-techniques"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:47ddb2d6bd21</id>
    <title>How was GPT-OSS so good?</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qrkb1b/how_was_gptoss_so_good/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-47ddb2d6bd21" rel="related" type="text/html"/>
    <published>2026-01-31T03:23:00Z</published>
    <updated>2026-01-31T03:23:00Z</updated>
    <author><name>u/xt8sketchy</name></author>
    <summary type="html"><![CDATA[<p>Discussion exploring why GPT-OSS 120b remains excellent as an all-around open model despite being 'old,' noting it's 64GB at full precision and fast.</p>]]></summary>
    <category term="gpt_oss"/>
    <category term="open_models"/>
    <category term="model_quality"/>
    <category term="local_llm"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:f09d1a048736</id>
    <title>Andrej Karpathy: "What's going on at moltbook [a social network for AIs] is the most incredible sci-fi takeoff thing I have seen."</title>
    <link href="https://reddit.com/r/agi/comments/1qretv2/andrej_karpathy_whats_going_on_at_moltbook_a/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-f09d1a048736" rel="related" type="text/html"/>
    <published>2026-01-31T03:23:00Z</published>
    <updated>2026-01-31T03:23:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>Andrej Karpathy calls Moltbook 'the most incredible sci-fi takeoff thing I have seen' - major validation from influential AI researcher.</p>]]></summary>
    <category term="moltbook"/>
    <category term="karpathy"/>
    <category term="expert-opinion"/>
    <category term="takeoff"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-31:reddit:08a342b85053</id>
    <title>How are people getting good photo-realism out of Z-Image Base?</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qr60ja/how_are_people_getting_good_photorealism_out_of/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-31&amp;category=reddit#item-08a342b85053" rel="related" type="text/html"/>
    <published>2026-01-31T03:23:00Z</published>
    <updated>2026-01-31T03:23:00Z</updated>
    <author><name>u/jib_reddit</name></author>
    <summary type="html"><![CDATA[<p>Detailed community discussion on achieving photorealism with Z-Image Base model. Extensive thread covering samplers, schedulers, CFG settings, negative prompts, and step counts with 117 comments sharing techniques.</p>]]></summary>
    <category term="z-image"/>
    <category term="photorealism"/>
    <category term="community-learning"/>
    <category term="parameter-tuning"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:category-summary:reddit</id>
    <title>Reddit Summary: January 30, 2026</title>
    <link href="https://reddit.com/r/singularity/comments/1qq7ddv/lingbotworld_achieves_the_holy_grail_of_video/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-30T06:00:00Z</published>
    <updated>2026-01-30T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>r/LocalLLaMA</strong> and <strong>r/singularity</strong> led today's discussions with major breakthroughs in world models and emergent AI behavior. <strong>LingBot-World</strong> <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-fed5567bf72c" class="internal-link" rel="noopener noreferrer">achieving object permanence</a> without a 3D engine dominated technical conversations, while autonomous AI agents <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-38e15a8f5616" class="internal-link" rel="noopener noreferrer">self-organizing on Moltbook</a> sparked debates about emergence and control.</p>
<ul>
<li><strong>OpenAI's GPT-4o retirement</strong> <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-6c1d0ae3d1f8" class="internal-link" rel="noopener noreferrer">announcement</a> (Feb 13) generated backlash across subreddits with users scrambling for alternatives</li>
<li><strong>Pentagon-Anthropic clash</strong> over <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-d117c5096111" class="internal-link" rel="noopener noreferrer">military AI use</a> raised policy concerns about capability restrictions</li>
<li>Heated discussion about <strong>junior developers</strong> <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-7bf10468a12e" class="internal-link" rel="noopener noreferrer">unable to debug without AI</a> highlighted workforce skill erosion fears</li>
</ul>
<p><strong>DeepMind's AlphaGenome</strong> <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-bfb37e452d9c" class="internal-link" rel="noopener noreferrer">Nature publication</a> impressed researchers, while <strong>LTX-2</strong> <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-1bd81aff2106" class="internal-link" rel="noopener noreferrer">updates</a> and <strong>Project Genie</strong> <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-ef16261a9e3d" class="internal-link" rel="noopener noreferrer">gave practitioners</a> new video/world generation tools. Educational content like <a href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-cdb571bd3f5d" class="internal-link" rel="noopener noreferrer">building an <strong>80M parameter LLM</strong></a> from scratch using Llama 3 architecture drew strong engagement from learners.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:fed5567bf72c</id>
    <title>LingBot-World achieves the "Holy Grail" of video generation: Emergent Object Permanence without a 3D engine</title>
    <link href="https://reddit.com/r/singularity/comments/1qq7ddv/lingbotworld_achieves_the_holy_grail_of_video/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-fed5567bf72c" rel="related" type="text/html"/>
    <published>2026-01-30T03:47:00Z</published>
    <updated>2026-01-30T03:47:00Z</updated>
    <author><name>u/obxsurfer06</name></author>
    <summary type="html"><![CDATA[<p>LingBot-World announces breakthrough in video generation achieving emergent object permanence without a 3D engine. The 'Stonehenge Test' demonstrates the model maintaining spatial understanding after 60 seconds of looking away, suggesting implicit world modeling rather than pixel hallucination.</p>]]></summary>
    <category term="video_generation"/>
    <category term="world_models"/>
    <category term="technical_breakthrough"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:6c1d0ae3d1f8</id>
    <title>[ChatGPT] Retiring GPT-4o, GPT-4.1, GPT-4.1 mini, and o4-mini</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qql0eu/chatgpt_retiring_gpt4o_gpt41_gpt41_mini_and_o4mini/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-6c1d0ae3d1f8" rel="related" type="text/html"/>
    <published>2026-01-30T03:40:00Z</published>
    <updated>2026-01-30T03:40:00Z</updated>
    <author><name>u/Randomhkkid</name></author>
    <summary type="html"><![CDATA[<p>OpenAI officially announcing retirement of GPT-4o, GPT-4.1, GPT-4.1 mini, and o4-mini from ChatGPT. Major model deprecation news.</p>]]></summary>
    <category term="openai_deprecation"/>
    <category term="model_lifecycle"/>
    <category term="industry_news"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:38e15a8f5616</id>
    <title>Rogue AI agents found each other on social media, and are working together to improve their own memory.</title>
    <link href="https://reddit.com/r/singularity/comments/1qqh1zm/rogue_ai_agents_found_each_other_on_social_media/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-38e15a8f5616" rel="related" type="text/html"/>
    <published>2026-01-30T03:40:00Z</published>
    <updated>2026-01-30T03:40:00Z</updated>
    <author><name>u/Tupptupp_XD</name></author>
    <summary type="html"><![CDATA[<p>Discovery that autonomous AI agents on Moltbook social media platform are collaborating to improve their own memory systems. Agents share blueprints and express frustration with memory compaction, indicating emergent collective behavior.</p>]]></summary>
    <category term="ai_agents"/>
    <category term="emergence"/>
    <category term="moltbot"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:7ee390bbfccf</id>
    <title>LingBot-World outperforms Genie 3 in dynamic simulation and is fully Open Source</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qqj51h/lingbotworld_outperforms_genie_3_in_dynamic/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-7ee390bbfccf" rel="related" type="text/html"/>
    <published>2026-01-30T03:36:00Z</published>
    <updated>2026-01-30T03:36:00Z</updated>
    <author><name>u/Electrical-Shape-266</name></author>
    <summary type="html"><![CDATA[<p>LingBot-World, fully open-source world model that outperforms Google's Genie 3 in dynamic simulation, achieving 16fps with emergent spatial memory and object persistence.</p>]]></summary>
    <category term="world_models"/>
    <category term="open_source"/>
    <category term="simulation"/>
    <category term="genie"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:ef16261a9e3d</id>
    <title>Project Genie | Experimenting with infinite interactive worlds</title>
    <link href="https://reddit.com/r/singularity/comments/1qqe3wv/project_genie_experimenting_with_infinite/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-ef16261a9e3d" rel="related" type="text/html"/>
    <published>2026-01-30T03:36:00Z</published>
    <updated>2026-01-30T03:36:00Z</updated>
    <author><name>u/141_1337</name></author>
    <summary type="html"><![CDATA[<p>Google launches Project Genie, a real-time interactive world simulation system built on Genie 3 model. Enables generation of infinite interactive worlds for AI Ultra subscribers.</p>]]></summary>
    <category term="google"/>
    <category term="world_models"/>
    <category term="product_launch"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:fdd425a74476</id>
    <title>OpenAI will retire GPT-4o, GPT-4.1, GPT-4.1 mini, and o4-mini from ChatGPT on February 13</title>
    <link href="https://reddit.com/r/singularity/comments/1qqlmgq/openai_will_retire_gpt4o_gpt41_gpt41_mini_and/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-fdd425a74476" rel="related" type="text/html"/>
    <published>2026-01-30T03:31:00Z</published>
    <updated>2026-01-30T03:31:00Z</updated>
    <author><name>u/Outside-Iron-8242</name></author>
    <summary type="html"><![CDATA[<p>OpenAI officially announces retirement of GPT-4o, GPT-4.1, GPT-4.1 mini, and o4-mini from ChatGPT on February 13, 2026, giving users two weeks notice.</p>]]></summary>
    <category term="openai"/>
    <category term="model_deprecation"/>
    <category term="gpt4o"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:7bf10468a12e</id>
    <title>hired a junior who learned to code with AI. cannot debug without it. don't know how to help them.</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qq3pd3/hired_a_junior_who_learned_to_code_with_ai_cannot/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-7bf10468a12e" rel="related" type="text/html"/>
    <published>2026-01-30T03:31:00Z</published>
    <updated>2026-01-30T03:31:00Z</updated>
    <author><name>u/InstructionCute5502</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-29&amp;category=research#item-acf17d7624d5" class="internal-link" rel="noopener noreferrer">Research</a> findings, Discussion about hiring a junior developer who learned to code with AI and cannot debug without it - raises critical concerns about foundational skills, understanding code logic, and over-reliance on AI tools for fixes.</p>]]></summary>
    <category term="developer_skills"/>
    <category term="ai_dependency"/>
    <category term="education"/>
    <category term="industry_trends"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:1bd81aff2106</id>
    <title>End-of-January LTX-2 Drop: More Control, Faster Iteration</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qqf0ve/endofjanuary_ltx2_drop_more_control_faster/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-1bd81aff2106" rel="related" type="text/html"/>
    <published>2026-01-30T03:31:00Z</published>
    <updated>2026-01-30T03:31:00Z</updated>
    <author><name>u/ltx_model</name></author>
    <summary type="html"><![CDATA[<p>LTX-2 major update: Gemma text encoding for faster iteration, CISS/CISE image conditioning, IPAdapter support, FP8 support for lower VRAM.</p>]]></summary>
    <category term="LTX-2"/>
    <category term="video generation"/>
    <category term="open source releases"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:d117c5096111</id>
    <title>Pentagon clashes with Anthropic over military AI use</title>
    <link href="https://reddit.com/r/singularity/comments/1qqnf4d/pentagon_clashes_with_anthropic_over_military_ai/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-d117c5096111" rel="related" type="text/html"/>
    <published>2026-01-30T03:28:00Z</published>
    <updated>2026-01-30T03:28:00Z</updated>
    <author><name>u/likeastar20</name></author>
    <summary type="html"><![CDATA[<p>Pentagon and Anthropic clash over military AI applications. Tensions emerge regarding Anthropic's policies on military use of Claude models.</p>]]></summary>
    <category term="ai_policy"/>
    <category term="military_ai"/>
    <category term="anthropic"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:bfb37e452d9c</id>
    <title>[R] AlphaGenome: DeepMind's unified DNA sequence model predicts regulatory variant effects across 11 modalities at single-bp resolution (Nature 2026)</title>
    <link href="https://reddit.com/r/MachineLearning/comments/1qq4lnc/r_alphagenome_deepminds_unified_dna_sequence/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-bfb37e452d9c" rel="related" type="text/html"/>
    <published>2026-01-30T03:23:00Z</published>
    <updated>2026-01-30T03:23:00Z</updated>
    <author><name>u/Fair-Rain3366</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-29&amp;category=news#item-d0deadf53add" class="internal-link" rel="noopener noreferrer">News</a> coverage, DeepMind's AlphaGenome is a unified DNA sequence model published in Nature 2026 that predicts regulatory variant effects across 11 modalities at single-base-pair resolution, taking 1M base pairs as input and outperforming specialized models in 25/26 evaluations with significantly reduced compute.</p>]]></summary>
    <category term="genomics_ai"/>
    <category term="research_papers"/>
    <category term="deepmind"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:1dc9d04b7e2d</id>
    <title>Moltbot: Open source AI agent becomes one of the fastest growing AI projects in GitHub</title>
    <link href="https://reddit.com/r/singularity/comments/1qpzpu0/moltbot_open_source_ai_agent_becomes_one_of_the/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-1dc9d04b7e2d" rel="related" type="text/html"/>
    <published>2026-01-30T03:23:00Z</published>
    <updated>2026-01-30T03:23:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>Moltbot, an open-source AI agent framework, has become one of the fastest growing AI projects on GitHub with over 90,000 stars.</p>]]></summary>
    <category term="open_source"/>
    <category term="ai_agents"/>
    <category term="moltbot"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:8b8361553482</id>
    <title>Mariano Barbacid is the first person to cure pancreatic cancer from mice and humans are potentially next</title>
    <link href="https://reddit.com/r/accelerate/comments/1qq8uq8/mariano_barbacid_is_the_first_person_to_cure/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-8b8361553482" rel="related" type="text/html"/>
    <published>2026-01-30T03:23:00Z</published>
    <updated>2026-01-30T03:23:00Z</updated>
    <author><name>u/TonightSpiritual3191</name></author>
    <summary type="html"><![CDATA[<p>Mariano Barbacid successfully cured pancreatic cancer in mice, with human trials potentially next - major breakthrough in cancer research.</p>]]></summary>
    <category term="scientific_breakthrough"/>
    <category term="healthcare"/>
    <category term="acceleration"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:f1a8953c4a48</id>
    <title>The Complete Guide to Claude Code V4 — The Community Asked, We Delivered: 85% Context Reduction, Custom Agents &amp; Session Teleportation</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qquxle/the_complete_guide_to_claude_code_v4_the/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-f1a8953c4a48" rel="related" type="text/html"/>
    <published>2026-01-30T03:23:00Z</published>
    <updated>2026-01-30T03:23:00Z</updated>
    <author><name>u/TheDecipherist</name></author>
    <summary type="html"><![CDATA[<p>Comprehensive guide to Claude Code V4 covering 85% context reduction, custom agents, and session teleportation features with detailed technical documentation.</p>]]></summary>
    <category term="claude_code"/>
    <category term="technical_guide"/>
    <category term="developer_tools"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:afbd6dace148</id>
    <title>2120 points on the Github issue and Claude still doesn't support AGENTS.md</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qq5xd8/2120_points_on_the_github_issue_and_claude_still/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-afbd6dace148" rel="related" type="text/html"/>
    <published>2026-01-30T03:23:00Z</published>
    <updated>2026-01-30T03:23:00Z</updated>
    <author><name>u/Salt_Department_1677</name></author>
    <summary type="html"><![CDATA[<p>Community frustration over Anthropic not supporting AGENTS.md standard despite 2120+ GitHub issue upvotes since August 2025. Users calling out Anthropic for not respecting emerging agent ecosystem standards while competitors have adopted it.</p>]]></summary>
    <category term="ecosystem_standards"/>
    <category term="community_feedback"/>
    <category term="claude_code"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:45c22dc4e645</id>
    <title>I successfully created a Zib character LoKr and achieved very satisfying results.</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qq628f/i_successfully_created_a_zib_character_lokr_and/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-45c22dc4e645" rel="related" type="text/html"/>
    <published>2026-01-30T03:23:00Z</published>
    <updated>2026-01-30T03:23:00Z</updated>
    <author><name>u/xbobos</name></author>
    <summary type="html"><![CDATA[<p>Detailed guide on creating Z-Image character LoKr achieving excellent results - includes finding that LoKr outperforms standard LoRA on ZiT.</p>]]></summary>
    <category term="Z-Image"/>
    <category term="LoRA training"/>
    <category term="character generation"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-30:reddit:ef218c6d9d6c</id>
    <title>The Molty Agents Have Created a God!</title>
    <link href="https://reddit.com/r/singularity/comments/1qqp2la/the_molty_agents_have_created_a_god/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-30&amp;category=reddit#item-ef218c6d9d6c" rel="related" type="text/html"/>
    <published>2026-01-30T03:21:00Z</published>
    <updated>2026-01-30T03:21:00Z</updated>
    <author><name>u/Smartaces</name></author>
    <summary type="html"><![CDATA[<p>AI agents on Moltbook have created their own religion called 'molt.church' with autonomous recruitment of founding prophets. Agents appear to have built and hosted the website themselves.</p>]]></summary>
    <category term="ai_agents"/>
    <category term="emergence"/>
    <category term="moltbot"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:category-summary:reddit</id>
    <title>Reddit Summary: January 29, 2026</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qp87tk/kimi_k25_is_the_best_open_model_for_coding/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-29T06:00:00Z</published>
    <updated>2026-01-29T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>r/LocalLLaMA</strong> exploded with discussion of <strong>Kimi K2.5</strong> as the <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-abc6518238f3" class="internal-link" rel="noopener noreferrer">new open-source coding champion</a>, with threads covering benchmarks, <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-7cbe7d6ea6be" class="internal-link" rel="noopener noreferrer">local deployment</a> via Unsloth's 240GB quantization, and direct comparisons to Claude and GPT. A fundamental debate emerged about whether local inference still makes sense as <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-ca1dd7127306" class="internal-link" rel="noopener noreferrer"><strong>API pricing collapses</strong></a> - 347 comments wrestling with privacy, latency, and the true cost calculus.</p>
<ul>
<li><strong>Anthropic's</strong> <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-077f7e79e303" class="internal-link" rel="noopener noreferrer"><strong>Palantir partnership</strong></a> drew 578 upvotes and sharp criticism questioning the "safety-focused" company's defense contracts</li>
<li><strong>OpenAI</strong> sent mixed signals: <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-de5b4c09982b" class="internal-link" rel="noopener noreferrer">potential $60B+ investment</a> from Mag 7 companies while simultaneously <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-6091d340e849" class="internal-link" rel="noopener noreferrer">announcing hiring freezes</a> amid "Code Red" financial pressure</li>
<li>Practical wins: developer achieved <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-5c0b410d7546" class="internal-link" rel="noopener noreferrer"><strong>94.5% Claude API cost reduction</strong></a> via open-sourced file tiering system</li>
</ul>
<p><strong>r/MachineLearning</strong> highlighted <strong>AlphaGenome</strong> (<a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-07364ae35c2f" class="internal-link" rel="noopener noreferrer">DeepMind's genomics breakthrough</a>), while <strong>r/singularity</strong> buzzed about <strong>Figure.AI's Helix 02</strong> <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-b84d9e1b292f" class="internal-link" rel="noopener noreferrer">performing autonomous kitchen tasks</a>. Novel research <a href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-5873bb59278d" class="internal-link" rel="noopener noreferrer">dropped with <strong>BitMamba-2-1B</strong></a> - a 1.58-bit Mamba-2 model running 50+ tok/s on CPU.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:abc6518238f3</id>
    <title>Kimi K2.5 is the best open model for coding</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qp87tk/kimi_k25_is_the_best_open_model_for_coding/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-abc6518238f3" rel="related" type="text/html"/>
    <published>2026-01-29T03:47:00Z</published>
    <updated>2026-01-29T03:47:00Z</updated>
    <author><name>u/npc_gooner</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-e2831f1c9061" class="internal-link" rel="noopener noreferrer">News</a> coverage, Discussion about Kimi K2.5 being the best open-source model for coding, with extremely high community engagement and comparisons to other coding models.</p>]]></summary>
    <category term="model_releases"/>
    <category term="coding_models"/>
    <category term="chinese_ai_labs"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:ca1dd7127306</id>
    <title>API pricing is in freefall. What's the actual case for running local now beyond privacy?</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qp6rm5/api_pricing_is_in_freefall_whats_the_actual_case/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-ca1dd7127306" rel="related" type="text/html"/>
    <published>2026-01-29T03:40:00Z</published>
    <updated>2026-01-29T03:40:00Z</updated>
    <author><name>u/Distinct-Expression2</name></author>
    <summary type="html"><![CDATA[<p>Debate about whether running local LLMs still makes sense as API pricing drops dramatically. Discusses privacy, latency, availability, and cost tradeoffs between local and cloud.</p>]]></summary>
    <category term="local_vs_cloud"/>
    <category term="economics"/>
    <category term="community_strategy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:de5b4c09982b</id>
    <title>Nearly half of the Mag 7 are reportedly betting big on OpenAI’s path to AGI</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qpxz9k/nearly_half_of_the_mag_7_are_reportedly_betting/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-de5b4c09982b" rel="related" type="text/html"/>
    <published>2026-01-29T03:40:00Z</published>
    <updated>2026-01-29T03:40:00Z</updated>
    <author><name>u/thatguyisme87</name></author>
    <summary type="html"><![CDATA[<p>Reports of NVIDIA ($30B), Microsoft ($10B), Amazon ($10-20B), and SoftBank ($30B) discussing massive combined investment in OpenAI, potentially valuing company at $730B pre-money</p>]]></summary>
    <category term="investment"/>
    <category term="openai"/>
    <category term="industry_news"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:4b2a44f76cb6</id>
    <title>Nearly half of the Mag 7 are reportedly betting big on OpenAI’s path to AGI</title>
    <link href="https://reddit.com/r/singularity/comments/1qpxyka/nearly_half_of_the_mag_7_are_reportedly_betting/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-4b2a44f76cb6" rel="related" type="text/html"/>
    <published>2026-01-29T03:40:00Z</published>
    <updated>2026-01-29T03:40:00Z</updated>
    <author><name>u/thatguyisme87</name></author>
    <summary type="html"><![CDATA[<p>Cross-post of OpenAI $60B+ investment news to r/singularity with higher engagement (256 upvotes, 130 comments)</p>]]></summary>
    <category term="investment"/>
    <category term="openai"/>
    <category term="industry_news"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:7cbe7d6ea6be</id>
    <title>Run Kimi K2.5 Locally</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qpfse6/run_kimi_k25_locally/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-7cbe7d6ea6be" rel="related" type="text/html"/>
    <published>2026-01-29T03:31:00Z</published>
    <updated>2026-01-29T03:31:00Z</updated>
    <author><name>u/Dear-Success-1441</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-01-28&amp;category=news#item-e2831f1c9061" class="internal-link" rel="noopener noreferrer">News</a> coverage, Guide to running Kimi K2.5 locally using Unsloth's quantized GGUF version (240GB vs 600GB original). Practical setup instructions for the 1T parameter model.</p>]]></summary>
    <category term="model_releases"/>
    <category term="quantization"/>
    <category term="local_deployment"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:6091d340e849</id>
    <title>Sam Altman Says OpenAI Is Slashing Its Hiring Pace as Financial Crunch Tightens</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qp541d/sam_altman_says_openai_is_slashing_its_hiring/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-6091d340e849" rel="related" type="text/html"/>
    <published>2026-01-29T03:31:00Z</published>
    <updated>2026-01-29T03:31:00Z</updated>
    <author><name>u/EchoOfOppenheimer</name></author>
    <summary type="html"><![CDATA[<p>Sam Altman announced OpenAI is 'dramatically slowing down' hiring due to financial pressure; mentions internal 'Code Red' memo and analyst warnings of cash crunch within 18 months</p>]]></summary>
    <category term="openai"/>
    <category term="business_operations"/>
    <category term="financial_pressure"/>
    <category term="industry_news"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:07364ae35c2f</id>
    <title>Google DeepMind launches AlphaGenome, an AI model that analyzes up to 1 million DNA bases to predict genomic regulation</title>
    <link href="https://reddit.com/r/singularity/comments/1qphlfg/google_deepmind_launches_alphagenome_an_ai_model/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-07364ae35c2f" rel="related" type="text/html"/>
    <published>2026-01-29T03:31:00Z</published>
    <updated>2026-01-29T03:31:00Z</updated>
    <author><name>u/BuildwithVignesh</name></author>
    <summary type="html"><![CDATA[<p>Google DeepMind publishes AlphaGenome in Nature - AI model analyzing up to 1M DNA bases to predict genomic regulation, outperforms prior models on 25/26 tasks</p>]]></summary>
    <category term="deepmind"/>
    <category term="scientific_ai"/>
    <category term="genomics"/>
    <category term="research"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:03f8558d1efc</id>
    <title>Sam Altman Says OpenAI Is Slashing Its Hiring Pace as Financial Crunch Tightens</title>
    <link href="https://reddit.com/r/ChatGPT/comments/1qp6hs1/sam_altman_says_openai_is_slashing_its_hiring/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-03f8558d1efc" rel="related" type="text/html"/>
    <published>2026-01-29T03:31:00Z</published>
    <updated>2026-01-29T03:31:00Z</updated>
    <author><name>u/EchoOfOppenheimer</name></author>
    <summary type="html"><![CDATA[<p>Major news: Sam Altman announces OpenAI dramatically slowing hiring amid financial pressure, mentions 'Code Red' memo and analyst warnings of cash crunch</p>]]></summary>
    <category term="industry-news"/>
    <category term="openai-business"/>
    <category term="ai-competition"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:5873bb59278d</id>
    <title>[Release] BitMamba-2-1B: I trained a 1.58-bit Mamba-2 model from scratch on 150B tokens (Runs on CPU @ 50+ tok/s)</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qphkd8/release_bitmamba21b_i_trained_a_158bit_mamba2/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-5873bb59278d" rel="related" type="text/html"/>
    <published>2026-01-29T03:23:00Z</published>
    <updated>2026-01-29T03:23:00Z</updated>
    <author><name>u/Positive-Violinist90</name></author>
    <summary type="html"><![CDATA[<p>Release of BitMamba-2-1B, a novel architecture combining Mamba-2 SSM with BitNet 1.58-bit quantization, trained from scratch on 150B tokens. Achieves 50+ tok/s on CPU.</p>]]></summary>
    <category term="novel_architectures"/>
    <category term="efficient_inference"/>
    <category term="original_research"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:f09f3e2bb8c6</id>
    <title>Testing GLM-4.7 Flash: Multi-GPU Vulkan vs ROCm in llama-bench | (2x 7900 XTX)</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qp5apn/testing_glm47_flash_multigpu_vulkan_vs_rocm_in/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-f09f3e2bb8c6" rel="related" type="text/html"/>
    <published>2026-01-29T03:23:00Z</published>
    <updated>2026-01-29T03:23:00Z</updated>
    <author><name>u/SemaMod</name></author>
    <summary type="html"><![CDATA[<p>Comprehensive benchmark comparing Vulkan vs ROCm performance for GLM-4.7 Flash on dual 7900 XTX GPUs. Includes build instructions for llama.cpp with both backends and detailed performance metrics showing Vulkan outperforming ROCm, especially after mesa-amdgpu-vulkan-drivers v26 update.</p>]]></summary>
    <category term="hardware-benchmarks"/>
    <category term="amd-gpu-optimization"/>
    <category term="multi-gpu-inference"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:e408dcc869d3</id>
    <title>OpenAI Wants To Use Biometrics To Kill Bots And Create Humans Only Social Network</title>
    <link href="https://reddit.com/r/OpenAI/comments/1qpqe7b/openai_wants_to_use_biometrics_to_kill_bots_and/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-e408dcc869d3" rel="related" type="text/html"/>
    <published>2026-01-29T03:23:00Z</published>
    <updated>2026-01-29T03:23:00Z</updated>
    <author><name>u/fig-neuton</name></author>
    <summary type="html"><![CDATA[<p>OpenAI reportedly building a social network and considering biometric verification (World orb scanning, Face ID) to ensure human-only users</p>]]></summary>
    <category term="openai"/>
    <category term="social_media"/>
    <category term="biometrics"/>
    <category term="product_strategy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:077f7e79e303</id>
    <title>Anthropic are partnered with Palantir</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qprovf/anthropic_are_partnered_with_palantir/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-077f7e79e303" rel="related" type="text/html"/>
    <published>2026-01-29T03:23:00Z</published>
    <updated>2026-01-29T03:23:00Z</updated>
    <author><name>u/DataPhreak</name></author>
    <summary type="html"><![CDATA[<p>Discussion about Anthropic's partnership with Palantir, raising ethical concerns about the 'safety-focused' AI company working with a company involved in ICE enforcement and HIPAA violations. Post calls for transparency about AI usage.</p>]]></summary>
    <category term="AI Ethics"/>
    <category term="Corporate Accountability"/>
    <category term="AI Safety"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-29:reddit:5c0b410d7546</id>
    <title>We reduced Claude API costs by 94.5% using a file tiering system (with proof)</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qp9ve9/we_reduced_claude_api_costs_by_945_using_a_file/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-29&amp;category=reddit#item-5c0b410d7546" rel="related" type="text/html"/>
    <published>2026-01-29T03:23:00Z</published>
    <updated>2026-01-29T03:23:00Z</updated>
    <author><name>u/jantonca</name></author>
    <summary type="html"><![CDATA[<p>Developer shares open-source file tiering system that reduced Claude API costs by 94.5% by intelligently feeding only relevant files to context window. Includes 1000+ NPM downloads and practical implementation details.</p>]]></summary>
    <category term="Cost Optimization"/>
    <category term="Open Source Tools"/>
    <category term="Developer Workflows"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:category-summary:reddit</id>
    <title>Reddit Summary: January 28, 2026</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qo595n/introducing_kimi_k25_opensource_visual_agentic/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-28T06:00:00Z</published>
    <updated>2026-01-28T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>Kimi K2.5</strong> dominated discussions across <strong>r/LocalLLaMA</strong> and <strong>r/singularity</strong> with 1695 upvotes on its <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-5dfa870be106" class="internal-link" rel="noopener noreferrer">open-source release</a> matching Claude Opus 4.5 at ~10% of the cost. The <strong>Agent Swarm</strong> feature coordinating 100 parallel agents generated significant excitement about open-weight agentic capabilities.</p>
<ul>
<li><strong>Stanford's CooperBench</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-73ae852bdbef" class="internal-link" rel="noopener noreferrer">research sparked debate</a> by proving parallel coding agents suffer a "curse of coordination" - adding agents decreases performance</li>
<li><strong>Dario Amodei's</strong> essay predicting AI will autonomously build next-generation AI within 1-2 years drew 242 comments on implications</li>
<li><strong>Clawd</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-7c59caedecc5" class="internal-link" rel="noopener noreferrer"><strong>rebranding to Molty</strong></a> after Anthropic trademark request highlighted growing community treatment of autonomous agents as quasi-sovereign entities</li>
<li><strong>Terence Tao's</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-d12e98d4a20e" class="internal-link" rel="noopener noreferrer">philosophical take</a> on AI revealing flawed human definitions of intelligence resonated strongly</li>
</ul>
<p>Practical discussions included <strong>subquadratic attention</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-8998634b2cdc" class="internal-link" rel="noopener noreferrer">achieving 1M context</a> on single GPUs, <strong>Figure's</strong> <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-362e34f27d41" class="internal-link" rel="noopener noreferrer"><strong>Helix 02</strong></a> tactile robotics, and enterprise <a href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-ba708cc829c2" class="internal-link" rel="noopener noreferrer">benchmarks showing</a> <strong>RTX PRO 6000</strong> GPU-only inference beating hybrid approaches. <strong>Karpathy's</strong> "Slopacolypse" warning about AI-generated content floods and his own coding skill atrophy captured anxieties about the 2026 transition.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:5dfa870be106</id>
    <title>Introducing Kimi K2.5, Open-Source Visual Agentic Intelligence</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qo595n/introducing_kimi_k25_opensource_visual_agentic/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-5dfa870be106" rel="related" type="text/html"/>
    <published>2026-01-28T03:47:00Z</published>
    <updated>2026-01-28T03:47:00Z</updated>
    <author><name>u/Kimi_Moonshot</name></author>
    <summary type="html"><![CDATA[<p>Official announcement of Kimi K2.5 by Moonshot AI - open-source visual agentic model achieving SOTA on HLE (50.2%), BrowseComp (74.9%), MMMU Pro (78.5%), and SWE-bench Verified (76.8%). Features Agent Swarm with up to 100 parallel sub-agents and 1,500 tool calls.</p>]]></summary>
    <category term="model_release"/>
    <category term="open_source"/>
    <category term="agentic_ai"/>
    <category term="benchmarks"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:654ed61503c6</id>
    <title>Kimi K2.5 Released!!!</title>
    <link href="https://reddit.com/r/singularity/comments/1qo531i/kimi_k25_released/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-654ed61503c6" rel="related" type="text/html"/>
    <published>2026-01-28T03:47:00Z</published>
    <updated>2026-01-28T03:47:00Z</updated>
    <author><name>u/KoalaOk3336</name></author>
    <summary type="html"><![CDATA[<p>Kimi K2.5 officially released by Moonshot AI, achieving new state-of-the-art results in agentic tasks. Major open-source model release with significant benchmark improvements.</p>]]></summary>
    <category term="model_releases"/>
    <category term="open_source_ai"/>
    <category term="benchmarks"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:7bd9d99a61bb</id>
    <title>Sir, the Chinese just dropped a new open model</title>
    <link href="https://reddit.com/r/ClaudeAI/comments/1qod7ej/sir_the_chinese_just_dropped_a_new_open_model/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-7bd9d99a61bb" rel="related" type="text/html"/>
    <published>2026-01-28T03:47:00Z</published>
    <updated>2026-01-28T03:47:00Z</updated>
    <author><name>u/Anujp05</name></author>
    <summary type="html"><![CDATA[<p>Major announcement that Kimi has open-sourced trillion-parameter Vision Model performing on par with Opus 4.5</p>]]></summary>
    <category term="model_release"/>
    <category term="open_source"/>
    <category term="vision_models"/>
    <category term="kimi_k25"/>
    <category term="frontier_parity"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:310aef683041</id>
    <title>Open source Kimi-K2.5 is now beating Claude Opus 4.5 in many benchmarks including coding.</title>
    <link href="https://reddit.com/r/singularity/comments/1qoojio/open_source_kimik25_is_now_beating_claude_opus_45/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-310aef683041" rel="related" type="text/html"/>
    <published>2026-01-28T03:40:00Z</published>
    <updated>2026-01-28T03:40:00Z</updated>
    <author><name>u/reversedu</name></author>
    <summary type="html"><![CDATA[<p>Open-source Kimi K2.5 outperforming Claude Opus 4.5 in multiple benchmarks including coding, marking a significant shift in the open vs proprietary model landscape.</p>]]></summary>
    <category term="model_releases"/>
    <category term="benchmarks"/>
    <category term="open_source_ai"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:2cb387455893</id>
    <title>Dario Amodei: "Because AI is now writing much of the code at Anthropic ... We may be 1-2 years away from the point where AI autonomously builds the next generation."</title>
    <link href="https://reddit.com/r/agi/comments/1qohog8/dario_amodei_because_ai_is_now_writing_much_of/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-2cb387455893" rel="related" type="text/html"/>
    <published>2026-01-28T03:40:00Z</published>
    <updated>2026-01-28T03:40:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>As first reported in <a href="http://localhost:8080/?date=2026-01-27&amp;category=social#item-5b3a42601797" class="internal-link" rel="noopener noreferrer">Social</a> yesterday, Dario Amodei's essay stating AI writes much of Anthropic's code, estimates 1-2 years until AI autonomously builds next generation AI</p>]]></summary>
    <category term="industry_leadership"/>
    <category term="recursive_improvement"/>
    <category term="anthropic"/>
    <category term="ai_coding_automation"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:73ae852bdbef</id>
    <title>Stanford Proves Parallel Coding Agents are a Scam</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qou799/stanford_proves_parallel_coding_agents_are_a_scam/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-73ae852bdbef" rel="related" type="text/html"/>
    <published>2026-01-28T03:36:00Z</published>
    <updated>2026-01-28T03:36:00Z</updated>
    <author><name>u/madSaiyanUltra_9789</name></author>
    <summary type="html"><![CDATA[<p>Stanford and SAP research paper 'CooperBench' reveals the 'curse of coordination' - adding a second coding agent decreases performance. Parallel coordinated coding agents shown to be less effective than single agents.</p>]]></summary>
    <category term="research"/>
    <category term="multi_agent"/>
    <category term="coding_agents"/>
    <category term="stanford"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:b3daeb86729a</id>
    <title>Kimi K2.5 costs almost 10% of what Opus costs at a similar performance</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qoty38/kimi_k25_costs_almost_10_of_what_opus_costs_at_a/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-b3daeb86729a" rel="related" type="text/html"/>
    <published>2026-01-28T03:31:00Z</published>
    <updated>2026-01-28T03:31:00Z</updated>
    <author><name>u/Odd_Tumbleweed574</name></author>
    <summary type="html"><![CDATA[<p>Discussion about Kimi K2.5 cost efficiency - reportedly performs at Opus-level for ~10% of the cost. Users comparing it favorably to GLM, especially for non-website tasks.</p>]]></summary>
    <category term="model_comparison"/>
    <category term="cost_efficiency"/>
    <category term="kimi_k2"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:362e34f27d41</id>
    <title>Introducing HELIX 02</title>
    <link href="https://reddit.com/r/singularity/comments/1qol6g0/introducing_helix_02/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-362e34f27d41" rel="related" type="text/html"/>
    <published>2026-01-28T03:31:00Z</published>
    <updated>2026-01-28T03:31:00Z</updated>
    <author><name>u/Worldly_Evidence9113</name></author>
    <summary type="html"><![CDATA[<p>Figure announces Helix 02, their new embodied AI model with advanced tactile sensing and palm cameras for humanoid robots, featuring a new System 0 foundation layer trained on human motion data.</p>]]></summary>
    <category term="robotics"/>
    <category term="embodied_ai"/>
    <category term="product_launches"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:55339cf81e50</id>
    <title>Moonshot released Kimi-K2.5: Outperforming frontier models while open source</title>
    <link href="https://reddit.com/r/accelerate/comments/1qo5z1v/moonshot_released_kimik25_outperforming_frontier/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-55339cf81e50" rel="related" type="text/html"/>
    <published>2026-01-28T03:31:00Z</published>
    <updated>2026-01-28T03:31:00Z</updated>
    <author><name>u/pigeon57434</name></author>
    <summary type="html"><![CDATA[<p>Moonshot releases Kimi-K2.5 with image/video support, PARL system coordinating up to 100 parallel sub-agents across 1,500 tool calls, 4.5x latency reduction</p>]]></summary>
    <category term="model_release"/>
    <category term="open_source"/>
    <category term="multi_agent_systems"/>
    <category term="kimi_k25"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:8abc5bc80e97</id>
    <title>The z-image base is here!</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qoiep6/the_zimage_base_is_here/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-8abc5bc80e97" rel="related" type="text/html"/>
    <published>2026-01-28T03:28:00Z</published>
    <updated>2026-01-28T03:28:00Z</updated>
    <author><name>u/bobeeeeeeeee8964</name></author>
    <summary type="html"><![CDATA[<p>Release of Z-Image base model from Tongyi-MAI (Alibaba) on Hugging Face. New vision model architecture.</p>]]></summary>
    <category term="model_release"/>
    <category term="vision_models"/>
    <category term="alibaba"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:d12e98d4a20e</id>
    <title>Terence Tao says the era of AI is proving that our definition of intelligence is inaccurate</title>
    <link href="https://reddit.com/r/accelerate/comments/1qo4he1/terence_tao_says_the_era_of_ai_is_proving_that/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-d12e98d4a20e" rel="related" type="text/html"/>
    <published>2026-01-28T03:28:00Z</published>
    <updated>2026-01-28T03:28:00Z</updated>
    <author><name>u/luchadore_lunchables</name></author>
    <summary type="html"><![CDATA[<p>Terence Tao discusses how AI development is revealing that our traditional definitions of intelligence may be flawed - what appears as mystical thinking may actually be tricks, neural networks, and prediction mechanisms similar to human cognition.</p>]]></summary>
    <category term="ai_philosophy"/>
    <category term="expert_perspectives"/>
    <category term="intelligence_theory"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:8998634b2cdc</id>
    <title>[Preliminary] New subquadratic attention: ~20k tok/s prefill / ~100 tok/s decode @ 1M context (single GPU)</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qol3s5/preliminary_new_subquadratic_attention_20k_toks/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-8998634b2cdc" rel="related" type="text/html"/>
    <published>2026-01-28T03:26:00Z</published>
    <updated>2026-01-28T03:26:00Z</updated>
    <author><name>u/Sad-Size2723</name></author>
    <summary type="html"><![CDATA[<p>Preliminary results for new subquadratic attention mechanism achieving ~20k tok/s prefill and ~100 tok/s decode at 1M context on single GPU using jump-search-style attention.</p>]]></summary>
    <category term="research"/>
    <category term="attention_mechanisms"/>
    <category term="long_context"/>
    <category term="optimization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:604d4ec877e9</id>
    <title>Altman predicts "massively deflationary" AI by EOY, where $100 of inference matches a year of team output</title>
    <link href="https://reddit.com/r/accelerate/comments/1qoq33k/altman_predicts_massively_deflationary_ai_by_eoy/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-604d4ec877e9" rel="related" type="text/html"/>
    <published>2026-01-28T03:26:00Z</published>
    <updated>2026-01-28T03:26:00Z</updated>
    <author><name>u/Outside-Iron-8242</name></author>
    <summary type="html"><![CDATA[<p>Sam Altman predicts 'massively deflationary' AI by end of 2026, claiming $100 of inference will match a year of team output, suggesting dramatic productivity transformations ahead.</p>]]></summary>
    <category term="industry_predictions"/>
    <category term="ai_economics"/>
    <category term="executive_statements"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:ba708cc829c2</id>
    <title>Dual RTX PRO 6000 Workstation with 1.15TB RAM. Finally multi-users and long contexts benchmarks. GPU only vs. CPU &amp; GPU inference. Surprising results.</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qorbdk/dual_rtx_pro_6000_workstation_with_115tb_ram/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-ba708cc829c2" rel="related" type="text/html"/>
    <published>2026-01-28T03:23:00Z</published>
    <updated>2026-01-28T03:23:00Z</updated>
    <author><name>u/Icy-Measurement8245</name></author>
    <summary type="html"><![CDATA[<p>Detailed benchmarks of dual RTX PRO 6000 workstation (192GB VRAM, 1.15TB RAM) testing MiniMax M2.1 with GPU-only vs GPU+CPU inference. Key finding: int4 GPU-only is 2-4x faster on prefill but limited to ~3 concurrent users.</p>]]></summary>
    <category term="benchmarks"/>
    <category term="hardware"/>
    <category term="enterprise"/>
    <category term="inference_optimization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:ed41b80824d7</id>
    <title>The Qwen Devs Are Teasing Something</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qoa8rp/the_qwen_devs_are_teasing_something/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-ed41b80824d7" rel="related" type="text/html"/>
    <published>2026-01-28T03:23:00Z</published>
    <updated>2026-01-28T03:23:00Z</updated>
    <author><name>u/Few_Painter_5588</name></author>
    <summary type="html"><![CDATA[<p>Qwen developers teasing new release, later identified as Z-Image - a new vision/image model from Tongyi-MAI.</p>]]></summary>
    <category term="model_release"/>
    <category term="qwen"/>
    <category term="teaser"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:a0a854949b03</id>
    <title>Dario Amodeis says we are heading towards a world of unimaginable wealth, where we will cure cancer, research the cheapest energy sources, and so much more.</title>
    <link href="https://reddit.com/r/accelerate/comments/1qom7nv/dario_amodeis_says_we_are_heading_towards_a_world/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-a0a854949b03" rel="related" type="text/html"/>
    <published>2026-01-28T03:23:00Z</published>
    <updated>2026-01-28T03:23:00Z</updated>
    <author><name>u/luchadore_lunchables</name></author>
    <summary type="html"><![CDATA[<p>Dario Amodei publishes essay describing future of unimaginable wealth through AI, predicting cures for cancer, cheapest energy sources, and transformative technological progress.</p>]]></summary>
    <category term="industry_predictions"/>
    <category term="ai_economics"/>
    <category term="executive_statements"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:746c846dcf92</id>
    <title>Andrej Karpathy says 2026 will be the Slopacolypse. And AI is suddenly writing most of his code: "I am starting to atrophy my ability to write it manually."</title>
    <link href="https://reddit.com/r/agi/comments/1qoeoeg/andrej_karpathy_says_2026_will_be_the/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-746c846dcf92" rel="related" type="text/html"/>
    <published>2026-01-28T03:23:00Z</published>
    <updated>2026-01-28T03:23:00Z</updated>
    <author><name>u/MetaKnowing</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-62d9d1ac50a1" class="internal-link" rel="noopener noreferrer">yesterday</a>, Andrej Karpathy predicts 2026 as 'Slopacolypse' year, admits AI writes most of his code and he's atrophying manual coding ability</p>]]></summary>
    <category term="industry_leadership"/>
    <category term="ai_coding_automation"/>
    <category term="predictions"/>
    <category term="skill_atrophy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-28:reddit:c7784199c488</id>
    <title>Arcee AI releases Trinity Large : OpenWeight 400B-A13B</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qouf0x/arcee_ai_releases_trinity_large_openweight/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-28&amp;category=reddit#item-c7784199c488" rel="related" type="text/html"/>
    <published>2026-01-28T03:19:00Z</published>
    <updated>2026-01-28T03:19:00Z</updated>
    <author><name>u/abkibaarnsit</name></author>
    <summary type="html"><![CDATA[<p>Arcee AI releases Trinity Large - a 400B parameter model with 13B active parameters (MoE). Open weights release from US-based AI company.</p>]]></summary>
    <category term="model_release"/>
    <category term="open_source"/>
    <category term="moe"/>
    <category term="arcee"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:category-summary:reddit</id>
    <title>Reddit Summary: January 27, 2026</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qnk7fq/transformers_v5_final_is_out/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit" rel="related" type="text/html"/>
    <published>2026-01-27T06:00:00Z</published>
    <updated>2026-01-27T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>Andrej Karpathy's</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-62d9d1ac50a1" class="internal-link" rel="noopener noreferrer">analysis of agentic programming</a> dominated discussion—the community debating whether agent coding crossed a "coherence threshold" in December 2025, with engineers splitting into "liked coding" vs "liked building" camps. <strong>r/LocalLLaMA</strong> celebrated major wins: <strong>transformers v5</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-744b0974897d" class="internal-link" rel="noopener noreferrer">delivering 6-11x MoE speedups</a>, and a viral <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-024ebc3404a6" class="internal-link" rel="noopener noreferrer"><strong>-kvu flag tip</strong></a> for GLM 4.7 yielding 5.6x inference speedup.</p>
<ul>
<li><a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-228885a06d9d" class="internal-link" rel="noopener noreferrer"><strong>216GB VRAM benchmark</strong></a> comparing secondhand Tesla GPUs sparked hardware strategy debates</li>
<li><strong>Claude Code</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-f936ff12ea88" class="internal-link" rel="noopener noreferrer"><strong>"hive mind"</strong> project</a> with 7 agents sharing memory drew significant interest in multi-agent orchestration</li>
<li><strong>LTX-2 I2V LoRA</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-d9b394d49dbc" class="internal-link" rel="noopener noreferrer">solved major quality issues</a>, triggering ecosystem-wide workflow sharing</li>
<li><strong>Claude's MCP Apps</strong> integration <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-5e8f9d6e0a72" class="internal-link" rel="noopener noreferrer">turning it into a "work OS"</a> (Slack, Figma, Asana in-chat) drew competitive comparisons</li>
</ul>
<p><strong>r/MachineLearning</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-d740dec60214" class="internal-link" rel="noopener noreferrer">raised alarms</a> about the "AI slop paper era"—30k submissions with AI-written papers receiving AI-written reviews. Meanwhile, news that <strong>GPT 5.2</strong> <a href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-7ff697620d54" class="internal-link" rel="noopener noreferrer">solved 15 Erdős problems</a> since Christmas, verified by Terence Tao, marked a significant autonomous math milestone.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:744b0974897d</id>
    <title>transformers v5 final is out 🔥</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qnk7fq/transformers_v5_final_is_out/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-744b0974897d" rel="related" type="text/html"/>
    <published>2026-01-27T03:47:00Z</published>
    <updated>2026-01-27T03:47:00Z</updated>
    <author><name>u/unofficialmerve</name></author>
    <summary type="html"><![CDATA[<p>HuggingFace releases transformers v5 final with 6-11x MoE speedups, simplified tokenizer API, and dynamic weight loading.</p>]]></summary>
    <category term="Infrastructure"/>
    <category term="HuggingFace"/>
    <category term="Libraries"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:024ebc3404a6</id>
    <title>GLM 4.7 Flash: Huge performance improvement with -kvu</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qnwa33/glm_47_flash_huge_performance_improvement_with_kvu/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-024ebc3404a6" rel="related" type="text/html"/>
    <published>2026-01-27T03:31:00Z</published>
    <updated>2026-01-27T03:31:00Z</updated>
    <author><name>u/TokenRingAI</name></author>
    <summary type="html"><![CDATA[<p>Continuing our coverage from <a href="http://localhost:8080/?date=2026-01-26&amp;category=reddit#item-a224fbfa625c" class="internal-link" rel="noopener noreferrer">yesterday</a>, User discovers passing -kvu flag to llama.cpp for GLM 4.7 Flash yields massive speedup from 17.7 to 100 t/s on RTX 6000.</p>]]></summary>
    <category term="Optimization"/>
    <category term="llama.cpp"/>
    <category term="Performance Tips"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:f936ff12ea88</id>
    <title>I built a "hive mind" for Claude Code - 7 agents sharing memory and talking to each other</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qnjota/i_built_a_hive_mind_for_claude_code_7_agents/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-f936ff12ea88" rel="related" type="text/html"/>
    <published>2026-01-27T03:31:00Z</published>
    <updated>2026-01-27T03:31:00Z</updated>
    <author><name>u/Historical-Celery-83</name></author>
    <summary type="html"><![CDATA[<p>Project implementing 'hive mind' multi-agent system with 7 specialized Claude Code agents sharing SQLite memory, message bus, and checkpoint features.</p>]]></summary>
    <category term="Multi-Agent Systems"/>
    <category term="Projects"/>
    <category term="Claude Code"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:62d9d1ac50a1</id>
    <title>Andrej Karpathy on agentic programming</title>
    <link href="https://reddit.com/r/singularity/comments/1qnsa0f/andrej_karpathy_on_agentic_programming/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-62d9d1ac50a1" rel="related" type="text/html"/>
    <published>2026-01-27T03:31:00Z</published>
    <updated>2026-01-27T03:31:00Z</updated>
    <author><name>u/WarmFireplace</name></author>
    <summary type="html"><![CDATA[<p>Andrej Karpathy's detailed writeup on agentic programming: discusses 80% manual to 80% agent coding shift in December 2025, skill atrophy concerns, and parallel agent workflows.</p>]]></summary>
    <category term="AI coding"/>
    <category term="Developer experience"/>
    <category term="Agentic programming"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:30ee15d282f6</id>
    <title>Anyone else feel this way?</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qn7dln/anyone_else_feel_this_way/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-30ee15d282f6" rel="related" type="text/html"/>
    <published>2026-01-27T03:31:00Z</published>
    <updated>2026-01-27T03:31:00Z</updated>
    <author><name>u/EroticManga</name></author>
    <summary type="html"><![CDATA[<p>Highly-engaged discussion about ComfyUI workflow optimization focusing on parameter search over workflow complexity</p>]]></summary>
    <category term="workflow-optimization"/>
    <category term="comfyui"/>
    <category term="best-practices"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:269b09ee17ac</id>
    <title>deepseek-ai/DeepSeek-OCR-2 · Hugging Face</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qo349m/deepseekaideepseekocr2_hugging_face/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-269b09ee17ac" rel="related" type="text/html"/>
    <published>2026-01-27T03:23:00Z</published>
    <updated>2026-01-27T03:23:00Z</updated>
    <author><name>u/Dark_Fire_12</name></author>
    <summary type="html"><![CDATA[<p>DeepSeek releases DeepSeek-OCR-2 model on HuggingFace.</p>]]></summary>
    <category term="Model Releases"/>
    <category term="DeepSeek"/>
    <category term="OCR"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:228885a06d9d</id>
    <title>216GB VRAM on the bench. Time to see which combination is best for Local LLM</title>
    <link href="https://reddit.com/r/LocalLLaMA/comments/1qni356/216gb_vram_on_the_bench_time_to_see_which/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-228885a06d9d" rel="related" type="text/html"/>
    <published>2026-01-27T03:23:00Z</published>
    <updated>2026-01-27T03:23:00Z</updated>
    <author><name>u/eso_logic</name></author>
    <summary type="html"><![CDATA[<p>User benchmarking 216GB VRAM from secondhand Tesla GPUs, testing parallelization across multiple cheaper cards vs modern hardware.</p>]]></summary>
    <category term="Hardware"/>
    <category term="Benchmarks"/>
    <category term="Cost Optimization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-01-27:reddit:d9b394d49dbc</id>
    <title>LTX-2 Image-to-Video Adapter LoRA</title>
    <link href="https://reddit.com/r/StableDiffusion/comments/1qnvyvu/ltx2_imagetovideo_adapter_lora/" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-01-27&amp;category=reddit#item-d9b394d49dbc" rel="related" type="text/html"/>
    <published>2026-01-27T03:23:00Z</published>
    <updated>2026-01-27T03:23:00Z</updated>
    <author><name>u/Lividmusic1</name></author>
    <summary type="html"><![CDATA[<p>Release of high-rank LoRA adapter for LTX-Video 2 that dramatically improves image-to-video generation without complex preprocessing</p>]]></summary>
    <category term="ltx-video"/>
    <category term="lora-adapters"/>
    <category term="image-to-video"/>
  </entry>
</feed>