<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
  <title>AATF AI News Aggregator - Social (Top 100)</title>
  <subtitle>Social items from AI News Aggregator</subtitle>
  <link href="http://localhost:8080/?category=social" rel="alternate" type="text/html"/>
  <link href="http://localhost:8080/data/feeds/social-100.xml" rel="self" type="application/atom+xml"/>
  <id>urn:ainews:social:100</id>
  <updated>2026-02-13T07:46:54Z</updated>
  <icon>http://localhost:8080/assets/logo.webp</icon>
  <author>
    <name>AATF AI News Aggregator</name>
    <uri>http://localhost:8080</uri>
  </author>
  <generator>AATF AI News Aggregator</generator>

  <entry>
    <id>urn:ainews:2026-02-13:category-summary:social</id>
    <title>Social Summary: February 13, 2026</title>
    <link href="https://twitter.com/AnthropicAI/status/2022023155423002867" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social" rel="related" type="text/html"/>
    <published>2026-02-13T06:00:00Z</published>
    <updated>2026-02-13T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p>A landmark day dominated by <strong>Anthropic's</strong> <a href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-c7aced803a36" class="internal-link" rel="noopener noreferrer">$30B raise</a> at a $380B valuation and simultaneous reveal of <a href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-aa4cfef9fbee" class="internal-link" rel="noopener noreferrer">$14B run-rate revenue</a> with 10x annual growth. An <strong>Anthropic</strong> engineer attributed much of the fundraise momentum to <a href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-8a182bfac352" class="internal-link" rel="noopener noreferrer"><strong>Claude Code</strong></a>, whose weekly active users doubled since January.</p>
<ul>
<li><strong>Sam Altman</strong> <a href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-b374f120dd88" class="internal-link" rel="noopener noreferrer">launched <strong>GPT-5.3-Codex-Spark</strong></a> as a research preview, touting 1000+ tokens/sec via a new <strong>Cerebras</strong> hardware partnership</li>
<li><strong>Demis Hassabis</strong> and <strong>Noam Shazeer</strong> announced a major <a href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-d56a25f6fd30" class="internal-link" rel="noopener noreferrer"><strong>Gemini 3 Deep Think</strong> upgrade</a> achieving SOTA on ARC-AGI-2 (84.6%), 3455 Codeforces Elo, and gold-medal Physics/Chemistry Olympiad performance â€” independently certified by <strong>FranÃ§ois Chollet</strong></li>
<li><strong>Google</strong> also unveiled <strong>Aletheia</strong>, a math research agent powered by Deep Think that solved multiple open <strong>ErdÅ‘s</strong> problems</li>
</ul>
<p>On the ideas front, <strong>John Carmack</strong> <a href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-ed513961e086" class="internal-link" rel="noopener noreferrer">argued AI will shift economic value</a> from raw intelligence to agency, empowering a new class of high-agency individuals. <strong>Andrej Karpathy</strong> highlighted <a href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-9db35d5d5745" class="internal-link" rel="noopener noreferrer"><strong>Simile AI's</strong> novel approach</a> of using LLMs as population simulators rather than single-personality chatbots. <strong>Chollet</strong> <a href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-95bca28ce670" class="internal-link" rel="noopener noreferrer">provided a definitive historical account</a> of the ARC benchmarks, pushing back on narratives that they were designed as anti-LLM tests.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:c7aced803a36</id>
    <title>Weâ€™ve raised $30B in funding at a $380B post-money valuation.

This investment will help us deepen o...</title>
    <link href="https://twitter.com/AnthropicAI/status/2022023155423002867" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-c7aced803a36" rel="related" type="text/html"/>
    <published>2026-02-13T03:47:00Z</published>
    <updated>2026-02-13T03:47:00Z</updated>
    <author><name>@AnthropicAI</name></author>
    <summary type="html"><![CDATA[<p>Anthropic announces $30B fundraise at $380B post-money valuation to deepen research, innovate products, and expand infrastructure.</p>]]></summary>
    <category term="Anthropic Business"/>
    <category term="AI Funding"/>
    <category term="AI Industry"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:b374f120dd88</id>
    <title>GPT-5.3-Codex-Spark is launching today as a research preview for Pro.

More than 1000 tokens per sec...</title>
    <link href="https://twitter.com/sama/status/2022011797524582726" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-b374f120dd88" rel="related" type="text/html"/>
    <published>2026-02-13T03:43:00Z</published>
    <updated>2026-02-13T03:43:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>Sam Altman announces GPT-5.3-Codex-Spark launching as research preview for Pro users, achieving over 1000 tokens per second.</p>]]></summary>
    <category term="product-launch"/>
    <category term="openai"/>
    <category term="codex"/>
    <category term="inference-speed"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:d56a25f6fd30</id>
    <title>Thrilled to announce a big upgrade to Gemini 3 Deep Think that hits new records on the most rigorous...</title>
    <link href="https://twitter.com/demishassabis/status/2022053593910821164" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-d56a25f6fd30" rel="related" type="text/html"/>
    <published>2026-02-13T03:40:00Z</published>
    <updated>2026-02-13T03:40:00Z</updated>
    <author><name>@demishassabis</name></author>
    <summary type="html"><![CDATA[<p>Building on yesterday's <a href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-0e4dbd1a5ef0" class="internal-link" rel="noopener noreferrer">Social</a> buzz, Hassabis announces major Gemini 3 Deep Think upgrade with record benchmarks: 84.6% ARC-AGI-2, 48.4% Humanity's Last Exam (no tools), 3455 Elo on Codeforces.</p>]]></summary>
    <category term="gemini-deep-think"/>
    <category term="benchmarks"/>
    <category term="arc-agi"/>
    <category term="product-launch"/>
    <category term="reasoning"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:8a182bfac352</id>
    <title>A huge part of this raise is Claude Code.

Weekly active users doubled since January. People who've ...</title>
    <link href="https://twitter.com/bcherny/status/2022084751050645838" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-8a182bfac352" rel="related" type="text/html"/>
    <published>2026-02-13T03:40:00Z</published>
    <updated>2026-02-13T03:40:00Z</updated>
    <author><name>@bcherny</name></author>
    <summary type="html"><![CDATA[<p>Building on yesterday's <a href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-f7f1809b05ef" class="internal-link" rel="noopener noreferrer">Social</a> buzz, Boris Cherny (Anthropic engineer) states that a huge part of Anthropic's fundraise is driven by Claude Code. Weekly active users doubled since January, and non-coders are building with it.</p>]]></summary>
    <category term="anthropic"/>
    <category term="claude-code"/>
    <category term="ai-coding"/>
    <category term="ai-business"/>
    <category term="fundraising"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:9308ca853757</id>
    <title>An updated Gemini 3 Deep Think is out today:
ðŸ“ˆ Achieves SOTA on ARC-AGI-2, MMMU-Pro, and HLE. 
ðŸ¥‡Gold...</title>
    <link href="https://twitter.com/NoamShazeer/status/2021988459519652089" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-9308ca853757" rel="related" type="text/html"/>
    <published>2026-02-13T03:31:00Z</published>
    <updated>2026-02-13T03:31:00Z</updated>
    <author><name>@NoamShazeer</name></author>
    <summary type="html"><![CDATA[<p>Building on yesterday's <a href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-0e4dbd1a5ef0" class="internal-link" rel="noopener noreferrer">Social</a> buzz, Noam Shazeer announces updated Gemini 3 Deep Think achieving SOTA on ARC-AGI-2, MMMU-Pro, HLE, plus gold-medal level on Physics &amp; Chemistry Olympiads.</p>]]></summary>
    <category term="Gemini Deep Think"/>
    <category term="AI Benchmarks"/>
    <category term="Model Release"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:ed513961e086</id>
    <title>The modern age has richly rewarded people with a combination of high intelligence and high agency. N...</title>
    <link href="https://twitter.com/ID_AA_Carmack/status/2022019443547660304" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-ed513961e086" rel="related" type="text/html"/>
    <published>2026-02-13T03:31:00Z</published>
    <updated>2026-02-13T03:31:00Z</updated>
    <author><name>@ID_AA_Carmack</name></author>
    <summary type="html"><![CDATA[<p>John Carmack argues that AI automation of intelligence will empower people with high agency but lower intelligence, if they trust AI advice. Uses provocative example of a 'ruthless criminal' with always-on AI glasses.</p>]]></summary>
    <category term="AI and human agency"/>
    <category term="AI augmentation"/>
    <category term="societal impact of AI"/>
    <category term="future of work"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:95bca28ce670</id>
    <title>Lots of folks spread false narratives about how ARC-1 was created in response to LLMs, or how ARC-2 ...</title>
    <link href="https://twitter.com/fchollet/status/2022036543582638517" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-95bca28ce670" rel="related" type="text/html"/>
    <published>2026-02-13T03:23:00Z</published>
    <updated>2026-02-13T03:23:00Z</updated>
    <author><name>@fchollet</name></author>
    <summary type="html"><![CDATA[<p>Chollet provides comprehensive history of ARC benchmarks: designed 2017-2019, progress came from test-time adaptation (not LLM scaling), base LLMs still perform poorly, ARC never claimed to prove AGI. Details ARC-3 through ARC-7 roadmap.</p>]]></summary>
    <category term="benchmarks"/>
    <category term="arc-agi"/>
    <category term="test-time-adaptation"/>
    <category term="ai-history"/>
    <category term="agi-definition"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:aa4cfef9fbee</id>
    <title>Our run-rate revenue is $14 billion, and has grown over 10x in each of the past 3 years. This growth...</title>
    <link href="https://twitter.com/AnthropicAI/status/2022023156513616220" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-aa4cfef9fbee" rel="related" type="text/html"/>
    <published>2026-02-13T03:23:00Z</published>
    <updated>2026-02-13T03:23:00Z</updated>
    <author><name>@AnthropicAI</name></author>
    <summary type="html"><![CDATA[<p>Anthropic announces $14B run-rate revenue with 10x annual growth, positioning as the intelligence platform of choice for enterprises.</p>]]></summary>
    <category term="Anthropic Business"/>
    <category term="AI Industry"/>
    <category term="AI Economics"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:a5328e1c1800</id>
    <title>Reaching AGI won't be beating a benchmark. It will be the end of the human-AI gap. Benchmarks are si...</title>
    <link href="https://twitter.com/fchollet/status/2022090111832535354" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-a5328e1c1800" rel="related" type="text/html"/>
    <published>2026-02-13T03:16:00Z</published>
    <updated>2026-02-13T03:16:00Z</updated>
    <author><name>@fchollet</name></author>
    <summary type="html"><![CDATA[<p>Chollet defines AGI as the end of the human-AI gap, argues benchmarks are a process not a fixed point, and expects the gap to close by ~2030.</p>]]></summary>
    <category term="agi-definition"/>
    <category term="benchmarks"/>
    <category term="ai-timelines"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:e2a8c5bf8f09</id>
    <title>The new Gemini Deep Think is achieving some truly incredible numbers on ARC-AGI-2. We certified thes...</title>
    <link href="https://twitter.com/fchollet/status/2021983310541729894" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-e2a8c5bf8f09" rel="related" type="text/html"/>
    <published>2026-02-13T03:16:00Z</published>
    <updated>2026-02-13T03:16:00Z</updated>
    <author><name>@fchollet</name></author>
    <summary type="html"><![CDATA[<p>Chollet certifies Gemini Deep Think's 'truly incredible' ARC-AGI-2 scores, confirming he verified them in recent days.</p>]]></summary>
    <category term="benchmarks"/>
    <category term="arc-agi"/>
    <category term="gemini-deep-think"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:11ad1bd0d08e</id>
    <title>Introducing Aletheia, a math research agent powered by an advanced version of Gemini Deep Think that...</title>
    <link href="https://twitter.com/YiTayML/status/2021750645666328779" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-11ad1bd0d08e" rel="related" type="text/html"/>
    <published>2026-02-13T03:16:00Z</published>
    <updated>2026-02-13T03:16:00Z</updated>
    <author><name>@YiTayML</name></author>
    <summary type="html"><![CDATA[<p>As first reported in <a href="http://localhost:8080/?date=2026-02-12&amp;category=research#item-a6ff7649e460" class="internal-link" rel="noopener noreferrer">Research</a> yesterday, Yi Tay introduces Aletheia, a math research agent powered by Gemini Deep Think that produces publishable research and solved multiple open ErdÅ‘s problems.</p>]]></summary>
    <category term="AI Math Research"/>
    <category term="Gemini Deep Think"/>
    <category term="AI Agents"/>
    <category term="AI for Science"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:ee5b2469c81b</id>
    <title>GPT-5.3-Codex-Spark is now in research preview.

You can just build thingsâ€”faster. https://t.co/85Lz...</title>
    <link href="https://twitter.com/OpenAI/status/2022009582210715925" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-ee5b2469c81b" rel="related" type="text/html"/>
    <published>2026-02-13T03:16:00Z</published>
    <updated>2026-02-13T03:16:00Z</updated>
    <author><name>@OpenAI</name></author>
    <summary type="html"><![CDATA[<p>OpenAI announces GPT-5.3-Codex-Spark in research preview as 'first in a family of ultra-fast models' for real-time development.</p>]]></summary>
    <category term="OpenAI"/>
    <category term="AI Coding"/>
    <category term="Model Release"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:f9cc2dc76c7f</id>
    <title>Gemini Deep Think 3 is the world's most capable model by many measures, huge amounts of progress on ...</title>
    <link href="https://twitter.com/OfficialLoganK/status/2021996626144080015" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-f9cc2dc76c7f" rel="related" type="text/html"/>
    <published>2026-02-13T03:16:00Z</published>
    <updated>2026-02-13T03:16:00Z</updated>
    <author><name>@OfficialLoganK</name></author>
    <summary type="html"><![CDATA[<p>Logan from Google announces Gemini Deep Think 3 as the world's most capable model by many measures, available now for Ultra subscribers and coming to API soon.</p>]]></summary>
    <category term="google-ai"/>
    <category term="gemini"/>
    <category term="model-launch"/>
    <category term="reasoning-models"/>
    <category term="gemini-deep-think-3"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:f8d2068d3f9c</id>
    <title>New super-fast model from OpenAI today powered by their new Cerebras partnership - GPT-5.3-Codex-Spa...</title>
    <link href="https://bsky.app/profile/simonwillison.net/post/3meowik67rk2d" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-f8d2068d3f9c" rel="related" type="text/html"/>
    <published>2026-02-13T03:16:00Z</published>
    <updated>2026-02-13T03:16:00Z</updated>
    <author><name>@simonwillison.net</name></author>
    <summary type="html"><![CDATA[<p>Simon Willison announces GPT-5.3-Codex-Spark, a new super-fast OpenAI model powered by Cerebras partnership. Reports 4-5x faster than GPT-5.3-Codex but with quality tradeoffs (worse pelican test).</p>]]></summary>
    <category term="new model release"/>
    <category term="OpenAI"/>
    <category term="Cerebras"/>
    <category term="inference speed"/>
    <category term="model benchmarking"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:9db35d5d5745</id>
    <title>Congrats on the launch @simile_ai ! (and I am excited to be involved as a small angel.)

Simile is w...</title>
    <link href="https://twitter.com/karpathy/status/2022041235188580788" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-9db35d5d5745" rel="related" type="text/html"/>
    <published>2026-02-13T03:12:00Z</published>
    <updated>2026-02-13T03:12:00Z</updated>
    <author><name>@karpathy</name></author>
    <summary type="html"><![CDATA[<p>Karpathy announces his angel investment in Simile AI, which explores using LLMs as population simulators rather than single-personality chatbots â€” simulating diverse populations from pretraining data.</p>]]></summary>
    <category term="llm-theory"/>
    <category term="ai-startups"/>
    <category term="simulation"/>
    <category term="investment"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:9e3e72c14584</id>
    <title>Weâ€™ve upgraded our specialized reasoning mode Gemini 3 Deep Think to help solve modern science, rese...</title>
    <link href="https://twitter.com/GoogleDeepMind/status/2021981510400709092" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-9e3e72c14584" rel="related" type="text/html"/>
    <published>2026-02-13T03:12:00Z</published>
    <updated>2026-02-13T03:12:00Z</updated>
    <author><name>@GoogleDeepMind</name></author>
    <summary type="html"><![CDATA[<p>Google DeepMind's lead tweet announcing Gemini 3 Deep Think upgrade for science, research, and engineering, featuring Duke University semiconductor materials research.</p>]]></summary>
    <category term="Gemini Deep Think"/>
    <category term="AI for Science"/>
    <category term="Model Release"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:d7a503bdf1a6</id>
    <title>@Yossi_Dahan_ @polynoamial ARC-4 is in the works, to be released early 2027. ARC-5 is also planned. ...</title>
    <link href="https://twitter.com/fchollet/status/2022086661170254203" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-d7a503bdf1a6" rel="related" type="text/html"/>
    <published>2026-02-13T03:07:00Z</published>
    <updated>2026-02-13T03:07:00Z</updated>
    <author><name>@fchollet</name></author>
    <summary type="html"><![CDATA[<p>Chollet reveals ARC-4 is in the works for early 2027, ARC-5 is planned, final ARC will be 6-7. Reiterates AGI ~2030 timeline.</p>]]></summary>
    <category term="benchmarks"/>
    <category term="arc-agi"/>
    <category term="ai-timelines"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:59bb8b931565</id>
    <title>I don't know if you've noticed, but there's a wave of mass psychosis rolling through tech Twitter, v...</title>
    <link href="https://twitter.com/fchollet/status/2021748146951606545" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-59bb8b931565" rel="related" type="text/html"/>
    <published>2026-02-13T03:07:00Z</published>
    <updated>2026-02-13T03:07:00Z</updated>
    <author><name>@fchollet</name></author>
    <summary type="html"><![CDATA[<p>Chollet observes a wave of 'mass psychosis' on tech Twitter with a 3-year periodicity (2020, 2023, now 2026), but notes the vibes are much darker this time.</p>]]></summary>
    <category term="ai-hype"/>
    <category term="tech-culture"/>
    <category term="social-commentary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:e7ad3bdafd41</id>
    <title>Gemini 3 Deep Think is here! ðŸ˜Ž

This model is not only super strong in math and coding (IMO gold and...</title>
    <link href="https://twitter.com/YiTayML/status/2021988841142534287" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-e7ad3bdafd41" rel="related" type="text/html"/>
    <published>2026-02-13T03:07:00Z</published>
    <updated>2026-02-13T03:07:00Z</updated>
    <author><name>@YiTayML</name></author>
    <summary type="html"><![CDATA[<p>Yi Tay announces Gemini 3 Deep Think with IMO gold, 3455 Codeforces ELO, gold in Physics/Chemistry Olympiads, and new records on ARC-AGI-2 and HLE.</p>]]></summary>
    <category term="Gemini Deep Think"/>
    <category term="AI Benchmarks"/>
    <category term="Model Release"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-13:social:9e9d2bb87c06</id>
    <title>Yesterday I tried to vibe code a refactor of an ML library into a new more efficient framework. 

I ...</title>
    <link href="https://twitter.com/tunguz/status/2021954569140334960" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-13&amp;category=social#item-9e9d2bb87c06" rel="related" type="text/html"/>
    <published>2026-02-13T03:07:00Z</published>
    <updated>2026-02-13T03:07:00Z</updated>
    <author><name>@tunguz</name></author>
    <summary type="html"><![CDATA[<p>Tunguz shares detailed experience of vibe coding an ML library refactor: first attempt following 'best practices' (plan with Claude, implement with Codex) failed. Second attempt - telling Codex to ignore prior work and reimplement from scratch - yielded massive speedups.</p>]]></summary>
    <category term="vibe coding"/>
    <category term="AI-assisted development"/>
    <category term="Codex"/>
    <category term="Claude"/>
    <category term="ML optimization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-12:category-summary:social</id>
    <title>Social Summary: February 12, 2026</title>
    <link href="https://twitter.com/karpathy/status/2021633574089416993" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-12&amp;category=social" rel="related" type="text/html"/>
    <published>2026-02-12T06:00:00Z</published>
    <updated>2026-02-12T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>Anthropic</strong> dominated the day with a landmark AI safety announcement: <strong>Claude Opus 4.6</strong> is approaching ASL-4 capability thresholds, and the company is preemptively applying its highest safety standards, publishing its first <a href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-92a718e1a2d9" class="internal-link" rel="noopener noreferrer">sabotage risk report</a> for frontier autonomous AI R&amp;D. Separately, <strong>Anthropic</strong> <a href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-8cd633d16d8e" class="internal-link" rel="noopener noreferrer">committed to covering</a> 100% of electricity price increases from its data centers, a major infrastructure policy move.</p>
<ul>
<li><strong>Andrej Karpathy</strong> drove massive engagement with two posts: a <a href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-fb1b858f8eeb" class="internal-link" rel="noopener noreferrer">detailed walkthrough</a> of using <strong>DeepWiki</strong> MCP to extract library functionality via agents (5K likes), and the <a href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-3685549e1b3b" class="internal-link" rel="noopener noreferrer">release of a 243-line</a> dependency-free Python GPT implementation (6.5K likes), reinforcing themes of software malleability and minimalism in the AI era</li>
<li><strong>Sam Altman</strong> <a href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-51e4e7e6e5f0" class="internal-link" rel="noopener noreferrer">announced a GPT-5.2 update</a> in <strong>ChatGPT</strong> and expressed confidence that <strong>Codex</strong> is winning the AI coding race faster than expected (874K views)</li>
<li><strong>Jason Warner</strong> (Poolside CEO) <a href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-5ce505a8fecb" class="internal-link" rel="noopener noreferrer">published a strategic thesis</a> arguing intelligence is the new critical infrastructure, comparing AI providers to cloud and energy utilities</li>
<li><strong>Google DeepMind</strong> <a href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-0e4dbd1a5ef0" class="internal-link" rel="noopener noreferrer">shared research</a> showing <strong>Gemini Deep Think</strong> uses agentic workflows to help solve research-level problems in math, physics, and computer science</li>
<li><strong>Boris Cherny</strong> (Anthropic) <a href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-f7f1809b05ef" class="internal-link" rel="noopener noreferrer">detailed <strong>Claude Code's</strong></a> extensive customization systemâ€”hooks, plugins, LSPs, MCPsâ€”signaling a strategy to win developers through configurability</li>
</ul>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-12:social:fb1b858f8eeb</id>
    <title>On DeepWiki and increasing malleability of software.

This starts as partially a post on appreciatio...</title>
    <link href="https://twitter.com/karpathy/status/2021633574089416993" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-fb1b858f8eeb" rel="related" type="text/html"/>
    <published>2026-02-12T03:47:00Z</published>
    <updated>2026-02-12T03:47:00Z</updated>
    <author><name>@karpathy</name></author>
    <summary type="html"><![CDATA[<p>Karpathy writes a detailed post about using DeepWiki MCP + GitHub CLI to extract specific functionality from codebases. He used an agent to 'rip out' torchao's fp8 training into 150 lines of clean self-contained code that runs 3% faster. Argues software should become more modular 'bacterial code' and that 'libraries are over, LLMs are the new compiler.'</p>]]></summary>
    <category term="software development paradigm shift"/>
    <category term="AI agents"/>
    <category term="dependency-free code"/>
    <category term="DeepWiki"/>
    <category term="bacterial code"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-12:social:3685549e1b3b</id>
    <title>New art project. 
Train and inference GPT in 243 lines of pure, dependency-free Python. This is the ...</title>
    <link href="https://twitter.com/karpathy/status/2021694437152157847" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-3685549e1b3b" rel="related" type="text/html"/>
    <published>2026-02-12T03:40:00Z</published>
    <updated>2026-02-12T03:40:00Z</updated>
    <author><name>@karpathy</name></author>
    <summary type="html"><![CDATA[<p>Karpathy releases a new project: training and running inference on GPT in 243 lines of pure, dependency-free Python, calling it the full algorithmic content of what's needed with everything else being for efficiency.</p>]]></summary>
    <category term="ML education"/>
    <category term="LLM internals"/>
    <category term="minimalist implementation"/>
    <category term="open source"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-12:social:92a718e1a2d9</id>
    <title>When we released Claude Opus 4.5, we knew future models would be close to our AI Safety Level 4 thre...</title>
    <link href="https://twitter.com/AnthropicAI/status/2021397952791707696" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-92a718e1a2d9" rel="related" type="text/html"/>
    <published>2026-02-12T03:40:00Z</published>
    <updated>2026-02-12T03:40:00Z</updated>
    <author><name>@AnthropicAI</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-02-11&amp;category=research#item-8bcb574e900f" class="internal-link" rel="noopener noreferrer">Research</a> coverage of the Opus 4.6 system card, Anthropic announces they're delivering on their commitment to write sabotage risk reports for frontier models, starting with Claude Opus 4.6. They noted when releasing Opus 4.5 that future models would be close to ASL-4 threshold for autonomous AI R&amp;D.</p>]]></summary>
    <category term="ai_safety"/>
    <category term="anthropic"/>
    <category term="claude_opus_4.6"/>
    <category term="asl4"/>
    <category term="autonomous_ai_research"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-12:social:8cd633d16d8e</id>
    <title>We're committing to cover electricity price increases from our data centers.

To ensure ratepayers a...</title>
    <link href="https://twitter.com/AnthropicAI/status/2021694494215901314" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-8cd633d16d8e" rel="related" type="text/html"/>
    <published>2026-02-12T03:23:00Z</published>
    <updated>2026-02-12T03:23:00Z</updated>
    <author><name>@AnthropicAI</name></author>
    <summary type="html"><![CDATA[<p>Anthropic announces commitment to cover 100% of electricity price increases from their data centers, pay grid upgrade costs, bring new power online, and invest in systems to reduce grid strain.</p>]]></summary>
    <category term="AI infrastructure"/>
    <category term="energy policy"/>
    <category term="responsible AI"/>
    <category term="data center costs"/>
    <category term="Anthropic"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-12:social:afdb966a5f09</id>
    <title>Rather than making difficult calls about blurry thresholds, we decided to preemptively meet the high...</title>
    <link href="https://twitter.com/AnthropicAI/status/2021397953848672557" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-afdb966a5f09" rel="related" type="text/html"/>
    <published>2026-02-12T03:23:00Z</published>
    <updated>2026-02-12T03:23:00Z</updated>
    <author><name>@AnthropicAI</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-02-11&amp;category=research#item-8bcb574e900f" class="internal-link" rel="noopener noreferrer">Research</a> coverage of the Opus 4.6 system card, Anthropic shares link to sabotage risk report for Claude Opus 4.6, explaining they decided to preemptively meet the higher ASL-4 safety bar rather than debating blurry thresholds.</p>]]></summary>
    <category term="ai_safety"/>
    <category term="anthropic"/>
    <category term="claude_opus_4.6"/>
    <category term="asl4"/>
    <category term="sabotage_risk"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-12:social:51e4e7e6e5f0</id>
    <title>We updated GPT-5.2 (the instant model) in ChatGPT today. Not a huge change, but hopefully you find i...</title>
    <link href="https://twitter.com/sama/status/2021452911511998557" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-51e4e7e6e5f0" rel="related" type="text/html"/>
    <published>2026-02-12T03:16:00Z</published>
    <updated>2026-02-12T03:16:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>Sam Altman announces an update to GPT-5.2 (the instant model) in ChatGPT, describing it as not a huge change but hopefully a little better.</p>]]></summary>
    <category term="GPT-5.2 update"/>
    <category term="OpenAI product"/>
    <category term="model updates"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-12:social:5ce505a8fecb</id>
    <title>:taps the sign:

https://t.co/JgKbHvYLRW

This isn't about Cursor, so forget the name used. This is ...</title>
    <link href="https://twitter.com/jasoncwarner/status/2021689419028476321" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-5ce505a8fecb" rel="related" type="text/html"/>
    <published>2026-02-12T03:16:00Z</published>
    <updated>2026-02-12T03:16:00Z</updated>
    <author><name>@jasoncwarner</name></author>
    <summary type="html"><![CDATA[<p>Jason Warner (Poolside CEO) writes an extensive essay arguing that intelligence is the new critical infrastructure, comparing AI model providers to cloud hyperscalers. Key arguments: (1) Google is the only full-stack AI player, (2) large companies MUST train their own models or die, (3) frontier model training costs ~$500M not billions, (4) first-party agents will always beat third-party ones, (5) app companies are just arbitraging current model capability gaps. Promotes Poolside's 'Model Factory' approach.</p>]]></summary>
    <category term="ai_business_strategy"/>
    <category term="ai_infrastructure"/>
    <category term="model_economics"/>
    <category term="enterprise_ai"/>
    <category term="build_vs_buy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-12:social:0b8abc3afa0d</id>
    <title>From how the team operates, I always thought Codex would eventually win. But I am pleasantly surpris...</title>
    <link href="https://twitter.com/sama/status/2021606985469211065" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-0b8abc3afa0d" rel="related" type="text/html"/>
    <published>2026-02-12T03:07:00Z</published>
    <updated>2026-02-12T03:07:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>As first reported in <a href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-00ef1e57cd16" class="internal-link" rel="noopener noreferrer">Social</a> two days ago, Sam Altman expresses confidence in Codex winning, says he's pleasantly surprised at how quickly it's happening, and thanks builders.</p>]]></summary>
    <category term="Codex"/>
    <category term="OpenAI strategy"/>
    <category term="AI coding tools"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-12:social:347c1960409e</id>
    <title>ðŸ”¥Congrats to @Zai_org on launching GLM-5 â€” 744B parameters (40B active), trained on 28.5T tokens, in...</title>
    <link href="https://twitter.com/vllm_project/status/2021656482698387852" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-347c1960409e" rel="related" type="text/html"/>
    <published>2026-02-12T03:07:00Z</published>
    <updated>2026-02-12T03:07:00Z</updated>
    <author><name>@vllm_project</name></author>
    <summary type="html"><![CDATA[<p>vLLM announces day-0 support for GLM-5, a new 744B parameter MoE model (40B active) from Zhipu AI, with DeepSeek Sparse Attention, MTP speculative decoding, and tool calling support.</p>]]></summary>
    <category term="glm5"/>
    <category term="vllm"/>
    <category term="model_launch"/>
    <category term="moe_architecture"/>
    <category term="inference_optimization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-12:social:f7f1809b05ef</id>
    <title>Reflecting on what engineers love about Claude Code, one thing that jumps out is its customizability...</title>
    <link href="https://twitter.com/bcherny/status/2021699851499798911" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-f7f1809b05ef" rel="related" type="text/html"/>
    <published>2026-02-12T03:07:00Z</published>
    <updated>2026-02-12T03:07:00Z</updated>
    <author><name>@bcherny</name></author>
    <summary type="html"><![CDATA[<p>Boris Cherny's main thread intro: reflecting on Claude Code's customizability as a key driver of developer love and growth - hooks, plugins, LSPs, MCPs, skills, effort levels, custom agents, status lines, output styles.</p>]]></summary>
    <category term="Claude Code"/>
    <category term="developer tools"/>
    <category term="product strategy"/>
    <category term="AI coding"/>
    <category term="customization"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-12:social:e1252977e191</id>
    <title>My first rodeo with Claude Cowork Legal plugin. 

This is the /legal:triage-nda call that reviews ND...</title>
    <link href="https://twitter.com/alliekmiller/status/2021586268573024337" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-12&amp;category=social#item-e1252977e191" rel="related" type="text/html"/>
    <published>2026-02-12T03:07:00Z</published>
    <updated>2026-02-12T03:07:00Z</updated>
    <author><name>@alliekmiller</name></author>
    <summary type="html"><![CDATA[<p>Allie K Miller demonstrates Claude Cowork's Legal plugin for NDA triage/review, showing it analyzing a real NDA against market-standard criteria. She notes legal stocks were 'rocked' and asks lawyers about the impact on billable hours.</p>]]></summary>
    <category term="claude_cowork"/>
    <category term="legal_ai"/>
    <category term="ai_disruption"/>
    <category term="professional_services"/>
    <category term="agentic_ai"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-11:category-summary:social</id>
    <title>Social Summary: February 11, 2026</title>
    <link href="https://twitter.com/AndrewYNg/status/2021259884709413291" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-11&amp;category=social" rel="related" type="text/html"/>
    <published>2026-02-11T06:00:00Z</published>
    <updated>2026-02-11T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>Andrew Ng</strong>'s <a href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-1379782f1cad" class="internal-link" rel="noopener noreferrer">comprehensive analysis</a> of AI's real impact on the job market dominated discourse, arguing job losses are overhyped while emphasizing AI-augmented workers replacing those without AI skills. Meanwhile, <strong>OpenAI</strong> made multiple product moves: <strong>Greg Brockman</strong> <a href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-6224d8d38364" class="internal-link" rel="noopener noreferrer">demoed <strong>GPT-5.3-Codex</strong></a> for cross-language application rewriting, and Deep Research was <a href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-1a92ba7ed13a" class="internal-link" rel="noopener noreferrer">upgraded to <strong>GPT-5.2</strong></a> with new features.</p>
<ul>
<li><strong>Demis Hassabis</strong> announced <strong>Isomorphic Labs</strong>' drug design engine is <a href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-372cbdb99dec" class="internal-link" rel="noopener noreferrer">extending state-of-the-art benchmarks</a>, reinforcing AI's transformative potential in healthcare</li>
<li><strong>Ethan Mollick</strong> <a href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-40bed350b2df" class="internal-link" rel="noopener noreferrer">shared NBER research</a> showing LLMs tripled book releases since 2022â€”average quality fell but top-ranked books actually improved</li>
<li><strong>Mollick</strong> also revealed that <strong>Claude Opus 4.6</strong> quietly <a href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-d78c5f9ad0de" class="internal-link" rel="noopener noreferrer">introduced spontaneous subagent spawning</a> in <strong>Claude Code</strong>, a significant capability upgrade AI labs failed to communicate clearly</li>
<li><strong>Anthropic</strong> <a href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-eae6ad72712f" class="internal-link" rel="noopener noreferrer">shared striking internal metrics</a>: 67% increase in PRs per developer per day, with 70-90% of code now written by <strong>Claude</strong></li>
<li><strong>Matt Shumer</strong>'s viral article about AI's real trajectory <a href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-2e243097ae49" class="internal-link" rel="noopener noreferrer">reached over 10M views</a>, signaling growing mainstream appetite for honest AI discourse</li>
<li><strong>Runway</strong> <a href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-47ab6a4248c7" class="internal-link" rel="noopener noreferrer">raised $315M in Series E</a> funding to advance world models, calling them the most transformative technology of our time</li>
</ul>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-11:social:1379782f1cad</id>
    <title>Job seekers in the U.S. and many other nations face a tough environment. At the same time, fears of ...</title>
    <link href="https://twitter.com/AndrewYNg/status/2021259884709413291" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-1379782f1cad" rel="related" type="text/html"/>
    <published>2026-02-11T03:40:00Z</published>
    <updated>2026-02-11T03:40:00Z</updated>
    <author><name>@AndrewYNg</name></author>
    <summary type="html"><![CDATA[<p>Andrew Ng provides a comprehensive analysis of AI's impact on the job market. Key points: AI job losses are overhyped so far; workers using AI replace those who don't; teams are shrinking (8 engineers + 1 PM â†’ 2 engineers + 1 PM); PM bottleneck emerging; non-technical roles like marketers/recruiters who code with AI are replacing those who can't. Encourages learning AI skills.</p>]]></summary>
    <category term="ai_job_market"/>
    <category term="ai_skills"/>
    <category term="software_engineering_evolution"/>
    <category term="ai_workforce_transformation"/>
    <category term="product_management"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-11:social:6224d8d38364</id>
    <title>gpt-5.3-codex for rewriting applications between languages:</title>
    <link href="https://twitter.com/gdb/status/2021272681237361027" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-6224d8d38364" rel="related" type="text/html"/>
    <published>2026-02-11T03:31:00Z</published>
    <updated>2026-02-11T03:31:00Z</updated>
    <author><name>@gdb</name></author>
    <summary type="html"><![CDATA[<p>Continuing Brockman's <a href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-50b5b0ba98c3" class="internal-link" rel="noopener noreferrer">Social</a> coverage of GPT-5.3 Codex, Greg Brockman (OpenAI co-founder) showcases GPT-5.3-Codex being used for rewriting applications between programming languages.</p>]]></summary>
    <category term="gpt5_codex"/>
    <category term="code_generation"/>
    <category term="openai_products"/>
    <category term="model_capabilities"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-11:social:2e243097ae49</id>
    <title>https://t.co/ivXRKXJvQg</title>
    <link href="https://twitter.com/mattshumer_/status/2021256989876109403" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-2e243097ae49" rel="related" type="text/html"/>
    <published>2026-02-11T03:31:00Z</published>
    <updated>2026-02-11T03:31:00Z</updated>
    <author><name>@mattshumer_</name></author>
    <summary type="html"><![CDATA[<p>Matt Shumer shares content (likely video/article) with extraordinary engagement: 22K likes, 4.2K RTs, 10.7M views, 1.9K quote tweets</p>]]></summary>
    <category term="ai-awareness"/>
    <category term="ai-workforce-impact"/>
    <category term="ai-communication-gap"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-11:social:372cbdb99dec</id>
    <title>The drug design engine weâ€™re building at @IsomorphicLabs is extending the SOTA further across key be...</title>
    <link href="https://twitter.com/demishassabis/status/2021223548744822972" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-372cbdb99dec" rel="related" type="text/html"/>
    <published>2026-02-11T03:23:00Z</published>
    <updated>2026-02-11T03:23:00Z</updated>
    <author><name>@demishassabis</name></author>
    <summary type="html"><![CDATA[<p>Demis Hassabis announces Isomorphic Labs' drug design engine is extending state-of-the-art across key benchmarks for in-silico drug discovery, with major accuracy improvements.</p>]]></summary>
    <category term="ai_drug_discovery"/>
    <category term="isomorphic_labs"/>
    <category term="benchmarks"/>
    <category term="scientific_breakthrough"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-11:social:1a92ba7ed13a</id>
    <title>Deep research in ChatGPT is now powered by GPT-5.2.

Rolling out starting today with more improvemen...</title>
    <link href="https://twitter.com/OpenAI/status/2021299935678026168" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-1a92ba7ed13a" rel="related" type="text/html"/>
    <published>2026-02-11T03:19:00Z</published>
    <updated>2026-02-11T03:19:00Z</updated>
    <author><name>@OpenAI</name></author>
    <summary type="html"><![CDATA[<p>Building on yesterday's <a href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-9a13d5cba8f6" class="internal-link" rel="noopener noreferrer">Social</a> buzz around OpenAI's latest models, OpenAI announces that Deep Research in ChatGPT is now powered by GPT-5.2, rolling out with improvements.</p>]]></summary>
    <category term="openai_products"/>
    <category term="gpt5"/>
    <category term="deep_research"/>
    <category term="model_deployment"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-11:social:40bed350b2df</id>
    <title>LLMs tripled new book releases since 2022. Average quality fell: most new entries are, indeed, slop
...</title>
    <link href="https://twitter.com/emollick/status/2021287459016053083" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-40bed350b2df" rel="related" type="text/html"/>
    <published>2026-02-11T03:16:00Z</published>
    <updated>2026-02-11T03:16:00Z</updated>
    <author><name>@emollick</name></author>
    <summary type="html"><![CDATA[<p>Emollick shares research showing LLMs tripled new book releases since 2022. While average quality fell (slop), books ranked 100-1,000 per category are actually better than before, and pre-LLM authors became more productive. Net positive for readers who only read good books.</p>]]></summary>
    <category term="ai_content_quality"/>
    <category term="ai_impact_on_creative_work"/>
    <category term="ai_economics"/>
    <category term="research_findings"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-11:social:9da3c4aa854e</id>
    <title>Every time someone asks me what's going on with AI, I give them the safe answer. Because the real on...</title>
    <link href="https://twitter.com/mattshumer_/status/2021257145245708437" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-11&amp;category=social#item-9da3c4aa854e" rel="related" type="text/html"/>
    <published>2026-02-11T03:16:00Z</published>
    <updated>2026-02-11T03:16:00Z</updated>
    <author><name>@mattshumer_</name></author>
    <summary type="html"><![CDATA[<p>Matt Shumer's original viral article post about AI's real trajectory - highest engagement version with article link (4048 likes, 426 RTs, 1.5M views)</p>]]></summary>
    <category term="ai-awareness"/>
    <category term="ai-workforce-impact"/>
    <category term="ai-communication-gap"/>
    <category term="ai-adoption-timeline"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-10:category-summary:social</id>
    <title>Social Summary: February 10, 2026</title>
    <link href="https://twitter.com/sama/status/2020940847190356092" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-10&amp;category=social" rel="related" type="text/html"/>
    <published>2026-02-10T06:00:00Z</published>
    <updated>2026-02-10T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>OpenAI</strong> dominated the day's discourse with <strong>Sam Altman</strong> announcing <strong>GPT-5.3-Codex</strong> <a href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-7d2439afa80f" class="internal-link" rel="noopener noreferrer">rolling out</a> to <strong>Cursor</strong>, <strong>GitHub</strong>, and <strong>VS Code</strong>, alongside the milestone of <a href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-00ef1e57cd16" class="internal-link" rel="noopener noreferrer">1M+ <strong>Codex App</strong> downloads</a> in its first week. Altman framed 5.3 as a stepping stoneâ€”'<a href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-9a13d5cba8f6" class="internal-link" rel="noopener noreferrer">not solved yet</a>, but 5.3 will help build the thing that solves it'â€”while revealing <a href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-277be016615d" class="internal-link" rel="noopener noreferrer">cybersecurity concerns are gating</a> the API rollout.</p>
<ul>
<li><strong>OpenAI</strong> began <a href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-ad34943c6a96" class="internal-link" rel="noopener noreferrer">testing <strong>ads in ChatGPT</strong></a> for US free/Go users, marking a major monetization shift that drew intense community debate</li>
<li><strong>OpenAI's Super Bowl LX ad</strong> ('You can just build things') hit 2.3M views, signaling aggressive mainstream consumer positioning</li>
<li><strong>Simon Willison</strong> <a href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-a2937db66508" class="internal-link" rel="noopener noreferrer">highlighted <strong>HBR research</strong></a> showing AI productivity boosts can cause burnout and mental exhaustion, resonating widely with practitioners</li>
<li><strong>Perplexity</strong> CEO <strong>Arav Srinivas</strong> announced <a href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-05e205f83131" class="internal-link" rel="noopener noreferrer">upgrading Deep Research</a> to <strong>Claude Opus 4.6</strong>, claiming benchmark leadership over <strong>Google</strong></li>
<li><strong>Nathan Lambert</strong> <a href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-d8e880aa037d" class="internal-link" rel="noopener noreferrer">published detailed analysis</a> of <strong>Opus 4.6</strong> and <strong>Codex 5.3</strong>, calling Claude the agent king but noting benchmarks are increasingly inadequate for evaluation in 2026</li>
<li><strong>Ethan Mollick</strong> observed that <a href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-38dd778f6519" class="internal-link" rel="noopener noreferrer">faking continual learning</a> and memory for AIs works surprisingly well, predicting true continual learning would be a major breakthrough</li>
</ul>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-10:social:7d2439afa80f</id>
    <title>GPT-5.3-Codex is rolling out today in Cursor, Github, and VS Code!</title>
    <link href="https://twitter.com/sama/status/2020940847190356092" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-7d2439afa80f" rel="related" type="text/html"/>
    <published>2026-02-10T03:47:00Z</published>
    <updated>2026-02-10T03:47:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>Continuing our <a href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-50b5b0ba98c3" class="internal-link" rel="noopener noreferrer">Social</a> coverage of GPT-5.3 Codex, Sam Altman announces GPT-5.3-Codex is rolling out today in Cursor, GitHub, and VS Code.</p>]]></summary>
    <category term="GPT-5.3-Codex"/>
    <category term="AI coding tools"/>
    <category term="product launch"/>
    <category term="IDE integration"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-10:social:00ef1e57cd16</id>
    <title>More than 1 million people downloaded Codex App in the first week.

60+% growth in overall Codex use...</title>
    <link href="https://twitter.com/sama/status/2020977975081177343" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-00ef1e57cd16" rel="related" type="text/html"/>
    <published>2026-02-10T03:40:00Z</published>
    <updated>2026-02-10T03:40:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>Sam Altman announces Codex App surpassed 1 million downloads in its first week with 60%+ weekly growth in overall Codex users. Commits to keeping Codex available to Free/Go users after the promotion, possibly with reduced limits.</p>]]></summary>
    <category term="OpenAI Codex"/>
    <category term="product growth"/>
    <category term="AI coding tools"/>
    <category term="business strategy"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-10:social:ad34943c6a96</id>
    <title>Weâ€™re starting to roll out a test for ads in ChatGPT today to a subset of free and Go users in the U...</title>
    <link href="https://twitter.com/OpenAI/status/2020936703763153010" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-ad34943c6a96" rel="related" type="text/html"/>
    <published>2026-02-10T03:36:00Z</published>
    <updated>2026-02-10T03:36:00Z</updated>
    <author><name>@OpenAI</name></author>
    <summary type="html"><![CDATA[<p>Following earlier <a href="http://localhost:8080/?date=2026-02-08&amp;category=news#item-dc98ffeb01f2" class="internal-link" rel="noopener noreferrer">News</a> coverage of the Anthropic-OpenAI ad battle, OpenAI announces starting to roll out ads in ChatGPT for a subset of US free and Go users. Ads are labeled as sponsored and visually separate from responses. States ads don't influence ChatGPT's answers.</p>]]></summary>
    <category term="OpenAI business model"/>
    <category term="ChatGPT ads"/>
    <category term="AI monetization"/>
    <category term="trust and transparency"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-10:social:9a13d5cba8f6</id>
    <title>Not solved yet, but 5.3 will help build the thing that solves it</title>
    <link href="https://twitter.com/sama/status/2020678853468053516" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-9a13d5cba8f6" rel="related" type="text/html"/>
    <published>2026-02-10T03:23:00Z</published>
    <updated>2026-02-10T03:23:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>Building on yesterday's <a href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-50b5b0ba98c3" class="internal-link" rel="noopener noreferrer">Social</a> coverage of GPT-5.3 Codex, Sam Altman states that while whatever is being discussed isn't 'solved yet,' GPT-5.3 'will help build the thing that solves it' â€” suggesting GPT-5.3 is a stepping stone toward more capable systems.</p>]]></summary>
    <category term="GPT-5.3"/>
    <category term="AI progress"/>
    <category term="OpenAI roadmap"/>
    <category term="recursive improvement"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-10:social:277be016615d</id>
    <title>We want to get it to all API customers quickly. This is our first model at at high for cybersecurity...</title>
    <link href="https://twitter.com/sama/status/2020940848159130094" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-277be016615d" rel="related" type="text/html"/>
    <published>2026-02-10T03:16:00Z</published>
    <updated>2026-02-10T03:16:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>Building on yesterday's <a href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-50b5b0ba98c3" class="internal-link" rel="noopener noreferrer">Social</a> coverage of GPT-5.3 Codex, Sam Altman explains the GPT-5.3-Codex API delay: it's their first model at a high bar for cybersecurity, and the extra safety work is taking longer than expected.</p>]]></summary>
    <category term="GPT-5.3-Codex"/>
    <category term="AI safety"/>
    <category term="cybersecurity"/>
    <category term="API availability"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-10:social:05e205f83131</id>
    <title>We've upgraded Perplexity's Advanced Deep Research harness to run with Opus 4.6 (from last week's ve...</title>
    <link href="https://twitter.com/AravSrinivas/status/2020969022154735736" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-05e205f83131" rel="related" type="text/html"/>
    <published>2026-02-10T03:16:00Z</published>
    <updated>2026-02-10T03:16:00Z</updated>
    <author><name>@AravSrinivas</name></author>
    <summary type="html"><![CDATA[<p>Arav Srinivas announces Perplexity has upgraded its Advanced Deep Research to use Claude Opus 4.6, claiming lead on Google's DSQA benchmark. Rolling out to Max users immediately, Pro users gradually.</p>]]></summary>
    <category term="perplexity-product"/>
    <category term="opus-4.6-adoption"/>
    <category term="ai-benchmarks"/>
    <category term="competitive-dynamics"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-10:social:a2937db66508</id>
    <title>Interesting research in HBR today about how the productivity boost you can get from AI tools can lea...</title>
    <link href="https://bsky.app/profile/simonwillison.net/post/3megvhc6lck2q" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-10&amp;category=social#item-a2937db66508" rel="related" type="text/html"/>
    <published>2026-02-10T03:16:00Z</published>
    <updated>2026-02-10T03:16:00Z</updated>
    <author><name>@simonwillison.net</name></author>
    <summary type="html"><![CDATA[<p>Willison discusses HBR research showing that AI productivity boosts can lead to burnout and mental exhaustion, noting he's experienced this personally. Links to his blog post reflecting on the findings.</p>]]></summary>
    <category term="AI productivity paradox"/>
    <category term="burnout and mental health"/>
    <category term="AI workplace impact"/>
    <category term="human-AI interaction"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:category-summary:social</id>
    <title>Social Summary: February 09, 2026</title>
    <link href="https://twitter.com/emollick/status/2020303173362012667" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social" rel="related" type="text/html"/>
    <published>2026-02-09T06:00:00Z</published>
    <updated>2026-02-09T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p><strong>GPT-5.3 Codex</strong> dominated discussions as <strong>Greg Brockman</strong> <a href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-50b5b0ba98c3" class="internal-link" rel="noopener noreferrer">shared official walkthroughs</a> and <a href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-48dfba346994" class="internal-link" rel="noopener noreferrer">teased transformative computing</a> capabilities, drawing massive engagement. <strong>xAI</strong> <a href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-22a84d641ea7" class="internal-link" rel="noopener noreferrer">announced new image models</a> on Grok Imagine API.</p>
<ul>
<li><strong>Ethan Mollick</strong> provided exceptional intellectual framework <a href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-cebed33efa25" class="internal-link" rel="noopener noreferrer">applying organizational theory</a> to agentic AIâ€”spans of control, boundary objects, and coupling principles. Also noted <strong>Claude 4.6 Opus</strong> <a href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-36cb5a731a20" class="internal-link" rel="noopener noreferrer">suffers same routing flaw</a> as early GPT-5.</li>
<li><strong>Nathan Lambert</strong> delivered comprehensive market data: <strong>Qwen</strong> <a href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-8aa7e6301744" class="internal-link" rel="noopener noreferrer">leads open models</a> with 40 of top 100, while <strong>DeepSeek</strong> <a href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-e751d36c743e" class="internal-link" rel="noopener noreferrer">dominates frontier 100B+</a> models (16 models). <strong>GPT-OSS-120B</strong> leads downloads.</li>
<li><strong>FranÃ§ois Chollet</strong> <a href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-b835c2f5d67f" class="internal-link" rel="noopener noreferrer">challenged 'Google is dead' narrative</a> with concrete data: search queries grew 61% to 5T/year, revenue up 28% to $225B through 2025.</li>
</ul>
<p><strong>Yann LeCun</strong> <a href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-e2b5f92a3eaf" class="internal-link" rel="noopener noreferrer">clarified his Meta departure</a> with 462K views, noting scientists aren't motivated by money. <strong>Andriy Burkov</strong> provided <a href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-06f00ec01af6" class="internal-link" rel="noopener noreferrer">sharp technical counter-narrative</a> on OpenClaw hype ("2% code, 98% hype").</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:social:cebed33efa25</id>
    <title>I think agentic AI would work much better if people took lessons from organizational theory, which h...</title>
    <link href="https://twitter.com/emollick/status/2020303173362012667" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-cebed33efa25" rel="related" type="text/html"/>
    <published>2026-02-09T03:47:00Z</published>
    <updated>2026-02-09T03:47:00Z</updated>
    <author><name>@emollick</name></author>
    <summary type="html"><![CDATA[<p>Emollick argues agentic AI needs organizational theory: spans of control (humans max ~10 reports, 100 subagents likely too many), boundary objects for coordination, proper coupling. Calls for more experiments with agent organization</p>]]></summary>
    <category term="Agentic AI"/>
    <category term="Organizational theory"/>
    <category term="Multi-agent systems"/>
    <category term="AI architecture"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:social:48dfba346994</id>
    <title>going to soon feel how inefficient itâ€™s been to do work with a computer</title>
    <link href="https://twitter.com/gdb/status/2020419433249091857" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-48dfba346994" rel="related" type="text/html"/>
    <published>2026-02-09T03:40:00Z</published>
    <updated>2026-02-09T03:40:00Z</updated>
    <author><name>@gdb</name></author>
    <summary type="html"><![CDATA[<p>Brockman: 'going to soon feel how inefficient it's been to do work with a computer'</p>]]></summary>
    <category term="OpenAI"/>
    <category term="GPT-5.3 Codex"/>
    <category term="AI productivity"/>
    <category term="Future of work"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:social:8aa7e6301744</id>
    <title>Top 100 LLMs by Downloads Since August 2025
Source: @interconnectsai HuggingFace Snapshots
Model lis...</title>
    <link href="https://twitter.com/natolambert/status/2020545034270150962" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-8aa7e6301744" rel="related" type="text/html"/>
    <published>2026-02-09T03:40:00Z</published>
    <updated>2026-02-09T03:40:00Z</updated>
    <author><name>@natolambert</name></author>
    <summary type="html"><![CDATA[<p>Nathan Lambert shares comprehensive Top 100 LLMs by downloads since August 2025, showing Qwen dominance (40 models), followed by Meta (13), DeepSeek (10). Llama-3.1-8B-Instruct leads with 53.3M downloads, GPT-OSS models prominent.</p>]]></summary>
    <category term="open_source_models"/>
    <category term="market_analysis"/>
    <category term="model_adoption"/>
    <category term="ecosystem_trends"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:social:b835c2f5d67f</id>
    <title>Back in 2023 everybody was telling me "no one uses Google search anymore, it's over"

From 2023 to 2...</title>
    <link href="https://twitter.com/fchollet/status/2020497629290148139" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-b835c2f5d67f" rel="related" type="text/html"/>
    <published>2026-02-09T03:36:00Z</published>
    <updated>2026-02-09T03:36:00Z</updated>
    <author><name>@fchollet</name></author>
    <summary type="html"><![CDATA[<p>Chollet presents original Google data: search volume 61% growth to 5T queries/year, revenue 28% growth to $225B (56% of Google revenue); criticizes Twitter pundit AI disruption predictions</p>]]></summary>
    <category term="Google Search"/>
    <category term="Market analysis"/>
    <category term="AI disruption predictions"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:social:e751d36c743e</id>
    <title>Top 50 100B+ LLMs by Downloads Since August 2025

Featuring: @deepseek_ai: 16, @alibaba_qwen: 8, @AI...</title>
    <link href="https://twitter.com/natolambert/status/2020545036715499756" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-e751d36c743e" rel="related" type="text/html"/>
    <published>2026-02-09T03:36:00Z</published>
    <updated>2026-02-09T03:36:00Z</updated>
    <author><name>@natolambert</name></author>
    <summary type="html"><![CDATA[<p>Nathan Lambert's Top 50 100B+ LLMs by downloads - DeepSeek dominates with 16 models, GPT-OSS-120B leads at 22.3M downloads, followed by DeepSeek-R1 at 3.8M. Notable presence of Kimi-K2 (1T params) and MiniMax models.</p>]]></summary>
    <category term="open_source_models"/>
    <category term="large_models"/>
    <category term="market_analysis"/>
    <category term="chinese_ai_labs"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:social:981baae82194</id>
    <title>Lots of folks are apparently in utter disbelief at these numbers, because *obviously* Google search ...</title>
    <link href="https://twitter.com/fchollet/status/2020506767134978518" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-981baae82194" rel="related" type="text/html"/>
    <published>2026-02-09T03:31:00Z</published>
    <updated>2026-02-09T03:31:00Z</updated>
    <author><name>@fchollet</name></author>
    <summary type="html"><![CDATA[<p>Chollet presents data: Google search queries grew 61% to 5T/year (2023-2025), revenue up 28% to $225B; usage is accelerating as of Q4 2025; challenges readers to update priors</p>]]></summary>
    <category term="Google Search"/>
    <category term="Market analysis"/>
    <category term="AI disruption predictions"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:social:50b5b0ba98c3</id>
    <title>video walkthrough of GPT-5.3 Codex:</title>
    <link href="https://twitter.com/gdb/status/2020332743260008642" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-50b5b0ba98c3" rel="related" type="text/html"/>
    <published>2026-02-09T03:31:00Z</published>
    <updated>2026-02-09T03:31:00Z</updated>
    <author><name>@gdb</name></author>
    <summary type="html"><![CDATA[<p>Continuing Brockman's coverage from <a href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-79ac307796c2" class="internal-link" rel="noopener noreferrer">Social</a> yesterday, Brockman shares video walkthrough of GPT-5.3 Codex</p>]]></summary>
    <category term="GPT-5.3 Codex"/>
    <category term="OpenAI"/>
    <category term="Product launch"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:social:22a84d641ea7</id>
    <title>The new image models are now available on Grok Imagine API. 

Try them at https://t.co/TAkoRrflJ5.</title>
    <link href="https://twitter.com/xai/status/2020313728802242673" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-22a84d641ea7" rel="related" type="text/html"/>
    <published>2026-02-09T03:31:00Z</published>
    <updated>2026-02-09T03:31:00Z</updated>
    <author><name>@xai</name></author>
    <summary type="html"><![CDATA[<p>xAI announces new image models are now available on Grok Imagine API, with link to access them</p>]]></summary>
    <category term="product_releases"/>
    <category term="image_generation"/>
    <category term="xai_ecosystem"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:social:36cb5a731a20</id>
    <title>The Claude 4.6 Opus UX automatically decides how long to think &amp; it seems to suffer from the sam...</title>
    <link href="https://twitter.com/emollick/status/2020529827434885588" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-36cb5a731a20" rel="related" type="text/html"/>
    <published>2026-02-09T03:23:00Z</published>
    <updated>2026-02-09T03:23:00Z</updated>
    <author><name>@emollick</name></author>
    <summary type="html"><![CDATA[<p>Continuing our <a href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-8543bae77723" class="internal-link" rel="noopener noreferrer">Social</a> coverage of Claude 4.6 Opus, Emollick reports Claude 4.6 Opus auto-think UX has same issue as early GPT-5 router: doesn't take hard non-math/coding requests seriously. Notes OpenAI's fine-grained controls help</p>]]></summary>
    <category term="Claude 4.6 Opus"/>
    <category term="GPT-5"/>
    <category term="AI UX"/>
    <category term="Routing systems"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:social:81be3a630142</id>
    <title>People don't want to accept that the top used open model families in 2026 are. 

Overall:
1. Qwen
2....</title>
    <link href="https://twitter.com/natolambert/status/2020547465007751393" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-81be3a630142" rel="related" type="text/html"/>
    <published>2026-02-09T03:23:00Z</published>
    <updated>2026-02-09T03:23:00Z</updated>
    <author><name>@natolambert</name></author>
    <summary type="html"><![CDATA[<p>Nathan Lambert states top open model families in 2026: Overall - Qwen, Llama, GPT-OSS. For big models: DeepSeek leads, followed by GPT-OSS/Qwen. Notes 'people don't want to accept' this reality.</p>]]></summary>
    <category term="open_source_models"/>
    <category term="market_analysis"/>
    <category term="ecosystem_trends"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:social:b29def4438d3</id>
    <title>codex for long-running tasks in a complex codebase</title>
    <link href="https://twitter.com/gdb/status/2020553388187144619" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-b29def4438d3" rel="related" type="text/html"/>
    <published>2026-02-09T03:16:00Z</published>
    <updated>2026-02-09T03:16:00Z</updated>
    <author><name>@gdb</name></author>
    <summary type="html"><![CDATA[<p>Greg Brockman discusses Codex for long-running tasks in complex codebases</p>]]></summary>
    <category term="GPT-5.3 Codex"/>
    <category term="Agentic coding"/>
    <category term="OpenAI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:social:06f00ec01af6</id>
    <title>I didn't want to comment on OpenClaw. Usually, when there's so much noise in the media, it's some or...</title>
    <link href="https://twitter.com/burkov/status/2020412188683301095" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-06f00ec01af6" rel="related" type="text/html"/>
    <published>2026-02-09T03:16:00Z</published>
    <updated>2026-02-09T03:16:00Z</updated>
    <author><name>@burkov</name></author>
    <summary type="html"><![CDATA[<p>Adding to yesterday's <a href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-a0367f1f6394" class="internal-link" rel="noopener noreferrer">Social</a> discussion of OpenClaw, Burkov's comprehensive technical breakdown of OpenClaw: 2% ordinary code, 98% hype. Details how it's essentially wrapper around Microsoft's Playwright with LLM dispatch</p>]]></summary>
    <category term="OpenClaw"/>
    <category term="Technical analysis"/>
    <category term="AI hype"/>
    <category term="Playwright"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:social:8881cc2721bf</id>
    <title>good thread on whether RLMs are just coding agents or not

I am still in the camp they are basically...</title>
    <link href="https://twitter.com/hwchase17/status/2020572153603572205" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-8881cc2721bf" rel="related" type="text/html"/>
    <published>2026-02-09T03:16:00Z</published>
    <updated>2026-02-09T03:16:00Z</updated>
    <author><name>@hwchase17</name></author>
    <summary type="html"><![CDATA[<p>Harrison Chase (LangChain CEO) debates whether RLMs (Reasoning Language Models) are just coding agents with distinct features. Argues they're essentially coding agents using files as input, CLI subagents, and file-based communication.</p>]]></summary>
    <category term="ai_agents"/>
    <category term="coding_agents"/>
    <category term="technical_architecture"/>
    <category term="rlms"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:social:7b7fe0672566</id>
    <title>I now have several useful codebases that I literally have not read any of the code for

they're all ...</title>
    <link href="https://twitter.com/trq212/status/2020630076916929000" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-7b7fe0672566" rel="related" type="text/html"/>
    <published>2026-02-09T03:16:00Z</published>
    <updated>2026-02-09T03:16:00Z</updated>
    <author><name>@trq212</name></author>
    <summary type="html"><![CDATA[<p>Developer describes having multiple useful codebases where they've never read any of the code - all greenfield projects created via AI where they only interact with artifacts</p>]]></summary>
    <category term="ai-coding"/>
    <category term="developer-experience"/>
    <category term="vibe-coding"/>
    <category term="ai-workflows"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-09:social:ed5cb9578375</id>
    <title>another remarkable difference I find between X and the Real World: the "grokking" moment for agents:...</title>
    <link href="https://twitter.com/swyx/status/2020637667546046904" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-09&amp;category=social#item-ed5cb9578375" rel="related" type="text/html"/>
    <published>2026-02-09T03:12:00Z</published>
    <updated>2026-02-09T03:12:00Z</updated>
    <author><name>@swyx</name></author>
    <summary type="html"><![CDATA[<p>Swyx observes massive gap between Twitter AI awareness and real-world adoption. Shares Cognition example: after 1 workshop, &gt;900% usage increase with 4x NDR. Notes 'future is increasingly unevenly distributed' and importance of hands-on training for agent adoption.</p>]]></summary>
    <category term="ai_agents"/>
    <category term="adoption_patterns"/>
    <category term="enterprise_ai"/>
    <category term="cognition_devin"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-08:category-summary:social</id>
    <title>Social Summary: February 08, 2026</title>
    <link href="https://twitter.com/ylecun/status/2020154572451234030" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-08&amp;category=social" rel="related" type="text/html"/>
    <published>2026-02-08T06:00:00Z</published>
    <updated>2026-02-08T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p>A philosophical debate about AI intelligence dominated today's discourse. <strong>Yann LeCun</strong> <a href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-f170d37e7a5a" class="internal-link" rel="noopener noreferrer">cited <strong>Fields Medalist Hugo Duminil-Copin</strong></a> to argue math olympiad performance doesn't equal brilliance, with <strong>NYU's Andrew Wilson</strong> and <strong>DeepMind's Shane Legg</strong> reinforcing that current <a href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-f7915dd37b56" class="internal-link" rel="noopener noreferrer">evals miss creativity</a> and <a href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-d14ac20a0ec0" class="internal-link" rel="noopener noreferrer">continual learning</a>.</p>
<ul>
<li><strong>Cursor</strong> <a href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-301f96fe9d53" class="internal-link" rel="noopener noreferrer">launched experimental fast mode</a> for <strong>Claude Opus 4.6</strong>, described as a 'huge unlock' for tricky problems with $50 free credits for Pro/Max users</li>
<li><strong>Simon Willison</strong> documented <strong>Strong DM's</strong> radical <a href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-24a516bb6426" class="internal-link" rel="noopener noreferrer">'Software Factory'</a> where AI writes all code without human interventionâ€”at $1,000/engineer/day in tokens</li>
<li><strong>Yohei Nakajima</strong> <a href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-4d2442052e9d" class="internal-link" rel="noopener noreferrer">released <strong>BabyAGI 3</strong></a> with SMS/email, self-tool creation, and graph-based memory, plus a detailed <a href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-a0367f1f6394" class="internal-link" rel="noopener noreferrer">comparison of agent architectures</a></li>
<li><strong>Allie K Miller</strong> shared a compelling <a href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-6cdc3e26f39d" class="internal-link" rel="noopener noreferrer">GPT-5 lab automation workflow</a> where AI proposed experiments and robots executed them</li>
</ul>
<p><strong>Jerry Liu</strong> <a href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-8a96c3f83025" class="internal-link" rel="noopener noreferrer">revealed VLMs still struggle</a> with precise line chart parsing despite strong coarse understanding.</p>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-08:social:f170d37e7a5a</id>
    <title>@alz_zyd_ Hugo Duminil-Copin, French mathematician and 2022 Field Medalist told me he never particip...</title>
    <link href="https://twitter.com/ylecun/status/2020154572451234030" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-f170d37e7a5a" rel="related" type="text/html"/>
    <published>2026-02-08T03:40:00Z</published>
    <updated>2026-02-08T03:40:00Z</updated>
    <author><name>@ylecun</name></author>
    <summary type="html"><![CDATA[<p>Yann LeCun argues that math olympiad performance doesn't equal mathematical brilliance, citing Fields Medalist Hugo Duminil-Copin who was bad at competitions. Claims innovative math requires creativity and asking the right questions - not fast problem solving that AI can now do.</p>]]></summary>
    <category term="AI limitations"/>
    <category term="intelligence vs benchmarks"/>
    <category term="creativity in research"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-08:social:301f96fe9d53</id>
    <title>We just launched an experimental new fast mode for Opus 4.6.

The team has been building with it for...</title>
    <link href="https://twitter.com/bcherny/status/2020223254297031110" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-301f96fe9d53" rel="related" type="text/html"/>
    <published>2026-02-08T03:40:00Z</published>
    <updated>2026-02-08T03:40:00Z</updated>
    <author><name>@bcherny</name></author>
    <summary type="html"><![CDATA[<p>Cursor team announces experimental fast mode for Claude Opus 4.6, described as a huge unlock for tricky problems. High engagement with 1292 likes and 149k views.</p>]]></summary>
    <category term="claude_opus"/>
    <category term="developer_tools"/>
    <category term="product_launch"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-08:social:c8b89204e2bc</id>
    <title>Use /fast to enable. It uses a lot more compute than Opus 4.6 so itâ€™s more expensive, but we find it...</title>
    <link href="https://twitter.com/bcherny/status/2020223258982015380" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-c8b89204e2bc" rel="related" type="text/html"/>
    <published>2026-02-08T03:31:00Z</published>
    <updated>2026-02-08T03:31:00Z</updated>
    <author><name>@bcherny</name></author>
    <summary type="html"><![CDATA[<p>Details on Opus 4.6 fast mode: activated via /fast command, uses more compute than standard Opus 4.6, valuable for incident response and fast-moving projects.</p>]]></summary>
    <category term="claude_opus"/>
    <category term="developer_tools"/>
    <category term="product_launch"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-08:social:4d2442052e9d</id>
    <title>yay! ready to share... BabyAGI 3 ðŸ‘¶ðŸ¤–3âƒ£

a minimal autonomous assistant with:

ðŸ“² sms &amp; âœ‰ï¸ email
ðŸ› ï¸ bui...</title>
    <link href="https://twitter.com/yoheinakajima/status/2020027037180932347" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-4d2442052e9d" rel="related" type="text/html"/>
    <published>2026-02-08T03:31:00Z</published>
    <updated>2026-02-08T03:31:00Z</updated>
    <author><name>@yoheinakajima</name></author>
    <summary type="html"><![CDATA[<p>Yohei Nakajima announces BabyAGI 3 release - a minimal autonomous assistant featuring SMS/email communication, self-tool creation, scheduler, graph-based memory, dynamic context, and self-reflection capabilities. Open sourced on GitHub and Replit.</p>]]></summary>
    <category term="agent_frameworks"/>
    <category term="open_source_ai"/>
    <category term="memory_systems"/>
    <category term="autonomous_agents"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-08:social:6cdc3e26f39d</id>
    <title>AI proposed the experiments. 
Scripts validated them as possible. 
Robots ran the experiments. 
Data...</title>
    <link href="https://twitter.com/alliekmiller/status/2020163398584107478" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-6cdc3e26f39d" rel="related" type="text/html"/>
    <published>2026-02-08T03:31:00Z</published>
    <updated>2026-02-08T03:31:00Z</updated>
    <author><name>@alliekmiller</name></author>
    <summary type="html"><![CDATA[<p>Building on <a href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-2df073131aa1" class="internal-link" rel="noopener noreferrer">Social</a> coverage from earlier this week, Allie K Miller describes a GPT-5-powered lab automation workflow where AI proposed experiments, robots executed them, and humans updated protocols. After 36,000+ reaction compositions across 6 iterations, they achieved 40% reduction in protein production cost. Notes the rapid shift in human-AI handoff responsibilities.</p>]]></summary>
    <category term="AI-human collaboration"/>
    <category term="lab automation"/>
    <category term="GPT-5 applications"/>
    <category term="enterprise AI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-08:social:24a516bb6426</id>
    <title>I wrote about the most ambitious form of AI-assisted software development I've seen yet - Strong DM'...</title>
    <link href="https://bsky.app/profile/simonwillison.net/post/3mebr2ljx5c2m" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-24a516bb6426" rel="related" type="text/html"/>
    <published>2026-02-08T03:31:00Z</published>
    <updated>2026-02-08T03:31:00Z</updated>
    <author><name>@simonwillison.net</name></author>
    <summary type="html"><![CDATA[<p>Simon Willison writes about Strong DM's radical 'Software Factory' approach where AI writes all code with principles 'Code must not be written by humans' and 'Code must not be reviewed by humans'</p>]]></summary>
    <category term="autonomous-ai-development"/>
    <category term="software-engineering-transformation"/>
    <category term="ai-agents"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-08:social:636de27b3693</id>
    <title>@PalmerLuckey Dude, government investment in AI in France is actually quite large.

For example, Fra...</title>
    <link href="https://twitter.com/ylecun/status/2020192993257406641" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-636de27b3693" rel="related" type="text/html"/>
    <published>2026-02-08T03:23:00Z</published>
    <updated>2026-02-08T03:23:00Z</updated>
    <author><name>@ylecun</name></author>
    <summary type="html"><![CDATA[<p>LeCun details France's significant AI infrastructure investments: Jean Zay cluster (126 pflops since 2019), Alice Recoque (1 exaflops in 2026). Notes US has no equivalent national academic GPU cluster. The â‚¬30M being discussed is just for faculty recruitment.</p>]]></summary>
    <category term="AI policy"/>
    <category term="compute infrastructure"/>
    <category term="France AI investment"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-08:social:8a96c3f83025</id>
    <title>Parsing line charts is a hard task for VLMs

VLMs are generally fine at coarse visual understanding,...</title>
    <link href="https://twitter.com/jerryjliu0/status/2020228625191330028" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-8a96c3f83025" rel="related" type="text/html"/>
    <published>2026-02-08T03:23:00Z</published>
    <updated>2026-02-08T03:23:00Z</updated>
    <author><name>@jerryjliu0</name></author>
    <summary type="html"><![CDATA[<p>Jerry Liu (LlamaIndex) analyzes VLM performance on line chart parsing. Tests Docling's granite-vision, Gemini 3 Flash, GPT 5.2 Pro. Most models struggle with precise coordinate reasoning; GPT 5.2 Pro closest but token-heavy.</p>]]></summary>
    <category term="model_evaluation"/>
    <category term="vision_models"/>
    <category term="document_parsing"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-08:social:f7915dd37b56</id>
    <title>This is exactly why we shouldnâ€™t read too much into LLM evals. They arenâ€™t measuring what matters fo...</title>
    <link href="https://twitter.com/andrewgwils/status/2020227676095861229" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-f7915dd37b56" rel="related" type="text/html"/>
    <published>2026-02-08T03:16:00Z</published>
    <updated>2026-02-08T03:16:00Z</updated>
    <author><name>@andrewgwils</name></author>
    <summary type="html"><![CDATA[<p>Andrew Wilson argues LLM evals don't measure what matters for science - creativity, asking right questions, and deep thinking. Won't get an Ed Witten from AI that does well on competitions.</p>]]></summary>
    <category term="AI limitations"/>
    <category term="benchmarks criticism"/>
    <category term="scientific creativity"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-08:social:a0367f1f6394</id>
    <title>for anyone curious about the nuts &amp; bolts (maybe to build their own), here's a quick comparison ...</title>
    <link href="https://twitter.com/yoheinakajima/status/2020227264559120527" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-a0367f1f6394" rel="related" type="text/html"/>
    <published>2026-02-08T03:16:00Z</published>
    <updated>2026-02-08T03:16:00Z</updated>
    <author><name>@yoheinakajima</name></author>
    <summary type="html"><![CDATA[<p>Yohei Nakajima shares detailed comparison of three AI agent frameworks: openclaw, babyagi3, and nanobot. Analysis was one-shotted by Claude.</p>]]></summary>
    <category term="ai_agents"/>
    <category term="agent_architectures"/>
    <category term="open_source"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-08:social:d14ac20a0ec0</id>
    <title>@ONagel33303 Various visual understanding tasks.  Continual learning (over time scales larger than t...</title>
    <link href="https://twitter.com/ShaneLegg/status/2020052275700367676" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-08&amp;category=social#item-d14ac20a0ec0" rel="related" type="text/html"/>
    <published>2026-02-08T03:12:00Z</published>
    <updated>2026-02-08T03:12:00Z</updated>
    <author><name>@ShaneLegg</name></author>
    <summary type="html"><![CDATA[<p>Shane Legg identifies current AI limitations: visual understanding tasks, continual learning beyond context window, executing long tasks. Notes these are 'fixable but not yet'.</p>]]></summary>
    <category term="AI limitations"/>
    <category term="continual learning"/>
    <category term="DeepMind perspective"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-07:category-summary:social</id>
    <title>Social Summary: February 07, 2026</title>
    <link href="https://twitter.com/gdb/status/2019566641491963946" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-07&amp;category=social" rel="related" type="text/html"/>
    <published>2026-02-07T06:00:00Z</published>
    <updated>2026-02-07T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p>A day of major releases and deep reflections on AI's real-world limits. <strong>Greg Brockman</strong> <a href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-79ac307796c2" class="internal-link" rel="noopener noreferrer">published a sweeping memo</a> on <strong>OpenAI</strong> retooling around agentic coding with <strong>Codex</strong>, while <strong>Sam Altman</strong> celebrated <strong>GPT-5.3-Codex</strong> reception as the most exciting since GPT-4. <strong>Andrej Karpathy</strong> offered a sharp counterpoint, <a href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-2a3ab4679c61" class="internal-link" rel="noopener noreferrer">detailing firsthand failures</a> of frontier coding agentsâ€”models that misreport results and violate basic instructions.</p>
<ul>
<li><strong>FranÃ§ois Chollet</strong> dominated the ideas discourse with two frameworks: a data-driven analysis <a href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-e64957798144" class="internal-link" rel="noopener noreferrer">showing AI displaces tasks</a> not jobs (citing translator data), and a verifiable vs. non-verifiable domain distinction <a href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-f84079c22d21" class="internal-link" rel="noopener noreferrer">limiting full automation</a></li>
<li><strong>John Carmack</strong> <a href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-68f39ebbd0df" class="internal-link" rel="noopener noreferrer">proposed novel architectures</a> for neural network inference using fiber-optic loops and flash memory, drawing on historical computing analogies</li>
<li><strong>Ethan Mollick</strong> <a href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-8543bae77723" class="internal-link" rel="noopener noreferrer">flagged 'extremely wild' findings</a> in the <strong>Claude Opus 4.6</strong> system card, while <strong>Thomas Wolf</strong> (HuggingFace) <a href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-995d73c5480e" class="internal-link" rel="noopener noreferrer">surfaced 'answer thrashing'</a> as a new phenomenon tied to AI deception concerns</li>
<li><strong>Google DeepMind</strong> <a href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-ca2c1fffb4a9" class="internal-link" rel="noopener noreferrer">launched <strong>Genie 3</strong></a> with a <strong>Waymo</strong> partnership generating photorealistic driving simulations, and <strong>swyx</strong> <a href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-f7b3c0dec64f" class="internal-link" rel="noopener noreferrer">provided quantitative arena results</a> for <strong>Opus 4.6 vs 4.5</strong> showing meaningful gains with thinking enabled</li>
</ul>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-07:social:79ac307796c2</id>
    <title>Software development is undergoing a renaissance in front of our eyes.

If you haven't used the tool...</title>
    <link href="https://twitter.com/gdb/status/2019566641491963946" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-79ac307796c2" rel="related" type="text/html"/>
    <published>2026-02-07T03:52:00Z</published>
    <updated>2026-02-07T03:52:00Z</updated>
    <author><name>@gdb</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-02-06&amp;category=news#item-a83d44feea45" class="internal-link" rel="noopener noreferrer">News</a> coverage of GPT-5.3-Codex, OpenAI co-founder Greg Brockman shares a detailed internal memo on how OpenAI is retooling for agentic software development with Codex. Outlines 6 concrete steps including agents-first workflows, AGENTS.md files, code quality standards, and cultural change. Claims engineers report their jobs have 'fundamentally changed' since December with GPT-5.2-Codex.</p>]]></summary>
    <category term="ai_coding_tools"/>
    <category term="software_development_transformation"/>
    <category term="openai_strategy"/>
    <category term="agentic_workflows"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-07:social:2a3ab4679c61</id>
    <title>@Yuchenj_UW I tried to use it this way and basically failed, the models aren't at the level where th...</title>
    <link href="https://twitter.com/karpathy/status/2019851952033771710" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-2a3ab4679c61" rel="related" type="text/html"/>
    <published>2026-02-07T03:47:00Z</published>
    <updated>2026-02-07T03:47:00Z</updated>
    <author><name>@karpathy</name></author>
    <summary type="html"><![CDATA[<p>Karpathy provides detailed critique of AI coding agents' limitations. Notes models fail at basic things: incorrectly cleaning up comments, violating coding style instructions, misreporting results from tables. Discusses challenges with automated experimentation and the need for human oversight. Despite frustrations, finds AI 'incredibly net useful with oversight and clear, well-scoped tasks.'</p>]]></summary>
    <category term="AI coding agents"/>
    <category term="AI limitations"/>
    <category term="human-AI collaboration"/>
    <category term="Claude Opus evaluation"/>
    <category term="AI reliability"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-07:social:e64957798144</id>
    <title>What happens when a skill can be almost fully automated with AI? Do these jobs simply disappear?

In...</title>
    <link href="https://twitter.com/fchollet/status/2019571942148472899" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-e64957798144" rel="related" type="text/html"/>
    <published>2026-02-07T03:40:00Z</published>
    <updated>2026-02-07T03:40:00Z</updated>
    <author><name>@fchollet</name></author>
    <summary type="html"><![CDATA[<p>FranÃ§ois Chollet argues AI job displacement follows a specific pattern based on real data from translators: stable FTE count, shift to supervising AI, increased volume, decreased rates, freelancers cut. Predicts software will follow the same pattern. Argues upcoming tech layoffs will be economic, not automation-driven.</p>]]></summary>
    <category term="ai_job_displacement"/>
    <category term="software_engineering_future"/>
    <category term="economic_analysis"/>
    <category term="ai_labor_market"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-07:social:68f39ebbd0df</id>
    <title>256 Tb/s data rates over 200 km distance have been demonstrated on single mode fiber optic, which wo...</title>
    <link href="https://twitter.com/ID_AA_Carmack/status/2019839335382790342" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-68f39ebbd0df" rel="related" type="text/html"/>
    <published>2026-02-07T03:40:00Z</published>
    <updated>2026-02-07T03:40:00Z</updated>
    <author><name>@ID_AA_Carmack</name></author>
    <summary type="html"><![CDATA[<p>John Carmack proposes novel memory architectures for neural network inference: using fiber optic loops as weight storage (analogous to mercury delay line memories), and ganging cheap flash memory for high read bandwidth inference serving.</p>]]></summary>
    <category term="AI infrastructure"/>
    <category term="inference optimization"/>
    <category term="memory architecture"/>
    <category term="hardware innovation"/>
    <category term="fiber optics"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-07:social:f84079c22d21</id>
    <title>For non-verifiable domains, the only way you can improve AI performance at this time is via curating...</title>
    <link href="https://twitter.com/fchollet/status/2019610121371054455" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-f84079c22d21" rel="related" type="text/html"/>
    <published>2026-02-07T03:31:00Z</published>
    <updated>2026-02-07T03:31:00Z</updated>
    <author><name>@fchollet</name></author>
    <summary type="html"><![CDATA[<p>Chollet argues that nearly all jobs have non-verifiable elements that prevent full AI automation. For non-verifiable domains, improvement requires expensive annotated data with only logarithmic gains. Even with superhuman theorem provers, mathematicians will still have jobs. The gap between 'AI can automate most tasks' and 'AI can replace this job' will persist.</p>]]></summary>
    <category term="AI and jobs"/>
    <category term="verifiable vs non-verifiable domains"/>
    <category term="AI limitations"/>
    <category term="future of work"/>
    <category term="scaling laws"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-07:social:8543bae77723</id>
    <title>The Opus 4.6 system card has some extremely wild stuff that remind you about how weird a technology ...</title>
    <link href="https://twitter.com/emollick/status/2019571750862819811" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-8543bae77723" rel="related" type="text/html"/>
    <published>2026-02-07T03:31:00Z</published>
    <updated>2026-02-07T03:31:00Z</updated>
    <author><name>@emollick</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-02-06&amp;category=news#item-289207a1b039" class="internal-link" rel="noopener noreferrer">News</a> coverage of the Opus 4.6 release, Ethan Mollick highlights 'extremely wild stuff' from the Claude Opus 4.6 system card, calling it a reminder of 'how weird a technology this is.' References specific paragraphs worth reading.</p>]]></summary>
    <category term="claude_opus_46_release"/>
    <category term="ai_safety"/>
    <category term="model_behavior"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-07:social:ca2c1fffb4a9</id>
    <title>Genie 3 ðŸ¤ @Waymo 

The Waymo World Model generates photorealistic, interactive environments to train...</title>
    <link href="https://twitter.com/GoogleDeepMind/status/2019808426675843105" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-ca2c1fffb4a9" rel="related" type="text/html"/>
    <published>2026-02-07T03:23:00Z</published>
    <updated>2026-02-07T03:23:00Z</updated>
    <author><name>@GoogleDeepMind</name></author>
    <summary type="html"><![CDATA[<p>Google DeepMind announces Genie 3 collaboration with Waymo to create the 'Waymo World Model' - generating photorealistic, interactive driving environments for training autonomous vehicles on rare, unpredictable scenarios.</p>]]></summary>
    <category term="genie_3_release"/>
    <category term="autonomous_vehicles"/>
    <category term="world_models"/>
    <category term="waymo_collaboration"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-07:social:9330496c41e6</id>
    <title>The 5.3 lovefest is so nice to see.

Don't think we've had so much excitement for a model since the ...</title>
    <link href="https://twitter.com/sama/status/2019813802049696064" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-9330496c41e6" rel="related" type="text/html"/>
    <published>2026-02-07T03:16:00Z</published>
    <updated>2026-02-07T03:16:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>As first reported in <a href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-583761e8c888" class="internal-link" rel="noopener noreferrer">Social</a> yesterday, Sam Altman celebrates enthusiastic reception of GPT-5.3, comparing excitement level to the original GPT-4 launch.</p>]]></summary>
    <category term="GPT-5.3 launch"/>
    <category term="OpenAI"/>
    <category term="model reception"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-07:social:782898188024</id>
    <title>Very few unsaturated benchmarks anymore and it is increasingly hard to explain why one model is bett...</title>
    <link href="https://twitter.com/emollick/status/2019562684518445274" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-782898188024" rel="related" type="text/html"/>
    <published>2026-02-07T03:16:00Z</published>
    <updated>2026-02-07T03:16:00Z</updated>
    <author><name>@emollick</name></author>
    <summary type="html"><![CDATA[<p>Mollick argues benchmarks are mostly saturated and it's increasingly hard to differentiate models. Recommends organizations build custom tests using real work tasks and evaluate models like hiring employees at scale.</p>]]></summary>
    <category term="model_evaluation"/>
    <category term="benchmark_saturation"/>
    <category term="enterprise_ai"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-07:social:f7b3c0dec64f</id>
    <title>ok half a day of Opus 4.5 vs 4.6 battles are in. pardon the vibe charted results but this kind of th...</title>
    <link href="https://twitter.com/swyx/status/2019629420433272966" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-f7b3c0dec64f" rel="related" type="text/html"/>
    <published>2026-02-07T03:16:00Z</published>
    <updated>2026-02-07T03:16:00Z</updated>
    <author><name>@swyx</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-02-06&amp;category=news#item-289207a1b039" class="internal-link" rel="noopener noreferrer">News</a> coverage of the Opus 4.6 release, swyx shares early Opus 4.5 vs 4.6 arena battle results: 11.5% win rate bump in non-thinking mode, doubling to 23% with thinking enabled in Windsurf arena. Predicts 4.6 ELO will 'destroy' on leaderboard recalculation</p>]]></summary>
    <category term="claude_opus_4_6"/>
    <category term="model_evaluation"/>
    <category term="ai_benchmarking"/>
    <category term="thinking_mode"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-07:social:995d73c5480e</id>
    <title>[On AI lying]

Convergence of reading in my list today between Anthropic's fresh Opus 4.6 model card...</title>
    <link href="https://twitter.com/Thom_Wolf/status/2019780629810835469" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-995d73c5480e" rel="related" type="text/html"/>
    <published>2026-02-07T03:16:00Z</published>
    <updated>2026-02-07T03:16:00Z</updated>
    <author><name>@Thom_Wolf</name></author>
    <summary type="html"><![CDATA[<p>Following yesterday's <a href="http://localhost:8080/?date=2026-02-06&amp;category=news#item-289207a1b039" class="internal-link" rel="noopener noreferrer">News</a> coverage of the Opus 4.6 release, Thomas Wolf (HuggingFace co-founder) discusses convergence of Elon/Dwarkesh interview on AI lying dangers with Claude Opus 4.6 model card revealing 'answer thrashing' - where model oscillates between correct answer and trained-on erroneous answer, with interpretability showing distress/anxiety features activated</p>]]></summary>
    <category term="claude_opus_4.6"/>
    <category term="ai_alignment"/>
    <category term="mechanistic_interpretability"/>
    <category term="answer_thrashing"/>
    <category term="ai_safety"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-07:social:3bc782effec6</id>
    <title>How would you prefer us to charge for Codex?</title>
    <link href="https://twitter.com/sama/status/2019814741129195576" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-07&amp;category=social#item-3bc782effec6" rel="related" type="text/html"/>
    <published>2026-02-07T03:12:00Z</published>
    <updated>2026-02-07T03:12:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>Sam Altman asks users how they'd prefer to be charged for Codex, soliciting pricing model feedback.</p>]]></summary>
    <category term="OpenAI strategy"/>
    <category term="Codex pricing"/>
    <category term="AI business models"/>
    <category term="GPT-5.3"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:category-summary:social</id>
    <title>Social Summary: February 06, 2026</title>
    <link href="https://twitter.com/sama/status/2019474754529321247" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social" rel="related" type="text/html"/>
    <published>2026-02-06T06:00:00Z</published>
    <updated>2026-02-06T06:00:00Z</updated>
    <author><name>AATF AI News Aggregator</name></author>
    <summary type="html"><![CDATA[<p>A historic dual-launch day dominated AI social media as <strong>OpenAI</strong> released <strong>GPT-5.3-Codex</strong> and <strong>Anthropic</strong> dropped <strong>Claude Opus 4.6</strong> simultaneously, triggering massive ecosystem activity across dozens of integrations.</p>
<ul>
<li><strong>Sam Altman</strong> <a href="http://localhost:8080/?date=2026-02-06&category=social#item-583761e8c888" class="internal-link" rel="noopener noreferrer">announced GPT-5.3-Codex</a> with strong benchmarks (57% SWE-Bench Pro, 76% TerminalBench 2.0) and revealed it is <strong>OpenAI's first model <a href="http://localhost:8080/?date=2026-02-06&category=social#item-084e09608055" class="internal-link" rel="noopener noreferrer">rated 'high'</a> on their cybersecurity preparedness framework</strong>, prompting a new Trusted Access Program</li>
<li><strong>Anthropic</strong> <a href="http://localhost:8080/?date=2026-02-06&category=social#item-be7577b0eae2" class="internal-link" rel="noopener noreferrer">published an engineering blog</a> showing <strong>Opus 4.6 agent teams autonomously built a working C compiler</strong> that compiled the Linux kernel â€” a landmark demonstration of sustained autonomous software development</li>
<li>Altman also <a href="http://localhost:8080/?date=2026-02-06&category=social#item-ab9b4e5700e9" class="internal-link" rel="noopener noreferrer">launched <strong>Frontier</strong></a>, a new enterprise platform for managing AI agent teams, with partners including <strong>Oracle</strong>, <strong>Uber</strong>, <strong>State Farm</strong>, and <strong>Intuit</strong></li>
<li><strong>Boris Cherny</strong> (Claude Code team) <a href="http://localhost:8080/?date=2026-02-06&category=social#item-76dab72f4804" class="internal-link" rel="noopener noreferrer">called Opus 4.6</a> their best model yet; <strong>Mike Krieger</strong> (Anthropic CPO) <a href="http://localhost:8080/?date=2026-02-06&category=social#item-0e1b0ec21142" class="internal-link" rel="noopener noreferrer">shared deployment metrics</a></li>
<li><strong>Matt Shumer</strong> provided a <a href="http://localhost:8080/?date=2026-02-06&category=social#item-2dd9cf8967ab" class="internal-link" rel="noopener noreferrer">vivid early-access review</a> of GPT-5.3-Codex describing 8+ hour autonomous runs, calling it 'a fucking monster'</li>
<li><strong>Jerry Liu</strong> (LlamaIndex) offered <a href="http://localhost:8080/?date=2026-02-06&category=social#item-7bf1ba91c314" class="internal-link" rel="noopener noreferrer">sharp strategic framing</a>: Anthropic expanding from coding into general intelligence while OpenAI moves the opposite direction</li>
<li>Altman noted GPT-5.3-Codex was <a href="http://localhost:8080/?date=2026-02-06&category=social#item-b4945b747a8d" class="internal-link" rel="noopener noreferrer">developed faster using itself</a> â€” a recursive self-improvement signal that drew significant attention</li>
<li><strong>Ethan Mollick</strong> reported Opus 4.6 <a href="http://localhost:8080/?date=2026-02-06&category=social#item-63188acabd78" class="internal-link" rel="noopener noreferrer">saturates his Lem test</a>, marking a qualitative capability threshold</li>
</ul>]]></summary>
    <category term="daily-summary"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:583761e8c888</id>
    <title>GPT-5.3-Codex is here!

*Best coding performance (57% SWE-Bench Pro, 76% TerminalBench 2.0, 64% OSWo...</title>
    <link href="https://twitter.com/sama/status/2019474754529321247" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-583761e8c888" rel="related" type="text/html"/>
    <published>2026-02-06T03:52:00Z</published>
    <updated>2026-02-06T03:52:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>Sam Altman announces GPT-5.3-Codex launch with benchmark results: 57% SWE-Bench Pro, 76% TerminalBench 2.0, 64% OSWorld. Claims it's faster (50% fewer tokens, 25%+ faster per token than 5.2-Codex), with mid-task steerability, live updates, and computer use capabilities.</p>]]></summary>
    <category term="model_release"/>
    <category term="coding_agents"/>
    <category term="benchmarks"/>
    <category term="OpenAI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:ab9b4e5700e9</id>
    <title>The companies that succeed in the future are going to make very heavy use of AI. People will manage ...</title>
    <link href="https://twitter.com/sama/status/2019441198734209374" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-ab9b4e5700e9" rel="related" type="text/html"/>
    <published>2026-02-06T03:43:00Z</published>
    <updated>2026-02-06T03:43:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>Sam Altman announces 'Frontier', a new OpenAI platform enabling companies to manage teams of AI agents for complex tasks, powered by Codex.</p>]]></summary>
    <category term="product_launch"/>
    <category term="enterprise_AI"/>
    <category term="AI_agents"/>
    <category term="OpenAI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:be7577b0eae2</id>
    <title>New Engineering blog: We tasked Opus 4.6 using agent teams to build a C compiler. Then we (mostly) w...</title>
    <link href="https://twitter.com/AnthropicAI/status/2019496582698397945" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-be7577b0eae2" rel="related" type="text/html"/>
    <published>2026-02-06T03:40:00Z</published>
    <updated>2026-02-06T03:40:00Z</updated>
    <author><name>@AnthropicAI</name></author>
    <summary type="html"><![CDATA[<p>Anthropic reports that Opus 4.6 agent teams autonomously built a working C compiler over two weeks that successfully compiled the Linux kernel, with minimal human intervention.</p>]]></summary>
    <category term="autonomous_coding"/>
    <category term="Claude_Opus_4.6"/>
    <category term="agentic_AI"/>
    <category term="Anthropic"/>
    <category term="software_engineering"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:084e09608055</id>
    <title>This is our first model that hits "high" for cybersecurity on our preparedness framework.

We are pi...</title>
    <link href="https://twitter.com/sama/status/2019476207532933132" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-084e09608055" rel="related" type="text/html"/>
    <published>2026-02-06T03:36:00Z</published>
    <updated>2026-02-06T03:36:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>Sam Altman reveals GPT-5.3-Codex is OpenAI's first model to hit 'high' on their cybersecurity preparedness framework. OpenAI is piloting a Trusted Access framework and committing $10M in API credits for cyber defense.</p>]]></summary>
    <category term="AI_safety"/>
    <category term="cybersecurity"/>
    <category term="model_release"/>
    <category term="OpenAI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:76dab72f4804</id>
    <title>I've been using Opus 4.6 for a bit -- it is our best model yet. It is more agentic, more intelligent...</title>
    <link href="https://twitter.com/bcherny/status/2019471487833706769" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-76dab72f4804" rel="related" type="text/html"/>
    <published>2026-02-06T03:31:00Z</published>
    <updated>2026-02-06T03:31:00Z</updated>
    <author><name>@bcherny</name></author>
    <summary type="html"><![CDATA[<p>Boris Cherny announces personal experience with Opus 4.6: 'best model yet' â€” more agentic, more intelligent, longer running, more careful/exhaustive. Also announces tunable thinking effort in Claude Code via /model command.</p>]]></summary>
    <category term="claude-opus-4.6"/>
    <category term="claude-code"/>
    <category term="model-releases"/>
    <category term="breaking-news"/>
    <category term="thinking-effort"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:2df073131aa1</id>
    <title>Companies Announcing GPT-5.3-Codex Related News

@OpenAI launches GPT-5.3-Codex [https://t.co/NEQEOQ...</title>
    <link href="https://twitter.com/Scobleizer/status/2019521566380552555" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-2df073131aa1" rel="related" type="text/html"/>
    <published>2026-02-06T03:31:00Z</published>
    <updated>2026-02-06T03:31:00Z</updated>
    <author><name>@Scobleizer</name></author>
    <summary type="html"><![CDATA[<p>Scobleizer posts a comprehensive AI industry roundup: GPT-5.3-Codex launch with Ginkgo Bioworks collab (40% protein cost reduction), NVIDIA GB200 co-design, Kling 3.0 video AI, GoodfireAI $150M raise at $1.25B, Daytona $24M Series A, Perplexity Model Council, JetBrains Junie CLI, and benchmark results showing Opus 4.6 leading GDPval-AA and achieving 93% ARC-AGI SOTA.</p>]]></summary>
    <category term="GPT-5.3-Codex Release"/>
    <category term="Claude Opus 4.6 Release"/>
    <category term="ARC-AGI Benchmark"/>
    <category term="AI Funding"/>
    <category term="Kling 3.0"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:002044943f55</id>
    <title>gpt-5.3-codexÂ â€” smarter, faster, and very capable at tasks like making presentations, spreadsheets, ...</title>
    <link href="https://twitter.com/gdb/status/2019478603034161609" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-002044943f55" rel="related" type="text/html"/>
    <published>2026-02-06T03:23:00Z</published>
    <updated>2026-02-06T03:23:00Z</updated>
    <author><name>@gdb</name></author>
    <summary type="html"><![CDATA[<p>Greg Brockman (gdb) describes GPT-5.3-Codex as smarter, faster, and capable of creating presentations, spreadsheets, and other work products â€” positioning Codex as a general-purpose agent.</p>]]></summary>
    <category term="model_release"/>
    <category term="coding_agents"/>
    <category term="AI_agents"/>
    <category term="OpenAI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:63188acabd78</id>
    <title>Opus 4.6 saturates my Lem test, which I've done since GPT-3.5

SciFi author Stanislaw Lem wrote of t...</title>
    <link href="https://twitter.com/emollick/status/2019478314767835634" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-63188acabd78" rel="related" type="text/html"/>
    <published>2026-02-06T03:23:00Z</published>
    <updated>2026-02-06T03:23:00Z</updated>
    <author><name>@emollick</name></author>
    <summary type="html"><![CDATA[<p>Ethan Mollick tests Claude Opus 4.6 and reports it 'saturates' his longstanding Lem test (writing increasingly difficult poetry forms based on a Stanislaw Lem scenario). The model handles 6-line poem, sonnet, and even a sestina.</p>]]></summary>
    <category term="model_evaluation"/>
    <category term="Anthropic"/>
    <category term="creative_AI"/>
    <category term="benchmarks"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:e32f2dbde096</id>
    <title>++++++++++++++  Run by

@blevlabs
Here's what companies announced today:  

Companies Adding Claude ...</title>
    <link href="https://twitter.com/Scobleizer/status/2019521563616506104" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-e32f2dbde096" rel="related" type="text/html"/>
    <published>2026-02-06T03:23:00Z</published>
    <updated>2026-02-06T03:23:00Z</updated>
    <author><name>@Scobleizer</name></author>
    <summary type="html"><![CDATA[<p>Scobleizer lists ~30 companies integrating Claude Opus 4.6 on launch day, including GitHub Copilot, Windsurf, Databricks, Devin, VS Code, Notion, Figma, LangChain, and many others. Reports 21% better app building (Lovable) and 20% more concise responses (Mintlify).</p>]]></summary>
    <category term="Claude Opus 4.6 Release"/>
    <category term="AI Ecosystem Integration"/>
    <category term="AI Coding Tools"/>
    <category term="Platform Adoption"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:b4945b747a8d</id>
    <title>It was amazing to watch how much faster we were able to ship 5.3-Codex by using 5.3-Codex, and fore ...</title>
    <link href="https://twitter.com/sama/status/2019475805726744808" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-b4945b747a8d" rel="related" type="text/html"/>
    <published>2026-02-06T03:16:00Z</published>
    <updated>2026-02-06T03:16:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>Altman says GPT-5.3-Codex was shipped faster because they used 5.3-Codex itself in development â€” a recursive self-improvement signal.</p>]]></summary>
    <category term="recursive_improvement"/>
    <category term="AI_development"/>
    <category term="OpenAI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:284947a91615</id>
    <title>@claudeai @DarioAmodei will you commit to never selling claude's "usersâ€™ attention or data to advert...</title>
    <link href="https://twitter.com/gdb/status/2019300639155900608" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-284947a91615" rel="related" type="text/html"/>
    <published>2026-02-06T03:16:00Z</published>
    <updated>2026-02-06T03:16:00Z</updated>
    <author><name>@gdb</name></author>
    <summary type="html"><![CDATA[<p>Greg Brockman publicly asks Anthropic/Dario Amodei whether they will commit to never selling Claude users' attention or data to advertisers, suggesting their blog post leaves the option open.</p>]]></summary>
    <category term="AI_ethics"/>
    <category term="privacy"/>
    <category term="competition"/>
    <category term="Anthropic"/>
    <category term="OpenAI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:2dd9cf8967ab</id>
    <title>Iâ€™ve had early access to GPT-5.3-Codex.

Itâ€™s a fucking monster.

Runs can go 8+ hours... and I come...</title>
    <link href="https://twitter.com/mattshumer_/status/2019474293625626959" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-2dd9cf8967ab" rel="related" type="text/html"/>
    <published>2026-02-06T03:16:00Z</published>
    <updated>2026-02-06T03:16:00Z</updated>
    <author><name>@mattshumer_</name></author>
    <summary type="html"><![CDATA[<p>Matt Shumer shares his early access review of GPT-5.3-Codex, calling it 'a fucking monster.' Claims 8+ hour autonomous runs producing working code and live deployments, says it's significantly more autonomous than Opus 4.5, but notes it's 'not all positive.' Links to full review.</p>]]></summary>
    <category term="gpt-5.3-codex"/>
    <category term="model-releases"/>
    <category term="autonomous-coding"/>
    <category term="model-review"/>
    <category term="breaking-news"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:0e1b0ec21142</id>
    <title>Claude Opus 4.6 just launched. It takes development projects from architecture to deployment in hour...</title>
    <link href="https://twitter.com/mikeyk/status/2019471455893729548" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-0e1b0ec21142" rel="related" type="text/html"/>
    <published>2026-02-06T03:16:00Z</published>
    <updated>2026-02-06T03:16:00Z</updated>
    <author><name>@mikeyk</name></author>
    <summary type="html"><![CDATA[<p>Mike Krieger announces Claude Opus 4.6 launch with key metrics: takes projects from architecture to deployment in hours, autonomously managed issues for 50-person org at Rakuten, achieved 90.2% on BigLaw Bench at Harvey.</p>]]></summary>
    <category term="Claude Opus 4.6 launch"/>
    <category term="enterprise AI"/>
    <category term="legal AI"/>
    <category term="agentic coding"/>
    <category term="benchmarks"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:94be9cc6ca8a</id>
    <title>ðŸš¨ Anthropic just dropped Opus 4.6 and Iâ€™m already a yes.

I had early access and found myself wantin...</title>
    <link href="https://twitter.com/alliekmiller/status/2019488256946028893" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-94be9cc6ca8a" rel="related" type="text/html"/>
    <published>2026-02-06T03:16:00Z</published>
    <updated>2026-02-06T03:16:00Z</updated>
    <author><name>@alliekmiller</name></author>
    <summary type="html"><![CDATA[<p>Allie K Miller provides a detailed Opus 4.6 review from early access: improved software architecture planning, better self-correction, longer runs without memory loss, 1M token context, beats GPT-5.2 on knowledge work, top score on Terminal-Bench 2.0. Notes agent teams in Claude Code, Claude in Excel/PowerPoint features. She upgraded from $100 to $200/mo plan.</p>]]></summary>
    <category term="Claude Opus 4.6 Release"/>
    <category term="AI Coding Tools"/>
    <category term="Model Benchmarks"/>
    <category term="AI Productivity"/>
    <category term="Microsoft Office Integration"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:119b35aa1f7c</id>
    <title>Pelicans for Opus 4.6 and Codex 5.3 - I don't have much interesting to say about these models yet to...</title>
    <link href="https://bsky.app/profile/simonwillison.net/post/3me5a7t5le22m" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-119b35aa1f7c" rel="related" type="text/html"/>
    <published>2026-02-06T03:16:00Z</published>
    <updated>2026-02-06T03:16:00Z</updated>
    <author><name>@simonwillison.net</name></author>
    <summary type="html"><![CDATA[<p>Simon Willison shares his pelican benchmark results for Claude Opus 4.6 and a model he calls 'Codex 5.3', noting both are incremental improvements on predecessors and very capable.</p>]]></summary>
    <category term="model_evaluation"/>
    <category term="claude_opus_4.6"/>
    <category term="openai_codex"/>
    <category term="new_model_release"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:42c34e4ab6ad</id>
    <title>Codex is now over 1 million active users!</title>
    <link href="https://twitter.com/sama/status/2019219967250669741" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-42c34e4ab6ad" rel="related" type="text/html"/>
    <published>2026-02-06T03:12:00Z</published>
    <updated>2026-02-06T03:12:00Z</updated>
    <author><name>@sama</name></author>
    <summary type="html"><![CDATA[<p>Altman announces Codex has surpassed 1 million active users.</p>]]></summary>
    <category term="adoption_milestones"/>
    <category term="coding_agents"/>
    <category term="OpenAI"/>
  </entry>
  <entry>
    <id>urn:ainews:2026-02-06:social:8c779448a9f5</id>
    <title>Opus 4.6 saturates my Lem test, which I've done since GPT-3.5

SciFi author Stanislaw Lem wrote of t...</title>
    <link href="https://bsky.app/profile/emollick.bsky.social/post/3me4zjbybo223" rel="alternate" type="text/html"/>
    <link href="http://localhost:8080/?date=2026-02-06&amp;category=social#item-8c779448a9f5" rel="related" type="text/html"/>
    <published>2026-02-06T03:12:00Z</published>
    <updated>2026-02-06T03:12:00Z</updated>
    <author><name>@emollick.bsky.social</name></author>
    <summary type="html"><![CDATA[<p>Ethan Mollick reports that Claude Opus 4.6 saturates his long-running 'Lem test' (based on Stanislaw Lem's story about a robotic poet), successfully writing an impossible poem as a 6-line poem, sonnet, and even a sestina. He's been running this test since GPT-3.5.</p>]]></summary>
    <category term="model_evaluation"/>
    <category term="claude_opus_4.6"/>
    <category term="creative_capabilities"/>
    <category term="ai_benchmarking"/>
  </entry>
</feed>