<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gardener Technical Report</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, monospace;
            line-height: 1.7;
            color: #1a1a1a;
            max-width: 800px;
            margin: 0 auto;
            padding: 40px 20px;
            background: #fafafa;
        }
        header {
            border-bottom: 3px solid #2d2d2d;
            padding-bottom: 20px;
            margin-bottom: 40px;
        }
        h1 {
            font-size: 2em;
            margin-bottom: 10px;
            color: #2d2d2d;
        }
        h2 {
            font-size: 1.4em;
            margin-top: 40px;
            margin-bottom: 15px;
            color: #2d2d2d;
            border-bottom: 1px solid #ddd;
            padding-bottom: 8px;
        }
        h3 {
            font-size: 1.1em;
            margin-top: 25px;
            margin-bottom: 10px;
            color: #444;
        }
        p {
            margin-bottom: 15px;
        }
        a {
            color: #0066cc;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        .meta {
            color: #666;
            font-size: 0.9em;
        }
        ul, ol {
            margin-bottom: 15px;
            padding-left: 25px;
        }
        li {
            margin-bottom: 8px;
        }
        blockquote {
            border-left: 3px solid #ddd;
            margin: 15px 0;
            padding-left: 15px;
            color: #555;
            font-style: italic;
        }
        code {
            background: #e8e8e8;
            padding: 2px 6px;
            border-radius: 3px;
            font-size: 0.9em;
        }
        pre {
            background: #2d2d2d;
            color: #f8f8f8;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-size: 0.85em;
        }
        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 30px 0;
        }
        .nav {
            margin-bottom: 30px;
        }
        .nav a {
            margin-right: 15px;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="nav">
        <a href="index.html">‚Üê All Reports</a>
        <a href="gardener-vibe-coding.html">Vibe Coding</a>
        <a href="gardener-humanoid-robot.html">Humanoid Robots</a>
        <a href="gardener-physical-ai.html">Physical AI</a>
    </div>
<h1>Physical AI & Embodied Intelligence</h1>
<p># Physical AI & Embodied Intelligence</p>
<p><em>Gardener Technical Analysis | 2026-02-13</em></p>
<p><em>This report analyzes 66 curated items with technical depth.</em></p>
<hr>
<p>---</p>
<h2>Executive Synthesis</h2>
<p>## Executive Synthesis</p>
<p>Analysis of 66 sources reveals several technical developments in physical ai.</p>
<h3>Language Models & Architecture</h3>
<p>### Language Models & Architecture</p>
<p><strong>[AINews] Z.ai GLM-5: New SOTA Open Weights LLM</strong></p>
<p><em>Latent.Space</em></p>
<p>Building on yesterday's <a href="/?date=2026-02-12&category=reddit#item-caa559351de6">Reddit</a> coverage, Z.ai launched GLM-5, a new state-of-the-art open-weights LLM with 744B parameters (40B active) trained o...</p>
<p><a href="https://www.latent.space/p/ainews-zai-glm-5-new-sota-open-weights">Source</a></p>
<p><strong>Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment</strong></p>
<p><em>arXiv (Artificial Intelligence)</em></p>
<p>This paper investigates test-time verification as a way to close the gap between intended instructions and generated actions in Vision-Language-Action (VLA) models for robotics. They characterize test...</p>
<p><a href="http://arxiv.org/abs/2602.12281">Source</a></p>
<p><strong>Causal-JEPA: Learning World Models through Object-Level Latent Interventions</strong></p>
<p><em>arXiv (Artificial Intelligence)</em></p>
<p>Proposes C-JEPA, an object-centric world model extending JEPA to object-level representations with masking that induces latent interventions for causal reasoning. Shows gains in visual QA tasks. Autho...</p>
<p><a href="http://arxiv.org/abs/2602.11389">Source</a></p>
<p><strong>Gaia2: Benchmarking LLM Agents on Dynamic and Asynchronous Environments</strong></p>
<p><em>arXiv (Artificial Intelligence)</em></p>
<p>Introduces Gaia2, a benchmark for evaluating LLM agents in dynamic, asynchronous environments where environments evolve independently of agent actions. Includes write-action verifiers for RL training....</p>
<p><a href="http://arxiv.org/abs/2602.11964">Source</a></p>
<p><strong>VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model</strong></p>
<p><em>arXiv (Robotics)</em></p>
<p>VLAW proposes iterative co-improvement of VLA policies and world models through online interaction, using action-conditioned video generation models as learned simulators. Addresses the key challenge...</p>
<p><a href="http://arxiv.org/abs/2602.12063">Source</a></p>
<h3>Robotics & Control</h3>
<p>### Robotics & Control</p>
<p><strong>Accelerating Robotic Reinforcement Learning with Agent Guidance</strong></p>
<p><em>arXiv (Artificial Intelligence)</em></p>
<p>Introduces Agent-guided Policy Search (AGPS) that replaces human supervisors with a multimodal agent for real-world robotic RL training, addressing the scalability bottleneck of human-in-the-loop meth...</p>
<p><a href="http://arxiv.org/abs/2602.11978">Source</a></p>
<p><strong>Weaves Isaac the folding clothes robot is available at $8K to SF Bay Area customers. Promises to tidy a load in 30-90 min with AI and calling teleoperators if complex folds</strong></p>
<p><em>r/singularity</em></p>
<p>Weaves Isaac clothes-folding robot available at $8K for SF Bay Area, folds a load in 30-90 minutes with AI and teleoperator fallback.</p>
<p><a href="https://reddit.com/r/singularity/comments/1r2uo9w/weaves_isaac_the_folding_clothes_robot_is/">Source</a></p>
<p><strong>Multi Graph Search for High-Dimensional Robot Motion Planning</strong></p>
<p><em>arXiv (Artificial Intelligence)</em></p>
<p>Introduces Multi-Graph Search (MGS), a search-based motion planning algorithm that generalizes classical search to a multi-graph setting for high-dimensional robotic systems like manipulators.</p>
<p><a href="http://arxiv.org/abs/2602.12096">Source</a></p>
<p><strong>Human-Like Gaze Behavior in Social Robots: A Deep Learning Approach Integrating Human and Non-Human Stimuli</strong></p>
<p><em>arXiv (Robotics)</em></p>
<p>Studies human-like gaze behavior for social robots using deep learning, including both human and non-human stimuli like conversations, pointing, door openings, and object drops. Addresses the underexp...</p>
<p><a href="http://arxiv.org/abs/2602.11648">Source</a></p>
<p><strong>Chinese #AI-Powered #Robot Revolutionizing Safety in Hazardous Grain #Warehouses</strong></p>
<p><em>Twitter</em></p>
<p>by @tweetciiiim #R... Ronald van Loon shares news about Chinese AI-powered robot revolutionizing safety in hazardous grain warehouses.</p>
<p><a href="https://twitter.com/Ronald_vanLoon/status/2021992225404588086">Source</a></p>
<h3>Other</h3>
<p>### Other</p>
<p><strong>The modern age has richly rewarded people with a combination of high intelligence and high agency. N...</strong></p>
<p><em>Twitter</em></p>
<p>John Carmack argues that AI automation of intelligence will empower people with high agency but lower intelligence, if they trust AI advice. Uses provocative example of a 'ruthless criminal' with alwa...</p>
<p><a href="https://twitter.com/ID_AA_Carmack/status/2022019443547660304">Source</a></p>
<p><strong># A 150-year-old passage from Marx basically describes AGI ‚Äî and a short story called ‚ÄúManna‚Äù shows both possible outcomes</strong></p>
<p><em>r/singularity</em></p>
<p>Discussion connecting a Marx passage from Capital Vol. III to AGI's potential societal impact, referencing the short story 'Manna' as illustrating two possible outcomes of labor displacement by techno...</p>
<p><a href="https://reddit.com/r/singularity/comments/1r2pqcm/a_150yearold_passage_from_marx_basically/">Source</a></p>
<p><strong>AI agents for B2B. Please suggest any masterminds, communities etc</strong></p>
<p><em>r/LocalLLaMA</em></p>
<p>Discussion about whether large context windows are being overused as storage instead of improving retrieval quality, arguing attention is a finite computational budget.</p>
<p><a href="https://reddit.com/r/LocalLLaMA/comments/1r30kyj/ai_agents_for_b2b_please_suggest_any_masterminds/">Source</a></p>
<p><strong>Pack it in: Packing into Partially Filled Containers Through Contact</strong></p>
<p><em>arXiv (Robotics)</em></p>
<p>Presents a contact-aware bin-packing approach for partially filled containers that exploits purposeful interactions with previously placed objects to create free space, unlike traditional collision-fr...</p>
<p><a href="http://arxiv.org/abs/2602.12095">Source</a></p>
<p><strong>My AGI Investment Strategy</strong></p>
<p><em>r/singularity</em></p>
<p>Detailed investment strategy post from someone who quit their job 3 years ago to research AI, sharing portfolio allocation thesis based on AGI timeline predictions.</p>
<p><a href="https://reddit.com/r/singularity/comments/1r3271w/my_agi_investment_strategy/">Source</a></p>
<h3>Safety & Alignment</h3>
<p>### Safety & Alignment</p>
<p><strong>You don't need a Mac Mini to run @OpenClaw.</strong></p>
<p><em>Twitter</em></p>
<p>Use https://t.co/jeP0nebHIv instead. With it you can sa... Scobleizer promotes a cloud hosting service for OpenClaw, an AI agent with full system access. Pitches it as solving setup complexity and sec...</p>
<p><a href="https://twitter.com/Scobleizer/status/2021862295421559158">Source</a></p>
<p><strong>It‚Äôs AI-fornication</strong></p>
<p><em>r/ChatGPT</em></p>
<p>AI-generated parody song 'AI-fornication' in the style of Red Hot Chili Peppers about AI risks.</p>
<p><a href="https://reddit.com/r/ChatGPT/comments/1r33bpl/its_aifornication/">Source</a></p>
<h3>Code Generation & Synthesis</h3>
<p>### Code Generation & Synthesis</p>
<p><strong>I made Cursor work for 44mins at a time, running new automation test cases üëÄ https://t.co/GQn1vH41zr</strong></p>
<p><em>Twitter</em></p>
<p>tdinh_me reports making Cursor run automated test cases for 44 minutes continuously, showcasing extended AI coding agent sessions.</p>
<p><a href="https://twitter.com/tdinh_me/status/2021788077400977731">Source</a></p>
<h3>Learning & Training</h3>
<p>### Learning & Training</p>
<p><strong>Ôº´ÔΩÖÔΩô  Ôº©ÔΩéÔΩìÔΩâÔΩáÔΩàÔΩîÔΩìÔºö</strong></p>
<p><em>Twitter</em></p>
<p>(ùôâùô§ùô©ùôö ùôöùô®ùô•ùôöùôòùôûùôñùô°ùô°ùôÆ ùô©ùôùùôö ùô°ùôñùô®ùô© ùô§ùô£ùôö.) ‚Ä¢ Why driverless train operations require more than ... Kirk Borne shares key insights on driverless train operations, discussing digital twins, predictive availability...</p>
<p><a href="https://twitter.com/KirkDBorne/status/2021985526413242853">Source</a></p>
<h2>Critical Assessment</h2>
<p>## Critical Assessment</p>
<p>Key observations:</p>
<ul>
<li>66 items analyzed from news, research, social, and reddit sources</li>
<li>Themes identified: Language Models & Architecture, Robotics & Control, Other, Safety & Alignment, Code Generation & Synthesis, Learning & Training</li>
<li>See individual sources for detailed methodology and results</li>
</ul>
<h2>References</h2>
<p>## References</p>
<p>1. <a href="https://twitter.com/ID_AA_Carmack/status/2022019443547660304">The modern age has richly rewarded people with a combination of high intelligence and high agency. N...</a></p>
<p>2. [[AINews] Z.ai GLM-5: New SOTA Open Weights LLM](https://www.latent.space/p/ainews-zai-glm-5-new-sota-open-weights)</p>
<p>3. <a href="http://arxiv.org/abs/2602.12281">Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment</a></p>
<p>4. <a href="http://arxiv.org/abs/2602.11389">Causal-JEPA: Learning World Models through Object-Level Latent Interventions</a></p>
<p>5. <a href="http://arxiv.org/abs/2602.11964">Gaia2: Benchmarking LLM Agents on Dynamic and Asynchronous Environments</a></p>
<p>6. <a href="http://arxiv.org/abs/2602.12063">VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model</a></p>
<p>7. <a href="http://arxiv.org/abs/2602.12215">LDA-1B: Scaling Latent Dynamics Action Model via Universal Embodied Data Ingestion</a></p>
<p>8. <a href="http://arxiv.org/abs/2602.12099">GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning</a></p>
<p>9. <a href="http://arxiv.org/abs/2602.11236">ABot-M0: VLA Foundation Model for Robotic Manipulation with Action Manifold Learning</a></p>
<p>10. <a href="https://www.latent.space/p/boltz">üî¨Beyond AlphaFold: How Boltz is Open-Sourcing the Future of Drug Discovery</a></p>
<p>11. <a href="https://www.latent.space/p/jeffdean">Owning the AI Pareto Frontier ‚Äî Jeff Dean</a></p>
<p>12. <a href="https://twitter.com/jerryjliu0/status/2022001467851411776">Existing AI agents are largely short-horizon (e.g. chat) or constrained (e.g. agentic process automa...</a></p>
<p>13. <a href="https://twitter.com/Scobleizer/status/2021862295421559158">You don't need a Mac Mini to run @OpenClaw.</a></p>
<p>14. <a href="http://arxiv.org/abs/2602.11541">Budget-Constrained Agentic Large Language Models: Intention-Based Planning for Costly Tool Use</a></p>
<p>15. <a href="http://arxiv.org/abs/2602.12218">The Observer Effect in World Models: Invasive Adaptation Corrupts Latent Physics</a></p>
<p>16. <a href="http://arxiv.org/abs/2602.11291">H-WM: Robotic Task and Motion Planning Guided by Hierarchical World Model</a></p>
<p>17. <a href="http://arxiv.org/abs/2602.11758">HAIC: Humanoid Agile Object Interaction Control via Dynamics-Aware World Model</a></p>
<p>18. <a href="http://arxiv.org/abs/2602.11978">Accelerating Robotic Reinforcement Learning with Agent Guidance</a></p>
<p>19. <a href="http://arxiv.org/abs/2602.11583">The Five Ws of Multi-Agent Communication: Who Talks to Whom, When, What, and Why -- A Survey from MARL to Emergent Language and LLMs</a></p>
<p>20. <a href="http://arxiv.org/abs/2602.11666">PhyNiKCE: A Neurosymbolic Agentic Framework for Autonomous Computational Fluid Dynamics</a></p>

    <hr>
    <footer>
        <p class="meta">Gardener Technical Reports | AI News Aggregator</p>
    </footer>
</body>
</html>
